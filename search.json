[{"title":"计算机组成 -- 异常","url":"%2F2020%2F01%2F20%2Fcomputer-organization-exception%2F","content":"\n## 异常\n1. 异常是一个**硬件和软件组合在一起的处理过程**\n   - 异常的**发生**和**捕捉**，是在**硬件**层面完成的\n   - 异常的**处理**，是在**软件**层面完成的\n2. 计算机会为每一种可能发生的异常，分配一个**异常代码**（Exception Number），别称**中断向量**（Interrupt Vector）\n3. 异常发生的时候，通常是CPU检测到一个特殊的**信号**\n   - 在组成原理里面，一般叫作发生了一个**事件**（Event），CPU在检测到事件的时候，就已经拿到了**对应的异常代码**\n4. 异常代码\n   - **IO**发出的信号的异常代码，是由**操作系统**来分配，即由**软件**来设定\n   - 像**加法溢出**这样的异常代码，是由**CPU预分配**的，即由**硬件**来设定\n5. 拿到**异常代码**后，CPU会触发**异常处理流程**\n   - 计算机在**内存**里，会保留一个**异常表**（Exception Table），别称**中断向量表**（Interrupt Vector Table）\n   - 存放的是不同的异常代码对应的异常处理程序所在的**地址**\n   - CPU拿到异常代码后，会先把当前程序的**执行现场**（CPU当前运行程序**用到的所有寄存器**），保存到**程序栈**里面\n   - 然后**根据异常代码查询**，找到对应的**异常处理程序**，最后把后续指令执行的**指挥权**，交给这个异常处理程序\n6. 异常可以由**硬件**触发，也可以由**软件**触发\n\n<!-- more -->\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-exception.jpg\" width=1000/>\n\n### 分类\n1. **中断**（Interrupt）\n   - 程序执行到**一半**的时候，被**打断**了，该打断执行的信号，来自于CPU外部的**IO设备**\n   - 在键盘上按下一个按键，就会触发一个相应的**信号**到达CPU\n     - CPU里面某个开关的值发生了变化，即触发了一个**中断类型**的异常\n2. **陷阱**（Trap）\n   - 陷阱是程序**主动触发**的异常\n   - **断点**\n     - 当程序的指令执行到某个位置时，会掉入这个陷阱中，然后，对应的**异常处理程序**会来处理\n   - **系统调用**\n     - 当应用程序**调用系统调用**时，会从程序的**用户态**切换到**内核态**\n     - 应用程序通过**系统调用**去读取文件、创建进程，也是通过触发一次**陷阱**来进行的\n       - 这是因为**用户态**的应用程序**没有权限**来做这些事情，要把对应的流程转交给**有权限的『异常处理程序』**来进行\n3. **故障**（Fault）\n   - 与陷阱的区别：陷阱是程序**刻意触发**的，而故障则不是\n   - 程序进行**加法计算**时发生了**溢出**，属于**故障**类型的异常\n   - 故障和陷阱、中断的一个重要区别\n     - **故障**在异常程序处理完成后，仍然回来处理**当前指令**，而不是去执行程序的下一条指令\n     - 因为当前指令因为故障的原因并没有成功执行完成，需要**重新执行**一次（抢救一下！）\n4. **中止**（Abort）\n   - 中止是故障的一种**特殊情况**\n   - 当**CPU遇到故障**，但恢复不过来的时候，程序不得不中止（退出程序执行）\n\n| 类型 | 原因 | 示例 | 触发时机 | 处理后操作 |\n| --- | --- | --- | --- | --- |\n| 中断 | **IO设备信号** | 用户键盘输入 | **异步** | 下一条指令 |\n| 陷阱 | **程序刻意触发** | 程序进行**系统调用**（用户态、内核态切换） | 同步 | 下一条指令 |\n| 故障 | **程序执行出错** | 程序加载的**缺页错误** | 同步 | **当前指令** |\n| 中止 | **故障无法恢复** | ECC内存校验失败 | 同步 | 退出程序 |\n\n1. 异步 + 同步\n   - **中断**异常的信号来自于**系统外部**，而不是在程序的执行过程中，因此称为**异步**类型的异常\n   - **陷阱**、**故障**以及**中止**类型的异常，是在程序执行的过程中发生的，因此称为**同步**类型的异常\n2. 在**处理异常**的过程中，无论是**异步的中断**，还是**同步的陷阱和故障**，都采用**统一**的处理流程\n   - **保存现场 -> 异常代码查询 -> 异常处理程序调用**\n   - **中止**类型的异常，是**故障**类型异常的一种**特殊**情况\n     - 当**中止**异常发生时，发现**没有异常处理程序能够处理这种异常**，程序不得不进入**中止**状态，**退出**当前程序的执行\n\n### 处理 -- 上下文切换\n1. 在实际的异常处理流程执行之前，CPU需要去做一次『**保存现场**』的操作\n   - 保存现场的操作，和**函数调用**的过程非常类似\n   - 切换到异常处理程序的时候，好像去**调用一个异常处理函数**，指令的**控制权**被切换到另一个函数里面\n   - 因此要把当前正在执行的指令去**压栈**，这样才能在异常处理程序执行完成之后，重新回到当前指令继续往下执行\n2. 切换到异常处理程序，比函数调用，是更**复杂**一些\n   - 因为异常情况通常发生在程序**正常执行的预期之外**，如中断、故障发生的时候\n     - 因此除了本来程序压栈要做的事情之外，还需要把**CPU当前运行程序用到的所有寄存器**，都放到**栈**里面\n       - 典型案例：**条件码寄存器**里面的内容\n   - **陷阱**：涉及程序指令在**用户态**和**内核态**之间的切换\n     - 在**压栈**的时候，对应的数据是压到**内核栈**里，而不是程序栈\n   - **故障**：在异常处理程序执行完成之后，从栈里返回出来，继续执行的不是顺序的下一条指令，而是**故障发生的当前指令**\n     - 因为当前指令因为故障没有正常执行成功，必须**重新执行**一次\n3. 异常处理流程，不像**顺序执行的指令间的函数调用关系**，而是更像**两个不同的独立进程**之间在**CPU层面的切换**\n   - 因此这个过程称为**上下文切换**（Context Switch）\n","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- 超线程 + SIMD","url":"%2F2020%2F01%2F19%2Fcomputer-organization-hyper-threading-simd%2F","content":"\n## 超线程 -- 线程级并行\n\n### Pentium 4\n1. Pentium 4失败的原因：**CPU的流水线级数太深**\n2. 超长的流水线，使得之前很多**解决冒险**、**提升并发**的方案都用不上\n3. 解决冒险、提升并发的方案，本质上是一种**指令级并行**的技术方案，即CPU希望在同一个时间，去**并行执行两条指令**\n  - 但这两条指令，原本在代码里是有**先后顺序**的\n4. 无论是**流水线架构**、**分支预测**以及**乱序执行**，还是**超标量**和**超长指令字**\n  - 都是想通过在同一时间执行两条指令，来提升CPU的**吞吐率**\n  - 但在Pentium 4上，上面这些方法都可能因为**流水线太深**，而**起不到效果**\n  - 更深的流水线意味着**同时在流水线里面的指令就很多，相互的依赖关系就多**\n  - 因此，很多时候不得不把**流水线停顿**下来，**插入很多NOP操作**，来解决这些**依赖**带来的**冒险**问题\n\n<!-- more -->\n\n### 超线程\n1. 无论是多个CPU核心运行不同的程序，还是单个CPU核心里切换运行不同线程的任务\n   - 在**同一时间**点上，**一个物理的CPU核心只会运行一个线程的指令**，其实并没有做到真正的**指令级并行**\n2. 超线程的CPU，把一个**物理**层面的CPU核心，**伪装**成两个**逻辑**层面的CPU核心\n   - 这个CPU会在硬件层面**增加很多电路**，使得可以在一个CPU核心内部，**维护两个不同线程的指令的状态信息**\n   - 在一个物理CPU核心内部，会有**双份**的**PC寄存器**、**指令寄存器**、**条件码寄存器**\n   - 在外面看来，似乎有**两个逻辑层面的CPU在同时运行**\n   - 因此，超线程技术也被叫为**同时多线程**（Simultaneous Multi-Threading，**SMT**）技术\n3. 但CPU的**其它**功能组件，**没有提供双份**，无论是**指令译码器**还是**ALU**，一个物理CPU核心仍然只有一份\n   - 因为**超线程并不是真的去同时运行两个指令**\n   - 超线程的目的：在线程A的指令在**流水线停顿**的时候，让线程B去执行指令，此时CPU的**指令译码器**和**ALU**是**空闲**的\n     - 线程B**没有**对线程A里面的指令有关联和**依赖**\n4. CPU通过**很小的代价**，就能实现同时运行多个线程的效果\n    - 只需要在CPU核心增加**10%左右的逻辑功能**，增加**可以忽略不计的晶体管数量**\n5. 超线程并**没有增加功能单元（ALU）**，所以超线程只在**特定的应用场景**下效果比较好\n   - 一般是**各个线程等待时间比较长**的应用场景\n   - 例如需要应对很多请求的**数据库应用**，就比较适合使用超线程，各个指令都要**等待访问内存数据**，但并**不需要做太多计算**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hyper-threading.jpg\" width=1000/>\n\n## SIMD -- 指令级并行\n1. **SIMD**：Single Instruction Multiple Data，**单指令多数据流**，支持SIMD的指令集：**MMX**、**SSE**\n2. 两段代码\n   - 通过**循环**的方式，给list里面的每一个数加1\n   - 实现相同的功能，直接调用**NumPy**库的add方法\n   - 性能差异：**32.72**\n3. 原因：NumPy直接用了**SIMD指令**，能够**并行**进行**向量的操作**\n   - 通过**循环**来一步一步计算的算法，称为**SISD**，**单指令单数据**\n   - 如果是**多核CPU**，可以同时处理多个指令的方式称为**MIMD**，**多指令多数据**\n4. SIMD在**获取数据**和**执行指令**的时候，都做了**并行**\n   - **从内存读取数据**的时候，SIMD**一次性读取多个数据**\n     - 下面程序数组里面的元素是**integer**，需要**4Bytes**的内存空间\n     - Intel在引入**SSE**指令集的时候，在CPU里添加了**8个128Bits的寄存器**\n       - **128Bits ≈ 16Bytes**，即一个寄存器可以**一次性加载4个整数**\n       - 比循环分别读取4次对应的数据，能节省不少时间\n   - 在数据读取之后，到了指令的**执行**层面，SIMD也是可以**并行执行**的\n     - 4个整数各自加1，互相之间**完全没有依赖**，即**不需要处理冒险问题**\n     - 只要CPU里有**足够的功能单元**，能够同时进行这些计算，那这个加法就是**4路同时并行**的\n     - 因此那些在**计算层面**存在大量『**数据并行**』的计算中，使用SIMD能够很好地提升性能\n   - 实践：**向量运算**（同一向量的不同维度之间的计算是**相互独立**的）、**矩阵运算**\n     - 图片、视频、音频的处理\n     - 机器学习算法的计算\n5. 基于**SIMD**的**向量计算指令**，是在Intel发布Pentium处理器的时候引入的指令集\n   - 当时的指令集叫作**MMX**（Matrix Math eXtensions，**矩阵数学扩展**）\n   - Pentium处理器，第一个有能力进行**多媒体处理**的CPU\n\n```python\n$ python\n>>> import numpy as np\n>>> import timeit\n>>> a = list(range(1000))\n>>> b = np.array(range(1000))\n>>> timeit.timeit(\"[i + 1 for i in a]\", setup=\"from __main__ import a\", number=1000000)\n32.260748863220215\n>>> timeit.timeit(\"np.add(1, b)\", setup=\"from __main__ import np, b\", number=1000000)\n0.9859158992767334\n```\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-simd.jpg\" width=1000/>","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- Superscalar + VLIW","url":"%2F2020%2F01%2F19%2Fcomputer-organization-superscalar-vliw%2F","content":"\n## 吞吐率\n1. 程序的CPU执行时间 = 指令数 × **CPI** × Clock Cycle Time\n2. CPI = Clock Per Instruction\n3. **IPC = 1/CPI = Instruction Per Clock**\n   - **一个时钟周期内能够执行的指令数**，代表了**CPU的吞吐率**\n   - **最佳**情况下，IPC只能到**1**\n     - 无论做了哪些流水线层面的优化，即使做到了**指令执行**层面的**乱序执行**\n     - CPU仍然**只能在一个时钟周期内取一条指令！！**\n     - 无论指令后续无论优化得多好，一个时钟周期也只能执行一条指令，**IPC只能是1**\n4. 但**Intel** CPU或者**ARM** CPU，一般IPC能做到**2**以上\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-superscalar-vliw-ipc.jpg\" width=1000/>\n\n<!-- more -->\n\n## 多发射 + 超标量\n1. **整数**计算过程和**浮点数**的计算过程**差异比较大**\n   - 整数计算和浮点数计算的**电路**，在CPU层面是**分开**的\n   - 一直到**80386**，CPU都是**没有专门的浮点数计算的电路**的，当时的浮点数计算，都是通过**软件**进行**模拟**的\n   - 在80386时代，Intel给386配了单独的**387芯片**，专门用来做**浮点数运算**\n     - **386dx**：**带**387浮点数计算芯片\n     - 386sx：不带387浮点数计算芯片\n2. CPU会有**多个ALU**，在**指令执行**阶段，会采用**乱序执行**，这是由很多个**功能单元**（FU）**并行**（Parallel）进行的\n   - 但**取指令**（IF）和**指令译码**（ID）并不是并行的\n3. **增加硬件**\n   - 一次性从内存里面取出**多条指令**，然后分发给多个**并行的指令译码器**，进行译码，然后对应交给不同的功能单元去处理\n     - **不同功能单元的流水线长度不同**\n     - 平时所说的**14**级流水线，通常指的是进行**整数计算**指令的流水线长度，如果是浮点数运算，实际的流水线长度会更长\n   - 这样在一个时钟周期内，能完成多条指令，**IPC**可以**大于1**\n   - 这种CPU设计，称为**多发射**（Mulitple Issue）或者**超标量**（Superscalar）\n     - **多发射**：在同一个时间，可能会**同时**把**多条指令**发射到不同的**译码器**或者后续处理的**流水线**中去\n     - **超标量**：本来在一个时钟周期内，只能执行一个**标量**（Scalar）的计算，在**多发射**的情况下，能够**同时进行多次计算**\n4. Intel从Pentium时代，第一次引入超标量技术，整个CPU的**性能上了一个台阶**，对应的技术，一直沿用至今\n    - **超标量**技术和**流水线**技术，都是依赖于**硬件层面**能够检测到对应的**指令的先后依赖关系**，解决**冒险**问题，但使得**电路变复杂**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-mulitple-issue.jpg\" width=1000/>\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-superscalar.jpg\" width=800/>\n\n## 超长指令字\n1. 无论是**乱序执行**，还是**超标量**，在实际的硬件层面，实施起来都比较麻烦，因为CPU要解决**依赖冲突**的问题（即**冒险**问题）\n   - 在指令执行之前，需要判断指令之间是否有依赖关系，如果有对应的**依赖**关系，指令就**不能分发到执行阶段**\n   - 对于**依赖关系的检测**，使得**CPU的电路**变得更加**复杂**\n2. 程序的CPU执行时间 = **指令数 × CPI × Clock Cycle Time**\n   - 可以通过改进**编译器**来优化**指令数**这个指标\n   - 诞生了**超长指令字设计**（Very Long Instruction Word，**VLIW**），尝试通过**编译器**来优化**指令数**和**CPI**\n3. 在**乱序执行**和**超标量**的CPU架构里，**指令的前后依赖关系**，是由CPU内部的**硬件电路**来检测的\n   - 到了**超长指令字**的架构里面，该工作交给了**编译器**来实现\n4. 编译器把**没有依赖关系**的代码位置进行**交换**，然后把**多条连续的指令**打包成一个**指令包**\n5. CPU运行时，不再是取一条指令，而是**取出一个指令包**，**译码解析整个指令包**，解析出3条指令直接**并行**运行\n6. 使用**超长指令字**架构的CPU，同样采用的是**流水线**架构，一组指令，仍然要经历多个时钟周期\n7. **流水线停顿**这件事情在**超长指令字**架构里面，很多时候也是由**编译器**实现的\n   - 除了**停下整个处理器流水线**，超长指令字架构的CPU**不能在某个时钟周期停顿一下**，等待前面依赖的操作执行完成\n   - **编译器**需要在适当的位置插入**NOP**操作，直接在编译出来的**机器码**里面，就已经把**流水线停顿**这件事在**软件层面**处理了\n8. 安腾处理器失败的原因\n   - 安腾处理器的**指令集**和**x86**是不同的，原来x86上的所有**程序**都没办法在安腾处理器上运行，需要通过编译器**重新编译**\n   - 安腾处理器的**VLIW**架构决定了如果安腾处理器需要**提升并行度**，就需要**增加一个指令包里包含的指令数**\n     - 一旦从3变成6，虽然**同为VLIW架构**，**同样指令集**的安腾处理器，程序也需要**重新编译**\n     - **编译器**判断**依赖关系**：3个指令以及由3个指令组成的指令包之间 -> 6个指令以及由6个指令组成的指令包之间\n       - 编译器需要**重新编译**，**交换指令顺序**和**插入NOP操作**，才能满足条件\n   - 不容易**向前兼容**，也不容易**向后兼容**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-vliw-1.jpg\" width=1000/>\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-vliw-2.jpg\" width=1000/>","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- 冒险","url":"%2F2020%2F01%2F17%2Fcomputer-organization-hazard%2F","content":"\n## 冒险\n1. 流水线架构的CPU，是**主动**进行的冒险选择，期望通过冒险带来**更高的回报**\n    - 对于各种冒险可能造成的问题，都准备好了**应对方案**\n2. 分类\n    - **结构冒险**（**Structural** Hazard）\n    - **数据冒险**（**Data** Hazard）\n    - **控制冒险**（**Control** Hazard）\n\n<!-- more -->\n\n## 结构冒险\n1. 结构冒险，本质上是一个**硬件层面的资源竞争问题**\n2. CPU在**同一个时钟周期**，同时在运行**两条计算机指令的不同阶段**，但这两个不同的阶段可能会用到**同样的硬件电路**\n\n### 内存的数据访问\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hazard-prediction-structural-mem-access.jpg\" width=1000/>\n\n1. 第1条指令执行到**访存**（MEM）阶段的时候，流水线的第4条指令，在执行**取指令**（Fetch）操作\n2. **访存**和**取指令**，都是要进行内存数据的读取，而**内存只有一个地址译码器**，只能在一个时钟周期内读取一条数据\n    - **无法同时执行**第1条指令的**读取内存数据**和第4条指令的**读取指令代码**\n\n### 解决方案\n1. 解决方案：**增加资源**\n2. **哈佛架构**\n   - 把内存分成两部分，它们**有各自的地址译码器**，这两部分分别是**存放指令的程序内存**和**存放数据的数据内存**\n   - 缺点：**无法**根据实际情况去**动态调整**\n3. **普林斯顿架构 -- 冯.诺依曼体系架构**\n   - 今天使用的CPU，仍然是冯.诺依曼体系架构，并没有把内存拆成程序内存和数据内存两部分\n1. **混合架构**\n   - 现代CPU没有在内存层面进行对应的拆分，但在**CPU内部的高速缓存**部分进行了区分，分成了**指令缓存**和**数据缓存**\n   - 内存的访问速度远比CPU的速度慢，**现代CPU并不会直接读取主内存**\n     - 会从主内存把**指令**和**数据**加载到**高速缓存**中，后续的访问都是访问高速缓存\n   - 指令缓存和数据缓存的拆分，使得CPU在进行**数据访问**和**取指令**的时候，不会再发生资源冲突的情况\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hazard-prediction-structural-solution.jpg\" width=600/>\n\n## 数据冒险\n1. **结构冒险**是**硬件层面**的问题，可以通过**增加硬件资源**的方式来解决；但还有很多冒险问题属于**程序逻辑**层面，最常见是**数据冒险**\n2. 数据冒险：**同时在执行多个指令之间，有数据依赖的情况**\n3. 依赖分类\n    - **先写后读**（Read After Write，**RAW**）\n    - **先读后写**（Write After Read，**WAR**）\n    - **写后再写**（Write After Write，**WAW**）\n\n### 依赖\n\n#### 写 -> 读\n```c raw.c\nint main() {\n    int a = 1;\n    int b = 2;\n    a = a + 2;\n    b = a + 3;\n}\n```\n```\n$ gcc -g -c raw.c\n$ objdump -d -M intel -S raw.o\n```\n```\n......\n0000000000000000 <main>:\nint main() {\n   0:\t55                   \tpush   rbp\n   1:\t48 89 e5             \tmov    rbp,rsp\n\tint a = 1;\n   4:\tc7 45 fc 01 00 00 00 \tmov    DWORD PTR [rbp-0x4],0x1\n\tint b = 2;\n   b:\tc7 45 f8 02 00 00 00 \tmov    DWORD PTR [rbp-0x8],0x2\n\ta = a + 2;\n  12:\t83 45 fc 02          \tadd    DWORD PTR [rbp-0x4],0x2\n\tb = a + 3;\n  16:\t8b 45 fc             \tmov    eax,DWORD PTR [rbp-0x4]\n  19:\t83 c0 03             \tadd    eax,0x3\n  1c:\t89 45 f8             \tmov    DWORD PTR [rbp-0x8],eax\n}\n  1f:\t5d                   \tpop    rbp\n  20:\tc3                   \tret\n```\n1. 内存地址12的机器码，把0x2添加到`rbp-0x4`对应的**内存地址**\n2. 内存地址16的机器码，从`rbp-0x4`这个**内存地址**里面读取，把值把写入到`eax`这个**寄存器**里面\n3. 必须保证：在内存地址16的指令读取`rbp-0x4`里面的值之前，内存地址12的指令写入到`rbp-0x4`的操作已经完成\n4. **写 -> 读**的依赖关系，一般称为**数据依赖**，即Data Dependency\n5. 简单理解：**先写入，才能读**\n\n#### 读 -> 写\n```c war.c\nint main() {\n  int a = 1;\n  int b = 2;\n  a = b + a;\n  b = a + b;\n}\n```\n```\n$ gcc -g -c war.c\n$ objdump -d -M intel -S war.o\n```\n```\n......\n0000000000000000 <main>:\nint main() {\n   0:\t55                   \tpush   rbp\n   1:\t48 89 e5             \tmov    rbp,rsp\n\tint a = 1;\n   4:\tc7 45 fc 01 00 00 00 \tmov    DWORD PTR [rbp-0x4],0x1\n\tint b = 2;\n   b:\tc7 45 f8 02 00 00 00 \tmov    DWORD PTR [rbp-0x8],0x2\n\ta = b + a;\n  12:\t8b 45 f8             \tmov    eax,DWORD PTR [rbp-0x8]\n  15:\t01 45 fc             \tadd    DWORD PTR [rbp-0x4],eax\n\tb = a + b;\n  18:\t8b 45 fc             \tmov    eax,DWORD PTR [rbp-0x4]\n  1b:\t01 45 f8             \tadd    DWORD PTR [rbp-0x8],eax\n}\n  1e:\t5d                   \tpop    rbp\n  1f:\tc3                   \tret\n```\n1. 内存地址15的指令，要把`eax`寄存器里面的值读出来，再加到`rbp-0x4`的内存地址\n2. 内存地址18的指令，要更新`eax`寄存器\n3. 如果内存地址18的`eax`的写入先完成，在内存地址为15的代码里面取出`eax`才发生，程序就会出错\n  - 同样要保证对于`eax`的**先读后写**的操作顺序\n4. **读 -> 写**的依赖关系，一般称为**反依赖**，即Anti Dependency\n5. 简单理解：**前一个读操作取出来的数据用于其它运算，后一个写操作就不能先执行完成**\n\n#### 写 -> 写\n```c waw.c\nint main() {\n  int a = 1;\n  a = 2;\n}\n```\n```\n$ gcc -g -c waw.c\n$ objdump -d -M intel -S waw.o\n```\n```\n......\n0000000000000000 <main>:\nint main() {\n   0:\t55                   \tpush   rbp\n   1:\t48 89 e5             \tmov    rbp,rsp\n\tint a = 1;\n   4:\tc7 45 fc 01 00 00 00 \tmov    DWORD PTR [rbp-0x4],0x1\n\ta = 2;\n   b:\tc7 45 fc 02 00 00 00 \tmov    DWORD PTR [rbp-0x4],0x2\n}\n  12:\t5d                   \tpop    rbp\n  13:\tc3                   \tret\n```\n1. 内存地址4的指令和内存地址b的指令，都是将对应的数据写入到`rbp-0x4`  的内存地址里面\n2. 必须保证：内存地址4的指令的写入，在内存地址b的指令的写入之前完成\n3. **写 -> 写**的依赖关系，一般称为**输出依赖**，即Output Dependency\n5. 简单理解：**覆盖写**\n\n### 解决方案 -- 流水线停顿\n1. 除了**读 -> 读**，对于**同一个**寄存器或者内存地址的操作，都有**明确强制的顺序要求**\n2. 解决数据冒险的简单方案：**流水线停顿**（Pipeline Stall）、别称：**流水线冒泡**（Pipeline Bubbling）\n  - 这是一种**以牺牲CPU性能为代价**的方案，在最坏的情况下，**流水线架构的CPU会退化成单指令周期的CPU！！**\n3. 在进行**指令译码**的时候，会拿到对应指令**所需要访问的寄存器和内存地址**\n  - 此时能判断这个指令是否会触发数据冒险，如果会触发数据冒险，可以决定让整个流水线**停顿一个或多个周期**\n4. 时钟信号会**不停地**在0和1之间**自动切换**，并**没有办法真的停顿下来**\n  - 在实践过程中，并不是让流水线停下来，而是在执行后面的操作步骤前**插入**一个**NOP**（No Option）操作\n  - 好像在一个水管里面，进了一个**空气泡**，因此也叫**流水线冒泡**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hazard-prediction-pipeline-stall.jpg\" width=1000/>\n\n## 操作数前推\n\n### 流水线对齐\n\n#### 五级流水线\n**取指令（IF） -> 指令译码（ID） -> 指令执行（EX） -> 内存访问（MEM） -> 数据写回（WB）**\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hazard-prediction-5-stage.jpg\" width=1000/>\n\n#### MIPS指令\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hazard-prediction-mips.jpg\" width=1000/>\n\n1. 在MIPS的体系结构下，**不同类型的指令，会在流水线的不同阶段进行不同的操作**\n2. **LOAD**：从**内存**里**读取**数据到**寄存器**\n  - 需要经历5个完整的流水线\n3. **STORE**：从**寄存器**往**内存**里**写入**数据\n  - 不需要有**写回寄存器**的操作，即没有**数据写回**（WB）的流水线阶段\n4. **ADD**、**SUB**\n  - 加减法指令，**所有操作**都在**寄存器**完成，没有实际的**内存访问**（MEM）操作\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hazard-prediction-mips-load-store-r.jpg\" width=1000/>\n\n1. 有些指令没有对应的流水线阶段，但**不能跳过对应的阶段**直接执行下一阶段\n2. 如果先后执行一条LOAD指令和一条ADD指令，LOAD指令的WB阶段和ADD指令的WB阶段，在**同一个时钟周期**发生\n  - 相当于触发了一个**结构冒险**事件，产生了**资源竞争**\n3. 在实践中，各个指令不需要的阶段，**不会直接跳过**，而是会运行一次**NOP**操作\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hazard-prediction-mips-load-add.jpg\" width=800/>\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hazard-prediction-mips-nop.jpg\" width=1000/>\n\n### 操作数前推\n1. 通过**NOP**操作进行对齐，在流水线里，就不会遇到**资源竞争**产生的**结构冒险**问题\n  - NOP操作，即**流水线停顿**插入的对应操作\n2. 插入过多的**NOP**操作，意味着CPU**空转**增多\n\n```c\n// s1 s2 t0都是寄存器\nadd $t0, $s2,$s1 // s1 + s2 -> t0\nadd $s2, $s1,$t0 // s1 + t0 -> s2\n```\n1. 后一条add指令，依赖寄存器t0的值，而t0里面的值，又来自于前一条add指令的计算结果\n  - 因此后一条add指令，需要等待前一条add指令的**数据写回**（WB）阶段完成之后才能执行\n2. 这是一个**数据冒险**：**数据依赖**类型（**写 -> 读**），上面的方案是通过**流水线停顿**来解决这个问题\n3. 要在第二条指令的**译码**阶段之后，插入对应的NOP指令，直到前一条指令的数据写回完成之后，才能继续执行\n4. 这虽然解决了数据冒险的问题，但也**浪费了两个时钟周期**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hazard-prediction-mips-nop-2-add.jpg\" width=1000/>\n\n1. 第二条指令的执行，未必需要等待第一条指令写回完成才能进行\n2. 如果能够把第一条指令的执行结果**作为输入直接传输**到第二条指令的执行阶段\n  - 那第二条指令就不用再从**寄存器**里面，把数据再单独读取出来才能执行代码\n  - 可以在第一条指令的**执行（EX）阶段完成**之后，直接将结果数据传输到下一条指令的**ALU**\n    - 这样，下一条指令不再需要再插入两个NOP阶段，就可以正常走到执行阶段\n3. 上面的方案就是**操作数前推**（Operand **Forwarding**）、**操作数旁路**（Operand **Bypassing**）\n  - Forwarding：**逻辑**含义，第一条指令的执行结果**作为输入直接转发**给第二条指令的ALU\n  - Bypassing：**硬件**含义，为了实现Forwarding，在CPU的硬件层面，需要**单独**拉出一根信号传输的线路\n    - 使得ALU的计算结果能够**重新回到**ALU的输入\n    - 越过了**写入寄存器**，再**从寄存器读出来**的过程，可以**节省两个时钟周期**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hazard-prediction-mips-operand-forwarding-2-add.jpg\" width=1000/>\n\n1. **操作数前推**的解决方案可以和**流水线停顿**一起使用\n  - 虽然可以把操作数转发到下一条指令，但下一条指令仍然需要停顿一个时钟周期\n2. 先执行一条LOAD指令，再执行ADD指令\n  - LOAD指令在访存阶段才能把数据读取出来，下一条指令的执行阶段，需要等上一阶段的访存阶段完成之后，才能进行\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hazard-prediction-mips-operand-forwarding-load-add.jpg\" width=1000/>\n\n**操作数前推并不能减少所有冒泡**，只能去掉其中一部分，仍然需要通过插入一些**NOP**来解决**数据冒险**问题\n\n## 乱序执行\n1. **结构冒险**\n  - 限制来源：**在同一时钟周期内，不同的指令的不同流水线阶段，要访问相同的硬件资源**\n  - 解决方案：_**增加资源**_\n2. **数据冒险**\n  - 限制来源：**数据之间的各种依赖**\n  - 解决方案：_**流水线停顿**、**操作数前推**_\n3. 即便综合运用这三个技术，仍然会遇到**不得不停下整个流水线**，等待前面的指令完成的情况\n\n### 填补空闲的NOP\n1. 无论是**流水线停顿**，还是**操作数前推**，只要前面指令的特定阶段还没有执行完成，后面的指令就会被**阻塞**\n2. 虽然**代码生成**的指令是**顺序**的，如果后面的指令**不需要依赖**前面指令的执行结果，完全可以**不必等待**前面的指令执行完成\n  - 这样的解决方案，在计算机组成里面，被称为**乱序执行**（**Out-of-Order** Execution，OoOE）\n\n```c\na = b + c\nd = a * e\nx = y * z\n```\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hazard-prediction-3-command.jpg\" width=1000/>\n\n### 实现过程\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hazard-prediction-oooe.jpg\" width=1000/>\n\n1. **取指令**和**指令译码**阶段，乱序执行的CPU和使用流水线架构的CPU是一样的，会**一级一级顺序进行**\n2. 指令译码完成后，CPU**不会直接进行指令执行**，而是进行一次**指令分发**\n  - 指令分发：把指令分发到**保留站**（Reservation Stations，RS）\n    - 类比：**保留站 -> 火车站**，**指令 -> 火车**\n  - 这些**指令不会立即执行**，而是等待它们**所依赖的数据**，传递给它们之后才会执行\n    - 类比：**数据 -> 乘客**，火车需要等乘客\n3. 一旦指令依赖的数据到齐了，指令就可以交到后面的**功能单元**（Function Unit，FU，本质是**ALU**）去执行了\n  - 很多功能单元是可以**并行运行**的，但**不同的功能单元能够支持执行的指令是不相同的**\n4. 指令执行阶段完成后，我们并**不能立即把结果写回到寄存器**里面，而是把结果先存放到**重排序缓冲区**（ReOrder Buffer，ROB）\n5. 在**重排序缓冲区**里，我们的CPU会按照**取指令的顺序**，对指令的计算结果重新排序\n  - 只有**排在前面的指令**都已经**完成**了，才会**提交指令**，完成整个指令的运算结果\n6. 实际的指令计算结果数据，并**不是直接写到内存或者高速缓存**，而是先写入**存储缓冲区**（Store Buffer）\n  - **最终才会写入内存和高速缓存**\n7. 在乱序执行的情况下，只有**CPU内部指令的执行层面**，可能是**乱序**的\n  - 只要能在**指令译码**阶段**正确地分析出指令之间的数据依赖关系**，『乱序』就只会在**相互没有影响**的指令之间发生\n    - 相互没有影响 ≈ **不破坏数据依赖**\n  - 即便指令的执行过程是乱序的，在指令的计算结果**最终写入到寄存器和内存之前**，依然会进行一次**排序**\n    - 以确保**所有指令**在**外部看来**仍然是**有序完成**的\n\n### 回到样例\n```c\na = b + c\nd = a * e\nx = y * z\n```\n1. d依赖于a的计算结果，不会在a的计算完成之前执行\n2. `x = y * z`的指令同样会被分发到**保留站**，x所依赖的y和z的数据是准备好的，这里的乘法运算不会等待d的计算结果\n3. 如果只有一个FU能够计算乘法，那么这个FU并不会因为d要等待a的计算结果而被限制，会先被拿来计算x\n4. x计算完成后，d也等来了a的计算结果，此时，唯一的乘法FU会去计算d的结果\n5. 在**重排序缓冲区**里，把对应的计算结果的提交顺序，仍然设置为**a->d->x**，但实际计算完成的顺序是**x->a->d**\n6. 整个过程中，计算乘法的FU**没有被闲置**，意味着**CPU的吞吐率最大化**\n\n### 小结\n1. 整个乱序执行技术，类似于在**指令的执行阶段**提供了一个**线程池**，**FU**就是**线程**\n  - 指令不再是顺序执行的，而是根据线程池所**拥有的资源**，各个任务**是否可以进行执行**，进行**动态调度**\n  - 在执行完成之后，又重新把结果放在一个**队列**里面，**按照指令的分发顺序重新排序**\n  - 即使内部是『乱序』的，但**外部看来**，仍然是**顺序执行**的\n2. 乱序执行，**极大地提高了CPU的运行效率**\n  - 核心原因：**CPU的运行速度比访问主内存的速度快很多**\n  - 如果采用**顺序执行**的方式，很多时间会被浪费在前面指令**等待获取内存数据**\n    - 为此，CPU不得不加入**NOP**操作进行**空转**\n  - 乱序执行充分利用了**较深流水线**带来的**并发性**，可以充分利用CPU的性能\n\n## 控制冒险\n1. 在**结构冒险**和**数据冒险**中，所有的**流水线停顿**都要从**指令执行**（EX）阶段开始\n  - 流水线的前两个阶段，即**取指令**（IF）和**指令译码**（ID），是不需要停顿的\n  - 基于一个基本假设：所有的指令代码都是**顺序加载执行**的\n    - 不成立的情况：在执行的代码中，遇到**if/else**条件分支，或者**for/while**循环\n2. jne指令发生的时候，CPU可能会跳转去执行其它指令\n  - jne后的那一条指令是否应该顺序加载执行，在流水线里进行**取指令**的时候，是**无法知道**的\n  - 要等到**jne指令执行完成**，更新了**PC寄存器**后，才能知道是否执行下一条指令，还是跳转到另一个内存地址，去取别的指令\n3. 为了确保能**取到正确的指令**，不得不进行**等待延迟**的情况，这就是**控制冒险**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hazard-prediction-if.jpg\" width=1000/>\n\n### 缩短分支延迟\n1. **条件跳转指令**实际上进行了两种电路操作：**条件比较** + **实际跳转**\n2. **条件跳转**\n  - 根据**指令的opcode**，就能确认**对应的条件码寄存器**\n3. **实际跳转**\n  - 把要**跳转的地址**写入到**PC寄存器**\n4. 无论是**指令的opcode**，还是**对应的条件码寄存器**，还是**跳转的地址**，都是在**指令译码**阶段就能获得的\n  - 对应的**条件码比较电路**，只需要**简单的逻辑门电路**即可，并不需要一个完整而复杂的ALU\n  - 可以将**条件判断**、**地址跳转**，都提前到**指令译码**阶段进行，而不需要放在**指令执行**阶段\n  - 在CPU里面设计对应的**旁路**，在**指令译码**阶段，就提供对应的**判断比较的电路**\n5. 这种方式，本质上和前面**数据冒险**的**操作数前推**的解决方案类似，就是在**硬件电路层面**，把一些计算结果**更早地反馈**到流水线中\n  - 这样反馈会变得更快，后面的指令需要**等待的时间**就会**变短**\n6. 只是**改造硬件**，并**不能彻底解决问题**\n  - 跳转指令的比较结果，仍然要在**指令执行**完成后才能知道\n  - 在流水线里，第一条指令进行**指令译码**的时钟周期里，其实就要**取下一条指令**了\n    - 但由于第一条指令还没开始指令执行阶段，此时并不知道比较的结果，自然也就无法准确知道要取哪一条指令了\n\n### 分支预测\n\n#### 静态预测\n1. CPU预测：条件跳转**一定不发生**\n2. 如果**预测成功**，可以**节省**本来需要停顿下来**等待的时间**\n2. 如果**预测失败**，需要**丢弃**后面已经取出指令且已经执行的部分\n  - 这个丢弃的操作，在流水线里面叫作**Zap**或者**Flush**\n  - CPU不仅要执行后面的指令，对于已经在流水线里面**执行到一半**的指令，还需要做对应的**清除**操作\n    - 例如清空已经使用的**寄存器**里面的数据，而这些清除操作，有一定的**开销**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hazard-prediction-static-prediction.jpg\" width=1000/>\n\n#### 动态预测\n1. **一级分支预测**（One Level Branch Prediction）、**1比特饱和计数**（1-bit saturating counter）\n  - 用**1Bit**，记录当前分支的比较情况，**直接用当前分支的比较情况来预测下一次分支的比较情况**\n2. **状态机**（State Machine）\n  - 如果状态机总共有**4个状态**，需要2个比特来记录对应的状态，这样的策略叫作**2比特饱和计数**或者**双模态预测器**\n\n#### 循环嵌套\n```java\npublic class BranchPrediction {\n    public static void main(String args[]) {\n        long start = System.currentTimeMillis();\n        for (int i = 0; i < 100; i++) {\n            for (int j = 0; j < 1000; j++) {\n                for (int k = 0; k < 10000; k++) {\n                }\n            }\n        }\n        long end = System.currentTimeMillis();\n        System.out.println(\"Time spent is \" + (end - start));\n\n        start = System.currentTimeMillis();\n        for (int i = 0; i < 10000; i++) {\n            for (int j = 0; j < 1000; j++) {\n                for (int k = 0; k < 100; k++) {\n                }\n            }\n        }\n        end = System.currentTimeMillis();\n        System.out.println(\"Time spent is \" + (end - start) + \"ms\");\n    }\n}\n```\n```\nTime spent is 4\nTime spent is 19ms\n```\n1. 循环其实也是利用**cmp**和**jle**指令来实现的\n2. 每一次循环都有一个**cmp**和**jle**指令\n  - 每一个**jle**都意味着要**比较条件码寄存器的状态**，来决定是**顺序执行**代码，还是要**跳转**到另外的地址\n  - 每一次**循环发生**的时候，都会有一次『**分支**』\n3. 分支预测策略最简单的方式：假设分支**不发生**\n  - 对应循环，就是**循环始终进行下去**\n4. 上面第一段代码**分支预测错误**的情况**比较少**\n  - 更多的计算机指令，在流水线里顺序运行下去了，而不是把运行到一半的指令丢弃掉，再去重新加载新的指令执行\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-hazard-prediction-loop.jpg\" width=800/>","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- 指令流水线","url":"%2F2020%2F01%2F17%2Fcomputer-organization-instruction-pipeline%2F","content":"\n## 单指令周期处理器\n1. 一条CPU指令的执行：**Fetch -> Decode -> Execute**\n   - 这个执行过程，**最少**需要花费**一个时钟周期**，因为在**取指令**的时候，需要通过时钟周期的信号，来决定**计数器的自增**\n2. **单指令周期处理器**（Single Cycle Processor）：在**一个时钟周期**内，处理器正好能**处理一条指令**，即**CPI**为**1**\n3. 时钟周期是**固定**的，但指令的**电路复杂程度**是不同的，因此一条指令的**实际执行时间**是不同的\n   - 随着**门电路层数**的增加，由于**门延迟**的存在，**位数多、计算复杂**的指令需要的执行时间会更长\n4. 不同指令的执行时间不同，但需要让**所有指令**都在一个时钟周期内完成，只能把时钟周期和**执行时间最长的指令**设成一样\n   - 快速执行完成的指令，需要等待**满**一个时钟周期，才能执行下一条指令\n5. CPI能够保持在1，但**时钟频率没办法设置太高**，因为有些**复杂指令**是没办法在一个时钟周期内运行完成的\n   - 在下一个时钟周期到来，开始执行下一条指令的时候，前一条指令的执行结果可能还没有写入到**寄存器**里\n   - 那么下一条指令读取的数据就是**不准确**的，会**出现错误**\n6. 无论是PC上使用的**Intel CPU**，还是手机上使用的**ARM CPU**，都不是单指令周期处理器，而是采用了**指令流水线**的技术\n\n<!-- more -->\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-instruction-pipeline-single-cycle-processor-1.jpg\" width=800/>\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-instruction-pipeline-single-cycle-processor-2.jpg\" width=800/>\n\n## 流水线设计\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-instruction-pipeline.jpg\" width=1000/>\n\n1. 不用把**时钟周期**设置成**整条指令**执行的时间，而是拆分成完成一个**小步骤**需要的时间\n2. 每一阶段的电路在完成对应的任务之后，不需要等待整个指令执行完成，而是可以**直接执行下一条指令的对应阶段**\n3. 每一个独立的步骤，称之为**流水线阶段**或者**流水线级**（Pipeline **Stage**）\n4. 如果把一个指令的执行过程拆分成：**Fetch -> Decode -> Execute**，那么这就是**三级**的流水线\n   - 如果进一步把**Execute**拆分成：**ALU计算（指令执行）-> 内存访问 -> 数据写回**，那么就会变成一个**五级**的流水线\n   - 五级的流水线，表示在**同一个时钟周期**内，**同时运行五条指令的不同阶段**\n   - 虽然执行一条指令的时钟周期变成了**5**，但可以把**CPU的主频提得更高**\n5. 不需要确保最复杂的指令在时钟周期内执行完成，只要保证一个**最复杂的流水线级的操作**，能在一个**时钟周期**内完成\n   - 如果某一个操作步骤的时间太长，可以将该步骤拆分成更多的步骤，让所有步骤需要**执行的时间都尽量差不多**\n6. 解决的问题\n   - 单指令周期处理器的**性能瓶颈**来自于**最复杂的指令**\n   - 不能通过流水线，来减少**单条指令执行的延时**；但通过**同时执行多条指令的不同阶段**，提升了CPU的**吞吐率**\n7. 现代的**ARM CPU**或者**Intel CPU**，流水线级已经到达了**14级**\n\n### 性能瓶颈\n1. **增加流水线深度**，是有**性能成本**的\n2. 用来同步时钟周期的，不再是指令级别的，而是**流水线阶段级别**的\n3. 每一级流水线对应的输出，都要放到**流水线寄存器**里面，然后在**下一个时钟周期**，交给**下一个流水线级**去处理\n   - 每增加一级的流水线，就要多一级写入到流水线寄存器的操作（速度非常快，**$20ps = 20 \\times 10^{-12}s$**）\n   - 如果不断地加深流水线，开销就会越大，单纯地增加流水线级数，不仅不能提升性能，反而会有更多的**overhead**的开销\n\n<img src=https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-instruction-pipeline-performance-bottleneck.jpg width=1000/>\n\n## 奔腾4\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-instruction-pipeline-pentium-4.jpg\" width=1000/>\n\n1. 为了达到10GHz，在NetBurst架构中，使用了**超长的流水线**\n   - Pentium III的流水线深度为**11级**，现在日常使用的手机ARM CPU或者Intel i7服务器的CPU，流水线的深度是**14级**\n   - Pentium 4的流水线深度是**20级**，到了代号为Prescott的90纳米工艺处理器Pentium 4，流水线深度增加到了**31级**\n2. 在**同主频**下，**增加流水线深度**，其实是**降低了CPU的性能**\n   - 因为一个**Pipeline Stage**，就需要一个**时钟周期**\n   - **31**个Stage的**3GHz**主频的CPU，其实和**11**个Stage的**1GHz**主频的CPU，性能其实是**差不多**的\n     - 实际上，因为每个Stage都需要对应的**Pipeline寄存器的开销**，更深的流水线性能可能还会**更差**\n\n### 响应时间 + 吞吐率\n1. 流水线技术不能缩短**单条指令**的**响应时间**这个性能指标，但可以增加在运行**很多条指令**时候的**吞吐率**\n   - 因为不同的指令，实际执行需要的时间是不同的\n2. 顺序执行3条指令\n   - 一条整数的加法，需要200ps\n   - 一条整数的乘法，需要300ps\n   - 一条浮点数的乘法，需要600ps\n3. 在单指令周期CPU上运行，三条指令都需要600ps，总执行时间为**1800ps**\n4. 如果采用**6级**流水线CPU，每个Pipeline Stage都只需要100ps\n   - 指令1的第一个100ps的Stage结束之后，指令2就开始执行\n   - 指令2的第一个100ps的Stage结束之后，指令3就开始执行\n   - 3条指令顺序执行所需要的总时间为**800ps**\n   - 在1800ps内，使用流水线的CPU比单指令周期的CPU可以多执行一倍以上的指令数\n   - 每条指令从开始到结束的时间并没有变化，即**响应时间没有变化**，但同样的时间内，完成的指令数增多了，即**吞吐率上升**了\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-instruction-pipeline-pentium-4-response-time-throughput.jpg\" width=600/>\n\n### 冒险 + 分支预测\n1. Intel CPU支持的指令集很大（2000+）\n   - 有的指令很**简单**，如无条件跳转指令，不需要通过ALU进行任何计算，只需要更新一下PC寄存器里面的内容即可\n   - 有的指令很**复杂**，如浮点数的运行，需要进行指数位比较、对齐，然后对有效位进行移位，然后再进行计算\n   - 两者的执行时间可能相差**二三十倍**，那Pentium 4的超长流水线是不是很合理？\n2. Pentium 4失败的主要原因：**功耗问题**\n   - **提升流水线深度**，必须要和**提升CPU主频**同时进行，才能保持和原来**相同的性能**\n   - 由于流水线深度的增加，需要的电路数也变多了，也就是所使用的**晶体管**也变多了\n   - 功耗变大的原因：**主频提升** + **晶体管数量增加**\n\n#### 冒险\n```java\nint a = 10 + 5; // 指令1\nint b = a * 2; // 指令2\nfloat c = b * 1.0f; // 指令3\n```\n1. 指令2不能在指令1的第一个Stage结束后进行，因为指令2**依赖**指令1的计算结果，同样指令3也依赖指令2的计算结果\n2. 即使采用了流水线技术，这三条指令执行完成的时间为`200 + 300 + 600 = 1100ps`，而非前面的**理论值800ps**\n   - 流水线技术带来的**性能提升**，只是一个**理想情况**\n3. 上面的**依赖问题**，就是计算机组成里面所说的**冒险**（Hazard）\n   - 上面的例子是数据层面的依赖，即**数据冒险**\n   - 在实际应用中，还会有**结构冒险**、**控制冒险**等其它依赖问题\n   - 解决方案：**乱序执行**、**分支预测**\n4. **流水线越长，冒险的问题越难解决**，因为同一时间**同时运行**的指令太多了\n5. 如果是20级流水线，需要确保这20条指令之间没有依赖关系\n   - 而平时写程序，通常前后的代码都有一定的依赖关系\n   - 所以超长流水线的**执行效率**反而**下降**了\n\n#### 乱序执行\n```java\nint a = 10 + 5; // 指令1\nint b = a * 2; // 指令2\nfloat c = b * 1.0f; // 指令3\nint x = 10 + 5; // 指令4\nint y = a * 2; // 指令5\nfloat z = b * 1.0f; // 指令6\nint o = 10 + 5; // 指令7\nint p = a * 2; // 指令8\nfloat q = b * 1.0f; // 指令9\n```\n1. 先执行1、4、7三条指令，这三条指令之间是没有**依赖**关系的\n2. 再执行2、5、8以及3、6，9，这样又能够**充分利用**CPU的计算能力\n\n## 小结\n1. 流水线技术和其它技术一样，都讲究**折衷**（Trade-Off）\n2. 一个合理的流水线深度，会提升CPU执行计算机指令的**吞吐率**\n3. 一般用**IPC**（Instruction Per Cycle）来衡量CPU执行指令的**效率**\n   - IPC是**CPI**（Cycle Per Instruction）的**倒数**\n4. **过深的流水线**，不仅不能提升计算机指令的吞吐率，还会加大计算的**功耗**和**散热**问题\n5. 流水线技术带来的**吞吐率提升**，只是一个理想情况下**理论值**，实际应用中，还需要解决**指令之间的依赖问题**\n   - **超长**的流水线的**执行效率**变得很低","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- 建立数据通路","url":"%2F2020%2F01%2F16%2Fcomputer-organization-build-data-path%2F","content":"\n## 三种周期\n### 指令周期\n1. 执行一条指令的过程\n   - **Fetch**（取得指令）\n     - 从**PC寄存器**里面找到对应的**指令地址**，根据指令地址从**内存**里把具体的指令，**加载到指令寄存器**中\n     - 然后把PC寄存器**自增**，便于未来执行下一条指令\n   - **Decode**（指令译码）\n     - 根据**指令寄存器**里面的指令，解析成要进行什么样的操作，是**R、I、J**中的哪一种指令\n     - 具体要操作哪些**寄存器**、**数据**或者**内存地址**\n   - **Execute**（执行指令）\n     - **实际运行**对应的R、I、J这些特定的指令，进行**算术逻辑操作**、**数据传输**或者**直接的地址跳转**\n   - 重复上面步骤\n2. **指令周期**（Instruction Cycle）：**Fetch -> Decode -> Execute**\n\n<!-- more -->\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-build-data-path-instruction-cycle.jpg\" width=800/>\n\n#### 涉及的组件\n1. **取指令**的阶段，指令是放在**存储器**里的\n2. 通过**PC寄存器**和**指令寄存器**取出指令的过程，是由**控制器**（Control Unit）操作的\n3. 指令的**解码**过程，也是由**控制器**进行的\n4. 一旦到了**执行指令**阶段，R、I型指令都是由**算术逻辑单元**（ALU）操作\n    - 进行**算术操作**、**逻辑操作**的**R型**指令\n    - 进行**数据传输**、**条件分支**的**I型**指令\n5. 如果是**简单的无条件地址跳转**，可以直接在**控制器**里面完成，不需要用到运算器\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-build-data-path-instruction-cycle-component.jpg\" width=800/>\n\n### 机器周期\n1. Machine Cycle：**机器周期**或者**CPU周期**\n2. CPU内部的操作速度很快，但访问内存的速度却慢很多，每条指令都需要从内存里面加载而来\n    - 一般把**从内存里读取一条指令的最短时间**，称为CPU周期\n\n### 时钟周期\n1. Clock Cycle：**时钟周期**（主频）\n\n### 三者关系\n1. 一个**CPU周期（机器周期）**，通常会由几个**时钟周期**累积起来\n2. 对于一个**指令周期**来说，取出一条指令，然后执行它，至少需要**两个CPU周期**\n    - 取出指令至少需要一个CPU周期，执行指令至少也需要一个CPU周期\n      - **指令译码**只需要**组合逻辑电路**，**不需要一个完整的时钟周期** -- **时间很短**\n    - 复杂的指令规则需要更多的CPU周期\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-build-data-path-cycle.jpg\" width=1000/>\n\n## 建立数据通路\n1. **数据通路**就是处理器单元，由两类元件组成：**操作元件**、**存储元件**\n2. **操作元件**\n   - 也称为**组合逻辑元件**，即**ALU**\n   - 功能：在特定的输入下，根据**组合电路**的逻辑，生成特定的输出\n3. **存储元件**\n   - 也叫**状态元件**，如计算过程中用到的寄存器，不论是**通用寄存器**还是**状态寄存器**，都是存储元件\n4. 通过**数据总线**的方式，把操作元件和存储元件连接起来，就可以完成数据的**存储**、**处理**和**传输**了，**建立了数据通路**\n\n### 控制器\n1. 控制器只是机械地重复**Fetch -> Decode -> Execute**循环中的前两个步骤\n   - 然后把在最后一个步骤通过**控制器**产生的**控制信号**，交给**ALU**去处理\n2. **所有CPU支持的指令**，都会在**控制器**里面，被解析成不同的**输出信号** -- **电路非常复杂**\n3. 运算器里的ALU和各种组合逻辑电路，可以认为是一个固定功能的电路\n   - 控制器翻译出来的就是不同的**控制信号**\n   - 这些控制信号，告诉**ALU**去做不同的计算\n4. **指令译码器**将输入的**机器码**（机器指令），解析成不同的**操作码**和**操作数**，然后传输给**ALU**进行计算\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-build-data-path-controller.jpg\" width=600/>\n\n### 所需硬件电路\n1. **ALU**\n   - 一个**没有状态**的，**根据输入计算输出**的组合逻辑电路\n2. **寄存器**\n   - 一个能进行**状态读写**的电路元件\n   - 这个电路能够**存储上一次的计算结果**\n   - 常见实现：**锁存器**（Latch）、**D触发器**（Data/Delay Flip-flop）\n3. 『**自动**』的电路\n   - 按照固定的周期，不停地实现**PC寄存器**自增，自动去执行**Fetch -> Decode -> Execute**的步骤\n   - **PC寄存器 = 程序计数器**\n4. 『**译码**』的电路\n   - 对**指令**进行**decode**\n   - 拿到**内存地址**去**获取**对应的数据或者指令\n\n## 时序逻辑电路\n1. **组合**逻辑电路：**只需要给定输入，就能得到固定的输出**\n2. **时序**逻辑电路解决的问题\n   - **自动运行**\n     - 时序电路接通之后可以不停地开启和关闭开关，进入一个自动运行的状态\n     - 场景：控制器不停地让PC寄存器**自增读取**下一条指令\n   - **存储**\n     - 通过时序电路实现的**触发器**，能把计算结果**存储在特定的电路**里面\n     - 不像组合逻辑电路那样，一旦输入有任何变化，对应的输出也会改变\n   - 本质上解决了各个功能按照**时序协调**的问题\n     - 无论是程序实现的软件指令，还是硬件层面的各种指令操作，都有先后的顺序要求\n     - 时序电路使得不同的事件按照**时间顺序**发生\n\n### 时钟信号\n1. CPU的**主频**是由一个**晶体振荡器**来实现的，而这个晶体振荡器生成的**电路信号**，就是**时钟信号**\n2. 开关A，一开始是断开的，由**手工控制**；另一个开关B，一开始是合上的；磁性线圈对准开关B\n   - 一旦合上开关A，磁性线圈会通电，产生磁性，开关B就会从合上变成断开\n   - 一旦开关B断开，电路中断，磁性线圈失去磁性，于是开关B又会**弹回到**合上的状态\n   - 这样，电路就会来回不断地在**开启**、**关闭**两个状态中切换，对**下游电路**来说，就不断地产生**0**和**1**的信号\n3. 这种按照**固定周期**不断在0和1之间切换的信号，就是**时钟信号**（Clock Signal）\n4. **反馈电路**：_**把电路的输出信号作为输入信号，在回到当前电路**_\n   - 通过**反相器**（Inverter）实现的时钟信号\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-build-data-path-crystal-oscillator.jpg\" width=800/>\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-build-data-path-clock-signal.jpg\" width=800/>\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-build-data-path-feedback-circuit-inverter.jpg\" width=800/>\n\n### D触发器 -- 存储\n\n#### RS触发器\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-build-data-path-rs-trigger.jpg\" width=1000/>\n\n##### 或非门\n| NOR | **0** | **1** |\n| --- | --- | --- |\n| **0** | 1 | 0 |\n| **1** | 0 | 0 |\n\n##### 过程\n1. 电路一开始，输入开关都是关闭的\n   - A的输入：<0,0>，A的输出：1\n   - B的输入：<1,0>，B的输出：0，反馈到A，没有任何变化，Q的输出：0\n2. 把A的开关R合上\n   - A的输入：<0,1>，A的输出：0\n   - B的输入：<0,0>，B的输出：1，反馈到A，Q的输出：1\n   - A的输入：<1,1>，A的输出：0\n   - 电路仍然是**稳定**的，不会像晶振那样震荡\n3. 把A的开关R打开\n   - A的输入：<1,0>，A的输出：0\n   - B的输入：<0,0>，B的输出：1，反馈到A，Q的输出：1\n   - 电路依然是**稳定**的，开关R、S的状态和第一步是一样的，但Q的输出是1（**保留上一步的输出**）\n4. 把B的开关S合上\n   - B的输入：<?,1>，B的输出：0，Q的输出：0\n5. 小结\n   - **接通开关R，输出变为1，即使断开开关，输出还是1；接通开始S，输出变为0，即使断开开关，输出还是0**\n   - **当两个开关都断开的时候，最终的输出结果，取决于之前动作的输出结果 -- 记忆功能**\n   - RS触发器也称为**复位置位**触发器（**Reset-Set Flip Flop**）\n\n| R | S | Q |\n| --- | --- | --- |\n| 1 | 0 | 1 |\n| 0 | 1 | 0 |\n| 0 | 0 | Q |\n| 1 | 1 | NA |\n\n#### D触发器\n\n##### 控制何时往Q写入数据\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-build-data-path-rs-flip-flop-clk.jpg\" width=1000/>\n\n1. 在RS触发器的基础上，在R和S开关之后，加入两个**与门**，同时给这两个与门加入一个**时钟信号CLK**作为电路输入\n2. 当时钟信号CLK在**低电平**的时候，与门的输入里有一个0，两个实际的R和S后的与门的输出**必然为0**\n   - 无论怎么按R和S开关，根据R-S触发器的真值表，**对应的Q值都不会发生变化**\n3. 当时钟信号CLK在**高电平**的时候，与门的一个输入为1，输出结果**完全取决于R和S的开关**\n   - 此时可以通过开关R和S，来决定对应Q的输出\n4. 小结\n   - 通过一个**时钟信号**，可以在**特定的时间**对输出Q进行**写入**操作\n\n##### D触发器\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-build-data-path-rs-flip-flop-clk-d.jpg\" width=1000/>\n\n1. 让R和S的开关，通过一个**反相器**连起来，就是**通过同一个开关控制R和S**\n2. 当CLK信号是1，R和S就可以设置输出Q；当CLK信号是0，无论R和S怎么设置，输出信号都不会改变\n3. 用来控制R和S两个开关的信号，视为一个输入的**数据信号**，即**Data**，这就是D型触发器的由来\n4. 小结：把R和S两个信号通过一个反相器合并，可以通过一个数据信号进行Q的写入操作\n5. 一个D触发器，只能控制**1bit**的读写\n   - 如果同时拿出多个D触发器并列在一起，并且把用**同一个CLK信号**控制所有D触发器的开关\n   - 这样就变成了N位的D触发器，可以同时控制N位的读写\n6. CPU里的**寄存器**可以直接通过**D触发器**来构造的\n\n### PC寄存器\n1. PC寄存器，也称为**程序计数器**（Program Counter）\n2. 有了**时钟信号**，可以提供**定时的输入**，有了**D触发器**，可以在**时钟信号控制的时间点写入数据**\n   - 把两者**组合**起来，就可以实现一个**自动的计数器**\n3. 加法器的两个输入，一个**始终设置为1**，另外一个来自于一个D触发器，把加法器的输出结果，写到D触发器\n   - 这样D触发器里面的数据会在**固定的时钟信号为1**的时候**更新一次**，每过一个时钟周期，就能**固定自增1**\n   - 每次自增之后，可以去对应的D触发器里取值，即**下一条需要运行指令的地址**（同一程序的指令要**顺序**存放在内存里）\n   - 因此同一程序**顺序**地存放指令，就是为了通过**程序计数器**就能**定时不断地**执行新指令\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-build-data-path-pc.jpg\" width=800/>\n\n### 译码器\n1. 数据能存储在**D触发器**里，把很多D触发器放在一起，就能形成一块很大的存储空间，甚至当成一块**内存**来使用\n   - 在写入和读取数据时，怎么定位是操作哪一个Bit？ -- **寻址、译码器**\n2. 实际使用的计算机内存使用的是**DRAM**，并非通过D触发器来实现的，而是使用**CMOS**芯片来实现 -- 但不影响理解译码器的原理\n\n#### 2-1选择器\n1. 把**寻址**退化到**最简单**的情况：在两个地址中，去选择一个地址，即**2-1选择器**\n2. 2-1选择器的组成：一个**反相器**、两个**与门**、一个**或门**\n   - 通过控制反相器的输入是0还是1，来决定对应的输出信号，是和地址A还是地址B的输入信号一致\n3. 一个反相器只能有0和1两种状态，所以只能从两个地址中选择一个，如果输入的信号有三个不同的开关，称为**3-8译码器**\n   - 现代计算器的CPU是64位，意味着**寻址空间**为**$2^{64}$**，需要一个有**64个开关的译码器**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-build-data-path-2-1-selector.jpg\" width=800/>\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-build-data-path-decoder-memory.jpg\" width=800/>\n\n#### 本质\n1. 译码器的**本质**，是从输入的多个位的信号中，根据**一定的开关和电路组合**，选择出自己想要的信号\n2. 除了**寻址**外，还可以通过译码器，找出**期望执行的指令**，即**opcod**e，以及后面对应的**操作数**或**寄存器地址**\n\n## 简单的CPU\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-build-data-path-cpu.jpg\" width=800/>\n\n1. **自动计数器**\n   - 自动计数器会随着**时钟主频**不断地**自增**，作为**PC寄存器**\n2. **地址译码器**\n   - 地址译码器需要连着通过大量的**D触发器**组成的**内存**\n3. 自动计数器随着时钟主频不断自增，从地址译码器当中，找到对应的计数器所表示的**内存地址**，然后读取出里面的**CPU指令**\n4. 读取出来的CPU指令会通过**CPU时钟**的控制，写入到一个**由D触发器组成的寄存器**，即**指令寄存器**\n5. **指令译码器**\n   - 指令译码器不是用来寻址的，而是将拿到的指令，解析成**opcode**和对应的**操作数**\n6. 拿到对应的opcode和操作数，对应的**输出线路**要连接**ALU**，开始进行各种**算术**和**逻辑**运算\n   - 对应的**计算结果**，再**写回**到**D触发器组成的寄存器**或者**内存**中","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- 定点数 + 浮点数","url":"%2F2020%2F01%2F15%2Fcomputer-organization-fix-float%2F","content":"\n## 浮点数的不精确性\n```\n>>> 0.3 + 0.6\n0.8999999999999999\n```\n1. 32bit是无法表达所有实数的，只能表达`2^32`次方不同的数字，差不多**40亿**\n2. 40亿个数字比起无限多的实数集合只是沧海一粟，应该让这40亿个数映射到实数集合上的哪些数字，在实际应用中才最划算\n\n<!-- more -->\n\n## 定点数\n1. 用**4个bit**表示`0~9`的整数，那么32个bit就可以表示8个这样的整数\n2. 然后把**最右边的2个**`0~9`的整数，当成**小数**部分；把**最左边6个**`0~9`的整数，当成**整数**部分\n3. 这样用32bit可以表示`0.00~999999.99`这**1亿**个实数\n4. 这种用**二进制表示十进制**的编码方式，称为**BCD编码**（**Binary-Coded Decimal**）\n5. 应用非常广泛：超市、银行\n6. 缺点\n   - **浪费**\n     - 本来32bit可以表示40亿个不同的数字，但在**BCD编码**下，只能表示1亿个数\n     - 如果**精确到分**，能够表达的**最大金额**为**100W**，非常有限\n   - 无法同时表示**很大的数字**和**很小的数字**\n\n## 浮点数\n1. 浮点数的**科学计数法**的表示，有一个**IEEE**的标准，定义了两个基本的格式\n    - 一个是用**32bit**表示**单精度**的浮点数，即**float**\n    - 一个是用**64bit**表示**双精度**的浮点数，即**double**\n2. float\n    - **符号位s -- 1bit**\n      - 用来表示正数还是负数，所有浮点数都是有符号的\n    - **指数位e -- 8bit**\n      - 8bit表示的整数空间，为`0~255`，**`1~254`**映射到**`-126~127`**这254个有正有负的数上（差值为**127**）\n      - `0`和`255`是**标志位**，主要用于表示**0**和一些**特殊的数**\n    - **有效数位f -- 23bit**\n    - **$(-1)^s \\times 1.f \\times 2^e$**\n      - 没办法表示0，需要借助指数位e\n\n| 格式 | s=符号位 | e=指数位 | f=有效数位 |\n| --- | --- | --- | --- |\n| float | 1 bit | 8 bit | 23 bit |\n\n| s | e | f | 浮点数 | 备注 |\n| --- | --- | --- | --- | --- |\n| 0 or 1 | 0 | 0 | 0 | |\n| 0 | 255 | 0 | 无穷大 | |\n| 1 | 255 | 0 | 无穷小 | |\n| 0 or 1 | 255 | != 0 | NAN | |\n| 0 or 1 | 0 | != 0 | 0.f | **暂未消化** |\n\n### 特殊数的Java实现\n```java java.lang.Float\n/**\n  * A constant holding the positive infinity of type\n  * {@code float}. It is equal to the value returned by\n  * {@code Float.intBitsToFloat(0x7f800000)}.\n  */\npublic static final float POSITIVE_INFINITY = 1.0f / 0.0f;\n\n/**\n  * A constant holding the negative infinity of type\n  * {@code float}. It is equal to the value returned by\n  * {@code Float.intBitsToFloat(0xff800000)}.\n  */\npublic static final float NEGATIVE_INFINITY = -1.0f / 0.0f;\n\n/**\n  * A constant holding a Not-a-Number (NaN) value of type\n  * {@code float}.  It is equivalent to the value returned by\n  * {@code Float.intBitsToFloat(0x7fc00000)}.\n  */\npublic static final float NaN = 0.0f / 0.0f;\n```\n```java\nprivate static String getFloatBinaryString(float f) {\n    StringBuilder builder = new StringBuilder(Integer.toBinaryString(Float.floatToIntBits(f)));\n    int length = builder.length();\n    if (length < 32) {\n        for (int i = 0; i < 32 - length; i++) {\n            builder.insert(0, \"0\");\n        }\n    }\n    String s = builder.toString();\n    return s.substring(0, 1) + \"-\" + s.substring(1, 9) + \"-\" + s.substring(9, 32) + \" -> \" + f;\n}\n\npublic static void main(String[] args) {\n    System.out.println(getFloatBinaryString(0.0F));\n    System.out.println(getFloatBinaryString(-0.0F));\n    System.out.println(getFloatBinaryString(-0.0F));\n\n    System.out.println(getFloatBinaryString(Float.POSITIVE_INFINITY));\n    System.out.println(getFloatBinaryString(-Float.POSITIVE_INFINITY));\n    System.out.println(getFloatBinaryString(Float.NEGATIVE_INFINITY));\n    System.out.println(getFloatBinaryString(-Float.NEGATIVE_INFINITY));\n\n    System.out.println(getFloatBinaryString(Float.NaN));\n    System.out.println(getFloatBinaryString(-Float.NaN));\n}\n```\n```\n0-00000000-00000000000000000000000 -> 0.0\n1-00000000-00000000000000000000000 -> -0.0\n0-11111111-00000000000000000000000 -> Infinity\n1-11111111-00000000000000000000000 -> -Infinity\n1-11111111-00000000000000000000000 -> -Infinity\n0-11111111-00000000000000000000000 -> Infinity\n0-11111111-10000000000000000000000 -> NaN\n0-11111111-10000000000000000000000 -> NaN\n```\n\n### 表示\n\n#### 0.5\n1. **$0.5 = (-1)^0 \\times 1.0 \\times 2^{-1}$**\n2. **$s=0, f=0, e=-1$**\n  - **$e$**表示从`-126~127`个，而-1是其中**第126个**\n3. 如果不考虑符号，浮点数能够表示的最小的数和最大的数，差不多是**$1.17 \\times 10^{-38}$**和**$3.40 \\times 10^{38}$**\n  - 比**BSD**编码能表示的范围**大很多**\n4. 浮点数是**没法精确表示0.3和0.6的**，而0.5是能够被精确地表示成二进制浮点数的\n  - 浮点数无论是**表示**还是**计算（如加法）**其实都是**近似计算**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-fix-float-0.5.jpg\" width=1000/>\n\n```java\npublic static void main(String[] args) {\n    System.out.println(getFloatBinaryString(0.5F));\n    System.out.println(getFloatBinaryString(-0.5F));\n}\n```\n```\n0-01111110-00000000000000000000000 -> 0.5\n1-01111110-00000000000000000000000 -> -0.5\n```\n\n#### 9.1\n1. 输入一个任意的**十进制浮点数**，背后都会对应一个**二进制表示**\n2. 首先把**整数**部分转换成一个二进制，9对应为`1001`\n3. 把对应的**小数**部分也换成二进制\n  - 二进制小数`0.1001`：**$1 \\times 2^{-1} + 0 \\times 2^{-2} + 0 \\times 2^{-3} + 1 \\times 2^{-4} = 0.5625$**\n  - **十进制小数** -> **二进制小数**\n    - **× 2，然后看是否超过1，如果超过1，就记为1，并把结果减去1，进一步循环操作**\n    - 参照下表，0.1的二进制小数为`0.000110011...`\n4. 把整数部分和小数部分**拼接**在一起，9.1的二进制表示为`1001.000110011...`\n  - 二进制的科学计数法：**$1.001000110011... \\times 2^{3}$**\n  - 此时可以对应到浮点数的格式，**$s=0, e=3+127=130=0b10000010, f=00100011001100110011001$**\n    - f最长只有23位，无限循环二进制小数会被**截断**（只能用近似值**表示**的**根本原因**）\n    - 指数位有正有负，映射到浮点数格式，需要加上**偏移量127**\n  - 浮点数9.1的二进制表示`0-10000010-00100011001100110011001`\n    - 再换算成十进制为`9.09999942779541015625 ≈ 9.1`，只是一个**近似值**\n\n| 行号 | 算式 | 是否超过1 | 二进制位 | 剩余差值 | 备注 |\n| --- | --- | --- | --- | --- | --- |\n| 1 | 0.1 × 2 = 0.2 | 否 | 0 | 0.2 |  |\n| 2 | 0.2 × 2 = 0.4 | 否 | 0 | 0.4 |  |\n| 3 | 0.4 × 2 = 0.8 | 否 | 0 | 0.8 |  |\n| 4 | 0.8 × 2 = 1.6 | 是 | 1 | 0.6 |  |\n| 5 | 0.6 × 2 = 1.2 | 是 | 1 | 0.2 |  |\n| 6 | 0.2 × 2 = 0.4 | 否 | 0 | 0.4 | 开始重复，第2~4行 |\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-fix-float-9.1.jpg\" width=1000/>\n\n### 运算（加法）\n1. 原则：**先对齐、再计算**\n2. 两个浮点数的指数位可能是不一样的，需要先把两个**指数位变成一样**的，然后**只去计算有效位的加法**\n\n#### 0.5 + 0.125\n1. **0.5**对应的指数位是`-1`，有效位是`00...`（前面默认有个1）\n2. **0.125**对应的指数位为`-3`，有效位是`00...`（前面默认有个1）\n  - 先**对齐**，把指数位统一成`-1`，对应的有效位`1.00...`要对应的**右移**两位，变成`0.01...`\n3. 计算两者相加的有效位`1.f`，变成了`1.01`，而指数位为`-1`\n4. 实现这样一个加法，**只需要位移**，在**电路层面**，并**没有引入太多新的复杂性**\n\n| | 符号位s | 指数位e | 有效位1.f |\n| --- | --- | --- | --- |\n| 0.5 | 0 | -1 | 1.00... |\n| 0.125 | 0 | -3 | 1.00... |\n| 0.125：**对齐指数位** + **有效位右移** | 0 | -1 | 0.01... |\n| 0.5+0.125 | 0 | -1 | 1.01... |\n\n```java\npublic static void main(String[] args) {\n    System.out.println(getFloatBinaryString(0.5F));\n    System.out.println(getFloatBinaryString(0.125F));\n    System.out.println(getFloatBinaryString(0.5F + 0.125F));\n}\n```\n```\n0-01111110-00000000000000000000000 -> 0.5\n0-01111100-00000000000000000000000 -> 0.125\n0-01111110-01000000000000000000000 -> 0.625\n```\n\n#### 精度丢失\n1. 在上面浮点数的加法过程中，**指数位较小**的数，需要进行**有效位的右移**，最右侧的有效位就会被**丢弃**\n2. 两个相加数的**指数位相差得越大**，位移的位数就越大，**可能丢失的精度就越大**\n3. 32位浮点数的有效位长度一共只有**23**位，如果两个数的指数位相差超过23位，较小的数右移24位之后，所有的有效位**都丢失**了\n4. 解决方案（**软件层面算法**）：[Kahan summation algorithm](https://en.wikipedia.org/wiki/Kahan_summation_algorithm)\n\n```java\nfloat a = 1 << 24;\nfloat b = 1.0f;\nSystem.out.println(getFloatBinaryString(a));\n\nfloat c = a + b;\nSystem.out.println(getFloatBinaryString(c));\nfloat d = c - a;\nSystem.out.println(getFloatBinaryString(d));\n```\n```\n0-10010111-00000000000000000000000 -> 1.6777216E7\n0-10010111-00000000000000000000000 -> 1.6777216E7\n0-00000000-00000000000000000000000 -> 0.0\n```\n```java\nfloat a = 1 << 24;\nSystem.out.println(a); // 1.6777216E7\n\nfloat sum = 0.0f;\nfor (int i = 0; i < 20_000_000; i++) {\n    float x = 1.0f;\n    sum += x;\n}\n// 精度丢失，积少成多会导致误差很大\nSystem.out.println(\"sum is \" + sum); // 1.6777216E7\n```\n\n## 小结\n1. 一般情况下，在实际应用中，如果需要**精确数值**（如银行存款、电商交易），一般会使用**定点数**或者**整数**\n2. 浮点数适用情况：**不需要非常精确**的计算结果","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- 乘法器","url":"%2F2020%2F01%2F14%2Fcomputer-organization-multiplier%2F","content":"\n## 13 × 9\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-multiplier-13-9.jpg\" width=1000/>\n\n<!-- more -->\n\n## 顺序乘法\n1. 二进制的乘法，在单个位上，乘数只能是**0或1**，所以实际的乘法，就退化成**位移**和**加法**\n2. 被乘数13表示成二进制是`1101`，乘数9表示成二进制是`1001`\n    - 最后边的个位是1，个位乘以被乘数，被乘数`1101`得以保留\n    - 二位和四位都是0，所以乘以被乘数都是0，保留下来的都是`0000`\n    - 八位是1，仍然需要把被乘数`1101`复制下来，但需要把复制好的结果**向左移动三位**\n    - 然后把上面四个**乘法加位移**的结果再加起来\n      - 最后一步的加法可以用上一讲的**加法器**来实现\n3. 二进制乘法因为只有0和1两种情况，所以可以做成输入输出都是4个开关，中间有一个开关\n    - 中间的开关决定，下面的输出是**完全复制**输入，还是将输出**全部设置为0**\n4.  **位移**：左移一位，就错开一位接线；左移两位，就错开两位接线\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-multiplier-seq-1.jpg\" width=800/>\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-multiplier-seq-2.jpg\" width=800/>\n\n### 节约开关（晶体管）\n1. 为了节省资源（开关，即晶体管）\n    - 类似13×9这样两个四位数的乘法，不需要把四次单位乘法的结果都用**四组独立的开关单独记录**然后再加起来\n    - 否则，如果计算一个32位的整数乘法，就要32组开关，**非常浪费**\n    - 如果**顺序地计算**，只需要**一组开关**就好\n2. 先拿乘数最右侧的**个位**乘以被乘数，然后把结果写入用来存放计算结果的开关里面\n3. 然后，把**被乘数左移一位**，把**乘数右移一位**，仍然用乘数的**个位**去乘以被乘数，然后把结果**加**到刚才的结果上\n4. 反复重复上面的步骤，直到不能再左移和或右移位置\n5. 这样，乘数和被乘数就像**两列相向行驶的列车**\n    - 仅仅需要一个**加法器**，一个**可以左移一位的电路**，一个**可以右移一位的电路**，就能完成整个乘法\n    - 下图中**控制测试**的含义：通过一个**时钟信号**，控制左移、右移和重新计算乘法和加法的时机\n6. 缺点：**慢**\n    - 在上面乘法器的实现过程中，其实就是**把乘法展开**，变成了**加法+位移**的实现\n    - 如果是4位数乘法，就要进行4组**位移+加法**的操作，而且这4组操作**不能同时进行**\n      - 下一组的**加法**要依赖上一组的加法后的计算结果，下一组的**位移**也要依赖上一组的位移结果\n    - 这样，整个算法都是**顺序**的，最终该乘法的计算速度，其实和我们要计算的**位数N**有关，**时间复杂度为`O(N)`！！**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-multiplier-seq-3.jpg\" width=800/>\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-multiplier-seq-4.jpg\" width=800/>\n\n## 并行加速\n1. 目标：`O(N) -> O(logN)`\n2. 前面**顺序乘法器**硬件的实现，类比于体育比赛里面的**单败淘汰赛**，只有一个擂台会存下最新的计算结果，时间复杂度为**`O(N)`**\n3. 加速的办法，就是把比赛变成**世界杯那样的淘汰赛**，时间复杂度为**`O(logN)`**\n    - 对应到CPU的硬件上，就需要**更多的晶体管开关**，来存放**中间计算结果**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-multiplier-parallel-1.jpg\" width=800/>\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-multiplier-parallel-2.jpg\" width=800/>\n\n## 电路并行\n1. 顺序乘法器的计算会慢的核心原因是**顺序计算**\n2. **加法器**（顺序计算的典型例子）\n    - 每一个全加器，都需要等待上一个全加器的输出结果\n    - **位数越多**，越往高位走，等待前面的步骤就越多，这个等待的时间叫作**门延迟**（Gate Delay）\n3. 每通过一个门电路，就要**等待**门电路的计算结果，就是一层的**门电路延迟**，一般取一个**T**作为符号\n    - 一个全加器，对应3T的延迟\n    - 4位整数，最高位的计算需要等待前面三个全加器的进位结果，即**9T**的延迟\n    - 64位整数，对应就是**63×3=189T**的延迟，非常长！\n4. 时钟频率\n    - 上面的顺序乘法器中，如果想要用更少的电路，中间的计算结果需要保存在**寄存器**里面\n    - 然后等待下一个时钟周期的到来，控制测试信息才能进行下一次位移和加法，这个延迟**比门延迟更可观**\n5. 并行的前提\n    - **如果相加的两个数是确定的，那高位是否会进位其实也是确定的**\n6. 并行的目标\n   - 让高位和低位的计算**同时出结果**\n   - 高位**不需要等待**低位的进位结果，把低位的所有输入信号都放进来，**直接计算出高位的计算结果和进位结果**\n7. 并行的方案\n   - 把**进位部分的电路完全展开**，类似于**多项式乘法**一样完全展开\n   - 把**需要较少，但有较多层前后计算依赖关系**的门电路，展开成**需要较多，但依赖关系更少**的门电路\n   - 如果完成展开电路，高位的进位和计算结果，可以与低位的计算结果**同时获得**\n     - 核心原因：**电路是天然并行的（电信号实时传输）**，一个输入信号，可以**同时传播**到所有接通的线路当中\n8. 下图是4位加法器的**完全展开的门电路图**，只需要**3T**的延迟就可以拿到**是否进位**的计算结果\n    - 对于64位的加法器，也**不会增加门延迟**，只是从上往下**复制**这个电路，**接入更多信号**而已\n9. 不论把对应的门电路逻辑进行**完全展开**来**减少门延迟**，还是**并行计算**多个位的乘法，都是把电路变**复杂**了，这意味着**晶体管变多**\n    - 通过更多的晶体管，可以拿到**更低的门延迟**，以及用**更少的时钟周期**完成一个计算指令\n10. RISC Vs CISC\n    - 用**简单电路**，但需要更长的门延迟和时钟周期\n    - 用**复杂电路**，但更短的门延迟和时钟周期来计算一个**复杂的指令**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-multiplier-parallel-3.jpg\" width=600/>","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- 加法器","url":"%2F2020%2F01%2F13%2Fcomputer-organization-adder%2F","content":"\n## 基本门电路\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-adder-gate-circuit.jpg\" width=1000/>\n\n1. 基本门电路：**输入都是两个单独的bit，输出是一个单独的bit**\n2. 如果要对2个8bit的数字，计算**与或非**的简单逻辑（无进位），只需要连续摆放8个开关，来代表一个8bit数字\n3. 这样的两组开关，从左到右，上下单个的位开关之间，都统一用『**与门**』或者『**或门**』连起来\n   - 就能实现两个8bit数的**AND**运算或者**OR**运算\n\n<!-- more -->\n\n## 异或门 + 半加器\n\n### 一bit加法\n1. 个位\n   - 输入的两位为`00`和`11`，对应的输出为`0`\n   - 输入的两位为`10`和`01`，对应的输出为`1`\n   - 上面两种关系都是**异或门**（XOR）的功能\n   - **异或门是一个最简单的整数加法，所需要使用的基本门电路**\n2. 进位\n   - 输入的两位为`11`时，需要向**更左侧**的一位进行进位，对应一个**与门**\n3. 通过一个**异或门**计算出**个位**，通过一个**与门**计算出**是否进位**\n   - 把这两个门电路**打包**，叫作**半加器**（Half Adder）\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-adder-half-adder.jpg\" width=1000/>\n\n## 全加器\n1. **半加器只能解决一bit加法的问题**，不能解决2bit或以上的加法（因为有**进位**信号）\n2. 二进制加法的竖式，从右往左，第二列称为**二位**，第三列称为**四位**，第四列称为**八位**\n3. 全加器：**两个半加器**和**一个或门**\n   - 把两个半加器的**进位输出**，作为一个**或门**的输入\n     - **只要两次加法中任何一次需要进位**，那么在二位上，就需要向左侧的四位进一位\n     - 一共只有三个bit相加，即使都是1，也**最多只会进一位**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-adder-full-adder.jpg\" width=1000/>\n\n### 8bit加法\n1. 把8个全加器**串联**，个位全加器的进位信号作为二位全加器的输入信号，二位全加器的进位信号作为四位全加器的输入信号\n2. 个位全加器只需要用到**一个半加器**，或者让**全加器的进位输入始终是0**，因为个位没有来自更右侧的进位\n3. 最左侧的进位信号，表示的并不是再进一位，而是表示**加法是否溢出**\n   - 该溢出信号可以输出到硬件中的其它标志位，让计算机知道计算结果是否溢出\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-adder-full-adder-8bit.jpg\" width=1000/>\n\n## 分层思想\n**门电路 -> 半加器 -> 全加器 -> 加法器 -> ALU**","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- 电路","url":"%2F2020%2F01%2F11%2Fcomputer-organization-circuit%2F","content":"\n## 电报机\n1. 电报机的本质：**蜂鸣器** + **电线** + **按钮开关**\n2. 蜂鸣器装在接收方，开关留在发送方，双方通过电线连在一起\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-circuit-telegraph.jpg\" width=600/>\n\n<!-- more -->\n\n## 继电器\n1. 电线的线路越长，电线的电阻越大，当电阻很大，而电压不够时，即使按下开关，蜂鸣器也不会响的\n2. **继电器**（Relay）：为了实现**接力传输信号**\n3. 中继：不断地通过新的电源**重新放大**已经**开始衰减**的原有信号\n    - 中间所有小电报站都使用『**螺旋线圈+磁性开关**』的方式，来替代**蜂鸣器+普通开关**\n    - 只在电报的**始发**和**终点**用普通开关和蜂鸣器\n    - 这样就可以将长距离的电报线路，拆成一个个小的电报线路，接力传输电报信号\n4. 继电器别名：**电驿**，驿站的驿\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-circuit-relay.jpg\" width=600/>\n\n## 二进制\n1. 有了继电器后，输入端通过开关的『开』和『关』表示1和0，输出端也能表示1和0\n    - 输出端的作用，不仅仅是通过一个蜂鸣器或者灯泡，提供一个供人观察的输出信号\n    - 还可以通过『螺旋线圈+磁性开关』，使得输出也有『开』和『关』两种状态，表示1和0，作为**后续线路的输入信号**\n2. 与（AND）\n    - 在输入端的电路上，提供**串联**的两个开关，只有两个开关都打开，电路才接通，输出的开关才能接通\n3. 或（OR）\n    - 在输入端的电路上，提供**两条独立的线路**到输出端\n    - 两条线路上各有一个开关，任意一个开关打开了，到输出端的电路都是接通的\n4. 非（NOT） -- **反相器**\n    - 把『螺旋线圈+磁性开关』的组合，从**默认关闭**（只有通电才打开），换成**默认打开**（只有通电才关闭）\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-circuit-inverter.jpg\" width=600/>","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- 二进制编码","url":"%2F2020%2F01%2F11%2Fcomputer-organization-binary%2F","content":"\n## 补码表示法\n1. 原码表示法\n   - `0011`为3，`1011`为-3\n   - 缺点：`0000`和`1000`都表示为0\n       - **浪费 + 模凌两可**\n2. 由此诞生了**补码表示法**，其实就是一个简单的**翻转**而已\n    - 用补码表示负数，使得**整数的相加**变得容易，不需要做任何特殊处理，当成**普通的二进制相加**即可\n\n<!-- more -->\n\n## 字符串\n1. **ASCII**码类似一个字典，用8位二进制中的128个不同的数字，**映射**到128个不同的字符里\n    - `a`在ASCII里面是第97个，二进制为`0110 0001`，对应的十六进制为`0x61`\n    - 字符串`9`用`0011 1001`来表示，字符串`15`用`0011 0001`和`0011 0101`来表示，**占用更多的空间**\n    - 因此**存储数据**的时候，要采用**二进制序列化**的形式，\n      - 而不是简单地把数据通过CSV或者JSON这样的**文本格式**存储来进行序列化\n      - 不管是整点数，还是浮点数，采用**二进制序列化**比**存储文本**能节省不少空间\n2. **字符集**（Charset）和**字符编码**（Character Encoding）\n    - **字符集**：字符的集合\n      - **Unicode是字符集**，包含150种语言的14万个字符\n    - **字符编码**：对于字符集里的这些字符，怎么**用二进制表示**出来的一个**字典**\n      - Unicode可以用**UTF-8、UTF-16、UTF-32**来进行编码，**存储成二进制**\n      - 某段文本用编码A存储下来，另外一个程序用编码B进行解码和展示，就会出现**乱码**","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- 动态链接","url":"%2F2020%2F01%2F10%2Fcomputer-organization-dynamic-link%2F","content":"\n## 静态链接\n1. 把对应的不同文件内的代码段合并在一起，成为最后的**可执行文件**，可以做到**代码在开发阶段的复用**\n2. 很多程序都需要通过**装载器**装载到**内存**里面，里面链接好的**同样的功能代码**，也都需要再装载一遍，**再占一遍内存空间**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-dynamic-link-usr.jpg\" width=1000/>\n\n<!-- more -->\n\n## 动态链接\n1. 动态链接过程中，需要链接的不是存储在**硬盘上的目标文件代码**，而是加载到**内存**中的**共享库**（Shared Libraries）\n    - 加载到内存中的共享库会被很多程序的指令调用\n2. **Windows**的共享库文件是`.dll`（Dynamic-Link Libary）文件；**Linux**的共享库文件是`.so`（Shared Object）文件\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-dynamic-link.jpg\" width=1000/>\n\n## 地址无关 + 相对地址\n1. 要在程序**运行时**共享代码，这些机器码必须是**地址无关**的，即**编译出来的共享库文件的指令代码**，是**地址无关码**\n    - 地址无关码（**PIC**）：Position-Independent Code，无论加载到哪个物理内存地址，都能够正常执行\n    - 大部分函数库都能做到地址无关，因为都是接受特定的输入，进行确定的操作，然后给出返回结果\n2. 对于所有**动态链接共享库**的程序来讲\n    - 虽然**共享库**用的都是**同一段物理内存地址**\n    - 但在不同的应用程序里，共享库所在的**虚拟内存地址是不同**的\n    - 不应该要求动态链接同一个共享库的不同程序，必须把这个共享库所使用的虚拟内存地址变成一致 -- **万恶的侵入性**\n3. **动态共享库**编译出来的**代码指令**如果做到**地址无关**的？\n    - 动态共享库**内部的变量和函数调用**很容易解决，只需要使用**相对地址**即可\n      - 各种指令中使用到的内存地址，给出的不是一个绝对的地址空间，而是一个**相对于当前指令偏移量的内存地址**\n      - **整个共享库**是放在一段**连续的虚拟内存地址**中\n        - 无论装载到哪一段虚拟内存地址，**不同指令之间的相对地址都是不变的**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-dynamic-link-pic.jpg\" width=1000/>\n\n## 解决方案：PLT + GOT\n\n### 源代码\n\n#### lib.h\n```c\n// lib.h\n\n#ifndef LIB_H\n#define LIB_H\n\nvoid show_me_the_money(int money);\n\n#endif\n```\n#### lib.c\n```c\n// lib.c\n#include <stdio.h>\n\nvoid show_me_the_money(int money)\n{\n    printf(\"Show me USD %d from lib.c \\n\", money);\n}\n```\n#### show_me_poor.c\n```c\n// show_me_poor.c\n#include \"lib.h\"\n\nint main()\n{\n    int money = 5;\n    show_me_the_money(money);\n}\n```\n\n### lib.c -> lib.so\n```\n$ gcc lib.c -fPIC -shared -o lib.so\n$ gcc -o show_me_poor show_me_poor.c lib.so\n```\n1. `-fPIC`：Position Independent Code，编译成一个**地址无关**的代码\n2. gcc编译了可执行文件`show_me_poor`：**动态链接**了`lib.so`\n\n### PLT -- Procedure Link Table\n```\n$ objdump -d -M intel -S show_me_poor\n......\n00000000004004e0 <.plt>:\n  4004e0:\tff 35 22 0b 20 00    \tpush   QWORD PTR [rip+0x200b22]        # 601008 <_GLOBAL_OFFSET_TABLE_+0x8>\n  4004e6:\tff 25 24 0b 20 00    \tjmp    QWORD PTR [rip+0x200b24]        # 601010 <_GLOBAL_OFFSET_TABLE_+0x10>\n  4004ec:\t0f 1f 40 00          \tnop    DWORD PTR [rax+0x0]\n......\n00000000004004f0 <show_me_the_money@plt>:\n  4004f0:\tff 25 22 0b 20 00    \tjmp    QWORD PTR [rip+0x200b22]        # 601018 <show_me_the_money>\n  4004f6:\t68 00 00 00 00       \tpush   0x0\n  4004fb:\te9 e0 ff ff ff       \tjmp    4004e0 <.plt>\n......\n000000000040060d <main>:\n  40060d:\t55                   \tpush   rbp\n  40060e:\t48 89 e5             \tmov    rbp,rsp\n  400611:\t48 83 ec 10          \tsub    rsp,0x10\n  400615:\tc7 45 fc 05 00 00 00 \tmov    DWORD PTR [rbp-0x4],0x5\n  40061c:\t8b 45 fc             \tmov    eax,DWORD PTR [rbp-0x4]\n  40061f:\t89 c7                \tmov    edi,eax\n  400621:\te8 ca fe ff ff       \tcall   4004f0 <show_me_the_money@plt>\n  400626:\tc9                   \tleave\n  400627:\tc3                   \tret\n  400628:\t0f 1f 84 00 00 00 00 \tnop    DWORD PTR [rax+rax*1+0x0]\n  40062f:\t00\n......\n```\n1. main函数调用show_me_the_money函数时，对应的代码是`call   4004f0 <show_me_the_money@plt>`\n    - `@plt`：需要从PLT，也就是**程序链接表**（**Procedure Link Table**）查找要调用的函数，对应的地址是4004f0\n2. 来到4004f0，里面又有一次跳转`jmp    4004e0 <.plt>`，来到GLOBAL_OFFSET_TABLE，即**GOT**\n3. GLOBAL_OFFSET_TABLE即**全局偏移表**\n\n### GOT -- Global Offset Table\n1. 在**共享库**的**`data section`**，保存了一张**全局偏移表**（**GOT**，Global Offset Table）\n2. 重要前提：**共享库**的代码部分和数据部分\n    - **代码部分**的**物理内存是共享**的\n    - **数据部分**是各个动态链接它的应用程序里面**各加载一份的**\n3. 所有需要引用**当前共享库外部地址的指令**，都会**查询GOT**，来找到当前运行程序的**虚拟内存**里的对应位置\n    - 步骤：**想要调用共享库的实际指令 -> PLT -> GOT -> 本进程的虚拟内存地址 -> 物理内存地址（共享库）**\n4. GOT里的内容，是在**本进程加载一个个共享库**的时候写进去的\n    - GOT里的内容是**运行时计算**的，并非编译时确定的\n5. 不同的进程，调用同样的lib.so，**各自GOT里面指向最终加载的动态链接库的虚拟内存地址是不同的！！**\n6. 不同的程序调用同样的动态库，各自的内存地址是独立的，调用的又都是同一个动态库\n    - 但不需要去修改动态库里面代码所使用的地址，**各个程序各自维护好自己的GOT**，能够找到对应的动态库即可\n7. 本质：通过各个可执行程序在**加载**时，**生成的各不相同的GOT表**，来找到它需要调用到的外部变量和函数的地址\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-dynamic-link-got.jpg\" width=1000/>\n\n## 小结\n1. **静态链接** -> 代码在**开发阶段**的复用；**动态链接** -> 代码在**运行阶段**的复用\n2. C语言的标准库在1MB以上\n    - /usr/bin下有上千个可执行文件，如果每一个都把标准库静态链接进来，会占用几GB甚至几十GB的的磁盘空间\n    - 服务端要开上千个进程，如果采用静态链接，会占用几GB的内存空间\n3. 动态链接的主要价值：**节省资源（磁盘、内存）！！**","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- 段 + 页","url":"%2F2020%2F01%2F09%2Fcomputer-organization-segmentation-page%2F","content":"\n## 程序装载\n1. 背景\n    - 通过**链接器**，把多个目标文件合并成一个最终可执行文件\n    - 运行可执行文件时，其实是通过一个**装载器**，解析`ELF`或者`PE`格式的可执行文件\n      - 装载器会把对应的指令和数据加载到内存里面，让CPU去执行\n2. 装载器需要满足两个条件\n   - 可执行程序加载后**占用的内存空间**应该是**连续**的\n     - 执行程序时，程序计数器是**顺序**地一条一条指令执行下去\n   - 需要**同时加载**很多个程序，并且**不能让程序自己规定在内存中加载的位置**\n3. 内存地址\n    - **虚拟**内存地址：**指令**里用到的内存地址\n    - **物理**内存地址：**内存硬件**里的空间地址\n4. 一个思路\n    - 在**物理内存**里面找一段**连续**的内存空间，分配给装载的程序\n      - 然后把这段**连续的内存空间地址**和整个程序**指令里指定的内存地址**做一个**映射**\n    - 程序里有指令和各种内存地址，而我们**只需要关心虚拟内存地址**即可\n    - 对任何一个程序来说，它所看到的都是**同样的内存地址**\n      - 维护一个**虚拟内存**到**物理内存**的**映射**表\n      - 实际程序指令执行的时候，会通过虚拟内存地址，找到对应的物理内存地址，然后执行\n    - 因为是**连续的内存地址空间**，只需要维护映射关系的**起始地址**和**对应的空间大小**即可\n\n<!-- more -->\n\n## 内存分段\n1. 分段（**Segmentation**）：找出一段**连续的物理内存**和虚拟内存地址进行**映射**\n2. 段：系统分配出来的那个**连续**的内存空间\n3. 解决了程序本身不需要关心具体的物理内存地址的问题，但仍然存在两个问题\n  - **内存碎片**（Memory Fragmentation）\n  - **性能瓶颈**（内存交换用到了**硬盘**，如果需要换出的程序所占用的物理内存很大，就会很慢）\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-segmentation-page-segmentation.png\" width=1000/>\n\n### 内存碎片\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-segmentation-page-memory-fragmentation.png\" width=1000/>\n\n#### 内存交换\n1. 内存交换：Memory Swapping\n2. 把Python程序占用的256MB内存写到**硬盘**上，然后再从硬盘读回来到**内存**里面\n  - 读回来的时候，不再把它加载到原来的位置，而是紧跟在已经占用了512MB内存后面\n  - 这样就有了**连续**的256MB的内存空间\n3. Linux会分配一个**Swap硬盘分区**，专门给Linux进行内存交换的\n\n### 性能瓶颈\n1. **虚拟内存**、**内存分段**、**内存交换**的组合仍然会遇到性能瓶颈\n2. **硬盘的访问速度要比内存慢很多！！**\n  - 每次内存交换，都需要把一大段连续的内存数据写入到硬盘\n\n## 内存分页\n1. 内存**分段**的主要问题：**内存碎片** + **内存交换的空间太大**\n2. **分段**是分配**一整段连续的空间**给到程序，**分页**是把**整个物理内存空间**切成一段段**固定尺寸**的大小\n  - 而对应程序所需要占用的**虚拟内存空间**，也同样切成一段段**固定尺寸**的大小\n  - 这样一个**连续且尺寸固定**的内存空间，叫作**页**\n3. 从虚拟内存到物理内存的映射，不再是拿整段连续内存的物理地址，而是按照一个个**页**来\n4. 页的尺寸一般**远小于**整个程序的大小，Linux下，页大小通常是**4KB**\n5. 这样，内存空间都是预先划分好了，就没有了不能使用的内存碎片，而只有被释放出来的很多4KB的页\n  - 即使内存空间不够，需要让现有的、正在运行的其它程序，通过**内存交换**释放出一些内存的**页**出来\n  - 这样，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多的时间\n6. 内存分页的思路：**化整为零！！**\n\n```\n$ getconf PAGE_SIZE\n4096\n```\n\n### 缺页错误\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-segmentation-page-page-fault.png\" width=1000/>\n\n1. 分页的方式使得在加载程序的时候，不再需要一次性都把程序加载到物理内存中\n  - 完全可以在进行虚拟内存和物理内存的**页之间的映射**之后，并不把页加载到物理内存里面\n  - 只在程序运行中，需要用到对应虚拟内存里面的指令和数据时，再加载到物理内存里面去 -- **懒加载**\n2. 操作系统\n  - 当要读取特定的页，却发现数据并没有加载到物理内存里面，就会触发一个**来自于CPU的缺页错误**（Page Fault）\n  - **操作系统会捕捉到缺页错误**，然后将对应的页，从存放在硬盘上的虚拟内存读取出来，加载到物理内存里面\n3. 好处\n  - 可以运行那些**远大于**我们实际物理内存的程序（如大型游戏）\n  - 任何程序都不需要一次性加载完所有指令和数据，**按需加载**即可\n4. 通过**虚拟内存**、**内存分页**、**内存交换**的结合，可以让程序不再需要考虑**物理地址**、**程序加载**、**内存管理**等问题\n  - 对任何一个程序来说，都只需要把内存当成一块**完整且连续**的空间来直接使用即可","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- ELF + 静态链接","url":"%2F2020%2F01%2F08%2Fcomputer-organization-elf-static-link%2F","content":"\n## 代码拆分\n\n### 源代码\n\n#### add_lib.c\n```c\n// add_lib.c\nint add(int a, int b)\n{\n    return a+b;\n}\n```\n#### link_example.c\n```c\n// link_example.c\n\n#include <stdio.h>\n\nint main()\n{\n    int a = 10;\n    int b = 5;\n    int c = add(a, b);\n    printf(\"c=%d\\n\", c);\n}\n```\n\n<!-- more -->\n\n### gcc + objdump\n```\n$ gcc -g -c add_lib.c link_example.c\n$ objdump -d -M intel -S add_lib.o\n$ objdump -d -M intel -S link_example.o\n```\n#### add_lib.o\n```\nadd_lib.o：     文件格式 elf64-x86-64\nDisassembly of section .text:\n0000000000000000 <add>:\n// add_lib.c\nint add(int a, int b)\n{\n   0:\t55                   \tpush   rbp\n   1:\t48 89 e5             \tmov    rbp,rsp\n   4:\t89 7d fc             \tmov    DWORD PTR [rbp-0x4],edi\n   7:\t89 75 f8             \tmov    DWORD PTR [rbp-0x8],esi\n\treturn a+b;\n   a:\t8b 45 f8             \tmov    eax,DWORD PTR [rbp-0x8]\n   d:\t8b 55 fc             \tmov    edx,DWORD PTR [rbp-0x4]\n  10:\t01 d0                \tadd    eax,edx\n}\n  12:\t5d                   \tpop    rbp\n  13:\tc3                   \tret\n```\n\n#### link_example.o\n```\nlink_example.o：     文件格式 elf64-x86-64\nDisassembly of section .text:\n0000000000000000 <main>:\n// link_example.c\n#include <stdio.h>\n\nint main()\n{\n   0:\t55                   \tpush   rbp\n   1:\t48 89 e5             \tmov    rbp,rsp\n   4:\t48 83 ec 10          \tsub    rsp,0x10\n\tint a = 10;\n   8:\tc7 45 fc 0a 00 00 00 \tmov    DWORD PTR [rbp-0x4],0xa\n\tint b = 5;\n   f:\tc7 45 f8 05 00 00 00 \tmov    DWORD PTR [rbp-0x8],0x5\n\tint c = add(a, b);\n  16:\t8b 55 f8             \tmov    edx,DWORD PTR [rbp-0x8]\n  19:\t8b 45 fc             \tmov    eax,DWORD PTR [rbp-0x4]\n  1c:\t89 d6                \tmov    esi,edx\n  1e:\t89 c7                \tmov    edi,eax\n  20:\tb8 00 00 00 00       \tmov    eax,0x0\n  25:\te8 00 00 00 00       \tcall   2a <main+0x2a>\n  2a:\t89 45 f4             \tmov    DWORD PTR [rbp-0xc],eax\n\tprintf(\"c=%d\\n\", c);\n  2d:\t8b 45 f4             \tmov    eax,DWORD PTR [rbp-0xc]\n  30:\t89 c6                \tmov    esi,eax\n  32:\tbf 00 00 00 00       \tmov    edi,0x0\n  37:\tb8 00 00 00 00       \tmov    eax,0x0\n  3c:\te8 00 00 00 00       \tcall   41 <main+0x41>\n}\n  41:\tc9                   \tleave\n  42:\tc3                   \tret\n```\n\n## 运行link_example.o\n```\n$ ll link_example.o\n-rw-r--r--. 1 root root 3408 4月   2 21:24 link_example.o\n\n$ chmod u+x link_example.o\n\n$ ./link_example.o\n-bash: ./link_example.o: 无法执行二进制文件\n```\n1. `add_lib.o`和`link_example.o`，通过objdump后，两个程序的地址都是从**0**开始的\n2. `add_lib.o`和`link_example.o`并不是一个**可执行文件**，而只是**目标文件**（Object File）\n    - 只有通过**链接器**（Linker）把多个**目标文件**以及调用的各种**函数库**链接起来，才能得到一个**可执行文件**\n    - gcc的`-o`参数，可以生成对应的可执行文件\n\n## 生成可执行文件\n```\n$ gcc -o link-example add_lib.o link_example.o\n\n$ ./link-example\nc = 15\n```\n\n## C代码 -> 汇编代码 -> 机器码\n1. **编译**（Compile） -> **汇编**（Assemble） -> **链接**（Link）\n    - 生成**可执行文件**\n2. 通过**装载器**（Loader）把可执行文件**装载**（Load）到内存中，CPU从内存中读取**指令**和**数据**，来开始真正执行程序\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-composition-elf-static-link-compile-assemble-link.jpg\" width=600/>\n\n## ELF格式 + 链接\n程序最终通过**装载器**变成**指令**和**数据**，但生成的可执行代码不仅仅是一条条的指令\n```\n$ objdump -d -M intel -S link-example\n```\n```\nlink-example：     文件格式 elf64-x86-64\nDisassembly of section .init:\n......\nDisassembly of section .plt:\n......\nDisassembly of section .text:\n......\n000000000040052d <add>:\n// add_lib.c\nint add(int a, int b)\n{\n  40052d:\t55                   \tpush   rbp\n  40052e:\t48 89 e5             \tmov    rbp,rsp\n  400531:\t89 7d fc             \tmov    DWORD PTR [rbp-0x4],edi\n  400534:\t89 75 f8             \tmov    DWORD PTR [rbp-0x8],esi\n\treturn a+b;\n  400537:\t8b 45 f8             \tmov    eax,DWORD PTR [rbp-0x8]\n  40053a:\t8b 55 fc             \tmov    edx,DWORD PTR [rbp-0x4]\n  40053d:\t01 d0                \tadd    eax,edx\n}\n  40053f:\t5d                   \tpop    rbp\n  400540:\tc3                   \tret\n\n0000000000400541 <main>:\n// link_example.c\n#include <stdio.h>\nint main()\n{\n  400541:\t55                   \tpush   rbp\n  400542:\t48 89 e5             \tmov    rbp,rsp\n  400545:\t48 83 ec 10          \tsub    rsp,0x10\n\tint a = 10;\n  400549:\tc7 45 fc 0a 00 00 00 \tmov    DWORD PTR [rbp-0x4],0xa\n\tint b = 5;\n  400550:\tc7 45 f8 05 00 00 00 \tmov    DWORD PTR [rbp-0x8],0x5\n\tint c = add(a, b);\n  400557:\t8b 55 f8             \tmov    edx,DWORD PTR [rbp-0x8]\n  40055a:\t8b 45 fc             \tmov    eax,DWORD PTR [rbp-0x4]\n  40055d:\t89 d6                \tmov    esi,edx\n  40055f:\t89 c7                \tmov    edi,eax\n  400561:\tb8 00 00 00 00       \tmov    eax,0x0\n  400566:\te8 c2 ff ff ff       \tcall   40052d <add>\n  40056b:\t89 45 f4             \tmov    DWORD PTR [rbp-0xc],eax\n\tprintf(\"c=%d\\n\", c);\n  40056e:\t8b 45 f4             \tmov    eax,DWORD PTR [rbp-0xc]\n  400571:\t89 c6                \tmov    esi,eax\n  400573:\tbf 20 06 40 00       \tmov    edi,0x400620\n  400578:\tb8 00 00 00 00       \tmov    eax,0x0\n  40057d:\te8 8e fe ff ff       \tcall   400410 <printf@plt>\n}\n......\nDisassembly of section .fini:\n......\n```\n1. **可执行代码**和**目标代码**类似，在Linux下，**可执行文件**和**目标文件**所使用的都是**ELF**格式\n    - ELF：**Execuatable and Linkable File Format**，**可执行**与**可链接**文件格式\n2. main函数里调用add的跳转地址，不再是下一条指令的地址，而是**add函数的入口地址**，这是**ELF格式**和**链接器**的功劳\n\n### ELF格式\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-composition-elf-static-link-elf-format.jpg\" width=600/>\n\n1. ELF有一个基本的**文件头**，用来表示这个文件的**基本属性**（是否是可执行文件、对应的CPU、操作系统等）\n2. ELF文件格式把各种信息，分成一个个的**Section**保存起来\n    - **.text** section\n      - **代码段**或指令段（Code Section），用来保存程序的代码和指令\n    - **.data** section\n      - **数据段**（Data Section），用来保存程序里面设置好的**初始化**数据信息\n    - **.rel.text** section\n      - **重定位表**（Relocation Table）\n      - `link_example.o`里面的main函数调用了add和printf这两个函数\n        - 但在**链接发生之前**，并不知道该跳转到哪里，这些信息会存储在重定位表里（**链接**的时候进行**修正**）\n    - **.symtab** Section\n      - **符号表**（Symbol Table），保存了**当前文件**里面定义的函数名称和对应地址的地址簿\n\n### 链接\n1. **链接器**会扫描**所有**输入的**目标文件**，然后把所有**符号表**里的信息收集起来，构成一个**全局的符号表**\n2. 然后再根据**重定位表**，把所有不确定要跳转到哪个地址的代码，根据**全局符号表**里面存储的地址，进行一次**修正**\n3. 最后，把所有的目标文件的**对应段**进行一次合并，变成了最终的可执行代码\n4. 因此，可执行文件里面的**函数调用的地址都是正确的**\n    - 装载器不再需要考虑**地址跳转**的问题，只需要解析ELF文件，把对应的指令和数据，加载到内存里面供CPU执行即可\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-composition-elf-static-link-link-process.jpg\" width=1000/>\n\n## Linux + Windows\n1. Linux和Windows的**可执行文件**的格式是不一样的\n    - Windows：**PE**（Portable Executable Format）\n    - Linux下的装载器只能解析ELF格式，而不能解析PE格式\n2. **Wine**：兼容PE格式的装载器\n3. **WSL**（Windows Subsystem for Linux）：可以解析和加载ELF格式的文件","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- 函数调用","url":"%2F2020%2F01%2F07%2Fcomputer-organization-function-call%2F","content":"\n## 程序栈\n```c\n// function_example.c\n\n#include <stdio.h>\n\nint static add(int a, int b)\n{\n    return a+b;\n}\n\nint main()\n{\n    int x = 5;\n    int y = 10;\n    int u = add(x, y);\n}\n```\n\n<!-- more -->\n\n```\n$ gcc -g -c function_example.c\n$ objdump -d -M intel -S function_example.o\n```\n```\n......\n0000000000000000 <add>:\n......\nint static add(int a, int b)\n{\n   0:\t55                   \tpush   rbp\n   1:\t48 89 e5             \tmov    rbp,rsp\n   4:\t89 7d fc             \tmov    DWORD PTR [rbp-0x4],edi\n   7:\t89 75 f8             \tmov    DWORD PTR [rbp-0x8],esi\n\treturn a+b;\n   a:\t8b 45 f8             \tmov    eax,DWORD PTR [rbp-0x8]\n   d:\t8b 55 fc             \tmov    edx,DWORD PTR [rbp-0x4]\n  10:\t01 d0                \tadd    eax,edx\n}\n  12:\t5d                   \tpop    rbp\n  13:\tc3                   \tret\n\n0000000000000014 <main>:\n\nint main()\n{\n  14:\t55                   \tpush   rbp\n  15:\t48 89 e5             \tmov    rbp,rsp\n  18:\t48 83 ec 10          \tsub    rsp,0x10\n\tint x = 5;\n  1c:\tc7 45 fc 05 00 00 00 \tmov    DWORD PTR [rbp-0x4],0x5\n\tint y = 10;\n  23:\tc7 45 f8 0a 00 00 00 \tmov    DWORD PTR [rbp-0x8],0xa\n\tint u = add(x, y);\n  2a:\t8b 55 f8             \tmov    edx,DWORD PTR [rbp-0x8]\n  2d:\t8b 45 fc             \tmov    eax,DWORD PTR [rbp-0x4]\n  30:\t89 d6                \tmov    esi,edx\n  32:\t89 c7                \tmov    edi,eax\n  34:\te8 c7 ff ff ff       \tcall   0 <add>\n  39:\t89 45 f4             \tmov    DWORD PTR [rbp-0xc],eax\n}\n  3c:\tc9                   \tleave\n  3d:\tc3                   \tret\n```\n1. `call`指令后面紧跟的是**跳转后的程序地址**\n2. add函数\n   - 代码先执行一条`push`指令和一条`mov`指令 -- **压栈**\n   - 在函数执行结束的时候，又执行了一条`pop`指令和一条`ret`指令 -- **出栈**\n3. 实现**函数调用**的几个思路\n   - 思路1：把调用的函数指令，直接插入在调用函数的地方，替换掉对应的call指令\n     - 问题：如果函数A调用函数B，而函数B又调用函数A，会产生无穷无尽地替换\n   - 思路2：CPU内部专门设立一个「**程序调用寄存器**」，用来存储接下来要**跳转回来执行的指令地址**\n     - 问题：在**多层**函数调用里，只记录一个地址是不够的，例如函数A调用函数B，函数B调用函数C，依次类推\n       - CPU里的**寄存器非常珍贵且有限**，Intel i7 CPU只有16个64位寄存器\n   - 思路3：在**内存**（比CPU的寄存器**便宜**！）里开辟一段空间，采用**栈**（**后进先出**）的数据结构\n     - **函数调用之前 -> 压栈，函数执行完之后 -> 出栈**\n     - 在真实的程序里，压栈的不只有函数调用完成后的返回地址\n       - 如果函数A调用函数B时，需要传输的**参数数据**在**寄存器不够用**时，也会被压入栈中\n     - 整个函数A所**占用的所有内存**，就是函数A的**栈帧**（**Stack Frame**）\n     - 实际的程序栈布局，**底在最上面，顶在最下面**\n       - **栈底的内存地址**一开始就是**固定**的，一层层压栈后，栈顶的内存地址是在**逐渐变小**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-function-call-stack.jpg\" width=1000/>\n\n### 实际执行过程\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-function-call-stack-add.jpg\" width=1000/>\n\n1. 栈指针：`rsp` ，帧指针：`rbp`\n2. add函数：入口为0、1行，结束为12、13行\n3. 调用34行的`call`指令时，会把**当前的PC寄存器里的值压栈（下一条指令的地址，即39行）**\n    - 目的：保留main函数调用add函数后要执行的指令地址\n4. add函数的第0行：`push   rbp`指令，在进行**压栈**（**寄存器 -> 内存**）\n    - `rbp`又叫**栈帧指针**，存放了**当前栈帧**位置的寄存器\n    - `push   rbp`把之前的调用函数，即**main函数的栈帧的栈底地址**，压到**栈顶**\n5. add函数的第1行：`mov    rbp,rsp`\n    - 把`rsp`这个**栈指针**的值复制到`rbp`，而`rsp`始终会指向**栈顶**\n    - 该命令意味着，`rbp`这个栈帧指针指向的地址，变成当前**最新的栈顶**，即**add函数的栈帧的栈底地址**\n6. add函数的第12行：`pop    rbp`：将**当前的栈顶出栈**\n7. add函数的第13行：`ret`：把call调用的时候压栈的指令地址出栈（即39行），更新到PC寄存器\n    - 将程序的**控制权**返回到出栈后的栈顶，即main函数\n8. 无论多少层的函数调用，只需要通过维持`rbp`和`rsp`，这两个维护**栈顶所在地址**的寄存器，就能管理好不同函数之间的跳转\n\n## 构造stack overflow\n1. 栈大小是有限的，构造stack overflow通常有两种方式\n   - **无限递归**\n   - **在栈空间里面创建非常占内存的变量**\n\n## 函数内联（性能优化）\n```c\n// function_example_inline.c\n\n#include <stdio.h>\n#include <time.h>\n#include <stdlib.h>\n\nint static add(int a, int b)\n{\n  return a+b;\n}\n\nint main()\n{\n  srand(time(NULL));\n  int x = rand() % 5;\n  int y = rand() % 10;\n  int u = add(x, y);\n  printf(\"u = %d\\n\",u);\n}\n```\n```\n$ gcc -g -c -O function_example_inline.c\n$ objdump -d -M intel -S function_example_inline.o\n```\n```\n......\n0000000000000000 <main>:\n{\n\treturn a+b;\n}\n\nint main()\n{\n......\n\treturn a+b;\n  4e:\t8d 34 0b             \tlea    esi,[rbx+rcx*1]\n\tint u = add(x, y);\n\tprintf(\"u = %d\\n\", u);\n  51:\tbf 00 00 00 00       \tmov    edi,0x0\n  56:\tb8 00 00 00 00       \tmov    eax,0x0\n  5b:\te8 00 00 00 00       \tcall   60 <main+0x60>\n}\n  60:\t5b                   \tpop    rbx\n  61:\tc3                   \tret\n```\n1. 没有把add函数单独编译成一段指令顺序，而是在调用`u=add(x, y)`，**直接替换成指令**，这就是**函数内联**\n2. 内联的优点\n  - **CPU需要执行的指令数减少**\n  - 根据地址跳转的过程不需要了，压栈和出栈的过程也不用了\n3. 内联的代价\n  - 内联意味着，把可以复用的程序指令在调用它的地方**完全展开**了\n  - 这样会导致**整个程序占用的空间会变大**\n4. **叶子函数**（**叶子过程**）：没有调用其它函数，只会被调用的函数","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- goto","url":"%2F2020%2F01%2F06%2Fcomputer-organization-goto%2F","content":"## CPU执行指令\n1. CPU是由一堆**寄存器**组成的，而寄存器是由多个**触发器**（Flip-Flop）或者**锁存器**（Latches）组成的简单电路\n    - 触发器和锁存器是两种不同原理的数字电路组成的**逻辑门**\n2. N个触发器或者锁存器，就可以组成一个N位的寄存器，能保存N位的数据，64位的Intel服务器，寄存器就是64位的\n3. 寄存器分类\n   - **PC寄存器**（Program Counter Register），也称为**指令地址寄存器**（Instruction Address Register）\n     - 用来存放**下一条**需要执行的计算机指令的**内存地址**\n   - **指令寄存器**（Instruction Register）\n     - 用来存放**当前正在执行**的指令\n   - **条件码寄存器**（Status Register）\n      - 用里面的**一个个标志位**（Flag），存放CPU进行**算术**或者**逻辑**计算的结果\n   - 其它\n      - 整数寄存器、浮点数寄存器、向量寄存器、地址寄存器、通用寄存器\n4. 程序执行\n    - CPU会根据**PC寄存器**里面的地址，从**内存**里把需要执行的指令读取到**指令寄存器**里面执行\n    - 然后根据**指令长度**自增，开始**顺序读取**下一条指令，一个程序的指令，在内存里面是**连续保存**的，也会一条条**顺序加载**\n    - 特殊指令，如J类指令（**跳转指令**），会**直接修改PC寄存器里面的地址值**\n      - 这样下一条要执行的指令就不是从内存里面顺序加载的了\n\n<!-- more -->\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-goto-register.jpg\" width=1000/>\n\n## if-else\n```c\n// test.c\n\n#include <time.h>\n#include <stdlib.h>\n\nint main()\n{\n  srand(time(NULL));\n  int r = rand() % 2;\n  int a = 10;\n  if (r == 0)\n  {\n    a = 1;\n  } else {\n    a = 2;\n  }\n}\n```\n```\n$ gcc -g -c test.c\n$ objdump -d -M intel -S test.o\n```\n```\n......\nint main()\n{\n......\n  if (r == 0)\n  33:\t83 7d fc 00          \tcmp    DWORD PTR [rbp-0x4],0x0\n  37:\t75 09                \tjne    42 <main+0x42>\n  {\n    a = 1;\n  39:\tc7 45 f8 01 00 00 00 \tmov    DWORD PTR [rbp-0x8],0x1\n  40:\teb 07                \tjmp    49 <main+0x49>\n  } else {\n    a = 2;\n  42:\tc7 45 f8 02 00 00 00 \tmov    DWORD PTR [rbp-0x8],0x2\n  }\n}\n  49:\tc9                   \tleave\n  4a:\tc3                   \tret\n```\n1. 对于`r == 0`的条件判断，被编译成了`cmp`和`jne`这两条指令\n  - `cmp`指令比较了前后两个操作数的值\n    - `DWORD PTR`代表操作的数据类型是**32位的整数**，`[rbp-0x4]`是一个寄存器的地址，从寄存器里拿到的变量r的值\n    - 第2个操作数`0x0`：常量0的16进制表示\n    - `cmp`指令的比较结果，会存入到**条件码寄存器**当中去\n      - 如果比较的结果为**True**，即`r==0`，就把**零标志条件码**（对应的条件码是**ZF**，Zero Flag）设置位1\n      - Intel CPU的其它标志位\n        - 进位标志（**CF**，Carry Flag）、符号标志（**SF**，Sign Flag）、溢出标志（**OF**，Overflow Flag）\n  - `cmp`指令执行完成后，PC寄存器会**自动自增**，开始执行下一条`jne`指令\n    - `jne = jump if not equal`，`jne`指令会查看对应的**零标志位**，如果为**0**，会跳转到42的位置\n      - 42对应的是汇编代码的行号，也是else条件里面的第一条指令\n      - 当发生**跳转**时\n        - PC寄存器就不再自增，而是被**直接设置**成42，CPU再把42地址里的指令加载到**指令寄存器**来执行\n        - 跳转到执行地址为42的指令，实际是一条`mov`指令\n          - 该指令将2设置到另一个**32位整型**的寄存器地址，相当于一个**赋值**操作\n        - 然后PC寄存器里的值继续自增，执行`leave`指令\n2. 如果`r == 0`条件满足，在赋值的`mov`指令执行完成后，有一个`jmp`的**无条件跳转指令**，跳转到49（`leave`指令）\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-goto-if-else.jpg\" width=1000/>\n\n## for\n```c\n// test.c\n\nint main()\n{\n  int a = 0;\n  for (int i = 0; i < 3; i++)\n  {\n    a += i;\n  }\n}\n```\n```\n$ gcc -g -c -std=c99 for.c\n$ objdump -d -M intel -S for.o\n```\n```\n......\nint main()\n{\n......\n  for (int i = 0; i < 3; i++)\n   b:\tc7 45 f8 00 00 00 00 \tmov    DWORD PTR [rbp-0x8],0x0\n  12:\teb 0a                \tjmp    1e <main+0x1e>\n  {\n......\n  for (int i = 0; i < 3; i++)\n  1a:\t83 45 f8 01          \tadd    DWORD PTR [rbp-0x8],0x1\n  1e:\t83 7d f8 02          \tcmp    DWORD PTR [rbp-0x8],0x2\n  22:\t7e f0                \tjle    14 <main+0x14>\n  24:\tb8 00 00 00 00       \tmov    eax,0x0\n  }\n}\n  29:\t5d                   \tpop    rbp\n  2a:\tc3                   \tret\n```\n1. 循环是用1e地址上的`cmp`比较指令和`jle`条件跳转指令来实现的\n2. `jle`跳转的地址，是`jle`指令前面的地址14（**向前跳转**）\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-goto-for.jpg\" width=1000/>","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"数学 -- 保证不输钱","url":"%2F2020%2F01%2F05%2Fmath-not-to-lose-money%2F","content":"\n问题抽象一下：假设有n个坑，第$i$个坑投注了$X_i$，倍率为$Y_i$，怎样设置倍率才能保证不亏钱？\n\n推导过程如下：\n\n假设某场第$k$个坑赔最少，最少赔付记为$min = (X_k \\times Y_k)$\n\n则$(X_k \\times Y_k) \\leq (X_l \\times Y_l) \\quad l \\in \\[1,n\\]$\n\n易得$\\frac{X_k \\times Y_k}{Y_l} \\leq X_l \\quad l \\in \\[1,n\\]$\n\n而收入为$(\\sum_{i=1}^n{X_i}) \\geq (\\sum_{i=1}^n{\\frac{X_k \\times Y_k}{Y_i}}) = (\\sum_{i=1}^n{\\frac{1}{Y_i}}) \\times (X_k \\times Y_k) = (\\sum_{i=1}^n{\\frac{1}{Y_i}}) \\times min$\n\n而不亏钱，只要保证$(\\sum_{i=1}^n{X_i}) \\geq min$即可，而由上易知，$(\\sum_{i=1}^n{\\frac{1}{Y_i}}) \\geq 1$为不亏钱的充分条件\n\n回到某同事预设的倍率：`[5, 5, 5, 5, 10, 15, 25, 45]`，$(\\sum_{i=1}^n{\\frac{1}{Y_i}}) = (\\frac{1}{5}+\\frac{1}{5}+\\frac{1}{5}+\\frac{1}{5}+\\frac{1}{10}+\\frac{1}{15}+\\frac{1}{25}+\\frac{1}{45}) \\approx 1.029 \\geq 1$\n\n理论上按这个预设倍率是不会亏钱的\n\n<!-- more -->","tags":["Math"],"categories":["Math"]},{"title":"计算机组成 -- 指令","url":"%2F2020%2F01%2F04%2Fcomputer-organization-instruction%2F","content":"\n## CPU + 计算机指令\n1. **硬件**的角度\n    - CPU是一个**超大规模集成电路**，通过电路实现了加法、乘法乃至各种各样的处理逻辑\n2. **软件工程师**的角度\n    - CPU就是一个执行各种**计算机指令**的逻辑机器\n    - 计算机指令是一门CPU能听懂的语言，也称为**机器语言**\n    - 不同的CPU能够听懂的语言不太一样，两种CPU各自支持的语言，就是两组不同的**计算机指令集**\n    - 计算机程序平时是存储在存储器中，这种程序指令存储在存储器里面的计算机，叫作**存储程序型计算机**\n\n<!-- more -->\n\n## 代码 -> 机器码（编译 -> 汇编）\n```c\n// test.c\nint main()\n{\n    int a = 1;\n    int b = 2;\n    a = a + b;\n}\n```\n1. **编译**（Compile）成**汇编**代码：把整个程序翻译成一个汇编语言（ASM，Assembly Language）的程序\n2. **汇编**：针对汇编代码，用**汇编器**（Assembler）翻译成**机器码**（Machine Code）\n   - 机器码由**0**和**1**组成的机器语言表示，一串串的**16进制**数字，就是CPU能够真正认识的**计算机指令**\n\n### 汇编代码 + 机器码\n```\n$ gcc --help\n-c                       编译、汇编到目标代码，不进行链接\n\n$ objdump --help\n-d, --disassemble        Display assembler contents of executable sections\n-M, --disassembler-options=OPT 将文本传递到 OPT 反汇编程序\n-S, --source             Intermix source code with disassembly\n\n$ gcc -g -c test.c\n$ objdump -d -M intel -S test.o\n```\n```\ntest.o：     文件格式 elf64-x86-64\n\nDisassembly of section .text:\n\n0000000000000000 <main>:\nint main()\n{\n   0:\t55                   \tpush   rbp\n   1:\t48 89 e5             \tmov    rbp,rsp\n\tint a = 1;\n   4:\tc7 45 fc 01 00 00 00 \tmov    DWORD PTR [rbp-0x4],0x1\n\tint b = 2;\n   b:\tc7 45 f8 02 00 00 00 \tmov    DWORD PTR [rbp-0x8],0x2\n\ta = a + b;\n  12:\t8b 45 f8             \tmov    eax,DWORD PTR [rbp-0x8]\n  15:\t01 45 fc             \tadd    DWORD PTR [rbp-0x4],eax\n}\n  18:\t5d                   \tpop    rbp\n  19:\tc3                   \tret\n```\n1. 左边的一堆数字是**机器码**，右边一系列的`push,mov,add,pop`就是对应的**汇编代码**\n2. 一行C代码，可能会对应**一条或多条**机器码和汇编代码\n3. 汇编代码和机器码之间是**一一对应**的\n    - 汇编代码：**给程序员看的机器码！！**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-instruction-compile-assembly.png\" width=1000/>\n\n## 解析指令和机器码\n\n### 指令类型\n| 指令类型 | 场景 | 示例指令 | 示例汇编代码 | 含义 | 注释 |\n| --- | --- | --- | --- | --- | --- |\n| **算术**指令 | 加减乘除 | add | `add $s1,$s2,$s3` | `$s1=$s2+$s3` | 将s2和s3寄存器中的数相加后的结果放到寄存器s1中 |\n| **逻辑**指令 | 与、非 | or | `or $s1,$s2,$s3` | `$s1=$s2\\|$s3` | 将s2和s3寄存器中的数**按位取或**后的结果放到寄存器s1中 |\n| **数据传输**指令 | 变量赋值、在内存读写数据 | load | `load $1,10($2)` | `$s1=memroy[$s2+10]` | 取s2寄存器中的数，加上10偏移量后，<br>找到内存中的**字**，存入到s1寄存器中 |\n| **条件分支**指令 | if-else | branch on equal | `beq $s1,$s2,10` | `if($s1==$s2) goto PC+4+10` | 如果s1和s2寄存器内的值相等，从程序计数器往后跳10 |\n| **无条件跳转**指令 | **函数调用** | jump | `j 1000` | `goto 1000` | 跳转到1000这个目标地址 |\n\n### MIPS指令集\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-instruction-mips.jpg\" width=1000/>\n\n1. MIPS指令是一个**32位**的整数，高6位叫作**操作码**（opcode），代表这条指令具体是一条怎样的指令\n    - 剩下的26位有三种格式，分别是**R**、**I**、**J**\n    - **R指令**\n       - 一般用来做**算术**和**逻辑**操作，里面有读取和写入数据的寄存器地址\n       - 如果是**逻辑位**操作，后面还有位移操作的位移量\n       - 最后的功能码，则是在前面的操作码不够的时候，扩展操作码表示对应的具体指令\n    - **I指令**\n       - 通常用在**数据传输**、**条件分支**、以及在**运算**时使用的并非变量而是**常数**的时候\n       - 第三种情况：此时没有了位移量和操作码，也没有第三个寄存器，而是把这三部分直接**合并**成一个**地址值**或者一个**常数**\n    - **J指令**\n       - 跳转指令，高6位之外的26位都是一个跳转后的地址\n2. `add $t0,$s1,$s2`，用十进制表示\n    - opcode：**0**\n    - rs代表第一个寄存器s1的地址**17**\n    - rt代表第二个寄存器s2的地址**18**\n    - rd代表目标的临时寄存器t0的地址**8**\n    - 由于不是位移操作，所以位移量是**0**\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-instruction-mips-add.jpg\" width=1000/>\n\n打孔代表1，没打孔代表0\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-instruction-mips-add-punching-tape.png\" width=600/>","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- 提升性能","url":"%2F2020%2F01%2F03%2Fcomputer-organization-improve-performance%2F","content":"\n## CPU的功耗\n```\nCPU time = 时钟周期时间（Clock Cycle Time） × CPU时钟周期数（CPU Cycles）\n         = 时钟周期时间（Clock Cycle Time） × 指令数 × 每条指令的平均周期数（Cycles Per Instruction，CPI）\n```\n1. 80年代开始，CPU硬件工程师主要着力**提升CPU主频**，到功耗是CPU的**人体极限**\n2. CPU，一般被叫做**超大规模集成电路**，这些电路，实际上都是一个个**晶体管**组合而成的\n    - CPU计算，实际上是让晶体管里面的『开关』不断地去打开或关闭，来组合完成各种运算和功能\n3. 如果要计算得快，有两个方向：**增加密度**（7nm制程）、**提升主频**，但这两者都会增加**功耗**，带来耗电和散热的问题\n    - 密度 -> 晶体管数量\n    - 主频 -> 开关频率\n4. 如果功耗增加太多，会导致CPU散热跟不上，此时就需要**降低电压**（低压版CPU）\n\n```\n功耗 ≈ 1/2 × 负载电容 × 电压的平方 × 开关频率 × 晶体管数量\n```\n\n<!-- more -->\n\n## 并行优化 -- 阿姆达尔定律\n```\n优化后的执行时间 = 受优化影响的执行时间 / 加速倍数 + 不受影响的执行时间\n```\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-improve-performance-amdahl-low.jpg\" width=1000/>\n\n## 其它\n1. 加速**大概率**事件（**CPU -> GPU -> TPU**）\n2. 通过**流水线**提高性能\n3. 通过**预测**提高性能（**分支和冒险**、**局部性原理**）\n","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- 性能","url":"%2F2020%2F01%2F02%2Fcomputer-organization-performance%2F","content":"\n## 性能指标\n1. **响应时间**（Response time）、**执行时间**（Execution time）\n    - 执行一个程序，需要花多少时间\n2. **吞吐率**（Throughput）、**带宽**（Bandwidth）\n    - 单位时间范围内，能处理多少数据或执行多少指令，可以通过多核、集群等方式来提升吞吐率\n3. **性能 =  1/响应时间**\n\n<!-- more -->\n\n## CPU时钟\n1. time命令\n   - real time\n     - Wall Clock Time/Elapsed Time，运行程序整个过程中流逝掉的时间\n   - user time\n     - 在**用户态**运行指令的时间\n   - sys time\n     - 在**操作系统内核**里运行指令的时间\n2. 程序实际花费的CPU执行时间：**CPU time = user time + sys time**\n3. 程序实际占用的CPU time一般比Elapsed Time**少**（单核情况下）\n\n```shell\n$ time seq 1000000 | wc -l\n1000000\n\nreal\t0m0.024s\nuser\t0m0.018s\nsys\t0m0.005s\n```\n1. 程序实际花了0.024s，CPU time只有`0.018s+0.005s=0.023s`\n2. 如果在一台多核或多CPU的机器上运行，seq和wc可能会被分配到两个CPU上\n   - user和sys是两个CPU相加的，而real是现实时钟里走过的时间\n   - 极端情况下（两个命令完全并行），`user + sys ≈ real × 2`\n\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-performance-cpu-time-elapsed-time.jpg\" width=1000/>\n\n### 时钟周期时间\n```\nCPU time = 时钟周期时间（Clock Cycle） × CPU时钟周期数（CPU Cycles）\n         = 时钟周期时间（Clock Cycle） × 指令数 × 每条指令的平均周期数（Cycles Per Instruction，CPI）\n```\n1. CPU主频 -- 2.8GHz\n    - 代表CPU能够识别出来的**最小时间间隔**\n    - CPU内部，存在一个晶体振荡器，简称**晶振**\n    - 时钟周期时间为`1/2.8GHz`\n2. 提升性能的方向\n   - **缩短时钟周期时间**\n     - 提升主频（超频或换CPU）\n   - **降低CPI**\n     - 流水线技术（Pipeline）\n   - **减少指令数**\n     - 编译器的挑战","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- First Draft","url":"%2F2020%2F01%2F01%2Fcomputer-organization-von-neumann-architecture%2F","content":"\n<img src='https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-composition-von-neumann-architecture.jpg' width=1000/>\n\n从**输入设备**读取输入信息，通过**运算器**和**控制器**来执行存储在**存储器**里的程序，最终把结果输出到**输出设备**中\n\n<!-- more -->","tags":["Computer Organization"],"categories":["Computer Organization"]},{"title":"计算机组成 -- 知识地图","url":"%2F2020%2F01%2F01%2Fcomputer-organization-knowledge-map%2F","content":"\n<img src=\"https://computer-composition-1253868755.cos.ap-guangzhou.myqcloud.com/computer-organization-knowledge-map.png\" width=1000/>\n\n<!-- more -->\n","tags":["Knowledge Map"],"categories":["Computer Organization"]},{"title":"Linux使用 -- awk","url":"%2F2019%2F10%2F23%2Flinux-practice-awk%2F","content":"\n## awk sed\n1. awk更像是**脚本语言**\n2. awk：用于**比较规范**的文本处理，用于**统计**数量并输出指定字段\n3. sed：用于将**不规范**的文本，处理为**比较规范**的文本\n\n<!-- more -->\n\n## 控制流程\n1. 输入数据前例程**`BEGIN{}`**\n2. 主输入循环**`{}`**\n3. 所有文件读取完成例程**`END{}`**\n\n## 记录和字段\n1. **每行**称为AWK的**记录**\n2. 使用**分隔符**（可以**自定义**，默认是**空格**和**制表符**）分隔开的单词称为**字段**\n\n### 字段的引用\n1. `$1 $2 ... $n`：表示每一个字段\n2. `-F`：自定义分隔符，可以使用正则表达式\n\n```\n[root@localhost ~]# awk -F\"'\" '/^menu/{print $2}' /boot/grub2/grub.cfg\nCentOS Linux (3.10.0-1062.el7.x86_64) 7 (Core)\nCentOS Linux (0-rescue-6a299ef164734d338007f5e88cee6be0) 7 (Core)\n\n[root@localhost ~]# awk -F\"'\" '/^menu/{print x++,$2}' /boot/grub2/grub.cfg\n0 CentOS Linux (3.10.0-1062.el7.x86_64) 7 (Core)\n1 CentOS Linux (0-rescue-6a299ef164734d338007f5e88cee6be0) 7 (Core)\n```\n\n## 表达式\n1. 赋值操作符\n    - `var1 = 'name'`\n    - `var2 = 'hello' 'world'`\n    - `var3 = $1`\n    - `++ -- += -= *= /= %= ^=`\n2. 算数操作符\n    - `+ - * / % ^`\n3. 系统变量\n    - `FS`和`OFS`：**字段分隔符**，`OFS`表示输出的字段分隔符\n    - `RS`：**记录分隔符**（默认是**换行符**）\n    - `NR`和`FNR`：行数\n    - `NF`：字段数量，最后一个字段内容可以用`$NF`取出\n4. 关系操作符\n    - `< > <= >= == != ~ !~`\n5. 布尔操作符\n    - `&& || !`\n\n```\n[root@localhost ~]# head -5 /etc/passwd\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n\n[root@localhost ~]# head -5 /etc/passwd | awk -F':' '{print $1}'\nroot\nbin\ndaemon\nadm\nlp\n\n[root@localhost ~]# head -5 /etc/passwd | awk 'BEGIN{FS=\":\"}{print $1}'\nroot\nbin\ndaemon\nadm\nlp\n\n[root@localhost ~]# head -5 /etc/passwd | awk 'BEGIN{FS=\":\"}{print $1,$2}'\nroot x\nbin x\ndaemon x\nadm x\nlp x\n\n[root@localhost ~]# head -5 /etc/passwd | awk 'BEGIN{FS=\":\";OFS=\"-\"}{print $1,$2}'\nroot-x\nbin-x\ndaemon-x\nadm-x\nlp-x\n\n[root@localhost ~]# head -5 /etc/passwd | awk 'BEGIN{RS=\":\"}{print $0}' | head -5\nroot\nx\n0\n0\nroot\n```\n```\n[root@localhost ~]# head -5 /etc/passwd | awk '{print NR,$0}'\n1 root:x:0:0:root:/root:/bin/bash\n2 bin:x:1:1:bin:/bin:/sbin/nologin\n3 daemon:x:2:2:daemon:/sbin:/sbin/nologin\n4 adm:x:3:4:adm:/var/adm:/sbin/nologin\n5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n\n[root@localhost ~]# head -5 /etc/passwd | awk '{print FNR,$0}'\n1 root:x:0:0:root:/root:/bin/bash\n2 bin:x:1:1:bin:/bin:/sbin/nologin\n3 daemon:x:2:2:daemon:/sbin:/sbin/nologin\n4 adm:x:3:4:adm:/var/adm:/sbin/nologin\n5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n\n[root@localhost ~]# awk '{print FNR,$0}' /etc/hosts /etc/hosts\n1 127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n2 ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n1 127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n2 ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n\n[root@localhost ~]# awk '{print NR,$0}' /etc/hosts /etc/hosts\n1 127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n2 ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n3 127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n4 ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n```\n```\n[root@localhost ~]# head -5 /etc/passwd | awk 'BEGIN{FS=\":\"}{print NF}'\n7\n7\n7\n7\n7\n\n[root@localhost ~]# head -5 /etc/passwd | awk 'BEGIN{FS=\":\"}{print $NF}'\n/bin/bash\n/sbin/nologin\n/sbin/nologin\n/sbin/nologin\n/sbin/nologin\n```\n\n## 条件和循环\n\n### 条件\n```\nif(表达式)\n    {awk语句}\n[else\n    {awk语句}\n]\n```\n```\n[root@localhost ~]# cat kpi.txt\nuser1 70 72 74 76 74 72\nuser2 80 82 84 82 80 78\nuser3 60 61 62 63 64 65\nuser4 90 89 88 87 86 85\nuser5 45 60 63 62 61 50\n[root@localhost ~]# awk '{if($2>=80) print $1}' kpi.txt\nuser2\nuser4\n[root@localhost ~]# awk '{if($2>=80) {print $1;print $2}}' kpi.txt\nuser2\n80\nuser4\n90\n```\n\n### 循环\n```\nwhile(表达式)\n    {awk语句}\n\ndo{\n    awk语句\n}while(表达式)\n\nfor(初始值;循环判断条件;累加)\n    {awk语句}\n```\n```\n[root@localhost ~]# cat kpi.txt\nuser1 70 72 74 76 74 72\nuser2 80 82 84 82 80 78\nuser3 60 61 62 63 64 65\nuser4 90 89 88 87 86 85\nuser5 45 60 63 62 61 50\n[root@localhost ~]# awk '{sum=0; for(i=2;i<=NF;i++) sum+=$i; print $1,sum/(NF-1)}' kpi.txt\nuser1 73\nuser2 81\nuser3 62.5\nuser4 87.5\nuser5 56.8333\n```\n\n## 数组\n\n### 数组的定义\n1. 数组：一组有某种关联的数据（变量），通过下标依次访问\n2. `数组名[下标]=值`\n    - 下标可以使用**数字**，也可以使用**字符串**\n\n### 数组的遍历\n1. `for (变量 in 数组名)`\n   - 使用`数组名[变量]`的方式依次对每个数组的元素进行操作\n\n### 删除数组\n1. `delete 数组名`\n2. `delete 数组名[下标]`\n\n### 命令行参数数组\n1. **ARGC**\n2. **ARGV**\n\n### 样例\n```\n[root@localhost ~]# cat kpi.txt\nuser1 70 72 74 76 74 72\nuser2 80 82 84 82 80 78\nuser3 60 61 62 63 64 65\nuser4 90 89 88 87 86 85\nuser5 45 60 63 62 61 50\n[root@localhost ~]# awk '{sum=0; for(i=2;i<=NF;i++) sum+=$i; avg[$1]=sum/(NF-1)} END{for(user in avg) print user,avg[user]}' kpi.txt\nuser1 73\nuser2 81\nuser3 62.5\nuser4 87.5\nuser5 56.8333\n[root@localhost ~]# awk '{sum=0; for(i=2;i<=NF;i++) sum+=$i; avg[$1]=sum/(NF-1)} END{for(user in avg) sum2+=avg[user]; print sum2/NR}' kpi.txt\n72.1667\n```\n```\n[root@localhost ~]# cat avg.awk\n{sum=0; for(i=2;i<=NF;i++) sum+=$i; avg[$1]=sum/(NF-1)} END{for(user in avg) sum2+=avg[user]; print sum2/NR}\n\n[root@localhost ~]# awk -f avg.awk kpi.txt\n72.1667\n```\n```\n[root@localhost ~]# cat arg.awk\nBEGIN {\n    for (x=0;x<ARGC;x++)\n        print ARGV[x]\n    print ARGC\n}\n\n[root@localhost ~]# awk -f arg.awk  11 22 33\nawk\n11\n22\n33\n4\n```\n```\n[root@localhost ~]# cat result.awk\n{\nsum = 0;\nfor (i=2; i<=NF; i++)\n    sum += $i\navg[$1] = sum/(NF-1)\n\nif (avg[$1] >= 80)\n    letter=\"S\"\nelse if (avg[$1] >= 70)\n    letter=\"A\"\nelse if (avg[$1] >= 60)\n    letter=\"B\"\nelse\n    letter=\"C\"\n\nprint $1,avg[$1],letter\nletter_all[letter]++\n}\n\nEND {\nfor (user in avg)\n    sum_all += avg[user]\navg_all =  sum_all/NR\nprint \"avg all\",avg_all\n\nfor (user in avg)\n    if (avg[user] > avg_all)\n        above++\n    else\n        below++\n\nprint \"above\",above\nprint \"below\",below\n\nfor (l in letter_all)\n    print l,letter_all[l]\n}\n\n[root@localhost ~]# awk -f result.awk kpi.txt\nuser1 73 A\nuser2 81 S\nuser3 62.5 B\nuser4 87.5 S\nuser5 56.8333 C\navg all 72.1667\nabove 3\nbelow 2\nA 1\nB 1\nC 1\nS 2\n```\n\n## 函数\n\n### 算术函数\n1. `sin() cos()`\n2. `int()`\n3. `rand() srand()`\n\n```\n[root@localhost ~]# awk 'BEGIN{pi=3.14;print int(pi)}'\n3\n[root@localhost ~]# awk 'BEGIN{print rand()}'\n0.237788\n[root@localhost ~]# awk 'BEGIN{print rand()}'\n0.237788\n[root@localhost ~]# awk 'BEGIN{srand();print rand()}'\n0.41332\n[root@localhost ~]# awk 'BEGIN{srand();print rand()}'\n0.388034\n```\n\n### 字符串函数\n1. `gsub(r,s,t)`\n2. `index(s,t)`\n3. `length(s)`\n4. `match(s,r)`\n5. `split(s,a,sep)`\n6. `sub(r,s,t)`\n7. `substr(s,p,n)`\n\n### 自定义函数\n```\nfunction 函数名 (参数) {\n    awk语句\n    return awk变量\n}\n```\n```\n[root@localhost ~]# awk 'function a() {return 0} BEGIN{print a()}'\n0\n[root@localhost ~]# awk 'function double(str) {return str str} BEGIN{print double(\"hello awk\")}'\nhello awkhello awk\n```","tags":["Linux Practice"],"categories":["Practice"]},{"title":"Linux使用 -- sed","url":"%2F2019%2F10%2F22%2Flinux-practice-sed%2F","content":"\n## sed awk\n1. `sed`：一般用于对文本内容做**替换**\n2. `awk`：一般用于对文本内容进行**统计**、按**需要的格式**进行输出\n\n<!-- more -->\n\n## 替换指令\n\n### 模式空间\n1. 将文件以**行**为单位读取到内存（模式空间）\n2. 使用sed的每个脚本对该行进行操作\n3. 处理完成后输出该行\n\n### 替换命令s\n```\nsed 's/old/new/' filename\nsed -e 's/old/new/' -e 's/old/new/' filename ...\nsed -i 's/old/new/' 's/old/new/' filename ...\n```\n带正则表达式的替换命令s\n```\nsed 's/正则表达式/new/' filename\nsed -r 's/扩展正则表达式(+、？、|)/new/' filename\n```\n\n### 样例\n\n#### 基本使用\n```\n[root@localhost ~]# echo a a a > afile\n[root@localhost ~]# sed 's/a/aa/' afile\naa a a\n[root@localhost ~]# sed 's///aa/' afile\nsed：-e 表达式 #1，字符 5：“s”的未知选项\n[root@localhost ~]# sed 's!/!aa!' afile\na a a\n[root@localhost ~]# sed -e 's/a/aa/' -e 's/aa/bb/' afile\nbb a a\n[root@localhost ~]# sed 's/a/aa/;s/aa/bb/' afile\nbb a a\n[root@localhost ~]# cat afile\na a a\n[root@localhost ~]# sed -i 's/a/aa/;s/aa/bb/' afile\n[root@localhost ~]# cat afile\nbb a a\n```\n```\n[root@localhost ~]# head -5 /etc/passwd\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n[root@localhost ~]# head -5 /etc/passwd | sed 's/...//'\nt:x:0:0:root:/root:/bin/bash\n:x:1:1:bin:/bin:/sbin/nologin\nmon:x:2:2:daemon:/sbin:/sbin/nologin\n:x:3:4:adm:/var/adm:/sbin/nologin\nx:4:7:lp:/var/spool/lpd:/sbin/nologin\n[root@localhost ~]# head -5 /etc/passwd | sed 's/s*bin//'\nroot:x:0:0:root:/root://bash\n:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/:/sbin/nologin\nadm:x:3:4:adm:/var/adm://nologin\nlp:x:4:7:lp:/var/spool/lpd://nologin\n\n[root@localhost ~]# grep root /etc/passwd\nroot:x:0:0:root:/root:/bin/bash\noperator:x:11:0:operator:/root:/sbin/nologin\n[root@localhost ~]# grep root /etc/passwd | sed 's/^root//'\n:x:0:0:root:/root:/bin/bash\noperator:x:11:0:operator:/root:/sbin/nologin\n```\n\n#### 扩展元字符\n`+`、`?`、`|`是扩展元字符，所以需要`-r`参数，`()`也是扩展元字符\n```\n[root@localhost ~]# cat bfile\nb\na\naa\naaa\nab\nabb\nabbb\n[root@localhost ~]# sed 's/ab*/!/' bfile\nb\n!\n!a\n!aa\n!\n!\n!\n[root@localhost ~]# sed -r 's/ab+/!/' bfile\nb\na\naa\naaa\n!\n!\n!\n[root@localhost ~]# sed -r 's/ab?/!/' bfile\nb\n!\n!a\n!aa\n!\n!b\n!bb\n[root@localhost ~]# sed -r 's/a|b/!/' bfile\n!\n!\n!a\n!aa\n!b\n!bb\n!bbb\n[root@localhost ~]# sed -r 's/(aa)|(bb)/!/' bfile\nb\na\n!\n!a\nab\na!\na!b\n```\n`()`扩展元字符支持**回调**\n```\n[root@localhost ~]# cat cfile\naxyzb\n[root@localhost ~]# sed -r 's/(a.*b)/\\1:\\1/' cfile\naxyzb:axyzb\n```\n\n#### 全局替换\n```\n[root@localhost ~]# head -5 /etc/passwd\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n\n[root@localhost ~]# head -5 /etc/passwd | sed 's/root/!!!!/'\n!!!!:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n\n[root@localhost ~]# head -5 /etc/passwd | sed 's/root/!!!!/g'\n!!!!:x:0:0:!!!!:/!!!!:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n\n[root@localhost ~]# head -5 /etc/passwd | sed 's/root/!!!!/2'\nroot:x:0:0:!!!!:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n```\n\n#### 标志位\n1. `s/old/new/标志位`\n2. `数字`：第几次出现才进行替换\n3. `g`：每次出现都进行替换\n4. `p`：打印**模式空间**的内容\n   - `sed -n 'script' filename`阻止默认输出\n5. `w file`：将**模式空间**的内容写入到文件\n\n匹配成功的行，会被多打印一次\n```\n[root@localhost ~]# head -5 /etc/passwd | sed 's/root/!!!!/p'\n!!!!:x:0:0:root:/root:/bin/bash\n!!!!:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n```\n只有匹配成功的行才会被打印\n```\n[root@localhost ~]# head -5 /etc/passwd | sed -n 's/root/!!!!/p'\n!!!!:x:0:0:root:/root:/bin/bash\n```\n匹配成功的行被写入到另外的文件\n```\n[root@localhost ~]# head -5 /etc/passwd | sed -n 's/root/!!!!/w /tmp/a.txt'\n[root@localhost ~]# cat /tmp/a.txt\n!!!!:x:0:0:root:/root:/bin/bash\n```\n\n#### 寻址\n1. 默认对**每行**进行操作，增加寻址后对**匹配的行**进行操作\n2. `/正则表达式/s/old/new/g`\n3. `行号s/old/new/g`\n    - 行号可以是最后一行`$`\n4. 可以使用**两个寻址符号**，也可以混合使用**行号**和**正则地址**\n\n```\n[root@localhost ~]# head -6 /etc/passwd\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\nsync:x:5:0:sync:/sbin:/bin/sync\n[root@localhost ~]# head -6 /etc/passwd | sed 's/adm/!/'\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\n!:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\nsync:x:5:0:sync:/sbin:/bin/sync\n```\n```\n[root@localhost ~]# head -6 /etc/passwd | sed '1s/adm/!/'\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\nsync:x:5:0:sync:/sbin:/bin/sync\n[root@localhost ~]# head -6 /etc/passwd | sed '1,3s/adm/!/'\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\nsync:x:5:0:sync:/sbin:/bin/sync\n[root@localhost ~]# head -6 /etc/passwd | sed '1,$s/adm/!/'\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\n!:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\nsync:x:5:0:sync:/sbin:/bin/sync\n```\n```\n[root@localhost ~]# head -6 /etc/passwd | sed '/root/s/bash/!/'\nroot:x:0:0:root:/root:/bin/!\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\nsync:x:5:0:sync:/sbin:/bin/sync\n[root@localhost ~]# head -6 /etc/passwd | sed '2s/nologin/!/'\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/!\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\nsync:x:5:0:sync:/sbin:/bin/sync\n[root@localhost ~]# head -6 /etc/passwd | sed '/^bin/s/nologin/!/'\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/!\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\nsync:x:5:0:sync:/sbin:/bin/sync\n```\n```\n[root@localhost ~]# head -6 /etc/passwd | sed '/^bin/,$s/nologin/!/'\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/!\ndaemon:x:2:2:daemon:/sbin:/sbin/!\nadm:x:3:4:adm:/var/adm:/sbin/!\nlp:x:4:7:lp:/var/spool/lpd:/sbin/!\nsync:x:5:0:sync:/sbin:/bin/sync\n[root@localhost ~]# head -6 /etc/passwd | sed '/^bin/,$s/nologin/!/g'\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/!\ndaemon:x:2:2:daemon:/sbin:/sbin/!\nadm:x:3:4:adm:/var/adm:/sbin/!\nlp:x:4:7:lp:/var/spool/lpd:/sbin/!\nsync:x:5:0:sync:/sbin:/bin/sync\n```\n\n#### 分组\n1. 寻址可以匹配**多条命令**\n2. `/regular/{s/old/new/;s/old/new/}`\n\n#### sed脚本文件\n1. 可以将选项保存为文件，使用`-f`加载脚本文件\n2. `sed -f sedscript filename`\n\n## 其它指令\n\n### 删除\n1. `[寻址]d`\n2. 删除**模式空间**的内容，改变脚本的**控制流**，读取新的输入行\n\n```\n[root@localhost ~]# cat bfile\nb\na\naa\naaa\nab\nabb\nabbb\n[root@localhost ~]# sed '/ab/d' bfile\nb\na\naa\naaa\n[root@localhost ~]# sed '/ab/d;s/a/!/' bfile\nb\n!\n!a\n!aa\n[root@localhost ~]# sed '/ab/d;=' bfile\n1\nb\n2\na\n3\naa\n4\naaa\n```\n\n### 追加 插入 更改\n1. 追加命令`a`\n2. 插入命令`i`\n3. 更改命令`c`\n\n```\n[root@localhost ~]# cat bfile\nb\na\naa\naaa\nab\nabb\nabbb\n[root@localhost ~]# sed '/ab/i hello' bfile\nb\na\naa\naaa\nhello\nab\nhello\nabb\nhello\nabbb\n[root@localhost ~]# sed '/ab/a hello' bfile\nb\na\naa\naaa\nab\nhello\nabb\nhello\nabbb\nhello\n[root@localhost ~]# sed '/ab/c hello' bfile\nb\na\naa\naaa\nhello\nhello\nhello\n```\n\n### 读文件和写文件\n1. 读文件命令`r`\n2. 写文件命令`w`\n\n```\n[root@localhost ~]# cat bfile\nb\na\naa\naaa\nab\nabb\nabbb\n[root@localhost ~]# cat afile\nbb a a\n[root@localhost ~]# sed '/ab/r afile' bfile\nb\na\naa\naaa\nab\nbb a a\nabb\nbb a a\nabbb\nbb a a\n```\n\n### 打印\n1. 打印命令p（直接将**匹配的行**输出，而替换命令的p标志位是将**替换后的模式空间**输出）\n\n```\n[root@localhost ~]# cat bfile\nb\na\naa\naaa\nab\nabb\nabbb\n[root@localhost ~]# sed '/ab/p' bfile\nb\na\naa\naaa\nab\nab\nabb\nabb\nabbb\nabbb\n[root@localhost ~]# sed -n '/ab/p' bfile\nab\nabb\nabbb\n```\n\n### 下一行\n1. 下一行命令`n`\n2. 打印行号命令`=`\n\n### 退出\n1. 退出命令`q`\n2. 哪个效率更高？\n    - `sed 10q filename` -- 效率更高\n    - `sed -n 1,10p filename` -- 10行后的数据依然会被读入内存，只是不进行匹配\n\n```\n[root@localhost ~]# seq 1 1000000 > lines.txt\n[root@localhost ~]# wc -l lines.txt\n1000000 lines.txt\n\n[root@localhost ~]# time sed -n '1,10p' lines.txt\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\nreal\t0m0.080s\nuser\t0m0.068s\nsys\t0m0.011s\n\n[root@localhost ~]# time sed -n '10q' lines.txt\n\nreal\t0m0.002s\nuser\t0m0.002s\nsys\t0m0.000s\n```\n\n## 多行模式空间\n1. 使用多行模式的场景\n    - XML或JSON格式的配置文件，为多行出现\n2. 多行模式处理命令\n    - `N`：将下一行**追加**到模式空间\n    - `P`：**打印**模式空间中第一个字符到**第一个换行符**\n    - `D`：**删除**模式空间中第一个字符到**第一个换行符**\n3. **在多行模式中，`.`可以匹配换行符**\n\n```\n[root@localhost ~]# cat dfile\nhel\nlo\n[root@localhost ~]# sed 'N' dfile\nhel\nlo\n[root@localhost ~]# sed 'N;s/hello/!!!/' dfile\nhel\nlo\n[root@localhost ~]# sed 'N;s/hel\\nlo/!!!/' dfile\n!!!\n[root@localhost ~]# sed 'N;s/hel.lo/!!!/' dfile\n!!!\n```\n\n```\n[root@localhost ~]# cat > b.txt << EOF\n> hell\n> o bash hel\n> lo bash\n> EOF\n[root@localhost ~]# cat b.txt\nhell\no bash hel\nlo bash\n[root@localhost ~]# sed 'N;s/\\n//;s/hello bash/hello sed\\n/;P;D' b.txt\nhello sed\n hello sed\n\n[root@localhost ~]#\n```\n\n### 保持空间\n1. 保持空间是多行的一种操作方式\n2. 将内存**暂存在保持空间**，便于做多行处理\n3. **保持空间的初始内容是一个换行符**\n4. 保持空间命令\n   - `h`（覆盖）、`H`（追加）：模式空间 -> 保持空间\n   - `g`（覆盖）、`G`（追加）：保持空间 -> 模式空间\n   - `x`：保持空间 <-交换-> 模式空间\n\n```\n[root@localhost ~]# head -6 /etc/passwd\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nadm:x:3:4:adm:/var/adm:/sbin/nologin\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\nsync:x:5:0:sync:/sbin:/bin/sync\n[root@localhost ~]# head -6 /etc/passwd | cat -n\n     1\troot:x:0:0:root:/root:/bin/bash\n     2\tbin:x:1:1:bin:/bin:/sbin/nologin\n     3\tdaemon:x:2:2:daemon:/sbin:/sbin/nologin\n     4\tadm:x:3:4:adm:/var/adm:/sbin/nologin\n     5\tlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n     6\tsync:x:5:0:sync:/sbin:/bin/sync\n[root@localhost ~]# head -6 /etc/passwd | cat -n | tac\n     6\tsync:x:5:0:sync:/sbin:/bin/sync\n     5\tlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n     4\tadm:x:3:4:adm:/var/adm:/sbin/nologin\n     3\tdaemon:x:2:2:daemon:/sbin:/sbin/nologin\n     2\tbin:x:1:1:bin:/bin:/sbin/nologin\n     1\troot:x:0:0:root:/root:/bin/bash\n```\n```\n[root@localhost ~]# cat -n /etc/passwd | head -6 | sed -n '1h;G;x;$p'\n     5\tlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n     4\tadm:x:3:4:adm:/var/adm:/sbin/nologin\n     3\tdaemon:x:2:2:daemon:/sbin:/sbin/nologin\n     2\tbin:x:1:1:bin:/bin:/sbin/nologin\n     1\troot:x:0:0:root:/root:/bin/bash\n     1\troot:x:0:0:root:/root:/bin/bash\n[root@localhost ~]# cat -n /etc/passwd | head -6 | sed -n '1h;1!G;x;$p'\n     5\tlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n     4\tadm:x:3:4:adm:/var/adm:/sbin/nologin\n     3\tdaemon:x:2:2:daemon:/sbin:/sbin/nologin\n     2\tbin:x:1:1:bin:/bin:/sbin/nologin\n     1\troot:x:0:0:root:/root:/bin/bash\n[root@localhost ~]# cat -n /etc/passwd | head -6 | sed -n '1h;1!G;$!x;$p'\n     6\tsync:x:5:0:sync:/sbin:/bin/sync\n     5\tlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n     4\tadm:x:3:4:adm:/var/adm:/sbin/nologin\n     3\tdaemon:x:2:2:daemon:/sbin:/sbin/nologin\n     2\tbin:x:1:1:bin:/bin:/sbin/nologin\n     1\troot:x:0:0:root:/root:/bin/bash\n```\n按照保持空间的方式去思考！\n```\n[root@localhost ~]# cat -n /etc/passwd | head -6 | sed 'G;h'\n     1\troot:x:0:0:root:/root:/bin/bash\n\n     2\tbin:x:1:1:bin:/bin:/sbin/nologin\n     1\troot:x:0:0:root:/root:/bin/bash\n\n     3\tdaemon:x:2:2:daemon:/sbin:/sbin/nologin\n     2\tbin:x:1:1:bin:/bin:/sbin/nologin\n     1\troot:x:0:0:root:/root:/bin/bash\n\n     4\tadm:x:3:4:adm:/var/adm:/sbin/nologin\n     3\tdaemon:x:2:2:daemon:/sbin:/sbin/nologin\n     2\tbin:x:1:1:bin:/bin:/sbin/nologin\n     1\troot:x:0:0:root:/root:/bin/bash\n\n     5\tlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n     4\tadm:x:3:4:adm:/var/adm:/sbin/nologin\n     3\tdaemon:x:2:2:daemon:/sbin:/sbin/nologin\n     2\tbin:x:1:1:bin:/bin:/sbin/nologin\n     1\troot:x:0:0:root:/root:/bin/bash\n\n     6\tsync:x:5:0:sync:/sbin:/bin/sync\n     5\tlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n     4\tadm:x:3:4:adm:/var/adm:/sbin/nologin\n     3\tdaemon:x:2:2:daemon:/sbin:/sbin/nologin\n     2\tbin:x:1:1:bin:/bin:/sbin/nologin\n     1\troot:x:0:0:root:/root:/bin/bash\n\n[root@localhost ~]# cat -n /etc/passwd | head -6 | sed -n 'G;h;$p'\n     6\tsync:x:5:0:sync:/sbin:/bin/sync\n     5\tlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n     4\tadm:x:3:4:adm:/var/adm:/sbin/nologin\n     3\tdaemon:x:2:2:daemon:/sbin:/sbin/nologin\n     2\tbin:x:1:1:bin:/bin:/sbin/nologin\n     1\troot:x:0:0:root:/root:/bin/bash\n\n[root@localhost ~]# cat -n /etc/passwd | head -6 | sed -n '1!G;h;$p'\n     6\tsync:x:5:0:sync:/sbin:/bin/sync\n     5\tlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n     4\tadm:x:3:4:adm:/var/adm:/sbin/nologin\n     3\tdaemon:x:2:2:daemon:/sbin:/sbin/nologin\n     2\tbin:x:1:1:bin:/bin:/sbin/nologin\n     1\troot:x:0:0:root:/root:/bin/bash\n[root@localhost ~]# cat -n /etc/passwd | head -6 | sed '1!G;h;$!d'\n     6\tsync:x:5:0:sync:/sbin:/bin/sync\n     5\tlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin\n     4\tadm:x:3:4:adm:/var/adm:/sbin/nologin\n     3\tdaemon:x:2:2:daemon:/sbin:/sbin/nologin\n     2\tbin:x:1:1:bin:/bin:/sbin/nologin\n     1\troot:x:0:0:root:/root:/bin/bash\n```","tags":["Linux Practice"],"categories":["Practice"]},{"title":"Linux使用 -- 元字符","url":"%2F2019%2F10%2F21%2Flinux-practice-meta-char%2F","content":"\n## 元字符\n1. `.`：匹配除**换行符**外的任意单个字符\n2. `*`：匹配任意一个跟在它**前面**的字符\n    - 作为**通配符**（`*`、`?`）时是可以**单独使用**的，但作为**元字符**时必须与**前面的字符**一起使用\n3. `[]`：匹配方括号中字符类中的任意一个\n4. `^`：匹配开头\n5. `$`：匹配结尾\n6. `\\`：转义后面的特殊字符\n\n## 扩展元字符\n1. `+`：匹配前面的正则表达式出现**至少一次**\n2. `?`：匹配前面的正则表达式出现**零次或一次**\n3. `|`：匹配它前面或后面的正则表达式\n\n<!-- more -->\n\n## grep\n```\n[root@localhost ~]# grep password /root/anaconda-ks.cfg\n# Root password\n\n[root@localhost ~]# grep pass.... /root/anaconda-ks.cfg\nauth --enableshadow --passalgo=sha512\n# Root password\n\n[root@localhost ~]# grep pass....$ /root/anaconda-ks.cfg\n# Root password\n\n[root@localhost ~]# grep pass.* /root/anaconda-ks.cfg\nauth --enableshadow --passalgo=sha512\n# Root password\n\n[root@localhost ~]# grep pass.*$ /root/anaconda-ks.cfg\nauth --enableshadow --passalgo=sha512\n# Root password\n\n[root@localhost ~]# grep ^# /root/anaconda-ks.cfg\n#version=DEVEL\n# System authorization information\n# Use CDROM installation media\n# Use graphical install\n# Run the Setup Agent on first boot\n# Keyboard layouts\n# System language\n# Network information\n# Root password\n# System services\n# System timezone\n# System bootloader configuration\n# Partition clearing information\n\n[root@localhost ~]# grep '\\.' /root/anaconda-ks.cfg\nlang en_US.UTF-8\nnetwork  --hostname=localhost.localdomain\nrootpw --iscrypted $6$ynKum27gNnySda5k$gDx0Wm4.9kU7rDTmkQTfHmyKAp9z/tRgAp/DOoZ5t2k1tda0p/JK/dLG5gGfkEZJJLGHZ1DPjPOFwKPyUNpQ4.\n```\n\n## find\n```\n[root@localhost ~]# cd /etc/\n[root@localhost etc]# find passwd\npasswd\n[root@localhost etc]# ls passwd*\npasswd  passwd-  passwd.bak\n[root@localhost etc]# find /etc -name passwd\n/etc/passwd\n/etc/pam.d/passwd\n[root@localhost etc]# find /etc -name 'pass*'\n/etc/openldap/certs/password\n/etc/passwd-\n/etc/passwd\n/etc/selinux/targeted/active/modules/100/passenger\n/etc/pam.d/passwd\n/etc/pam.d/password-auth-ac\n/etc/pam.d/password-auth\n/etc/passwd.bak\n[root@localhost etc]# find /etc -regex .*wd\n/etc/passwd\n/etc/security/opasswd\n/etc/pam.d/passwd\n[root@localhost etc]# find /etc -regex .etc.*wd\n/etc/passwd\n/etc/security/opasswd\n/etc/pam.d/passwd\n[root@localhost etc]# find /etc -type f -regex .*wd\n/etc/passwd\n/etc/security/opasswd\n/etc/pam.d/passwd\n```\n```\n[root@localhost ~]# touch /tmp/{1..9}.txt\n[root@localhost ~]# ls /tmp/*.txt\n/tmp/1.txt  /tmp/3.txt  /tmp/5.txt  /tmp/7.txt  /tmp/9.txt\n/tmp/2.txt  /tmp/4.txt  /tmp/6.txt  /tmp/8.txt\n[root@localhost ~]# cd /tmp/\n[root@localhost tmp]# find *.txt\n1.txt\n2.txt\n3.txt\n4.txt\n5.txt\n6.txt\n7.txt\n8.txt\n9.txt\n[root@localhost tmp]# find *.txt -exec rm -v {} \\;\n已删除\"1.txt\"\n已删除\"2.txt\"\n已删除\"3.txt\"\n已删除\"4.txt\"\n已删除\"5.txt\"\n已删除\"6.txt\"\n已删除\"7.txt\"\n已删除\"8.txt\"\n已删除\"9.txt\"\n```\n\n## atime ctime mtime\n\n1. **atime**(access time)：文件**访问**时间\n2. **ctime**(change time)：文件**inode**变化的时间\n3. **mtime**(modify time)：文件**data block**变化的时间\n\n```\n[root@localhost ~]# echo 123 > filea\n[root@localhost ~]# stat filea\n  文件：\"filea\"\n  大小：4         \t块：8          IO 块：4096   普通文件\n设备：fd00h/64768d\tInode：33639131    硬链接：1\n权限：(0644/-rw-r--r--)  Uid：(    0/    root)   Gid：(    0/    root)\n环境：unconfined_u:object_r:admin_home_t:s0\n最近访问：2019-10-21 18:07:29.947289146 +0800\n最近更改：2019-10-21 18:07:29.947289146 +0800\n最近改动：2019-10-21 18:07:29.947289146 +0800\n创建时间：-\n\n[root@localhost ~]# LANG=C stat filea\n  File: ‘filea’\n  Size: 4         \tBlocks: 8          IO Block: 4096   regular file\nDevice: fd00h/64768d\tInode: 33639131    Links: 1\nAccess: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)\nContext: unconfined_u:object_r:admin_home_t:s0\nAccess: 2019-10-21 18:07:29.947289146 +0800\nModify: 2019-10-21 18:07:29.947289146 +0800\nChange: 2019-10-21 18:07:29.947289146 +0800\n Birth: -\n\n[root@localhost ~]# cat filea\n123\n[root@localhost ~]# LANG=C stat filea\n  File: ‘filea’\n  Size: 4         \tBlocks: 8          IO Block: 4096   regular file\nDevice: fd00h/64768d\tInode: 33639131    Links: 1\nAccess: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)\nContext: unconfined_u:object_r:admin_home_t:s0\nAccess: 2019-10-21 18:08:33.795681820 +0800\nModify: 2019-10-21 18:07:29.947289146 +0800\nChange: 2019-10-21 18:07:29.947289146 +0800\n Birth: -\n\n[root@localhost ~]# touch  filea\n[root@localhost ~]# LANG=C stat filea\n  File: ‘filea’\n  Size: 4         \tBlocks: 8          IO Block: 4096   regular file\nDevice: fd00h/64768d\tInode: 33639131    Links: 1\nAccess: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)\nContext: unconfined_u:object_r:admin_home_t:s0\nAccess: 2019-10-21 18:08:46.922164691 +0800\nModify: 2019-10-21 18:08:46.922164691 +0800\nChange: 2019-10-21 18:08:46.922164691 +0800\n Birth: -\n\n[root@localhost ~]# chmod 755 filea\n[root@localhost ~]# LANG=C stat filea\n  File: ‘filea’\n  Size: 4         \tBlocks: 8          IO Block: 4096   regular file\nDevice: fd00h/64768d\tInode: 33639131    Links: 1\nAccess: (0755/-rwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)\nContext: unconfined_u:object_r:admin_home_t:s0\nAccess: 2019-10-21 18:08:46.922164691 +0800\nModify: 2019-10-21 18:08:46.922164691 +0800\nChange: 2019-10-21 18:09:09.367990500 +0800\n Birth: -\n\n[root@localhost ~]# echo 123456 >> filea\n[root@localhost ~]# LANG=C stat filea\n  File: ‘filea’\n  Size: 11        \tBlocks: 8          IO Block: 4096   regular file\nDevice: fd00h/64768d\tInode: 33639131    Links: 1\nAccess: (0755/-rwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)\nContext: unconfined_u:object_r:admin_home_t:s0\nAccess: 2019-10-21 18:08:46.922164691 +0800\nModify: 2019-10-21 18:09:32.947855914 +0800\nChange: 2019-10-21 18:09:32.947855914 +0800\n Birth: -\n```","tags":["Linux Practice"],"categories":["Practice"]},{"title":"Linux使用 -- 脚本控制","url":"%2F2019%2F10%2F20%2Flinux-practice-shell-control%2F","content":"\n## 优先级控制\n1. 使用**nice**和**renice**来调整脚本优先级\n2. 避免出现不可控的**死循环**（导致**CPU占用过高**或**死机**）\n\n<!-- more -->\n\n### Fork炸弹\n```bash\n# 大部分限制对root无效\n[root@localhost ~]# ulimit -a\ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nscheduling priority             (-e) 0\nfile size               (blocks, -f) unlimited\npending signals                 (-i) 3795\nmax locked memory       (kbytes, -l) 64\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 1024\npipe size            (512 bytes, -p) 8\nPOSIX message queues     (bytes, -q) 819200\nreal-time priority              (-r) 0\nstack size              (kbytes, -s) 8192\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 3795\nvirtual memory          (kbytes, -v) unlimited\nfile locks                      (-x) unlimited\n```\n\n#### Session A\n```\n[zhongmingmao@localhost ~]$ func() {\n> func | func&\n> }\n[zhongmingmao@localhost ~]$ func\n-bash: fork: retry: No child processes\n-bash: fork: retry: No child processes\n...\n-bash: fork: Resource temporarily unavailable\n-bash: fork: Resource temporarily unavailable\n```\n\n#### Session B\nload很高\n```\n[root@localhost ~]# id zhongmingmao\nuid=1000(zhongmingmao) gid=1000(zhongmingmao) 组=1000(zhongmingmao)\n[root@localhost ~]# top -u 1000\ntop - 22:26:34 up  5:49,  3 users,  load average: 337.21, 175.05, 74.72\nTasks: 107 total,   1 running, 106 sleeping,   0 stopped,   0 zombie\n%Cpu(s):  0.0 us,  0.3 sy,  0.0 ni, 99.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\nKiB Mem :   995748 total,   840952 free,   105932 used,    48864 buff/cache\nKiB Swap:  2097148 total,  2013948 free,    83200 used.   793856 avail Mem\n\n   PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND\n  5012 zhongmi+  20   0  115580    820    800 S  0.0  0.1   0:00.05 bash\n\n[root@localhost ~]# kill -9 5012\n```\n\n## 捕获信号\n1. **kill**默认会发送**15**号信号给应用程序\n2. **ctrl+c**发送**2**号信号给应用程序\n3. **9号信号不可阻塞！！**\n\n```\n[root@localhost ~]# kill -l\n 1) SIGHUP\t 2) SIGINT\t 3) SIGQUIT\t 4) SIGILL\t 5) SIGTRAP\n 6) SIGABRT\t 7) SIGBUS\t 8) SIGFPE\t 9) SIGKILL\t10) SIGUSR1\n11) SIGSEGV\t12) SIGUSR2\t13) SIGPIPE\t14) SIGALRM\t15) SIGTERM\n16) SIGSTKFLT\t17) SIGCHLD\t18) SIGCONT\t19) SIGSTOP\t20) SIGTSTP\n21) SIGTTIN\t22) SIGTTOU\t23) SIGURG\t24) SIGXCPU\t25) SIGXFSZ\n26) SIGVTALRM\t27) SIGPROF\t28) SIGWINCH\t29) SIGIO\t30) SIGPWR\n31) SIGSYS\t34) SIGRTMIN\t35) SIGRTMIN+1\t36) SIGRTMIN+2\t37) SIGRTMIN+3\n38) SIGRTMIN+4\t39) SIGRTMIN+5\t40) SIGRTMIN+6\t41) SIGRTMIN+7\t42) SIGRTMIN+8\n43) SIGRTMIN+9\t44) SIGRTMIN+10\t45) SIGRTMIN+11\t46) SIGRTMIN+12\t47) SIGRTMIN+13\n48) SIGRTMIN+14\t49) SIGRTMIN+15\t50) SIGRTMAX-14\t51) SIGRTMAX-13\t52) SIGRTMAX-12\n53) SIGRTMAX-11\t54) SIGRTMAX-10\t55) SIGRTMAX-9\t56) SIGRTMAX-8\t57) SIGRTMAX-7\n58) SIGRTMAX-6\t59) SIGRTMAX-5\t60) SIGRTMAX-4\t61) SIGRTMAX-3\t62) SIGRTMAX-2\n63) SIGRTMAX-1\t64) SIGRTMAX\n```\n```\n[root@localhost ~]# cat 15.sh\n#!/bin/bash\n\ntrap \"echo sig 15\" 15\ntrap \"echo sig 2\" 2\n\necho $$\n\nwhile :\ndo\n    :\ndone\n```\n\n### Session A\n```\n[root@localhost ~]# bash 15.sh\n17560\n```\n\n### Session B\n```\n[root@localhost ~]# kill 17560\n```\n\n### Session A\n程序不会结束\n```\n[root@localhost ~]# bash 15.sh\n17560\nsig 15\n\n```\n\n### Session B\n```\n[root@localhost ~]# kill -9 17560\n```\n\n### Session A\n程序结束\n```\n[root@localhost ~]# bash 15.sh\n17560\nsig 15\n已杀死\n```\nctrl+c也无法结束程序\n```\n[root@localhost ~]# bash 15.sh\n17608\n^Csig 2\n```","tags":["Linux Practice"],"categories":["Practice"]},{"title":"Linux使用 -- Shell","url":"%2F2019%2F10%2F19%2Flinux-practice-shell%2F","content":"\n## 转义 + 引用\n1. 特殊字符\n    - 一个字符不仅有**字面意义**，还有**元意**（meta-meaning）\n    - 如`# ; \\ \" '`\n2. 转义\n    - `\\n \\r \\t`\n    - `\\$ \\\" \\\\`\n3. 引用\n    - `\"`：**不完全引用**，解析里面的**变量**\n    - `'`：**完全引用**，不做任何解析\n    - `：运行**命令**\n\n<!-- more -->\n\n```\n[root@localhost ~]# echo \"$a\"\n\n[root@localhost ~]# echo \"\\$a\"\n$a\n[root@localhost ~]# echo \" abc\"x\"edf \"\n abcxedf\n[root@localhost ~]# echo \" abc\\\"x\\\"edf \"\n abc\"x\"edf\n```\n\n```\n[root@localhost ~]# var1=123\n[root@localhost ~]# echo \"$var1\"\n123\n[root@localhost ~]# echo '$var'\n$var\n```\n\n## 运算符\n1. 赋值运算符\n    - **=**赋值运算符，用于**算数赋值**和**字符串赋值**\n    - 使用**unset**取消为变量的赋值\n    - **=**还可以作为**测试运算符**\n2. 算术运算符\n    - `+ - * / ** %`\n    - 使用**expr**进行运算，`expr 4 + 5`，只支持**整数**\n3. 数字常量\n    - `let \"变量名=变量值\"`\n    - 变量值使用**0**开头为八进制\n    - 变量值使用**0x**开头为十六进制\n4. **双圆括号**（let命令的简化）\n    - `(( a=10 ))`\n    - `(( a++ ))`\n    - `echo $(( 10+20 ))`\n\n```\n[root@localhost ~]# expr 4 + 5\n9\n[root@localhost ~]# expr 4 +5\nexpr: 语法错误\n[root@localhost ~]# expr 4 + 5.0\nexpr: 非整数参数\n[root@localhost ~]# num=`expr 4 + 5`\n[root@localhost ~]# echo $num\n9\n```\n```bash\n[root@localhost ~]# (( a=4+5 ))\n[root@localhost ~]# echo $a\n9\n# 默认是字符串赋值\n[root@localhost ~]# b=4+5\n[root@localhost ~]# echo $b\n4+5\n[root@localhost ~]# (( a++ ))\n[root@localhost ~]# echo $a\n10\n[root@localhost ~]# (( a++ ))\n[root@localhost ~]# echo $a\n11\n```\n\n## 特殊字符\n\n### 引号\n1. `'`：完全引用\n2. `\"`：不完全引用\n3. `：执行命令\n\n### 括号\n1. **圆括号**：`()`、`(())`、`$()`\n   - 单独使用圆括号会产生一个子Shell`(xyz=123)`\n   - 数组初始化`IPS=(ip1 ip2 ip3)`\n   - 数字常量：`(())`（**let**命令的简写）\n   - 运行指令：`$()`\n2. **方括号**：`[]`（**test**命令的简写）、`[[]]`\n    - 单独使用方括号是测试（**test**）或**数组元素**功能\n    - 两个方括号表示**测试表达式**\n3. **尖括号**：`< >`\n    - 比较符号\n    - 重定向符号\n4. **花括号**：`{}`\n    - 输出范围：`echo {0..9}`\n    - 文件复制：`cp /etc/passwd{,.bak}`\n\n```bash\n# 产生一个子Shell\n[root@localhost ~]# ( abc=123 )\n[root@localhost ~]# echo $abc\n\n[root@localhost ~]# ipt=(ip1 ip2 ip3)\n[root@localhost ~]# echo ${ipt[@]}\nip1 ip2 ip3\n[root@localhost ~]# echo ${#ipt[@]}\n3\n[root@localhost ~]# echo $(( 10+20 ))\n30\n[root@localhost ~]# l=$(ls)\n[root@localhost ~]# echo $l\n10.sh 11.sh 12.sh 13.sh 15.sh 5.sh 6.sh 7.sh 8.sh a.mp4 anaconda-ks.cfg a.sh a.txt b.mp4 b.txt c.mp4 combine.sh error.txt ls.txt subshell.sh\n```\n```\n[root@localhost ~]# [ 5 -gt 4 ]\n[root@localhost ~]# echo $?\n0\n[root@localhost ~]# [ 5 -gt 6 ]\n[root@localhost ~]# echo $?\n1\n[root@localhost ~]# [[ 5 > 4 ]]\n[root@localhost ~]# echo $?\n0\n[root@localhost ~]# [[ 5 < 6 ]]\n[root@localhost ~]# echo $?\n0\n```\n```\n[root@localhost ~]# echo {0..9}\n0 1 2 3 4 5 6 7 8 9\n[root@localhost ~]# cp -v /etc/passwd{,.bak}\n\"/etc/passwd\" -> \"/etc/passwd.bak\"\n```\n\n### 运算符号和逻辑符号\n1. 算术运算符：`+ - * / %`\n2. 比较运算符：`> < =`\n3. 逻辑运算符：`&& || !`\n\n```\n[root@localhost ~]# (( 5 > 4 ))\n[root@localhost ~]# echo $?\n0\n[root@localhost ~]# (( 5 < 4 ))\n[root@localhost ~]# echo $?\n1\n[root@localhost ~]# (( 5 > 4 && 6 > 5 ))\n[root@localhost ~]# echo $?\n0\n[root@localhost ~]# (( 5 > 4 && 6 < 5 ))\n[root@localhost ~]# echo $?\n1\n[root@localhost ~]# (( 5 > 4 || 6 < 5 ))\n[root@localhost ~]# echo $?\n0\n[root@localhost ~]# (( ! 5 > 4 ))\n[root@localhost ~]# echo $?\n1\n```\n\n### 转义符号\n1. 普通字符 -> 具有不同的功能：`\\n`\n2. 特殊字符 -> 当做普通字符：`\\'`\n\n### 其它符号\n1. `#`：注释符\n2. `;`：命令分隔符\n    - **case**语句的分隔符要转义**`;;`**\n3. `:`：**空命令**\n4. `.`和`source`命令相同\n5. `~`：家目录\n6. `-`：上一次访问的目录\n7. `,`：分隔目录\n8. `*`：通配符\n9. `?`：条件测试或通配符\n10. `$`：取值符号\n11. `|`：管道符\n12. `&`：后台运行\n13. `_`：**空格**\n\n```\n[root@localhost ~]# ifdown ens33 ; ifup ens33\n成功断开设备 \"ens33\"。\n连接已成功激活（D-Bus 活动路径：/org/freedesktop/NetworkManager/ActiveConnection/3）\n```\n```\n[root@localhost ~]# grep -A10 case /etc/bashrc | head -n 10\n    case $TERM in\n    xterm*|vte*)\n      if [ -e /etc/sysconfig/bash-prompt-xterm ]; then\n          PROMPT_COMMAND=/etc/sysconfig/bash-prompt-xterm\n      elif [ \"${VTE_VERSION:-0}\" -ge 3405 ]; then\n          PROMPT_COMMAND=\"__vte_prompt_command\"\n      else\n          PROMPT_COMMAND='printf \"\\033]0;%s@%s:%s\\007\" \"${USER}\" \"${HOSTNAME%%.*}\" \"${PWD/#$HOME/~}\"'\n      fi\n      ;;\n```\n```bash\n# 永远为true，常用于死循环的占位符\n[root@localhost ~]# :\n[root@localhost ~]# echo $?\n0\n```\n```\n[root@localhost ~]# cd /tmp/\n[root@localhost tmp]# cd -\n/root\n[root@localhost ~]# cd -\n/tmp\n```\n```\n[root@localhost tmp]# echo {0..9}\n0 1 2 3 4 5 6 7 8 9\n[root@localhost tmp]# echo { 0..9 }\n{ 0..9 }\n```\n\n## 测试\n\n### 退出\n1. exit 10返回10给Shell，返回值**非0**表示**不正常退出**\n2. `$?`：判断当前Shell**前一个进程**是否正常退出\n\n```\n[root@localhost ~]# cat 8.sh\n#!/bin/bash\n\npwd\nexit 127\n[root@localhost ~]# bash 8.sh\n/root\n[root@localhost ~]# echo $?\n127\n```\n\n### test\n1. test命令用于**检查文件**或者**比较值**\n2. test可以做以下测试\n    - **文件**测试\n    - **整数比较**测试\n    - **字符串**测试\n3. test命令可以简化为`[]`\n4. `[]`的**扩展写法**是`[[]]`，支持`&& || < >`\n\n```\n$ man test\n...\n-z STRING\n        the length of STRING is zero\nSTRING1 = STRING2\n        the strings are equal\nSTRING1 != STRING2\n        the strings are not equal\n\n...\n\nINTEGER1 -eq INTEGER2\n        INTEGER1 is equal to INTEGER2\nINTEGER1 -ge INTEGER2\n        INTEGER1 is greater than or equal to INTEGER2\nINTEGER1 -gt INTEGER2\n        INTEGER1 is greater than INTEGER2\nINTEGER1 -le INTEGER2\n        INTEGER1 is less than or equal to INTEGER2\nINTEGER1 -lt INTEGER2\n        INTEGER1 is less than INTEGER2\nINTEGER1 -ne INTEGER2\n        INTEGER1 is not equal to INTEGER2\n\n...\n\n-d FILE\n        FILE exists and is a directory\n-e FILE\n        FILE exists\n-f FILE\n        FILE exists and is a regular file\n-x FILE\n        FILE exists and execute (or search) permission is granted\n...\n```\n```\n[root@localhost ~]# test -f /etc/passwd\n[root@localhost ~]# echo $?\n0\n[root@localhost ~]# test -f /etc/passwd1\n[root@localhost ~]# echo $?\n1\n[root@localhost ~]# [ -d /etc ]\n[root@localhost ~]# echo $?\n0\n[root@localhost ~]# [ -e /etc ]\n[root@localhost ~]# echo $?\n0\n[root@localhost ~]# [ -e /etc/passwd ]\n[root@localhost ~]# echo $?\n0\n[root@localhost ~]# [ 5 -gt 4 ]\n[root@localhost ~]# echo $?\n0\n[root@localhost ~]# [[ 5 > 4 ]]\n[root@localhost ~]# echo $?\n0\n[root@localhost ~]# [ \"abc\" = \"abc\" ]\n[root@localhost ~]# echo $?\n0\n[root@localhost ~]# [ \"abc\" = \"ABC\" ]\n[root@localhost ~]# echo $?\n1\n```\n\n## 判断 + 分支\n\n### if-then\n```\n[root@localhost ~]# [ $UID = 0 ]\n[root@localhost ~]# echo $?\n0\n[root@localhost ~]# [ $USER = root ]\n[root@localhost ~]# echo $?\n0\n[root@localhost ~]# if [ $UID = 0 ]; then\n> echo 'root user'\n> fi\nroot user\n[root@localhost ~]# su - zhongmingmao\n[zhongmingmao@localhost ~]$ if [ $UID = 0 ]; then echo 'root user'; fi\n[zhongmingmao@localhost ~]$ if pwd\n> then\n>     echo 'pwd running'\n> fi\n/home/zhongmingmao\npwd running\n[zhongmingmao@localhost ~]$ if abc; then     echo 'abc running'; fi\n-bash: abc: command not found\n[zhongmingmao@localhost ~]$ abc\n-bash: abc: command not found\n[zhongmingmao@localhost ~]$ echo $?\n127\n```\n\n### if-then-else\n```\n[root@localhost ~]# cat 9.sh\n#!/bin/bash\n\nif [ $UID = 0 ]; then\n    echo 'root user'\nelse\n    echo 'other user'\nfi\n[root@localhost ~]# bash 9.sh\nroot user\n[root@localhost ~]# cp 9.sh /tmp/\n[root@localhost ~]# su - zhongmingmao\n[zhongmingmao@localhost ~]$ bash /tmp/9.sh\nother user\n```\n\n### if-elif-else\n```\n[root@localhost ~]# cat 10.sh\n#!/bin/bash\n\nif [ $USER = root ]; then\n    echo 'root user'\nelif [ $USER = zhongmingmao ]; then\n    echo 'zhongmingmao user'\nelse\n    echo 'other user'\nfi\n[root@localhost ~]# bash 10.sh\nroot user\n[root@localhost ~]# cp 10.sh /tmp/\n[root@localhost ~]# su - zhongmingmao\n[zhongmingmao@localhost ~]$ bash /tmp/10.sh\nzhongmingmao user\n[zhongmingmao@localhost ~]$ su - zhongmingwu\nPassword:\n[zhongmingwu@localhost ~]$ bash /tmp/10.sh\nother user\n```\n\n### 嵌套if\n```\n[root@localhost ~]# cat 11.sh\n#!/bin/bash\n\nif [ $UID = 0 ]; then\n    echo 'please run'\n    if [ -e /tmp/10.sh ]; then\n        bash /tmp/10.sh\n    fi\nelse\n    echo 'please switch to root'\nfi\n[root@localhost ~]# bash 11.sh\nplease run\nroot user\n```\n\n### case\n```\n[root@localhost ~]# cat 12.sh\n#!/bin/bash\n\ncase \"$1\" in\n    \"start\")\n        echo $0 start...\n        ;;\n    \"stop\")\n        echo $0 stop...\n        ;;\n    \"restart\"|\"reload\")\n        echo $0 restart...\n        ;;\n    *)\n        echo \"Usage: $0 {start|stop|restart|reload}\"\n        ;;\nesac\n[root@localhost ~]# bash 12.sh start\n12.sh start...\n[root@localhost ~]# bash 12.sh stop\n12.sh stop...\n[root@localhost ~]# bash 12.sh restart\n12.sh restart...\n[root@localhost ~]# bash 12.sh reload\n12.sh restart...\n[root@localhost ~]# bash 12.sh aaa\nUsage: 12.sh {start|stop|restart|reload}\n[root@localhost ~]# bash 12.sh\nUsage: 12.sh {start|stop|restart|reload}\n```\n\n## 循环\n\n### for\n1. 遍历**命令的执行结果**\n    - 使用**反引号**或`$()`执行命令，命令的结果当做列表进行处理\n2. 遍历**变量**和**文件内容**\n    - 列表中包含多个变量，变量用**空格**分隔\n    - 对文本处理，要用文本查看命令取出文本内容\n      - 默认**逐行处理**，如果文本出现**空格**会当做**多行**处理\n3. C语言风格（常用于**awk**）\n    - Shell**不擅长做数值计算**\n\n```\n[root@localhost ~]# echo {1..9}\n1 2 3 4 5 6 7 8 9\n[root@localhost ~]# for i in {1..9}\n> do\n>     echo $i\n> done\n1\n2\n3\n4\n5\n6\n7\n8\n9\n```\n```\n[root@localhost ~]# touch a.mp3 b.mp3 c.mp3\n[root@localhost ~]# for filename in `ls *.mp3`\n> do\n>     mv $filename $(basename $filename .mp3).mp4\n> done\n[root@localhost ~]# ls *.mp4\na.mp4  b.mp4  c.mp4\n```\n```\n[root@localhost ~]# for (( i=1; i<=10; i++ ))\n> do\n>     echo $i\n> done\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n```\n\n### while + until\n```\n[root@localhost ~]# a=1\n[root@localhost ~]# while [ $a -lt 10 ]\n> do\n>     echo $a\n>     (( a++ ))\n> done\n1\n2\n3\n4\n5\n6\n7\n8\n9\n```\n```bash\n# 死循环\n[root@localhost ~]# while :\n> do\n>     echo `date`\n> done\n2019年 10月 19日 星期六 20:50:50 CST\n2019年 10月 19日 星期六 20:50:50 CST\n```\n```\n[root@localhost ~]# until :; do     echo `date`; done\n[root@localhost ~]#\n```\n\n### 位置参数\n1. `$0`：脚本名称\n2. `$1...${10}`：具体的位置参数\n3. **`$*`**、**`$@`**：所有的位置参数\n4. **`$#`**：位置参数的数量\n\n```\n[root@localhost ~]# cat 13.sh\n#!/bin/bash\n\nfor pos in $*\ndo\n    if [ \"$pos\" = \"help\" ]; then\n        echo $pos $pos\n    fi\ndone\n[root@localhost ~]# bash 13.sh\n[root@localhost ~]# bash 13.sh a\n[root@localhost ~]# bash 13.sh a help\nhelp help\n[root@localhost ~]# bash 13.sh help b\nhelp help\n```\n```\n[root@localhost ~]# cat 13.sh\n#!/bin/bash\n\nwhile [ $# -gt 0 ]\ndo\n    if [ \"$1\" == \"help\" ]; then\n        echo $1 $1\n    fi\n    shift # 参数左移\ndone\n[root@localhost ~]# bash 13.sh a\n[root@localhost ~]# bash 13.sh a help\nhelp help\n[root@localhost ~]# bash 13.sh help b\nhelp help\n```\n\n## 函数\n\n### 自定义函数\n```\n[root@localhost ~]# function cdls() {\n> cd /var\n> ls\n> }\n[root@localhost ~]# cdls\n14.sh  cache  db     games   kerberos  local  log   nis  preserve  spool  yp\nadm    crash  empty  gopher  lib       lock   mail  opt  run       tmp\n[root@localhost var]# cdls2() {\n> cd /tmp/\n> ls\n> }\n[root@localhost var]# cdls2\n10.sh                                                                    vmware-root_700-2730627996\n9.sh                                                                     vmware-root_701-3979708482\na.txt                                                                    vmware-root_703-3988031936\ndate.txt                                                                 vmware-root_704-2990744159\nhello.txt                                                                vmware-root_705-4256479617\nsystemd-private-111840b59ff9417c8b178c56e9ab231b-chronyd.service-daldqM  vmware-root_708-2998936538\nvmware-root_694-2688619536                                               vmware-root_709-4248287236\nvmware-root_696-2722173465                                               vmware-root_714-2965382611\nvmware-root_698-2730496923                                               vmware-root_718-2957190230\nvmware-root_699-3979839557                                               yum_save_tx.2019-12-18.17-51.rs2rU4.yumtx\n[root@localhost tmp]# unset cdls cdls2\n[root@localhost tmp]# cdls\n-bash: cdls: 未找到命令\n[root@localhost tmp]# cdls2\n-bash: cdls2: 未找到命令\n```\n```\n[root@localhost tmp]# cdls() {\n> cd $1\n> ls\n> }\n[root@localhost tmp]# cdls /var/\n14.sh  cache  db     games   kerberos  local  log   nis  preserve  spool  yp\nadm    crash  empty  gopher  lib       lock   mail  opt  run       tmp\n```\n**local变量**是在**函数作用范围内**的变量，为了避免函数内外**同名变量**的影响\n```\n[root@localhost ~]# cat 14.sh\n#!/bin/bash\n\ncheckpid() {\n    local i # i很常见，设置为local变量\n    for i in $*\n    do\n        [ -d \"/proc/$i\" ] && echo $i\n    done\n}\n[root@localhost ~]# source 14.sh\n[root@localhost ~]# checkpid 1\n1\n[root@localhost ~]# checkpid 1 2\n1\n2\n[root@localhost ~]# checkpid 1 2 65534\n1\n2\n```\n\n### 系统脚本\n`/etc/init.d/functions`\n```\n[root@localhost ~]# grep -A9 'echo_success()' /etc/init.d/functions\necho_success() {\n    [ \"$BOOTUP\" = \"color\" ] && $MOVE_TO_COL\n    echo -n \"[\"\n    [ \"$BOOTUP\" = \"color\" ] && $SETCOLOR_SUCCESS\n    echo -n $\"  OK  \"\n    [ \"$BOOTUP\" = \"color\" ] && $SETCOLOR_NORMAL\n    echo -n \"]\"\n    echo -ne \"\\r\"\n    return 0\n}\n[root@localhost ~]# source /etc/init.d/functions\n[root@localhost ~]# echo_success\n[root@localhost ~]#                                        [  确定  ]\n```\n`/etc/profile`\n```\n[root@localhost ~]# grep -A10 'pathmunge ()' /etc/profile\npathmunge () {\n    case \":${PATH}:\" in\n        *:\"$1\":*)\n            ;;\n        *)\n            if [ \"$2\" = \"after\" ] ; then\n                PATH=$PATH:$1\n            else\n                PATH=$1:$PATH\n            fi\n    esac\n```\n`~/.bash_profile` -> `~/.bashrc`\n```\n[root@localhost ~]# cat ~/.bash_profile\necho ~/.bash_profile\n# .bash_profile\n\n# Get the aliases and functions\nif [ -f ~/.bashrc ]; then\n    . ~/.bashrc\nfi\n\n# User specific environment and startup programs\n\nPATH=$PATH:$HOME/bin\n\nexport PATH\n```\n`~/.bashrc` -> `/etc/bashrc`\n```\n[root@localhost ~]# cat ~/.bashrc\necho ~/.bashrc\n# .bashrc\n\n# User specific aliases and functions\n\nalias rm='rm -i'\nalias cp='cp -i' \nalias mv='mv -i'\n\n# Source global definitions\nif [ -f /etc/bashrc ]; then\n    . /etc/bashrc\nfi\n```","tags":["Linux Practice"],"categories":["Practice"]},{"title":"Linux使用 -- 变量","url":"%2F2019%2F10%2F18%2Flinux-practice-var%2F","content":"\n## 命名规则\n1. **字母**、**数字**、**下划线**\n2. 不以字母开头\n\n## 赋值\n1. 基本概念\n    - Shell变量是**弱类型**的变量\n2. 方式\n    - 变量名=变量值\n      - `a=123`，等号左右不能出现**空格**\n    - 使用let为变量赋值\n      - `let a=10+20`，Shell是**解释性**语言，尽量**不要进行运算**\n    - 将命令赋值给变量\n      - `l=ls`\n    - 将命令结果赋值给变量，使用`$()`或者\\`\\`\n      - `letc=$(ls -l /etc)`\n    - 变量值有空格等特殊字符可以包含在`\"\"`或者`''`中\n      - `a='hello world'`\n\n<!-- more -->\n\n```\n[root@localhost ~]# a=123\n[root@localhost ~]# a =123\n-bash: a: 未找到命令\n[root@localhost ~]# a = 123\n-bash: a: 未找到命令\n[root@localhost ~]# a= 123\n-bash: 123: 未找到命令\n```\n```\n[root@localhost ~]# l=ls\n[root@localhost ~]# $l\nanaconda-ks.cfg  a.sh  a.txt  b.txt  combine.sh  error.txt  ls.txt\n```\n```\n[root@localhost ~]# cmd1=`ls /root`\n[root@localhost ~]# echo $cmd1\nanaconda-ks.cfg a.sh a.txt b.txt combine.sh error.txt ls.txt\n\n[root@localhost ~]# cmd2=$(ls /root)\n[root@localhost ~]# echo $cmd2\nanaconda-ks.cfg a.sh a.txt b.txt combine.sh error.txt ls.txt\n```\n```\n[root@localhost ~]# string1=hello bash\n[root@localhost ~]# echo $string1\nhello\n[root@localhost ~]# string1='hello bash'\n[root@localhost ~]# echo $string1\nhello bash\n[root@localhost ~]# string2=\"I'm bash\"\n[root@localhost ~]# echo $string2\nI'm bash\n[root@localhost ~]# string3='Hello \"zhongmingmao\"'\n[root@localhost ~]# echo $string3\nHello \"zhongmingmao\"\n```\n\n## 引用\n1. `${变量名}`是对变量的引用 -- 最正式的用法\n2. `echo ${变量名}`查看变量的值\n3. `${变量名}`在部分情况下可以省略为`$变量名`\n\n```\n[root@localhost ~]# string1='hello bash'\n[root@localhost ~]# echo $string1\nhello bash\n[root@localhost ~]# echo ${string1}\nhello bash\n[root@localhost ~]# echo $string123\n\n[root@localhost ~]# echo ${string1}23\nhello bash23\n```\n\n## 作用范围\n1. 默认作用范围\n    - **当前Shell**\n2. 变量导出\n    - **export**\n3. 变量的删除\n    - **unset**\n\n```\n[root@localhost ~]# a=1\n[root@localhost ~]# bash # 进入子进程\n[root@localhost ~]# echo $a\n\n[root@localhost ~]# a=2\n[root@localhost ~]# exit\n[root@localhost ~]# echo $a\n1\n```\n```\n[root@localhost ~]# b='hello subshell'\n[root@localhost ~]# vim subshell.sh\n[root@localhost ~]# cat subshell.sh\n#!/bin/bash\n\n# demo subshell\n\necho $b\n[root@localhost ~]# chmod u+x subshell.sh\n[root@localhost ~]# bash subshell.sh\n\n[root@localhost ~]# ./subshell.sh\n\n[root@localhost ~]# source ./subshell.sh\nhello subshell\n[root@localhost ~]# . ./subshell.sh\nhello subshell\n```\n```\n[root@localhost ~]# export b='hello subshell'\n[root@localhost ~]# ./subshell.sh\nhello subshell\n[root@localhost ~]# bash ./subshell.sh\nhello subshell\n```\n```\n[root@localhost ~]# unset b\n[root@localhost ~]# echo $b\n\n[root@localhost ~]#\n```\n\n## 系统环境变量\n1. 环境变量：每个Shell打开都可以获得到的变量\n    - 命令：`env`、`set`（更详细）\n    - `$PATH`\n    - `PS1`\n    - `$?`（上一条命令是否正常执行）、`$$`（PID）、`$0`（执行的文件名）\n2. 位置变量\n    - `$1`、`$2`...`$n`\n\n### $PATH\n$PATH被**export**过，对**子Shell**生效，但对平行Shell不生效\n\n#### Session A\n```\n[root@localhost ~]# cat 5.sh\n#!/bin/bash\n\necho 'hello bash'\ndu -sh\n[root@localhost ~]# chmod u+x 5.sh\n[root@localhost ~]# echo $PATH\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin\n[root@localhost ~]# ./5.sh\nhello bash\n80K\t.\n[root@localhost ~]# 5.sh\nbash: 5.sh: 未找到命令\n[root@localhost ~]# PATH=$PATH:/root\n[root@localhost ~]# echo $PATH\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/root\n[root@localhost ~]# 5.sh\nhello bash\n80K\t.\n[root@localhost ~]# which 5.sh\n/root/5.sh\n[root@localhost ~]# bash # 进入子进程\n[root@localhost ~]# echo $PATH # PATH依然有效\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/root\n[root@localhost ~]# 5.sh\nhello bash\n80K\t.\n```\n\n#### Session B\n```\n[root@localhost ~]# echo $PATH\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin\n```\n\n### $PS1\n```\n[root@localhost ~]# echo $PS1\n[\\u@\\h \\W]\\$\n```\n\n### $?、$$、$0\n```\n[root@localhost ~]# ifconfig > /dev/null\n[root@localhost ~]# echo $?\n0\n[root@localhost ~]# ifconfig nonn1 > /dev/null\nnonn1: error fetching interface information: Device not found\n[root@localhost ~]# echo $?\n1\n```\n```\n[root@localhost ~]# echo $$\n3143\n[root@localhost ~]# bash # 进入子进程\n[root@localhost ~]# echo $$\n3227\n[root@localhost ~]# ps -f\nUID         PID   PPID  C STIME TTY          TIME CMD\nroot       3143   3139  0 19:05 pts/1    00:00:00 -bash\nroot       3227   3143  0 19:24 pts/1    00:00:00 bash\nroot       3238   3227  0 19:24 pts/1    00:00:00 ps -f\n```\n```\n[root@localhost ~]# echo $0\nbash\n[root@localhost ~]# cat 6.sh\n#!/bin/bash\n\necho $$\necho $0\n[root@localhost ~]# chmod u+x 6.sh\n[root@localhost ~]# bash 6.sh\n3243\n6.sh\n[root@localhost ~]# . 6.sh\n3227\nbash\n```\n\n### $1、$n\n```\n[root@localhost ~]# cat 7.sh\n#!/bin/bash\n\n# $1 $2 ${10}\necho $1\necho $2\necho ${2-X} # 参数替换\n[root@localhost ~]# chmod u+x 7.sh\n[root@localhost ~]# ./7.sh -a -b\n-a\n-b\n-b\n[root@localhost ~]# ./7.sh -a\n-a\n\nX\n```\n\n## 环境变量配置文件\n1. /etc/profile\n2. /etc/bashrc -- **nologin** shell\n3. /etc/profile.d/\n4. ~/.bash_profile\n5. ~/.bash_rc -- **nologin** shell\n\n```\n[root@localhost ~]# head -n 1 /etc/profile\necho /etc/profile\n[root@localhost ~]# head -n 1 /etc/bashrc\necho /etc/bashrc\n[root@localhost ~]# head -n 1 ~/.bashrc\necho ~/.bashrc\n[root@localhost ~]# head -n 1 ~/.bash_profile\necho ~/.bash_profile\n\n[root@localhost ~]# su - root\n上一次登录：一 10月 18 19:05:34 CST 2019从 192.168.206.1pts/1 上\n/etc/profile\n/root/.bash_profile\n/root/.bashrc\n/etc/bashrc\n\n[root@localhost ~]# su root\n/root/.bashrc\n/etc/bashrc\n\n[root@localhost ~]# bash\n/root/.bashrc\n/etc/bashrc\n\n[root@localhost ~]# source /etc/profile\n/etc/profile\n[root@localhost ~]# source /etc/bashrc\n/etc/bashrc\n```\n\n## 数组\n```\n[root@localhost ~]# IPTS=( 10.0.0.1 10.0.0.2 10.0.0.3 )\n[root@localhost ~]# echo $IPTS # 只会显示第一个元素\n10.0.0.1\n[root@localhost ~]# echo ${IPTS[@]}\n10.0.0.1 10.0.0.2 10.0.0.3\n[root@localhost ~]# echo ${#IPTS[@]}\n3\n[root@localhost ~]# echo ${IPTS[1]}\n10.0.0.2\n```\n","tags":["Linux Practice"],"categories":["Practice"]},{"title":"Linux使用 -- 管道 + 重定向","url":"%2F2019%2F10%2F17%2Flinux-practice-pipe-redirect%2F","content":"\n## 管道\n1. **管道**是**进程通信**的方式\n    - **信号**也是进程通信的方式，例如`kill -9 pid`是让进程处于某种**运行状态**\n2. **匿名管道**（管道符`|`）是Shell编程经常用到的**通信**工具\n3. 管道符是`|`，将前一个命令执行的结果传递给后面的命令\n    - `;`只是隔开多条命令，顺序执行，**命令之间没有任何关系**\n\n<!-- more -->\n\n### Session A\n```\n$ cat | tail -f | ps -f\nUID         PID   PPID  C STIME TTY          TIME CMD\nroot       2348   2344  0 16:12 pts/1    00:00:00 -bash\nroot       2971   2348  0 19:13 pts/1    00:00:00 cat\nroot       2972   2348  0 19:13 pts/1    00:00:00 tail -f\nroot       2973   2348  0 19:13 pts/1    00:00:00 ps -f\n\n```\n1. cat的本质：将文本内容作为输入，与终端建立连接\n2. 管道符`|`给两边的**外部命令**分别创建了对应的**子进程**，对应pid为2971、2972、2973（已结束）\n    - 如果子进程是Shell脚本，称为**子Shell**（如果使用了cd、pwd等内建命令，作用范围仅限于子Shell之内）\n\n### Session B\n2971的1和2972的2建立了连接，即**前一个命令的标准输出**与**后一个命令的标准输入**建立了连接\n```\n[root@localhost ~]# ls -l /proc/2971/fd\n总用量 0\nlrwx------. 1 root root 64 10月 17 19:18 0 -> /dev/pts/1\nl-wx------. 1 root root 64 10月 17 19:18 1 -> pipe:[53011]\nlrwx------. 1 root root 64 10月 17 19:13 2 -> /dev/pts/1\n\n[root@localhost ~]# ls -l /proc/2972/fd\n总用量 0\nlr-x------. 1 root root 64 10月 17 19:18 0 -> pipe:[53011]\nl-wx------. 1 root root 64 10月 17 19:18 1 -> pipe:[53013]\nlrwx------. 1 root root 64 10月 17 19:13 2 -> /dev/pts/1\n\n[root@localhost ~]# ls -l /proc/2973/fd\nls: 无法访问/proc/2973/fd: 没有那个文件或目录\n```\n\n## 重定向\n1. 重定向的本质：将**进程的输入和输出**与**文件**建立连接\n2. 进程运行时会默认打开**标准输入**（fd=**0**），**标准输出**（fd=**1**）、**错误输出**（fd=**2**）\n3. 输入重定向：`<`\n    - `read var < /path/to/file`\n4. 输出重定向：`>`（覆盖）、`>>`（追加）、`2>`（**错误**重定向）、`&>`（**全部**重定向）\n    - `echo 123 > /path/to/file`\n5. 输入重定向 + 输出重定向 -- 常用于在Shell中**生成配置文件**\n    - `cat > /path/to/file <<EOF`\n\n### 输入重定向\n```\n[root@localhost ~]# wc -l\n123\n456 # 输入CTRL+D\n2\n\n[root@localhost ~]# wc -l < /etc/passwd\n20\n```\n```\n[root@localhost ~]# read var\n123\n[root@localhost ~]# echo $var\n123\n\n[root@localhost ~]# echo 123 > a.txt\n[root@localhost ~]# read var2 < a.txt\n[root@localhost ~]# echo $var2\n123\n```\n\n### 输出重定向\n```\n[root@localhost ~]# echo $var2 > b.txt\n[root@localhost ~]# cat b.txt\n123\n\n[root@localhost ~]# echo $var2 >> b.txt\n[root@localhost ~]# cat b.txt\n123\n123\n```\n```\n[root@localhost ~]# nocmd\n-bash: nocmd: 未找到命令\n[root@localhost ~]# nocmd 2> error.txt\n[root@localhost ~]# cat error.txt\n-bash: nocmd: 未找到命令\n\n[root@localhost ~]# ls &> ls.txt\n[root@localhost ~]# cat ls.txt\nanaconda-ks.cfg\na.txt\nb.txt\nerror.txt\nls.txt\n```\n\n### 组合使用（生成配置文件）\n```\n[root@localhost ~]# cat combine.sh\n#!/bin/bash\n\ncat > /root/a.sh <<EOF\necho \"hello bash\"\nEOF\n```\n```\n[root@localhost ~]# bash combine.sh\n[root@localhost ~]# cat a.sh\necho \"hello bash\"\n```\n","tags":["Linux Practice"],"categories":["Practice"]},{"title":"Linux使用 -- 执行脚本方式","url":"%2F2019%2F10%2F16%2Flinux-practice-script-execution%2F","content":"\n## 2.sh\n```bash\n#!/bin/bash\n\n# demo 2.sh\ncd /tmp\npwd\n```\n\n## 执行方式\n\n### 子进程\n#### bash ./filename.sh\n在当前终端下面产生一个**bash子进程**，bash子进程再去解释`filename.sh`（不需要`x`权限）\n```\n[root@localhost ~]# ll 2.sh\n-rw-r--r--. 1 root root 37 10月 16 16:30 2.sh\n\n[root@localhost ~]# bash 2.sh\n/tmp\n\n[root@localhost ~]# pwd\n/root\n```\n\n<!-- more -->\n\n#### ./filename.sh\n同样产生一个**子进程**，但使用的是`Sha-Bang`（即`#!`）来解释`filename.sh`\n```\n[root@localhost ~]# ./2.sh\n-bash: ./2.sh: 权限不够\n\n[root@localhost ~]# chmod u+x 2.sh\n\n[root@localhost ~]# ./2.sh\n/tmp\n\n[root@localhost ~]# pwd\n/root\n```\n\n### 当前进程\n\n#### source ./filename.sh\n在**当前进程**解释`filename.sh`\n```\n[root@localhost ~]# source ./2.sh\n/tmp\n\n[root@localhost tmp]# pwd\n/tmp\n```\n\n#### . ./filename.sh\n同`source`方式\n```\n[root@localhost ~]# . 2.sh\n/tmp\n\n[root@localhost tmp]# pwd\n/tmp\n```\n\n## 内建命令\n1. 内建命令**不需要创建子进程**（如cd、pwd等）\n2. 内建命令**对当前Shell生效**","tags":["Linux Practice"],"categories":["Practice"]},{"title":"Linux使用 -- sar + iftop","url":"%2F2019%2F10%2F15%2Flinux-practice-sar-iftop%2F","content":"\n## sar\n```\nyum install sysstat\n```\n\n### CPU\n```\n$ sar -u ALL 1 5\nLinux 2.6.32-696.el6.x86_64 (xxx) \t2019年10月15日 \t_x86_64_\t(40 CPU)\n\n17时25分50秒     CPU      %usr     %nice      %sys   %iowait    %steal      %irq     %soft    %guest     %idle\n17时25分51秒     all     14.75      0.00      1.13      0.00      0.00      0.00      0.25      0.00     83.87\n17时25分52秒     all     11.17      0.00      1.74      0.00      0.00      0.00      0.25      0.00     86.84\n17时25分53秒     all     12.31      0.00      1.61      0.00      0.00      0.00      0.25      0.00     85.83\n17时25分54秒     all     12.85      0.00      1.41      0.00      0.00      0.00      0.30      0.00     85.44\n17时25分55秒     all     12.18      0.00      1.31      0.00      0.00      0.00      0.25      0.00     86.26\n平均时间:     all     12.65      0.00      1.44      0.00      0.00      0.00      0.26      0.00     85.65\n```\n\n<!-- more -->\n\n1. %user\n    - Percentage of CPU utilization that occurred while executing at the user  level  (application).\n    - Note that this field includes time spent running virtual processors.\n2. %usr\n    - Percentage  of  CPU utilization that occurred while executing at the user level (application).\n    - Note that this field does **NOT include** time spent **running virtual processors**.\n3. %nice\n    - Percentage of CPU utilization that occurred while executing at the user level with nice priority.\n4. %system\n    - Percentage of CPU utilization that occurred while executing at the system level (kernel).\n    - Note that this field includes time spent servicing hardware and software interrupts.\n5. %sys\n    - Percentage of CPU utilization that occurred while executing at the system level (kernel).\n    - Note that this field does **NOT include** time spent **servicing hardware or software interrupts**.\n6. %iowait\n    - Percentage  of  time that the CPU or CPUs were _**idle during which the system had an outstanding disk I/O request**_.\n7. %steal\n    - Percentage of time spent in involuntary wait by the virtual CPU or CPUs while  the  hypervisor was servicing another virtual processor.\n8. %irq\n    - Percentage of time spent by the CPU or CPUs to service **hardware interrupts**.\n9. %soft\n    - Percentage of time spent by the CPU or CPUs to service **software interrupts**.\n10. %guest\n    - Percentage of time spent by the CPU or CPUs to **run a virtual processor**.\n11. %gnice\n    - Percentage of time spent by the CPU or CPUs to **run a niced guest**.\n12. %idle\n    - Percentage  of  time that the CPU or CPUs were _**idle and the system did not have an outstanding disk I/O request**_.\n\n<img src=\"https://linux-practice-1253868755.cos.ap-guangzhou.myqcloud.com/linux-practice-sar-cpu.jpg\"/>\n\n### 内存\n```\n$ sar -r 1 5\nLinux 2.6.32-696.el6.x86_64 (xxx) \t2019年10月15日 \t_x86_64_\t(40 CPU)\n\n18时09分14秒 kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit\n18时09分15秒    404496  65578096     99.39    100240  10128668 100398588    121.89\n18时09分16秒    439788  65542804     99.33    100260  10136372 100398984    121.89\n18时09分17秒    435164  65547428     99.34    100360  10140920 100399712    121.89\n18时09分18秒    418348  65564244     99.37    100404  10147072 100400992    121.90\n18时09分19秒    414344  65568248     99.37    100464  10150912 100401388    121.90\n平均时间:    422428  65560164     99.36    100346  10140789 100399933    121.89\n\n$ free\n             total       used       free     shared    buffers     cached\nMem:      65982592   65590372     392220    3777404     100700   10166360\n-/+ buffers/cache:   55323312   10659280\nSwap:     16383996     291572   16092424\n```\n1. kbmemfree\n    - Amount of free memory available in kilobytes.\n2. kbmemused\n    - Amount of used memory in kilobytes (calculated as **total installed memory - kbmemfree - kbbuffers - kbcached - kbslab**).\n3. %memused\n    - Percentage of used memory.\n4. kbbuffers\n    - Amount of memory used as **buffers** by the **kernel** in kilobytes.\n5. kbcached\n    - Amount of memory used to **cache data** by the **kernel** in kilobytes.\n6. kbcommit\n    - Amount of memory in kilobytes needed for current **workload**.\n    - This is an estimate of how much RAM/swap is needed to guarantee that there never is out of memory.\n7. **%commit**\n    - Percentage of memory needed for current workload in relation to the total amount of memory (RAM+swap).\n    - This number may be greater than 100% because the kernel usually overcommits memory.\n8. kbslab\n    - Amount of memory in kilobytes used by the **kernel** to **cache** data structures for its own use.\n\n### IO\n```\n$ sar -b 1 5\nLinux 2.6.32-696.el6.x86_64 (xxx) \t2019年10月15日 \t_x86_64_\t(40 CPU)\n\n18时21分42秒       tps      rtps      wtps   bread/s   bwrtn/s\n18时21分43秒    107.07      1.01    106.06      8.08  26965.66\n18时21分44秒    319.19      2.02    317.17     16.16 136614.14\n18时21分45秒     34.00      0.00     34.00      0.00   2280.00\n18时21分46秒     36.00      0.00     36.00      0.00   2736.00\n18时21分47秒     36.63      0.99     35.64     15.84   2352.48\n平均时间:    106.01      0.80    105.21      8.02  33935.07\n```\n1. tps\n    - Total  number  of transfers per second that were issued to physical devices.  A transfer is an I/O request to a physical device. **Multiple logical requests can be combined into a single  I/O request to the device**.  A transfer is of indeterminate size.\n2. rtps\n    - Total number of read requests per second issued to physical devices.\n3. wtps\n    - Total number of write requests per second issued to physical devices.\n4. bread/s\n    - Total amount of data read from the devices in **blocks** per second.  Blocks are equivalent to **sectors** and therefore have a size of **512 bytes**.\n5. bwrtn/s\n    - Total amount of data written to devices in **blocks** per second.\n\n### 设备\n```\n$ df -h\nFilesystem            Size  Used Avail Use% Mounted on\n/dev/sda2              99G  5.3G   89G   6% /\ntmpfs                  32G  3.7G   28G  12% /dev/shm\n/dev/sda1             477M   28M  425M   7% /boot\n/dev/sda5             436G   71M  414G   1% /data\n/dev/sdb1             3.7T  2.5T  1.1T  70% /data1\n\n$ sar -dp 1 3\nLinux 2.6.32-696.el6.x86_64 (xxx) \t2019年10月15日 \t_x86_64_\t(40 CPU)\n\n16时51分55秒       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util\n16时51分56秒       sda      1.00      0.00    240.00    240.00      0.00      3.00      3.00      0.30\n16时51分56秒       sdb     50.00      0.00   4312.00     86.24      0.01      0.10      0.08      0.40\n\n16时51分56秒       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util\n16时51分57秒       sda      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00\n16时51分57秒       sdb     31.68      0.00   2099.01     66.25      0.00      0.03      0.03      0.10\n\n16时51分57秒       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util\n16时51分58秒       sda      4.08      0.00    106.12     26.00      0.00      0.75      0.75      0.31\n16时51分58秒       sdb     17.35      0.00   1102.04     63.53      0.00      0.06      0.06      0.10\n\n平均时间:       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util\n平均时间:       sda      1.67      0.00    115.05     68.80      0.00      1.20      1.20      0.20\n平均时间:       sdb     33.11      0.00   2512.37     75.88      0.00      0.07      0.06      0.20\n```\n1. tps\n    - Indicate the number of transfers per second that were issued to the device. Multiple logical requests can be combined into a single I/O request to the device. A transfer is of indeterminate size.\n2. rd_sec/s\n    - Number of **sectors** read from the device. The size of a sector is **512** bytes.\n3. wr_sec/s\n    - Number of **sectors** written to the device. The size of a sector is **512** bytes.\n4. avgrq-sz\n    - The average size (in **sectors**) of the requests that were issued to the device.\n5. avgqu-sz\n    - The average queue **length** of the requests that were issued to the device.\n6. await\n    - The average time (in **milliseconds**) for I/O requests issued to the device to  be  served. This includes the time spent by the requests **in queue** and the time spent **servicing** them.\n7. svctm\n    - The average service time (in milliseconds) for I/O requests that were issued to the device.\n    - Warning! Do not trust this field any more. This field will be removed in a future sysstat version.\n8. %util\n    - Percentage of elapsed time during which I/O requests were issued to the device (**bandwidth utilization** for the device).\n    - Device saturation occurs when this value is close to 100%.\n\n### 进程\n```\n$ sar -q 1 5\nLinux 2.6.32-696.el6.x86_64 (xxx) \t2019年10月15日 \t_x86_64_\t(40 CPU)\n\n18时32分20秒   runq-sz  plist-sz   ldavg-1   ldavg-5  ldavg-15\n18时32分21秒        11     39947      1.42      2.59      3.96\n18时32分22秒         6     39942      1.42      2.59      3.96\n18时32分23秒         5     39943      1.42      2.59      3.96\n18时32分24秒         4     39939      1.42      2.59      3.96\n18时32分25秒         8     39939      3.79      3.06      4.10\n平均时间:         7     39942      1.89      2.68      3.99\n```\n1. runq-sz\n    - Run queue length (number of tasks waiting for runtime).\n2. plist-sz\n    - Number of tasks in the task list.\n3. ldavg-1\n    - System load average for the last minute.\n    - The load average is calculated as the average number of **runnable** or **running** tasks (**R** state), and the number of tasks in **uninterruptible** sleep (**D** state) over the specified interval.\n4. ldavg-5\n    - System load average for the past 5 minutes.\n5. ldavg-15\n    - System load average for the past 15 minutes.\n\n## iftop\n```\nyum install epel-release\nyum install iftop\n```\n\n<img src=\"https://linux-practice-1253868755.cos.ap-guangzhou.myqcloud.com/linux-practice-iftop.jpg\"/>","tags":["Linux Practice"],"categories":["Practice"]},{"title":"Linux使用 -- ext4（inode + datablock）","url":"%2F2019%2F10%2F14%2Flinux-practice-ext4%2F","content":"\n## 基本结构\n1. 超级块\n    - 在ext4文件系统**最开头**的部分\n    - 记录了整个文件系统中所包含的文件的**元数据**，`df`命令读取的就是超级块中的内容，所以**执行很快**\n2. 超级块副本\n3. **inode**\n    - 记录每个文件的**大小**（非实际大小，用于`ls`命令）、权限、编号等信息，但**文件名**是记录在**父目录的inode**中\n    - **文件**的`r`权限，是读取**文件内容**；而**目录**的`r`权限，是读取**目录下的文件名称**\n4. **datablock**\n    - 记录**数据**，inode和datablock是**链式**结构\n    - `ls`统计的是**inode**里面的文件大小，而`du`统计的是文件**datablock**的总大小\n\n```\n[root@localhost ~]# ls -li anaconda-ks.cfg\n33574978 -rw-------. 1 root root 1260 12月 15 19:25 anaconda-ks.cfg\n```\n\n<!-- more -->\n\n## ext4\n```\n[root@localhost sdb1]# df -Th\n文件系统                类型      容量  已用  可用 已用% 挂载点\ndevtmpfs                devtmpfs  475M     0  475M    0% /dev\ntmpfs                   tmpfs     487M     0  487M    0% /dev/shm\ntmpfs                   tmpfs     487M  7.7M  479M    2% /run\ntmpfs                   tmpfs     487M     0  487M    0% /sys/fs/cgroup\n/dev/mapper/centos-root xfs        17G  1.4G   16G    9% /\n/dev/sda1               xfs      1014M  137M  878M   14% /boot\ntmpfs                   tmpfs      98M     0   98M    0% /run/user/0\n/dev/sdb1               ext4      991M  2.6M  922M    1% /mnt/sdb1\n\n[root@localhost sdb1]# pwd\n/mnt/sdb1\n```\n\n## touch\n文件大小为0（此时**只有inode**，**没有datablock**），inode编号为12\n```\n[root@localhost sdb1]# touch afile\n\n[root@localhost sdb1]# ls -li afile\n12 -rw-r--r--. 1 root root 0 12月 18 18:12 afile\n\n[root@localhost sdb1]# du -sh afile\n0\tafile\n```\n`ls`命令是4字节（包含换行符），`du`命令是4K（ext4中的默认**数据块**大小是**4K**），因此如果存储很多**小文件**，存储空间的开销也会很大，因此会有专门针对小文件的**网络文件系统**\n```\n[root@localhost sdb1]# echo 123 > afile\n\n[root@localhost sdb1]# ls -li afile\n12 -rw-r--r--. 1 root root 4 12月 18 19:13 afile\n\n[root@localhost sdb1]# du -sh afile\n4.0K\tafile\n```\n\n## cp\nafile和afile2的**inode**编号是不一样的（**datablock**也是不一样的），所以修改afile不会影响到afile2\n```\n[root@localhost sdb1]# cp afile afile2\n\n[root@localhost sdb1]# ls -li afile afile2\n12 -rw-r--r--. 1 root root 4 12月 18 19:13 afile\n13 -rw-r--r--. 1 root root 4 12月 18 19:35 afile2\n```\n\n## mv\nafile2改名为afile3，但**inode**编号没有发生改变（对应的datablock也没有发生变化），实际修改的是`/mnt/sdb1`目录的**datablock**（文件名和inode的**对应关系**），因此在**同一个分区内**mv大文件也非常快（因为inode和datablock是由分区内的文件系统**统一管理**的）\n```\n[root@localhost sdb1]# mv afile2 afile3\n\n[root@localhost sdb1]# ls -li afile*\n12 -rw-r--r--. 1 root root 4 12月 18 19:13 afile\n13 -rw-r--r--. 1 root root 4 12月 18 19:35 afile3\n\n[root@localhost sdb1]# pwd\n/mnt/sdb1\n\n[root@localhost sdb1]# dd if=/dev/zero bs=4M count=256 of=./bigfile\ndd: 写入\"./bigfile\" 出错: 设备上没有空间\n记录了244+0 的读入\n记录了243+0 的写出\n1019617280字节(1.0 GB)已复制，9.29186 秒，110 MB/秒\n\n[root@localhost sdb1]# time mv bigfile bigfile2\nreal\t0m0.029s\nuser\t0m0.002s\nsys\t0m0.017s\n\n[root@localhost sdb1]# time mv bigfile2 /tmp\nreal\t0m1.723s\nuser\t0m0.026s\nsys\t0m1.109s\n```\n\n## vim\n```bash\n# 写入123\n[root@localhost sdb1]# vim afile4\n[root@localhost sdb1]# ls -li afile4\n15 -rw-r--r--. 1 root root 4 12月 19 23:05 afile4\n\n# 追加456，会修改inode\n[root@localhost sdb1]# vim afile4\n[root@localhost sdb1]# ls -li afile4\n16 -rw-r--r--. 1 root root 8 12月 19 23:06 afile4\n\n# echo追加789，不会修改inode，只会修改datablock\n[root@localhost sdb1]# echo 789 >> afile4\n[root@localhost sdb1]# ls -li afile4\n16 -rw-r--r--. 1 root root 12 12月 19 23:08 afile4\n```\n```bash\n# Session A，追加aaa\n[root@localhost sdb1]# vim afile4\n\n# Session B\n[root@localhost sdb1]# ls -li .afile4.swp  afile4\n16 -rw-r--r--. 1 root root    12 12月 19 23:08 afile4\n14 -rw-r--r--. 1 root root 12288 12月 19 23:10 .afile4.swp\n\n# Session A，wq退出vim，16和14消失，变成了15！！\n[root@localhost sdb1]# ls -li afile4\n15 -rw-r--r--. 1 root root 16 12月 19 23:12 afile4\n```\n\n## rm\nrm的本质：使得**inode**与**文件名**的**链接断开**，时间复杂度为`O(1)`\n```bash\n[root@localhost sdb1]# rm afile4\nrm：是否删除普通文件 \"afile4\"？y\n\n[root@localhost sdb1]# dd if=/dev/zero bs=4M count=256 of=./bigfile\ndd: 写入\"./bigfile\" 出错: 设备上没有空间\n记录了244+0 的读入\n记录了243+0 的写出\n1019617280字节(1.0 GB)已复制，1.13283 秒，900 MB/秒\n\n[root@localhost sdb1]# time rm -f bigfile\nreal\t0m0.086s\nuser\t0m0.000s\nsys\t0m0.085s\n```\n\n## ln\nln的本质：使得更多的文件名指向inode\n```bash\n# 1表示有一个文件名与该inode建立了链接\n[root@localhost sdb1]# ls -li afile\n12 -rw-r--r--. 1 root root 4 12月 18 19:13 afile\n```\n\n### 硬链接（不能跨文件系统/分区）\n```bash\n# 2表示afile和bfile都与同一个inode建立了链接，也称为硬链接（inode相同！！）\n[root@localhost sdb1]# ln afile bfile\n[root@localhost sdb1]# ls -li afile bfile\n12 -rw-r--r--. 2 root root 4 12月 18 19:13 afile\n12 -rw-r--r--. 2 root root 4 12月 18 19:13 bfile\n\n[root@localhost sdb1]# cat afile\n123\n[root@localhost sdb1]# cat bfile\n123\n[root@localhost sdb1]# echo 456 >> afile\n[root@localhost sdb1]# cat bfile\n123\n456\n\n# 只是解除bfile和inode的链接关系！！\n[root@localhost sdb1]# rm bfile\nrm：是否删除普通文件 \"bfile\"？y\n[root@localhost sdb1]# ls -li afile\n12 -rw-r--r--. 1 root root 8 12月 19 23:29 afile\n\n# 文件名和inode的链接关系是存在父目录的datablock中，因此不会占用更多的磁盘空间！！\n\n# 硬链接是不能跨越文件系统的！！因为inode是维护在文件系统中的\n# 可以考虑采用软链接\n[root@localhost sdb1]# ln afile /tmp/bfile\nln: 无法创建硬链接\"/tmp/bfile\" => \"afile\": 无效的跨设备连接\n```\n\n### 软链接（符号链接，可以跨文件系统/分区）\n```bash\n[root@localhost sdb1]# ls -li afile\n12 -rw-r--r--. 1 root root 4 12月 19 23:37 afile\n[root@localhost sdb1]# ln -s afile aafile\n\n# inode不一样，aafile的datablock记录了目标文件的绝对路径或相对路径！！\n# 类型为l，为符号链接，权限为777\n[root@localhost sdb1]# ls -li afile aafile\n14 lrwxrwxrwx. 1 root root 5 12月 19 23:41 aafile -> afile\n12 -rw-r--r--. 1 root root 4 12月 19 23:37 afile\n\n# 对链接文件做权限设置是无效的，都会传递给对应的目标文件！！\n[root@localhost sdb1]# chmod u-x aafile\n[root@localhost sdb1]# ls -li afile aafile\n14 lrwxrwxrwx. 1 root root 5 12月 19 23:41 aafile -> afile\n12 -rw-r--r--. 1 root root 4 12月 19 23:37 afile\n[root@localhost sdb1]# chmod u+x aafile\n[root@localhost sdb1]# ls -li afile aafile\n14 lrwxrwxrwx. 1 root root 5 12月 19 23:41 aafile -> afile\n12 -rwxr--r--. 1 root root 4 12月 19 23:37 afile\n```\n\n## facl\n```bash\n[root@localhost sdb1]# ls -li afile\n12 -rw-r--r--. 1 root root 4 12月 19 23:37 afile\n[root@localhost sdb1]# getfacl afile\n# file: afile\n# owner: root\n# group: root\nuser::rw-\ngroup::r--\nother::r--\n\n[root@localhost sdb1]# setfacl -m u:zhongmingmao:r afile\n[root@localhost sdb1]# getfacl afile\n# file: afile\n# owner: root\n# group: root\nuser::rw-\nuser:zhongmingmao:r--\ngroup::r--\nmask::r--\nother::r--\n# 权限中的+表示有facl权限\n[root@localhost sdb1]# ls -li afile\n12 -rw-r--r--+ 1 root root 4 12月 19 23:37 afile\n\n[root@localhost sdb1]# setfacl -m g:zhongmingmao:rwx afile\n[root@localhost sdb1]# getfacl afile\n# file: afile\n# owner: root\n# group: root\nuser::rw-\nuser:zhongmingmao:r--\ngroup::r--\ngroup:zhongmingmao:rwx\nmask::rwx\nother::r--\n\n# 回收facl权限\n[root@localhost sdb1]# setfacl -x g:zhongmingmao afile\n[root@localhost sdb1]# getfacl afile\n# file: afile\n# owner: root\n# group: root\nuser::rw-\nuser:zhongmingmao:r--\ngroup::r--\nmask::r--\nother::r--\n```","tags":["File System"],"categories":["Practice"]},{"title":"Linux使用 -- ls VS du","url":"%2F2019%2F10%2F13%2Flinux-practice-ls-du%2F","content":"\n## du\n**estimate file space usage**\n\n## 非空洞文件\n```\n[root@localhost dd]# dd if=/dev/zero bs=4M count=10 of=afile\n记录了10+0 的读入\n记录了10+0 的写出\n41943040字节(42 MB)已复制，0.0569579 秒，736 MB/秒\n[root@localhost dd]# ls -lh afile\n-rw-r--r--. 1 root root 40M 12月 16 20:55 afile\n[root@localhost dd]# du -sh afile\n40M\tafile\n```\n\n<!-- more -->\n\n## 空洞文件\n```\n[root@localhost dd]# dd if=/dev/zero bs=4M count=10 seek=20 of=bfile\n记录了10+0 的读入\n记录了10+0 的写出\n41943040字节(42 MB)已复制，0.0357481 秒，1.2 GB/秒\n[root@localhost dd]# ls -lh bfile\n-rw-r--r--. 1 root root 120M 12月 16 20:58 bfile\n[root@localhost dd]# du -sh bfile\n40M\tbfile\n```\n空洞文件常用于**虚拟化**，下图为在虚拟机上执行df命令\n```\n[root@localhost dd]# df -h\n文件系统                 容量  已用  可用 已用% 挂载点\ndevtmpfs                 475M     0  475M    0% /dev\ntmpfs                    487M     0  487M    0% /dev/shm\ntmpfs                    487M  7.7M  479M    2% /run\ntmpfs                    487M     0  487M    0% /sys/fs/cgroup\n/dev/mapper/centos-root   17G  1.6G   16G    9% /\n/dev/sda1               1014M  137M  878M   14% /boot\ntmpfs                     98M     0   98M    0% /run/user/0\n```\n虚拟机在宿主机上实际占用的磁盘空间\n```\n➜ du -sh centos7.vmwarevm\n1.8G\tcentos7.vmwarevm\n```\n\n\n","tags":["Linux Practice"],"categories":["Practice"]},{"title":"Linux使用 -- 守护进程","url":"%2F2019%2F10%2F12%2Flinux-practice-daemon-process%2F","content":"\n## nohup & VS 守护进程\n1. **nohup**命令使得进程忽略**hangup**（挂起）信号\n2. 守护进程\n    - 不需要**终端**就能启动\n    - 输出会打印到特定的文件中\n    - 守护进程占用的目录是**根目录**\n\n<!-- more -->\n\n## nohup &\n### Session A\n```\n[root@localhost ~]# tail -f /var/log/messages\nDec 16 06:39:44 localhost NetworkManager[758]: <info>  [1576496384.0844] dhcp4 (ens33):   nameserver '192.168.206.2'\nDec 16 06:39:44 localhost NetworkManager[758]: <info>  [1576496384.0844] dhcp4 (ens33):   domain name 'localdomain'\nDec 16 06:39:44 localhost NetworkManager[758]: <info>  [1576496384.0844] dhcp4 (ens33): state changed bound -> bound\nDec 16 06:39:44 localhost dbus[687]: [system] Activating via systemd: service name='org.freedesktop.nm_dispatcher' unit='dbus-org.freedesktop.nm-dispatcher.service'\nDec 16 06:39:44 localhost systemd: Starting Network Manager Script Dispatcher Service...\nDec 16 06:39:44 localhost dhclient[13173]: bound to 192.168.206.134 -- renewal in 805 seconds.\nDec 16 06:39:44 localhost dbus[687]: [system] Successfully activated service 'org.freedesktop.nm_dispatcher'\nDec 16 06:39:44 localhost systemd: Started Network Manager Script Dispatcher Service.\nDec 16 06:39:44 localhost nm-dispatcher: req:1 'dhcp4-change' [ens33]: new request (3 scripts)\nDec 16 06:39:44 localhost nm-dispatcher: req:1 'dhcp4-change' [ens33]: start running ordered scripts...\n```\n\n### Session B\ntail命令的进程ID为13864，父进程ID为1824\n```\n[root@localhost ~]# ps -ef | grep tail\nroot      13864   1824  0 06:47 pts/0    00:00:00 tail -f /var/log/messages\nroot      13885  13869  0 06:48 pts/1    00:00:00 grep --color=auto tail\n```\n关闭Session A，tail命令为Session A终端的子进程，也会被关闭\n```\n[root@localhost ~]# ps -ef | grep tail\nroot      13892  13869  0 06:51 pts/1    00:00:00 grep --color=auto tail\n```\n\n### Session C\n```\n[root@localhost ~]# nohup tail -f /var/log/messages &\n[1] 13935\n[root@localhost ~]# nohup: 忽略输入并把输出追加到\"nohup.out\"\n\n[root@localhost ~]# pwd\n/root\n[root@localhost ~]# cat nohup.out\nDec 16 06:53:09 localhost NetworkManager[758]: <info>  [1576497189.5907] dhcp4 (ens33): state changed bound -> bound\nDec 16 06:53:09 localhost dbus[687]: [system] Activating via systemd: service name='org.freedesktop.nm_dispatcher' unit='dbus-org.freedesktop.nm-dispatcher.service'\nDec 16 06:53:09 localhost systemd: Starting Network Manager Script Dispatcher Service...\nDec 16 06:53:09 localhost dhclient[13173]: bound to 192.168.206.134 -- renewal in 855 seconds.\nDec 16 06:53:09 localhost dbus[687]: [system] Successfully activated service 'org.freedesktop.nm_dispatcher'\nDec 16 06:53:09 localhost systemd: Started Network Manager Script Dispatcher Service.\nDec 16 06:53:09 localhost nm-dispatcher: req:1 'dhcp4-change' [ens33]: new request (3 scripts)\nDec 16 06:53:09 localhost nm-dispatcher: req:1 'dhcp4-change' [ens33]: start running ordered scripts...\nDec 16 06:53:53 localhost systemd: Started Session 15 of user root.\nDec 16 06:53:53 localhost systemd-logind: New session 15 of user root.\n```\n查看Session C终端下的进程情况，tail命令的进程ID为13935，父进程ID为13920\n```\n[root@localhost ~]# ps -ef | grep tail\nroot      13935  13920  0 06:54 pts/0    00:00:00 tail -f /var/log/messages\nroot      13938  13920  0 06:55 pts/0    00:00:00 grep --color=auto tail\n[root@localhost ~]# ps\n   PID TTY          TIME CMD\n 13920 pts/0    00:00:00 bash\n 13935 pts/0    00:00:00 tail\n 13939 pts/0    00:00:00 ps\n```\n\n### Session B\n关闭Session C，对应的bash进程13920被Kill，tail命令对应的进程13935成为了**孤儿进程**，会**1号**进程**收留**\n```\n[root@localhost ~]# ps -ef | grep tail\nroot      13935      1  0 06:54 ?        00:00:00 tail -f /var/log/messages\nroot      13942  13869  0 06:59 pts/1    00:00:00 grep --color=auto tail\n```\n进入**proc**目录，查看**cwd**和**fd**\n```bash\n[root@localhost ~]# cd /proc/13935/\n\n[root@localhost 13935]# ls -l cwd\nlrwxrwxrwx. 1 root root 0 12月 16 07:55 cwd -> /root\n\n# 禁用标准输入\n[root@localhost 13935]# ls -l fd\n总用量 0\nl-wx------. 1 root root 64 12月 16 07:55 0 -> /dev/null\nl-wx------. 1 root root 64 12月 16 07:55 1 -> /root/nohup.out\nl-wx------. 1 root root 64 12月 16 06:55 2 -> /root/nohup.out\nlr-x------. 1 root root 64 12月 16 07:55 3 -> /var/log/messages\nlr-x------. 1 root root 64 12月 16 07:55 4 -> anon_inode:inotify\n```\n\n## 守护进程sshd\n```bash\n[root@localhost 13935]# ps -ef | grep sshd\nroot       1027      1  0 12月15 ?      00:00:00 /usr/sbin/sshd -D\nroot      13865   1027  0 06:47 ?        00:00:00 sshd: root@pts/1\nroot      14081  13869  0 07:58 pts/1    00:00:00 grep --color=auto sshd\n\n[root@localhost 13935]# cd /proc/1027\n\n# 占用的目录是根目录\n[root@localhost 1027]# ls -l cwd\nlrwxrwxrwx. 1 root root 0 12月 16 07:59 cwd -> /\n\n[root@localhost 1027]# ls -l fd\n总用量 0\nlr-x------. 1 root root 64 12月 16 06:14 0 -> /dev/null\nlrwx------. 1 root root 64 12月 16 06:14 1 -> socket:[20381]\nlrwx------. 1 root root 64 12月 16 06:14 2 -> socket:[20381]\nlrwx------. 1 root root 64 12月 16 06:14 3 -> socket:[20529]\nlrwx------. 1 root root 64 12月 16 06:14 4 -> socket:[20538]\n```","tags":["Linux Practice"],"categories":["Practice"]},{"title":"Linux使用 -- 帮助命令","url":"%2F2019%2F10%2F11%2Flinux-practice-help%2F","content":"\n## man\n1. Executable programs or shell commands\n2. System calls (functions provided by the kernel)\n3. Library calls (functions within program libraries)\n4. Special files (usually found in /dev)\n5. File formats and conventions eg /etc/passwd\n6. Games\n7. Miscellaneous (including macro packages and conventions), e.g. man(7), groff(7)\n8. System administration commands (usually only for root)\n9. Kernel routines [Non standard]\n\n```\n$ ls /usr/bin/passwd /etc/passwd\n/etc/passwd  /usr/bin/passwd\n\n$ man 1 passwd\n$ man 5 passwd\n$ man -a passwd\n```\n\n<!-- more -->\n\n## help\n1. shell（**命令解析器**）自带的命令称为**内部命令**，其它的是**外部命令**\n2. 内部命令：`help cd`\n3. 外部命令：`ls --help`\n\n```\n$ type cd\ncd is a shell builtin\n\n$ type ls\nls is aliased to `ls --color=auto'\n```\n\n## info\n1. info比help更**详细**，`info ls`\n","tags":["Linux Practice"],"categories":["Practice"]},{"title":"Redis -- Pipeline","url":"%2F2019%2F10%2F10%2Fredis-pipeline%2F","content":"\n## 消息交互\n\n### 一次操作\n客户端将请求传送给服务器，服务器处理完后再将响应回复给客户端，这需要花费**一个网络数据包来回的时间**\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-pipeline-one-op.png\" width=1000/>\n\n<!-- more -->\n\n### 多次操作\n连续执行多条指令，会花费**多个网络数据包来回的时间**\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-pipeline-multi-op.png\" width=1000/>\n\n在客户端代码层面，需要经历`写-读-写-读`才能完整地执行完两条指令，如果将顺序调整为`写-写-读-读`，两个指令同样能够正常完成\n两个连续的写操作和两个连续的读操作总共只会花费**一次网络来回**，看起来像**合并**了一样\n管道操作的本质：**客户端**通过**改变**管道中指令列表的**读写顺序**，可以**大福节省IO时间**，管道中的**指令越多**，**效果越好**\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-pipeline-multi-op-merge.png\" width=1000/>\n\n## 管道本质\n\n### 网络交互\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-thread-io-model-server-client.png\" width=1000/>\n\n1. 客户端进程调用`write`函数将消息写到操作系统**内核为套接字分配的发送缓冲**`send buffer`\n2. 客户端操作系统内核将发送缓冲的内容发送到网卡，网卡硬件将数据通过网际路由送到服务器的网卡\n3. 服务器操作系统内核将网卡的数据放到**内核为套接字分配的接收缓冲**`recv buffer`\n4. 服务器进程调用`read`从接收缓冲中取出消息进行处理\n5. 服务器进程调用`write`将响应消息写到内核为套接字分配的发送缓冲`send buffer`\n6. 服务器操作系统内核将发送缓冲中的内容发送到网卡，网卡硬件将数据通过网际路由送到客户端的网卡\n7. 客户端操作系统内核将网卡的数据放到内核为套接字分配的接收缓冲`recv buffer`\n8. 客户端进程调用`read`从接收缓冲中取出消息返回给上层业务逻辑进行处理\n\n### 解析\n1. `write`函数只负责将数据写到操作系统内核的**发送缓冲**，如果发送缓冲**满**了，那么需要**等待**，这是**写操作IO操作的真正耗时**\n2. `read`函数只负责将数据从操作系统内核的**接收缓冲**取出来，如果接收缓冲是**空**的，那么需要**等待**，这是**读操作IO操作的真正耗时**\n3. 对于`value = redis.get(key)`这个请求来说\n    - `write`操作**几乎没有耗时**\n        - 写到发送缓存就返回\n    - `read`会**比较耗时**\n        - 因为需要等待消息经过**网络路由**到达目标机器**处理**后的响应消息，再**回送**到当前的内核**接收缓冲**才可以返回\n4. 对于管道来说\n    - 连续的`write`操作没什么耗时\n    - 之后第一个`read`操作会等待**一个网络的来回**开销\n        - 然后所有的响应消息就已经回送到内核的接收缓冲了，后续的`read`操作**直接**可以从接收缓存中取出结果，速度非常快","tags":["Redis"],"categories":["Redis"]},{"title":"Redis -- 持久化","url":"%2F2019%2F10%2F09%2Fredis-persistence%2F","content":"\n## 持久化机制\n1. Redis有两种持久化机制，一种是**快照**，另一种是**AOF日志**\n2. **快照**是一次**全量备份**，**AOF日志**是连续的**增量备份**\n3. **快照**是**内存数据的二进制序列化形式**，在存储上非常**紧凑**，**AOF日志**记录的是**内存数据修改的指令记录文本**\n    - **AOF日志**在**长期**的运行过程中会变得很**庞大**，数据库**重启**时需要加载AOF日志进行**指令重放**，时间很**漫长**\n    - 因此需要**定期**进行**AOF重写**，给**AOF日志**进行**瘦身**\n\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-persistence.png\" width=1000/>\n\n<!-- more -->\n\n## 快照原理\n1. Redis是**单线程**程序，要同时负责多个**客户端套接字的并发读写操作**和**内存数据结构的逻辑读写**\n2. 在**服务线上请求**的同时，Redis还需要进行**内存快照**\n    - 内存快照要求Redis必须进行**文件IO操作**，可文件IO操作是**不能使用多路复用API**的\n    - 存在的挑战\n        - 单线程同时在服务线上的请求还要进行文件IO操作，而文件IO操作会**严重拖垮服务器请求的性能**\n        - 为了不阻塞线上的业务，需要**边持久化边响应**客户端请求\n    - Redis使用操作系统的**多进程COW（Copy On Write）**机制来实现快照持久化\n\n### Fork多进程\n1. Redis在持久化时会调用`glibc`的`fork`函数产生一个子进程，**快照持久化完全交给子进程来处理**，父进程继续处理客户端请求\n2. 子进程刚产生时，和父进程**共享**内存里的**代码段**和**数据段**，在进程分离那一瞬间，**内存的增长几乎没有明显变化**\n3. **子进程**做数据持久化，**不会修改**现有的内存数据结构，只是对数据结构进行**遍历读取**，然后**序列化**写到**磁盘**中\n4. **父进程**必须持续服务客户端请求，然后对内存数据结构进行**不间断地修改**\n    - 此时会使用操作系统的**COW机制**来进行**数据段页面的分离**\n    - 当父进程对数据段中的一个页面进行修改时，会将被共享的页面**复制**一份**分离**出去，然后对这个复制的页面进行**修改**\n    - 此时**子进程相应的页面没有变化**，还是子进程产生时那一瞬间的数据，因此称为**快照**\n5. 随着父进程修改操作的持续进行，越来越多的共享页面被分离出去，内存会持续增长，但也不会超过原有数据内存大小的两倍\n\n```python\n# 父进程里返回子进程的pid，子进程里返回0，如果操作系统内存资源不足，pid为负，表示fork失败\npid = os.fork()\nif pid > 0:\n    handle_client_requests()    # 父进程继续处理客户端请求\nif pid == 0:\n    handle_snapshot_write()     # 子进程处理快照写磁盘\nif pid < 0:\n    # fork error\n```\n\n## AOF原理\n1. AOF：**Append Only File**\n2. AOF日志存储的是Redis服务器的**顺序指令序列**，AOF日志只记录对内存进行修改的指令记录\n3. **执行指令 -> 日志存盘**\n    - Redis会在收到客户端修改指令后，进行参数校验进行逻辑处理后，如果没问题，会立即将该指令文本存储到AOF日志中\n4. Redis在长期运行的过程中，AOF日志会**越来越大**\n    - 如果实例宕机重启，**重放整个AOF日志会非常耗时**，导致长时间Redis**无法对外提供服务**，所以需要对AOF日志**瘦身**\n\n### AOF重写\n1. Redis提供了**`bgrewriteaof`**指令用于对AOF日志进行瘦身\n2. 原理\n    - 开辟一个子进程**对内存进行遍历**转换成一系列Redis操作指令，**序列化**到一个**新的AOF日志文件**中\n    - 序列化完毕后再将操作期间发生的**增量AOF日志**追加到新的AOF日志文件中，追加完成后立马**替换**旧的AOF日志\n\n### fsync\n1. AOF日志是以**文件**的形式存在的，当程序对AOF日志文件进行**写操作**时\n    - 实际上是将内容写到**内核为文件描述符分配的一个内存缓冲区**中，然后内核会**异步将脏数据刷回磁盘**\n    - 如果机器突然**宕机**，AOF日志内容可能还没来得及完全刷到磁盘上，此时会出现**日志丢失**\n2. `glibc`提供了`fsync(int fd)`函数可以将指定文件的内容_**强制从内核缓存刷新到磁盘**_\n    - 只要Redis进程**实时调用**`fsync`函数就可以保证**AOF日志不丢失**，但`fsync`是一个**磁盘IO**操作，**非常慢**\n    - 在生产环境中，Redis通常每隔**1S**（可配置）左右就执行一次`fsync`操作，在保持**高性能**的同时，**尽可能少丢失数据**\n3. Redis提供了另外两种策略\n    - 一种是**永远不`fsync`**，让操作系统来决定何时同步磁盘，很不安全\n    - 一种是**每个指令都执行`fsync`**，很慢\n\n## 运维\n1. **快照**是通过**开启子进程**的方式进行的，是一个**比较耗资源**的操作\n    - 遍历**整个内存**，**大量写磁盘**会加重系统负载\n2. AOF的`fsync`是一个耗时的**磁盘IO**操作，会降低Redis性能，同时会增加系统IO负担\n3. 通常Redis主节点不会进行持久化操作，**持久化操作主要在从节点进行**\n    - 这里的从节点指的是**备份节点**，没有来自客户端请求的压力\n\n## 混合持久化\n1. 重启Redis，**很少使用rdb**来恢复内存状态，因为会**丢失大量数据**\n    - 通常使用**AOF日志重放**，但重放AOF日志相对rdb来说要**慢很多**\n2. Redis 4.0为了解决该问题，引入了_**混合持久化**_\n    - 将**rdb文件的内容**和**增量的AOF日志文件**存在一起\n    - 增量AOF日志：自持久化**开始**到持久化**结束**这段时间发生的增量AOF日志，通常这部分AOF日志**很小**\n    - Redis重启时，先加载rdb的内容，再重放增量AOF日志，**重启效率大幅提升**\n\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-persistence-hybrid.png\" width=1000/>","tags":["Redis"],"categories":["Redis"]},{"title":"Redis -- RESP","url":"%2F2019%2F10%2F08%2Fredis-communication-protocol%2F","content":"\n## RESP\n1. **RESP**（Redis Serialization Protocol），Redis序列化协议，是一种**直观的文本协议**，**实现简单**，**解析性能好**\n2. Redis协议将传输的结构数据分为5种最小单元类型，单元**结束**时统一加上换行回车符号**`\\r\\n`**\n    - **单行**字符串：以`+`符号开头\n    - **多行**字符串：以`$`符号开头，后跟字符串**长度**\n    - **整数值**：以`:`符号开头，后跟整数的**字符串形式**\n    - **错误**：以`-`符号开头\n    - **数组**：以`*`符号开头，后跟数组的**长度**\n\n<!-- more -->\n\n### 单行字符串\n```\n+hello world\\r\\n\n```\n\n### 多行字符串\n字符串长度为`11`\n```\n$11\\r\\nhello world\\r\\n\n```\n\n#### NULL\n用**多行**字符串表示，但长度要写成`-1`\n```\n$-1\\r\\n\n```\n\n#### 空串\n用**多行**字符串表示，长度为`0`，两个`\\r\\n`之间隔的是**空串**\n```\n$0\\r\\n\\r\\n\n```\n\n### 整数\n```\n:1024\\r\\n\n```\n\n### 错误\n```\n-WRONGTYPE Operation against a key holding the wrong kind of value\\r\\n\n```\n\n### 数组\n`[1,2,3]`\n```\n*3\\r\\n:1\\r\\n:2\\r\\n:3\\r\\n\n```\n\n## 客户端 -> 服务端\n客户端向服务器发送的指令只有一种格式，即**多行字符串数组**，`set author zhongmingmao`会被序列化成下面的字符串\n```\n*3\\r\\n$3\\r\\nset\\r\\n$6\\r\\nauthor\\r\\n$12\\r\\nzhongmingmao\\r\\n\n```\n\n## 服务端 -> 客户端\n\n### 单行字符串\n```bash\n127.0.0.1:6379> set author zhongmingmao\nOK\n```\n没有使用**双引号**括起来，是**单行**字符串响应\n```\n+OK\\r\\n\n```\n\n### 多行字符串\n```bash\n127.0.0.1:6379> get author\n\"zhongmingmao\"\n```\n使用**双引号**括起来，是**多行**字符串响应\n```\n$12\\r\\nzhongmingmao\\r\\n\n```\n\n### 错误\n```bash\n127.0.0.1:6379> incr author\n(error) ERR value is not an integer or out of range\n```\n```\n-ERR value is not an integer or out of range\\r\\n\n```\n\n### 整数\n```bash\n127.0.0.1:6379> incr books\n(integer) 1\n```\n```\n:1\\r\\n\n```\n\n### 数组\n```bash\n127.0.0.1:6379> hset info name zhongmingmao\n(integer) 1\n127.0.0.1:6379> hset info age 18\n(integer) 1\n127.0.0.1:6379> hgetall info\n1) \"name\"\n2) \"zhongmingmao\"\n3) \"age\"\n4) \"18\"\n```\n```\n*4\\r\\n$4\\r\\nname\\r\\n$12\\r\\nzhongmingmao\\r\\n$3\\r\\nage\\r\\n$2\\r\\n18\\r\\n\n```\n\n### 嵌套\n```bash\n127.0.0.1:6379> scan 0\n1) \"0\"\n2) 1) \"author\"\n   2) \"books\"\n   3) \"info\"\n```\n```\n*2\\r\\n$1\\r\\n0\\r\\n*3\\r\\n$6\\r\\nauthor\\r\\n$5\\r\\nbooks\\r\\n$4\\r\\ninfo\\r\\n\n```\n\n## 小结\nRedis协议中有**大量冗余的回车换行符**，但依然是**非常受欢迎**的**文本协议**，很多开源项目都使用了RESP协议","tags":["Redis"],"categories":["Redis"]},{"title":"Redis -- 线程IO模型","url":"%2F2019%2F10%2F07%2Fredis-thread-io-model%2F","content":"\n## 非阻塞IO\n1. 当调用套接字的读写方法，默认都是**阻塞**的\n    - `read(n)`表示最多读取n个字节后再返回，如果一个字节都没有，那么线程会阻塞，直到有新的数据到来或者连接关闭\n    - `write`一般不会阻塞，除非内核为套接字分配的写缓冲区已经**满**了才会阻塞，直到缓冲区有空闲空间挪出来\n2. 非阻塞IO在套接字对象上提供了一个选项**`Non_Blocking`**（读写方法**不会阻塞**，能读多少读多少，能写多少写多少）\n    - 能读多少取决于内核为套接字分配的**读缓冲区**内部的数据字节数\n    - 能写多少取决于内核为套接字分配的**写缓冲区**的空闲空间字节数\n    - 读方法和写方法都会通过**返回值**告知程序**实际读写了多少字节**\n\n<!-- more -->\n\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-thread-io-model-server-client.png\" width=1000/>\n\n## 事件轮询/多路复用\n1. 非阻塞IO存在的问题是**没有通知机制**，可以通过**事件轮询API**来解决这个问题\n2. 最简单的事件轮询API是`select`函数，这是**操作系统**提供给用户程序的API\n    - 输入是**读写描述符列表**`read_fds & write_fds`，输出的是与之对应的**可读可写事件**\n    - 同时还提供一个`timeout`参数，如果没有任何事件到来，那么最多等待`timeout`时间，线程处于**阻塞**状态\n    - 期间有任何事件到来，就立即返回，时间过了之后，还没有任何事件到来，也会立即返回\n    - 拿到事件后，线程可以继续挨个处理相应的事件，事件处理完之后继续过来轮询\n    - 这样线程进入一个死循环，称为**事件循环**\n3. 通过`select`系统调用**同时处理多个**通道描述符的读写事件，因此将这类系统调用称为**多路复用API**\n4. 现代操作系统的多路复用API已经不再使用`select`系统调用，而是使用**`epoll(linux)`**和**`kqueue(freebsd & macosx)`**\n    - 这是因为`select`系统调用的**性能**在**描述符很多**时会非常差\n5. 服务端套接字`serversocket`对象的读操作是指调用`accept`接受**客户端新连接**\n    - 何时有新连接到来，也是可以通过`select`系统调用的读事件来得到通知\n6. _**事件轮询API**就是Java语言层面的**NIO**_\n\n```python\nread_events, write_events = select(read_fds, write_fds, timeout)\nfor event in read_events:\n    handle_read(event.fd)\nfor event in write_events:\n    handle_write(event.fd)\nhandle_others()  # 处理其它事情，如定时任务等\n```\n\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-thread-io-model-select.png\" width=1000/>\n\n## 指令队列\n1. Redis会将每个**客户端套接字**都关联一个**指令队列**，客户端的指令通过**队列**来排队进行**顺序**处理，**先到先服务**\n\n## 响应队列\n1. Redis同样会为每个**客户端套接字**关联一个**响应队列**\n2. Redis服务器通过响应队列来将**指令的返回结果**回复给客户端\n3. 如果队列为空，那么意味着连接暂时处于空闲状态，不需要去获取写事件，可以将当前的客户端描述符从`write_fds`移除\n    - 等响应队列里面有值了，再将描述符放进去\n    - 避免`select`系统调用立即返回写事件，结果发现什么数据都没有，这样会导致**CPU飙升**\n\n## 定时任务\n1. 服务器处理要响应IO事件外，还需要处理其它事情，例如定时任务\n    - 如果线程阻塞在select系统调用上，定时任务将无法得到准确调度\n2. Redis的定时任务会记录在一个**最小堆**中，在该堆中，最快要执行的任务排在堆的最上方\n    - 在每个循环周期，Redis都会将最小堆里面已经到点的任务立即进行处理\n    - 处理完毕后，将最快要执行的任务还需要的时间记录下来，该时间就是`select`系统调用的`timeout`参数\n    - Redis知道未来的`timeout`时间内，没有其它定时任务要执行，所以可以安心休眠`timeout`时间","tags":["Redis"],"categories":["Redis"]},{"title":"Redis -- 限流","url":"%2F2019%2F10%2F06%2Fredis-limiting%2F","content":"\n## 窗口限流\n1. 用一个zset记录用户行为历史，_**同一个用户同一种行为用一个zset记录**_\n2. 为了节省内存，只需要保留**时间窗口内**的行为记录\n    - 如果用户是**冷用户**，滑动窗口内的行为为空记录，可以把对应的zset从内存中移除\n3. 通过统计滑动窗口内的行为数量与阈值max_count进行比较，决定当前行为是否允许\n4. 该方案不适合类似限定60S内操作不超过100W的场景，因为**消耗大量的存储**\n\n<!-- more -->\n\n```java\n@AllArgsConstructor\npublic class WindowRateLimiter {\n    private Jedis jedis;\n\n    public boolean isActionAllowed(String userId, String actionKey, int period, int maxCount) throws IOException {\n        String key = String.format(\"hist:%s:%s\", userId, actionKey);\n        long nowTs = System.currentTimeMillis();\n        // 几个连续的Redis操作都是针对同一个Key，pipeline可以显著提升Redis存取效率\n        Pipeline pipe = jedis.pipelined();\n        pipe.multi();\n        pipe.zadd(key, nowTs, \"\" + nowTs);\n        // 截断窗口\n        pipe.zremrangeByScore(key, 0, nowTs - period * 1000);\n        Response<Long> count = pipe.zcard(key);\n        // 配置窗口过期时间\n        pipe.expire(key, period + 1);\n        pipe.exec();\n        pipe.close();\n        return count.get() <= maxCount;\n    }\n\n    public static void main(String[] args) throws IOException {\n        SimpleRateLimiter limiter = new SimpleRateLimiter(new Jedis(\"localhost\", 16379));\n        for (int i = 0; i < 5; i++) {\n            System.out.println(limiter.isActionAllowed(\"zhongmingmao\", \"reply\", 60, 3));\n        }\n        // true\n        // true\n        // true\n        // false\n        // false\n    }\n}\n```\n\n## 漏斗限流\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-limiting-funnel.png\" width=1000/>\n\n1. 漏斗的**容量是有限**的\n    - 如果漏嘴流水的速率大于灌水的速率，那么漏斗永远都装不满\n    - 如果漏嘴流水速率小于灌水的速率，一旦漏斗满了，灌水就需要暂停并等待漏斗腾空\n2. **漏斗的剩余空间**代表**当前行为可以持续进行的数量**\n3. **漏嘴的流水速率**代表着**系统允许该行为的最大频率**\n\n### 单机\n```java\npublic class FunnelRateLimiter {\n\n    static class Funnel {\n        int capacity;\n        float leakingRate;\n        int leftQuota;\n        long leakingTs;\n\n        public Funnel(int capacity, float leakingRate) {\n            this.capacity = capacity;\n            this.leakingRate = leakingRate;\n            this.leftQuota = capacity;\n            this.leakingTs = System.currentTimeMillis();\n        }\n\n        // 漏水\n        void makeSpace() {\n            long nowTs = System.currentTimeMillis();\n            long deltaTs = nowTs - leakingTs;\n            int deltaQuota = (int) (deltaTs * leakingRate);\n            if (deltaQuota < 0) { // 间隔时间太长，整数数字过大溢出\n                this.leftQuota = capacity;\n                this.leakingTs = nowTs;\n                return;\n            }\n            if (deltaQuota < 1) { // 腾出空间太小，最小单位是1\n                return;\n            }\n            this.leftQuota += deltaQuota;\n            this.leakingTs = nowTs;\n            if (this.leftQuota > this.capacity) {\n                this.leftQuota = this.capacity;\n            }\n        }\n\n        // 灌水\n        boolean watering(int quota) {\n            // 每次灌水前都触发漏水来腾出空间\n            makeSpace();\n            if (this.leftQuota >= quota) {\n                this.leftQuota -= quota;\n                return true;\n            }\n            return false;\n        }\n    }\n\n    private Map<String, Funnel> funnels = new HashMap<>();\n\n    public boolean isActionAllowed(String userId, String actionKey, int capacity, float leakingRate) {\n        String key = String.format(\"%s:%s\", userId, actionKey);\n        Funnel funnel = funnels.get(key);\n        if (funnel == null) {\n            funnel = new Funnel(capacity, leakingRate);\n            funnels.put(key, funnel);\n        }\n        // 需要1个quota\n        return funnel.watering(1);\n    }\n}\n```\n\n### Redis-Cell\nRedis 4.0提供了限流Redis模块，称为`redis-cell`，该模块也使用了**漏斗算法**，并提供了**原子的限流指令**`cl.throttle`\n```bash\n# 每60S最多回复30次，漏斗的初始容量为15，一开始可以连续回复15次，然后开始受漏水速率的影响\n> cl.throttle zhongmingmao:reply 15 30 60 1\n                            ▲     ▲  ▲  ▲  ▲\n                            |     |  |  |  └───── need 1 quota (可选参数，默认值也是1)\n                            |     |  └──┴─────── 30 operations / 60 seconds 漏水速率\n                            |     └───────────── 15 capacity 漏斗容量\n                            └─────────────────── key zhongmingmao\n\n127.0.0.1:6379> cl.throttle zhongmingmao:reply 15 30 60 1\n1) (integer) 0      # 0表示允许，1表示拒绝\n2) (integer) 16     # 漏斗容量capacity\n3) (integer) 15     # 漏斗剩余空间left_quota\n4) (integer) -1     # 如果拒绝了，需要多长时间后再试，单位为秒\n5) (integer) 2      # 多长时间后，漏斗完全空出来（left_quota==capacity），单位秒\n```","tags":["Redis"],"categories":["Redis"]},{"title":"Redis -- Scan","url":"%2F2019%2F10%2F05%2Fredis-scan%2F","content":"\n## keys的缺点\n1. 没有`offset`和`limit`参数，可能会一下子匹配到**大量**数据\n2. 复杂度为**`O(n)`**，如果实例中有千万级别的Key，该指令会导致Redis服务**卡顿**\n    - 所有读写Redis的其它指令都会被**延后**甚至会**超时**报错，因为Redis是**单线程**架构，**顺序执行**所有指令\n3. 为了解决这些问题，Redis在2.8版本引入了`scan`\n\n<!-- more -->\n\n## scan的特点\n1. 复杂度也是**`O(n)`**，但是它是通过**游标**分步进行，**不会阻塞线程**\n2. 提供`limit`参数，可以控制每次返回结果的最大条数\n3. 和`keys`一样，也提供**模式匹配**功能\n4. **服务器不需要维护游标状态**，游标的唯一状态就是`scan`返回给客户端的**游标整数**\n5. 返回的结果可能会**重复**，需要客户端**去重**\n6. 遍历过程中如果有数据修改，**改动后的数据不一定能够遍历到**\n7. _**单次返回的结果为空并不意味着遍历结束，而是要看返回的游标值是否为0**_\n\n## 基础使用\n往Redis插入10000条数据\n```python\nimport redis\n\nclient = redis.Redis(host='localhost', port=16379)\nfor i in range(10000):\n    client.set(\"key%d\" % i, i)\n```\n`scan`指令有三个参数：`cursor`、`key_pattern`、`limit`，第一次遍历时`cursor`为0\n`limit`不是限定返回结果的数量，而是限定服务器**单次遍历的字典槽位数量**（约等于）\n```bash\n127.0.0.1:6379> scan 0 match key99* count 1000\n1) \"1624\" # next cursor\n2) 1) \"key9956\"\n   2) \"key9963\"\n   3) \"key9927\"\n   4) \"key9937\"\n   5) \"key9962\"\n   6) \"key9993\"\n127.0.0.1:6379> scan 1624 match key99* count 1000\n1) \"12332\"\n2)  1) \"key9922\"\n    2) \"key9985\"\n    3) \"key9910\"\n    4) \"key9952\"\n    5) \"key9920\"\n    6) \"key993\"\n    7) \"key9987\"\n    8) \"key9958\"\n    9) \"key9996\"\n   10) \"key9946\"\n   11) \"key9981\"\n   12) \"key9971\"\n   13) \"key9982\"\n   14) \"key9908\"\n...\n127.0.0.1:6379> scan 4199 match key99* count 1000\n1) \"0\" # no more result\n2)  1) \"key9951\"\n    2) \"key995\"\n    3) \"key9909\"\n    4) \"key9949\"\n    5) \"key9934\"\n    6) \"key9942\"\n    7) \"key9994\"\n    8) \"key9959\"\n    9) \"key9938\"\n   10) \"key9995\"\n   11) \"key9904\"\n```\n\n## 字典结构\n1. Redis中所有的Key都存储在一个很大的字典中，该字典与Java的**HashMap**类似，都是**一维数组+二维链表**结构\n2. 第一维数组的大小总是`2^n`，扩容一次数组大小空间**加倍**\n3. `scan`指令返回的**游标**是第一维数组的**位置索引**，将该位置索引称为**槽**（`slot`）\n4. `limit`参数表示**需要遍历的槽位数**，并不是所有的槽位上都会挂接链表\n    - 每次遍历都会将limit数量的槽位上挂接的所有链表元素进行模式匹配过滤后，一次性返回给客户端\n\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-scan-hashmap.png\" width=1000/>\n\n## 遍历顺序\n1. 并不是从第一维数组的第0位一直遍历到末尾，而是采用**高位进位加法**来遍历\n2. 这主要时考虑到字典的**扩容**和**缩容**时**避免槽位的遍历重复和遗漏**\n\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-scan-high-carry.gif\" width=600/>\n\n## 字典扩容\n1. 数组长度为`2^n`次方，所以**取模运算**等价于**位与**操作，`a mod 8 = a & (8-1) = a & 7`，7称为字典的**mask**值\n2. 假设当前的字典的数组长度由8位扩容到16位，那么3号槽位011将会被**rehash**到**3**号槽位和**11**号槽位\n    - 假设开始槽位的二进制数为**xxx**，那么该槽位中的元素将被rehash到**0xxx**和**1xxx**\n\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-scan-rehash.png\" width=600/>\n\n## 扩缩容前后的遍历顺序\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-scan-cap-change.png\" width=1000/>\n\n1. 采用**高位进位加法**的遍历顺序，_**rehash后的槽位在遍历顺序是相邻的！！**_\n2. 扩容\n    - 假设当前要**即将**遍历**`110`**这个位置，扩容后，当前槽位上所有的元素对应的新槽位是**`0110`**和**`1110`**\n    - 此时可以直接从0110这个槽位开始往后继续遍历，0110槽位之前的所有槽位都已经遍历过了\n    - 这样可以**避**免扩容后对已经遍历过的槽位进行**重复遍历**\n2. **缩容**\n    - 假设当前**即将**遍历**`110`**这个位置，缩容后，当前槽位所有的元素对应的新槽位是**`10`**\n    - 此时可以直接从10这个槽位开始往后继续遍历，10槽位之前的所有槽位都已经遍历过了，这样能**避免**缩容的**重复遍历**\n    - 但是这会对010这个槽位上的元素进行重复遍历！！\n\n## 渐进式rehash\n1. Redis采用渐进式rehash，需要同时保留**旧数组**和**新数组**\n    - 然后在**定时任务**中以及后续对hash的指令操作中渐渐地将旧数组中挂接的元素迁移到新数组上\n2. 意味着如果要操作**处于rehash中**的字典，需要**同时访问**新旧两个数组结构\n    - scan处于rehash中的字典，需要同时扫描新旧槽位，然后将结果融合后返回给客户端\n\n## 大Key扫描\n1. 大Key的缺点\n    - 在集群环境中，如果一个Key太大，会导致**数据迁移卡顿**\n    - 在**内存分配**方面，如果一个Key太大，那么当它需要扩容时，会**一次性申请**更大的内存，导致卡顿\n        - 如果这个大Key被删除，内存会**一次性回收**，导致卡顿\n2. 在平时的业务开发中，**要尽量避免大Key的产生！！**\n3. 定位大Key的方法：`–-bigkeys`\n\n```bash\n$ docker exec -it my_redis redis-cli --bigkeys\n\n# Scanning the entire keyspace to find biggest keys as well as\n# average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec\n# per 100 SCAN commands (not usually needed).\n\n[00.00%] Biggest string found so far 'key7974' with 4 bytes\n\n-------- summary -------\n\nSampled 10000 keys in the keyspace!\nTotal key length in bytes is 68890 (avg len 6.89)\n\nBiggest string found 'key7974' has 4 bytes\n\n0 lists with 0 items (00.00% of keys, avg size 0.00)\n0 hashs with 0 fields (00.00% of keys, avg size 0.00)\n10000 strings with 38890 bytes (100.00% of keys, avg size 3.89)\n0 streams with 0 entries (00.00% of keys, avg size 0.00)\n0 sets with 0 members (00.00% of keys, avg size 0.00)\n0 zsets with 0 members (00.00% of keys, avg size 0.00)\n```","tags":["Redis"],"categories":["Redis"]},{"title":"Redis -- 位图","url":"%2F2019%2F10%2F04%2Fredis-bitmap%2F","content":"\n## 概述\n1. 位图不是特殊的数据结构，而是**普通的字符串**，即**byte数组**\n2. 可以使用普通的`get/set`来直接获取或设置**整个位图**的内容\n    - 也可以使用位图操作`getbit/setbit`将byte数组看成**位数组**来处理\n\n<!-- more -->\n\n## setbit / getbit\nRedis的位数组是**自动扩展**的，如果设置了某个偏移位置超出了现有的内容范围，就会自动将位数组进行**零扩充**\n\n### ASCII码\n```python\n>>> bin(ord('h'))\n'0b1101000' # 高位 -> 低位\n>>> bin(ord('e'))\n'0b1100101'\n>>> bin(ord('l'))\n'0b1101100'\n>>> bin(ord('o'))\n'0b1101111'\n```\n\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-bitmap-ascii.gif\" width=1000/>\n\n### 零存整取\n位数组的顺序和字符的位顺序是**相反**的，设置h时，只需要设置位数组的第1/2/4位\n```bash\n127.0.0.1:6379> setbit s 1 1\n(integer) 0\n127.0.0.1:6379> setbit s 2 1\n(integer) 0\n127.0.0.1:6379> setbit s 4 1\n(integer) 0\n127.0.0.1:6379> setbit s 9 1\n(integer) 0\n127.0.0.1:6379> setbit s 10 1\n(integer) 0\n127.0.0.1:6379> setbit s 13 1\n(integer) 0\n127.0.0.1:6379> setbit s 15 1\n(integer) 0\n127.0.0.1:6379> get s\n\"he\"\n```\n\n### 零存零取\n```bash\n127.0.0.1:6379> setbit w 1 1\n(integer) 0\n127.0.0.1:6379> setbit w 2 1\n(integer) 0\n127.0.0.1:6379> setbit w 4 1\n(integer) 0\n127.0.0.1:6379> getbit w 1 # 获取具体位置上的值 0/1\n(integer) 1\n127.0.0.1:6379> getbit w 2\n(integer) 1\n127.0.0.1:6379> getbit w 4\n(integer) 1\n127.0.0.1:6379> getbit w 5\n(integer) 0\n```\n\n### 整存零取\n```bash\n127.0.0.1:6379> set w h # 整存\nOK\n127.0.0.1:6379> getbit w 1\n(integer) 1\n127.0.0.1:6379> getbit w 2\n(integer) 1\n127.0.0.1:6379> getbit w 4\n(integer) 1\n127.0.0.1:6379> getbit w 5\n(integer) 0\n```\n\n### 不可打印字符\n如果对应位的字节是**不可打印字符**，redis-cli会显示该字符的**16进制**形式\n```bash\n127.0.0.1:6379> setbit x 0 1\n(integer) 0\n127.0.0.1:6379> setbit x 1 1\n(integer) 0\n127.0.0.1:6379> get x\n\"\\xc0\"\n```\n\n## bitcount / bitpos\n1. **bitcount**：统计**指定范围内1的个数**\n2. **bitpos**：查找**指定范围**内出现的**第一个**0或1\n3. 指定的**位范围**必须是**8的倍数**，不能任意指定\n\n```\nh        e        l        l        o\n01101000 01100101 01101100 01101100 01101111\n```\n\n```bash\n127.0.0.1:6379> set w hello # 01101000 01100101 01101100 01101100 01101111\nOK\n127.0.0.1:6379> bitcount w # 所有字符中1的位数\n(integer) 21\n127.0.0.1:6379> bitcount w 0 0 # 第一个字符中1的位数\n(integer) 3\n127.0.0.1:6379> bitcount w 0 1 # 迁两个字符中1的位数\n(integer) 7\n127.0.0.1:6379> bitpos w 0 # 第一个0位\n(integer) 0\n127.0.0.1:6379> bitpos w 1 # 第一个1位\n(integer) 1\n127.0.0.1:6379> bitpos w 1 1 1 # 从第二个字符开始，第一个1位\n(integer) 9\n127.0.0.1:6379> bitpos w 1 2 2 # 从第三个字符开始，第一个1位\n(integer) 17\n```\n\n## bitfield\nbitfield有三个子指令（`get/set/incrby`），最多只能处理**64个连续的位**\n```bash\n127.0.0.1:6379> set w hello # 01101000 01100101 01101100 01101100 01101111\nOK\n127.0.0.1:6379> bitfield w get u4 0 # 从第一位开始取4位，结果是无符号数\n1) (integer) 6 # 0110\n127.0.0.1:6379> bitfield w get u3 2 # 从第三位开始取3位，结果是无符号数\n1) (integer) 5 # 101\n127.0.0.1:6379> bitfield w get i4 0 # 从第一位开始取4位，结果是有符号数\n1) (integer) 6 # 0110\n127.0.0.1:6379> bitfield w get i3 2 # 从第三位开始取3位，结果是有符号数\n1) (integer) -3 # 101\n```\n\n一次性执行多个子指令\n```bash\n127.0.0.1:6379> bitfield w get u4 0 get u3 2 get i4 0 get i3 2\n1) (integer) 6\n2) (integer) 5\n3) (integer) 6\n4) (integer) -3\n```\n\n`hello` -> `hallo`，`a`的ASCII码为97\n```bash\n127.0.0.1:6379> bitfield w set u8 8 97 # 从第9位开始，将接下来的8位用无符号数97替代\n1) (integer) 101\n127.0.0.1:6379> get w\n\"hallo\"\n```\n\n`incrby`溢出时，Redis默认的处理是**折返**，8位无符号数255，加1溢出变为0，8位有符号数127，加1溢出变成-128\n```bash\n127.0.0.1:6379> set w hello # 01101000 01100101 01101100 01101100 01101111\nOK\n127.0.0.1:6379> bitfield w incrby u4 2 1 # 从第3位开始，对接下来的4位无符号数+1\n1) (integer) 11\n127.0.0.1:6379> bitfield w incrby u4 2 4\n1) (integer) 15\n127.0.0.1:6379> bitfield w incrby u4 2 1 # 溢出折返\n1) (integer) 0\n```\n\n`bitfield`提供了**溢出策略**子指令`overflow`，默认是折返（`wrap`），`fail`策略是**报错不执行**，`sat`策略是**饱和截断**\n`overflow`子指令**只会影响下一条指令A**，指令A执行完之后，溢出策略会恢复为默认值`wrap`\n\n`sat`策略\n```bash\n127.0.0.1:6379> set w hello\nOK\n127.0.0.1:6379> bitfield w overflow sat incrby u4 2 1\n1) (integer) 11\n127.0.0.1:6379> bitfield w overflow sat incrby u4 2 4\n1) (integer) 15\n127.0.0.1:6379> bitfield w overflow sat incrby u4 2 1 # 保持最大值\n1) (integer) 15\n```\n\n`fail`策略\n```bash\n127.0.0.1:6379> set w hello\nOK\n127.0.0.1:6379> bitfield w overflow fail incrby u4 2 1\n1) (integer) 11\n127.0.0.1:6379> bitfield w overflow fail incrby u4 2 4\n1) (integer) 15\n127.0.0.1:6379> bitfield w overflow fail incrby u4 2 1 # 不执行\n1) (nil)\n127.0.0.1:6379> bitfield w get u4 2\n1) (integer) 15\n```\n","tags":["Redis"],"categories":["Redis"]},{"title":"Redis -- 延时队列","url":"%2F2019%2F10%2F03%2Fredis-delay-queue%2F","content":"\n## 异步消息队列\nRedis的**list**数据结构常用来作为**异步消息队列**使用，使用`rpush/lpush`操作**入队**，使用`lpop/rpop`来操作**出队**\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-delay-queue-list.png\" width=1000/>\n\n<!-- more -->\n\n```bash\n> rpush my-queue apple banana pear\n(integer) 3\n> llen my-queue\n(integer) 3\n> lpop my-queue\n\"apple\"\n> llen my-queue\n(integer) 2\n> lpop my-queue\n\"banana\"\n> llen my-queue\n(integer) 1\n> lpop my-queue\n\"pear\"\n> llen my-queue\n(integer) 0\n> lpop my-queue\n(nil)\n```\n\n## 空队列\n1. 如果队列为空，客户端会陷入**pop的死循环**，**空轮询**不仅拉高了**客户端的CPU**，**Redis的QPS**也会被拉高\n2. 如果空轮询的客户端有几十个，**Redis的慢查询**也会显著增加，可以尝试让客户端线程`sleep 1s`\n3. 但睡眠会导致消息的**延迟增大**，可以使用**`blpop/brpop`**（blocking，**阻塞读**）\n    - 阻塞读在队列没有数据时，会立即进入**休眠**状态，一旦有数据到来，会立即被**唤醒**，**消息延迟几乎为0**\n\n## 空闲连接\n1. 如果线程一直阻塞在那里，Redis的客户端连接就成了**闲置连接**\n2. 闲置过久，**服务器**一般会**主动断开**连接，**减少闲置的资源占用**，此时`blpop/brpop`会**抛出异常**\n\n## 锁冲突处理\n1. 分布式锁**加锁失败**的处理策略\n    - **直接抛出异常**，通知用户稍后重试\n    - **sleep**后再重试\n    - 将请求转移到**延时队列**，过一会重试\n2. 抛出异常\n    - 这种方式比较适合由**用户直接发起**的请求\n3. sleep\n    - sleep会**阻塞**当前的消息处理线程，从而导致队列的后续消息处理出现**延迟**\n    - 如果**碰撞比较频繁**，sleep方案不合适\n4. _**延时队列**_\n    - 比较适合异步消息处理的场景，通过将当前冲突的请求转移到另一个队列**延后处理**来**避免冲突**\n\n## 延时队列\n1. 可以通过Redis的**zset**来实现延时队列\n2. 将消息序列化成一个字符串作为zet的`value`，将该消息的**到期处理时间**作为`score`\n3. 然后**多线程轮询**zset获取**到期的任务**进行处理\n    - 多线程是为了保障**可用性**，但同时要考虑**并发安全**，确保**任务不能被多次执行**\n\n```java\npublic class RedisDelayingQueue<T> {\n    @Data\n    @AllArgsConstructor\n    @NoArgsConstructor\n    private static class TaskItem<T> {\n        private String id;\n        private T msg;\n    }\n\n    private Type taskType = new TypeReference<TaskItem<T>>() {\n    }.getType();\n\n    private Jedis jedis;\n    private String queueKey;\n\n    public RedisDelayingQueue(Jedis jedis, String queueKey) {\n        this.jedis = jedis;\n        this.queueKey = queueKey;\n    }\n\n    public void delay(T msg) {\n        TaskItem<T> task = new TaskItem<>(UUID.randomUUID().toString(), msg);\n        jedis.zadd(queueKey, System.currentTimeMillis() + 5000, JSON.toJSONString(task));\n    }\n\n    public void loop() {\n        // 可以进一步优化，通过Lua脚本将zrangeByScore和zrem统一挪到Redis服务端进行原子化操作，减少抢夺失败出现的资源浪费\n        while (!Thread.interrupted()) {\n            // 只取一条\n            Set<String> values = jedis.zrangeByScore(queueKey, 0, System.currentTimeMillis(), 0, 1);\n            if (values.isEmpty()) {\n                try {\n                    Thread.sleep(500);\n                } catch (InterruptedException e) {\n                    break;\n                }\n                continue;\n            }\n            String s = values.iterator().next();\n            if (jedis.zrem(queueKey, s) > 0) {\n                // zrem是多线程多进程争夺任务的关键\n                TaskItem<T> task = JSON.parseObject(s, taskType);\n                this.handleMsg(task.msg);\n            }\n        }\n    }\n\n    private void handleMsg(T msg) {\n        try {\n            System.out.println(msg);\n        } catch (Throwable ignored) {\n            // 一定要捕获异常，避免因为个别任务处理问题导致循环异常退出\n        }\n    }\n\n    public static void main(String[] args) {\n        final RedisDelayingQueue<String> queue = new RedisDelayingQueue<>(new Jedis(\"localhost\", 16379), \"q-demo\");\n        Thread producer = new Thread() {\n            @Override\n            public void run() {\n                for (int i = 0; i < 10; i++) {\n                    queue.delay(\"zhongmingmao\" + i);\n                }\n            }\n\n        };\n        Thread consumer = new Thread() {\n            @Override\n            public void run() {\n                queue.loop();\n            }\n\n        };\n\n        producer.start();\n        consumer.start();\n        try {\n            producer.join();\n            Thread.sleep(6000);\n            consumer.interrupt();\n            consumer.join();\n        } catch (InterruptedException ignored) {\n        }\n    }\n}\n```\n","tags":["Redis"],"categories":["Redis"]},{"title":"Redis -- 分布式锁","url":"%2F2019%2F10%2F02%2Fredis-distributed-lock%2F","content":"\n## 方案\n### setnx + del\n```bash\n> setnx lock:user true\nOK\n# 执行业务逻辑\n> del lock:user\n(integer) 1\n```\n存在的问题：如果逻辑执行过程中出现异常，可能会导致**del**指令没有被调用，陷入**死锁**，锁永远不会被释放\n\n<!-- more -->\n\n### setnx + expire + del\n```bash\n> setnx lock:user true\nOK\n> expire lock:user 10\n(integer) 1\n# 执行业务逻辑\n> del lock:user\n(integer) 1\n```\n存在的问题：如果**setnx**和**expire**之间的服务器进程突然挂掉，会导致**expire**无法执行，也会造成**死锁**\n问题根源：**setnx**和**expire**是两条独立的指令，而**不是原子指令**\n\n### set扩展参数\n```bash\n> set lock:user true ex 5 nx # setnx和expire是组合在一起的原子指令\nOK\n# 执行业务逻辑\n> del lock:user\n(integer) 1\n```\n\n## 超时问题\nRedis的分布式锁**不能解决超时问题**，因此Redis分布式锁**不要用于较长时间的任务**\n\n### Lua脚本\nLua脚本可以保证**连续多个指令**的**原子性**执行，但该方案并不完美，只是**相对安全一点**\n```python\ntag = random.nextint()  # 随机数\nif redis.set(key, tag, nx=True, ex=5):\n    do_something()\n    # 释放锁时先匹配随机数是否一致，然后再删除Key\n    # 这样可以确保当前线程占有的锁不会被其它线程释放，除非这个锁是过期了被服务器自动释放\n    # 如果真的超时，当前线程的逻辑没有执行完成，其它线程也会趁虚而入\n    redis.delifequals(key, tag)\n\n# delifequals\nif redis.call(\"get\",KEYS[1]) == ARGV[1] then\n    return redis.call(\"del\",KEYS[1])\nelse\n    return 0\nend\n```\n\n## 可重入性\nRedis分布式锁如果要支持可重入，需要对客户端的**set**方法进行**包装**，使用线程的**ThreadLocal**变量存储当前持有锁的计数\n**不推荐使用可重入锁**，因为**加重了客户端的复杂性**，可以通过在**业务层面**调整来避免使用可重入的Redis分布式锁\n```java\npublic class RedisWithReentrantLock {\n    private final ThreadLocal<Map<String, Integer>> lockers = new ThreadLocal<>();\n    private Jedis jedis;\n\n    public RedisWithReentrantLock(Jedis jedis) {\n        this.jedis = jedis;\n    }\n\n    private boolean doLock(String key) {\n        // TODO 可以进一步细化考虑过期时间，代码复杂度将进一步提升\n        return jedis.set(key, \"\", \"nx\", \"ex\", 5L) != null;\n    }\n\n    private void doUnlock(String key) {\n        jedis.del(key);\n    }\n\n    private Map<String, Integer> currentLockers() {\n        Map<String, Integer> refs = lockers.get();\n        if (refs != null) {\n            return refs;\n        }\n        lockers.set(Maps.<String, Integer>newHashMap());\n        return lockers.get();\n    }\n\n    public boolean lock(String key) {\n        Map<String, Integer> refs = currentLockers();\n        Integer refCnt = refs.get(key);\n        if (refCnt != null) {\n            refs.put(key, refCnt + 1);\n            return true;\n        }\n        boolean ok = this.doLock(key);\n        if (!ok) {\n            return false;\n        }\n        refs.put(key, 1);\n        return true;\n    }\n\n    public boolean unlock(String key) {\n        Map<String, Integer> refs = currentLockers();\n        Integer refCnt = refs.get(key);\n        if (refCnt == null) {\n            return false;\n        }\n        refCnt -= 1;\n        if (refCnt > 0) {\n            refs.put(key, refCnt);\n        } else {\n            refs.remove(key);\n            this.doUnlock(key);\n        }\n        return true;\n    }\n\n    public static void main(String[] args) {\n        String lockName = \"zhongmingmao\";\n        RedisWithReentrantLock redis = new RedisWithReentrantLock(new Jedis(\"localhost\", 16379));\n        System.out.println(redis.lock(lockName));\n        System.out.println(redis.lock(lockName));\n        System.out.println(redis.unlock(lockName));\n        System.out.println(redis.unlock(lockName));\n    }\n}\n```\n","tags":["Redis"],"categories":["Redis"]},{"title":"Redis -- 基础数据结构","url":"%2F2019%2F10%2F01%2Fredis-basic-data-structure%2F","content":"\n## 数据结构\nRedis所有的数据结构都是以**唯一的key字符串**作为名称，然后通过该唯一key值来获取相应的value值\n\n### string\n1. Redis的字符串是**动态**字符串，是**可以修改**的字符串，内部结构实现上类似与Java的**ArrayList**\n    - 采用**预分配冗余空间**的方式来减少内存的频繁分配\n2. 当字符串长度**小于1M**时，扩容都是**加倍**现有的空间，如果**超过1M**，扩容时一次只会**多扩1M**的空间\n    - 字符串最大长度为**512M**\n\n<!-- more -->\n\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-data-structure-string.png\" width=1000/>\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-data-structure-string.gif\" width=1000/>\n\n#### 键值对\n```bash\n> set name zhongmingmao\nOK\n> get name\n\"zhongmingmao\"\n> exists name\n(integer) 1\n> del name\n(integer) 1\n> get name\n(nil)\n```\n\n#### 批量键值对\n批量对多个字符串进行读写，**节省网络开销**\n```bash\n> set name1 zhongmingmao\nOK\n> set name2 zhongmingwu\nOK\n> mget name1 name2 name3\n1) \"zhongmingmao\"\n2) \"zhongmingwu\"\n3) (nil)\n> mset name1 a name2 b name3 unknown\nOK\n> mget name1 name2 name3\n1) \"a\"\n2) \"b\"\n3) \"unknown\"\n```\n\n#### 过期和set命令扩展\n```bash\n> set name zhongmingmao\nOK\n> get name\n\"zhongmingmao\"\n> expire name 5\n(integer) 1\n> get name # 等5S后\n(nil)\n> setex name 5 zhongmingmao\nOK\n> get name\n\"zhongmingmao\"\n> get name # 等5S后\n(nil)\n> setnx name zhongmingmao\n(integer) 1\n> get name\n\"zhongmingmao\"\n> setnx name zhongmingwu\n(integer) 0 # name已存在，set失败\n> get name\n\"zhongmingmao\" # 结果不变\n```\n\n#### 计数\n如果value是一个**整数**，可以对其进行**自增**操作，自增是有范围的，即**signed long**的最大值和最小值\n```bash\n> set age 30\nOK\n> incr age\n(integer) 31\n> incrby age 5\n(integer) 36\n> incrby age -5\n(integer) 31\n> set age 9223372036854775807 # Long.Max\nOK\n> incr age\n(error) ERR increment or decrement would overflow\n```\n\n### list\n1. Redis的列表相当于Java的**LinkedList**，**插入**和**删除**的时间复杂度为`O(1)`，但**索引定位**的时间复杂度为`O(n)`\n2. 当列表弹出**最后一个**元素后，该数据结构**自动被删除，内存被回收**\n\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-data-structure-list.gif\" width=1000/>\n\n#### 队列\n```bash\n> rpush books python java golang\n(integer) 3\n> llen books\n(integer) 3\n> lpop books\n\"python\"\n> lpop books\n\"java\"\n> lpop books\n\"golang\"\n> lpop books\n(nil)\n```\n\n#### 栈\n```bash\n> rpush books python java golang\n(integer) 3\n> rpop books\n\"golang\"\n> rpop books\n\"java\"\n> rpop books\n\"python\"\n> rpop books\n(nil)\n```\n\n#### 慢操作\n1. **index**相当于Java链表的`get(int index)`方法，需要对链表进行**遍历**，性能随着参数index增大而变差\n    - index可以是**负数**，`index=-1`表示**倒数第一**个元素\n2. **ltrim start_index end_index**定义了一个区间，在这个区间内的值要保留\n\n```bash\n> rpush books python java golang\n(integer) 3\n> lindex books 1 # O(n)\n\"java\"\n> lrange books 0 -1 # O(n)\n1) \"python\"\n2) \"java\"\n3) \"golang\"\n> ltrim books 1 -1 # O(n)\nOK\n> lrange books 0 -1\n1) \"java\"\n2) \"golang\"\n> ltrim books 1 0 # 清空整个列表，因为区间范围长度为负\nOK\n> llen books\n(integer) 0\n```\n\n#### 快速列表\n1. 在**列表元素较少**的情况下会使用一块**连续的内存存储**，该结构称为`ziplist`，即**压缩列表**\n2. 到**数据比较多**的时候，才会改成`quicklist`\n3. 这是因为普通的链表需要的**附加指针空间太大**，会比较**浪费空间**，而且会**加重内存的碎片**\n4. Redis将**链表**和`ziplist`结合起来组成`quicklist`\n    - 将多个`ziplist`使用**双向指针**串联，这样即能满足**快速的插入删除性能**，又**不会出现太大的空间冗余**\n\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-data-structure-quick-list.png\" width=1000/>\n\n### hash\n1. Redis中的字典相当于Java中**HashMap**，是**无序**字典，同样使用**数组+链表**实现\n2. 但Redis的字典的**值只能是字符串**，**rehash**的方式也不一样\n    - Java的HashMap在字典很大时，rehash**非常耗时**，因为需要**一次性全部rehash**\n    - Redis为了**高性能**，不阻塞服务，采用**渐进式rehash策略**\n\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-data-structure-hash.png\" width=1000/>\n\n```bash\n> hset books java 'think in java'\n(integer) 1\n> hset books golang 'concurrency in go'\n(integer) 1\n> hset books python 'python cookbook'\n(integer) 1\n> hgetall books\n1) \"java\"\n2) \"think in java\"\n3) \"golang\"\n4) \"concurrency in go\"\n5) \"python\"\n6) \"python cookbook\"\n> hlen books\n(integer) 3\n> hget books java\n\"think in java\"\n> hset books golang 'learning go programming' # 因为是更新操作，所以返回0\n(integer) 0\n> hget books golang\n\"learning go programming\"\n> hmset books java 'effective java' python 'learning python' golang 'modern golang programming' # 批量set\nOK\n> hincrby zhongmingmao age 18\n(integer) 18\n> hget zhongmingmao age\n\"18\"\n```\n\n#### 渐进式rehash\n1. 渐进式rehash会在rehash的同时，**保留新旧两个hash结构**，查询时会**同时查询两个hash结构**\n2. 在后续的**定时任务**中以及hash操作指令中，**循序渐进**地将旧hash的内容迁移到新的hash结构中\n3. 当搬迁完成后，就会使用新的hash结构，当hash移除**最后一个**元素后，该数据结构会被**自动删除**，内存被**回收**\n\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-data-structure-hash-rehash.png\" width=1000/>\n\n### set\n1. Redis的集合相当于Java的**HashSet**，内部的键值对是**无序且唯一**的\n2. 内部实现相当于一个**特殊的字典**，字典中所有的value都是一个值**`NULL`**\n3. 当集合中**最后一个**元素被移除后，数据结构自动**删除**，内存被**回收**\n\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-data-structure-set.gif\" width=1000/>\n\n```bash\n> sadd books python\n(integer) 1\n> sadd books python\n(integer) 0 # 重复\n> sadd books java golang\n(integer) 2\n> smembers books # 无序\n1) \"golang\"\n2) \"java\"\n3) \"python\"\n> sismember books java # contains\n(integer) 1\n> sismember books rust\n(integer) 0\n> scard books # count\n(integer) 3\n> spop books\n\"golang\"\n```\n\n### zset\n1. Redis的有序集合类似于Java的**SortedSet**和**HashMap**的结合体\n    - 一方面zset是一个set，保证内部value的**唯一性**\n    - 另一方面zset给每个value赋予了一个**score**，代表value的**排序权重**\n2. zset中**最后一个**value被移除后，数据结构**自动删除**，内存被**回收**\n\n```bash\n> zadd books 9.0 'think in java'\n(integer) 1\n> zadd books 8.9 'java concurrency'\n(integer) 1\n> zadd books 8.6 'java cookbook'\n(integer) 1\n> zrange books 0 -1\n1) \"java cookbook\"\n2) \"java concurrency\"\n3) \"think in java\"\n> zrevrange books 0 -1\n1) \"think in java\"\n2) \"java concurrency\"\n3) \"java cookbook\"\n> zcard books # count\n(integer) 3\n> zscore books 'java concurrency'\n\"8.9000000000000004\" # double存储，存在精度问题\n> zrank books 'java concurrency'\n(integer) 1\n> zrangebyscore books 0 8.91\n1) \"java cookbook\"\n2) \"java concurrency\"\n> zrangebyscore books -inf 8.91 withscores\n1) \"java cookbook\"\n2) \"8.5999999999999996\"\n3) \"java concurrency\"\n4) \"8.9000000000000004\"\n> zrem books 'java concurrency'\n(integer) 1\n> zrange books 0 -1\n1) \"java cookbook\"\n2) \"think in java\"\n```\n\n#### 跳跃表\n1. zset内部的**排序功能**是通过**跳跃表**来实现的\n2. 跳跃表之所以跳跃，是因为内部的元素可能**身兼数职**\n    - 下图中间的元素，同时处于L0、L1和L2层，可以快速在**不同层次**之间进行跳跃\n3. **定位插入点**时，先在**顶层**进行定位，然后下潜到**下一层**定位，一直下潜到**最底层**找到合适的位置，将新元素插进去\n4. 跳跃表采用**随机策略**来决定新元素可以兼职到第几层\n    - L0层为100%的概率，L1层为50%的概率，L2层为25%的概率，L3层为12.5%的概率，一直随机到最顶层**L31**层\n\n<img src=\"https://redis-1253868755.cos.ap-guangzhou.myqcloud.com/redis-data-structure-zset-skip-list.png\" width=1000/>\n\n## 通用规则\n1. **list/hash/set/zset**都是**容器型**数据结构，有两条通用规则\n2. _**create if not exists !!**_\n3. _**drop if no elements !!**_\n\n## 过期时间\n1. 过期是以**对象**为单位的，如一个hash结构的过期是**整个**hash对象的过期，而不是其中的某个子key过期\n2. 如果一个**字符串**已经设置了过期时间，然后再调用**set**方法修改了它，那么它的**过期时间会消失**\n\n```bash\n> set name zhongmingmao\nOK\n> expire name 600\n(integer) 1\n> ttl name\n(integer) 597\n> set name zhongmingwu\nOK\n> ttl name\n(integer) -1\n```","tags":["Redis"],"categories":["Redis"]},{"title":"Kafka -- 调优","url":"%2F2019%2F09%2F30%2Fkafka-tuning%2F","content":"\n## 调优目标\n1. 主要目标：**高吞吐量**、**低延时**\n2. **吞吐量**\n    - 即**TPS**，指的是Broker端进程或Client端应用程序每秒能处理的**字节数**或**消息数**\n3. **延时**，可以有两种理解\n    - 从**Producer发送消息**到**Broker持久化**完成之间的时间间隔\n    - **端到端的延时**，即从**Producer发送消息**到**Consumer成功消费该消息**的总时长\n\n<!-- more -->\n\n## 优化漏斗\n优化漏斗是调优过程中的分层漏斗，层级越靠上，调优的效果越明显\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-tuning-funnel.png\" width=800/>\n\n### 操作系统层\n1. `mount -o noatime`\n    - 在**挂载**文件系统时禁用**atime**（Access Time）更新，记录的是**文件最后被访问的时间**\n    - 记录**atime**需要操作系统访问**inode**资源，禁用atime可以**避免inode访问时间的写入操作**\n2. 文件系统选择**ext4**、**XFS**、**ZFS**\n3. 将**swappiness**设置成一个**很小的值**（1~10，默认是60），防止Linux的`OOM Killer`开启**随机杀掉**进程\n    - **swappiness=0**，并不会禁止对swap的使用，只是**最大限度**地降低使用swap的可能性\n        - 因为一旦设置为0，当物理内存耗尽时，操作系统会触发**OOM Killer**\n        - OOM Killer会**随机**挑选一个进程然后kill掉，**不会给出任何预警**\n    - swappiness=N，表示内存使用**`(100-N)%`**时，开始使用Swap\n4. `ulimit -n`设置大一点，否则可能会出现**Too Many File Open**错误\n5. `vm.max_map_count`也设置大一点（如655360，默认值65530）\n    - 在一个主题数超多的机器上，可能会碰到**OutOfMemoryError：Map failed**错误\n6. **页缓存大小**\n    - 给Kafka预留的页缓存至少也要容纳一个**日志段**的大小（`log.segment.bytes`，默认值为**1GB**）\n    - 消费者程序在**消费**时能**直接命中**页缓存，从而避免**昂贵的物理磁盘IO操作**\n\n### JVM层\n1. 堆大小，经验值为**6~8GB**\n    - 如果需要精确调整，关注**Full GC后堆上存活对象的总大小**，然后将堆大小设置为该值的**1.5~2倍**\n    - `jmap -histo:live <pid>`可以人为触发Full GC\n2. 选择垃圾收集器\n    - 推荐使用**G1**，主要原因是**优化难度比CMS小**\n    - 如果使用G1后，频繁Full GC，配置`-XX:+PrintAdaptiveSizePolicy`，查看触发Full GC的原因\n    - 使用G1的另一个问题是**大对象**，即`too many humongous allocations`\n        - 大对象一般指的是**至少占用半个Region大小的对象**，大对象会被直接分配在**大对象区**\n        - 可以适当增大`-XX:+G1HeapRegionSize=N`\n3. _**尽量避免Full GC！！**_\n\n### 框架层\n尽量保持**客户端**版本和**Broker端**版本**一致**，否则可能会丧失很多**性能收益**，如**Zero Copy**\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-zero-copy.png\" width=1000/>\n\n### 应用程序层\n1. **不要频繁创建**Producer和Consumer对象实例，构造这些对象的**开销很大**\n2. **用完及时关闭**\n    - Producer对象和Consumer对象会创建很多物理资源，如Socket连接、ByteBuffer缓冲区，很容易造成**资源泄露**\n3. 合理利用**多线程**来改善性能，Kafka的Java Producer是线程安全的，而Java Consumer不是线程安全的\n\n## 性能指标调优\n\n### `TPS != 1000 / Latency(ms)`**\n1. 假设Kafka Producer以2ms的延时来发送消息，如果**每次都只发送一条消息**，那么`TPS=500`\n2. 但如果Producer不是每次只发送一条消息，而是在发送前**等待一段时间**，然后**统一发送一批**消息\n3. 如Producer每次发送前等待8ms，总共缓存了1000条消息，总延时累加到了10ms，但`TPS=100,000`\n    - 虽然延时增加了4倍，但TPS却增加了200倍，这就是**批次化**或**微批次化**的优势\n    - 用户一般愿意用**较小的延时增加**的代价，去换取**TPS的显著提升**，Kafka Producer就是采用了这样的思路\n    - 基于的前提：**内存操作**（几百纳秒）和**网络IO操作**（毫秒甚至秒级）的时间量级不同\n\n### 调优吞吐量\n1. Broker端\n    - 适当增加**`num.replica.fetchers`**（默认值为1），但**不用超过CPU核数**\n        - 生产环境中，配置了`acks=all`的Producer程序吞吐量被拖累的首要因素，就是**副本同步性能**\n    - 调优GC参数避免频繁Full GC\n2. Producer端\n    - 适当增加`batch.size`（默认值为16KB，可以增加到**512KB**或**1MB**）\n        - 增加消息批次的**大小**\n    - 适当增加`linger.ms`（默认值为0，可以增加到10~100）\n        - 增加消息批次的**缓存时间**\n    - 修改`compression.type`（默认值为none，可以修改为**lz4**或**zstd**，适配最好）\n    - 修改`acks`（默认值为1，可以修改为**0**或**1**）\n        - 优化的目标是吞吐量，不要开启`acks=all`（引入的**副本同步时间**通常是吞吐量的瓶颈）\n    - 修改`retries`（修改为**0**）\n        - 优化的目标是吞吐量，不要开启重试\n    - 如果多线程共享同一个Producer，增加`buffer.memory`（默认为`32MB`）\n        - `TimeoutException：Failed to allocate memory within the configured max blocking time`\n3. Consumer端\n    - 采用多Consumer进程或线程**同时消费**数据\n    - 适当增加`fetch.min.bytes`（默认值为1Byte，可以修改为**1KB**或更大）\n\n### 调优延时\n1. Broker端\n    - 适当增加`num.replica.fetchers`\n2. Producer端\n    - 设置`linger.ms=0`\n    - 设置`compression.type=none`\n        - 压缩会消耗CPU时间\n    - 设置`acks=1`\n3. Consumer端\n    - 设置`fetch.min.bytes=1`","tags":["Stream"],"categories":["Kafka"]},{"title":"Kafka -- 监控","url":"%2F2019%2F09%2F29%2Fkafka-monitor%2F","content":"\n## 主机监控\n1. 主机监控：监控Kafka集群Broker所在的节点机器的性能\n2. 常见的主机监控指标\n    - **机器负载**\n    - **CPU使用率**\n    - **内存使用率**，包括空闲内存和已使用内存\n    - **磁盘IO使用率**，包括读使用率和写使用率\n    - **网络IO使用率**\n    - **TCP连接数**\n    - **打开文件数**\n    - **inode使用情况**\n\n<!-- more -->\n\n## JVM监控\n1. 重点指标\n    - Full GC发生频率和时长\n    - 活跃对象大小\n    - 应用线程总数\n2. 设置堆大小\n    - 经历一次**Full GC**后，堆上存活的活跃对象大小为S，可以安全地将**老年代**堆大小设置为**1.5S**或者**2S**\n3. 从**0.9.0.0**版本开始，社区将默认的GC收集器设置为**G1**，而G1的**Full GC**是由**单线程**执行的，速度**非常慢**\n    - 一旦发现Broker进程**频繁Full GC**，可以开启G1的**`-XX:+PrintAdaptiveSizePolicy`**，获知引发Full GC的**原因**\n\n## 集群监控\n1. 查看Broker进程是否启动，端口是否建立\n    - 在容器化的Kafka环境，容器虽然启动成功，但由于网络配置有误，会出现进程已经启动但端口未成功监听的情形\n2. 查看Broker端**关键日志**\n    - Broker端服务器日志**server.log** -- 最重要\n    - 控制器日志**controller.log**\n    - 主题分区状态变更日志**state-change.log**\n3. 查看Broker端**关键线程**的运行状态\n    - 这些关键线程的**意外挂掉**，往往**无声无息**，但却影响巨大\n    - **Log Compaction**线程，这类线程以`kafka-log-cleaner-thread`开头\n        - 挂掉后，所有Compaction操作都会中断，导致Kafka内部的**位移主题**所占用的磁盘空间越来越大\n    - **副本拉取消息**的线程，通常以`ReplicaFetcherThread`开头\n        - 挂掉后，系统会表现为对应Follower副本不再从Leader副本拉取消息，Follower副本的**Lag**会越来越大\n4. 查看Broker端**关键JMX指标**\n    - **BytesIn/BytesOut**\n        - `kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec`\n        - `kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec`\n        - Broker端每秒入站和出站字节数，要确保这组值**不要接近网络带宽**，容易出现**网络丢包**的情形\n    - **NetworkProcessorAvgIdlePercent**\n        - `kafka.network:type=SocketServer,name=NetworkProcessorAvgIdlePercent`\n        - **网络线程池平均的空闲比例**，要确保该值长期大于**30%**\n    - **RequestHandlerAvgIdlePercent**\n        - `kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent`\n        - **IO线程池平均的空闲比例**，要确保该值长期大于**30%**\n    - **UnderReplicatedPartitions**\n        - `kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions`\n        - 未充分备份的分区数，一般为0\n            - 未充分备份，即**并非所有的Follower副本都和Leader副本保持同步**，此时可能会出现**数据丢失**\n    - **ISRShrink/ISRExpand**\n        - `kafka.server:type=ReplicaManager,name=IsrShrinksPerSec`\n        - `kafka.server:type=ReplicaManager,name=IsrExpandsPerSec`\n        - ISR收缩和扩容的频次指标\n    - **ActiveControllerCount**\n        - `kafka.controller:type=KafkaController,name=ActiveControllerCount`\n        - 当前处于**激活状态**的控制器数量\n            - 正常情况下，Controller所在Broker上的这个JMX指标值为1，其它Broker上这个值为0\n            - 如果发现存在**多台Broker**上该值都是**1**时，通常表明集群中出现了**脑裂**，此时一定要查看**网络连通性**\n            - 脑裂是**非常严重的分布式故障**，Kafka目前依托**ZK**来防止脑裂\n            - 一旦出现脑裂，Kafka是**无法保证正常工作**的\n5. 监控Kafka客户端\n    - 首先要关心的是客户端所在机器与Kafka Broker机器之间的**网络往返时延**（**RTT**），可以借助**ping**命令\n    - 生产者\n        - 以`kafka-producer-network-thread`开头的线程，负责**实际消息发送**\n        - 一旦该线程挂掉，Producer将无法正常工作，但Producer进程不会自动挂掉\n    - 消费者\n        - 关注以`kafka-coordinator-heartbeat-thread`开头的线程，心跳线程事关**Rebalance**\n    - JMX\n        - 生产者：`request-latency`，消息生产请求的延时，最直接表征Producer程序的**TPS**\n        - 消费者：`records-lag`、`records-lead`，直接反应消费者的**消费进度**\n        - 消费者组：`join rate`、`sync rate`，表征**Rebalance的频繁程度**\n","tags":["Stream"],"categories":["Kafka"]},{"title":"Kafka -- KafkaAdminClient","url":"%2F2019%2F09%2F28%2Fkafka-admin-client%2F","content":"\n## 背景\n1. 命令行脚本只能运行在控制台上，在应用程序、运维框架或者监控平台中集成它们，会非常困难\n2. 很多命令行脚本都是通过连接**ZK**来提供服务的，这会存在潜在的问题，即绕过Kafka的安全设置\n3. 运行这些命令行脚本需要使用Kafka内部的类实现，也就是Kafka**服务端**的代码\n    - 社区是希望用户使用Kafka**客户端**代码，通过**现有的请求机制**来运维管理集群\n4. 基于上述原因，社区于**0.11**版本正式推出**Java客户端版的KafkaAdminClient**\n\n<!-- more -->\n\n## 功能\n1. **主题管理**\n    - 主题的创建、删除、查询\n2. **权限管理**\n    - 具体权限的配置和删除\n3. **配置参数管理**\n    - Kafka各种资源（Broker、主题、用户、Client-Id等）的参数设置、查询\n4. **副本日志管理**\n    - 副本底层日志路径的变更和详情查询\n5. **分区管理**\n    - 创建额外的主题分区\n6. **消息删除**\n    - 删除指定位移之前的分区消息\n7. **Delegation Token管理**\n    - Delegation Token的创建、更新、过期、查询\n8. **消费者组管理**\n    - 消费者组的查询、位移查询和删除\n9. **Preferred领导者选举**\n    - 推选指定主题分区的Preferred Broker为领导者\n\n## 工作原理\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-admin-client.png\" width=1000/>\n\n1. KafkaAdminClient是**双线程**设计\n    - **前端主线程**\n        - 负责将用户要执行的**操作**转换成对应的**请求**，然后将请求发送到后端IO线程的队列中\n    - **后端IO线程**\n        - 从队列中读取相应的请求，再发送到对应的Broker节点上，之后把执行结果保存起来，等待前端线程的获取\n2. KafkaAdminClient在内部大量使用**生产者-消费者**模式将请求生成和处理解耦\n3. 前端主线程会创建名为**Call**的请求对象实例，该实例有两个主要任务\n    - **构建对应的请求对象**\n        - 创建主题：CreateTopicsRequest\n        - 查询消费者组位移：OffsetFetchRequest\n    - **指定响应的回调逻辑**\n        - 比如从Broker端接收到CreateTopicsResponse之后要执行的动作\n4. 后端IO线程使用了3个队列来承载不同时期的请求对象，分别为**新请求队列**、**待发送请求队列**和**处理中请求队列**\n    - 原因：**新请求队列的线程安全**是由Java的**Monitor锁**来保证的\n        - 为了保证前端线程不会因为Monitor锁被**阻塞**，后端IO线程会**定期**地将**新请求队列**中的**所有Call实例**全部搬移到**待发送请求队列**中进行处理\n    - **待发送请求队列**和**处理中请求队列**只由**后端IO线程**处理，因为**无需任何锁机制来保证线程安全**\n    - 当后端IO线程在处理某个请求时，会**显式**地将请求保存在**处理中请求队列**\n        - 一旦**处理完毕**，后端IO线程会自动调用Call对象中的**回调逻辑**完成最后的处理\n    - 最后，后端IO线程会通知前端主线程说结果已经准备完毕，这样前端主线程就能够及时获取到执行操作的结果\n        - KafkaAdminClient是使用了Object的**wait**和**notify**来实现**通知**机制\n    - KafkaAdminClient并没有使用Java已有的队列去实现请求队列\n        - 而是使用**ArrayList**和**HashMap**等简单容器，再配合**Monitor锁**来保证线程安全\n    - 后端线程名称：**`kafka-admin-client-thread`**，可以用**`jstack`**去确认程序是否正常工作\n        - 后端IO线程可能由于**未捕获某些异常**而意外挂掉\n\n## 应用场景\n\n### 创建主题\n```java\nProperties props = new Properties();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");\nprops.put(\"request.timeout.ms\", 600000);\nString newTopicName = \"test-topic\";\ntry (AdminClient client = AdminClient.create(props)) {\n    NewTopic newTopic = new NewTopic(newTopicName, 10, (short) 1);\n    CreateTopicsResult result = client.createTopics(Collections.singletonList(newTopic));\n    result.all().get(10, TimeUnit.SECONDS);\n}\n```\n\n### 查询消费者组位移\n```java\nString groupId = \"zhongmingmao\";\ntry (AdminClient client = AdminClient.create(props)) {\n    ListConsumerGroupOffsetsResult result = client.listConsumerGroupOffsets(groupId);\n    Map<TopicPartition, OffsetAndMetadata> offsets = result.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);\n    System.out.println(offsets);\n}\n```\n\n### 获取Broker磁盘占用\n```java\ntry (AdminClient client = AdminClient.create(props)) {\n    // 获取指定Broker上所有分区主题的日志路径信息\n    DescribeLogDirsResult ret = client.describeLogDirs(Collections.singletonList(0)); // 指定Broker id\n    long size = 0L;\n    for (Map<String, DescribeLogDirsResponse.LogDirInfo> logDirInfoMap : ret.all().get().values()) {\n        size += logDirInfoMap.values().stream().map(logDirInfo -> logDirInfo.replicaInfos).flatMap(\n                topicPartitionReplicaInfoMap ->\n                        topicPartitionReplicaInfoMap.values().stream().map(replicaInfo -> replicaInfo.size))\n                .mapToLong(Long::longValue).sum();\n    }\n    System.out.println(size); // 264599218\n}\n```","tags":["Stream"],"categories":["Kafka"]},{"title":"Kafka -- 常用脚本","url":"%2F2019%2F09%2F27%2Fkafka-shell%2F","content":"\n## 脚本列表\n```\nconnect-distributed              kafka-consumer-perf-test         kafka-reassign-partitions        kafka-verifiable-producer\nconnect-standalone               kafka-delegation-tokens          kafka-replica-verification       trogdor\nkafka-acls                       kafka-delete-records             kafka-run-class                  zookeeper-security-migration\nkafka-broker-api-versions        kafka-dump-log                   kafka-server-start               zookeeper-server-start\nkafka-configs                    kafka-log-dirs                   kafka-server-stop                zookeeper-server-stop\nkafka-console-consumer           kafka-mirror-maker               kafka-streams-application-reset  zookeeper-shell\nkafka-console-producer           kafka-preferred-replica-election kafka-topics\nkafka-consumer-groups            kafka-producer-perf-test         kafka-verifiable-consumer\n```\n\n<!-- more -->\n\n## kafka-broker-api-versions\n```\nkafka-broker-api-versions --bootstrap-server localhost:9092\nlocalhost:9092 (id: 0 rack: null) -> (\n\tProduce(0): 0 to 7 [usable: 7],\n\tFetch(1): 0 to 11 [usable: 11],\n\tListOffsets(2): 0 to 5 [usable: 5],\n\tMetadata(3): 0 to 8 [usable: 8],\n\tLeaderAndIsr(4): 0 to 2 [usable: 2],\n    ...\n)\n```\n1. kafka-broker-api-versions脚本用于验证**不同Kafka版本**之间**服务器**和**客户端**的适配性\n2. `Produce(0): 0 to 7 [usable: 7]`\n    - Produce请求，序号为0，表示Kafka所有请求类型中的**第一号**请求\n    - `0 to 7`表示Produce请求在Kafka 2.3中总共有**8个版本**\n    - `usable: 7`表示当前连入这个Broker的客户端API能够使用的版本号是7，即**最新版本**\n3. 在**0.10.2.0**之前，Kafka是**单向兼容**的，即高版本的Broker能够处理低版本Client发送的请求，反正则不行\n4. 从**0.10.2.0**开始，Kafka正式支持**双向兼容**，即_**低版本的Broker也能处理高版本Client的请求**_\n\n## kafka-console-producer\n```\n$ kafka-console-producer --broker-list localhost:9092 --topic zhongmingmao --request-required-acks -1 --producer-property compression.type=lz4\n>hello world\n>\n```\n\n## kafka-console-consumer\n如果没有指定`group`，每次运行Console Consumer，都会**自动生成一个新的消费者组**（console-consumer开头）来消费\n`--from-beginning`等同于将Consumer端参数`auto.offset.reset`设置为**`Earliest`**（默认值为`Latest`）\n```\n$ kafka-console-consumer --bootstrap-server localhost:9092 --topic zhongmingmao --group zhongmingmao --from-beginning --consumer-property enable.auto.commit=false\nhello world\n```\n\n## kafka-producer-perf-test\n向指定专题发送1千万条消息，每条消息大小为**1KB**，一般关注**99th**分位即可，可以作为该生产者对外承诺的**SLA**\n```\n$ kafka-producer-perf-test --topic zhongmingmao --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=localhost:9092 acks=-1 linger.ms=2000 compression.type=lz4\n24041 records sent, 4802.4 records/sec (4.69 MB/sec), 2504.6 ms avg latency, 3686.0 ms max latency.\n374745 records sent, 74829.3 records/sec (73.08 MB/sec), 3955.9 ms avg latency, 4258.0 ms max latency.\n530462 records sent, 106092.4 records/sec (103.61 MB/sec), 5043.2 ms avg latency, 5979.0 ms max latency.\n973178 records sent, 194402.3 records/sec (189.85 MB/sec), 4616.0 ms avg latency, 6092.0 ms max latency.\n1114737 records sent, 222858.3 records/sec (217.64 MB/sec), 3226.9 ms avg latency, 3501.0 ms max latency.\n1274003 records sent, 254647.8 records/sec (248.68 MB/sec), 2967.1 ms avg latency, 3258.0 ms max latency.\n1315568 records sent, 262798.2 records/sec (256.64 MB/sec), 2655.6 ms avg latency, 2790.0 ms max latency.\n1384239 records sent, 276847.8 records/sec (270.36 MB/sec), 2665.2 ms avg latency, 2799.0 ms max latency.\n1419418 records sent, 283883.6 records/sec (277.23 MB/sec), 2509.9 ms avg latency, 2612.0 ms max latency.\n10000000 records sent, 201751.200420 records/sec (197.02 MB/sec), 3041.05 ms avg latency, 6092.00 ms max latency, 2684 ms 50th, 5500 ms 95th, 5999 ms 99th, 6085 ms 99.9th.\n```\n\n## kafka-consumer-perf-test\n```\n$ kafka-consumer-perf-test --broker-list localhost:9092 --messages 10000000 --topic zhongmingmao\nstart.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec\n2019-09-27 19:46:34:219, 2019-10-30 19:46:52:092, 9765.6250, 546.3898, 10000002, 559503.2731, 50, 17823, 547.9226, 561072.8834\n```\n\n## 查看主题消息总数\n```\n$ \n$ kafka-run-class kafka.tools.GetOffsetShell --broker-list localhost:9092 --time -2 --topic zhongmingmao\nzhongmingmao:0:0\n\n$ kafka-run-class kafka.tools.GetOffsetShell --broker-list localhost:9092 --time -1 --topic zhongmingmao\nzhongmingmao:0:10000002\n```\n\n## 查看消息文件数据\n`--files`显式的是消息批次或消息集合的**元数据**信息\n```\n$ kafka-dump-log --files /usr/local/var/lib/kafka-logs/zhongmingmao-0/00000000000000000000.log | head -n 10\nDumping /usr/local/var/lib/kafka-logs/zhongmingmao-0/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 0 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1572434815538 size: 79 magic: 2 compresscodec: NONE crc: 234703942 isvalid: true\nbaseOffset: 1 lastOffset: 1 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 79 CreateTime: 1572434920055 size: 69 magic: 2 compresscodec: NONE crc: 1305542871 isvalid: true\nbaseOffset: 2 lastOffset: 16 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 148 CreateTime: 1572435583918 size: 1241 magic: 2 compresscodec: LZ4 crc: 3547131642 isvalid: true\nbaseOffset: 17 lastOffset: 31 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1389 CreateTime: 1572435583920 size: 1238 magic: 2 compresscodec: LZ4 crc: 2462803486 isvalid: true\nbaseOffset: 32 lastOffset: 46 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 2627 CreateTime: 1572435583924 size: 1238 magic: 2 compresscodec: LZ4 crc: 2150713960 isvalid: true\nbaseOffset: 47 lastOffset: 61 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 3865 CreateTime: 1572435583926 size: 1239 magic: 2 compresscodec: LZ4 crc: 1263953458 isvalid: true\nbaseOffset: 62 lastOffset: 76 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 5104 CreateTime: 1572435583932 size: 1238 magic: 2 compresscodec: LZ4 crc: 2346030242 isvalid: true\nbaseOffset: 77 lastOffset: 91 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 6342 CreateTime: 1572435583936 size: 1238 magic: 2 compresscodec: LZ4 crc: 1966965031 isvalid: true\n```\n`--deep-iteration`用于查看每条**具体**的消息\n```\n\n$ kafka-dump-log --files /usr/local/var/lib/kafka-logs/zhongmingmao-0/00000000000000000000.log --deep-iteration | head -n 25\nDumping /usr/local/var/lib/kafka-logs/zhongmingmao-0/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 0 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1572434815538 size: 79 magic: 2 compresscodec: NONE crc: 234703942 isvalid: true\n| offset: 0 CreateTime: 1572434815538 keysize: -1 valuesize: 11 sequence: -1 headerKeys: []\nbaseOffset: 1 lastOffset: 1 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 79 CreateTime: 1572434920055 size: 69 magic: 2 compresscodec: NONE crc: 1305542871 isvalid: true\n| offset: 1 CreateTime: 1572434920055 keysize: -1 valuesize: 1 sequence: -1 headerKeys: []\nbaseOffset: 2 lastOffset: 16 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 148 CreateTime: 1572435583918 size: 1241 magic: 2 compresscodec: LZ4 crc: 3547131642 isvalid: true\n| offset: 2 CreateTime: 1572435583623 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n| offset: 3 CreateTime: 1572435583916 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n| offset: 4 CreateTime: 1572435583916 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n| offset: 5 CreateTime: 1572435583917 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n| offset: 6 CreateTime: 1572435583917 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n| offset: 7 CreateTime: 1572435583917 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n| offset: 8 CreateTime: 1572435583917 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n| offset: 9 CreateTime: 1572435583917 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n| offset: 10 CreateTime: 1572435583917 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n| offset: 11 CreateTime: 1572435583917 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n| offset: 12 CreateTime: 1572435583918 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n| offset: 13 CreateTime: 1572435583918 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n| offset: 14 CreateTime: 1572435583918 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n| offset: 15 CreateTime: 1572435583918 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n| offset: 16 CreateTime: 1572435583918 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\nbaseOffset: 17 lastOffset: 31 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 1389 CreateTime: 1572435583920 size: 1238 magic: 2 compresscodec: LZ4 crc: 2462803486 isvalid: true\n| offset: 17 CreateTime: 1572435583918 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n| offset: 18 CreateTime: 1572435583918 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: []\n```\n`--print-data-log`用于查看**消息里面的实际数据**\n```\n$ kafka-dump-log --files /usr/local/var/lib/kafka-logs/zhongmingmao-0/00000000000000000000.log --deep-iteration --print-data-log | head -n 8\nDumping /usr/local/var/lib/kafka-logs/zhongmingmao-0/00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 0 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1572434815538 size: 79 magic: 2 compresscodec: NONE crc: 234703942 isvalid: true\n| offset: 0 CreateTime: 1572434815538 keysize: -1 valuesize: 11 sequence: -1 headerKeys: [] payload: hello world\nbaseOffset: 1 lastOffset: 1 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 79 CreateTime: 1572434920055 size: 69 magic: 2 compresscodec: NONE crc: 1305542871 isvalid: true\n| offset: 1 CreateTime: 1572434920055 keysize: -1 valuesize: 1 sequence: -1 headerKeys: [] payload: w\nbaseOffset: 2 lastOffset: 16 count: 15 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 148 CreateTime: 1572435583918 size: 1241 magic: 2 compresscodec: LZ4 crc: 3547131642 isvalid: true\n| offset: 2 CreateTime: 1572435583623 keysize: -1 valuesize: 1024 sequence: -1 headerKeys: [] payload: SSXVNJHPDQDXVCRASTVYBCWVMGNYKRXVZXKGXTSPSJDGYLUEGQFLAQLOCFLJBEPOWFNSOMYARHAOPUFOJHHDXEHXJBHWGSMZJGNLONJVXZXZOZITKXJBOZWDJMCBOSYQQKCPRRDCZWMRLFXBLGQPRPGRNTAQOOSVXPKJPJLAVSQCCRXFRROLLHWHOHFGCFWPNDLMWCSSHWXQQYKALAAWCMXYLMZALGDESKKTEESEMPRHROVKUMPSXHELIDQEOOHOIHEGJOAZBVPUMCHSHGXZYXXQRUICRIJGQEBBWAXABQRIRUGZJUUVFYQOVCDEDXYFPRLGSGZXSNIAVODTJKSQWHNWVPSAMZKOUDTWHIORJSCZIQYPCZMBYWKDIKOKYNGWPXZWMKRDCMBXKFUILWDHBFXRFAOPRUGDFLPDLHXXCXCUPLWGDPPHEMJGMTVMFQQFVCUPOFYWLDUEBICKPZKHKVMCJVWVKTXBKAPWAPENUEZNWNWDCACDRLPIPHJQQKMOFDQSPKKNURFBORJLBPCBIWTSJNPRBNITTKJYWAHWGKZYNUSFISPIYPIOGAUPZDXHCFVGXGIVVCPFHIXAACZXZLFDMOOSSNTKUPJQEIRRQAMUCTBLBSVPDDYOIHAOODZNJTVHDCIEGTAVMYZOCIVSKUNSMXEKBEWNZPRPWPUJABJXNQBOXSHOEGMJSNBUTGTIFVEQPSYBDXEXORPQDDODZGBELOISTRWXMEYWVVHGMJKWLJCCHPKAFRASZEYQZCVLFSLOWTLBMPPWPPFPQSAZPTULSTCDMODYKZGSRFQTRFTGCNMNXQQIYVUQZHVNIPHZWVBSGOBYIFDNNXUTBBQUYNXOZCSICGRTZSSRHROJRGBHMHEQJRDLOQBEPTOBMYLMIGPPDPOLTEUVDGATCGYPQOGOYYESKEGBLOCBIYSLQEYGCCIPBXPNSPKDYTBEWDHBHWVDPLOVHJPNYGJUHKKHDASNFGZDAIWWQEPPBRJKDGOSAFAPRLWFFXRVMZQTKRYF\n```\n\n## 查询消费者组位移\n`CURRENT-OFFSET`表示该消费者当前消费的最新位移，`LOG-END-OFFSET`表示对应分区最新生产消息的位移\n```\n$ kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group zhongmingmao\n\nGROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                     HOST            CLIENT-ID\nzhongmingmao    zhongmingmao    0          -               10000002        -               consumer-1-338796c8-e062-47e5-94d0-ed8d686a004f /127.0.0.1      consumer-1\n```","tags":["Stream"],"categories":["Kafka"]},{"title":"Kafka -- 重设消费者组位移","url":"%2F2019%2F09%2F26%2Fkafka-reset-consumer-group-offset%2F","content":"\n## 背景\n1. Kafka和传统的消息引擎在设计上有很大的区别，Kafka消费者读取消息是可以**重演**的\n2. 像RabbitMQ和ActiveMQ等传统消息中间件，处理和响应消息的方式是**破坏性**\n    - 一旦消息被成功处理，就会从Broker上被**删除**\n3. Kafka是基于**日志**结构（Log-based）的消息引擎\n    - 消费者在消费消息时，仅仅是从磁盘文件中读取数据而已，是**只读**操作，因为消费者**不会删除**消息数据\n    - 同时，由于位移数据是由消费者控制的，因此能够很容易地修改位移值，实现**重复消费**历史数据的功能\n4. Kafka Or 传统消息中间件\n    - 传统消息中间件：消息处理逻辑非常复杂，处理代价高、又**不关心消息之间的顺序**\n    - Kafka：需要**较高的吞吐量**、但**每条消息的处理时间很短**，又**关心消息的顺序**\n\n<!-- more -->\n\n## 重设位移策略\n1. **位移**维度\n    - 直接把消费者的位移值重设成给定的位移值\n2. **时间**维度\n    - 给定一个时间，让消费者把位移调整成**大于该时间的最小位移**\n\n| 维度 | 策略 | 含义 |\n| --- | --- | --- |\n| 位移维度 | **Earliest** | 把位移调整到**当前最早**位移处 |\n| | **Latest** | 把位移调整到**当前最新**位移处 |\n| | **Current** | 把位移调整到**当前最新提交**位移处 |\n| | **Specified-Offset** | 把位移调整成**指定位移** |\n| | **Shift-By-N** | 把位移调整成到**当前位移+N**处（N可以是**负值**） |\n| 时间维度 | **DateTime** | 把位移调整到**大于给定时间的最小位移**处 |\n| | **Duration** | 把位移调整到**距离当前时间指定间隔的位移**处 |\n\n1. **Earliest**\n    - **最早位移不一定是0**，在生产环境中，很久远的消息会被Kafka**自动删除**\n    - 如果想要**重新消费主题的所有消息**，可以使用Earliest策略\n2. **Latest**\n    - 如果想要**跳过所有历史消息**，打算从最新的消息处开始消费，可以使用Latest策略\n3. **Specified-Offset**\n    - 典型使用场景：消费者程序在处理某条**错误消息**时，可以**手动跳过**此消息的处理\n4. **Duration**\n    - 格式为`PnDTnHnMnS`，**D**、**H**、**M**、**S**分别代表天、小时、分钟、秒\n    - 如果想将位移调回到15分钟前，可以指定**`PT0H15M0S`**\n\n## 重设位移方式\n\n### 消费者API\n```java\n// org.apache.kafka.clients.consumer.Consumer\nvoid seek(TopicPartition partition, long offset);\nvoid seekToBeginning(Collection<TopicPartition> partitions);\nvoid seekToEnd(Collection<TopicPartition> partitions);\n```\n1. 每次调用`seek`方法**只能重设一个分区的位移**\n2. `seekToBeginning`和`seekToEnd`可以一次性重设多个分区\n\n#### Earliest\n```java\nProperties consumerProperties = new Properties();\n// 禁止自动提交位移\nconsumerProperties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);\nconsumerProperties.put(ConsumerConfig.GROUP_ID_CONFIG, \"zhongmingmao\");\nconsumerProperties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\nconsumerProperties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\nconsumerProperties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\nconsumerProperties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");\n\nString topic = \"zhongmingmao\";  // 要重设位移的Kafka主题\ntry (final KafkaConsumer<String, String> consumer = new KafkaConsumer<>(consumerProperties)) {\n    consumer.subscribe(Collections.singleton(topic));\n    // 调用consumer.poll(0)，不要调用consumer.poll(Duration.ofSecond(0))\n    consumer.poll(0);\n    // 一次性构造主题的所有分区对象\n    consumer.seekToBeginning(consumer.partitionsFor(topic).stream().map(\n            partitionInfo -> new TopicPartition(topic, partitionInfo.partition())).collect(Collectors.toList()));\n}\n```\n\n#### Latest\n```java\nconsumer.seekToEnd(consumer.partitionsFor(topic).stream().map(\n        partitionInfo -> new TopicPartition(topic, partitionInfo.partition())).collect(Collectors.toList()));\n```\n\n#### Current\n```java\nconsumer.partitionsFor(topic).stream().map(\n        info -> new TopicPartition(topic, info.partition())).forEach(\n        tp -> {\n            // 通过committed方法获取分区当前提交的最新位移\n            long committedOffset = consumer.committed(tp).offset();\n            consumer.seek(tp, committedOffset);\n        });\n```\n\n#### Specified-Offset\n```java\nlong targetOffset = 1234L;\nfor (PartitionInfo info : consumer.partitionsFor(topic)) {\n    TopicPartition tp = new TopicPartition(topic, info.partition());\n    consumer.seek(tp, targetOffset);\n}\n```\n\n#### Shift-By-N\n```java\nfor (PartitionInfo info : consumer.partitionsFor(topic)) {\n    TopicPartition tp = new TopicPartition(topic, info.partition());\n    // 假设向前跳123条消息\n    long targetOffset = consumer.committed(tp).offset() + 123L;\n    consumer.seek(tp, targetOffset);\n}\n```\n\n#### DateTime\n```java\nlong ts = LocalDateTime.of(2019, 6, 20, 20, 0)\n        .toInstant(ZoneOffset.ofHours(8)).toEpochMilli();\n// 查找对应的位移值\nMap<TopicPartition, Long> timeToSearch =\n        consumer.partitionsFor(topic).stream().map(info ->\n                new TopicPartition(topic, info.partition()))\n                .collect(Collectors.toMap(Function.identity(), tp -> ts));\n\n// offsetsForTimes\nfor (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : consumer.offsetsForTimes(timeToSearch).entrySet()) {\n    consumer.seek(entry.getKey(), entry.getValue().offset());\n}\n```\n\n#### Duration\n```java\nMap<TopicPartition, Long> timeToSearch = consumer.partitionsFor(topic).stream().map(\n        info -> new TopicPartition(topic, info.partition()))\n        .collect(Collectors.toMap(Function.identity(), tp -> System.currentTimeMillis() - 30 * 1000 * 60));\n\nfor (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : consumer.offsetsForTimes(timeToSearch).entrySet()) {\n    consumer.seek(entry.getKey(), entry.getValue().offset());\n}\n```\n\n### 命令行工具\n从Kafka **0.11**版本开始引入\n\n#### Earliest\n`--to-earliest`\n```\n$ kafka-consumer-groups --bootstrap-server localhost:9092 --group test-group --reset-offsets --all-topics --to-earliest --execute\n```\n\n#### Latest\n`--to-latest`\n```\n$ kafka-consumer-groups --bootstrap-server localhost:9092 --group test-group --reset-offsets --all-topics --to-latest --execute\n```\n\n#### Current\n`--to-current`\n```\n$ kafka-consumer-groups --bootstrap-server localhost:9092 --group test-group --reset-offsets --all-topics --to-current --execute\n```\n\n#### Specified-Offset\n`--to-offset`\n```\n$ kafka-consumer-groups --bootstrap-server localhost:9092 --group test-group --reset-offsets --all-topics --to-offset <offset> --execute\n```\n\n#### Shift-By-N\n`--shift-by`\n```\n$ kafka-consumer-groups --bootstrap-server localhost:9092 --group test-group --reset-offsets --shift-by <offset_N> --execute\n```\n\n#### DateTime\n`--to-datetime`\n```\n$ kafka-consumer-groups --bootstrap-server localhost:9092 --group test-group --reset-offsets --to-datetime 2019-09-26T00:00:00.000 --execute\n```\n\n#### Duration\n`--by-duration`\n```\n$ kafka-consumer-groups --bootstrap-server localhost:9092 --group test-group --reset-offsets --by-duration PT0H30M0S --execute\n```","tags":["Stream"],"categories":["Kafka"]},{"title":"Kafka -- 动态配置","url":"%2F2019%2F09%2F25%2Fkafka-dynamic-config%2F","content":"\n## 背景\n1. Kafka安装目录的config路径下，有`server.properties`文件\n    - 通常情况下，会指定`server.properties`来启动Broker\n    - 如果要设置Broker端的任何参数，必须要显式修改`server.properties`，然后重启Broker，让参数生效\n    - 但在生产环境，不能随意重启Broker，因此需要能够**动态**修改Broker端参数\n2. 社区于**1.1.0**正式引入了**动态Broker参数**\n    - 动态指的是修改参数后，无需重启Broker就能立即生效，而之前`server.properties`中配置的参数称为**静态参数**\n3. 并非所有Broker端参数都可以动态调整的，官方文档中有`Dynamic Update Mode`一列\n    - **read-only**\n        - 与原来的参数行为一样，只有重启Broker，才能令修改生效\n    - **per-broker**\n        - **动态参数**，修改之后，只会在**对应的Broker**上生效\n    - **cluster-wide**\n        - **动态参数**，修改之后，会在**整个集群**范围内生效\n\n<!-- more -->\n\n## 使用场景\n1. 动态调整Broker端各种**线程池大小**，实时应对**突发流量** -- 比较常用\n2. 动态调整Broker端连接信息或安全配置信息\n3. 动态更新SSL KeyStore有效期\n4. 动态调整Broker端Compact操作性能\n5. 实时变更JMX指标收集器（JMX Metrics Reporter）\n\n## 保存机制\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-dynamic-config-znode.png\" width=1000/>\n\n1. Kafka将**动态Broker参数**保存在**ZK**中\n2. `changes`节点用来**实时监测动态参数变更**的，**不会保存参数值**\n3. `topics`节点用来保存Kafka**主题级别**参数的\n4. `users`节点和`clients`节点用来**动态调整客户端配额**\n    - 配额：限制连入集群的客户端的**吞吐量**或**使用的CPU资源**\n5. `brokers`节点用来保存**动态Broker端参数**\n    - `<default>`节点用来保存`cluster-wide`范围的动态参数\n    - `broker_id`节点用来保存特定Broker的`per-broker`范围的动态参数\n6. 参数优先级\n    - _**`per-broker`参数 > `cluster-wide`参数 > static参数 > Kafka默认值**_\n7. 下图中的**ephemeralOwner**字段都是`0x0`，表示这些znode都是**持久化节点**，即使ZK集群重启，动态参数也不会丢失\n\n```\n[zk: localhost:2181(CONNECTED) 21] ls /config\n[changes, clients, brokers, topics, users]\n\n[zk: localhost:2181(CONNECTED) 22] ls /config/brokers\n[0, <default>]\n\n[zk: localhost:2181(CONNECTED) 23] get /config/brokers/<default>\n{\"version\":1,\"config\":{\"unclean.leader.election.enable\":\"true\"}}\ncZxid = 0xe89\nctime = Thu Oct 24 09:28:50 CST 2019\nmZxid = 0xe89\nmtime = Thu Oct 24 09:28:50 CST 2019\npZxid = 0xe89\ncversion = 0\ndataVersion = 0\naclVersion = 0\nephemeralOwner = 0x0\ndataLength = 64\nnumChildren = 0\n\n[zk: localhost:2181(CONNECTED) 24] get /config/brokers/0\n{\"version\":1,\"config\":{\"leader.replication.throttled.rate\":\"104857600\",\"follower.replication.throttled.rate\":\"104857600\"}}\ncZxid = 0xdef\nctime = Mon Oct 21 09:50:13 CST 2019\nmZxid = 0xe07\nmtime = Mon Oct 21 10:07:23 CST 2019\npZxid = 0xdef\ncversion = 0\ndataVersion = 1\naclVersion = 0\nephemeralOwner = 0x0\ndataLength = 122\nnumChildren = 0\n```\n\n## 配置命令\n\n### 设置cluster-wide参数\n如果要设置`cluster-wide`范围的动态参数，需要显式指定**`entity-default`**\n```\n$ kafka-configs --bootstrap-server localhost:9092 --entity-type brokers --entity-default --alter --add-config unclean.leader.election.enable=true\nCompleted updating default config for brokers in the cluster,\n```\n查看配置是否成功，`sensitive=false`表明**要调整的参数不是敏感数据**\n```\n$ kafka-configs --bootstrap-server localhost:9092 --entity-type brokers --entity-default --describe\nDefault config for brokers in the cluster are:\n  unclean.leader.election.enable=true sensitive=false synonyms={DYNAMIC_DEFAULT_BROKER_CONFIG:unclean.leader.election.enable=true}\n```\n\n### 设置per-broker参数\n```\n$ kafka-configs --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --alter --add-config unclean.leader.election.enable=false,leader.replication.throttled.rate=104857600,follower.replication.throttled.rate=104857600\nCompleted updating config for broker: 0.\n```\n查看配置是否成功，重点关注\n实际值：`unclean.leader.election.enable=false`\nper-broker参数：`DYNAMIC_BROKER_CONFIG:unclean.leader.election.enable=false`\ncluster-wide参数：`DYNAMIC_DEFAULT_BROKER_CONFIG:unclean.leader.election.enable=true`\nKafka默认值：`DEFAULT_CONFIG:unclean.leader.election.enable=false`\n```\n$ kafka-configs --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --describe\nConfigs for broker 0 are:\n  leader.replication.throttled.rate=null sensitive=true synonyms={DYNAMIC_BROKER_CONFIG:leader.replication.throttled.rate=null}\n  follower.replication.throttled.rate=null sensitive=true synonyms={DYNAMIC_BROKER_CONFIG:follower.replication.throttled.rate=null}\n  unclean.leader.election.enable=false sensitive=false synonyms={DYNAMIC_BROKER_CONFIG:unclean.leader.election.enable=false, DYNAMIC_DEFAULT_BROKER_CONFIG:unclean.leader.election.enable=true, DEFAULT_CONFIG:unclean.leader.election.enable=false}\n```\n\n### 删除cluster-wide参数\n```\n$ kafka-configs --bootstrap-server localhost:9092 --entity-type brokers --entity-default --alter --delete-config unclean.leader.election.enable\nCompleted updating default config for brokers in the cluster,\n\n$ kafka-configs --bootstrap-server localhost:9092  --entity-type brokers --entity-default --describe\nDefault config for brokers in the cluster are:\n```\n\n### 删除per-broker参数\n```\n$ kafka-configs --bootstrap-server localhost:9092 --entity-type brokers --entity-name 0 --alter --delete-config unclean.leader.election.enable,leader.replication.throttled.rate,follower.replication.throttled.rate\nCompleted updating config for broker: 0.\n\n$ kafka-configs --bootstrap-server localhost:9092  --entity-type brokers --entity-name 0 --describe\nConfigs for broker 0 are:\n```\n\n## 常用动态参数\n\n1. log.retention.ms\n    - 修改**日志留存时间**\n2. num.io.threads、num.network.threads\n    - 实现生产环境**动态按需扩容**\n3. 与SSL相关：ssl.keystore.type、ssl.keystore.location、ssl.keystore.password 和 ssl.key.password\n    - 允许动态实时调整这些参数后，可以创建那些**过期时间很短的SSL证书**\n    - 每当调整这些参数后，Kafka底层会**重新配置Socket连接通道并更新Keystore**\n    - 新的连接会使用新的Keystore，**阶段性地调整这些参数，有利于增加安全性**\n4. num.replica.fetchers\n    - **提高Follower拉取副本的速度**","tags":["Stream"],"categories":["Kafka"]},{"title":"Java性能 -- 高性能SQL","url":"%2F2019%2F09%2F24%2Fjava-performance-high-performance-sql%2F","content":"\n## 慢SQL诱因\n1. **无索引**、**索引失效**\n2. **锁等待**\n    - **InnoDB**支持**行锁**，**MyISAM**支持**表锁**\n    - InnoDB支持行锁更适合**高并发**场景，但行锁有可能会**升级为表锁**\n        - 一种情况是在**批量更新**时\n        - 行锁是基于**索引**加的锁，如果在**更新**操作时，**条件索引失效**，那么行锁会升级为表锁\n    - 基于**表锁**的数据库操作，会导致**SQL阻塞等待**，影响执行速度\n        - 在**写大于读**的情况下，不建议使用MyISAM\n    - 行锁相对于表锁，虽然粒度更细，并发能力提升，但也带来了新的问题，那就是**死锁**\n3. **不恰当的SQL**\n    - `SELECT *`\n    - `SELECT COUNT(*)`\n    - **大表**中使用`LIMIT M,N`\n    - 对**非索引字段**进行**排序**\n\n<!-- more -->\n\n## SQL诊断\n\n### EXPLAIN\n1. **id**：每个执行计划都有一个id，如果是一个联合查询，会有多个id\n2. **select_type**\n    - **SIMPLE**：普通查询，即没有联合查询、子查询\n    - **PRIMARY**：主查询\n    - **UNION**：UNION中后面的查询\n    - **SUBQUERY**：子查询\n3. **table**：当前执行计划查询的表，如果表有别名，则显示别名\n4. **partitions**：分区表信息\n5. **type**\n    - 从表中**查询到行**所执行的方式\n    - 由好到坏：_**`system > const > eq_ref > ref > range > index > ALL`**_\n    - **system/const**\n        - 表中只有**一行**数据匹配，**根据索引查询一次**就能找到对应的数据\n    - **eq_ref**\n        - 使用**唯一索引**扫描，常见于**多表连接**中使用**主键**和**唯一索引**作为**关联条件**\n    - **ref**\n        - 使用**非唯一索引**扫描，还可见于**唯一索引最左原则**匹配扫描\n    - **range**\n        - **索引范围扫描**，如`<`、`>`、`between`等操作\n    - **index**\n        - **索引全表扫描**，遍历整个索引树\n    - **ALL**\n        - **全表扫描**，遍历全表来找到对应的行\n6. **possible_keys**：可能使用到的索引\n7. **key**：实际使用到的索引\n8. **key_len**：当前使用的索引的长度，单位**Byte**\n9. **ref**：关联id等信息\n10. **rows**：查找到记录所**扫描**的行数\n11. **filtered**：查找到所需记录占总扫描记录数的**比例**\n12. **Extra**：额外信息\n\n### Show Profile\n1. 通过**EXPLAIN**分析执行计划，仅仅停留在分析SQL的**外部执行情况**\n    - 如果需要深入**MySQL内核**，从执行线程的状态和时间来分析，就需要选择**Profile**\n2. Profile除了可以分析**执行线程**的**状态**和**时间**\n    - 还支持查询在**ALL、CPU、MEMORY、BLOCK IO、CONTEXT SWITCHES**上所消耗的时间\n3. MySQL是从**5.0.37**才开始支持`Show Profile`\n4. `Show Profile`只显示最新发给服务器的SQL语句，默认记录**最新15条**\n    - 可以设置`profiling_history_size`，最大值为**100**\n\n```\nSHOW PROFILE [type [, type] ... ]\n[FOR QUERY n]\n[LIMIT row_count [OFFSET offset]]\n\ntype参数：\n| ALL：显示所有开销信息\n| BLOCK IO：阻塞的输入输出次数\n| CONTEXT SWITCHES：上下文切换相关开销信息\n| CPU：显示CPU的相关开销信息 \n| IPC：接收和发送消息的相关开销信息\n| MEMORY：显示内存相关的开销，目前无用\n| PAGE FAULTS：显示页面错误相关开销信息\n| SOURCE：列出相应操作对应的函数名及其在源码中的调用位置(行数) \n| SWAPS：显示swap交换次数的相关开销信息\n```\n\n```sql\nmysql> select @@version;\n+------------+\n| @@version  |\n+------------+\n| 5.6.37-log |\n+------------+\n\nmysql> select @@have_profiling;\n+------------------+\n| @@have_profiling |\n+------------------+\n| YES              |\n+------------------+\n\nmysql> select @@profiling_history_size;\n+--------------------------+\n| @@profiling_history_size |\n+--------------------------+\n|                       15 |\n+--------------------------+\n\nmysql> select @@profiling;\n+-------------+\n| @@profiling |\n+-------------+\n|           0 |\n+-------------+\n\nmysql> set profiling = 1;\n\nmysql> select @@profiling;\n+-------------+\n| @@profiling |\n+-------------+\n|           1 |\n+-------------+\n\nmysql> show profiles;\n+----------+------------+---------------------------+\n| Query_ID | Duration   | Query                     |\n+----------+------------+---------------------------+\n|        1 | 0.03954925 | SELECT @@profiling        |\n|        2 | 0.01086300 | SELECT COUNT(1) FROM XXXX |\n+----------+------------+---------------------------+\n\nmysql> show profile for query 2;\n+----------------------+----------+\n| Status               | Duration |\n+----------------------+----------+\n| starting             | 0.000032 |\n| checking permissions | 0.000007 |\n| Opening tables       | 0.000012 |\n| init                 | 0.000009 |\n| System lock          | 0.000009 |\n| optimizing           | 0.000014 |\n| statistics           | 0.000013 |\n| preparing            | 0.000012 |\n| executing            | 0.000008 |\n| Sending data         | 0.010665 |\n| end                  | 0.000009 |\n| query end            | 0.000008 |\n| closing tables       | 0.000038 |\n| freeing items        | 0.000016 |\n| cleaning up          | 0.000012 |\n+----------------------+----------+\n```\n\n## SQL优化\n\n### 优化分页查询\n1. 经常使用`LIMIT M,N`+`ORDER BY`来实现分页查询\n    - 在**没有任何索引条件支持**的情况下，需要做**大量的文件排序**操作（**file sort**），**性能很差**\n    - 即便有对应的索引，也只是在刚开始时效率比较理想，**越往后，性能越差**\n        - 使用`LIMIT M,N`时，**偏移量M越大**，数据库**检索的数据也会越多**\n        - 例如`LIMIT 10000,10`，数据库需要检索10010条记录，但最后只返回10条记录\n2. 优化方案：**子查询** + **覆盖索引**\n\n```sql\n-- 使用了索引，扫描了100010行\nmysql> explain select * from prop_action_reward order by create_time limit 100000,10;\n+----+-------------+--------------------+-------+---------------+-----------------+---------+------+--------+-------+\n| id | select_type | table              | type  | possible_keys | key             | key_len | ref  | rows   | Extra |\n+----+-------------+--------------------+-------+---------------+-----------------+---------+------+--------+-------+\n|  1 | SIMPLE      | prop_action_reward | index | NULL          | idx_create_time | 5       | NULL | 100010 | NULL  |\n+----+-------------+--------------------+-------+---------------+-----------------+---------+------+--------+-------+\n\n-- 耗费了0.19S，性能不太理想\nmysql> select * from prop_action_reward order by create_time limit 100000,10;\n....\n10 rows in set (0.19 sec)\n\n-- 查询获取到的100010条记录都返回给客户端了，耗时主要集中在Sending data阶段\nmysql> show profile for query 21;\n+----------------------+----------+\n| Status               | Duration |\n+----------------------+----------+\n| starting             | 0.000037 |\n| checking permissions | 0.000007 |\n| Opening tables       | 0.000016 |\n| init                 | 0.000028 |\n| System lock          | 0.000008 |\n| optimizing           | 0.000006 |\n| statistics           | 0.000010 |\n| preparing            | 0.000011 |\n| Sorting result       | 0.000005 |\n| executing            | 0.000004 |\n| Sending data         | 0.192705 |\n| end                  | 0.000018 |\n| query end            | 0.000008 |\n| closing tables       | 0.000010 |\n| freeing items        | 0.000029 |\n| cleaning up          | 0.000085 |\n+----------------------+----------+\n```\n\n```sql\n-- 子查询用到了覆盖索引（Using index），无需回表\nmysql> explain select * from prop_action_reward where id > (select id from prop_action_reward order by create_time limit 100000,1) limit 10;\n+----+-------------+--------------------+-------+---------------+-----------------+---------+------+----------+-------------+\n| id | select_type | table              | type  | possible_keys | key             | key_len | ref  | rows     | Extra       |\n+----+-------------+--------------------+-------+---------------+-----------------+---------+------+----------+-------------+\n|  1 | PRIMARY     | prop_action_reward | range | PRIMARY       | PRIMARY         | 8       | NULL | 47244120 | Using where |\n|  2 | SUBQUERY    | prop_action_reward | index | NULL          | idx_create_time | 5       | NULL | 94488240 | Using index |\n+----+-------------+--------------------+-------+---------------+-----------------+---------+------+----------+-------------+\n\n-- 耗费了0.03S，提升很大\nmysql> select * from prop_action_reward where id > (select id from prop_action_reward order by create_time limit 100000,1) limit 10;\n...\n10 rows in set (0.03 sec)\n\n-- 只会返回10条记录给客户端，所以快很多\nmysql> show profile for query 24;\n+----------------------+----------+\n| Status               | Duration |\n+----------------------+----------+\n| starting             | 0.000064 |\n| checking permissions | 0.000007 |\n| checking permissions | 0.000007 |\n| Opening tables       | 0.000019 |\n| init                 | 0.000030 |\n| System lock          | 0.000009 |\n| optimizing           | 0.000008 |\n| statistics           | 0.000022 |\n| optimizing           | 0.000007 |\n| statistics           | 0.000011 |\n| preparing            | 0.000015 |\n| Sorting result       | 0.000005 |\n| executing            | 0.000004 |\n| Sending data         | 0.028916 |\n| preparing            | 0.000013 |\n| executing            | 0.000005 |\n| Sending data         | 0.000055 |\n| end                  | 0.000006 |\n| query end            | 0.000007 |\n| closing tables       | 0.000009 |\n| freeing items        | 0.000022 |\n| cleaning up          | 0.000013 |\n+----------------------+----------+\n```\n\n### 优化SLECT COUNT(*)\n1. COUNT()是一个**聚合**函数，用来统计**行数**或**某一列的行数量**（不包括NULL值）\n2. 常用的是`COUNT(*)`和`COUNT(1)`，两者没有本质区别，在**InnoDB**，都会利用**主键列**实现行数的统计\n3. 通常**没有任何查询条件**下的`COUNT(*)`，**MyISAM的查询速度要明显快于InnoDB**\n    - 这是因为MyISAM记录了**整个表的行数**，无需遍历计算，直接获取即可，而InnoDB需要扫描表来统计具体的行数\n    - 如果带上查询条件，MyISAM和InnoDB都需要扫描表来进行行数的统计\n4. 优化方案\n    - 使用**近似值**，借助`EXPLAIN`中的`rows`\n    - 增加**汇总统计**，使用汇总统计表或缓存\n\n### 优化SLECT *\n1. 尽量使用**覆盖索引**\n\n## 记录慢SQL\n```sql\nmysql> show variables like '%slow_query%';\n+---------------------+-----------------------------------------------------+\n| Variable_name       | Value                                               |\n+---------------------+-----------------------------------------------------+\n| slow_query_log      | ON                                                  |\n| slow_query_log_file | /data_db3/mysql/3323/slowlog/slowlog_2019102209.log |\n+---------------------+-----------------------------------------------------+\n\nmysql> show variables like 'long_query_time';\n+-----------------+----------+\n| Variable_name   | Value    |\n+-----------------+----------+\n| long_query_time | 1.000000 |\n+-----------------+----------+\n```\n","tags":["Java Performance"],"categories":["Performance"]},{"title":"Kafka -- 主题管理","url":"%2F2019%2F09%2F22%2Fkafka-topic-management%2F","content":"\n## 日常管理\n\n### 创建主题\n```\n$ kafka-topics --bootstrap-server localhost:9092 --create --topic t1 --partitions 1 --replication-factor 1\n```\n1. 从Kafka **2.2**版本开始，推荐使用`--bootstrap-server`代替`--zookeeper`（标记为**已过期**）\n2. 原因\n    - 使用`--zookeeper`会绕过Kafka的**安全体系**，不受认证体系的约束\n    - 使用`--bootstrap-server`与集群交互是**未来的趋势**\n\n<!-- more -->\n\n### 查询主题列表\n```\n$ kafka-topics --bootstrap-server localhost:9092 --list\n__consumer_offsets\n_schemas\nt1\ntransaction\n```\n\n### 查询单个主题\n```\n$ kafka-topics --bootstrap-server localhost:9092 --describe --topic __consumer_offsets\nTopic:__consumer_offsets\tPartitionCount:50\tReplicationFactor:1\tConfigs:compression.type=producer,cleanup.policy=compact,segment.bytes=104857600\n    Topic: __consumer_offsets\tPartition: 0\tLeader: 0\tReplicas: 0\tIsr: 0\n    Topic: __consumer_offsets\tPartition: 1\tLeader: 0\tReplicas: 0\tIsr: 0\n    ...\n    Topic: __consumer_offsets\tPartition: 48\tLeader: 0\tReplicas: 0\tIsr: 0\n    Topic: __consumer_offsets\tPartition: 49\tLeader: 0\tReplicas: 0\tIsr: 0\n```\n\n### 增加主题分区\nKafka目前**不允许减少某个主题的分区数**，指定的分区数一定要**比原有分区数大**，否则Kafka会抛出InvalidPartitionsException\n```\n$ kafka-topics --bootstrap-server localhost:9092 --alter --topic t1 --partitions 3\n\n$ kafka-topics --bootstrap-server localhost:9092 --describe --topic t1\nTopic:t1\tPartitionCount:3\tReplicationFactor:1\tConfigs:segment.bytes=1073741824\n\tTopic: t1\tPartition: 0\tLeader: 0\tReplicas: 0\tIsr: 0\n\tTopic: t1\tPartition: 1\tLeader: 0\tReplicas: 0\tIsr: 0\n\tTopic: t1\tPartition: 2\tLeader: 0\tReplicas: 0\tIsr: 0\n\n$ kafka-topics --bootstrap-server localhost:9092 --alter --topic t1 --partitions 2\nError while executing topic command : org.apache.kafka.common.errors.InvalidPartitionsException: Topic currently has 3 partitions, which is higher than the requested 2.\n[2019-10-21 09:36:14,368] ERROR java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.InvalidPartitionsException: Topic currently has 3 partitions, which is higher than the requested 2.\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.wrapAndThrow(KafkaFutureImpl.java:45)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.access$000(KafkaFutureImpl.java:32)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl$SingleWaiter.await(KafkaFutureImpl.java:89)\n\tat org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:260)\n\tat kafka.admin.TopicCommand$AdminClientTopicService.alterTopic(TopicCommand.scala:215)\n\tat kafka.admin.TopicCommand$.main(TopicCommand.scala:62)\n\tat kafka.admin.TopicCommand.main(TopicCommand.scala)\nCaused by: org.apache.kafka.common.errors.InvalidPartitionsException: Topic currently has 3 partitions, which is higher than the requested 2.\n (kafka.admin.TopicCommand$)\n```\n\n### 修改主题级别参数\n`--bootstrap-server`是用来设置**动态参数**的，而**常规的主题级别参数**，还是使用`--zookeeper`\n```java\n$ kafka-configs --zookeeper localhost:2181 --entity-type topics --entity-name t1 --alter --add-config max.message.bytes=10485760\nCompleted Updating config for entity: topic 't1'.\n```\n\n### 变更副本数\n使用`kafka-reassign-partitions`脚本**增加**主题的副本数，参照下文\n\n### 修改主题限速\n主要是指设置Leader副本和Follower副本使用的**带宽**，想要让某个主题的副本在执行**副本同步**机制时，不要消耗过多的带宽\n需要修改Broker端参数**`leader.replication.throttled.rate`**和**`follower.replication.throttled.rate`**\n如果某主题的副本分别在0、1、2、3多个Broker上，需要依次到Broker0、Broker1、Broker2、Broker3上执行这条命令\n```\n$ kafka-configs --zookeeper localhost:2181 --entity-type brokers --entity-name 0 --alter --add-config 'leader.replication.throttled.rate=104857600,follower.replication.throttled.rate=104857600'\nCompleted Updating config for entity: brokers '0'.\n```\n设置完上面两个参数后，需要为该主题设置要限速的副本，通配符`*`代表**所有副本**都设置限速\n```\n$ kafka-configs --zookeeper localhost:2181 --entity-type topics --entity-name t1 --alter --add-config 'leader.replication.throttled.replicas=*,follower.replication.throttled.replicas=*'\nCompleted Updating config for entity: topic 't1'.\n```\n\n### 主题分区迁移\n使用`kafka-reassign-partitions`脚本对**主题各个分区的副本**进行调整，如把某些分区批量迁移到其它Broker上，参照下文\n\n### 删除主题\n删除操作是**异步**的，执行完命令后，主题仅仅被**标记为已删除**而已，Kafka会在**后台**默默开启主题删除操作\n```\n$ kafka-topics --bootstrap-server localhost:9092 --delete --topic t1\n```\n\n## 位移主题\n\n### 副本数量\n1. 在Kafka **0.11**之前，当Kafka**自动创建**`__consumer_offsets`时\n    - 会综合考虑**当前运行的Broker台数**和Broker端参数**`offsets.topic.replication.factor`**，取两者中的**较小值**\n    - 这违背了用户设置`offsets.topic.replication.factor`的初衷\n2. 在Kafka **0.11**之后，Kafka会**严格遵守**`offsets.topic.replication.factor`的值\n    - 如果当前运行的Broker数量小于`offsets.topic.replication.factor`，Kafka会**创建位移主题失败**，并抛出异常\n3. 如果`__consumer_offsets`的副本值为1，可以**增加**到3\n\nreassign.json -- 副本的配置\n```json\n{\"version\":1, \"partitions\":[\n    {\"topic\":\"__consumer_offsets\",\"partition\":0,\"replicas\":[0,1,2]}, \n    {\"topic\":\"__consumer_offsets\",\"partition\":1,\"replicas\":[0,2,1]},\n    {\"topic\":\"__consumer_offsets\",\"partition\":2,\"replicas\":[1,0,2]},\n    ...\n    {\"topic\":\"__consumer_offsets\",\"partition\":49,\"replicas\":[0,1,2]}\n]}\n```\n```\n$ kafka-reassign-partitions --zookeeper localhost:2181 --reassignment-json-file reassign.json --execute\nCurrent partition replica assignment\n\n{\"version\":1,\"partitions\":[{\"topic\":\"__consumer_offsets\",\"partition\":22,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":30,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":8,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":21,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":4,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":27,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":7,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":9,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":46,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":25,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":35,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":41,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":33,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":23,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":49,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":47,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":16,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":28,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":31,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":36,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":42,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":3,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":18,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":37,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":15,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":24,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":38,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":17,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":48,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":19,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":11,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":13,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":2,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":43,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":6,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":14,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":20,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":0,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":44,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":39,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":12,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":45,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":1,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":5,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":26,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":29,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":34,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":10,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":32,\"replicas\":[0],\"log_dirs\":[\"any\"]},{\"topic\":\"__consumer_offsets\",\"partition\":40,\"replicas\":[0],\"log_dirs\":[\"any\"]}]}\n\nSave this to use as the --reassignment-json-file option during rollback\nSuccessfully started reassignment of partitions.\n```\n\n### 查看消费者组提交的位移数据\n**OffsetsMessageFormatter**\n```\n$ kafka-console-consumer --bootstrap-server localhost:9092 --topic __consumer_offsets --formatter \"kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter\" --from-beginning\n[console-consumer-40652,test,0]::OffsetAndMetadata(offset=2, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1538842068384, expireTimestamp=Some(1539446868384))\n[console-consumer-6657,test,0]::NULL\n[console-consumer-66385,zhongmingmao,0]::OffsetAndMetadata(offset=5, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1538999538770, expireTimestamp=Some(1539604338770))\n[console-consumer-41615,test,0]::NULL\n[zhongmingmao,zhongmingmao1,0]::NULL\n[stock,stock,0]::NULL\n[zhongmingmao,zhongmingmao,1]::OffsetAndMetadata(offset=5, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1570536122165, expireTimestamp=None)\n[zhongmingmao,zhongmingmao,0]::OffsetAndMetadata(offset=5, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1570536122165, expireTimestamp=None)\n[zhongmingmao,zhongmingmao,4]::OffsetAndMetadata(offset=6, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1570536122165, expireTimestamp=None)\n[zhongmingmao,zhongmingmao,3]::OffsetAndMetadata(offset=6, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1570536122165, expireTimestamp=None)\n[zhongmingmao,zhongmingmao,2]::OffsetAndMetadata(offset=6, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1570536122165, expireTimestamp=None)\n[console-consumer-29492,test,0]::OffsetAndMetadata(offset=5, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1539220886461, expireTimestamp=Some(1539825686461))\n[console-consumer-88677,test,0]::OffsetAndMetadata(offset=10, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1539222370827, expireTimestamp=Some(1539827170827))\n[bijection,bijection,0]::OffsetAndMetadata(offset=20, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1553425113337, expireTimestamp=None)\n[console-consumer-60394,zhongmingmao,0]::OffsetAndMetadata(offset=3, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1538880245612, expireTimestamp=Some(1539485045612))\n[console-consumer-40652,test,0]::NULL\n[console-consumer-29492,test,0]::NULL\n[console-consumer-88677,test,0]::NULL\n[bijection,bijection,0]::NULL\n[console-consumer-66385,zhongmingmao,0]::NULL\n[console-consumer-60394,zhongmingmao,0]::NULL\n[zhongmingmao,zhongmingmao,1]::NULL\n[zhongmingmao,zhongmingmao,0]::NULL\n[zhongmingmao,zhongmingmao,4]::NULL\n[zhongmingmao,zhongmingmao,3]::NULL\n[zhongmingmao,zhongmingmao,2]::NULL\n```\n\n### 读取位移主题消息，查看消费者组的状态信息\n**GroupMetadataMessageFormatter**\n```\n$ kafka-console-consumer --bootstrap-server localhost:9092 --topic __consumer_offsets --formatter \"kafka.coordinator.group.GroupMetadataManager\\$GroupMetadataMessageFormatter\" --from-beginning\nconsole-consumer-40652::GroupMetadata(groupId=console-consumer-40652, generation=2, protocolType=Some(consumer), currentState=Empty, members=Map())\nconsole-consumer-18364::GroupMetadata(groupId=console-consumer-18364, generation=1, protocolType=Some(consumer), currentState=Stable, members=Map(consumer-1-6aa558f4-7166-457e-9006-39a5843aa976 -> MemberMetadata(memberId=consumer-1-6aa558f4-7166-457e-9006-39a5843aa976, groupInstanceId=Some(null), clientId=consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), )))\nconsole-consumer-18364::GroupMetadata(groupId=console-consumer-18364, generation=2, protocolType=Some(consumer), currentState=Empty, members=Map())\nconsole-consumer-6657::NULL\nconsole-consumer-20884::NULL\nconsole-consumer-60618::GroupMetadata(groupId=console-consumer-60618, generation=1, protocolType=Some(consumer), currentState=Stable, members=Map(consumer-1-da910be4-7520-4187-bb58-f1c060c48749 -> MemberMetadata(memberId=consumer-1-da910be4-7520-4187-bb58-f1c060c48749, groupInstanceId=Some(null), clientId=consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), )))\nconsole-consumer-60618::GroupMetadata(groupId=console-consumer-60618, generation=2, protocolType=Some(consumer), currentState=Empty, members=Map())\nconsole-consumer-46196::GroupMetadata(groupId=console-consumer-46196, generation=1, protocolType=Some(consumer), currentState=Stable, members=Map(consumer-1-4091fa6c-3326-4e2c-b860-fe94350c9433 -> MemberMetadata(memberId=consumer-1-4091fa6c-3326-4e2c-b860-fe94350c9433, groupInstanceId=None, clientId=consumer-1, clientHost=/192.168.11.195, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), )))\nconsole-consumer-46196::GroupMetadata(groupId=console-consumer-46196, generation=2, protocolType=Some(consumer), currentState=Empty, members=Map())\nconsole-consumer-46196::NULL\nconsole-consumer-66385::GroupMetadata(groupId=console-consumer-66385, generation=2, protocolType=Some(consumer), currentState=Empty, members=Map())\nconsole-consumer-41615::NULL\nstock::NULL\nzhongmingmao::GroupMetadata(groupId=zhongmingmao, generation=11, protocolType=Some(consumer), currentState=Empty, members=Map())\nconsole-consumer-82389::GroupMetadata(groupId=console-consumer-82389, generation=1, protocolType=Some(consumer), currentState=Stable, members=Map(consumer-1-354b4b29-df13-456c-80c5-6701e8900828 -> MemberMetadata(memberId=consumer-1-354b4b29-df13-456c-80c5-6701e8900828, groupInstanceId=Some(null), clientId=consumer-1, clientHost=/192.168.2.1, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), )))\nconsole-consumer-82389::GroupMetadata(groupId=console-consumer-82389, generation=2, protocolType=Some(consumer), currentState=Empty, members=Map())\nconsole-consumer-82389::NULL\nconsole-consumer-37711::GroupMetadata(groupId=console-consumer-37711, generation=1, protocolType=Some(consumer), currentState=Stable, members=Map(consumer-1-b8bc1ccd-5388-4f07-bfcf-0a416c143572 -> MemberMetadata(memberId=consumer-1-b8bc1ccd-5388-4f07-bfcf-0a416c143572, groupInstanceId=Some(null), clientId=consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), )))\nconsole-consumer-37711::GroupMetadata(groupId=console-consumer-37711, generation=2, protocolType=Some(consumer), currentState=Empty, members=Map())\nconsole-consumer-29492::GroupMetadata(groupId=console-consumer-29492, generation=2, protocolType=Some(consumer), currentState=Empty, members=Map())\nconsole-consumer-88677::GroupMetadata(groupId=console-consumer-88677, generation=2, protocolType=Some(consumer), currentState=Empty, members=Map())\nconsole-consumer-3420::GroupMetadata(groupId=console-consumer-3420, generation=1, protocolType=Some(consumer), currentState=Stable, members=Map(consumer-1-7e402ca2-5b9f-49a0-83e3-262443f148ca -> MemberMetadata(memberId=consumer-1-7e402ca2-5b9f-49a0-83e3-262443f148ca, groupInstanceId=Some(null), clientId=consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), )))\nconsole-consumer-3420::GroupMetadata(groupId=console-consumer-3420, generation=2, protocolType=Some(consumer), currentState=Empty, members=Map())\nbijection::GroupMetadata(groupId=bijection, generation=2, protocolType=Some(consumer), currentState=Empty, members=Map())\nconsole-consumer-37719::NULL\nconsole-consumer-56242::NULL\nconsole-consumer-51162::GroupMetadata(groupId=console-consumer-51162, generation=1, protocolType=Some(consumer), currentState=Stable, members=Map(consumer-1-0ae0c268-a22a-425b-be55-30393a02c0ad -> MemberMetadata(memberId=consumer-1-0ae0c268-a22a-425b-be55-30393a02c0ad, groupInstanceId=Some(null), clientId=consumer-1, clientHost=/192.168.2.1, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), )))\nconsole-consumer-51162::GroupMetadata(groupId=console-consumer-51162, generation=2, protocolType=Some(consumer), currentState=Empty, members=Map())\nconsole-consumer-51162::NULL\nconsole-consumer-60394::GroupMetadata(groupId=console-consumer-60394, generation=2, protocolType=Some(consumer), currentState=Empty, members=Map())\nconsole-consumer-40652::NULL\nconsole-consumer-29492::NULL\nconsole-consumer-88677::NULL\nbijection::NULL\nconsole-consumer-85955::GroupMetadata(groupId=console-consumer-85955, generation=1, protocolType=Some(consumer), currentState=Stable, members=Map(consumer-1-a127b884-0a3a-4fe0-a1ea-8bbee57c668a -> MemberMetadata(memberId=consumer-1-a127b884-0a3a-4fe0-a1ea-8bbee57c668a, groupInstanceId=Some(null), clientId=consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), )))\nconsole-consumer-85955::GroupMetadata(groupId=console-consumer-85955, generation=2, protocolType=Some(consumer), currentState=Empty, members=Map())\nconsole-consumer-85955::NULL\nconsole-consumer-54404::GroupMetadata(groupId=console-consumer-54404, generation=1, protocolType=Some(consumer), currentState=Stable, members=Map(consumer-1-5edfac05-7f42-4e4c-b906-b8e26149d527 -> MemberMetadata(memberId=consumer-1-5edfac05-7f42-4e4c-b906-b8e26149d527, groupInstanceId=Some(null), clientId=consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), )))\nconsole-consumer-54404::GroupMetadata(groupId=console-consumer-54404, generation=2, protocolType=Some(consumer), currentState=Empty, members=Map())\nconsole-consumer-6483::GroupMetadata(groupId=console-consumer-6483, generation=1, protocolType=Some(consumer), currentState=Stable, members=Map(consumer-1-bfa8f79d-03db-43c5-b9bb-a168849e162e -> MemberMetadata(memberId=consumer-1-bfa8f79d-03db-43c5-b9bb-a168849e162e, groupInstanceId=Some(null), clientId=consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), )))\nconsole-consumer-6483::GroupMetadata(groupId=console-consumer-6483, generation=2, protocolType=Some(consumer), currentState=Empty, members=Map())\nconsole-consumer-6483::NULL\nconsole-consumer-66385::NULL\nconsole-consumer-60394::NULL\nzhongmingmao::NULL\nconsole-consumer-49544::GroupMetadata(groupId=console-consumer-49544, generation=1, protocolType=Some(consumer), currentState=Stable, members=Map(consumer-1-5629e772-0ef1-4248-b9ed-42f997f54a4a -> MemberMetadata(memberId=consumer-1-5629e772-0ef1-4248-b9ed-42f997f54a4a, groupInstanceId=Some(null), clientId=consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), )))\n```","tags":["Stream"],"categories":["Kafka"]},{"title":"Java性能 -- 生产者消费者模式 + 装饰器模式","url":"%2F2019%2F09%2F22%2Fjava-performance-producer-consumer%2F","content":"\n## 生产者消费者模式\n\n### 实现方式\n\n#### Object的wait/notify/notifyAll\n1. 基于Object的wait/notify/notifyAll与对象监视器（**Monitor**）实现**线程间的等待和通知**\n2. 这种方式实现的生产者消费者模式是基于**内核**实现的，可能会导致大量的**上下文切换**，性能不是最理想的\n\n<!-- more -->\n\n#### Lock中Condition的await/signal/signalAll\n1. 相对于Object的wait/notify/notifyAll，更推荐JUC包提供的Lock && Condition实现的生产者消费者模式\n2. Lock && Condition实现的生产者消费者模式，是基于**Java代码层**实现的，在**性能**和**扩展性**方面更有优势\n\n#### BlockingQueue\n1. 简单明了\n\n### 限流算法\n**漏桶算法**通过**限制容量池大小**来控制流量，而**令牌桶算法**则通过**限制发放令牌的速率**来控制流量\n\n#### 漏桶算法\n1. 请求如果要进入业务层，就必须经过漏桶，而**漏桶出口的请求速率是均衡的**\n2. 如果漏桶已经满了，请求将会溢出，不会因为入口的请求量突然增加而导致系统崩溃\n\n#### 令牌桶算法\n1. 系统以一个**恒定的速度**在一个桶中放入令牌，一个请求如果要进入业务层，必须要拿到一个令牌\n2. 当桶里没有令牌可以取时，那么请求会被拒绝\n3. Guava中的**RateLimiter**是基于令牌桶算法实现的\n\n## 装饰器模式\n1. 装饰器模式能够为对象**动态添加新功能**，从一个对象的**外部**给对象添加功能，具有非常**灵活的扩展性**\n2. 装饰器模式还能够实现对象的**动态组合**\n\n### URL\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-decorator.png\" width=1000/>\n\n### IDecorator\n```java\npublic interface IDecorator {\n    void decorate();\n}\n```\n\n### Decorator\n```java\npublic class Decorator implements IDecorator {\n\n    @Override\n    public void decorate() {\n        System.out.println(\"Decorator\");\n    }\n}\n```\n\n### BaseDecorator\n```java\n@AllArgsConstructor\npublic class BaseDecorator implements IDecorator {\n    private IDecorator decorator;\n\n    @Override\n    public void decorate() {\n        if (decorator != null) {\n            decorator.decorate();\n        }\n    }\n}\n```\n\n### ADecorator\n```java\npublic class ADecorator extends BaseDecorator {\n\n    public ADecorator(IDecorator decorator) {\n        super(decorator);\n    }\n\n    @Override\n    public void decorate() {\n        System.out.println(\"ADecorator\");\n        super.decorate();\n    }\n}\n```\n\n### BDecorator\n```java\npublic class BDecorator extends BaseDecorator {\n\n    public BDecorator(IDecorator decorator) {\n        super(decorator);\n    }\n\n    @Override\n    public void decorate() {\n        System.out.println(\"BDecorator\");\n        super.decorate();\n    }\n\n    public static void main(String[] args) {\n        new BDecorator(new ADecorator(new Decorator())).decorate();\n        // BDecorator\n        // ADecorator\n        // Decorator\n    }\n}\n```","tags":["Design Pattern"],"categories":["Performance"]},{"title":"Java性能 -- 并发设计模式","url":"%2F2019%2F09%2F21%2Fjava-performance-concurrent-design-pattern%2F","content":"\n## 线程上下文模式\n1. 线程上下文指的是**贯穿线程整个生命周期**的对象中的一些**全局**信息，如Spring中的**ApplicationContext**\n2. 可以使用`ThreadLocal`实现上下文\n    - ThreadLocal是**线程本地变量**，可以实现**多线程的数据隔离**，每个线程只能访问各自内部的副本变量\n\n<!-- more -->\n\n## Thread-Per-Message模式\n1. **一个消息一个线程**\n    - 在Socket通信中，一个线程监听IO事件，每当监听到一个IO事件，就交给另一个处理线程执行IO操作\n2. 如果遇到高并发，就会出现**严重的性能问题**，因为线程在操作系统中也是昂贵的资源，不能无限制地创建\n    - 如果针对每个IO请求都创建一个线程来处理，在有大量请求同时进来时，就会创建大量线程\n    - 每次请求都需要**创建**和**销毁**线程，性能开销很大\n3. 可以使用**线程池**来代替线程的创建和销毁\n\n### ServerHandler\n```java\n@AllArgsConstructor\npublic class ServerHandler implements Runnable {\n    private Socket socket;\n\n    @Override\n    public void run() {\n        BufferedReader in = null;\n        PrintWriter out = null;\n        String msg;\n        try {\n            in = new BufferedReader(new InputStreamReader(socket.getInputStream()));\n            out = new PrintWriter(socket.getOutputStream(), true);\n            while ((msg = in.readLine()) != null && msg.length() != 0) {\n                System.out.println(\"server received : \" + msg);\n                out.print(\"received~\\n\");\n                out.flush();\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            try {\n                in.close();\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n            try {\n                out.close();\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n            try {\n                socket.close();\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n\n### Server\n```java\npublic class Server {\n    private static final int DEFAULT_PORT = 12345;\n    private static ServerSocket server;\n\n    public static void start() throws IOException {\n        start(DEFAULT_PORT);\n    }\n\n    public static void start(int port) throws IOException {\n        if (server != null) {\n            return;\n        }\n\n        try {\n            server = new ServerSocket(port);\n            while (true) {\n                Socket socket = server.accept();\n                new Thread(new ServerHandler(socket)).start();\n            }\n        } finally {\n            if (server != null) {\n                server.close();\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        new Thread(() -> {\n            try {\n                Server.start();\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n        }).start();\n    }\n}\n```\n\n## Worker-Thread模式\n1. Worker是**工人**的意思，代表在Worker-Thread模式中，会有一些工人不断轮流处理过来的工作\n    - 当没有工作时，工人会处于**等待**状态，直到有新的工作进来\n    - 除了**工人**角色，Worker-Thread模式还包括了**流水线**和**产品**\n2. 相比于Thread-Per-Message模式\n    - 可以减少频繁创建、销毁线程所带来的性能开销\n    - 也能避免无限制创建线程所带来的内存溢出风险\n\n### Package\n```java\n@Data\npublic class Package {\n    private String name;\n    private String address;\n\n    public void execute() {\n        System.out.println(Thread.currentThread().getName() + \" executed \" + this);\n    }\n}\n```\n\n### Worker\n```java\npublic class Worker extends Thread {\n    private static final Random RANDOM = new Random(System.currentTimeMillis());\n    private final PackageChannel channel;\n\n    public Worker(String name, PackageChannel channel) {\n        super(name);\n        this.channel = channel;\n    }\n\n    @Override\n    public void run() {\n        while (true) {\n            channel.take().execute();\n            try {\n                Thread.sleep(RANDOM.nextInt(1000));\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n\n### PackageChannel\n```java\npublic class PackageChannel {\n    private final static int MAX_PACKAGE_NUM = 100;\n\n    private final Package[] packageQueue;\n    private final Worker[] workerPool;\n    private int head;\n    private int tail;\n    private int count;\n\n    public PackageChannel(int workers) {\n        this.packageQueue = new Package[MAX_PACKAGE_NUM];\n        this.head = 0;\n        this.tail = 0;\n        this.count = 0;\n        this.workerPool = new Worker[workers];\n        this.init();\n    }\n\n    private void init() {\n        for (int i = 0; i < workerPool.length; i++) {\n            workerPool[i] = new Worker(\"Worker-\" + i, this);\n        }\n    }\n\n    /**\n     * push switch to start all of worker to work\n     */\n    public void startWorker() {\n        Arrays.asList(workerPool).forEach(Worker::start);\n    }\n\n    public synchronized void put(Package packageReq) {\n        while (count >= packageQueue.length) {\n            try {\n                this.wait();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        this.packageQueue[tail] = packageReq;\n        this.tail = (tail + 1) % packageQueue.length;\n        this.count++;\n        this.notifyAll();\n    }\n\n    public synchronized Package take() {\n        while (count <= 0) {\n            try {\n                this.wait();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        Package request = this.packageQueue[head];\n        this.head = (this.head + 1) % this.packageQueue.length;\n        this.count--;\n        this.notifyAll();\n        return request;\n    }\n}\n```\n\n### Test\n```java\npublic class Test {\n    public static void main(String[] args) {\n        // 新建8个工人\n        final PackageChannel channel = new PackageChannel(8);\n        // 开始工作\n        channel.startWorker();\n        // 为流水线添加包裹\n        for (int i = 0; i < 100; i++) {\n            Package packageReq = new Package();\n            packageReq.setAddress(\"test\");\n            packageReq.setName(\"test\");\n            channel.put(packageReq);\n        }\n    }\n}\n```\n\n## Future模式\n\n### Task\n```java\npublic interface Task<T, P> {\n    T doTask(P param);\n}\n```\n\n### TaskService\n```java\npublic interface TaskService<T, P> {\n    // 提交任务，不返回结果\n    Future<?> submit(Runnable runnable);\n\n    // 提交任务，返回结果\n    Future<T> submit(Task<T, P> task, P param);\n}\n```\n\n### Future\n```java\npublic interface Future<T> {\n    T get();\n\n    boolean done();\n}\n```\n\n### FutureTask\n```java\npublic class FutureTask<T> implements Future<T> {\n    private T result;\n    private boolean isDone = false;\n    private final Object Lock = new Object();\n\n    @Override\n    public T get() {\n        synchronized (Lock) {\n            while (!isDone) {\n                try {\n                    Lock.wait();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return result;\n    }\n\n    @Override\n    public boolean done() {\n        return isDone;\n    }\n\n    public void finish(T result) {\n        synchronized (Lock) {\n            if (isDone) {\n                return;\n            }\n            this.result = result;\n            isDone = true;\n            Lock.notifyAll();\n        }\n    }\n}\n```\n\n### TaskServiceImpl\n```java\npublic class TaskServiceImpl<T, P> implements TaskService<T, P> {\n    @Override\n    public Future<?> submit(Runnable runnable) {\n        new Thread(() -> runnable.run(), Thread.currentThread().getName()).start();\n        return new FutureTask<Void>();\n    }\n\n    @Override\n    public Future<T> submit(Task<T, P> task, P param) {\n        FutureTask<T> future = new FutureTask<>();\n        new Thread(() -> {\n            T t = task.doTask(param);\n            future.finish(t);\n        }, Thread.currentThread().getName()).start();\n        return future;\n    }\n}\n```\n\n### TaskA\n```java\npublic class TaskA<T, P> implements Task<T, P> {\n\n    @Override\n    public T doTask(P param) {\n        try {\n            TimeUnit.SECONDS.sleep(5);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        return (T) param;\n    }\n}\n```\n\n### App\n```java\npublic class App {\n    public static void main(String[] args) {\n        TaskService<String, String> taskService = new TaskServiceImpl<>();\n        Task<String, String> task = new TaskA<>();\n        Future<String> future = taskService.submit(task, \"zhongmingmao\");\n        System.out.println(future.get());\n    }\n}\n```","tags":["Design Pattern"],"categories":["Performance"]},{"title":"Kafka -- 高水位 + Leader Epoch","url":"%2F2019%2F09%2F20%2Fkafka-high-watermark-leader-epoch%2F","content":"\n## 高水位\n\n### 水位的定义\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-watermark.png\" width=1000/>\n\n<!-- more -->\n\n1. 经典教科书\n    - 在时刻T，任意创建时间（**Event Time**）为`T'`，且`T'<=T`的所有事件都已经到达，那么T就被定义为水位\n2. 《Streaming System》\n    - 水位是一个**单调增加**且表征**最早未完成工作的时间戳**\n3. 上图中标注为`Completed`的蓝色部分代表**已经完成**的工作，标注为`In-Flight`的红色部分代表**正在进行中**的工作\n    - 两者的**边界**就是水位线\n4. 在**Kafka**中，水位不是时间戳，而是与位置信息绑定的，即用**消息位移**来表征水位\n    - Kafka中也有**低水位**（Low Watermark），是与Kafka**删除消息**相关联的概念\n\n### 高水位的作用\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-high-watermark.png\" width=800/>\n\n1. 两个作用\n    - 定义**消息可见性**，即用来标识分区下的哪些消息可以被消费者消费的\n    - 帮助Kafka完成**副本同步**\n2. 上图是某个分区**Leader副本**的高水位图，在**分区高水位以下**的消息被认为是**已提交消息**，反之为未提交消息\n    - **消费者只能消费已提交消息**，即位移小于8的所有消息\n    - 暂不讨论Kafka事务，Kafka的**事务**机制会影响消费者所能看到的消息的范围，不只是简单依赖高水位来判断\n        - 而是依靠**LSO**（Log **Stable** Offset）的位移值来判断事务型消费者的可见性\n    - **位移值等于高水位的消息也属于未提交消息**，即高水位上的消息是不能被消费者消费的\n    - 图中还有一个**日志末端位移**（Log **End** Offset，**LEO**）的概念，表示**副本写入下一条消息的位移值**\n        - LEO为15，方框是虚线，表示当前副本只有15条消息，位移从0到14，下一条新消息的位移为15\n    - `[高水位,LEO)`的消息属于**未提交消息**，在同一个副本对象，**高水位值不会大于LEO值**\n    - **高水位**和**LEO**是副本对象的两个重要属性\n        - Kafka**所有副本对象**都有对应的高水位和LEO，而Kafka使用**Leader副本的高水位**来定义**所在分区的高水位**\n\n### 高水位的更新机制\n\n#### 远程副本\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-high-watermark-update.png\" width=600/>\n\n1. 每个副本对象都保存了一组高水位和LEO值，**Leader副本所在的Broker**还保存了_**其它Follower副本的LEO值**_\n2. Kafka把Broker 0上保存的Follower副本又称为**远程副本**（**Remote** Replica）\n3. Kafka**副本机制**在运行过程中\n    - 会更新\n        - Broker 1上Follower副本的高水位和LEO值\n        - Broker 0上Leader副本的高水位和LEO以及**所有远程副本的LEO**\n    - 不会更新\n        - Broker 0**所有远程副本的高水位值**，即图中标记为**灰色**的部分\n4. Broker 0保存远程副本的作用\n    - **帮助**Leader副本**确定**其**高水位**，即**分区高水位**\n\n#### 更新时机\n| 更新对象 | 更新时机 |\n| --- | --- |\n| Broker 0上Leader副本的LEO | Leader副本**接收**到生产者发送的消息，**写入到本地磁盘**后，会更新其LEO值 |\n| Broker 1上Follower副本的LEO | Follower副本从Leader副本**拉取**消息，**写入本地磁盘**后，会更新其LEO值 |\n| Broker 0上远程副本的LEO | Follower副本从Leader副本**拉取**消息时，会告诉Leader副本**从哪个位移开始拉取**，<br/>Leader副本会使用这个位移值来更新远程副本的LEO |\n| Broker 0上Leader副本的高水位 | 两个更新时机：一个是Leader副本更新其LEO之后，一个是更新完远程副本LEO之后<br/>具体算法：取Leader副本和所有与Leader**同步**的远程副本LEO中的**最小值** |\n| Broker 1上Follower副本的高水位 | Follower副本成功更新完LEO后，会比较其LEO与**Leader副本发来的高水位值**，<br/>并用两者的**较小值**去更新自己的高水位 |\n\n1. 与Leader副本保持同步，需要满足两个条件\n    - 该远程Follower副本在**ISR**中\n    - 该远程Follower副本LEO值**落后**Leader副本LEO值的时间**不超过**参数`replica.lag.time.max.ms`（**10秒**）\n2. 某个副本能否进入ISR是由第二个条件判断的\n    - 2个条件判断是为了应对意外情况：**Follower副本已经追上Leader，却不在ISR中**\n    - 假设Kafka只判断第1个条件，副本F刚刚重启，并且已经具备进入ISR的资格，但此时尚未进入到ISR\n        - 由于缺少了副本F的判断，**分区高水位有可能超过真正ISR中的副本LEO**，而**高水位>LEO**是**不允许**的\n\n#### Leader副本\n1. **处理生产者请求**\n    - 写入消息到本地磁盘，更新**LEO**\n    - 更新**分区高水位**值\n        - 获取Leader副本所在Broker端保存的所有远程副本LEO值`{LEO-1, LEO-2,... LEO-n}`\n        - 获取Leader副本的LEO值：`currentLEO`\n        - 更新**`currentHW = min(currentLEO, LEO-1, LEO-2,... LEO-n)`**\n2. **处理Follower副本拉取消息**\n    - 读取**磁盘**（或**页缓存**）中的消息数据\n    - 使用Follower副本发送请求中的位移值来更新远程副本的**LEO**值\n    - 更新**分区高水位**值（与上面一致）\n\n#### Follower副本\n1. **从Leader拉取消息**\n    - 写入消息到本地磁盘\n    - 更新**LEO**\n    - 更新**高水位**值\n        - 获取**Leader发送**的高水位值：`currentHW`\n        - 获取步骤2中更新的LEO值：`currentLEO`\n        - 更新高水位**`min(currentHW, currentLEO)`**\n\n### 副本同步样例\n主题是**单分区两副本**，首先是初始状态，所有值都是0\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-high-watermark-example-1.png\" width=1000/>\n\n当生产者向主题分区发送一条消息后，状态变更为\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-high-watermark-example-2.png\" width=1000/>\n\n此时，Leader副本成功将消息写入到**本地磁盘**，将**LEO**值更新为1（更新高水位值为0，并把结果发送给Follower副本）\nFollower再次尝试从Leader拉取消息，此时有消息可以拉取，Follower副本也成功更新**LEO**为1（并将高水位更新为0）\n此时，Leader副本和Follower副本的**LEO**都是1，但各自的**高水位依然是0**，需要等到**下一轮**的拉取中被更新\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-high-watermark-example-3.png\" width=1000/>\n\n在新一轮的拉取请求中，由于位移值为0的消息已经拉取成功，因此Follower副本这次拉取请求的位移值为**1**\nLeader副本接收到此请求后，更新**远程副本LEO**为**1**，然后更新**Leader高水位**值为**1**\n最后，**Leader副本**会将**当前更新过的高水位**值1发送给**Follower副本**，Follower副本接收到后，也会将自己的高水位值更新为**1**\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-high-watermark-example-4.png\" width=1000/>\n\n## Leader Epoch\n\n### 基本概念\n1. 上面的副本同步过程中，Follower副本的**高水位更新**需要**一轮额外的拉取请求**才能实现\n    - 如果扩展到**多个Follower副本**，可能需要**多轮拉取请求**\n    - 即**Leader副本高水位更新**和**Follower副本高水位更新**在**时间**上存在**错配**\n        - 这种错配是很多**数据丢失**或**数据不一致**问题的根源\n        - 因此，社区在**0.11**版本正式引入了`Leader Epoch`概念，来规避**高水位更新错配**导致的各种**不一致**问题\n2. Leader Epoch可以大致认为是**Leader版本**，由两部分数据组成\n    - **Epoch**\n        - 一个**单调递增**的版本号\n        - 每当**副本领导权发生变更**时，都会增加该版本号\n        - 小版本号的Leader被认为是**过期Leader**，不能再行使Leader权利\n    - **起始位移**（Start Offset）\n        - **Leader副本**在该Epoch值上写入的**首条消息**的位移\n3. 两个Leader Epoch，`<0,0>`和`<1,120>`\n    - `<0,0>`表示版本号为0，该版本的Leader从位移0开始保存消息，一共保存了120条消息\n    - 之后Leader发生了**变更**，版本号增加到1，新版本的起始位移是120\n4. Broker在**内存**中为每个**分区**都缓存`Leader Epoch`数据，同时还会**定期**地将这些数据**持久化**到一个`checkpoint`文件中\n    - 当**Leader副本写入消息到磁盘**时，Broker会尝试更新这部分缓存\n    - 如果Leader是**首次**写入消息，那么Broker会向缓存中**增加Leader Epoch条目**，否则不做更新\n    - 这样每次有Leader变更时，新的Leader副本会查询这部分缓存，取出对应的Leader Epoch的起始位移\n        - 然后进行相关的逻辑判断，避免**数据丢失**和**数据不一致**的情况\n\n### 数据丢失\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-leader-epoch-example-1.png\" width=1000/>\n\n1. 开始时，副本A和副本B都处于正常状态，A是Leader副本\n2. 某个的生产者（**默认acks设置**）向A发送了两条消息，A全部写入成功，Kafka会通知生产者说两条消息全部发送成功\n3. 假设Leader和Follower都写入了这两条消息，而且Leader副本的高水位也更新了，但_**Follower副本的高水位还未更新**_\n4. 此时副本B所在的Broker**宕机**，当它**重启**回来后，副本B会执行_**日志截断!!**_\n    - **将LEO值调整为之前的高水位值!!**，也就是1\n    - 位移值为1的那条消息被副本B**从磁盘中删除**，此时副本B的**底层磁盘文件**中只保留1条消息，即位移为0的消息\n5. 副本B执行完日志截断操作后，开始从A拉取消息，此时恰好副本A所在的Broker也宕机了，副本B自然成为新的Leader\n    - 当A回来后，需要执行相同的**日志截断**操作，但**不能超过新Leader**，即**将高水位调整与B相同的值**，也就是1\n    - 操作完成后，位移值为1的那条消息就从两个副本中被**永远抹掉**，造成了**数据丢失**\n\n### Leader Epoch规避数据丢失\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-leader-epoch-example-2.png\" width=1000/>\n\n1. Follower副本B重启后，需要向A发送一个特殊的请求去获取**Leader的LEO值**，该值为2\n2. 当获知Leader LEO后，B发现该LEO值**大于等于**自己的LEO，而且缓存中也**没有保存任何起始位移值>2的Epoch条目**\n    - **B无需执行任何日志截断操作**\n    - 明显改进：_**副本是否执行日志截断不再依赖于高水位进行判断**_\n3. A宕机，B成为Leader，当A重启回来后，执行与B相同的逻辑判断，发现同样**不需要执行日志截断**\n    - 至此位移值为1的那条消息在两个副本中**均得到保留**\n    - 后面生产者向B**写入新消息**后，副本B所在的Broker缓存中会生成新的Leader Epoch条目：**`[Epoch=1, Offset=2]`**\n\n## 小结\n1. **高水位**在界定**Kafka消息对外可见性**以及实现**副本机制**方面起到非常重要的作用\n    - 但设计上的缺陷给Kafka留下了很多**数据丢失**或**数据不一致**的潜在风险\n2. 为此，社区引入了**`Leader Epoch`**机制，尝试规避这类风险，并且效果不错","tags":["Stream"],"categories":["Kafka"]},{"title":"Java性能 -- 原型模式 + 享元模式","url":"%2F2019%2F09%2F19%2Fjava-performance-prototype-flyweight%2F","content":"\n## 原型模式\n1. 原型模式：通过给出一个原型对象来指明所创建的对象的类型，然后使用自身实现的**克隆接口**来复制这个原型对象\n2. 使用这种方式创新的对象的话，就无需再通过new实例化来创建对象了\n    - Object类的clone方法是一个**Native**方法，可以直接操作**内存中的二进制流**，所以相对new实例化来说，**性能更佳**\n\n<!-- more -->\n\n### 实现原型模式\n```java\nclass Prototype implements Cloneable {\n    @Override\n    public Prototype clone() {\n        Prototype prototype = null;\n        try {\n            prototype = (Prototype) super.clone();\n        } catch (CloneNotSupportedException e) {\n            e.printStackTrace();\n        }\n        return prototype;\n    }\n}\n\nclass ConcretePrototype extends Prototype {\n    public void show() {\n        System.out.println(\"原型模式实现类\");\n    }\n}\n\npublic class Client {\n    public static void main(String[] args) {\n        ConcretePrototype cp = new ConcretePrototype();\n        for (int i = 0; i < 10; i++) {\n            ConcretePrototype prototype = (ConcretePrototype) cp.clone();\n            prototype.show();\n        }\n    }\n}\n```\n1. **实现**`Cloneable`接口\n    - Cloneable接口与Serializable接口的作用类似，告诉JVM可以安全地在实现了Cloneable接口的类上使用clone方法\n    - 在JVM中，只有实现了Cloneable接口的类才可以被拷贝，否则会抛出`CloneNotSupportedException`\n2. **重写**Object类的`clone`方法\n    - Object类中有一个clone方法，作用是返回对象的一个**拷贝**\n    - 在重写的clone方法中调用**`super.clone()`**，因为默认情况下，_**类不具备复制对象的能力**_\n3. 通过clone方法复制的对象是**真正的对象复制**，clone方法复制的对象是一个**完全独立**的对象\n    - Object类的clone方法是一个**Native**方法，直接操作**内存的二进制流**，特别是复制大对象时，**性能**的差别特别明显\n\n```java\n@Data\nclass Student implements Cloneable {\n    private String name;\n\n    @Override\n    public Student clone() {\n        Student student = null;\n        try {\n            student = (Student) super.clone();\n        } catch (CloneNotSupportedException e) {\n            e.printStackTrace();\n        }\n        return student;\n    }\n}\n\npublic class Test {\n    public static void main(String args[]) {\n        Student stu1 = new Student();\n        stu1.setName(\"test1\");\n\n        Student stu2 = stu1.clone();\n        stu2.setName(\"test2\");\n\n        System.out.println(stu1.getName() + \" : \" + stu2.getName()); // test1 : test2\n    }\n}\n```\n\n### 深拷贝 / 浅拷贝\n1. 在调用`super.clone()`方法后，首先会检查当前对象所属的类是否支持clone，即看该类是否实现了`Cloneable`接口\n2. 如果支持，则创建当前对象所属类的一个新对象，并对该对象进行初始化\n    - 使得新对象的**成员变量**的值与当前对象的成员变量的值一模一样\n    - 但对于其它对象的引用以及List等类型的成员属性，则只能复制这些对象的**引用**\n    - 所以调用`super.clone()`的克隆对象方式，是一种**浅拷贝**\n3. **深拷贝**其实就是**基于浅拷贝来递归**实现具体的每个对象\n\n#### 浅拷贝\n```java\n// 浅拷贝\n@Data\nclass Student implements Cloneable {\n    private String name;\n    private Teacher teacher;\n\n    @Override\n    public Student clone() {\n        Student student = null;\n        try {\n            student = (Student) super.clone();\n        } catch (CloneNotSupportedException e) {\n            e.printStackTrace();\n        }\n        return student;\n    }\n}\n\n@Data\nclass Teacher implements Cloneable {\n    private String name;\n\n    @Override\n    public Teacher clone() {\n        Teacher teacher = null;\n        try {\n            teacher = (Teacher) super.clone();\n        } catch (CloneNotSupportedException e) {\n            e.printStackTrace();\n        }\n        return teacher;\n    }\n\n}\n\npublic class Test {\n\n    public static void main(String args[]) {\n        Teacher teacher = new Teacher();\n        teacher.setName(\"刘老师\");\n\n        Student stu1 = new Student();\n        stu1.setName(\"test1\");\n        stu1.setTeacher(teacher);\n        Student stu2 = stu1.clone();\n        stu2.setName(\"test2\");\n        stu2.getTeacher().setName(\"王老师\");\n\n        System.out.println(stu1.getName() + \" : \" + stu1.getTeacher().getName()); // test1 : 王老师\n        System.out.println(stu2.getName() + \" : \" + stu2.getTeacher().getName()); // test2 : 王老师\n    }\n}\n```\n\n#### 深拷贝\n```java\n@Data\nclass Student implements Cloneable {\n    private String name;\n    private Teacher teacher;\n\n    @Override\n    public Student clone() {\n        // 深拷贝\n        Student student = null;\n        try {\n            student = (Student) super.clone();\n            Teacher teacher = this.teacher.clone();\n            student.setTeacher(teacher);\n        } catch (CloneNotSupportedException e) {\n            e.printStackTrace();\n        }\n        return student;\n    }\n}\n```\n\n### 适用场景\n1. 在一些**重复创建对象**的场景下，可以使用原型模式来提供对象的创建性能\n2. Spring中的`@Service(\"prototype\")`\n\n## 享元模式\n1. 享元模式是运用**共享技术**有效地最大限度地**复用细粒度对象**的一种模式\n2. 在享元模式中，以**对象的信息状态**划分，可以分为**内部数据**和**外部数据**\n    - **内部数据**是对象可以**共享**出来的信息，这些信息**不会随着系统的运行而改变**\n    - **外部数据**则是在不同**运行时**被标记了不同的值\n3. 享元模式一般分为三个角色\n    - **Flyweight**（抽象享元类）：通常是一个接口或抽象类，向外界提供享元对象的**内部数据**或**外部数据**\n    - **ConcreteFlyweight**（具体享元类）：实现**内部数据共享**的类\n    - **FlyweightFactory**（享元工厂类）：**创建**和**管理**享元对象的工厂类\n\n### 实现享元模式\n\n#### Flyweight\n```java\ninterface Flyweight {\n    /* 对外状态对象 */\n    void operation(String name);\n\n    /* 对内对象 */\n    String getType();\n}\n```\n\n#### ConcreteFlyweight\n```java\n@AllArgsConstructor\nclass ConcreteFlyweight implements Flyweight {\n    // 内部数据，不会随着系统的运行而改变\n    private String type;\n\n    @Override\n    public void operation(String name) {\n        System.out.printf(\"[类型 (内在状态)] - [%s] - [名字 (外在状态)] - [%s]\\n\", type, name);\n    }\n\n    @Override\n    public String getType() {\n        return type;\n    }\n}\n```\n\n#### FlyweightFactory\n```java\nclass FlyweightFactory {\n    // 享元池，用来存储享元对象\n    private static final Map<String, Flyweight> FLYWEIGHT_MAP = new HashMap<>();\n\n    public static Flyweight getFlyweight(String type) {\n        if (FLYWEIGHT_MAP.containsKey(type)) {\n            // 如果在享元池中存在对象，则直接获取\n            return FLYWEIGHT_MAP.get(type);\n        } else {\n            // 在享元池不存在，则新创建对象，并放入到享元池\n            ConcreteFlyweight flyweight = new ConcreteFlyweight(type);\n            FLYWEIGHT_MAP.put(type, flyweight);\n            return flyweight;\n        }\n    }\n}\n```\n\n#### Client\n```java\npublic class Client {\n    public static void main(String[] args) {\n        Flyweight fw0 = FlyweightFactory.getFlyweight(\"a\");\n        Flyweight fw1 = FlyweightFactory.getFlyweight(\"b\");\n        Flyweight fw2 = FlyweightFactory.getFlyweight(\"a\");\n        Flyweight fw3 = FlyweightFactory.getFlyweight(\"b\");\n        fw1.operation(\"abc\");                                           // [类型 (内在状态)] - [b] - [名字 (外在状态)] - [abc]\n        System.out.printf(\"[结果 (对象对比)] - [%s]\\n\", fw0 == fw2);      // [结果 (对象对比)] - [true]\n        System.out.printf(\"[结果 (内在状态)] - [%s]\\n\", fw1.getType());   // [结果 (内在状态)] - [b]\n    }\n}\n```\n\n### 适用场景\n1. Java中的**String**，在一些**字符串常量**中，会共享**常量池**中字符串对象，从而**减少重复创建相同值对象**，减少空间占用\n2. **线程池**和**Java本地缓存**也是享元模式的一种实现\n\n```java\nString s1 = \"hello\";\nString s2 = \"hello\";\nSystem.out.println(s1 == s2); // true\n```","tags":["Design Pattern"],"categories":["Performance"]},{"title":"Kafka --  控制器","url":"%2F2019%2F09%2F18%2Fkafka-controller%2F","content":"\n## 控制器\n1. **控制器**（Controller）是Kafka的**核心组件**，主要作用是在**ZK**的帮助下**管理和协调整个Kafka集群**\n2. 集群中**任一**Broker都能充当控制器的角色，但在运行过程中，**只能有一个Broker成为控制器**，行使管理和协调的职责\n\n```\n[zk: localhost:2181(CONNECTED) 1] get /controller\n{\"version\":1,\"brokerid\":0,\"timestamp\":\"1571311742367\"}\ncZxid = 0xd68\nctime = Thu Oct 17 19:29:02 CST 2019\nmZxid = 0xd68\nmtime = Thu Oct 17 19:29:02 CST 2019\npZxid = 0xd68\ncversion = 0\ndataVersion = 0\naclVersion = 0\nephemeralOwner = 0x1000209974b0000\ndataLength = 54\nnumChildren = 0\n```\n\n<!-- more -->\n\n## Zookeeper\n1. Kafka控制器**重度依赖**ZK\n2. ZK是一个提供**高可靠性的分布式协调服务**框架\n3. ZK使用类似于**文件系统**的树形结构，**根目录**以`/`开始，结构上的每个节点称为**znode**，用来保存一些**元数据协调信息**\n4. 如果以znode的**持久性**来划分，znode可以分为**持久性znode**和**临时znode**\n    - 持久性znode不会因为ZK集群重启而消失\n    - 临时znode则会**与创建该znode的ZK会话绑定**，一旦**会话结束**，该节点会被**自动删除**\n5. ZK赋予客户端**监控znode变更**的能力，即所谓的**Watch通知**功能\n    - 一旦znode节点被**创建**、**删除**、**子节点数量发生变化**，**znode所存的数据本身发生变更**\n    - ZK会通过节点变更监听器（**ChangeHandler**）的方式**显式通知**客户端\n6. ZK被用来实现**集群成员管理**、**分布式锁**、**领导者选举**等功能，**Kafka控制器**大量使用**Watch**功能实现**对集群的协调管理**\n\nkafka在ZK中创建的znode\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-controller-znode.png\" width=1000/>\n\n## `/controller`节点\n1. Broker在启动时，会尝试去ZK创建`/controller`节点\n2. **第一个**成功创建`/controller`节点的Broker会被指定为为**控制器**\n\n## 控制器的职责\n1. **主题管理**\n    - 完成对Kafka主题的**创建**、**删除**以及**分区增加**的操作\n    - 执行`kafka-topics`时，大部分的后台工作都是由控制器完成的\n2. **分区重分配**\n    - 分区重分配主要是指`kafka-reassign-partitions`脚本提供的**对已有主题分区进行细粒度的分配功能**\n3. **Preferred领导者选举**\n    - Preferred领导者选举主要是Kafka为了**避免部分Broker负载过重**而提供的一种**换Leader**的方案\n4. **集群成员管理**\n    - 自动检测**新增Broker**、**Broker主动关闭**、**Broker宕机**\n    - 自动检测依赖于**Watch**功能和**ZK临时节点**组合实现的\n        - 控制器会利用Watch机制检查ZK的`/brokers/ids`节点下的**子节点数量变更**\n        - 当有新Broker启动后，它会在`/brokers/ids/`下创建专属的**临时znode节点**\n            - 一旦创建完毕，ZK会通过Watch机制将消息通知**推送**给**控制器**，控制器能够自动感知这个变化\n        - 当Broker**宕机**或者**主动关闭**后，该Broker与ZK的**会话结束**，这个znode会被**自动删除**\n            - ZK的Watch机制会将这一变更**推送**给**控制器**\n5. **数据服务**\n    - 向**其它Broker**提供数据服务，控制器上保存了**最全的集群元数据信息**\n    - 其它Broker会**定期**接收**控制器**发来的**元数据更新请求**，从而更新其**内存**中的缓存数据\n\n## 控制器保存的数据\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-controller-data.png\" width=1000/>\n\n1. 所有**主题信息**，包括具体的分区信息、比如领导者副本是谁，ISR集合有哪些副本\n2. 所有**Broker信息**，包括哪些运行中的Broker，哪些正在关闭的Broker\n3. 所有**涉及运维任务的分区**，包括当前正在进行**Preferred领导者选举**以及**分区重分配**的分区列表\n4. 上述这些数据在**ZK**中也保存了一份，每当控制器**初始化**时，都会从ZK上读取对应的元数据并填充到自己的**缓存**中\n    - 有了这些数据，控制器就能对**其它Broker**提供数据服务了\n    - 控制器通过向其它Broker**发送请求**的方式将这些数据**同步**到其它Broker上\n\n## 控制器故障转移\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-controller-failover.jpg\" width=1000/>\n\n1. 故障转移\n    - 当运行中的控制器突然**宕机**或者**意外终止**时，Kafka能**快速感知**并立即启用备用控制器来**代替**之前失败的控制器\n    - 该过程称为**FailOver**，该过程是**自动完成**的\n2. 一开始，Broker 0是控制器，当Broker 0宕机后，ZK通过Watch机制感知到并**删除了`/controller`临时节点**\n3. 然后，所有**存活的Broker**开始竞选新的控制器，Broker 3最终赢得了选举，成功地在ZK上重建了`/controller`临时节点\n4. 之后，Broker 3会**从ZK中读取集群元数据信息**，并**初始化到自己的缓存**中，至此控制器的FailOver完成\n\n## 控制器内部设计原理\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-controller-design.png\" width=1000/>\n\n1. 在Kafka 0.11之前，控制器的设计是相当繁琐的，导致很多Bug无法修复\n2. 控制器是**多线程**的设计，会在内部创建很多个线程\n    - 控制器需要为每个Broker都创建一个对应的**Socket连接**，然后再创建一个**专属的线程**，用于向这些Broker发送请求\n    - 控制器连接ZK的会话，也会创建**单独的线程**来处理**Watch机制的通知回调**\n    - 控制器还会为**主题删除**创建额外的**IO线程**\n3. 这些线程还会访问**共享**的控制器缓存数据，**多线程**访问**共享可变数据**是维持线程安全的最大难题\n    - 为了保护**数据安全性**，控制器在代码中大量使用**ReentrantLock**同步机制，进一步**拖慢**整个控制器的**处理速度**\n4. 社区在0.11版本**重构了控制器的底层设计**，把多线程的方案改成了**单线程+事件队列**的方案\n    - 引进了**事件处理器**，统一处理各种**控制器事件**\n    - 控制器将原来执行的操作全部建模成**独立的事件**，发送到专属的**事件队列**中，供事件处理器消费\n    - 单线程：控制器只是把**缓存状态变更方面的工作**委托给了这个线程而已\n    - 优点：控制器缓存中保存的状态只被一个线程处理，因此不需要**重量级的线程同步机制**来维护线程安全\n5. 针对控制器的第二个改进：将之前同步操作ZK全部换成**异步操作**\n    - ZK本身的API提供了**同步写**和**异步写**两种方式\n    - 之前控制器操作ZK时使用的是**同步API**，**性能很差**\n        - **当有大量主题分区发生变更时，ZK容易成为系统的瓶颈**\n6. Kafka从2.2开始，将**控制器发送的请求**和**普通数据类的请求**分开，实现控制器请求**单独处理**的逻辑\n    - 之前Broker对接收到的所有请求都**一视同仁**，不会区别对待\n    - 如果删除了某个主题，那么控制器会给主题的所有副本所在的Broker发送StopReplica请求\n    - 如果此时Broker上有大量Produce请求堆积，那么StopReplica请求只能**排队**\n    - 既然主题都要被删除了，继续处理Produce请求就显得很没有意义\n","tags":["Stream"],"categories":["Kafka"]},{"title":"Java性能 -- 单例模式","url":"%2F2019%2F09%2F17%2Fjava-performance-singleton%2F","content":"\n## 饿汉模式\n\n### class\n```java\n// 饿汉模式\npublic final class Singleton {\n    private static Singleton instance = new Singleton();\n\n    private Singleton() {\n    }\n\n    public static Singleton getInstance() {\n        return instance;\n    }\n}\n```\n\n<!-- more -->\n\n1. 使用了`static`修饰了成员变量instance，所以该变量会在**类初始化**的过程中被收集进_**类构造器`<clinit>`**_\n2. 在**多线程**场景下，**JVM**会保证只有一个线程能够执行该类的`<clinit>`方法，其它线程将会被**阻塞等待**\n    - 等到唯一的一次`<clinit>`方法执行完成后，其它线程将不会再执行`<clinit>`方法，转而执行自己的代码\n    - 因此，static修饰的成员变量instance，在**多线程**的情况下能保证**只实例化一次**\n3. 在**类初始化**阶段就已经在堆内存中开辟了一块内存，用于存放实例化对象，所以也称为**饿汉模式**\n    - 可以保证**多线程**情况下实例的唯一性，而且getInstance直接返回唯一实例，**性能很高**\n    - 在类成员变量比较多，或者变量比较大的情况下，这种模式可能会在没有使用类对象的情况下，**一直占用堆内存**\n    - 第三方框架一般不会采用饿汉模式来实现单例模式\n\n### enum\n```java\n// 饿汉模式 + 枚举实现\npublic enum Singleton {\n    INSTANCE;\n\n    public List<String> list;\n\n    // 默认构造函数\n    Singleton() {\n        list = new ArrayList<>();\n    }\n\n    public static Singleton getInstance() {\n        return INSTANCE;\n    }\n}\n```\n```java\n// javap -v\n  public static final Singleton INSTANCE;\n    descriptor: LSingleton;\n    flags: ACC_PUBLIC, ACC_STATIC, ACC_FINAL, ACC_ENUM\n\n  static {};\n    descriptor: ()V\n    flags: ACC_STATIC\n    Code:\n      stack=4, locals=0, args_size=0\n         0: new           #4                  // class Singleton\n         3: dup\n         4: ldc           #11                 // String INSTANCE\n         6: iconst_0\n         7: invokespecial #12                 // Method \"<init>\":(Ljava/lang/String;I)V\n        10: putstatic     #10                 // Field INSTANCE:LSingleton;\n        13: iconst_1\n        14: anewarray     #4                  // class Singleton\n        17: dup\n        18: iconst_0\n        19: getstatic     #10                 // Field INSTANCE:LSingleton;\n        22: aastore\n        23: putstatic     #1                  // Field $VALUES:[LSingleton;\n        26: return\n      LineNumberTable:\n        line 6: 0\n        line 5: 13\n```\n1. Java中的`enum`是一种**语法糖！！**，在javac编译后，枚举类中的**枚举域**会被声明为**static**属性\n2. 并且**枚举域的初始化**会被收录进静态代码块`static{}`，类初始化时会被收录进`<clinit>`，由JVM保证线程安全\n\n## 懒汉模式\n\n### Double-Check\n```java\n// 懒汉模式\npublic final class Singleton {\n    private static Singleton instance = null;\n\n    private Singleton() {\n    }\n\n    public static Singleton getInstance() {\n        if (null == instance) {\n            instance = new Singleton();\n        }\n        return instance;\n    }\n}\n```\n1. 懒汉模式是为了**避免加载类对象时提前创建对象**的一种单例模式\n2. 懒汉模式使用了**懒加载**方式，只有当系统使用到类对象时，才会将实例加载到堆内存中\n3. 上面的代码在**多线程**环境下，可能会出现**实例化多个类对象**的情况\n    - 当线程A进入到if判断条件后，开始实例化对象，此时instance依然为null\n    - 又有线程B进入到if判断条件，之后也会通过判断条件，进入到方法又创建一个实例\n    - 可以**对方法进行加锁**，保证多线程下仅创建一个实例\n\n```java\n// 懒汉模式 + synchronized同步锁\npublic final class Singleton {\n    private static Singleton instance = null;\n\n    private Singleton() {\n    }\n\n    public static synchronized Singleton getInstance() {\n        if (null == instance) {\n            instance = new Singleton();\n        }\n        return instance;\n    }\n}\n```\n1. **同步锁**会增加**锁竞争**，带来系统**性能开销**，从而导致系统性能下降，因此这种方式也会**降低单例模式的性能**\n2. 可以考虑将同步锁放在if条件里面，**减少锁粒度**，进而**减少同步锁的资源竞争**\n\n```java\n// 懒汉模式 + synchronized同步锁\npublic final class Singleton {\n    private static Singleton instance = null;\n\n    private Singleton() {\n    }\n\n    public static Singleton getInstance() {\n        if (null == instance) {\n            synchronized (Singleton.class) {\n                instance = new Singleton();\n            }\n        }\n        return instance;\n    }\n}\n```\n1. 上述代码依然会**创建多个实例**，因为在**多线程**并发情况下，可以同时通过if判断条件\n2. 因此需要在同步锁里面再加一个判断条件，即`Double-Check`\n\n```java\n// 懒汉模式 + synchronized同步锁 + Double-Check\npublic final class Singleton {\n    private static Singleton instance = null;\n    public List<String> list;\n\n    private Singleton() {\n        list = new ArrayList<>();\n    }\n\n    public static Singleton getInstance() {\n        if (null == instance) {\n            synchronized (Singleton.class) {\n                if (null == instance) {\n                    instance = new Singleton();\n                }\n            }\n        }\n        return instance;\n    }\n}\n```\n1. 在JVM中，**重排序**是非常重要的一环，尤其在并发编程中，JVM可能会进行任意排序以**提高程序性能**\n2. 上面代码`instance = new Singleton()`的执行过程\n    1. 给Singleton分配内存\n    2. 调用Singleton的构造函数来初始化成员变量（即list）\n    3. 将Singleton对象指向分配的内存空间（执行完之后instance为**非null**）\n3. 如果JVM发生重排序优化，上面的步骤3可能会发生在步骤2之前\n    - 如果初始化线程A刚好完成步骤3，而步骤2没有进行时，又有另一个线程B到了**第一次判断**\n    - 线程B判断instance为非null，直接返回对象（**未完成构造**）使用，可能会导致**异常**\n4. _**synchronized只能保证可见性、原子性，但无法保证同步块内执行的顺序!!**_\n5. **volatile**可以保证线程间变量的可见性，同时还可以阻止**局部重排序**的发生，代码如下\n\n```java\n// 懒汉模式 + synchronized同步锁 + Double-Check\npublic final class Singleton {\n    private volatile static Singleton instance = null;\n    public List<String> list;\n    \n    private Singleton() {\n        list = new ArrayList<>();\n    }\n\n    public static Singleton getInstance() {\n        if (null == instance) {\n            synchronized (Singleton.class) {\n                if (null == instance) {\n                    instance = new Singleton();\n                }\n            }\n        }\n        return instance;\n    }\n}\n```\n\n### 内部类\n```java\n// 懒汉模式 + 内部类实现\npublic final class Singleton {\n    public List<String> list;\n\n    private Singleton() {\n        list = new ArrayList<>();\n    }\n\n    public static class InnerSingleton {\n        private static Singleton instance = new Singleton();\n    }\n\n    public static Singleton getInstance() {\n        return InnerSingleton.instance;\n    }\n}\n```\n\n### enum\n```java\n// 懒汉模式 + 内部类 + 枚举实现\npublic class Singleton {\n    public List<String> list;\n\n    private Singleton() {\n        list = new ArrayList<>();\n    }\n\n    private enum EnumSingleton {\n        INSTANCE;\n        private Singleton instance;\n\n        EnumSingleton() {\n            instance = new Singleton();\n        }\n\n        public Singleton getSingleton() {\n            return instance;\n        }\n    }\n\n    public static Singleton getInstance() {\n        return EnumSingleton.INSTANCE.getSingleton();\n    }\n}\n```","tags":["Design Pattern"],"categories":["Performance"]},{"title":"Kafka -- 重平衡","url":"%2F2019%2F09%2F16%2Fkafka-rebalance%2F","content":"\n## 触发重平衡\n1. **组成员数量**发生变化 -- **最常见**\n2. **订阅主题数量**发生变化\n2. **订阅主题的分区数**发生变化\n\n<!-- more -->\n\n## 通知\n1. 重平衡过程是通过**消费者的心跳线程**通知到其它消费者实例的\n2. Kafka Java消费者需要**定期**地发送心跳请求到Broker端的协调者，表明它还活着\n3. 在Kafka **0.10.1.0**之前，**发送心跳请求**是在消费者**主线程**完成的，即调用`poll`方法的那个线程\n    - 弊端\n        - **消息处理**逻辑是也在**主线程**完成的\n        - 一旦消息处理消耗了很长时间，心跳请求将无法及时发送给协调者，导致协调者**误以为消费者已死**\n    - 从Kafka 0.10.1.0开始，社区引入了**单独的心跳线程**\n4. **重平衡的通知机制**是通过**心跳线程**来完成的\n    - 当协调者决定开启新一轮重平衡后，会将`REBALANCE_IN_PROGRESS`封装进**心跳请求的响应**中\n    - 当消费者实例发现心跳响应中包含`REBALANCE_IN_PROGRESS`，就知道重平衡要开始了，这是重平衡的通知机制\n5. `heartbeat.interval.ms`的真正作用是控制**重平衡通知的频率**\n\n## 消费者组状态机\n| 状态 | 描述 |\n| --- | --- |\n| **Empty** | 组内**没有任何成员**，但消费者组可能**存在已提交的位移数据**，而且这些位移**尚未过期** |\n| **Dead** | 组内**没有任何成员**，但**组的元数据已经在协调者端被移除**，协调者组件保存着当前向它注册过的所有组信息 |\n| **PreparingRebalance** | 消费者组**准备开启**重平衡，此时所有成员都要**重新请求加入消费者组** |\n| **CompletingRebalance** | 消费者组下**所有成员已经加入**，各个成员正在**等待分配方案**<br/>该状态在老版本中称为**AwaitingSync**，与CompetingRebalance是等价的 |\n| **Stable** | 消费者组的**稳定状态**，该状态表明重平衡**已经完成**，组内各成员都能够**正常消费数据**了 |\n\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-rebalance-consumer-group-state-machine.png\" width=1000>\n\n1. 一个消费者组最开始是**Empty**状态，当重平衡过程开启后，会被置于**PreparingRebalance**状态等待成员加入\n    - 之后变更到**CompletingRebalance**状态等待分配方案，最后流转到**Stable**状态完成重平衡\n2. 当有新成员加入或已有成员退出时，消费者组的状态从**Stable**直接跳到**PreparingRebalance**状态\n    - 所有现存成员都必须**重新申请加入组**\n3. 当所有成员都退出组后，消费者组状态变更为**Empty**\n    - Kafka**定期自动删除过期位移**的条件是消费者组要处于**Empty**状态\n    - `Removed ✘✘✘ expired offsets in ✘✘✘ milliseconds`\n\n## 重平衡流程\n重平衡流程需要**消费者端**和**协调者组件**共同参与才能完成\n\n### 消费者端\n1. 在消费者端，重平衡分为两个步骤：**加入组**、**等待领导者消费者（Leader Consumer）分配方案**\n    - 分别对应两类特定的请求：**JoinGroup请求**、**SyncGroup请求**\n2. 当组内成员加入组时，会向协调者发送JoinGroup请求\n    - 在JoinGroup请求中，每个成员都要将自己**订阅的主题**上报，这样协调者就能收集所有成员的订阅信息\n    - 一旦收集了**全部**成员的JoinGroup请求后，协调者会从这些成员中选择一个担任这个消费者组的**领导者**\n        - 通常请求下，**第一个**发送JoinGroup请求的成员会自动成为领导者\n        - 这里的领导者与**领导者副本**不是一个概念，这里的领导者是**具体的消费者实例**\n    - 消费者领导者的职责：**收集所有成员的订阅信息**，然后根据这些信息，_**制定具体的分区消费分配方案**_\n    - 选出领导者后协调者会把**消费者组订阅信息**封装进JoinGroup请求的响应体中，返回给领导者，**由领导者统一分配**\n3. **领导者**向协调者发送**SyncGroup请求**，将刚刚做出的**分配方案**发给协调者\n    - 其它成员也会向协调者发送SyncGroup请求，只不过请求体中并没有实际的内容\n    - 让协调者接收分配方案，然后统一以**SyncGroup响应**的方式分发给所有成员\n\n#### JoinGroup\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-rebalance-consumer-join-group.png\" width=1000>\n\n1. **JoinGroup**请求的主要作用是_**将组成员订阅信息发送给领导者消费者**_\n2. 待领导者**制定好分配方案**后，重平衡流程进入到**SyncGroup**请求阶段\n\n#### SyncGroup\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-rebalance-consumer-sync-group.png\" width=1000>\n\n1. **SyncGroup**请求的主要作用是_**让协调者把领导者制定的分配方案下发给各个组内成员**_\n2. 当所有成员都**成功接收到分配方案**后，消费者组进入**Stable**状态，即开始正常的消费工作\n\n### Broker端\n\n#### 新成员加入组\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-rebalance-broker-join-group.png\" width=1000>\n\n1. 新成员加入组指的是消费者组处于**Stable**状态后，有新成员加入，而不是全新启动一个消费者组\n2. 当协调者收到新的**JoinGroup**请求后，会通过**心跳请求响应**的方式通知组内现有的所有成员，**强制它们开启新一轮重平衡**\n\n#### 组成员主动离组\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-rebalance-broker-leave-group.png\" width=1000>\n\n1. 主动离组：消费者实例所在的线程或者进程调用**close()**方法**主动**通知协调者它要退出，即**LeaveGroup**请求\n2. 协调者收到**LeaveGroup**请求后，依然会以**心跳响应**的方式通知其它成员\n\n#### 组成员崩溃离组\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-rebalance-broker-crash-leave-group.png\" width=1000>\n\n1. 崩溃离组：消费者实例出现**严重故障**，突然宕机导致的离组\n2. 主动离组，协调者能**马上感知**并处理；崩溃离组，协调者需要**等待一段时间**才能感知到，参数`session.timeout.ms`\n\n#### 重平衡时协调者对组内成员提出位移的处理\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-rebalance-broker-commit-offset.png\" width=1000>\n\n1. 正常情况下，每个组内成员都会**定期**汇报位移给协调者\n2. 当重平衡开启时，协调者会给予成员一段**缓冲时间**\n    - 要求每个成员必须在这段缓冲时间内**快速上报位移信息**，然后再开启正常的**JoinGroup/SyncGroup**请求","tags":["Rebalance"],"categories":["Kafka"]},{"title":"Kafka -- 处理请求","url":"%2F2019%2F09%2F15%2Fkafka-process-request%2F","content":"\n## 请求协议\n1. Kafka自定义了一组请求协议，用于实现各种各样的交互操作\n    - **PRODUCE**请求用于生产消息，**FETCH**请求用于消费消息，**METADATA**请求用于请求Kafka集群元数据信息\n2. Kafka 2.3总共定义了**45**种请求格式，所有请求都通过**TCP**网络以**Socket**的方式进行通讯\n\n<!-- more -->\n\n## 处理请求方案\n\n### 顺序处理\n实现简单，但**吞吐量太差**，只适用于请求发送**非常不频繁**的场景\n```java\nwhile (true) {\n    Request request = accept(connection);\n    handle(request);\n}\n```\n\n### 单独线程处理\n为每个请求都**创建一个新的线程异步处理**，完全异步，但**开销极大**，只适用于请求发送**频率很低**的场景\n```java\nwhile (true) {\n    Request request = accept(connection);\n    Thread thread = new Thread(() -> { handle(request); });\n    thread.start();\n}\n```\n\n### Reactor模式\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-process-request-reactor.png\" width=1000>\n\n1. Reactor模式是**事件驱动**架构的一种实现方式，特别适合应用于处理多个客户端**并发**向服务器端发起请求的场景\n2. 多个客户端会发送请求给**Reactor**，Reactor有个**请求分发线程Acceptor**，将不同的请求下发到多个**工作线程**中处理\n3. **Acceptor**线程只用于请求分发，不涉及具体的逻辑处理，非常**轻量级**，有**很高的吞吐量**\n    - 工作线程可以根据实际业务处理需要任意增减，从而**动态调节系统负载能力**\n\n#### Kafka\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-process-request-reactor-kafka.png\" width=1000>\n\n1. Broker端有一个**SocketServer**组件，类似于Reactor模式中的**Dispatcher**\n    - 也有对应的**Acceptor线程**和一个工作线程池（即**网络线程池**，参数设置`num.network.threads`，默认值为**3**）\n2. Acceptor线程采用**轮询**的方式将入站请求**公平**地发到所有网络线程中\n    - 实现简单，**避免了请求处理的倾斜**，有利于实现**较为公平**的请求处理调度\n\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-process-request-reactor-kafka-io-pool.png\" width=1000>\n\n1. 当**网络线程**拿到请求后，并不是自己处理，而是将请求放入到一个**共享请求队列**中\n2. Broker端还有一个**IO线程池**，负责从共享请求队列中取出请求，执行**真正的处理**\n    - 如果是**PRODUCE**请求，将消息写入到**底层的磁盘日志**中\n    - 如果是**FETCH**请求，则从**磁盘**或**页缓存**中读取消息\n3. IO线程池中的线程才是执行请求逻辑的线程，参数`num.io.threads`，默认值为**8**\n4. 当**IO线程**处理完请求后，会将**生成的响应**发送到**网络线程池的响应队列**中\n    - 然后由**对应的网络线程**负责将Response返回给客户端\n5. **请求队列**是所有网络线程**共享**的，而**响应队列**是每个网络线程**专属**的\n    - Purgatory组件用于_**缓存延时请求**_\n    - 如`acks=all`的**PRODUCE**请求，必须等待**ISR中所有副本**都接收消息后才能返回\n        - 此时处理该请求的IO线程必须等待其他Broker的写入结果，当请求不能处理时，就会**暂存**在Purgatory中\n        - 等到条件满足后，IO线程会继续处理该请求，并将Response放入**对应**网络线程的响应队列中\n6. Kafka将PRODUCE、FETCH这类请求称为**数据类请求**，把LeaderAndIsr、StopReplica这类请求称为**控制类请求**\n    - 在**Kafka 2.3**，正式实现了**数据类请求**和**控制类请求**的**分离**（**完全拷贝**一套组件，实现两类请求的分离）","tags":["Stream"],"categories":["Kafka"]},{"title":"Kafka -- 副本","url":"%2F2019%2F09%2F14%2Fkafka-replication%2F","content":"\n## 副本机制的优点\n1. 提供**数据冗余**\n    - 即使系统部分组件失效，系统依然能够继续运转，增加了**整体可用性**和**数据持久性**\n2. 提供**高伸缩性**\n    - 支持**横向扩展**，能够通过增加机器的方式来提升读性能，进而提高**读操作吞吐量**\n3. 改善**数据局部性**\n    - 允许将数据放入与用户**地理位置相近**的地方，从而**降低系统延时**\n4. **Kafka**只能享受副本机制提供**数据冗余**实现的**高可用性**和**高持久性**\n\n<!-- more -->\n\n## 副本定义\n1. Kafka主题划分为若干个分区，副本的概念上是在**分区层级**下定义的，**每个分区配置若干个副本**\n2. 副本：本质上是一个_**只能追加写消息的提交日志**_\n    - **同一个分区下的所有副本保存有相同的消息序列**，这些副本**分散保存在不同的Broker**上，提高了**数据可用性**\n3. 实际生产环境中，每台Broker都可能保存有各个主题不同分区的不同副本\n\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-replication-def.png\" width=600/>\n\n## 副本角色\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-replication-role.png\" width=800/>\n\n1. Kafka采用基于领导者（**Leader-based**）的副本机制\n    - 副本分为两类：**领导者副本**（Leader Replica）和**追随者副本**（Follower Replica）\n        - 每个分区在**创建**时都要**选举**一个副本，称为领导者副本，其余的副本自动称为追随者副本\n    - **追随者副本是不对外提供服务**的，**所有的读写请求**都必须发往**领导者副本**所在的Broker，由该Broker负责处理\n        - 追随者副本的任务：从领导者副本**异步拉取消息**，并写入到自己的**提交日志**中，从而实现与领导者副本的**同步**\n        - 所以Kafka无法提供**读操作横向扩展**和**改善局部性**\n    - 当领导者副本所在的Broker挂了，Kafka依托于**ZK**提供的**监控功能**能够**实时感知**，并立即开启新一轮的领导者选举\n        - 从追随者副本中选择一个作为新的领导者，**老Leader**副本重启后，也只能作为**追随者副本**加入到集群中\n2. Leader-based副本机制的好处\n    - 方便实现**`Read-your-writes`**\n        - Read-your-writes：使用生产者API向Kafka成功写入消息后，马上使用消费者API去读取刚才生产的消息\n        - 如果允许追随者副本对外提供服务，由于副本同步是**异步**的，客户端可能看不到最新写入的消息\n    - 方便实现**单调读**`Monotonic Reads`\n        - 单调读：对于一个消费者用户而言，在**多次消费**消息时，不会看到某条消息一会存在一会不存在\n\n## **ISR**(In-Sync Replicas)\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-replication-isr.png\" width=600/>\n\n1. ISR中的副本都是**与Leader同步的副本**，不在ISR中的追随者副本就被认为与Leader不同步\n2. **Leader副本天然在ISR中**，某些特殊情况下，ISR只有Leader副本\n3. 上图中的2个Follower都有可能与Leader不同步，也都有可能与Leader同步\n    - 参照标准是Broker端参数**`replica.lag.time.max.ms`**，而不是相差的消息数\n    - `replica.lag.time.max.ms`：Follower副本能够落后Leader副本的最长时间间隔，默认**10秒**\n4. Follower副本同步的速度**持续慢于**Leader副本的消息写入速度\n    - 在`replica.lag.time.max.ms`后，Follower副本就会被认为与Leader副本不同步\n    - 此时，Kafka会**自动收缩ISR**，将该Follower副本踢出ISR\n    - 如果该Follower副本后面慢慢追上Leader的进度，它能够**重新**被加回ISR，因此ISR是一个**动态调整**的集合\n\n## Unclean Leader Election\n1. 如果**ISR为空**，说明Leader副本也挂了，Kafka需要重新选举一个新的Leader\n2. Kafka把**所有不在ISR中的存活副本**都称为**非同步副本**\n3. 通常来说，**非同步副本落后Leader太多**，如果选择非同步副本作为新Leader，可能会出现**数据丢失**\n4. 选举**非同步副本**的过程称为**Unclean Leader Election**，Broker端参数`unclean.leader.election.enable`\n5. **A Or C**\n    - **开启**Unclean Leader Election可能会造成**数据丢失**（C），但提高了**可用性**（A）\n    - **关闭**Unclean Leader Election维护了**数据一致性**（C），但牺牲了**可用性**（A）\n        - 强烈**推荐**关闭Unclean Leader Election","tags":["Stream"],"categories":["Kafka"]},{"title":"Java性能 -- JVM堆内存分配","url":"%2F2019%2F09%2F13%2Fjava-performance-jvm-heap-allocation%2F","content":"\n## JVM内存分配性能问题\n1. JVM内存分配不合理最直接的表现就是**频繁的GC**，这会导致**上下文切换**，从而**降低系统的吞吐量**，**增加系统的响应时间**\n\n## 对象在堆中的生命周期\n1. 在JVM内存模型的堆中，堆被划分为**新生代**和**老年代**\n    - 新生代又被进一步划分为**Eden区**和**Survivor区**，Survivor区由**From Survivor**和**To Survivor**组成\n2. 当创建一个对象时，对象会被**优先分配**到新生代的**Eden区**\n    - 此时JVM会给对象定义一个**对象年轻计数器**（`-XX:MaxTenuringThreshold`）\n3. 当Eden空间不足时，JVM将执行新生代的垃圾回收（**Minor GC**）\n    - JVM会把存活的对象转移到Survivor中，并且对象年龄+1\n    - 对象在Survivor中同样也会经历Minor GC，每经历一次Minor GC，对象年龄都会+1\n4. 如果分配的对象超过了`-XX:PetenureSizeThreshold`，对象会**直接被分配到老年代**\n\n<!-- more -->\n\n## 查看JVM堆内存分配\n1. 在默认不配置JVM堆内存大小的情况下，JVM根据默认值来配置当前内存大小\n2. 在JDK 1.7中，默认情况下**新生代**和**老年代**的比例是**1:2**，可以通过`–XX:NewRatio`来配置\n    - 新生代中的**Eden**:**From Survivor**:**To Survivor**的比例是**8:1:1**，可以通过`-XX:SurvivorRatio`来配置\n3. 若在JDK 1.7中开启了`-XX:+UseAdaptiveSizePolicy`，JVM会**动态调整**JVM**堆中各个区域的大小**以及**进入老年代的年龄**\n    - 此时`–XX:NewRatio`和`-XX:SurvivorRatio`将会失效，而JDK 1.8是默认开启`-XX:+UseAdaptiveSizePolicy`\n    - 在JDK 1.8中，**不要随意关闭**`-XX:+UseAdaptiveSizePolicy`，除非对堆内存的划分有明确的规划\n    - 每次**GC后**都会**重新计算**Eden、From Survivor、To Survivor的大小\n        - 计算依据是**GC过程**中统计的**GC时间**、**吞吐量**、**内存占用量**\n\n```\n$ java -XX:+PrintFlagsFinal -version | grep HeapSize\n    uintx ErgoHeapSizeLimit                         = 0               {product}\n    uintx HeapSizePerGCThread                       = 87241520        {product}\n    uintx InitialHeapSize                          := 261304192       {product}\n    uintx LargePageHeapSizeThreshold                = 134217728       {product}\n    uintx MaxHeapSize                              := 4181721088      {product}\njava version \"1.7.0_67\"\nJava(TM) SE Runtime Environment (build 1.7.0_67-b01)\nJava HotSpot(TM) 64-Bit Server VM (build 24.65-b04, mixed mode)\n```\n```\n$ jmap -heap 10773\nAttaching to process ID 10773, please wait...\nDebugger attached successfully.\nServer compiler detected.\nJVM version is 24.65-b04\n\nusing thread-local object allocation.\nGarbage-First (G1) GC with 12 thread(s)\n\nHeap Configuration:\n   MinHeapFreeRatio = 40\n   MaxHeapFreeRatio = 70\n   MaxHeapSize      = 268435456 (256.0MB)\n   NewSize          = 1363144 (1.2999954223632812MB)\n   MaxNewSize       = 17592186044415 MB\n   OldSize          = 5452592 (5.1999969482421875MB)\n   NewRatio         = 2\n   SurvivorRatio    = 8\n   PermSize         = 134217728 (128.0MB)\n   MaxPermSize      = 134217728 (128.0MB)\n   G1HeapRegionSize = 4194304 (4.0MB)\n\nHeap Usage:\nG1 Heap:\n   regions  = 64\n   capacity = 268435456 (256.0MB)\n   used     = 89813712 (85.65303039550781MB)\n   free     = 178621744 (170.3469696044922MB)\n   33.45821499824524% used\nG1 Young Generation:\nEden Space:\n   regions  = 11\n   capacity = 163577856 (156.0MB)\n   used     = 46137344 (44.0MB)\n   free     = 117440512 (112.0MB)\n   28.205128205128204% used\nSurvivor Space:\n   regions  = 1\n   capacity = 4194304 (4.0MB)\n   used     = 4194304 (4.0MB)\n   free     = 0 (0.0MB)\n   100.0% used\nG1 Old Generation:\n   regions  = 11\n   capacity = 100663296 (96.0MB)\n   used     = 39482064 (37.65303039550781MB)\n   free     = 61181232 (58.34696960449219MB)\n   39.221906661987305% used\nPerm Generation:\n   capacity = 134217728 (128.0MB)\n   used     = 41068592 (39.16606140136719MB)\n   free     = 93149136 (88.83393859863281MB)\n   30.598485469818115% used\n\n16298 interned Strings occupying 1462984 bytes.\n```\n\n## 内存泄露 / 内存溢出\n1. 内存泄露：**不再使用的对象无法得到及时的回收**，持续占用内存空间，从而造成内存空间的浪费\n2. 内存溢出：如**堆**内存空间不足，**栈**空间不足，**方法区**空间不足等\n3. 关系：_**内存泄露可能导致内存溢出，但内存溢出不一定是内存泄露导致的**_","tags":["Java Performance"],"categories":["Performance"]},{"title":"Kafka -- 监控消费进度","url":"%2F2019%2F09%2F12%2Fkafka-monitor-consume-progress%2F","content":"\n## Consumer Lag\n1. Consumer Lag（滞后程度）：**消费者当前落后于生产者的程度**\n2. Lag的单位是**消息数**，一般是在**主题**的级别上讨论Lag，但Kafka是在**分区**的级别上**监控**Lag，因此需要手动汇总\n3. 对于消费者而言，Lag是**最重要**的监控指标，直接反应了一个消费者的运行情况\n    - 一个正常工作的消费者，它的Lag值应该很小，甚至**接近于0**，**滞后程度很小**\n    - 如果Lag很大，表明消费者无法跟上生产者的速度，Lag会越来越大\n        - 极有可能导致消费者消费的数据已经不在**操作系统的页缓存**中了，这些数据会失去享有**Zero Copy**技术的资格\n        - 这样消费者不得不从**磁盘**读取这些数据，这将**进一步拉大**与生产者的差距\n        - 马太效应：_**Lag原本就很大的消费者会越来越慢，Lag也会也来越大**_\n\n<!-- more -->\n\n## 监控Lag\n\n### Kafka自带命令\n1. `kafka-consumer-groups`是Kafka提供的**最直接**的监控消费者消费进度的工具\n    - 也能监控**独立消费者**的Lag，独立消费者是没有使用**消费者组机制**的消费者程序，也要配置`group.id`\n    - **消费者组**要调用`KafkaConsumer.subscribe`，**独立消费者**要调用`KafkaConsumer.assign`**直接消费指定分区**\n2. 输出信息\n    - 消费者组、主题、分区、消费者实例ID、消费者连接Broker的主机名、消费者的CLIENT-ID信息\n    - **CURRENT-OFFSET**：消费者组当前最新消费消息的位移值\n    - **LOG-END-OFFSET**：每个分区当前最新生产的消息的位移值\n    - **LAG**：LOG-END-OFFSET和CURRENT-OFFSET的**差值**\n\n```\n$ kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group zhongmingmao\n\nGROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                     HOST            CLIENT-ID\nzhongmingmao    zhongmingmao    1          5               5               0               consumer-1-24d9f1a8-662a-4d20-a360-26a12ddb0902 /192.168.2.1    consumer-1\nzhongmingmao    zhongmingmao    0          5               5               0               consumer-1-24d9f1a8-662a-4d20-a360-26a12ddb0902 /192.168.2.1    consumer-1\nzhongmingmao    zhongmingmao    4          6               6               0               consumer-1-24d9f1a8-662a-4d20-a360-26a12ddb0902 /192.168.2.1    consumer-1\nzhongmingmao    zhongmingmao    3          6               6               0               consumer-1-24d9f1a8-662a-4d20-a360-26a12ddb0902 /192.168.2.1    consumer-1\nzhongmingmao    zhongmingmao    2          6               6               0               consumer-1-24d9f1a8-662a-4d20-a360-26a12ddb0902 /192.168.2.1    consumer-1\n\n$ kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group zhongmingmao\n\nConsumer group 'zhongmingmao' has no active members.\n\nGROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID\nzhongmingmao    zhongmingmao    1          5               5               0               -               -               -\nzhongmingmao    zhongmingmao    0          5               5               0               -               -               -\nzhongmingmao    zhongmingmao    4          6               6               0               -               -               -\nzhongmingmao    zhongmingmao    3          6               6               0               -               -               -\nzhongmingmao    zhongmingmao    2          6               6               0               -               -               -\n```\n\n### Kafka Java Consumer API\n```java\nprivate Map<TopicPartition, Long> lagOf(String groupId, String bootstrapServers) throws TimeoutException {\n    Properties props = new Properties();\n    props.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    try (AdminClient client = AdminClient.create(props)) {\n        // 获取给定消费者组的最新消费消息的位移\n        ListConsumerGroupOffsetsResult result = client.listConsumerGroupOffsets(groupId);\n        try {\n            Map<TopicPartition, OffsetAndMetadata> consumedOffsets = result.partitionsToOffsetAndMetadata().get(10, TimeUnit.SECONDS);\n            props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); // 禁止自动提交位移\n            props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);\n            props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n            props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n            try (final KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)) {\n                // 获取订阅分区的最新消息位移\n                Map<TopicPartition, Long> endOffsets = consumer.endOffsets(consumedOffsets.keySet());\n                return endOffsets.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                        // 计算Lag\n                        entry -> entry.getValue() - consumedOffsets.get(entry.getKey()).offset()));\n            }\n        } catch (InterruptedException e) {\n            // 处理中断异常\n            Thread.currentThread().interrupt();\n            return Collections.emptyMap();\n        } catch (ExecutionException e) {\n            return Collections.emptyMap();\n        } catch (TimeoutException e) {\n            throw new TimeoutException(\"Timed out when getting lag for consumer group \" + groupId);\n        }\n    }\n}\n\n@Test\npublic void getLagTest() throws TimeoutException {\n    lagOf(\"zhongmingmao\", \"localhost:9092\")\n            .forEach((topicPartition, lag) -> log.info(\"partition: {}, lag: {}\", topicPartition, lag));\n}\n```\n```\npartition: zhongmingmao-1, lag: 0\npartition: zhongmingmao-0, lag: 0\npartition: zhongmingmao-4, lag: 0\npartition: zhongmingmao-3, lag: 0\npartition: zhongmingmao-2, lag: 0\n```\n\n### Kafka JMX 监控指标\n1. 上面的两种方式，都可以很方便地查询到给定消费者组的Lag信息\n2. 但在实际监控场景中，往往需要借助现成的**监控框架**（如**Zabbix/Grafana**）\n    - 此时可以选择Kafka默认提供的**JMX监控指标**来监控消费者的Lag值\n3. **消费者**提供了`kafka.consumer:type=consumer-fetch-manager-metrics,client-id=\"{client-id}\"`的JMX指标\n    - `records-lag-max`和`records-lead-min`分别代表此**消费者**在**测试窗口时间**内曾经达到的**最大Lag值**和**最小Lead值**\n    - Lead：消费者**最新消费消息的位移**与**当前分区第一条消息位移**的差值，_**Lag越大，Lead越小**_\n    - 一旦监测到**Lead**越来越小，甚至**快接近于0**，预示着消费者端要**丢消息**了\n    - Kafka消息是有**留存时间**的，默认是**1周**，如果消费者程序足够慢，慢到它要消费的数据快被Kafka**删除**\n        - 一旦出现消息被删除，从而导致消费者程序**重新调整位移值**的情况，可能产生两个后果\n        - 一个是消费者**从头消费一遍**数据\n        - 另一个是消费者从**最新的消息位移处**开始消费，之前**没来得及消费的消息**全部被**跳过**，造成**丢消息的假象**\n    - Lag值从100W增加到200W，远不如Lead值从200减少到100重要，实际生产环境中，要**同时监控Lag值和Lead值**\n4. **消费者**还在**分区级别**提供了额外的JMX指标，用于**单独监控**分区级别的Lag和Lead值\n    - `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=\"{client-id}\",topic=\"{topic}\",partition=\"{partition}\"`\n    - 多了`records-lag-avg`和`records-lead-avg`，可以计算**平均**的Lag值和Lead值，经常使用\n\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-consumer-jmx-lag-lead.png\" width=1000/>\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-consumer-jmx-partition-lag-lead.png\" width=1000/>","tags":["Stream"],"categories":["Kafka"]},{"title":"Java性能 -- GC","url":"%2F2019%2F09%2F11%2Fjava-performance-gc%2F","content":"\n## GC机制\n\n### 回收区域\n1. JVM的内存区域中，**程序计数器**、**虚拟机栈**、**本地方法栈**是**线程私有**，随线程的创建而创建，销毁而销毁\n    - 栈中的栈帧随着方法的进入和退出进行**入栈**和**出栈**操作，每个栈帧分配多少内存基本是在**类结构**确定下来时就已知\n    - 因此，这三个区域的内存**分配**和**回收**都是具有**确定性**的\n2. **堆**中的回收主要是**对象**回收，**方法区**的回收主要是**废弃常量**和**无用类**的回收\n\n<!-- more -->\n\n### 回收时机\n1. 当一个对象**不再被引用**，就代表该对象**可以被回收**\n2. **引用计数法**：实现简单，判断效率高，但存在**循环引用**的问题\n3. **可达性分析算法**：HotSpot VM\n\n| 引用类型 | 功能特点 |\n| --- | --- |\n| **强引用**（Strong Reference） | 被强引用关联的对象，**永远**不会被垃圾回收器回收 |\n| **软引用**（Soft Reference） | 被软引用关联的对象，只有当系统将要发生**内存溢出**时，才会去回收软引用关联的对象 |\n| **弱引用**（Weak Reference） | **只**被弱引用关联的对象，**只要发生GC事件**，就会被回收 |\n| **虚引用**（Phantom Reference） | 被虚引用关联的对象，**唯一作用**是在这个对象被回收时收到一个**系统通知** |\n\n### 回收特性\n1. **自动性**\n    - Java提供了一个**系统级**的线程来**跟踪**每一块分配出去的内存空间\n    - 当JVM处于**空闲循环**时，GC线程会自动检查每一块分配出去的内存空间，然后自动回收每一块空闲的内存块\n1. **不可预期性**\n    - 很难确定一个没有被引用的对象是否会被立即回收，有可能当程序结束时，该对象仍在内存中\n    - GC线程在JVM中是**自动执行**的，**Java程序无法强制执行**，`System.gc`也只是**建议**执行垃圾回收\n\n## GC算法\nJVM提供了不同的GC算法来实现上面的GC机制\n\n| GC算法类型 | 优点 | 缺点 |\n| --- | --- | --- |\n| **Mark-Sweep** | 不需要移动对象，简单高效 | **效率低**、产生**内存碎片** |\n| **Copying** | 简单高效，不会产生内存碎片 | **内存使用率低**，有可能**频繁复制** |\n| **Mark-Compact** | 综合了前两种算法的优点 | 仍需要**移动局部对象** |\n\n## GC分类\n1. 不管是什么GC，**都会有STW**，只有**时间长短**的区别（CMS和G1的STW会短很多）\n2. 不用纠结于细分`Major GC`和`Full GC`，一次Full GC将对**新生代**、老年代、**元空间**、**堆外内存**进行垃圾回收\n3. 触发Full GC的原因\n    - 当新生代**晋升**到老年代的对象大小，比目前**老年代剩余的空间**还大\n    - 当**老年代的空间使用率**超过某个**阈值**\n    - 当**元空间**不足时（JDK 7**永久代**不足）\n    - 调用`System.gc()`\n\n## 垃圾回收器\n\n### 分类\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-gc-1.png\" width=1000>\n\n### 组合\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-gc-2.jpg\" width=800>\n\n### CMS / G1\n\n#### CMS\n1. CMS是基于**标记清除**算法实现的，用于**老年代**GC\n2. CMS的GC周期主要由**7个阶段**组成，其中两个阶段会发生**STW**，其它阶段都是**并发执行**的\n\n| 阶段 | 描述 |\n| --- | --- |\n| **Initial Mark** | **STW**，**并行**标记**可直达的存活对象** |\n| Concurrent Mark | 1. **并发执行**<br/>2. 继续**递归**遍历**老年代**，并标记可**直接**或**间接**到达的所有老年代存活对象<br/>3. 由于并发执行，对象可能发生**变化**，变化的对象所在的**Card**标识为**Dirty** |\n| Concurrent Preclean | 重新扫描前一阶段标记的Dirty对象，并标记被Dirty对象直接或间接引用的对象，然后清除Card标识 |\n| Concurrent Abortable Preclean | 标记可达的老年代对象，扫描处理**Dirty Card**中的对象 |\n| **Fianl Remark** | **STW**，重新扫描之前**并发**处理阶段的所有**残留**更新对象 |\n| Concurrent Sweep | 清理所有**未被标记**的**死亡**对象，回收被占用的空间 |\n| Concurrent Reset | 清理并恢复在CMS GC过程中的各种状态，重新初始化CMS相关数据结构 |\n\n#### G1\n1. G1是基于**标记整理**算法实现的，是一个**分代**垃圾收集器，既负责**新生代**的GC，也负责**老年代**的GC\n2. G1之前的各个分代使用的是**连续的虚拟内存地址**，G1使用了**Region**的方式对**堆内存**进行划分\n    - 同样也分**新生代**和**老年代**，每一代使用的是N个**不连续**的Region内存块，每个Region占用一块**连续**的虚拟内存地址\n    - G1中还有一种称为**Humongous**区域，用于存储**特别大**的对象\n        - G1优化：一旦发现没有引用指向**巨型对象**，则可直接在**新生代的Young GC**中被回收掉\n3. G1分为**Young GC**、**Mix GC**和**Full GC**\n    - Young GC主要是在**Eden**区进行，当Eden区空间不足时，会触发一次Young GC\n        - 将Eden区数据转移到Surivivor，如果Surivivor空间不足，（包括Surivivor的数据）则会**直接晋升**到老年代\n        - Young GC是**并行**执行的，也会发生**STW**\n    - 当堆空间的**占用率**达到一定阈值后会触发**G1 Mix GC**（参数`-XX:InitiatingHeapOccupancyPercent`，默认**45**）\n        - Mix GC主要包括4个阶段，其中只有**并发标记**阶段不会发生STW，其它阶段均会发生STW\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-gc-g1-heap.jpg\" width=800/>\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-gc-g1-young-mix.jpg\" width=1000/>\n\n#### 对比\n1. **CMS**主要集中在**老年代**的回收，而**G1**集中在**分代**回收，包括**新生代的Young GC**和**老年代的Mix GC**\n2. G1使用了**Region**的方式对堆内存进行划分，基于**标记整理**算法实现，整体减少了垃圾碎片的产生\n3. 在**初始化标记**阶段，**搜索可达对象**时使用到了**Card Table**，但实现方式不一样\n    - 在GC时，都是从**GC Root**开始搜索，有可能新生代引用到老年代对象，也有可能老年代引用到新生代对象\n    - 如果发生**Young GC**，除了**从新生代扫描根对象**，还需要**从老年代扫描根对象**，确认引用新生代对象的情况\n        - 这属于**跨代处理**，非常**消耗性能**\n        - 为了避免在**回收新生代**时跨代**扫描整个老年代**，**CMS**和**G1**都使用了**Card Table**来记录这些**引用关系**\n        - 只是**G1**在Card Table的基础上引入了**RSet**\n    - 每个**Region**初始化时，都会初始化一个**RSet**，RSet记录了_**其它Region中的对象引用本Region对象的关系**_\n4. CMS和G1在解决**并发标记漏标**的方式也不一样，**CMS**使用的是**Incremental Update**算法，**G1**使用的是**SATB**算法\n    - 在**并发标记**中，CMS和G1都是基于**三色标记**算法实现的\n        - **黑色**：节点被遍历完成，且子节点都遍历完成\n        - **灰色**：当前正在遍历的节点，且子节点还没有遍历\n        - **白色**：还没有遍历到的节点，即灰色节点的子节点\n    - 漏标问题\n        - 当一个**白色**标记对象在GC被清理掉时，正好有一个对象引用了该白色标记对象，就会出现**对象丢失**的问题\n        - 如下图所示，`B->D`的引用断开，换成了`A->D`的引用，由于A已经是**黑色**，JVM不会再扫描A及其子节点了\n            - 如果不做处理，那么就会**漏标D对象**\n    - **CMS：Incremental Update**\n        - 只要在**写屏障**里发现**一个白对象的引用被赋值到一个黑对象的字段里**，那就把这个白对象变成**灰色**的\n    - **G1：STAB**\n        - STAB算法认为**开始时所有能遍历到的对象**都是需要标记的，即认为**都是活**的\n        - STAB的全称为`snapshot-at-the-beginning`，目的是为了维持**并发GC的正确性**\n        - GC正确性：**保证存活的对象不被回收**，即不存在漏标问题，即保证回收的都是**真正的垃圾**\n        - 如果标记过程是**STW**，那么**GC的正确性**肯定是能够**保证**的，但并发标记就不一定了\n        - STAB：在GC开始时对内存进行一个_**对象图的逻辑快照**_\n            - **只要被快照到的对象在整个GC过程中都是活的**，即使该对象的引用稍后被修改或删除\n            - 同时**新分配**的对象也会被认为是**活**的，除此之外**其它不可达的对象**被认为是**死**的\n        - STAB能够**保证真正存活的对象不会被GC误回收**，但也造成了可以被回收的对象逃过了GC，导致了**浮动垃圾**\n5. G1具备**Pause Prediction Model**，参数`-XX:MaxGCPauseMillis`，默认值为**200ms**\n    - 根据模型统计出来的**历史数据**来预测**下一次GC所需要的Region数量**，_**通过控制Region数来控制目标停顿时间**_\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-gc-3color.png\" width=1000/>\n\n## GC性能指标\n1. **吞吐量**\n    - 吞吐量 = 应用程序耗时 / (应用程序耗时 + GC耗时)\n    - 吞吐量一般**不能低于95%**\n2. **停顿时间**\n    - 对于串行回收器来说，停顿时间可能会比较长\n    - 而使用**并发**回收器，由于垃圾收集器和应用程序**交替运行**，程序的**停顿时间会变短**\n        - 但**效率**很可能**不如独占垃圾收集器**，**吞吐量**也可能**降低**\n3. **GC频率**\n    - 增大**堆内存**空间可以有效降低GC频率，但也意味着堆积的回收对象越多，会增加回收时的停顿时间\n    - 可以适当地加大堆内存空间，保证正常的GC频率即可\n\n## GC日志分析\n1. JVM参数\n    - `-XX:+PrintGC`：输出GC日志\n    - `-XX:+PrintGCDetails`：输出GC的详细日志\n    - `-XX:+PrintGCTimeStamps`：输出GC的时间戳（以基准时间的形式）\n    - `-XX:+PrintGCDateStamps`：输出GC的时间戳（以日期的形式，如2013-05-04T21:53:59.234+0800）\n    - `-XX:+PrintHeapAtGC`：在进行GC的前后打印出堆的信息\n    - `-Xloggc:../logs/gc.log`：GC日志文件的输出路径\n2. 分析工具\n    - _**[GCeasy（推荐）](https://www.gceasy.io/index.jsp)**_\n    - [GCViewer](https://sourceforge.net/projects/gcviewer/)\n    \n## GC调优策略\n\n### 降低Minor GC频率\n1. 由于新生代空间较小，Eden区很快被填满，就会导致频繁Minor GC，可以通过**增大新生代空间**来**降低Minor GC频率**\n2. 单次Minor GC时间由两部分组成：T1（**扫描新生代**）+ T2（**复制存活对象**）\n3. 假设一个对象在Eden区的存活时间为500ms，Minor GC的时间间隔为300ms\n    - 由于该对象依然存活，Minor GC的时间为**T1+T2**\n4. 如果增大新生代空间，Minor GC的时间间隔扩大到600ms\n    - 此时存活时间为500ms的对象会在Eden区被回收，**不存在复制存活对象**，此时Minor GC时间为**2T1**\n    - 新生代扩容后，Minor GC增加了T1，但减少了T2，通常在JVM中，_**T2远大于T1**_\n5. 小结\n    - 如果堆内存中**长期对象很多**，扩容新生代，反而会增加Minor GC的时间\n    - 如果堆内存中**短期对象很多**，扩容新生代，_**单次Minor GC的时间不会显著增加**_\n        - 单次Minor GC的时间更多地取决于**GC后存活对象的数量**，而非Eden区的大小\n\n### 降低Full GC频率\n1. 由于**堆内存空间不足**或者**老年代对象太多**，会触发Full GC（带来**上下文切换**，增加系统的**性能开销**）\n2. 常见优化点：**减少创建大对象**、**增大堆内存空间（初始化堆内存为最大堆内存）**\n\n### 选择合适的GC回收器\n1. **响应速度快：CMS、G1**\n2. **吞吐量高：Parallel Scavenge**","tags":["GC"],"categories":["Performance"]},{"title":"Kafka -- Java消费者管理TCP连接","url":"%2F2019%2F09%2F10%2Fkafka-consumer-manage-tcp-connection%2F","content":"\n## 创建TCP连接\n1. 消费者端的主要程序入口是KafkaConsumer，但**构建KafkaConsumer实例不会创建任何TCP连接**\n    - 构建**KafkaProducer**实例时，会在后台默默地启动一个**Sender**线程，Sender线程负责**Socket**连接的创建\n    - 在Java构造函数中启动线程，会造成**this指针逃逸**，是一个**隐患**\n2. 消费者的TCP连接是在调用**`KafkaConsumer.poll`**方法时被创建的，poll方法内部有3个时机可以创建TCP连接\n\n<!-- more -->\n\n### 发起FindCoordinator请求时\n1. 消费者组有个组件叫作**协调者**（Coordinator）\n    - 驻留在**Broker**端的内存中，负责消费者组的**组成员管理**和各个消费者的**位移提交管理**\n2. 当消费者程序**首次**启动调用poll方法时，需要向**Kafka集群**（集群中的**任意**Broker）发送FindCoordinator请求\n    - 社区优化：消费者程序会向集群中**当前负载最小**的那台Broker发送请求\n    - **单向**负载评估（**非最优解**）：消费者连接的所有Broker中，谁的**待发送**请求最少，谁的负载就越小\n\n### 连接Coordinator时\n1. Broker处理完FindCoordinator请求后，会返回对应的响应结果，显式地告诉消费者哪个Broker是**真正的Coordinator**\n2. 消费者向真正的Coordinator所在的Broker发起Socket连接\n3. 成功接入Coordinator后，Coordinator开启**组协调**操作（加入组、等待组分配、心跳请求处理、位移获取和提交）\n\n### 消费数据时\n1. 消费者会为每个要消费的分区创建与该分区**领导者副本**所在Broker的Socket连接\n2. 假设消费者要消费5个分区的数据，这5个分区各自的领导者副本分布在4台Broker上\n    - 那么消费者在消费时会创建与这4台Broker的Socket连接\n\n## TCP连接数\n\n### 日志详解\n>[2019-05-27 10:00:54,142] DEBUG [Consumer clientId=consumer-1, groupId=test] **Initiating connection to node localhost:9092** (**id: -1** rack: null) using address localhost/127.0.0.1 (org.apache.kafka.clients.NetworkClient:944)\n\n消费者程序创建的**第一个TCP连接**，该Socket用于发送**FindCoordinator**请求\n此时消费者对要连接的Kafka集群**一无所知**，因此它连接的Broker节点的ID为**-1**，表示不知道要连接的Broker的任何信息\n\n---\n\n>[2019-05-27 10:00:54,188] DEBUG [Consumer clientId=consumer-1, groupId=test] **Sending metadata request** MetadataRequestData(topics=[MetadataRequestTopic(name='t4')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node localhost:9092 (id: -1 rack: null) (org.apache.kafka.clients.NetworkClient:1097)\n\n消费者**复用**刚刚创建的Socket连接，向Kafka集群发送**元数据请求**以获取**整个集群的信息**\n\n---\n\n>[2019-05-27 10:00:54,188] TRACE [Consumer clientId=consumer-1, groupId=test] **Sending FIND_COORDINATOR** {key=test,key_type=0} with correlation id 0 to **node -1** (org.apache.kafka.clients.NetworkClient:496)\n\n消费者程序开始发送**FindCoordinator**请求给第一步中连接的Broker，即**localhost:9092**（nodeId为**-1**）\n\n---\n\n>[2019-05-27 10:00:54,203] TRACE [Consumer clientId=consumer-1, groupId=test] **Completed receive from node -1 for FIND_COORDINATOR** with correlation id 0, received {throttle_time_ms=0,error_code=0,error_message=null, **node_id=2,host=localhost,port=9094**} (org.apache.kafka.clients.NetworkClient:837)\n\n十几毫秒后，消费者程序成功地获悉**Coordinator所在的Broker**，即**node_id=2,host=localhost,port=9094**\n\n---\n\n>[2019-05-27 10:00:54,204] DEBUG [Consumer clientId=consumer-1, groupId=test] **Initiating connection to node localhost:9094** (**id: 2147483645** rack: null) using address localhost/127.0.0.1 (org.apache.kafka.clients.NetworkClient:944)\n\n消费者此时已经知道**协调者Broker的连接信息**了，发起第二个Socket连接，创建连向**localhost:9094**的TCP连接\n只有连接了Coordinator，消费者才能正常地开启**消费组的各种功能**以及**后续的消息消费**\n此时的id是由`Integer.MAX_VALUE`减去**Coordinator所在的Broker的Id**计算出来的，即`2147483647 - 2 = 2147483645`\n这种节点ID的标记方式是Kafka社区**特意为之**，目的是要让**组协调请求**和**真正的数据获取请求**使用_**不同的Socket连接**_\n\n---\n\n>[2019-05-27 10:00:54,237] DEBUG [Consumer clientId=consumer-1, groupId=test] **Initiating connection to node localhost:9094** (**id: 2** rack: null) using address localhost/127.0.0.1 (org.apache.kafka.clients.NetworkClient:944)\n\n>[2019-05-27 10:00:54,237] DEBUG [Consumer clientId=consumer-1, groupId=test] **Initiating connection to node localhost:9092** (**id: 0** rack: null) using address localhost/127.0.0.1 (org.apache.kafka.clients.NetworkClient:944)\n\n>[2019-05-27 10:00:54,238] DEBUG [Consumer clientId=consumer-1, groupId=test] **Initiating connection to node localhost:9093** (**id: 1** rack: null) using address localhost/127.0.0.1 (org.apache.kafka.clients.NetworkClient:944)\n\n消费者又分别创建了**新的TCP连接**，主要用于**实际的消息获取**\n\n### 3类TCP连接\n1. **确定协调者**和**获取集群元数据**\n2. **连接协调者**，令其执行组成员管理操作\n3. 执行**实际的消息获取**\n\n## 关闭TCP连接\n1. 与生产者类似，消费者关闭Socket分为**主动关闭**和**Kafka自动关闭**\n    - **主动关闭**\n        - 手动调用**KafkaConsumer.close**或者执行**kill**（-2/-9）命令\n    - **自动关闭**\n        - 消费端参数**`connection.max.idle.ms`**，默认是**9分钟**\n        - 如果使用**循环**的方式来调用**poll**方法来消费消息，上面的**所有请求**都会**定期**发送到Broker，达到**长连接**的效果\n2. 当**第三类TCP连接成功创建**后，消费者程序就会**废弃第一类TCP连接**，之后**定期请求元数据**，会改用第三类TCP连接\n    - 第一类TCP连接会在后台被默默关闭，运行一段时间的消费者只会有后面两类TCP连接存在","tags":["TCP"],"categories":["Kafka"]},{"title":"Java性能 -- JIT","url":"%2F2019%2F09%2F09%2Fjava-performance-jit%2F","content":"\n## 编译\n1. **前端编译**：即常见的**.java文件**被编译成**.class文件**的过程\n2. **运行时编译**：机器无法直接运行Java生成的字节码，在**运行时**，**JIT**或者**解释器**会将**字节码**转换为**机器码**\n    - 类文件在运行时被进一步编译，可以变成**高度优化**的机器代码\n3. C/C++编译器的所有优化都是在**编译期**完成的，运行期的性能监控仅作为基础的优化措施是无法进行的\n4. **JIT编译器**是JVM中**运行时编译**最重要的部分之一\n\n<!-- more -->\n\n## 编译 / 加载 / 执行\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-jit-compile-run.jpg\" width=1000>\n\n### 类编译\n1. **javac**：将.java文件**编译**成.class文件\n2. **javap**：**反编译**.class文件，重点关注**常量池**和**方法表集合**\n    - 常量池主要记录的是类文件中出现的**字面量**和**符号引用**\n        - 字面量：**字符串常量**、**基本类型的常量**\n        - 符号引用：**类和接口的全限定名**、**类引用**、**方法引用**、**成员变量引用**\n    - 方法表集合\n        - 方法的字节码、方法访问权限、方法名索引、描述符索引、JVM执行指令、属性集合等\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-jit-javap.png\" width=1000>\n\n### 类加载\n1. 当一个类**被创建实例**或者**被其他对象引用**时，JVM如果没有加载过该类，会通过**类加载器**将**.class文件**加载到**内存**中\n2. 不同的实现类由不同的类加载器加载\n    - **JDK中的本地方法类**一般由根加载器（**Bootstrap Loader**）加载\n    - **JDK中内部实现的扩展类**一般由扩展加载器（**ExtClassLoader**）加载\n    - **程序中的类文件**则由系统加载器（**AppClassLoader**）加载\n3. 在类加载后，.class类文件中的**常量池信息**以及其他数据会被保存到JVM内存的**方法区**中\n\n### 类连接\n1. 类在加载进内存后，会进行**连接、初始化**，最后才能被使用，连接又包括**验证**、**准备**、**解析**三部分\n2. 验证\n    - 验证类**符合JVM规范**，在保证符合规范的前提下，**避免危害虚拟机安全**\n3. 准备\n    - **为类的静态变量分配内存**，初始化为**系统的初始值**\n    - 对于`final static`修饰的变量，**直接赋值**为用户的定义值\n        - `private final static int value = 123`，会在准备阶段分配内存，并初始化值为**123**\n        - `private static int value = 123`，会在准备阶段分配内存，并初始化值为**0**\n4. 解析\n    - 将**符号引用**转为**直接引用**\n    - 在**编译**时，Java类**并不知道**所引用的类的**实际地址**，因此只能使用符号引用来代替\n    - **.class文件的常量池**中存储了**符号引用**，实际使用时，需要将它们转化为**JVM能直接获取的内存地址或指针**\n\n### 类初始化\n1. 类初始化是类加载过程的最后阶段，首先执行构造器**`<clinit>`**方法\n2. 前端编译时（**javac**），收集所有的**静态变量赋值语句**、*s*静态代码块**、**静态方法**，成为**`<clinit>`**方法\n3. 初始化类的**静态变量**和**静态代码块**均为用户自定义的值，初始化顺序和Java源码**从上到下**的顺序一致\n4. 子类初始化时，会先调用**父类**的**`<clinit>`**方法，再调用子类的**`<clinit>`**方法\n5. JVM会保证**`<clinit>`**方法的**线程安全**，保证同一时间只有一个线程执行\n6. JVM在**实例化新对象**时，会调用**`<init>`**方法对**实例变量**进行初始化，并执行对应的构造方法内的代码\n\n## 即时编译\n1. 初始化完成后，类在调用执行过程中，执行引擎需要把**字节码**转换为**机器码**，然后才能在**操作系统**中执行\n    - 在字节码转换为机器码的过程中，虚拟机还存在着一道编译，那就是**即时编译**\n2. 起初，虚拟机中的字节码是由**解释器**（Interpreter）完成编译的\n    - 当虚拟机发现某个方法或者代码块运行得特别频繁的时候，就会把这些代码认定为**热点代码**\n    - 为了提高热点代码的**执行效率**，**JIT**会把热点代码编译成**与本地平台相关的高度优化的机器码**，然后保存在**内存**中\n\n### 即时编译类型\n1. 在**HotSpot VM**中，内置了两个JIT，分别是**C1**编译器（**Client** Compiler）和**C2**编译器（**Server** Compiler）\n2. **C1**编译器是一个**简单快速**的编译器，主要的关注点在于**局部性**的优化，适用于**执行时间较短**或**对启动速度有要求**的程序\n3. **C2**编译器是为**长期运行**的**服务器端**应用程序做性能调优的编译器，适用于**执行时间较长**或**对峰值性能有要求**的程序\n4. 在Java 7之前，需要根据**应用的特性**来选择对应的JIT，虚拟机默认采用**解释器**和其中一个**即时编译器**配合工作\n5. **Java 7引入了分层编译**，综合了**C1的启动性能优势**和**C2的峰值性能优势**\n    - 也可以通过参数`-client`、`-server`强制指定虚拟机的**即时编译模式**\n    - 分层编译是将**JVM的执行状态**分了5个层次\n    - 第0层\n        - 程序解释执行，默认开启Profiling（如果不开启，可触发第2层编译）\n    - 第1层\n        - 称为C1编译，将字节码编译为本地代码，进行**简单可靠**的优化，不开启Profiling\n    - 第2层\n        - 称为C1编译，开启Profiling，仅执行带**方法调用次数**和**循环回边执行次数**Profiling的C1编译\n    - 第3层\n        - 称为C1编译，开启Profiling，执行**所有**带Profiling的C1编译\n    - 第4层\n        - 称为C2编译，将字节码编译为本地代码\n        - 但会启用一些**编译耗时较长**的优化，甚至会根据性能监控信息进行一些**不可靠的激进优化**\n6. Java 8**默认开启分层编译**，参数`-client`、`-server`已失效\n    - 如果**只想开启C2**，可以**关闭分层编译**`-XX:-TieredCompilation`\n    - 如果**只想开启C1**，可以**打开分层编译**，并且使用参数`-XX:TieredStopAtLevel=1`\n7. **单一编译模式**（上面的都是**混合编译**模式）\n    - **`-Xint`**\n        - 强制虚拟机运行于**只有解释器的编译模式下**，**JIT完全不介入工作**\n    - **`-Xcomp`**\n        - 强制虚拟机运行于**只有JIT的编译模式下**\n\n```\n$ java -version\nopenjdk version \"1.8.0_222\"\nOpenJDK Runtime Environment (Zulu 8.40.0.25-CA-macosx) (build 1.8.0_222-b10)\nOpenJDK 64-Bit Server VM (Zulu 8.40.0.25-CA-macosx) (build 25.222-b10, mixed mode)\n\n$ java -Xint -version\nopenjdk version \"1.8.0_222\"\nOpenJDK Runtime Environment (Zulu 8.40.0.25-CA-macosx) (build 1.8.0_222-b10)\nOpenJDK 64-Bit Server VM (Zulu 8.40.0.25-CA-macosx) (build 25.222-b10, interpreted mode)\n\n$ java -Xcomp -version\nopenjdk version \"1.8.0_222\"\nOpenJDK Runtime Environment (Zulu 8.40.0.25-CA-macosx) (build 1.8.0_222-b10)\nOpenJDK 64-Bit Server VM (Zulu 8.40.0.25-CA-macosx) (build 25.222-b10, compiled mode)\n```\n\n### 热点探测\n1. HotSpot VM的热点探测是JIT优化的条件，热点探测是基于**计数器**的热点探测\n    - 采用这种方法的虚拟机会为每个方法建立**计数器**统计方法的执行次数\n    - 如果执行次数超过一定的**阈值**就认为是热点方法\n2. 虚拟机为**每个方法**准备了两类计数器：**方法调用计数器**（Invocation Counter）、**回边计数器**（Back Edge Counter）\n    - 在确定虚拟机运行参数的前提下，这两个计数器都有一个**明确的阈值**，当计数器**超过阈值**，就会触发**JIT编译**\n3. **方法调用计数器**\n    - **C1**模式下是**1500**次，**C2**模式下是**10000**次，可通过参数`-XX:CompileThreshold`来设置\n    - 在**分层编译**的情况下，参数`-XX:CompileThreshold`将**失效**\n        - 将会根据当前**待编译的方法数**以及**编译线程数**来**动态调整**\n        - 当方法计数器和回边计数器**之和**超过**方法计数器阈值**时，触发**JIT编译**\n4. **回边计数器**\n    - 用于统计一个方法中**循环体**代码执行的次数（**回边**：字节码中遇到控制流**向后跳转**的指令）\n    - 不开启分层编译时，**C1**默认为**13995**，**C2**默认为**10700**，可通过参数`-XX:OnStackReplacePercentage`来设置\n    - 在**分层编译**的情况下，参数`-XX:OnStackReplacePercentage`同样会**失效**\n        - 将会根据当前**待编译的方法数**以及**编译线程数**来**动态调整**\n    - 建立回边计数器的主要目的是为了触发**OSR**（On Stack Replacement）编译，即_**栈上编译**_\n        - 在一些**循环周期比较长**的代码段中，当循环达到回边计数器阈值时，JVM会认为这段代码是**热点代码**\n        - JIT编译器会将这段代码编译成**机器语言**并**缓存**，在该循环时间内，**直接替换**执行代码，**执行缓存的机器语言**\n\n### 编译优化技术\n\n#### 方法内联\n1. 调用一个方法通常要经历**压栈**和**出栈**\n    - 调用方法是将程序执行顺序转移到存储该方法的内存地址，将方法的内容执行完后，再返回到执行该方法前的位置\n    - 方法调用会产生一定的**时间开销**和**空间开销**，对于**方法体代码不是很大**，又**频繁调用**的方法来说，这个**开销会很大**\n2. 方法内联：_**把目标方法的代码复制到发起调用的方法中，避免发生真实的方法调用**_\n3. JVM会**自动识别**热点方法，并对它们使用**方法内联**进行优化，可以通过`-XX:CompileThreshold`来设置热点方法的阈值\n4. 热点方法**不一定**会被JVM做内联优化，如果**方法体太大**，JVM将不执行内联操作\n    - **经常执行**的方法，默认情况下，方法体大小**小于325字节**的都会进行内联，参数**`-XX:MaxFreqInlineSize`**\n    - **不经常执行**的方法，默认情况下，方法体大小**小于35字节**的才会进行内联，参数**`-XX:MaxInlineSize`**\n5. 提高**方法内联**的方式\n    - 减少`-XX:CompileThreshold`，增加`-XX:MaxFreqInlineSize`或`-XX:MaxInlineSize`\n    - 避免在一个方法中写大量代码，习惯使用**小方法体**\n    - 尽量使用**private**、**static**、**final**关键字**修饰方法**，编码方法因为**继承**，会需要_**额外的类型检查**_\n\n```\n-XX:+UnlockDiagnosticVMOptions  // 解锁对 JVM 进行诊断的选项参数。默认是关闭的，开启后支持一些特定参数对 JVM 进行诊断\n-XX:+PrintCompilation           // 在控制台打印编译过程信息\n-XX:+PrintInlining              // 将内联方法打印出来\n```\n\n```java\nprivate static int add1(int x1, int x2, int x3, int x4) {\n    return add2(x1, x2) + add2(x3, x4);\n}\n\nprivate static int add2(int x1, int x2) {\n    return x1 + x2;\n}\n\npublic static void main(String[] args) {\n    // 方法调用计数器的默认阈值在C1模式下是1500次，在C2模式在是10_000次\n    for (int i = 0; i < 1_000_000; i++) {\n        add1(1, 2, 3, 4);\n    }\n}\n```\n```\n377   21       4       Test::add1 (12 bytes)\n                            @ 2   Test::add2 (4 bytes)   inline (hot)\n                            @ 7   Test::add2 (4 bytes)   inline (hot)\n...\n384   24 %     4       Test::main @ 2 (23 bytes)\n                            @ 12   Test::add1 (12 bytes)   inline (hot)\n                              @ 2   Test::add2 (4 bytes)   inline (hot)\n                              @ 7   Test::add2 (4 bytes)   inline (hot)\n```\n\n#### 逃逸分析\n逃逸分析是判断一个对象是否被**外部方法引用**或**外部线程访问**的分析技术，编译器会根据逃逸分析的结果对代码进行优化\n\n##### 栈上分配\n1. 在Java中默认创建一个对象是在**堆**上分配内存的，当堆内存中的对象不再使用时，会被垃圾回收\n    - 这个过程相对分配在**栈**上的对象的创建和销毁来说，更耗**时间**和**性能**\n2. 逃逸分析如果发现**一个对象只在方法中使用**，就会将对象分配在**栈**上\n3. HotSpot VM暂时没有实现这项优化\n\n##### 锁消除\n1. 在局部方法中创建的对象只能被**当前线程**访问，无法被其他线程访问，JIT会对该对象的方法锁进行**锁消除**\n\n##### 标量替换\n1. 逃逸分析证明一个对象**不会被外部访问**\n    - 如果该对象可以被**拆分**的话，当程序真正执行的时候，可能不会创建这个对象，而是直接创建它的**成员变量**来代替\n2. 将对象拆分后，可以分配对象的**成员变量**在**栈**或**寄存器**上，原本的对象就无需分配内存空间了，称为**标量替换**\n\n```java\npublic void foo() {\n    TestInfo info = new TestInfo();\n    info.id = 1;\n    info.count = 99;\n}\n```\n逃逸分析后，代码被优化\n```java   \npublic void foo() {\n    id = 1;\n    count = 99;\n}\n```\n\n##### JVM参数\n```\n-XX:+DoEscapeAnalysis 开启逃逸分析（JDK 1.8默认开启）\n-XX:+EliminateLocks 开启锁消除（JDK 1.8默认开启）\n-XX:+EliminateAllocations 开启标量替换（JDK 1.8默认开启）\n```","tags":["JIT"],"categories":["Performance"]},{"title":"Kafka -- 多线程消费者","url":"%2F2019%2F09%2F08%2Fkafka-multi-thread-consumer%2F","content":"\n## Kafka Java Consumer设计原理\n1. Kafka Java Consumer从Kafka 0.10.1.0开始，KafkaConsumer变成了**双线程**设计，即**用户主线程**和**心跳线程**\n    - 用户主线程：启动Consumer应用程序main方法的那个线程\n    - 心跳线程：只负责定期给对应的Broker机器发送心跳请求，以标识消费者应用的存活性\n2. 引入心跳线程的另一个目的\n    - 将心跳频率和主线程调用KafkaConsumer.poll方法的频率分开，解耦**真实的消息处理逻辑**和**消费组成员存活性管理**\n3. 虽然有了心跳线程，但实际的消息获取逻辑依然是在用户主线程中完成\n    - 因此在**消费消息**的这个层面，依然可以安全地认为KafkaConsumer是**单线程的设计**\n4. 老版本Consumer是**多线程**的架构\n    - 每个Consumer实例在内部为**所有订阅的主题分区**创建对应的**消息获取线程**，即Fetcher线程\n5. 老版本Consumer同时也是**阻塞式**的，Consumer实例启动后，内部会创建很多阻塞式的消息获取迭代器\n    - 但在很多场景下，Consumer端有**非阻塞**需求，如在**流处理**应用中执行**过滤**、**分组**等操作就不能是阻塞式的\n    - 基于这个原因，社区为新版本Consumer设计了**单线程+轮询**的机制，该机制能较好地实现非阻塞的消息获取\n6. 单线程的设计**简化**了Consumer端的设计\n    - Consumer获取到消息后，处理消息的逻辑是否采用多线程，完全由使用者决定\n7. 不论使用哪一种编程语言，单线程的设计都比较容易实现\n    - 并不是所有的编程语言都能很好地支持多线程，而单线程设计的Consumer更容易**移植**到其他语言上\n\n<!-- more -->\n\n## 多线程方案\n1. KafkaConsumer是**线程不安全**的\n2. 不能多线程共享一个KafkaConsumer实例，否则会抛出**ConcurrentModificationException**\n3. 但KafkaConsumer.wakeup()是线程安全的\n\n### 方案1\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-multi-thread-consumer-1.png\" width=1000>\n\n1. 消费者程序启动多个线程，**每个线程维护专属的KafkaConsumer实例**，负责完整的消息获取、消息处理流程\n2. 优点\n    - **实现简单**，比较符合目前使用Consumer API的习惯\n    - 多个线程之间**没有任何交互**，省去了很多保障线程安全方面的开销\n    - Kafka主题中的**每个分区**都能保证**只被一个线程处理**，容易实现**分区内的消息消费顺序**\n3. 缺点\n    - 每个线程都维护自己的KafkaConsumer实例，必然会占用**更多的系统资源**，如内存、TCP连接等\n    - 能使用的线程数**受限**于Consumer**订阅主题的总分区数**\n    - 每个线程**完整**地执行消息获取和消息处理逻辑\n        - 一旦消息处理逻辑很重，消息处理速度很慢，很容易出现**不必要的Rebalance**，引发整个消费者组的**消费停滞**\n\n```java\npublic class KafkaConsumerRunner implements Runnable {\n    private final AtomicBoolean closed = new AtomicBoolean(false);\n    private final KafkaConsumer consumer = new KafkaConsumer(new Properties());\n\n    @Override\n    public void run() {\n        try {\n            consumer.subscribe(Collections.singletonList(\"topic\"));\n            while (!closed.get()) {\n                ConsumerRecords records = consumer.poll(Duration.ofMillis(10000));\n                //  执行消息处理逻辑\n            }\n        } catch (WakeupException e) {\n            // Ignore exception if closing\n            if (!closed.get()) {\n                throw e;\n            }\n        } finally {\n            consumer.close();\n        }\n    }\n\n    // Shutdown hook which can be called from a separate thread\n    public void shutdown() {\n        closed.set(true);\n        consumer.wakeup();\n    }\n}\n```\n\n### 方案2\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-multi-thread-consumer-2.png\" width=1000>\n\n1. 消费者程序使用单个或多个线程获取消息，同时创建多个消费线程执行消息处理逻辑\n    - 获取消息的线程可以是一个，也可以是多个，**每个线程维护专属的KafkaConsumer实例**\n    - 处理消息则由**特定的线程池**来做，从而实现**消息获取**和**消息处理**的**真正解耦**\n2. 优点\n    - 把任务切分成**消息获取**和**消息处理**两部分，分别由不同的线程来处理\n    - 相对于方案1，方案2最大的优势是它的**高伸缩性**\n        - 可以独立地调节消息获取的线程数，以及消息处理的线程数，不必考虑两者之间是否相互影响\n3. 缺点\n    - **实现难度大**，因为要分别管理两组线程\n    - 消息获取和消息处理解耦，**无法保证分区内的消费顺序**\n    - 两组线程，使得**整个消息消费链路被拉长**，最终导致**正确位移提交会变得异常困难**，可能会出现消息的**重复消费**\n\n```java\nprivate final KafkaConsumer<String, String> consumer;\nprivate ExecutorService executors;\n...\n\nprivate int workerNum = 10;\nexecutors = new ThreadPoolExecutor(\n    workerNum, workerNum, 0L, TimeUnit.MILLISECONDS,\n\tnew ArrayBlockingQueue<>(1000), \n\tnew ThreadPoolExecutor.CallerRunsPolicy());\n\n...\nwhile (true) {\n    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n    for (final ConsumerRecord record : records) {\n        // 由专门的线程池负责处理具体的消息\n        executors.submit(new Worker(record));\n    }\n}\n...\n```","tags":["Stream"],"categories":["Kafka"]},{"title":"Java性能 -- JVM内存模型","url":"%2F2019%2F09%2F07%2Fjava-performance-jvm-memory-model%2F","content":"\n## JVM内存模型\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-jvm-memory-model.jpg\" width=800>\n\n<!-- more -->\n\n### 堆\n1. 堆是JVM内存中**最大**的一块内存空间，被所有**线程共享**，**几乎所有对象和数组**都被分配到堆内存中\n2. 堆被划分为**新生代**和**老年代**，新生代又被划分为**Eden**区和**Survivor**区（**From** Survivor + **To** Survivor）\n3. **永久代**\n    - 在Java **6**中，永久代在**非堆**内存中\n    - 在Java **7**中，永久代的**静态变量**和**运行时常量池**被**合并到堆**中\n    - 在Java **8**中，永久代被**元空间**取代\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-jvm-heap.png\" width=800>\n\n### 程序计数器\n1. 程序计数器是一块**很小**的内存空间，主要用来记录各个**线程**执行的字节码的地址\n2. Java是**多线程语言**，当执行的线程数量**超过**CPU数量时，线程之间会根据时间片**轮询争夺CPU资源**\n    - 当一个线程的时间片用完了，或者其他原因导致该线程的CPU资源被提前抢夺\n    - 那么**退出的线程**需要**单独的程序计数器**来记录**下一条运行的指令**\n\n### 方法区\n1. **方法区 != 永久代**\n2. **HotSpot VM使用了永久代来实现方法区**，但在其他VM（**Oracle JRockit**、**IBM J9**）不存在永久代一说\n3. **方法区只是JVM规范的一部分**，在HotSpot VM中，使用了永久代来实现JVM规范的方法区\n4. 方法区主要用来存放**已被虚拟机加载的类相关信息**\n    - **类信息**（类的版本、字段、方法、接口和父类等信息）、**运行时常量池**、**字符串常量池**\n5. JVM在执行某个类的时候，必须经过**加载**、**连接**（验证、准备、解析）、**初始化**\n    - 加载类时，JVM会先加载class文件，在**class文件**除了有类的版本、字段、方法、接口等描述信息外，还有**常量池**\n        - 常量池（**Constant Pool Table**），用于存放**编译期**生成的各种**字面量**和**符号引用**\n        - 字面量：**字符串**（`String a=\"b\"`），**基本类型的常量**（final修饰）\n        - 符号引用：**类和方法的全限定名**、**字段的名称和描述符**、**方法的名称和描述符**\n    - 当类加载到内存中后，JVM会将**class文件常量池中的内容**存放到**运行时常量池**中\n    - 在解析阶段，JVM会把**符号引用**替换为**直接引用**（对象的索引值）\n6. **运行时常量池**是**全局共享**的，多个类共用一个运行时常量池\n    - class文件中的常量池多个相同的字符串在运行时常量池**只会存在一份**\n7. 方法区和堆类似，都是一个**共享内存区**，所以方法区是**线程共享**的\n    - 假设两个线程都试图访问方法区中同一个类信息，而这个类还没有装入JVM\n    - 那么此时只允许一个线程去加载该类，另一个线程必须等待\n8. HotSpot VM\n    - 在Java 7中，已经将永久代的**静态变量**和**运行时常量池**转移到**堆**中，其余部分则存储在JVM的**非堆**内存中\n    - 在Java 8中，已经用**元空间**代替永久代来实现**方法区**，并且元空间的存储位置是**本地内存**\n        - 之前永久代中**类的元数据**存储在**元空间**，永久代的**静态变量**和**运行时常量池**与Java 7一样，转移到**堆**中\n    - 移除永久代，使用元空间的好处\n        - 移除永久代是为了**融合HotSpot VM和JRockit VM**\n        - 永久代内存经常不够用或者发生**内存溢出**（java.lang.OutOfMemoryError: PermGen）\n        - 为永久代分配多大的空间很难确定，依赖很多因素\n9. JVM的内存模型只是一个规范，**方法区**也是一个**规范**，一个**逻辑分区**，并不是一个物理分区\n\n### 虚拟机栈\n1. Java虚拟机栈是**线程私有**的内存空间，和Java线程一起创建\n2. 当创建一个线程时，会在虚拟机栈中申请一个**线程栈**\n    - 用来保存方法的局部变量、操作数栈、动态链接方法和返回地址等信息，并参与方法的调用和返回\n3. 每一个**方法的调用**都伴随着栈帧的**入栈**操作，每一个**方法的返回**都伴随着栈帧的**出栈**操作\n\n### 本地方法栈\n1. 本地方法栈跟Java虚拟机栈的**功能类似**\n2. Java虚拟机栈用来管理**Java函数的调用**，而本地方法栈用来管理**本地方法（C语言实现）的调用**\n\n## JVM运行原理\n```java\npublic class JVMCase {\n    // 常量\n    private final static String MAN_SEX_TYPE = \"man\";\n    // 静态变量\n    public static String WOMAN_SEX_TYPE = \"woman\";\n\n    public static void main(String[] args) {\n        Student student = new Student();\n        student.setName(\"nick\");\n        student.setSexType(MAN_SEX_TYPE);\n        student.setAge(20);\n\n        JVMCase jvmCase = new JVMCase();\n        // 调用非静态方法\n        jvmCase.sayHello(student);\n        // 调用静态方法\n        print(student);\n    }\n    \n    // 非静态方法\n    private void sayHello(Student student) {\n        System.out.println(student.getName() + \" say: hello\");\n    }\n\n    // 常规静态方法\n    private static void print(Student student) {\n        System.out.println(student);\n    }\n}\n\n@Data\nclass Student {\n    private String name;\n    private String sexType;\n    private int age;\n}\n```\n\n1. JVM**向操作系统申请内存**\n    - JVM第一步是通过配置参数或者默认配置参数向操作系统申请内存空间，根据内存大小找到具体的**内存分配表**\n    - 然后把内存段的**起始地址**和**终止地址**分配给JVM，最后JVM进行**内部分配**\n2. JVM获得内存空间后，会根据配置参数分配**堆**、**栈**以及**方法区**的内存大小\n3. class文件**加载**、**验证**、**准备**和**解析**\n    - 其中**准备**阶段会为**类的静态成员（字段和方法）**分配内存，初始化为系统初始值\n4. **初始化**\n    - JVM首先会执行构造器`<clinit>`方法，编译器会在.java文件被**编译**成.class文件，收集所有类的**初始化代码**\n    - 初始化代码：**静态变量赋值语句**，**静态代码块**、**静态方法**\n5. 执行方法\n    - 启动main线程，执行main方法，执行第一行代码\n    - 在**堆**内存中会创建一个**Student对象**，**对象引用student**存放在**栈**中\n    - 再创建一个JVMCase对象，并调用sayHello非静态方法\n        - sayHello方法属于对象jvmCase，此时sayHello方法**入栈**，并调用栈中Student引用调用堆中的Studentd对象\n    - 调用静态方法print\n        - print方法属于JVMCase类，从静态方法中获取后放入到栈中，通过Student引用调用堆中的Studentd对象\n\n准备阶段\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-jvm-memory-model-example-1.jpg\" width=800>\n\n初始化阶段\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-jvm-memory-model-example-2.jpg\" width=800>\n\n创建一个Student对象\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-jvm-memory-model-example-3.jpg\" width=800>\n\n创建一个JVMCase对象，并调用sayHello非静态方法和print静态方法\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-jvm-memory-model-example-4.jpg\" width=800>","tags":["Java Performance"],"categories":["Performance"]},{"title":"Kafka -- CommitFailedException","url":"%2F2019%2F09%2F06%2Fkafka-commit-failed-exception%2F","content":"\n## CommitFailedException\n1. CommitFailedException是Consumer客户端在**提交位移**时出现的**不可恢复**的严重异常\n2. 如果异常是**可恢复的瞬时错误**，提交位移的API方法是支持**自动错误重试**的，如**commitSync**方法\n\n<!-- more -->\n\n## 解释\n> Commit cannot be completed since the **group has already rebalanced and assigned the partitions to another member**. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by **increasing** the **max.poll.interval.ms** or by **reducing** the maximum size of batches returned in poll() with **max.poll.records**.\n\n## 场景\n\n### 场景1\n```java\nProperties props = new Properties();\nprops.put(\"max.poll.interval.ms\", 5000);\nconsumer.subscribe(Arrays.asList(\"test-topic\"));\n \nwhile (true) {\n    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n    Thread.sleep(6000L);\n    consumer.commitSync();\n}\n```\n1. **消息处理的总时间超过预设的`max.poll.interval.ms`**时，Consumer端会抛出CommitFailedException\n2. 解决方案\n    - **缩短单条消息处理的时间**\n    - **增加`max.poll.interval.ms`**\n        - 使用**0.10.1.0**之前的客户端API，需要使用`session.timeout.ms`参数\n        - `session.timeout.ms`还有其他含义，`max.poll.interval.ms`是从`session.timeout.ms`剥离出来的参数\n    - **减少`max.poll.records`**\n    - **使用多线程来加速消费**\n        - 多线程如何**提交位移**是很容易出错的\n\n### 场景2\n1. Kafka Java Consumer端提供了一个名为**Standalone Consumer**的独立消费者\n    - 它**没有消费者组的概念**，每个独立消费者实例都**独立工作**，彼此之间毫无联系\n2. 独立消费者的**位移提交机制**和消费者组是**一样**的，也**必须指定group.id**才能提交位移\n3. 如果同时出现了设置**相同group.id**的**消费者组**程序和**独立消费者**程序\n    - 当**独立消费者**程序**手动提交位移**时，会抛出CommitFailedException，表明它不是消费者组内**合法**的成员","tags":["Stream"],"categories":["Kafka"]},{"title":"Java性能 -- 并发一致性","url":"%2F2019%2F09%2F05%2Fjava-performance-consistency%2F","content":"\n## 背景\n在并发编程中，Java是通过**共享内存**来实现共享变量操作的，所以在多线程编程中会涉及到**数据一致性**的问题\n```java\npublic class Example {\n    int x = 0;\n    public void count() {\n        x++;                    // 1\n        System.out.println(x)   // 2\n    }\n}\n```\n\n<!-- more -->\n\n1. 有两个线程分别执行count方法，x是共享变量\n2. 可能出现3种结果：**`<1,1>`**，`<2,1>`，`<1,2>`\n\n## Java内存模型\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-consistency-java-memory-model-1.jpg\" width=800/>\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-consistency-java-memory-model-2.jpg\" width=800/>\n\n1. Java采用**共享内存**模型来实现多线程之间的信息交换和数据同步\n2. 程序运行时，**局部变量**将会存放在**虚拟机栈**中，而**共享变量**将会被保存在**堆内存**中\n3. 由于局部变量随线程的创建而创建，线程的销毁而销毁，Java栈数据并非线程共享，所以不需要关心数据的一致性\n4. 共享变量存储在**堆内存**或**方法区**中，堆内存和方法区的数据是**线程共享**的\n    - 堆内存中的共享变量在**被不同线程操作**时，会被**加载到线程的工作内存**中，即_**CPU中的高速缓存**_\n    - CPU缓存可以分为L1缓存、L2缓存和L3缓存，每一级缓存中所存储的**全部数据**都是下一级缓存的**一部分**\n    - 当CPU要**读取**一个缓存数据时，会依次从**L1缓存、L2缓存、L3缓存、内存**中查找\n    - 如果是**单核CPU**运行多线程，多个线程同时访问进程中的共享数据，CPU将共享变量加载到高速缓存后\n        - 不同线程在访问缓存数据时，都会**映射到相同的缓存位置**，即使发生**线程切换**，**缓存仍然有效**\n    - 如果是**多核CPU**运行多线程，_**每个核都有一个L1缓存**_\n        - 如果多个线程运行在不同的内核上访问共享变量时，每个内核的L1缓存都将会缓存一份共享变量\n        - 假设线程A操作CPU从堆内存中获取一个缓存数据\n            - 此时堆内存中的缓存数据值为0，该缓存数据会被加载到L1缓存中\n            - 操作后，缓存数据的值变为了1，然后刷新到堆内存中\n        - 在正好刷新到堆内存之前，另一个线程B将堆内存中为0的缓存数据加载到另一个内核的L1缓存中\n            - 此时线程A将堆内存的数据刷新为1，而线程B实际拿到的缓存数据值为0\n            - 此时，**内核缓存中的数据**和**堆内存的数据**就不一致了\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-consistency-1-1-seq.jpg\" width=600/>\n\n## 重排序\n在**不影响运算结果**的前提下，编译器可能会**改变顺序代码的指令顺序**\n```java\npublic class Example {\n    int x = 0;\n    boolean flag = false;\n    // 线程1调用\n    public void writer() {\n        // 1和2可能会被重排序\n        x = 1;                // 1\n        flag = true;          // 2\n    }\n    // 线程2调用\n    public void reader() {\n        if (flag) {           // 3\n             int r1 = x;      // 4\n             System.out.println(r1==x)\n        }\n    }\n    // 线程1和线程2并发执行，线程2中的变量值可能出现两种情况：r1=0或r1=1\n}\n```\n\n## Happens-before 规则\n1. **程序次序规则**\n    - 在单线程中，代码的执行是有序的，虽然可能会存在指令重排序，但最终执行的结果和顺序执行的结果是一致的\n2. **锁定规则**\n    - 一个锁处于被线程锁定占用状态，只有当这个线程释放锁之后，其他线程才能再次获取锁\n3. **volatile变量规则**\n    - 如果一个线程正在写volatile变量，其他线程读取该变量会发生在写入之后\n4. **线程启动规则**\n    - Thread对象的**start()方法**先行发生于此线程的**其它每一个动作**\n5. **线程终止规则**\n    - **线程中的所有操作**都先行发生于**对此线程的中止检测**\n6. **对象终结规则**\n    - 一个对象的**初始化完成**先行发生于该对象**finalize()方法的开始**\n7. **线程中断规则**\n    - **对线程interrupt()方法的调用**先行发生于**被中断线程的代码检测到中断事件的发生**\n8. **传递性**\n    - 如果操作A happens-before 操作B，操作B happens-before 操作C，那么操作A happens-before 操作C\n\n## 一致性等级\n\n### 强一致性 - 全局锁\n**所有读写操作都按全局时钟下的顺序执行**，任何时刻线程读取到的缓存数据都是一样的，**Hashtable**就是强一致性\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-consistency-level-strong.jpg\" width=1000>\n\n### 顺序一致性 - volatile\n1. 多个线程的整体执行可能是无序的，但对于**单个线程**而言执行是**有序**的\n2. 要保证任何一次读都能读到最近一次写的数据，**volatile**可以阻止指令重排序\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-consistency-level-seq.jpg\" width=1000>\n\n### 弱一致性 - 读写锁\n不能保证任何一次读都能读到最近一次写入的数据，但能保证**最终**可以读到写入的数据，**读写锁**就是弱一致性","tags":["Consistency"],"categories":["Performance"]},{"title":"Java性能 -- 命令行工具","url":"%2F2019%2F09%2F04%2Fjava-performance-command-line-tool%2F","content":"\n## free\n```\n$ free -m\n             total       used       free     shared    buffers     cached\nMem:         15948      15261        687        304         37       6343\n-/+ buffers/cache:       8880       7068\nSwap:            0          0          0\n```\n\n<!-- more -->\n\n1. `Mem`是从**操作系统**的角度来看的\n    - 总共有15948M物理内存，其中15261M被使用了，还有687可用，`15948 = 15261 + 687`\n    - 有若干线程共享了304M物理内存，已经被弃用（值总为0）\n    - buffer / cached ：为了**提高IO性能**，由OS管理\n        - A buffer is something that has yet to be **\"written\"** to disk.\n        - A cache is something that has been **\"read\"** from the disk and stored for later use.\n        - buffer和cached占用的内存可以**被快速回收**\n2. `-/+ buffers/cache`是从**应用程序**的角度来看的\n    - 应用程序认为系统被用掉了8880M物理内存，还剩下7068M物理内存\n    - `8880 ≈ (15261 - 37 - 6343 = 8881)`\n    - `7068 ≈ (687 + 37 + 6343 = 7067)`\n\n## top\n```\n$ top -v\n\ttop: procps version 3.2.8\nusage:\ttop -hv | -abcHimMsS -d delay -n iterations [-u user | -U user] -p pid [,pid ...]\n\n$ top\ntop - 09:08:28 up 36 days, 13:19,  1 user,  load average: 0.31, 0.16, 0.11\nTasks: 274 total,   1 running, 273 sleeping,   0 stopped,   0 zombie\nCpu(s):  2.5%us,  1.6%sy,  0.0%ni, 95.9%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st\nMem:  16331512k total, 16141616k used,   189896k free,     5372k buffers\nSwap:        0k total,        0k used,        0k free,  7526888k cached\n\n  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+   PPID RUSER     UID GROUP    TTY      P SWAP   TIME CODE DATA nFLT nDRT WCHAN     Flags    COMMAND\n21862 dc        20   0 5113m 551m 5096 S  0.0  3.5  25:34.77     1 dc        555 dc       ?        4    0  25:34    4 4.8g  13k    0 futex_wai ..4.2... java\n12692 dc        20   0 5109m 513m 5792 S  0.2  3.2  19:54.09     1 dc        555 dc       ?        2    0  19:54    4 4.8g  30k    0 futex_wai ..4.2... java\n20299 dc        20   0 5054m 508m 2644 S  0.0  3.2 179:37.25     1 dc        555 dc       ?        4    0 179:37    4 4.8g  65k    0 futex_wai ..4.2... java\n...\n```\n\n1. top命令可以实时显示正在执行进程的**CPU使用率**、**内存使用率**以及**系统负载**等信息\n    - 上半部分显示的是**系统的统计信息**，下半部分显示的是**进程的使用率统计信息**\n2. 系统的统计信息\n    - Cpu\n        - %us：用户空间占用CPU百分比\n        - %sy：内核空间占用CPU百分比\n        - %ni：用户进程空间内**改变过优先级**的进程占用CPU百分比\n        - %id：**空闲**CPU百分比\n        - %wa：**等待输入输出**的CPU时间百分比\n        - %hi：**硬件中断**占用百分比\n        - %si：**软中断**占用百分比\n        - %st：**虚拟机**占用百分比\n3. 进程的使用率统计信息\n    - **PID**: Process Id\n        - The task's unique process ID, which periodically wraps, though never restarting at zero.\n    - **PPID**: Parent Process Pid\n        - The process ID of a task's parent.\n    - **RUSER**: Real User Name\n        - The real user name of the task's owner.\n    - **UID**: User Id\n        - The effective user ID of the task's owner.\n    - **USER**: User Name\n        - The effective user name of the task's owner.\n    - **GROUP**: Group Name\n        - The effective group name of the task's owner.\n    - **TTY**: Controlling Tty\n        - The name of the controlling terminal. This is usually the device (serial port, pty, etc.) from which the process was started, and which it uses for input or output. However, a task **need not be associated with a terminal**, in which case you'll see **`'?'`** displayed.\n    - **%CPU**: CPU usage\n        - The task's share of the elapsed CPU time since the last screen update, expressed as a percentage of total CPU time.\n        - In a true SMP environment, if 'Irix mode' is Off, top will operate in 'Solaris mode' where a task's cpu usage will be divided by the total number of CPUs. You toggle 'Irix/Solaris' modes with the 'I' interactive command.\n    - **S**: Process Status\n        - The status of the task which can be one of\n            - `'D' = uninterruptible sleep`\n            - `'R' = running`\n            - `'S' = sleeping`\n            - `'T' = traced or stopped`\n            - `'Z' = zombie`\n        - Tasks shown as **running** should be more properly thought of as **`ready to run`**\n            - their task_struct is simply represented on the Linux **run-queue**.\n            - Even without a true SMP machine, you may see numerous tasks in this state depending on top's **delay interval** and **nice value**.\n    - **P**: Last used CPU (SMP)\n        - A number representing the last used processor. In a true SMP environment this will likely change frequently since the kernel intentionally uses weak affinity. Also, the very act of running top may break this weak affinity and cause more processes to change CPUs more often (because of the extra demand for cpu time).\n    - **PR**: Priority\n        - The priority of the task.\n    - **NI**: Nice value\n        - The nice value of the task.\n        - A **negative nice value** means **higher priority**, whereas a **positive nice value** means **lower priority**.\n        - **Zero** in this field simply means **priority will not be adjusted** in determining a task's dispatchability.\n    - **TIME**: CPU Time\n        - Total CPU time the task has used since it started.\n    - **TIME+**: CPU Time, hundredths\n        - The same as 'TIME', but reflecting more granularity through **hundredths of a second**.\n    - **%MEM**: Memory usage (RES)\n        - A task's currently used share of **available physical memory**.\n    - **RES**: Resident size (kb)\n        - The **non-swapped physical memory** a task has used.\n        - _**RES = CODE + DATA**_.\n    - **CODE**: Code size (kb)\n        - The amount of **physical memory** devoted to **executable code**, also known as the **`'text resident set'`** size or **TRS**.\n    - **DATA**: Data+Stack size (kb)\n        - The amount of **physical memory** devoted to **other than executable code**, also known as the **`'data resident set'`** size or **DRS**.\n    - **SWAP**: Swapped size (kb)\n        - Per-process swap values are now taken from **/proc/#/status VmSwap field**.\n    - **VIRT**: Virtual Image (kb)\n        - The **total amount of virtual memory** used by the task.\n        - It includes all **code**, **data** and **shared libraries** plus **pages that have been swapped out**.\n    - **SHR**: Shared Mem size (kb)\n        - The **amount of shared memory** used by a task.\n        - It simply reflects memory that could be potentially shared with other processes.\n    - **nFLT**: Page Fault count\n        - The number of **major page faults** that have occurred for a task. A page fault occurs when a process attempts to **read from or write to a virtual page that is not currently present in its address space**. A major page fault is when **disk access** is involved in making that page available.\n    - **nDRT**: Dirty Pages count\n        - The number of pages that have been modified since they were last written to disk. **Dirty pages must be written to disk before the corresponding physical memory location can be used for some other virtual page**.\n    - **WCHAN**: Sleeping in Function\n        - Depending on the availability of the kernel link map ('System.map'), this field will show the name or the address of the **kernel function** in which the task is currently sleeping. Running tasks will display a dash ('-') in this column.\n    - **Flags**: Task Flags\n        - This column represents the task's current scheduling flags which are expressed in hexadecimal notation and with zeros suppressed.\n    - **COMMAND**: Command line or Program name\n4. 常用选项\n    - **-a : Sort by memory usage**\n        - This switch makes top to sort the processes by **allocated memory**\n    - **-d : Delay time** interval as: **-d ss.tt** (seconds.tenths)\n        - Specifies the delay between screen updates, and overrides the corresponding value in one's personal configuration file or the startup default.\n        - Later this can be changed with the **`'d'`** or **`'s'`** **interactive commands**.\n    - **-H : Threads** toggle\n        - When this toggle is On, all **individual threads** will be displayed. Otherwise, top displays **a summation of all threads in a process**.\n    - **-M : Detect memory units**\n        - Show memory units (**k/M/G**) and display floating point values in the memory summary.\n    - **-n : Number of iterations** limit as: **-n number**\n        - Specifies the **maximum number of iterations**, or frames, top should produce before ending\n    - **-p : Monitor PIDs** as: **-pN1 -pN2** ... or **-pN1, N2 [,...]**\n        - Monitor only processes with specified process IDs. This option can be given up to **20** times, or you can provide a **comma** delimited list with up to 20 pids. **Co-mingling** both approaches is **permitted**.\n        - This is a command-line option only. And should you wish to **return to normal operation**, it is not necessary to quit and and restart top -- just issue the **'=' interactive command**.\n4. 交互命令\n    - **`P`**： 根据**CPU**资源使用大小进行排序\n    - **`M`**： 根据**内存**资源使用大小进行排序\n    - `T`： 根据进程使用**CPU的累积时间**排序\n    - `N`： 按PID由高到低排列\n    - `r`： 修改进程的nice值(优先级)。优先级默认为10，正值使优先级降低，反之则提高的优先级\n    - `S`： 累计模式（把已完成或退出的子进程占用的CPU时间累计到**父进程**的TIME+ ）\n    - `W`： 将当前设置写入~/.toprc文件，下次启动自动调用toprc文件的设置\n    - `<`： 向前翻页\n    - `>`： 向后翻页\n    - `1`： 显示每个CPU的详细情况\n\n```\nHelp for Interactive Commands - procps version 3.2.8\nWindow 1:Def: Cumulative mode Off.  System: Delay 3.0 secs; Secure mode Off.\n\n  Z,B       Global: 'Z' change color mappings; 'B' disable/enable bold\n  l,t,m     Toggle Summaries: 'l' load avg; 't' task/cpu stats; 'm' mem info\n  1,I       Toggle SMP view: '1' single/separate states; 'I' Irix/Solaris mode\n\n  f,o     . Fields/Columns: 'f' add or remove; 'o' change display order\n  F or O  . Select sort field\n  <,>     . Move sort field: '<' next col left; '>' next col right\n  R,H     . Toggle: 'R' normal/reverse sort; 'H' show threads\n  c,i,S   . Toggle: 'c' cmd name/line; 'i' idle tasks; 'S' cumulative time\n  x,y     . Toggle highlights: 'x' sort field; 'y' running tasks\n  z,b     . Toggle: 'z' color/mono; 'b' bold/reverse (only if 'x' or 'y')\n  u       . Show specific user only\n  n or #  . Set maximum tasks displayed\n\n  k,r       Manipulate tasks: 'k' kill; 'r' renice\n  d or s    Set update interval\n  W         Write configuration file\n  q         Quit\n          ( commands shown with '.' require a visible task display window )\nPress 'h' or '?' for help with Windows,\nany other key to continue\n```\n\n## vmstat\n```\n$ vmstat -S M 1 5\nprocs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n 2  0      0    295      1   5684    0    0     8    23    1    2  5  1 93  0  0\n 0  0      0    295      1   5684    0    0     0     0 11326 25112  6  5 90  0  0\n 0  0      0    295      1   5685    0    0     0     0 10855 24065  2  2 96  0  0\n 0  0      0    294      1   5686    0    0     0     4 11756 25472  4  2 94  0  0\n 0  0      0    294      1   5686    0    0     0     0 10208 22726  4  4 91  0  0\n\n$ free -m\n             total       used       free     shared    buffers     cached\nMem:         15948      15655        293       5362          1       5687\n-/+ buffers/cache:       9966       5981\nSwap:            0          0          0\n```\n\n1. vmstat是一款指定采样周期和次数的**功能性监控工具**，可以用来监控进程上下文切换的情况\n2. procs\n    - r: The number of **runnable** processes (**running** or **waiting** for run time)\n    - b: The number of processes in **uninterruptible sleep**\n3. memory\n    - swpd: the amount of **virtual** memory used\n    - free: the amount of **idle** memory\n    - buff: the amount of memory used as **buffers**\n    - cache: the amount of memory used as **cache**\n4. swap\n    - si: Amount of memory **swapped in from disk** (/s)\n    - so: Amount of memory **swapped to** disk (/s)\n5. io\n    - bi: Blocks **received** from a block device (blocks/s)\n    - bo: Blocks **sent** to a block device (blocks/s)\n6. system\n    - in: The number of **interrupts** per second, including the clock\n    - cs: The number of **context switches** per second\n7. cpu\n    - us: Time spent running **non-kernel code**\n    - sy: Time spent running **kernel code**\n    - id: Time spent idle, this **includes IO-wait time**\n    - wa: Time spent waiting for IO, **included in idle**\n    - st: Time stolen from a virtual machine\n\n## pidstat\n1. pidstat可以监测到**具体线程的上下文切换**，pidstat是**sysstat**中的一个组件\n2. 常用参数\n    - `-u`: Report **CPU utilization**\n    - `-r`: Report **page faults** and **memory utilization**\n    - `-d`: Report **I/O statistics**\n    - `-w`: Report **task switching activity**\n    - `-t`: Also display **statistics for threads** associated with selected tasks\n    - `-p { pid [,...] | SELF | ALL }`: Select tasks (processes) for which statistics are to be reported\n\n### CPU使用率\n```\n$ pidstat -u -p 4256 1 3\nLinux 2.6.32-696.el6.x86_64 (XXXX) \t2019年XX月XX日 \t_x86_64_\t(32 CPU)\n\n22时59分32秒       PID    %usr %system  %guest    %CPU   CPU  Command\n22时59分33秒      4256   71.00   13.00    0.00   84.00     1  java\n22时59分34秒      4256   60.00   10.00    0.00   70.00     1  java\n22时59分35秒      4256   76.24   12.87    0.00   89.11     1  java\n平均时间:      4256   69.10   11.96    0.00   81.06     -  java\n\n$ pidstat -u -I -p 4256 1 3\nLinux 2.6.32-696.el6.x86_64 (XXXX) \t2019年XX月XX日 \t_x86_64_\t(32 CPU)\n\n23时06分18秒       PID    %usr %system  %guest    %CPU   CPU  Command\n23时06分19秒      4256   69.31   12.87    0.00    2.63     1  java\n23时06分20秒      4256   69.00   12.00    0.00    2.57     1  java\n23时06分21秒      4256   62.00   12.00    0.00    2.34     1  java\n平均时间:      4256   66.78   12.29    0.00    2.51     -  java\n```\n1. %usr\n    - Percentage of CPU used by the task while executing at the **user level** (**application**)\n    - Note that this field does **NOT include time spent running a virtual processor**\n2. %system\n    - Percentage of CPU used by the task while executing at the **system level** (**kernel**)\n3. %guest\n    - Percentage of CPU spent by the task in virtual machine (running a **virtual processor**)\n4. %CPU\n    - **Total percentage** of CPU time used by the task\n    - In an **SMP** environment, the task's CPU usage will be **divided** by the **total number of CPU's** if option **-I** has been entered on the command line\n5. CPU\n    - **Processor number** to which the task is attached\n\n### 页错误 + 内存使用率\n```\n$ pidstat -r -p 4256 1 3\n23时11分26秒       PID  minflt/s  majflt/s     VSZ    RSS   %MEM  Command\n23时11分27秒      4256   2132.00      0.00 22427892 5172756   7.84  java\n23时11分28秒      4256   1623.00      0.00 22427892 5172728   7.84  java\n23时11分29秒      4256   1942.00      0.00 22427892 5172728   7.84  java\n平均时间:      4256   1899.00      0.00 22427892 5172737   7.84  java\n```\n1. minflt/s\n    - Total number of **minor faults** the task has made per second, those which have **not required loading a memory page from disk**\n2. majflt/s\n    - Total number of **major faults** the task has made per second, those which have **required loading a memory page from disk**\n3. VSZ\n    - Virtual Size: The **virtual memory** usage of entire task in **kilobytes**\n4. RSS\n    - Resident Set Size: The **non-swapped physical memory** used by the task in **kilobytes**\n\n### IO统计\n```\n$ pidstat -d -p 4256 1 3\n23时24分59秒       PID   kB_rd/s   kB_wr/s kB_ccwr/s  Command\n23时25分00秒      4256      0.00    408.00      0.00  java\n23时25分01秒      4256      0.00    356.44      0.00  java\n23时25分02秒      4256      0.00    375.76      0.00  java\n平均时间:      4256      0.00    380.00      0.00  java\n```\n1. kB_rd/s\n    - Number of **kilobytes** the task has caused to be **read from disk** per second\n2. kB_wr/s\n    - Number of **kilobytes** the task has caused, or shall cause to be **written to disk** per second\n3. kB_ccwr/s\n    - Number of **kilobytes** whose **writing to disk** has been **cancelled** by the task\n    - This may occur when the task **truncates some dirty pagecache**\n        - In this case, some IO which another task has been accounted for will **not be happening**\n\n### 进程上下文切换\n```\n$ pidstat -w -p 4256 1 3\n22时54分33秒       PID   cswch/s nvcswch/s  Command\n22时54分34秒      4256      0.00      0.00  java\n22时54分35秒      4256      0.00      0.00  java\n22时54分36秒      4256      0.00      0.00  java\n平均时间:      4256      0.00      0.00  java\n```\n1. cswch/s\n    - Total number of **voluntary context switches** the task made per second\n    - A voluntary context switch occurs when a task blocks because it **requires a resource that is unavailable**\n2. nvcswch/s\n    - Total number of **non voluntary context switches** the task made per second\n    - A involuntary context switch takes place when a task executes for the duration of its **time slice** and then is **forced to relinquish** the processor\n\n### 线程上下文切换\n```\n$ pidstat -w -t -p 4256 | head -n 10\n\n23时32分03秒      TGID       TID   cswch/s nvcswch/s  Command\n23时32分03秒      4256         -      0.00      0.00  java\n23时32分03秒         -      4256      0.00      0.00  |__java\n23时32分03秒         -      4259      0.00      0.00  |__java\n23时32分03秒         -      4306      0.04      0.01  |__java\n23时32分03秒         -      4307      0.04      0.01  |__java\n23时32分03秒         -      4308      0.04      0.01  |__java\n23时32分03秒         -      4315      0.04      0.01  |__java\n```\n\n## jstat\n```\n$ jstat -options\n-class\n-compiler\n-gc\n-gccapacity\n-gccause\n-gcnew\n-gcnewcapacity\n-gcold\n-gcoldcapacity\n-gcpermcapacity\n-gcutil\n-printcompilation\n```\n1. class\n    - 显示**类加载**的相关信息\n2. compiler\n    - 显示**JIT编译**的相关信息\n3. gc\n    - 显示和GC相关的堆信息    \n4. gccapacity\n    - 显示各个代的容量以及使用情况\n5. gccause\n    - 显示垃圾回收的相关信息，同时显示最后一次或当前正在发生的垃圾回收的诱因\n6. gcnew\n    - 显示新生代信息\n7. gcnewcapacity\n    - 显示新生代的大小和使用情况\n8. gcold\n    - 显示老年代和永久代的信息\n9. gcoldcapacity\n    - 显示老年代的大小\n10. gcpermcapacity\n    - 显示永久代的大小\n11. _**gcutil**_\n    - 显示垃圾收集信息\n12. printcompilation\n    - 输出JIT编译的方法信息\n\n## jstack\njstack可以查看**线程堆栈**的运行情况，可以结合`pidstat -t -p PID`来查看具体线程的**状态**\n```\n$ sudo /usr/local/java/bin/jstack -F 5850\nThread 5853: (state = BLOCKED)\n - java.lang.Object.wait(long) @bci=0 (Interpreted frame)\n - java.lang.Object.wait() @bci=2, line=503 (Interpreted frame)\n - xx.xx.xx.service.client.proxy.Provider.start() @bci=889, line=208 (Interpreted frame)\n - xx.xx.xx.xx.xx.main(java.lang.String[]) @bci=368, line=90 (Interpreted frame)\n```\n\n## jmap\n可以通过`jamp -heap`查看堆内存的**初始化配置信息**以及堆内存的**使用情况**\n```\n$ jmap -heap 23594\nAttaching to process ID 23594, please wait...\nDebugger attached successfully.\nServer compiler detected.\nJVM version is 24.65-b04\n\nusing thread-local object allocation.\nGarbage-First (G1) GC with 12 thread(s)\n\nHeap Configuration:\n   MinHeapFreeRatio = 40\n   MaxHeapFreeRatio = 70\n   MaxHeapSize      = 268435456 (256.0MB)\n   NewSize          = 1363144 (1.2999954223632812MB)\n   MaxNewSize       = 17592186044415 MB\n   OldSize          = 5452592 (5.1999969482421875MB)\n   NewRatio         = 2\n   SurvivorRatio    = 8\n   PermSize         = 134217728 (128.0MB)\n   MaxPermSize      = 134217728 (128.0MB)\n   G1HeapRegionSize = 4194304 (4.0MB)\n\nHeap Usage:\nG1 Heap:\n   regions  = 64\n   capacity = 268435456 (256.0MB)\n   used     = 159804896 (152.40182495117188MB)\n   free     = 108630560 (103.59817504882812MB)\n   59.531962871551514% used\nG1 Young Generation:\nEden Space:\n   regions  = 27\n   capacity = 163577856 (156.0MB)\n   used     = 113246208 (108.0MB)\n   free     = 50331648 (48.0MB)\n   69.23076923076923% used\nSurvivor Space:\n   regions  = 1\n   capacity = 4194304 (4.0MB)\n   used     = 4194304 (4.0MB)\n   free     = 0 (0.0MB)\n   100.0% used\nG1 Old Generation:\n   regions  = 12\n   capacity = 100663296 (96.0MB)\n   used     = 42364384 (40.401824951171875MB)\n   free     = 58298912 (55.598175048828125MB)\n   42.08523432413737% used\nPerm Generation:\n   capacity = 134217728 (128.0MB)\n   used     = 43099600 (41.10298156738281MB)\n   free     = 91118128 (86.89701843261719MB)\n   32.11170434951782% used\n\n16133 interned Strings occupying 1421648 bytes.\n```\n\n可以通过`jamp -histo[:live]`查看堆内存中的**对象数目、大小统计直方图**，live只统计**存活对象**\n```\n$ jmap -histo -F 23594 | head\nAttaching to process ID 23594, please wait...\nDebugger attached successfully.\nServer compiler detected.\nJVM version is 24.65-b04\nIterating over heap. This may take a while...\nObject Histogram:\n\nnum \t  #instances\t#bytes\tClass description\n--------------------------------------------------------------------------\n1:\t\t9547\t24873832\tint[]\n2:\t\t78517\t11010880\t* ConstMethodKlass\n3:\t\t78517\t10062240\t* MethodKlass\n4:\t\t7196\t8222752\t* ConstantPoolKlass\n5:\t\t187123\t7484920\tjava.util.HashMap$EntryIterator\n6:\t\t43559\t6833504\tchar[]\nHeap traversal took 33.612 seconds.\n```\n\n可以通过`jmap -dump:format=b,file=/tmp/heap.hprof`把**堆内存的使用情况**dump到文件中，随后通过**MAT**工具进行分析\n```\n$ jmap -dump:format=b,file=/tmp/wall.hprof -F 23594\nAttaching to process ID 23594, please wait...\nDebugger attached successfully.\nServer compiler detected.\nJVM version is 24.65-b04\nDumping heap to /tmp/wall.hprof ...\nHeap dump file created\n\n$ du -sh /tmp/wall.hprof\n231M\t/tmp/wall.hprof\n```","tags":["Java Performance"],"categories":["Performance"]},{"title":"Kafka -- 提交位移","url":"%2F2019%2F09%2F03%2Fkafka-commit-offset%2F","content":"\n## 消费位移\n1. Consumer的**消费位移**，记录了Consumer要消费的**下一条消息**的位移\n2. 假设一个分区中有10条消息，位移分别为0到9\n    - 某个Consumer消费了5条消息，实际消费了位移0到4的5条消息，此时Consumer的位移为5，指向下一条消息的位移\n3. Consumer需要向Kafka汇报自己的位移数据，这个汇报过程就是**提交位移**\n    - Consumer能够**同时消费多个分区**的数据，所以位移的提交实际上是在**分区粒度**上进行的\n    - _**Consumer需要为分配给它的每个分区提交各自的位移数据**_\n4. 提交位移主要是为了**表征Consumer的消费进度**\n    - 当Consumer发生故障重启后，能够从Kafka中读取之前提交的位移值，然后从相应的位移处**继续消费**\n5. 位移提交的**语义**\n    - 如果提交了位移X，那么Kafka会认为位移值**小于**X的消息都已经被**成功消费**了\n\n<!-- more -->\n\n## 灵活\n1. 位移提交非常灵活，可以提交**任何位移值**，但要承担相应的后果\n2. 假设Consumer消费了位移为0~9的10条消息\n    - 如果提交的位移为20，位移位于10~19的消息可能会**丢失**\n    - 如果提交的位移为5，位移位于5~9的消息可能会被**重复消费**\n3. 位移提交的语义保障由应用程序保证，Kafka只会**无脑**地接受\n4. 位移提交的方式\n    - 从**用户角度**来看，分为**自动提交**和**手动提交**\n    - 从**Consumer端**来看，分为**同步提交**和**异步提交**\n\n## 自动提交\n1. 自动提交：Kafka Consumer在后台默默地提交位移\n2. 参数`enable.auto.commit`，默认值为**true**，启用自动提交\n3. 参数`auto.commit.interval.ms`，默认值为**5秒**，Kafka每5秒会自动提交一次位移\n4. Kafka会保证在开始调用poll方法时，提交**上次**poll返回的所有消息\n    - poll方法的逻辑：先提交上一批消息的位移，再处理下一批消息，因此能够保证_**消息不丢失**_\n5. 自动提交可能会出现_**重复消费**_\n    - Consumer每5秒提交一次位移，若提交位移后3秒发生**Rebalance**，所有Consumer从上次提交的位移处继续消费\n\n```java\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"group.id\", \"test\");\nprops.put(\"enable.auto.commit\", \"true\");\nprops.put(\"auto.commit.interval.ms\", \"2000\");\nprops.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\nprops.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\nKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\nconsumer.subscribe(Arrays.asList(\"foo\", \"bar\"));\nwhile (true) {\n    ConsumerRecords<String, String> records = consumer.poll(100);\n    for (ConsumerRecord<String, String> record : records)\n        System.out.printf(\"offset = %d, key = %s, value = %s%n\", record.offset(), record.key(), record.value());\n}\n```\n\n## 手动提交\n1. `enable.auto.commit=false`\n2. `KafkaConsumer#commitSync()`\n    - 提交`KafkaConsumer#poll()`返回的最新位移\n    - **同步**操作，一直等待，直到位移被成功提交才会返回\n    - 需要处理完poll方法返回的**所有消息**后，才提交位移，否则会出现**消息丢失**\n    - Consumer处于**阻塞**状态，直到远端的Broker返回提交结果，才会结束\n    - 因为应用程序而非资源限制而导致的阻塞都可能是**系统的瓶颈**，会影响整个应用程序的**TPS**\n3. `KafkaConsumer#commitAsync()`\n    - **异步**操作，立即返回，不会阻塞，不会影响Consumer应用的TPS，Kafka也提供了**回调**函数\n    - **`commitAsync`不能代替`commitSync`**，因为`commitAsync`_**不会自动重试**_\n        - 如果异步提交后再重试，提交的位移值很可能已经**过期**，因此异步提交的重试是**没有意义**的\n4. 手动提交需要组合`commitSync`和`commitAsync`，达到最优效果\n    - 利用`commitSync`的**自动重试**来规避**瞬时**错误，如网络瞬时抖动、Broker端的GC等\n    - 利用`commitAsync`的**非阻塞性**，保证Consumer应用的**TPS**\n\n```java\n// 同步提交\nwhile (true) {\n    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n    process(records); // 处理消息\n    try {\n        consumer.commitSync();\n    } catch (CommitFailedException e) {\n        handle(e); // 处理提交失败异常\n    }\n}\n```\n```java\n// 异步提交\nwhile (true) {\n    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n    process(records); // 处理消息\n    consumer.commitAsync((offsets, exception) -> {\n        if (exception != null)\n            handle(exception);\n    });\n}\n```\n```java\n// 同步提交 + 异步提交\ntry {\n    while (true) {\n        ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        commitAysnc(); // 使用异步提交规避阻塞\n    }\n} catch (Exception e) {\n    handle(e); // 处理异常\n} finally {\n    try {\n        consumer.commitSync(); // 最后一次（异常/应用关闭）提交使用同步阻塞式提交\n    } finally {\n        consumer.close();\n    }\n}\n```\n\n## 精细化提交\n1. 上面的位移提交方式，都是提交**poll**方法返回的**所有消息的位移**，即提交**最新一条消息**的位移\n2. 精细化提交\n    - `commitSync(Map<TopicPartition, OffsetAndMetadata> offsets)`\n    - `commitAsync(Map<TopicPartition, OffsetAndMetadata> offsets, OffsetCommitCallback callback)`\n\n```java\nMap<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();\nint count = 0;\nwhile (true) {\n    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n    for (ConsumerRecord<String, String> record : records) {\n        process(record);  // 处理消息\n        // 消费位移是下一条消息的位移，所以+1\n        offsets.put(new TopicPartition(record.topic(), record.partition()),\n                new OffsetAndMetadata(record.offset() + 1));\n        if (count % 100 == 0) {\n            // 精细化提交\n            consumer.commitAsync(offsets, null); // 回调处理逻辑是 null\n        }\n        count++;\n    }\n}\n```","tags":["Stream"],"categories":["Kafka"]},{"title":"Java性能 -- 协程","url":"%2F2019%2F09%2F02%2Fjava-performance-coroutine%2F","content":"\n## 线程实现模型\n1. **轻量级进程**和**内核线程**一对一相互映射实现的**1:1**线程模型\n2. **用户线程**和**内核线程**实现的**N:1**线程模型\n3. **用户线程**和**轻量级进程**混合实现的**N:M**线程模型\n\n<!-- more -->\n\n### 1:1线程模型\n1. 内核线程（**Kernel-Level Thread**）是由操作系统**内核**支持的线程，内核通过**调度器**对线程进行调度，负责完成线程的**切换**\n2. 在Linux中，往往通过**fork**函数创建一个**子进程**来代表一个**内核中的线程**\n    - 一个进程调用fork函数后，系统会先给新的子进程**分配资源**，然后**复制**主进程，只有少数值与主进程不一样\n3. 采用fork的方式，会产生大量的**冗余**数据，占用**大量内存空间**，也会消耗**大量CPU时间**来初始化内存空间和复制数据\n4. 如果是一模一样的数据，可以**共享**主进程的数据，于是轻量级进程（**Light Weight Process，LWP**）出现了\n    - LWP使用**clone**系统调用创建线程\n    - clone函数将**部分**父进程的资源的数据结构进行复制，复制内容**可选**，且没有被复制的资源可以通过**指针**共享给子进程\n    - LWP**运行单元更小**，**运行速度更快**，LWP和内核线程**一一映射**，每个LWP都是由一个内核线程支持\n\n### N:1线程模型\n1. 1:1线程模型的缺陷\n    - 在线程创建、切换上都存在**用户态和内核态的切换**\n    - 系统资源有限，**无法支持创建大量LWP**\n2. 该线程模型在**用户空间**完成了线程的创建、同步、销毁和调度，并不需要内核的帮助，**不会产生用户态和内核态的空间切换**\n\n### N:M线程模型\n1. N:1线程模型的缺陷\n    - **操作系统无法感知用户态的线程**，容易造成某个线程进行**系统调用**内核线程时被阻塞，从而导致**整个进程被阻塞**\n2. N:M线程模型是一种**混合**线程管理模型\n    - 支持**用户态线程**通过**LWP**与**内核线程**连接，**用户态的线程数量**和**内核态的LWP数量**是N:M的映射关系\n\n## Java线程 / Go协程\n1. Java线程\n    - Thead#start通过调用native方法**start0**实现\n    - 在Linux下，JVM Thread是基于**pthread_create**实现的，而pthread_create实际上调用了**clone**系统调用来创建线程\n    - 所以，Java在Linux下采用的是**1:1线程模型**（用户线程与轻量级线程一一映射），线程通过**内核调度**，涉及**上下文切换**\n2. Go协程\n    - Go语言使用了**N:M线程模型**实现了**自己的调度器**，在**N个内核线程上多路复用M个协程**\n    - 协程的上下文切换在**用户态**由**协程调度器**完成，**不需要陷入到内核**，相比Java线程，**代价很小**\n\n## 协程的实现原理\n1. 协程可以看作**一个类函数**或者**一块函数中的代码**，可以在主线程里面轻松创建多个协程\n2. 程序调用协程和调用函数是不一样的，协程可以通过**暂停**或者**阻塞**的方式将协程的执行挂起，而其他协程可以继续执行\n    - 协程的挂起只是在程序中（**用户态**）的挂起，同时将代码**执行权**转让给其他协程使用\n    - 待获取执行权的协程执行完之后，将从挂起点唤醒挂起的协程\n    - 协程的**挂起**和**唤醒**是通过一个**调度器**完成的\n\n### 图例解释\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-coroutine.jpg\" width=800/>\n\n1. 假设程序中默认创建两个线程为协程使用，在主线程中创建协程ABCD...，分别存储在**就绪队列**中\n2. 调度器首先会分配工作线程A执行协程A，工作线程B执行协程B，其他创建的协程将会在**等待队列**中进行排队等待\n3. 当协程A调用**暂停方法**或**被阻塞**时，协程A会进入到**挂起队列**，调度器会调用**等待队列**中的其他协程**抢占**线程A执行\n4. 当协程A**被唤醒**时，它需要重新进入到**就绪队列**中，通过调度器**抢占**线程\n    - 如果抢占成功，就继续执行协程A；如果抢占失败，就继续等待抢占线程\n\n### 线程 / 协程\n1. 相比于线程，协程少了由于同步资源**竞争**带来的_**CPU上下文切换**_\n2. 应用场景：_**IO阻塞型场景**_\n    - 比较适合**IO密集型**的应用，特别在**网络请求**中，有较多的时间在等待服务端响应\n        - 协程可以**保证线程不会阻塞在等待网络响应**（可以在协程层面阻塞）中，充分利用了多核多线程的能力\n    - 对于CPU密集型的应用，由于多数情况下CPU都比较繁忙，协程的优势就不会特别明显\n3. 线程是通过**共享内存**的方式来实现数据共享，而协程是使用了**通信**（MailBox）的方式来实现数据共享\n    - 这主要为了避免内存共享数据而带来的**线程安全**问题\n\n## 小结\n1. 协程可以认为是**运行在线程上的代码块**，协程提供的**挂起**操作会使**协程暂停执行**，而**不会导致线程阻塞**\n2. 协程是一种**轻量级资源**，即使创建上千个协程，对系统来说也不会是很大的负担，而线程则不然\n    - _**协程的设计方式极大地提高了线程的使用率**_\n","tags":["Java Performance"],"categories":["Performance"]},{"title":"Kafka -- 避免重平衡","url":"%2F2019%2F09%2F01%2Fkafka-avoid-rebalance%2F","content":"\n## 概念\n1. Rebalance是让Consumer Group下所有的Consumer实例**就如何消费订阅主题的所有分区达成共识**的过程\n2. 在Rebalance过程中，**所有Consumer实例共同参与**，在**协调者**组件的帮助下，完成**订阅主题分区的分配**\n3. 整个Rebalance过程中，所有Consumer实例都**不能消费任何消息**，因此对Consumer的**TPS**影响很大\n\n<!-- more -->\n\n## 协调者\n1. 协调者，即**Coordinator**，负责为Consumer Group执行**Rebalance**以及提供**位移管理**和**组成员管理**等\n2. Consumer端应用程序在提交位移时，其实是向**Coordinator所在的Broker提交位移**\n3. Consumer应用启动时，也是向Coordinator所在的Broker发送各种请求\n    - 然后由Coordinator负责执行**消费组的注册**、**成员管理记录**等**元数据管理**操作\n4. 所有Broker在启动时，都会创建和开启相应的Coordinator组件，**所有Broker都有各自的Coordinator组件**\n5. 内部位移主题`__consumer_offsets`记录了**为Consumer Group服务的Coordinator在哪一台Broker上**\n6. 为某个Consumer Group确定Coordinator所在的Broker，有两个步骤\n    - 确定由**位移主题的哪个分区**来保存该Consumer Group数据\n        - `partitionId = Math.abs(groupId.hashCode() % offsetsTopicPartitionCount`\n        - offsetsTopicPartitionCount默认为**50**\n    - 找出该分区**Leader**副本所在的Broker，该Broker即为对应的Coordinator\n\n## 弊端\n1. Rebalance**影响Consumer端TPS**\n2. Rebalance**很慢**\n3. Rebalance**效率不高**\n    - 每次Rebalance，Consumer Group下**所有成员**都需要参与，而且**不考虑局部性原理**，_**之前的分配方案都不会被保留**_\n    - 为了解决这个问题，社区于0.11.0.0版本推出**StickyAssignor**，即**粘性**的分区分配策略\n        - 粘性指的是每次Rebalance，都**尽可能地保留之前的分配方案**，尽量实现分区分配的**最小改动**\n        - 但该策略存在一些**Bug**，而且需要升级到0.11.0.0才能使用，实际生产环境中**用得不多**\n4. 影响Consumer端TPS + 慢属于**无解**，因此尽量_**减少不必要的Rebalance**_\n\n## 发生时机\n1. **组成员数量**发生变化 -- 最常见\n    - Consumer实例增加：一般是基于**增加TPS**或者**提高伸缩性**的需要，属于**计划内**的操作，**不属于不必要的Rebalance**\n    - Consumer实例**减少**：在某些情况下Consumer实例会被Coordinator**错误**地认为已停止而被踢出Consumer Group\n2. **订阅主题数量**发生变化\n    - 一般是**运维主动操作**，很难避免\n3. **订阅主题的分区数量**发生变化\n    - 一般是**运维主动操作**，很难避免\n\n## 实例减少\n\n### Consumer端参数\n1. 当Consumer Group完成Rebalance后，每个Consumer实例都会**定期**地向**Coordinator**发送**心跳**\n2. 如果某个Consumer实例不能及时地发送心跳\n    - Coordinator会认为该Consumer已死，并将其从Consumer Group中移除，开启新一轮的Rebalance\n3. Consumer端有一个参数`session.timeout.ms`，默认值为**10秒**\n    - 如果Coordinator在10秒内没有收到Consumer Group下某个Consumer实例的心跳，就会认为该Consumer已死\n4. Consumer端还有另一个参数`heartbeat.interval.ms`，默认值为**3秒**\n    - 设置得越小，Consumer实例发送心跳的频率就会越高，会额外消耗**带宽资源**，但能更快地知道是否开启Rebalance\n    - Coordinator通过将**REBALANCE_NEEDED标志**封装进**心跳响应**中，来通知Consumer实例开启Rebalance\n5. Consumer端还有另一个参数`max.poll.interval.ms`，默认值为**5分钟**\n    - 该参数用于控制Consumer**实际消费能力**对Rebalance的影响，限定了Consumer端两次调用**poll**方法的最大时间间隔\n    - Consumer如果在5分钟内**无法消费完**poll方法返回的消息，就会**主动发起离开组的请求**，开启新一轮的Rebalance\n\n### 非必要的Rebalance\n1. Consumer**未及时发送心跳**，导致被踢出Consumer Group而引发的Rebalance\n    - 生产配置：`session.timeout.ms=6000` + `heartbeat.interval.ms=2000`\n        - `session.timeout.ms=6000`：为了让Coordinator能够更快地定位已经挂掉的Consumer\n    - `session.timeout.ms > 3 * heartbeat.interval.ms`\n2. Consumer**消费时间过长**，主动发起离开组的请求而引发的Rebalance\n    - 如果消费逻辑很重（如DB操作），可以将`max.poll.interval.ms`设置得大一点\n3. 关注Consumer端的**GC**表现，频繁的**Full GC**会引起**非预期的Rebalance**","tags":["Rebalance"],"categories":["Kafka"]},{"title":"Java性能 -- 线程池大小","url":"%2F2019%2F08%2F31%2Fjava-performance-threadpool-size%2F","content":"\n## 线程池原理\n1. 在**Hotspot** JVM的线程模型中，Java线程被**一对一**映射为**内核线程**\n    - Java使用线程执行程序时，需要创建一个内核线程，当该Java线程被终止时，这个内核线程也会被回收\n    - Java线程的创建和销毁将会消耗一定的计算机资源，从而增加系统的性能开销\n    - 大量创建线程也会给系统带来性能问题，线程会抢占内存和CPU资源，可能会发生内存溢出、CPU超负载等问题\n2. 线程池：即可以**提高线程复用**，也可以**固定最大线程数**，防止无限制地创建线程\n    - 当程序提交一个任务需要一个线程时，会去线程池查找是否有**空闲**的线程\n    - 如果有，则直接使用线程池中的线程工作，如果没有，则判断当前已创建的线程数是否超过**最大线程数**\n    - 如果未超过，则创建新线程，如果已经超过，则进行**排队等待**或者直接**抛出异常**\n\n<!-- more -->\n\n## 线程池框架Executor\n1. Java最开始提供了**ThreadPool**来实现线程池，为了更好地实现**用户级的线程调度**，Java提供了一套**Executor**框架\n2. Executor框架包括了**ScheduledThreadPoolExecutor**和**ThreadPoolExecutor**两个**核心**线程池，**核心原理一样**\n    - ScheduledThreadPoolExecutor用来**定时**执行任务，ThreadPoolExecutor用来执行被提交的任务\n\n### Executors\n1. Executors利用**工厂模式**实现了4种类型的ThreadPoolExecutor\n2. **不推荐使用**Executors，因为会忽略很多线程池的参数设置，容易导致**无法调优**，产生**性能问题**或者**资源浪费**\n3. 推荐使用ThreadPoolExecutor自定义参数配置\n\n| 类型 | 特性 |\n| --- | --- |\n| newCachedThreadPool | 线程池大小**不固定**，可灵活回收空闲线程，若无可回收，则新建线程 |\n| newFixedThreadPool | 线程池大小**固定**，当有新任务提交，线程池中如果有空闲线程，则立即执行，<br/>否则新的任务会被**缓存**在一个**任务队列**中，等待线程池释放空闲线程 |\n| newScheduledThreadPool | 定时线程池，支持**定时**或者**周期性**地执行任务 |\n| newSingleThreadExecutor | 只创建一个线程，保证所有任务按照指定顺序（**FIFO**/**LIFO**/**优先级**）执行 |\n\n#### BlockingQueue\n1. ArrayBlockingQueue\n    - 基于**数组**结构实现的**有界**阻塞队列，按照**FIFO**原则对元素进行排序\n    - 使用**ReentrantLock**、**Condition**来实现线程安全\n2. LinkedBlockingQueue\n    - 基于**链表**结构实现的阻塞队列，按照**FIFO**原则对元素进行排序\n    - 使用**ReentrantLock**、**Condition**来实现线程安全\n    - **吞吐量**通常要高于ArrayBlockingQueue\n3. PriorityBlockingQueue\n    - 基于**二叉堆**结构实现的具有**优先级**的**无界**阻塞队列\n    - 队列**没有实现排序**，每当有数据变更时，都会将**最小**或**最大**的数据放在**堆最上面**的节点上\n    - 使用**ReentrantLock**、**Condition**来实现线程安全\n4. DelayQueue\n    - 支持**延时获取元素**的**无界**阻塞队列，基于**PriorityBlockingQueue**扩展实现\n5. SynchronousQueue\n    - **不存储多个元素**的阻塞队列，每次进行放入数据时，必须等待相应的消费者取走数据后，才可以再放入数据\n\n| 线程池类型 | 实现队列 |\n| --- | --- |\n| newCachedThreadPool | SynchronousQueue |\n| newFixedThreadPool | LinkedBlockingQueue |\n| newScheduledThreadPool | DelayedWorkQueue |\n| newSingleThreadExecutor | LinkedBlockingQueue |\n\n### ThreadPoolExecutor\n```java\n// 构造函数\npublic ThreadPoolExecutor(int corePoolSize, // 线程池的核心线程数\n                          int maximumPoolSize, // 线程池的最大线程数\n                          long keepAliveTime, // 当线程数大于核心线程数时，多余的空闲线程存活的最长时间\n                          TimeUnit unit, // 时间单位\n                          BlockingQueue<Runnable> workQueue, // 任务队列，用来存储等待执行的任务\n                          ThreadFactory threadFactory, // 线程工厂，用来创建线程，用默认即可\n                          RejectedExecutionHandler handler // 拒绝策略，当提交的任务过多而不能及时处理时，可以定制拒绝策略 \n                          ) \n```\n1. 在创建完线程池之后，默认情况下，线程池**并没有任何线程**，等到有任务来才创建线程去执行任务\n    - 如果调用**prestartAllCoreThreads**或者**prestartCoreThread**，可以提前创建等于**核心线程数**的线程数量，称为**预热**\n2. 当创建的线程数**等于corePoolSize**，提交的任务会被加入到设置的**阻塞队列**中\n3. 当阻塞队列**满**了，会创建线程执行任务，直到线程池中的数量**等于maximumPoolSize**\n4. 当线程数**等于maximumPoolSize**，新提交的任务无法加入到阻塞队列，也无法创建**非核心**线程**直接执行**\n    - 如果没有为线程池设置拒绝策略，线程池会抛出**RejectedExecutionException**，拒绝接受该任务\n5. 当线程数**超过corePoolSize**，在某些线程处理完任务后，如果等待keepAliveTime后仍然**空闲**，那么该线程将会被**回收**\n    - 回收线程时，**不会区分**是核心线程还是非核心线程，直到线程池中线程的数量等于corePoolSize，回收过程才会停止\n6. 默认情况下，当线程数**小于等于corePoolSize**时，是不会触发回收过程的，因此_**非核心业务线程池的空闲线程会长期存在**_\n    - 可以通过**allowCoreThreadTimeOut**方法设置：包括核心线程在内的**所有线程**，在空闲keepAliveTime后会被回收\n\n线程池的线程分配流程\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-threadpool-submit.png\" width=1000/>\n\n## 计算线程数量\n多线程执行的任务类型分为**CPU密集型**和**IO密集型**\n\n### CPU密集型\n1. 该类型任务的消耗主要是CPU资源，可以将线程数设置为**N（CPU核心数）+1**\n2. +1是为了防止线程偶发的缺页中断，或者其他原因导致的**任务暂停**而带来的影响，+1能够更充分地利用CPU的空闲时间\n\n### IO密集型\n1. 该类型任务在运行时，系统会用大部分的时间来处理**IO交互**\n2. 线程在处理IO的时间段内是**不会占用**CPU来处理，此时可以将CPU交出给其他线程使用，可以先设置为**2N**\n\n### 通用场景\n```\n线程数 = N * (1+ WT/ST)\n\nN = CPU核数\nWT = 线程等待时间\nST= 线程运行时间\n```\n可以根据业务场景，先简单地选择**N+1**或者**2N**，然后进行**压测**，最后依据压测结果进行调整\n","tags":["Thread Pool"],"categories":["Performance"]},{"title":"Java性能 -- 并发容器","url":"%2F2019%2F08%2F30%2Fjava-performance-concurrent-container%2F","content":"\n## 并发场景下的Map容器\n1. 某电商系统需要统计销量TOP 10的商品，通常用**哈希表**来存储商品和销量的键值对，然后使用**排序**获取销量TOP 10的商品\n2. 并发场景下不能使用HashMap\n    - JDK **1.7**，在并发场景下使用HashMap会出现**死循环**，导致**CPU使用率居高不下**，而**扩容**是导致死循环的主要原因\n    - JDK **1.8**，虽然修复了HashMap扩容导致的死循环问题，但在高并发场景下，依然会有**数据丢失**和**不准确**的情况\n3. 为了保证Map容器的**线程安全**，Java实现了**HashTable**、**ConcurrentHashMap**、**ConcurrentSkipListMap**\n    - HashTable、ConcurrentHashMap是**基于HashMap**实现的，适用于**小数据量**存取的场景\n    - ConcurrentSkipListMap是**基于TreeMap**的设计原理实现的\n        - ConcurrentSkipListMap是基于**跳表**实现的，而TreeMap是基于**红黑树**实现的\n        - ConcurrentSkipListMap最大的特点是存取**平均时间复杂度**为`O(log(n))`，适用于**大数据量**存取的场景\n\n<!-- more -->\n\n### HashTable / ConcurrentHashMap\n1. 在数据**不断地写入和删除**，且**不存在**数据**累积**以及数据**排序**的场景下，可以选用HashTable或者ConcurrentHashMap\n2. HashTable使用**synchronized同步锁**修饰了put、get、remove等方法\n    - 在**高并发**场景下，读写操作都会存在大量**锁竞争**，给系统带来**性能开销**\n3. 相比于HashTable，ConcurrentHashMap在保证**线程安全**的基础上兼具了**更好的并发性能**\n    - JDK 1.7中，ConcurrentHashMap使用了**分段锁Segment**减少了锁粒度，优化了锁的并发操作\n    - JDK 1.8中，ConcurrentHashMap做了大量的改动，**摒弃了Segment的概念**\n        - synchronized同步锁在JDK 1.6的性能已经得到了很大的提升\n        - 在JDK 1.8中，**重启了synchronized同步锁**，通过synchronized实现**Node**作为锁粒度\n        - put方法：没有哈希冲突时，使用**CAS**进行添加元素操作；有哈希冲突时，**通过synchronized将链表锁定**\n4. 在统计销量TOP 10的场景下，首选ConcurrentHashMap\n5. ConcurrentHashMap的**整体性能**要优于HashTable，但某些场景下ConcurrentHashMap不能替代HashTable\n    - 例如**强一致性**的场景，ConcurrentHashMap的get、size等方法都**没有加锁**，ConcurrentHashMap是**弱一致性**的\n\n### ConcurrentHashMap / ConcurrentSkipListMap\n1. ConcurrentHashMap在**数据量比较大**的时候，**链表会转换为红黑树**\n    - 红黑树在并发情况下，删除和插入过程有个**平衡**的过程，会涉及到**大量结点**，**竞争锁资源的代价相对较高**\n    - 而**跳跃表**的操作针对**局部**，需要**锁住的结点少**，在并发场景下性能会更好一些\n2. 在**非线程安全**的Map中，基于**红黑树**实现的**TreeMap**在**单线程**中的**性能表现**并不比跳跃表差\n3. 因此\n    - 在**非线程安全**的Map容器中，使用**TreeMap**来存取**大数据**\n    - 在**线程安全**的Map容器中，使用**ConcurrentSkipListMap**来存取**大数据**\n\n#### 跳跃表\n1. 跳跃表是基于链表扩展实现的一种特殊链表，类似于**树**的实现\n2. 跳跃表不仅实现了**横向链表**，还实现了**垂直方向**的**分层索引**\n3. 一个跳跃表由若干层链表组成，每一层都实现了一个**有序链表索引**，只有**最底层包含所有数据**\n    - 每一层由下往上依次通过一个指针**指向上层相同值的元素**，每层数据依次减少，到最顶层只会保留部分数据\n4. 跳跃表利用了**空间换时间**的方法来提高查询效率，程序总是从**最顶层**开始查询访问，通过判断元素值来缩小查询范围\n\n初始化的跳跃表\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-concurrent-container-skiplist-1.jpg\" width=1000/>\n\n查询Key值为9的结点\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-concurrent-container-skiplist-2.jpg\" width=1000/>\n\n1. 新增Key值为8的结点，首先**新增**一个结点（**CAS操作**）到**最底层**的链表中\n2. 根据概率算出level值，再根据level值新建索引层，最后**链接**索引层的新结点（**CAS操作**）\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-concurrent-container-skiplist-3.jpg\" width=1000/>\n\n1. 删除Key值为7的结点，首先找到待删除结点，将其**value**值设置为**null**\n2. 之后再向**待删除结点的next位置**新增一个**标记结点**，以便减少**并发冲突**\n3. 然后让待删除结点的前驱结点直接越过本身指向的待删除结点，直接指向后继结点，中间要被删除的结点最终会被垃圾回收\n4. 最后判断此次删除后是否导致某一索引层没有其他节点了，并视情况删除该层索引\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-concurrent-container-skiplist-4.jpg\" width=1000/>\n\n### 使用场景\n1. HashTable：数据**强一致性**\n2. ConcurrentHashMap：（大部分情况）数据**弱一致性**\n3. ConcurrentSkipListMap：数据量在**千万**级别，且存在**大量的增删改**操作\n\n## 并发场景下的List容器\n1. ArrayList并非线程安全容器，Java提供了线程安全容器：**Vector**、**CopyOnWriteArrayList**\n2. Vector是基于**synchronized同步锁**实现的线程安全，synchronized关键字几乎修饰了所有对外暴露的方法\n    - 在**读远大于写**的操作场景下，Vector将会发生**大量锁竞争**，给系统带来**性能开销**\n3. CopyOnWriteArrayList：**读操作无锁**，写操作通过**底层数组的新副本**来实现，是一种**读写分离**的并发策略\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-concurrent-container-cop-on-write-array-list.jpg\" width=1000/>\n\n## 小结\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-concurrent-container-summary.jpg\" width=1000/>\n\n## 参考资料\n1. [老生常谈，HashMap的死循环](https://juejin.im/post/5a66a08d5188253dc3321da0)\n","tags":["ConcurrentSkipListMap"],"categories":["Performance"]},{"title":"架构 -- 复杂度 -- 高性能","url":"%2F2019%2F08%2F29%2Farchitecture-complexity-high-performance%2F","content":"\n## 架构的目的\n1. 架构设计的目的：解决**软件系统复杂度**带来的问题\n2. 软件复杂度的主要来源：**高性能**、**高可用**、**可扩展性**、**低成本**、**安全**、**规模**\n\n<!-- more -->\n\n## 单机复杂度\n1. 计算机内部复杂度最关键的地方是**操作系统**\n2. 计算机性能的发展本质是由**硬件发展驱动**的，将硬件性能充分发挥出来的关键是操作系统\n    - 操作系统是软件系统的运行环境，**操作系统的复杂度直接决定了软件系统的复杂度**\n3. 操作系统和性能最相关的是**进程**和**线程**\n    - 最早期的计算机并没有操作系统，只有**输入、计算和输出**功能，大部分时间计算机都在等待用户输入指令\n    - 为了解决手工输入的低效，产生了**批处理**（即把要执行的指令预先写下来，形成任务，再交给计算机执行）\n        - 批处理有一个明显的缺点，即计算机一次只能执行一个任务，为了进一步提升性能，发明了**进程**\n    - 一个进程对应一个任务，每个任务都有自己独立的内存空间，**进程间互不相关，由操作系统进行调度**\n        - 此时CPU还没有**多核**和**多线程**的概念，为了达到**多进程并行**的目的，采取了**分时**的方式\n        - 进程有独立的内存空间，互不相关，但进程间仍需要进行通信，方式包括：**管道**、**消息队列**、**信号量**、**共享存储**\n        - 进程也有缺点，即单个进程内部只能**串行**处理，实际上进程内部的子任务是可以并行处理的，于是发明了**线程**\n    - 线程是进程内部的**子任务**，线程**共享**同一份进程数据，为了保证数据的正确性，发明了**互斥锁**机制\n        - 线程是操作系统**调度**的最小单位，进程是操作系统**分配资源**的最小单位\n    - 多进程多线程让多任务并行处理的性能大大提升，但本质上还是**分时**系统，并不能做到时间上真正的并行\n        - 解决方案：多CPU多核并行执行计算任务\n\n## 集群复杂度\n\n### 任务分配\n<img src=\"https://architecture-1253868755.cos.ap-guangzhou.myqcloud.com/architecture-complexity-high-performance-cluster-task-assignment-1.png\" width=600/>\n\n1. 每台机器都可以处理**完整**的业务任务，不同的任务分配到不同的机器上执行\n2. 1台服务器变成2台服务器，引入的**复杂度**\n    - 需要增加一个**任务分配器**\n        - 可能是：**硬件网络设备**（交换机）、**软件网络设备**（LVS）、**负载均衡软件**（Nginx）、**算法**\n        - 需要综合考虑性能、成本、可维护性、可用性等\n    - 任务分配器与真正的业务服务器之间有连接和交互，选择合适的连接方式，并对连接进行管理\n    - 任务分配器需要增加**分配算法**：轮询、按权重、按负载（业务服务器需要上报状态）\n3. 随着业务服务器数量的增加，系统性能会提升，任务分配器本身会成为**性能瓶颈**，任务分配器也需要**集群部署**\n\n<img src=\"https://architecture-1253868755.cos.ap-guangzhou.myqcloud.com/architecture-complexity-high-performance-cluster-task-assignment-2.png\" width=600/>\n\n1. 任务分配器从1台变成多台，带来的复杂度：**将不同的用户分配到不同的任务分配器上**\n    - 常见方法：DNS轮询、智能DNS、CDN、GSLB（Global Server Load Balance，全局负载均衡）设备\n2. 任务分配器和业务服务器的连接从**1对多**变成了**多对多**的网状结构\n3. 随着服务器数量的增加，状态管理、故障处理的复杂度会大大增加\n\n### 任务分解\n1. 通过**任务分配**，能够突破单台服务器处理性能的瓶颈，但随着业务越来越复杂，通过该方式来扩展性能，收益会越来越小\n2. 通过**任务分解**，能够把原来大一统且复杂的业务系统，拆分成小而简单但需要多个系统配合的业务系统\n    - 能够提高性能的原因：**简单的系统更容易做到高性能**、**可以针对单个任务进行扩展**\n3. 任务分解**不是越细越好**，因为任务分解带来的性能收益是有**上限**的\n    - 拆分得越细，为了完成某个业务，系统间的调用次数会呈**指数级上升**\n    - 系统间的调用目前都是通过**网络传输**的方式，**性能远低于系统内的函数调用**\n","tags":["High Performance"],"categories":["Architecture"]},{"title":"网络编程 -- TCP三次握手","url":"%2F2019%2F08%2F28%2Fnetwork-programming-tcp-3-way-handshake%2F","content":"\n## 服务端准备连接\n\n### 创建套接字\n```c\nint socket(int domain, int type, int protocol)\n```\n1. domain指的是**PF_INET、PF_INET6、PF_LOCAL**等，表示什么样的套接字\n2. type\n    - **SOCK_STREAM**：表示**字节流**，对应**TCP**\n    - **SOCK_DGRAM**：表示**数据报**，对应**UDP**\n    - **SOCK_RAW**：表示**原始套接字**\n3. protocol原本用来指定通信协议，但现在基本废弃，一般写成**0**即可\n\n<!-- more -->\n\n### bind\n```c\nbind(int fd, sockaddr * addr, socklen_t len)\n```\n1. 调用bind函数把**套接字**（fd）和**套接字地址**（addr）绑定\n2. 第二个参数为**通用地址格式**`sockaddr * addr`，实际传入的参数可能为**IPv4、IPv6或者本地套接字格式**\n    - bind函数会根据len字段（表示传入的地址长度）判断传入的addr参数该怎么解析\n\n#### 使用者 / 实现者\n对于**使用者**来说，每次需要将IPv4、IPv6或者本地套接字格式转化为**通用套接字格式**\n```c\nstruct sockaddr_in name;\nbind (sock, (struct sockaddr *) &name, sizeof (name))\n```\n\n对于**实现者**来说，可以根据该地址结构的**前两个字节**判断出是那种地址，为了处理可变长度的结构，需要借助**len**字段\n\n#### 地址 / 端口\n1. 可以把地址设置为**本机IP地址**\n    - 告诉操作系统内核，仅仅对目标IP是本机IP地址的IP包进行处理，但并不能提前预知应用会被部署到哪台机器上\n2. **通配地址**：一台机器有两块网卡，向这两块网卡发送的IP包都会被处理\n    - IPv4：**INADDR_ANY**；IPv6：**IN6ADDR_ANY**\n3. 如果将端口设置为**0**，相当于把**端口的选择权**交给操作系统**内核**（根据一定的算法选择一个**空闲**的端口），**在服务端不常用**\n\n初始化IPv4 TCP套接字（socket + bind）\n```java\n#include <stdio.h>\n#include <stdlib.h>\n#include <sys/socket.h>\n#include <netinet/in.h>\n\nint make_socket (uint16_t port)\n{\n  int sock;\n  struct sockaddr_in name;\n\n  /* 创建字节流类型的IPV4 socket */\n  sock = socket (PF_INET, SOCK_STREAM, 0);\n  if (sock < 0)\n    {\n      perror (\"socket\");\n      exit (EXIT_FAILURE);\n    }\n\n  /* 绑定到port和ip */\n  name.sin_family = AF_INET; /* IPV4 */\n  name.sin_port = htons (port);  /* 指定端口 */\n  name.sin_addr.s_addr = htonl (INADDR_ANY); /* 通配地址 */\n  /* 把IPV4地址转换成通用地址格式，同时传递长度 */\n  if (bind (sock, (struct sockaddr *) &name, sizeof (name)) < 0)\n    {\n      perror (\"bind\");\n      exit (EXIT_FAILURE);\n    }\n\n  return sock\n}\n```\n\n### listen\n1. 初始化创建的套接字，是一个**主动**套接字，目的是之后**主动发起请求**（调用**connect**函数）\n2. 通过调用**listen**函数，将原来的**主动**套接字转换为**被动**套接字，目的是之后用来**等待用户请求**\n\n```c\n// socketfd：套接字描述符\n// backlog：未完成连接队列的大小，决定了可以接收的并发数目，参数过大会占用过多的系统资源，Linux不允许修改该参数\n// 返回值为listen套接字\nint listen (int socketfd, int backlog)\n```\n\n### accept\n1. 当客户端的连接请求到达时，服务端应答成功，连接建立\n    - 此时操作系统**内核**需要把这个事件**通知**到应用程序，并让应用程序感知到这个连接\n2. accept函数的作用：_**连接建立后，操作系统内核和应用程序之间的桥梁**_\n3. **listen套接字一直存在**，要为成千上万的客户服务，直到这个listen套接字关闭\n    - 一旦一个客户与服务器连接成功，**完成TCP三次握手**，操作系统就会为这个客户**生成一个已连接套接字**\n    - 服务器使用这个已连接套接字和客户进行通信处理\n    - 如果服务器完成了对客户的服务，就会**关闭已连接套接字**，这样就完成了**TCP连接的释放**\n\n```c\n// listensockfd：listen套接字，经过socket、bind、listen操作后得到的套接字\n// 函数的返回值有两部分\n//  1. cliaddr：通过指针方式获取的客户端地址；addrlen：客户端地址的大小\n//  2. 函数的返回值，是一个全新的描述字，代表了与客户端的连接\nint accept(int listensockfd, struct sockaddr *cliaddr, socklen_t *addrlen)\n```\n\n## 客户端发起连接\n第一步和服务端一样，创建一个套接字（可以不bind）\n\n### connect\n1. 客户端和服务器建立连接，是通过**connect**函数完成的\n2. 客户端在**调用函数connect前可以不调用bind函数**\n    - 如果调用，内核会确定**源IP地址**，并按照一定的算法选择一个**临时端口**作为**源端口**\n3. 如果是TCP套接字，那么调用connect函数会激发TCP的三次握手，仅在**连接成功建立或出错**时返回\n    - 三次握手无法建立，客户端发出的**SYN**包没有任何响应，返回**TIMEOUT**错误\n        - 常见场景：服务器**IP**写错\n    - 客户端收到了**RST**（复位）应答，此时客户端会返回**CONNECTION REFUSED**错误\n        - 常见场景：服务器**端口**写错\n        - RST是TCP在发生错误时发送的一种**TCP分节**\n        - 产生RST的条件\n            - 目的地为某端口的SYN到达，然而并没有监听该端口的服务\n            - TCP想取消一个已有连接\n            - TCP接收到一个根本不存在的连接上的分节\n    - 客户端发出的**SYN**包在网络上引起**destination unreachable**，即**目标不可达**错误\n        - 场景场景：客户端与服务端**路由不通**\n\n```c\n// sockfd：连接套接字，通过前面的socket函数创建\n// servaddr：指向套接字地址结构（包含服务器的IP和端口）的指针\nint connect(int sockfd, const struct sockaddr *servaddr, socklen_t addrlen)\n```\n\n## TCP三次握手\n1. 服务器端通过socket、bind和listen完成了**被动套接字**的准备工作，然后调用accept，就会**阻塞等待**客户端的连接\n2. 客户端通过调用socket和connect函数后，也会**阻塞等待**\n3. 接下来的过程由操作系统内核的**网络协议栈**完成\n\n### 网络协议栈\n1. 客户端的网络协议栈向服务器端发送**SYN**包，告诉服务器端当前发送序列号为j，客户端进入**SYNC_SENT**状态\n2. 服务器端的网络协议栈收到这个SYN包后，和客户端进行**ACK**应答，应答值为j+1，表示对SYN包的确认\n    - 同时服务器也发送一个**SYN**包，告诉客户端当前服务器端的发送序列号为k，服务器端进入**SYNC_RCVD**状态\n3. 客户端的网络协议栈收到**ACK**包后，使得应用程序_**从connect阻塞调用返回**_\n    - 表示**客户端到服务端的单向连接建立成功**，客户端的状态为**ESTABLISHED**\n    - 同时客户端的网络协议栈也会对服务器端的SYN包进行ACK应答，应答值为k+1\n4. ACK包到达服务器端后，服务器端的网络协议栈使得应用程序_**从accept阻塞调用返回**_\n    - 表示**服务器端到客户端的单向连接也建立成功**，服务器端也进入了**ESTABLISHED**状态\n","tags":["Network Programming"],"categories":["Programming"]},{"title":"Spring -- Docker","url":"%2F2019%2F08%2F27%2Fspring-docker%2F","content":"\n## 容器 / 虚拟机\n容器是**应用层的抽象**，是标准化的单元，容器内部不包含**操作系统**的细节和内容，比虚拟机**轻量**\n<img src=\"https://spring-1253868755.cos.ap-guangzhou.myqcloud.com/spring-nosql-docker-container-vm.png\" width=1000/>\n\n<!-- more -->\n\n## Docker\n**开发**：简化开发环境的搭建；**运维**：交付系统更为流畅，伸缩性更好\n<img src=\"https://spring-1253868755.cos.ap-guangzhou.myqcloud.com/spring-nosql-docker.png\" width=1000/>\n\n## 常用命令\n\n### 镜像相关\n1. docker search \\<image\\>\n2. docker pull \\<image\\>\n\n### 容器相关\n1. docker run\n2. docker start/stop \\<container\\>\n3. docker ps \\<container\\>\n4. docker logs \\<container\\>\n\n### docker run\n1. docker run [**option...**] image [command] [arg...]\n2. -d：后台运行容器\n3. -e：设置环境变量\n4. \\-\\-expose/-p 宿主端口:容器端口\n5. \\-\\-name：指定容器名称\n6. \\-\\-link：链接其他容器\n7. -v 宿主目录:容器目录，挂载磁盘卷\n\n## mongo\n\n### docker search\n```\n$ docker search mongo\nNAME                                DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED\nmongo                               MongoDB document databases provide high avai…   6196                [OK]\nmongo-express                       Web-based MongoDB admin interface, written w…   516                 [OK]\ntutum/mongodb                       MongoDB Docker image – listens in port 27017…   228                                     [OK]\n...\n```\n\n### docker pull\n```\n$ docker pull mongo\nUsing default tag: latest\nlatest: Pulling from library/mongo\nDigest: sha256:d9e20d05063ba34bac4da916e335c70d6add38241cee1e99ad96c47660bd6955\nStatus: Image is up to date for mongo:latest\ndocker.io/library/mongo:latest\n```\n\n### docker images\n```\ndocker images\nREPOSITORY                  TAG                 IMAGE ID            CREATED             SIZE\nmongo                       latest              cdc6740b66a7        4 weeks ago         361MB\nzookeeper                   latest              4ebfb9474e72        5 months ago        150MB\nmysql                       latest              7bb2586065cd        5 months ago        477MB\n...\n```\n\n### docker run\n```\n$ docker run -d --name mongo -p 27017:27017 -v ~/docker-data/mongo:/data/db -e MONGO_INITDB_ROOT_USERNAME=root -e MONGO_INITDB_ROOT_PASSWORD=123456 mongo\n19fcb168261d63aa094ed79b7d93d997f1b58330537fc76bd1bebf24f8cbee1f\n```\n\n### docker ps\n```\n$ docker ps -a\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                      NAMES\n19fcb168261d        mongo               \"docker-entrypoint.s…\"   6 minutes ago       Up 6 minutes        0.0.0.0:27017->27017/tcp   mongo\n```\n\n### docker exec\n```\n$ docker exec -it mongo /bin/bash\nroot@19fcb168261d:/# mongo -uroot -p123456\nMongoDB shell version v4.2.0\nconnecting to: mongodb://127.0.0.1:27017/?compressors=disabled&gssapiServiceName=mongodb\nImplicit session: session { \"id\" : UUID(\"9413b54e-cf03-4951-9dbb-8e069565a503\") }\nMongoDB server version: 4.2.0\nWelcome to the MongoDB shell.\n\n> show dbs\nadmin   0.000GB\nconfig  0.000GB\nlocal   0.000GB\n```\n","tags":["NoSQL"],"categories":["Spring Boot"]},{"title":"Kafka -- 位移主题","url":"%2F2019%2F08%2F26%2Fkafka-offset-topic%2F","content":"\n## ZooKeeper\n1. 老版本Consumer的位移管理依托于**Apache ZooKeeper**，自动或手动地将位移数据提交到ZK中保存\n2. 当Consumer重启后，能自动从ZK中读取位移数据，从而在上次消费截止的地方继续消费\n3. 这种设计使得Kafka Broker不需要保存位移数据，减少了Broker端需要持有的**状态空间**，有利于实现**高伸缩性**\n4. 但ZK并**不适用于高频的写操作**\n\n<!-- more -->\n\n## 位移主题\n1. 将Consumer的位移数据作为**普通的Kafka消息**，提交到`__consumer_offsets`（保存Consumer的位移信息）\n    - 提交过程需要实现**高持久性**，并需要支持**高频的写操作**\n2. 位移主题是**普通的Kafka主题**，同时也是一个**内部主题**，交由Kafka管理即可\n3. 位移主题的**消息格式由Kafka定义**，用户不能修改\n    - 因此不能随意向位移主题写消息，一旦写入的消息不能满足格式，那Kafka内部无法成功解析，会造成**Broker崩溃**\n    - Kafka Consumer有**API**来提交位移（即向位移主题写消息）\n\n### 消息格式\n1. 常用格式：**Key-Value**\n    - Key为**消息键值**，Value为**消息体**，在Kafka中都是**字节数组**\n    - Key\n        - **`<Group ID, Topic, Partition>`**\n    - Value\n        - **Offset** + Other MetaData（时间戳等，这是为了执行各种各样的后续操作，例如删除过去位移信息等）\n2. 用于**保存Consumer Group信息**的消息\n    - 用来**注册**Consumer Group\n3. 用于**删除Group过期位移**甚至**删除Group**的消息\n    - 专属名词：**tombstone消息**，即**墓碑消息**，也称**delete mark**，主要特点是**消息体为null**\n    - 一旦某个Consumer Group下**所有的Consumer实例都停止**，而且它们的**位移数据已被删除**\n        - Kafka会向**位移主题的对应分区**写入tombstone消息，表明要**彻底删除**这个Consumer Group\n\n### 创建位移主题\n1. Kafka集群中的**第一个Consumer**程序启动时，会自动创建位移主题\n    - Broker端参数：**offsets.topic.num.partitions=50**，Kafka会自动创建**50分区**的位移主题\n    - Broker端参数：**offsets.topic.replication.factor=3**，Kafka会自动创建**3副本**的位移主题\n2. 手动创建位移主题\n    - 在Kafka集群尚未启动任何Consumer之前，使用Kafka API来创建\n3. 推荐：采用Kafka的**自动创建**\n\n### 提交位移\n1. 自动提交位移\n    - **enable.auto.commit=true**\n    - Consumer在后台默默地**定期提交位移**，提交间隔由参数控制`auto.commit.interval.ms`\n    - 缺点\n        - 完全无法把控Consumer端的位移管理\n            - 很多与Kafka集成的大数据框架都**禁用自动提交位移**的，如Spark、Flink等\n        - 只要Consumer一直启动着，就会**无限期**地向位移主题写入消息\n            - 假设Consumer当前消费了某个主题的最新一条消息，位移为100，之后该主题就没有产生任何新消息\n            - 但由于设置了自动提交位移，位移主题会不停地写入位移=100，这就要求位移主题有特定的**消息删除策略**\n2. 手动提交位移\n    - **enable.auto.commit=false**\n    - 需要应用程序手动提交位移\n\n### 删除过期消息\n1. 策略：**Compaction**（整理）\n2. Kafka使用**Compact策略**来删除位移主题中的**过期消息**，避免该主题**无限期膨胀**\n3. 过期消息：对于**同一个Key**的两条消息M1和M2，如果M1的发送时间早于M2，那么M1就是过期消息\n4. Compact过程：扫描日志的**所有消息**，剔除过期的消息，然后把剩下的消息整理在一起\n5. Kafka提供了**专门的后台线程**（**Log Cleaner**）来**定期巡检**待Compact的主题\n    - 如果位移主题**无限期膨胀**，占用过多的磁盘空间，检查下Log Cleaner线程的状态\n\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-offset-topic-compact.jpeg\" width=800/>\n","tags":["Stream"],"categories":["Kafka"]},{"title":"Java性能 -- 线程上下文切换","url":"%2F2019%2F08%2F25%2Fjava-performance-thread-cs%2F","content":"\n## 线程数量\n1. 在并发程序中，并不是启动更多的线程就能让程序最大限度地并发执行\n2. 线程数量设置太小，会导致程序不能充分地利用系统资源\n3. 线程数量设置**太大**，可能带来资源的**过度竞争**，导致**上下文切换**，带来的额外的**系统开销**\n\n<!-- more -->\n\n## 上下文切换\n1. 在单处理器时期，操作系统就能处理**多线程并发**任务，处理器给每个线程分配**CPU时间片**，线程在CPU时间片内执行任务\n    - CPU时间片是CPU分配给每个线程执行的时间段，一般为**几十毫秒**\n2. 时间片决定了一个线程可以**连续占用**处理器运行的时长\n    - 当一个线程的时间片用完，或者因自身原因被迫暂停运行，此时另一个线程会被操作系统选中来占用处理器\n    - **上下文切换**（Context Switch）：一个线程被**暂停剥夺**使用权，另一个线程被**选中开始**或者**继续运行**的过程\n        - **切出**：一个线程被剥夺处理器的使用权而被暂停运行\n        - **切入**：一个线程被选中占用处理器开始运行或者继续运行\n        - 切出切入的过程中，操作系统需要保存和恢复相应的**进度信息**，这个进度信息就是_**上下文**_\n3. 上下文的内容\n    - **寄存器的存储内容**：CPU寄存器负责存储已经、正在和将要执行的任务\n    - **程序计数器存储的指令内容**：程序计数器负责存储CPU正在执行的指令位置、即将执行的下一条指令的位置\n4. 当CPU数量远远不止1个的情况下，操作系统将CPU轮流分配给线程任务，此时的上下文切换会变得更加**频繁**\n    - 并且存在**跨CPU的上下文切换**，更加**昂贵**\n\n## 切换诱因\n1. 在操作系统中，上下文切换的类型可以分为**进程间**的上下文切换和**线程间**的上下文切换\n2. 线程状态：NEW、RUNNABLE、RUNNING、BLOCKED、DEAD\n    - Java线程状态：NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED\n4. 线程上下文切换：**RUNNING -> BLOCKED -> RUNNABLE -> 被调度器选中执行**\n    - 一个线程从RUNNING状态转为BLOCKED状态，称为一个线程的**暂停**\n        - 线程暂停被切出后，操作系统会保存相应的上下文\n        - 以便该线程再次进入RUNNABLE状态时能够在之前执行进度的基础上继续执行\n    - 一个线程从BLOCKED状态进入RUNNABLE状态，称为一个线程的**唤醒**\n        - 此时线程将获取上次保存的上下文继续执行\n5. 诱因：程序本身触发的**自发性上下文切换**、系统或虚拟机触发的**非自发性上下文切换**\n    - 自发性上下文切换\n        - _**sleep、wait、yield、join、park、synchronized、lock**_\n    - 非自发性上下文切换\n        - 线程被分配的**时间片用完**、**JVM垃圾回收**（**STW**、线程暂停）、线程**执行优先级**\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-cs-thread-life-cycle.jpg\" width=1000/>\n\n## 监控切换\n\n### 样例代码\n```java\npublic static void main(String[] args) {\n    new MultiThreadTesterAbstract().start();\n    new SerialThreadTesterAbstract().start();\n    // multi thread take 5401ms\n    // serial take 692ms\n}\n\nstatic abstract class AbstractTheadContextSwitchTester {\n    static final int COUNT = 100_000_000;\n    volatile int counter = 0;\n\n    void increaseCounter() {\n        counter++;\n    }\n\n    public abstract void start();\n}\n\nstatic class MultiThreadTesterAbstract extends AbstractTheadContextSwitchTester {\n\n    @Override\n    public void start() {\n        Stopwatch stopwatch = Stopwatch.createStarted();\n        Thread[] threads = new Thread[4];\n        for (int i = 0; i < 4; i++) {\n            threads[i] = new Thread(new Runnable() {\n                @Override\n                public void run() {\n                    while (counter < COUNT) {\n                        synchronized (this) {\n                            if (counter < COUNT) {\n                                increaseCounter();\n                            }\n                        }\n                    }\n                }\n            });\n            threads[i].start();\n        }\n        for (int i = 0; i < 4; i++) {\n            try {\n                threads[i].join();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        log.info(\"multi thread take {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n    }\n}\n\nstatic class SerialThreadTesterAbstract extends AbstractTheadContextSwitchTester {\n\n    @Override\n    public void start() {\n        Stopwatch stopwatch = Stopwatch.createStarted();\n        for (int i = 0; i < COUNT; i++) {\n            increaseCounter();\n        }\n        log.info(\"serial take {}ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS));\n    }\n}\n```\n1. 串行的执行速度比并发执行的速度要快，因为线程的**上下文切换**导致了**额外的开销**\n    - 使用synchronized关键字，导致了**资源竞争**，从而引起了上下文切换\n    - 即使不使用synchronized关键字，并发的执行速度也无法超越串行的执行速度，因为多线程同样存在上下文切换\n2. **Redis的设计很好地体现了单线程串行的优势**\n    - 从**内存**中快速读取值，不用考虑**IO瓶颈**带来的**阻塞**问题\n\n### 监控工具\n\n#### vmstat\n**cs**：系统的上下文切换频率\n```\nroot@5d15480e8112:/# vmstat\nprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n 3  0      0 693416  33588 951508    0    0    77   154  116  253  1  1 98  0  0\n```\n\n#### pidstat\n```\n-w  Report task switching activity (kernels 2.6.23 and later only).  The following values may be displayed:\n    UID\n         The real user identification number of the task being monitored.\n    USER\n         The name of the real user owning the task being monitored.\n    PID\n         The identification number of the task being monitored.\n    cswch/s\n         Total number of voluntary context switches the task made per second.  A voluntary context switch occurs when a task blocks because  it  requires  a\n         resource that is unavailable.\n    nvcswch/s\n         Total  number  of  non  voluntary context switches the task made per second.  A involuntary context switch takes place when a task executes for the\n         duration of its time slice and then is forced to relinquish the processor.\n    Command\n         The command name of the task.\n```\n```\nroot@5d15480e8112:/# pidstat -w -l -p 1 2 5\nLinux 4.9.184-linuxkit (5d15480e8112) \t09/16/2019 \t_x86_64_\t(2 CPU)\n\n07:28:03      UID       PID   cswch/s nvcswch/s  Command\n07:28:05        0         1      0.00      0.00  /bin/bash\n07:28:07        0         1      0.00      0.00  /bin/bash\n07:28:09        0         1      0.00      0.00  /bin/bash\n07:28:11        0         1      0.00      0.00  /bin/bash\n07:28:13        0         1      0.00      0.00  /bin/bash\nAverage:        0         1      0.00      0.00  /bin/bash\n```\n\n## 切换的系统开销\n1. 操作系统**保存和恢复上下文**\n2. 调度器进行**线程调度**\n3. 处理器**高速缓存重新加载**\n4. 可能导致**整个高速缓存区被冲刷**，从而带来时间开销\n\n## 竞争锁优化\n1. 多线程对锁资源的竞争会引起上下文切换，锁竞争导致的线程阻塞越多，上下文切换就越频繁，系统的性能开销就越大\n    - 在多线程编程中，锁本身不是性能开销的根源，_**锁竞争才是性能开销的根源**_\n2. 锁优化归根到底是**减少竞争**\n\n### 减少锁的持有时间\n1. 锁的持有时间越长，意味着越多的线程在等待该竞争锁释放\n2. 如果是**synchronized**同步锁资源，不仅带来了**线程间**的上下文切换，还有可能会带来**进程间**的上下文切换\n3. 优化方法：将一些**与锁无关的代码移出同步代码块**，尤其是那些开销较大的操作以及可能被阻塞的操作\n\n### 减少锁粒度\n\n#### 锁分离\n1. 读写锁实现了锁分离，由读锁和写锁两个锁实现，可以**共享读**，但**只有一个写**\n    - 读写锁在多线程读写时，**读读不互斥**，读写互斥，写写互斥\n    - 传统的独占锁在多线程读写时，**读读互斥**，读写互斥，写写互斥\n2. 在**读远大于写**的多线程场景中，锁分离避免了高并发读情况下的资源竞争，从而**避免了上下文切换**\n\n#### 锁分段\n1. 在使用锁来保证**集合**或者**大对象**的原子性时，可以将锁对象进一步分解\n2. Java 1.8之前的ConcurrentHashMap就是用了**锁分段**\n\n### 非阻塞乐观锁代替竞争锁\n1. **volatile**\n    - volatile关键字的作用是保证**可见性**和**有序性**，volatile的读写操作**不会导致上下文切换**，**开销较小**\n    - 由于volatile关键字**没有锁的排它性**，因此**不能保证**操作变量的**原子性**\n2. CAS\n    - CAS是一个**原子**的**if-then-act**操作\n    - CAS是一个**无锁算法**实现，保障了对一个共享变量读写操作的**一致性**\n    - **CAS不会导致上下文切换**，Java的**Atomic**包就使用了CAS算法来更新数据，而不需要额外加锁\n\n### synchronized锁优化\n1. 在JDK 1.6中，JVM将synchronized同步锁分为**偏向锁、轻量级锁、自旋锁、重量级锁**\n2. JIT编译器在动态编译同步代码块时，也会通过**锁消除、锁粗化**的方式来优化synchronized同步锁\n\n## wait/notify优化\n可以通过Object对象的**wait、notify、notifyAll**来实现**线程间的通信**，例如生产者-消费者模型\n```java\npublic class WaitNotifyTest {\n    public static void main(String[] args) {\n        Vector<Integer> pool = new Vector<>();\n        Producer producer = new Producer(pool, 10);\n        Consumer consumer = new Consumer(pool);\n        new Thread(producer).start();\n        new Thread(consumer).start();\n    }\n}\n\n@AllArgsConstructor\nclass Producer implements Runnable {\n    private final Vector<Integer> pool;\n    private Integer size;\n\n    @Override\n    public void run() {\n        for (; ; ) {\n            try {\n                produce((int) System.currentTimeMillis());\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n\n    private void produce(int i) throws InterruptedException {\n        while (pool.size() == size) {\n            synchronized (pool) {\n                pool.wait();\n            }\n        }\n        synchronized (pool) {\n            pool.add(i);\n            pool.notifyAll();\n        }\n    }\n}\n\n@AllArgsConstructor\nclass Consumer implements Runnable {\n    private final Vector<Integer> pool;\n\n    @Override\n    public void run() {\n        for (; ; ) {\n            try {\n                consume();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n\n    private void consume() throws InterruptedException {\n        synchronized (pool) {\n            while (pool.isEmpty()) {\n                pool.wait();\n            }\n        }\n        synchronized (pool) {\n            pool.remove(0);\n            pool.notifyAll();\n        }\n    }\n}\n```\n1. wait/notify的使用_**导致了较多的上下文切换**_\n2. 消费者第一次申请到锁，却发现没有内容可消费，执行**wait**，这会导致**线程挂起**，进入**阻塞状态**，这是一次上下文切换\n3. 当生产者获得锁并执行**notifyAll**之后，会**唤醒**处于阻塞状态的消费者线程，又会发生一次上下文切换\n4. 被唤醒的线程在继续运行时，需要再次申请相应对象的内部锁，此时可能需要与其他新来的活跃线程**竞争**，导致上下文切换\n5. 如果多个消费者线程同时被阻塞，用notifyAll将唤醒所有阻塞线程，但此时依然没有内容可消费\n    - 因此**过早地唤醒**，也可能导致线程再次进入阻塞状态，从而引起不必要的上下文切换\n6. 优化方法\n    - 可以考虑使**用notify代替notifyAll**，减少上下文切换\n    - 生产者执行完notify/notifyAll之后，**尽快释放内部锁**，避免被唤醒的线程再次等待该内部锁\n    - 为了避免长时间等待，使用wait(long)，但线程**无法区分**其返回是由于**等待超时**还是**被通知线程唤醒**，增加上下文切换\n    - 建议使用**Lock+Condition**代替synchronized+wait/notify/notifyAll，来实现等待通知\n\n## 合理的线程池大小\n1. _**线程池的线程数量不宜过大**_\n2. 一旦线程池的工作线程总数超过系统所拥有的**处理器数量**，就会导致**过多的上下文切换**\n\n## 协程：非阻塞等待\n1. 协程比线程更加**轻量**，相比于由**操作系统内核**管理的**进程**和**线程**，协程完全由程序本身所控制，即在**用户态**执行\n2. **协程避免了像线程切换那样产生的上下文切换**，在**性能**方面得到了**很大的提升**\n\n## 减少GC频率\n1. **GC会导致上下文切换**\n2. 很多垃圾回收器在回收旧对象时会产生内存碎片，从而需要进行内存整理，该过程需要移动存活的对象\n    - 而移动存活的对象意味着这些对象的内存地址会发生改变，因此在移动对象之前需要暂停线程，完成后再唤醒线程\n3. 因此减少GC的频率能够有效的减少上下文切换\n","tags":["Context Switch"],"categories":["Performance"]},{"title":"数据结构与算法 -- 递归","url":"%2F2019%2F08%2F24%2Fdata-structure-algorithm-recursive%2F","content":"\n## 递归三条件\n1. 一个问题的解可以分解成几个**子问题**（即数据规模更小的问题）的解\n2. 子问题与原问题，除了数据规模不同，**求解思路完全一样**\n3. 存在**递归终止条件**\n\n<!-- more -->\n\n## 编写递归代码\n1. 编写递归代码的关键：写出**递推公式** + 找到**终止条件**\n2. 样例：有n个台阶，每次可以跨1个或2个台阶，总共有几种走法？\n    - 根据第一步的走法分为两类，第一类第一步走了1个台阶，第二类第一步走了2个台阶\n    - **递推公式**：$f(n) = f(n-1) + f(n-2)$\n    - **终止条件**：$f(1) = 1, f(2) = 2$\n3. 对于递归代码，如果试图想弄清楚整个递和归的过程，会陷入一个**思维误区**\n    - 如果问题A可以分解为子问题B、C、D，假设子问题B、C、D**已经解决**，在此基础上思考如何解决问题A\n    - 只需要考虑问题A和子问题B、C、D**两层之间的关系**即可，无需一层一层往下思考子问题与子子问题的关系\n    - **屏蔽递归细节**，不要试图去分解递归的每个步骤\n\n```java\nint f(int n) {\n    if (n == 1) return 1;\n    if (n == 2) return 2;\n    return f(n-1) + f(n-2);\n}\n```\n\n## 警惕堆栈溢出\n1. 函数调用使用栈来保存临时变量，每调用一个函数，都会将临时变量封装为栈帧压入内存栈，等函数执行完成返回时才出栈\n2. 系统调用栈或虚拟机栈空间一般都不大，如果递归求解的数据规模很大，调用层次很深，一直压入栈，会有**堆栈溢出**的风险\n3. 解决方法：**限制递归调用的最大深度**\n    - 但不能完全解决问题，因为最大允许的递归深度与当前线程剩余的栈空间大小有关，**事先无法计算**\n    - 该方法仅适用于**最大深度较小**的情况\n\n## 警惕重复计算\n为了避免**重复计算**，可以通过一个数据结构（如**散列表**）来保存已经求解过的$f(k)$\n\n```java\nint f(int n) {\n    if (n == 1) return 1;\n    if (n == 2) return 2;\n    if (solvedMap.containsKey(n)) {\n        return solvedMap.get(n);\n    }\n    int ret = f(n-1) + f(n-2);\n    solvedMap.put(n, ret);\n    return ret;\n}\n```\n\n## 递归 / 非递归\n1. 递归有利有弊\n    - 利是递归代码的**表达力很强**，非常简洁\n    - 弊是**空间复杂度高**，有**堆栈溢出**的风险，存在**重复计算、过多的函数调用会耗时较多**的问题\n2. 递归代码都可以改成**迭代循环的非递归代码**\n    - 递归本身是借助**栈**来实现的，只是使用的栈是系统或虚拟机本身提供的\n    - 非递归代码：在内存堆上实现栈，手动模拟出栈和入栈的过程，**手动递归**，**本质并没有变**，反而**增加了实现的复杂度**\n","tags":["Algorithm"],"categories":["Data Structure & Algorithm"]},{"title":"网络编程 -- Socket + Address","url":"%2F2019%2F08%2F23%2Fnetwork-programming-socket-address%2F","content":"\n## Socket通信\n<img src=\"https://network-programming-1253868755.cos.ap-guangzhou.myqcloud.com/network-programming-socket.jpg\" width=1000/>\n\n<!-- more -->\n\n1. 在客户端发起连接请求之前，服务器端需要先完成**初始化**\n2. 服务器端初始化过程\n    - 初始化socket\n    - 然后执行**bind**函数，将服务器端的服务能力绑定到地址和端口上\n    - 然后执行**listen**函数，将原先的socket转换为服务器端socket\n    - 服务器端最后阻塞在**accept**上等待客户端请求的到来\n3. 客户端初始化socket，再执行**connect**向服务器端的地址和端口发起连接请求，即**TCP三次握手**\n4. 一旦TCP三次握手完成，客户端和服务器端建立连接，进入**数据传输**过程\n    - 客户端进程向操作系统内核发起**write**字节流写操作，内核协议栈将字节流通过网络设备传输到服务器端\n    - 服务器端从内核得到信息，将字节流从内核读入到进程中，并开始业务逻辑的处理\n    - 处理完之后，服务器端再将处理结果以同样的方式写给客户端\n    - 一旦连接建立，数据的传输是**双向**的\n5. 当客户端完成与服务器端的交互后，需要和服务器端断开连接时，会执行**close**函数\n    - 操作系统内核此时会通过原先的连接链路向服务器端发送一个**FIN**包，服务器端收到之后执行**被动关闭**\n    - 此时整个链路处于**半关闭状态**，此后，服务器端也会执行**close**函数，整个链路才会**真正关闭**\n    - 在**半关闭**状态下，发起close请求的一方在没有收到对方FIN包之前都认为连接是**正常**的\n    - 在**全关闭**状态下，双方都感知到连接已经关闭\n6. socket是**建立连接、传输数据**的**唯一途径**\n\n## Socket地址格式\n\n### 通用Socket地址格式\n```java\n/* POSIX.1g 规范规定了地址族为2字节的值. */\ntypedef unsigned short int sa_family_t;\n\n/* 描述通用套接字地址 */\nstruct sockaddr {\n    sa_family_t sa_family;  /* 地址族. 16-bit */\n    char sa_data[14];   /* 具体的地址值. 112-bit */\n};\n```\n1. 第一个字段为**地址族**，表示使用什么样的方式对地址进行解释和保存\n2. 常用地址族（AF：Address Family，PF：Protocol Family）\n    - **AF_LOCAL**\n        - **本地地址**，对应的是UNIX套接字，一般用于本地socket通信，很多情况下可以写成AF_UNIX、AF_FILE\n    - **AF_INET**\n        - IPv4地址\n    - **AF_INET6**\n        - IPv6地址\n\n### IPv4 Socket地址格式\n```java\n/* IPV4套接字地址，32bit值. */\ntypedef uint32_t in_addr_t;\nstruct in_addr {\n    in_addr_t s_addr;\n};\n\n/* 描述IPV4的套接字地址格式  */\nstruct sockaddr_in {\n    sa_family_t sin_family; /* 16-bit */\n    in_port_t sin_port;     /* 端口号 16-bit */\n    struct in_addr sin_addr;    /* Internet address. 32-bit */\n\n    /* 这里仅仅用作占位符，不做实际用处 */\n    unsigned char sin_zero[8];\n};\n```\n1. 与sockaddr一样，都有一个16bit的sin_family，对应于IPv4，该值为**AF_INET**\n2. 端口号最多为16bit，即65536，所以**支持寻址的端口号**最多为**65535**\n    - 5000以下有可能是**保留端口**\n3. 实际的IPv4是一个32bit的字段，最多支持的地址数为**42亿**\n\nglibc定义的保留端口\n```java\n/* Standard well-known ports.  */\nenum\n  {\n    IPPORT_ECHO = 7,\t\t/* Echo service.  */\n    IPPORT_DISCARD = 9,\t\t/* Discard transmissions service.  */\n    IPPORT_SYSTAT = 11,\t\t/* System status service.  */\n    IPPORT_DAYTIME = 13,\t/* Time of day service.  */\n    IPPORT_NETSTAT = 15,\t/* Network status service.  */\n    IPPORT_FTP = 21,\t\t/* File Transfer Protocol.  */\n    IPPORT_TELNET = 23,\t\t/* Telnet protocol.  */\n    IPPORT_SMTP = 25,\t\t/* Simple Mail Transfer Protocol.  */\n    IPPORT_TIMESERVER = 37,\t/* Timeserver service.  */\n    IPPORT_NAMESERVER = 42,\t/* Domain Name Service.  */\n    IPPORT_WHOIS = 43,\t\t/* Internet Whois service.  */\n    IPPORT_MTP = 57,\n\n    IPPORT_TFTP = 69,\t\t/* Trivial File Transfer Protocol.  */\n    IPPORT_RJE = 77,\n    IPPORT_FINGER = 79,\t\t/* Finger service.  */\n    IPPORT_TTYLINK = 87,\n    IPPORT_SUPDUP = 95,\t\t/* SUPDUP protocol.  */\n\n\n    IPPORT_EXECSERVER = 512,\t/* execd service.  */\n    IPPORT_LOGINSERVER = 513,\t/* rlogind service.  */\n    IPPORT_CMDSERVER = 514,\n    IPPORT_EFSSERVER = 520,\n\n    /* UDP ports.  */\n    IPPORT_BIFFUDP = 512,\n    IPPORT_WHOSERVER = 513,\n    IPPORT_ROUTESERVER = 520,\n\n    /* Ports less than this value are reserved for privileged processes.  */\n    IPPORT_RESERVED = 1024,\n\n    /* Ports greater this value are reserved for (non-privileged) servers.  */\n    IPPORT_USERRESERVED = 5000\n  };\n```\n\n### IPv6 Socket地址格式\n```java\nstruct sockaddr_in6 {\n    sa_family_t sin6_family; /* 16-bit */\n    in_port_t sin6_port;  /* 传输端口号 # 16-bit */\n    uint32_t sin6_flowinfo; /* IPv6流控信息 32-bit*/\n    struct in6_addr sin6_addr;  /* IPv6地址 128-bit */\n    uint32_t sin6_scope_id; /* IPv6域ID 32-bit */\n};\n```\n1. 先忽略sin6_flowinfo和sin6_scope_id，一个没在glibc的官网出现过，一个是当前未使用的字段\n2. sin6_family的值为**AF_INET6**，端口与IPv4一样，都是16bit，而sin6_addr为128bit，解决了**寻址数字不够**的问题\n\n### 本地Socket地址格式\n本地Socket主要用于**本地进程间的通信**\n```java\nstruct sockaddr_un {\n    unsigned short sun_family; /* 固定为 AF_LOCAL */\n    char sun_path[108];   /* 路径名 */\n};\n```\n\n### 对比\nIPv4 Socket和IPv6 Socket地址结构的长度是固定的，而本地Socket地址结构的长度是**可变**的\n<img src=\"https://network-programming-1253868755.cos.ap-guangzhou.myqcloud.com/network-programming-socket-address-vs.png\" width=1000/>\n","tags":["Socket"],"categories":["Programming"]},{"title":"Kafka -- 消费者组","url":"%2F2019%2F08%2F22%2Fkafka-consumer-group%2F","content":"\n## 消费者组\n1. 消费者组（Consumer Group）是Kafka提供的**可扩展**且具有**容错性**的**消费者机制**\n2. 一个消费者组内可以有多个消费者或消费者实例（进程/线程），它们共享一个**Group ID**（字符串）\n    - 组内的**所有消费者**协调在一起来消费订阅主题的**所有分区**\n    - 每个分区只能由同一个消费者组内的一个Consumer实例来消费，Consumer实例对分区有**所有权**\n\n<!-- more -->\n\n## 消息引擎模型\n1. 两种模型：**点对点模型**（消息队列）、**发布订阅模型**\n    - 点对点模型（传统的消息队列模型）\n        - 缺陷/特性：消息一旦被消费、就会从队列中被删除，而且只能被下游的一个Consumer消费\n        - **伸缩性很差**，下游的多个Consumer需要**抢占**共享消息队列中的消息\n    - 发布订阅模型\n        - 缺陷：**伸缩性不高**，每个订阅者都必须订阅主题的所有分区（**全量订阅**）\n2. **Consumer Group**\n    - 当Consumer Group订阅了多个主题之后\n    - 组内的每个Consumer实例不要求一定要订阅主题的所有分区，只会消费**部分分区**的消息\n    - Consumer Group之间**彼此独立**，互不影响，它们能够订阅相同主题而互不干涉\n    - Kafka使用Consumer Group机制实现了传统消息引擎系统的两种模型\n        - 如果所有Consumer实例都属于**同一个**Consumer Group，实现的是**点对点**模型\n        - 如果所有Consumer实例都属于**不同**的Consumer Group，实现的是**发布订阅**模型\n\n## Consumer实例数量\n1. 理想情况下，_**Consumer实例的数量 == 该Consumer Group订阅主题的分区总数**_\n2. 假设一个Consumer Group订阅了3个主题，分别为A（1分区）、B（2分区）、C（3分区），应该设置6个Consumer实例\n    - 如果只有3个实例，每个实例大约消费2个分区\n    - 如果有8个实例，有两个实例**不会被分配到任何分区**，永远处于**空闲状态**，**浪费资源**\n\n## 位移管理\n1. 位移可类比为`Map<TopicPartition, Long>`，TopicPartition代表一个分区，Long代表位移的类型\n2. 老版本的Consumer Group把**位移**保存在**Zookeeper**中\n    - Apache Zookeeper是一个**分布式的协调服务框架**，Kafka**重度依赖**ZK实现各种各样的协调管理\n    - 好处：减少Kafka Broker端的状态保存开销，**节点无状态**，可以自由扩缩容，实现**超强的伸缩性**\n    - 但ZK这类框架并**不适合进行频繁的写更新**，而Consumer Group的位移更新却是一个非常频繁的操作\n        - _**大吞吐量的写操作会极大地拖慢ZK集群的性能**_\n    - 因此，将Consumer位移保存在ZK中是不合适的做法\n3. 在新版本的Consumer Group中，重新设计了Consumer Group的**位移管理方式**（内部主题：**`__consumer_offsets`**）\n\n## 重平衡\n1. Rebalance本质上是一种**协议**，规定了一个Consumer Group下所有的Consumer如何达成一致来**分配分区**\n2. Rebalance的触发条件\n    - 组内**消费者数**发生变更\n    - 订阅**主题数**发生变更\n        - Consumer Group可以使用**正则表达式**的方式订阅主题\n    - 订阅主题的**分区数**发生变更\n        - Kafka当前**只允许增加**一个主题的分区数\n3. Rebalance发生时，Group下**所有的Consumer实例**都会协调在一起共同参与\n    - Kafka尽量保证提供**最公平**的分配策略，即每个Consumer实例能够得到较为平均的分区数\n4. 缺陷\n    - Rebalance过程**对Consumer Group消费过程有极大的影响**\n        - 在Rebalance过程中，所有Consumer实例都会**停止消费**，等待Rebalance完成\n    - **所有Consumer实例共同参与，全部重新分配所有分区**\n        - 更高效的分配方案：**尽量少改动**，这样可以**复用**已经建立的**TCP连接**\n    - Rebalance的过程可能会**持续很久**\n","tags":["Consumer Group"],"categories":["Kafka"]},{"title":"Spring -- MyBatis","url":"%2F2019%2F08%2F21%2Fspring-mybatis%2F","content":"\n## 概述\n1. MyBatis是一款优秀的持久层框架\n2. MyBatis支持_**定制化SQL、存储过程和高级映射**_\n3. JPA Or MyBatis\n    - JPA：数据操作都比较简单\n    - MyBatis：DBA需要对SQL进行审核，复杂SQL\n4. Spring + MyBatis\n    - MyBatis Spring Adapter\n    - MyBatis Spring-Boot-Starter\n\n<!-- more -->\n\n## 简单使用\n\n### pom.xml\n```xml\n<dependency>\n    <groupId>org.mybatis.spring.boot</groupId>\n    <artifactId>mybatis-spring-boot-starter</artifactId>\n    <version>1.3.2</version>\n</dependency>\n<dependency>\n    <groupId>org.joda</groupId>\n    <artifactId>joda-money</artifactId>\n    <version>LATEST</version>\n</dependency>\n<dependency>\n    <groupId>com.h2database</groupId>\n    <artifactId>h2</artifactId>\n    <scope>runtime</scope>\n</dependency>\n```\n\n### schema.sql\n```sql\ncreate table t_coffee (\n    id bigint not null auto_increment,\n    name varchar(255),\n    price bigint not null,\n    create_time timestamp,\n    update_time timestamp,\n    primary key (id)\n);\n```\n\n### application.properties\n```\nmybatis.type-handlers-package=me.zhongmingmao.mybatis.handler\nmybatis.configuration.map-underscore-to-camel-case=true\n```\n\n### Coffee\n```java\n@Data\n@Builder\n@NoArgsConstructor\n@AllArgsConstructor\npublic class Coffee {\n    private Long id;\n    private String name;\n    private Money price;\n    private Date createTime;\n    private Date updateTime;\n}\n```\n\n### MoneyTypeHandler\n```java\npackage me.zhongmingmao.mybatis.handler;\n\n/**\n * 在 Money 与 Long 之间转换的 TypeHandler，处理 CNY 人民币\n */\npublic class MoneyTypeHandler extends BaseTypeHandler<Money> {\n    @Override\n    public void setNonNullParameter(PreparedStatement ps, int i, Money parameter, JdbcType jdbcType) throws SQLException {\n        ps.setLong(i, parameter.getAmountMinorLong());\n    }\n\n    @Override\n    public Money getNullableResult(ResultSet rs, String columnName) throws SQLException {\n        return parseMoney(rs.getLong(columnName));\n    }\n\n    @Override\n    public Money getNullableResult(ResultSet rs, int columnIndex) throws SQLException {\n        return parseMoney(rs.getLong(columnIndex));\n    }\n\n    @Override\n    public Money getNullableResult(CallableStatement cs, int columnIndex) throws SQLException {\n        return parseMoney(cs.getLong(columnIndex));\n    }\n\n    private Money parseMoney(Long value) {\n        // return Money.ofMinor(CurrencyUnit.of(\"CNY\"), value);\n        return Money.of(CurrencyUnit.of(\"CNY\"), value / 100.0);\n    }\n}\n```\n\n### CoffeeMapper\n```java\npackage me.zhongmingmao.mybatis.mapper;\n\n@Mapper\npublic interface CoffeeMapper {\n\n    @Insert(\"insert into t_coffee (name, price, create_time, update_time) values (#{name}, #{price}, now(), now())\")\n    @Options(useGeneratedKeys = true)\n    int save(Coffee coffee);\n\n    @Select(\"select * from t_coffee where id = #{id}\")\n    @Results({\n            @Result(id = true, column = \"id\", property = \"id\"),\n            @Result(column = \"create_time\", property = \"createTime\"),\n            // map-underscore-to-camel-case = true 可以实现一样的效果\n            // @Result(column = \"update_time\", property = \"updateTime\"),\n    })\n    Coffee findById(@Param(\"id\") Long id);\n}\n```\n\n### 主程序\n```java\n@Slf4j\n@MapperScan(\"me.zhongmingmao.mybatis.mapper\")\n@SpringBootApplication\npublic class MybatisApplication implements ApplicationRunner {\n\n    @Autowired\n    private CoffeeMapper coffeeMapper;\n\n    public static void main(String[] args) {\n        SpringApplication.run(MybatisApplication.class, args);\n    }\n\n    @Override\n    public void run(ApplicationArguments args) throws Exception {\n        Coffee coffee = Coffee.builder().name(\"espresso\").price(Money.of(CurrencyUnit.of(\"CNY\"), 20.0)).build();\n        int count = coffeeMapper.save(coffee);\n        log.info(\"Save {} Coffee: {}\", count, coffee);\n\n        coffee = Coffee.builder().name(\"latte\").price(Money.of(CurrencyUnit.of(\"CNY\"), 25.0)).build();\n        count = coffeeMapper.save(coffee);\n        log.info(\"Save {} Coffee: {}\", count, coffee);\n\n        coffee = coffeeMapper.findById(coffee.getId());\n        log.info(\"Find Coffee: {}\", coffee);\n    }\n}\n```\n```\nSave 1 Coffee: Coffee(id=1, name=espresso, price=CNY 20.00, createTime=null, updateTime=null)\nSave 1 Coffee: Coffee(id=2, name=latte, price=CNY 25.00, createTime=null, updateTime=null)\nFind Coffee: Coffee(id=2, name=latte, price=CNY 25.00, createTime=Sun Sep 15 13:50:32 CST 2019, updateTime=Sun Sep 15 13:50:32 CST 2019)\n```\n\n## MyBatis Generator\n1. MyBatis代码生成器\n2. 根据**数据表**来生成相关代码\n    - POJO\n    - Mapper接口\n    - SQL Map XML\n\n### pom.xml\n```xml\n<dependency>\n    <groupId>org.mybatis.spring.boot</groupId>\n    <artifactId>mybatis-spring-boot-starter</artifactId>\n    <version>2.1.0</version>\n</dependency>\n<dependency>\n    <groupId>org.mybatis.generator</groupId>\n    <artifactId>mybatis-generator-core</artifactId>\n    <version>1.3.7</version>\n</dependency>\n<dependency>\n    <groupId>org.joda</groupId>\n    <artifactId>joda-money</artifactId>\n    <version>LATEST</version>\n</dependency>\n<dependency>\n    <groupId>com.h2database</groupId>\n    <artifactId>h2</artifactId>\n    <scope>runtime</scope>\n</dependency>\n```\n\n### generatorConfig.xml\n```xml\n<generatorConfiguration>\n    <context id=\"H2Tables\" targetRuntime=\"MyBatis3\">\n        <plugin type=\"org.mybatis.generator.plugins.FluentBuilderMethodsPlugin\"/>\n        <plugin type=\"org.mybatis.generator.plugins.ToStringPlugin\"/>\n        <plugin type=\"org.mybatis.generator.plugins.SerializablePlugin\"/>\n        <plugin type=\"org.mybatis.generator.plugins.RowBoundsPlugin\"/>\n\n        <jdbcConnection driverClass=\"org.h2.Driver\"\n                        connectionURL=\"jdbc:h2:mem:testdb\"\n                        userId=\"sa\"\n                        password=\"\">\n        </jdbcConnection>\n\n        <javaModelGenerator targetPackage=\"me.zhongmingmao.mybatis.generator.model\"\n                            targetProject=\"./src/main/java\">\n            <property name=\"enableSubPackages\" value=\"true\"/>\n            <property name=\"trimStrings\" value=\"true\"/>\n        </javaModelGenerator>\n\n        <sqlMapGenerator targetPackage=\"me.zhongmingmao.mybatis.generator.mapper\"\n                         targetProject=\"./src/main/resources/mapper\">\n            <property name=\"enableSubPackages\" value=\"true\"/>\n        </sqlMapGenerator>\n\n        <!-- 混合模式 -->\n        <javaClientGenerator type=\"MIXEDMAPPER\"\n                             targetPackage=\"me.zhongmingmao.mybatis.generator.mapper\"\n                             targetProject=\"./src/main/java\">\n            <property name=\"enableSubPackages\" value=\"true\"/>\n        </javaClientGenerator>\n\n        <table tableName=\"t_coffee\" domainObjectName=\"Coffee\">\n            <generatedKey column=\"id\" sqlStatement=\"CALL IDENTITY()\" identity=\"true\"/>\n            <columnOverride column=\"price\" javaType=\"org.joda.money.Money\" jdbcType=\"BIGINT\"\n                            typeHandler=\"me.zhongmingmao.mybatis.generator.handler.MoneyTypeHandler\"/>\n        </table>\n    </context>\n</generatorConfiguration>\n```\n\n### 目录结构\n```\nsrc/main\n├── java\n│   └── me\n│       └── zhongmingmao\n│           └── mybatis\n│               └── generator\n│                   ├── MybatisGeneratorApplication.java\n│                   └── handler\n│                       └── MoneyTypeHandler.java\n└── resources\n    ├── application.properties\n    ├── generatorConfig.xml\n    ├── mapper\n    └── schema.sql\n\n```\n\n### 生成MyBatis样板代码\n```java\nList<String> warnings = new ArrayList<>();\nConfigurationParser cp = new ConfigurationParser(warnings);\nConfiguration config = cp.parseConfiguration(getClass().getResourceAsStream(\"/generatorConfig.xml\"));\nDefaultShellCallback callback = new DefaultShellCallback(true);\nMyBatisGenerator myBatisGenerator = new MyBatisGenerator(config, callback, warnings);\nmyBatisGenerator.generate(null);\n```\n\n### 目录结构\n```\nsrc/main\n├── java\n│   └── me\n│       └── zhongmingmao\n│           └── mybatis\n│               └── generator\n│                   ├── MybatisGeneratorApplication.java\n│                   ├── handler\n│                   │   └── MoneyTypeHandler.java\n│                   ├── mapper\n│                   │   └── CoffeeMapper.java\n│                   └── model\n│                       ├── Coffee.java\n│                       └── CoffeeExample.java\n└── resources\n    ├── application.properties\n    ├── generatorConfig.xml\n    ├── mapper\n    │   └── me\n    │       └── zhongmingmao\n    │           └── mybatis\n    │               └── generator\n    │                   └── mapper\n    │                       └── CoffeeMapper.xml\n    └── schema.sql\n```\n\n### application.properties\n```\nmybatis.mapper-locations=classpath*:/mapper/**/*.xml\nmybatis.type-aliases-package=me.zhongmingmao.mybatis.generator.model\nmybatis.type-handlers-package=me.zhongmingmao.mybatis.generator.handler\nmybatis.configuration.map-underscore-to-camel-case=true\n```\n\n### 主程序\n```java\nCoffee espresso = new Coffee()\n        .withName(\"espresso\")\n        .withPrice(Money.of(CurrencyUnit.of(\"CNY\"), 20.0))\n        .withCreateTime(new Date())\n        .withUpdateTime(new Date());\ncoffeeMapper.insert(espresso);\n\nCoffee latte = new Coffee()\n        .withName(\"latte\")\n        .withPrice(Money.of(CurrencyUnit.of(\"CNY\"), 30.0))\n        .withCreateTime(new Date())\n        .withUpdateTime(new Date());\ncoffeeMapper.insert(latte);\n\n// 简单查询\nCoffee s = coffeeMapper.selectByPrimaryKey(1L);\nlog.info(\"Coffee {}\", s);\n\n// 复杂查询\nCoffeeExample example = new CoffeeExample();\nexample.createCriteria().andNameEqualTo(\"latte\");\nexample.setOrderByClause(\"id desc\");\nList<Coffee> list = coffeeMapper.selectByExample(example);\nlist.forEach(e -> log.info(\"selectByExample: {}\", e));\n```\n```\nCoffee Coffee [Hash = 981159997, id=1, name=espresso, price=CNY 20.00, createTime=Sun Sep 15 15:32:52 CST 2019, updateTime=Sun Sep 15 15:32:52 CST 2019]\nselectByExample: Coffee [Hash = 653345773, id=2, name=latte, price=CNY 30.00, createTime=Sun Sep 15 15:32:52 CST 2019, updateTime=Sun Sep 15 15:32:52 CST 2019]\n```\n\n## MyBatis PageHelper\n1. 支持多种数据库\n2. 支持多种分页方式\n3. SpringBoot支持（pagehelper-spring-boot-starter）\n\n### pom.xml\n```xml\n<dependency>\n    <groupId>org.mybatis.spring.boot</groupId>\n    <artifactId>mybatis-spring-boot-starter</artifactId>\n    <version>2.1.0</version>\n</dependency>\n<dependency>\n    <groupId>com.github.pagehelper</groupId>\n    <artifactId>pagehelper-spring-boot-starter</artifactId>\n    <version>1.2.12</version>\n</dependency>\n<dependency>\n    <groupId>org.joda</groupId>\n    <artifactId>joda-money</artifactId>\n    <version>LATEST</version>\n</dependency>\n<dependency>\n    <groupId>com.h2database</groupId>\n    <artifactId>h2</artifactId>\n    <scope>runtime</scope>\n</dependency>\n```\n\n### data.sql\n```sql\ninsert into t_coffee (name, price, create_time, update_time) values ('espresso', 2000, now(), now());\ninsert into t_coffee (name, price, create_time, update_time) values ('latte', 2500, now(), now());\ninsert into t_coffee (name, price, create_time, update_time) values ('capuccino', 2500, now(), now());\ninsert into t_coffee (name, price, create_time, update_time) values ('mocha', 3000, now(), now());\ninsert into t_coffee (name, price, create_time, update_time) values ('macchiato', 3000, now(), now());\n```\n\n### CoffeeMapper\n```java\n@Mapper\npublic interface CoffeeMapper {\n\n    @Select(\"select * from t_coffee order by id\")\n    List<Coffee> findAllWithRowBounds(RowBounds rowBounds);\n\n    @Select(\"select * from t_coffee order by id\")\n    List<Coffee> findAllWithParam(@Param(\"pageNum\") int pageNum, @Param(\"pageSize\") int pageSize);\n}\n```\n\n### application.properties\n```\n# mybatis\nmybatis.type-handlers-package=me.zhongmingmao.mybatis.pagehelper.handler\nmybatis.configuration.map-underscore-to-camel-case=true\n# pagehelper\npagehelper.offset-as-page-num=true\npagehelper.reasonable=true\npagehelper.page-size-zero=true\npagehelper.support-methods-arguments=true\n```\n\n### 主程序\n```java\ncoffeeMapper.findAllWithRowBounds(new RowBounds(1, 3))\n        .forEach(coffee -> log.info(\"Page(1) Coffee {}\", coffee));\ncoffeeMapper.findAllWithRowBounds(new RowBounds(2, 3))\n        .forEach(coffee -> log.info(\"Page(2) Coffee {}\", coffee));\n\nlog.info(\"==============\");\n\n// 获取所有记录\ncoffeeMapper.findAllWithRowBounds(new RowBounds(1, 0))\n        .forEach(coffee -> log.info(\"Page(1) Coffee {}\", coffee));\n\ncoffeeMapper.findAllWithParam(1, 3)\n        .forEach(coffee -> log.info(\"Page(1) Coffee {}\", coffee));\nList<Coffee> list = coffeeMapper.findAllWithParam(2, 3);\nPageInfo<Coffee> pageInfo = new PageInfo<>(list);\nlog.info(\"PageInfo: {}\", pageInfo);\n```\n```\nPage(1) Coffee Coffee(id=1, name=espresso, price=CNY 20.00, createTime=Sun Sep 15 16:12:50 CST 2019, updateTime=Sun Sep 15 16:12:50 CST 2019)\nPage(1) Coffee Coffee(id=2, name=latte, price=CNY 25.00, createTime=Sun Sep 15 16:12:50 CST 2019, updateTime=Sun Sep 15 16:12:50 CST 2019)\nPage(1) Coffee Coffee(id=3, name=capuccino, price=CNY 25.00, createTime=Sun Sep 15 16:12:50 CST 2019, updateTime=Sun Sep 15 16:12:50 CST 2019)\nPage(2) Coffee Coffee(id=4, name=mocha, price=CNY 30.00, createTime=Sun Sep 15 16:12:50 CST 2019, updateTime=Sun Sep 15 16:12:50 CST 2019)\nPage(2) Coffee Coffee(id=5, name=macchiato, price=CNY 30.00, createTime=Sun Sep 15 16:12:50 CST 2019, updateTime=Sun Sep 15 16:12:50 CST 2019)\n==============\nPage(1) Coffee Coffee(id=1, name=espresso, price=CNY 20.00, createTime=Sun Sep 15 16:12:50 CST 2019, updateTime=Sun Sep 15 16:12:50 CST 2019)\nPage(1) Coffee Coffee(id=2, name=latte, price=CNY 25.00, createTime=Sun Sep 15 16:12:50 CST 2019, updateTime=Sun Sep 15 16:12:50 CST 2019)\nPage(1) Coffee Coffee(id=3, name=capuccino, price=CNY 25.00, createTime=Sun Sep 15 16:12:50 CST 2019, updateTime=Sun Sep 15 16:12:50 CST 2019)\nPage(1) Coffee Coffee(id=4, name=mocha, price=CNY 30.00, createTime=Sun Sep 15 16:12:50 CST 2019, updateTime=Sun Sep 15 16:12:50 CST 2019)\nPage(1) Coffee Coffee(id=5, name=macchiato, price=CNY 30.00, createTime=Sun Sep 15 16:12:50 CST 2019, updateTime=Sun Sep 15 16:12:50 CST 2019)\nPage(1) Coffee Coffee(id=1, name=espresso, price=CNY 20.00, createTime=Sun Sep 15 16:12:50 CST 2019, updateTime=Sun Sep 15 16:12:50 CST 2019)\nPage(1) Coffee Coffee(id=2, name=latte, price=CNY 25.00, createTime=Sun Sep 15 16:12:50 CST 2019, updateTime=Sun Sep 15 16:12:50 CST 2019)\nPage(1) Coffee Coffee(id=3, name=capuccino, price=CNY 25.00, createTime=Sun Sep 15 16:12:50 CST 2019, updateTime=Sun Sep 15 16:12:50 CST 2019)\nPageInfo: PageInfo{pageNum=2, pageSize=3, size=2, startRow=4, endRow=5, total=5, pages=2, list=Page{count=true, pageNum=2, pageSize=3, startRow=3, endRow=6, total=5, pages=2, reasonable=true, pageSizeZero=true}[Coffee(id=4, name=mocha, price=CNY 30.00, createTime=Sun Sep 15 16:12:50 CST 2019, updateTime=Sun Sep 15 16:12:50 CST 2019), Coffee(id=5, name=macchiato, price=CNY 30.00, createTime=Sun Sep 15 16:12:50 CST 2019, updateTime=Sun Sep 15 16:12:50 CST 2019)], prePage=1, nextPage=0, isFirstPage=false, isLastPage=true, hasPreviousPage=true, hasNextPage=false, navigatePages=8, navigateFirstPage=1, navigateLastPage=2, navigatepageNums=[1, 2]}\n\n```\n","tags":["MyBatis"],"categories":["Spring Boot"]},{"title":"Java性能 --  CAS乐观锁","url":"%2F2019%2F08%2F20%2Fjava-performance-cas%2F","content":"\n## synchronized / Lock / CAS\n1. synchronized和Lock实现的同步锁机制，都属于**悲观锁**，而**CAS**属于_**乐观锁**_\n2. 悲观锁在**高并发**的场景下，激烈的锁竞争会造成**线程阻塞**，而大量阻塞线程会导致系统的**上下文切换**，增加系统的**性能开销**\n\n<!-- more -->\n\n## 乐观锁\n1. 乐观锁：在操作共享资源时，总是抱着乐观的态度进行，认为自己能够完成操作\n2. 但实际上，当多个线程同时操作一个共享资源时，只有一个线程会成功，**失败的线程不会被挂起**，仅仅只是返回\n3. 乐观锁相比于悲观锁来说，不会带来**死锁、饥饿**等活性故障问题，线程间的相互影响也远远比悲观锁要小\n    - 乐观锁**没有因竞争而造成的系统上下文切换**，所以在性能上更胜一筹\n\n## 实现原理\n1. CAS是实现乐观锁的核心算法，包含3个参数：V（需要更新的变量），E（预期值）、N（最新值）\n2. 只有V等于E时，V才会被设置为N\n3. 如果V不等于E了，说明其它线程已经更新了V，此时该线程不做操作，返回V的真实值\n\n### CAS实现原子操作\nAtomicInteger是基于CAS实现的一个线程安全的整型类，Unsafe调用CPU底层指令实现原子操作\n```java\n// java.util.concurrent.atomic.AtomicInteger\npublic final int getAndIncrement() {\n    return unsafe.getAndAddInt(this, valueOffset, 1);\n}\n\npublic final int getAndDecrement() {\n    return unsafe.getAndAddInt(this, valueOffset, -1);\n}\n```\n```java\n// sun.misc.Unsafe\npublic final int getAndAddInt(Object o, long offset, int delta) {\n    int v;\n    do {\n        v = getIntVolatile(o, offset);\n    } while (!compareAndSwapInt(o, offset, v, v + delta));\n    return v;\n}\n\npublic native int     getIntVolatile(Object o, long offset);\n\npublic final native boolean compareAndSwapInt(Object o, long offset, int expected, int x);\n```\n\n### 处理器实现原子操作\n1. CAS是调用**处理器底层指令**来实现原子操作的\n2. 处理器和物理内存之间的通信速度要远低于处理器间的处理速度，所以处理器有自己的**内部缓存**（L1/L2/L3）\n3. 服务器通常为多处理器，并且处理器是多核的，每个处理器维护了一块字节的缓存存，每个内核也维护了一块字节的缓存\n    - 此时在多线程并发就会存在**缓存不一致**的问题，从而导致**数据不一致**\n4. 处理器提供了**总线锁定**和**缓存锁定**两种机制来保证**复杂内存操作的原子性**\n    - 总线锁定\n        - 当处理器要操作一个**共享变量**时，会在**总线**上会发出一个**Lock信号**，此时其它处理器就不能操作共享变量了\n        - 总线锁定在阻塞其他处理器获取该共享变量的操作请求时，也可能会导致**大量阻塞**，从而**增加系统的性能开销**\n    - 缓存锁定（后来出现）\n        - 当某个处理器对**缓存**中的共享变量进行了操作，就会**通知**其他处理器**放弃存储**或者**重新读取**该共享变量\n        - 目前**最新的处理器**都支持缓存锁定机制\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-cas-cpu-cache.png\" width=800/>\n\n## 优化CAS乐观锁\n1. 乐观锁在**并发性能**上要优于悲观锁\n    - 但在**写大于读**的操作场景下，**CAS失败的可能性增大**，如果循环CAS，会**长时间占用CPU**\n    - 例如上面的AtomicInteger#getAndIncrement\n2. JDK 1.8中，提供了新的原子类**LongAdder**\n    - LongAdder在**高并发**场景下会**比AtomicInteger和AtomicLong的性能更好**，代价是消耗**更多的内存空间**\n        - 核心思想：_**空间换时间**_\n        - 实现原理：**降低操作共享变量的并发数**\n    - LongAdder内部由一个**base变量**和一个**cell[]数组**组成\n        - 当只有一个写线程（**没有竞争**）\n            - LongAdder会直接使用base变量作为原子操作变量，通过CAS操作修改base变量\n        - 当有多个写线程（**存在竞争**）\n            - 除了占用base变量的一个写线程外，其他写线程的value值会分散到cell数组中\n            - 不同线程会命中到数组的不同槽中，各个线程只对自己槽中的value进行CAS操作\n            - $value = base + \\sum_{i=0}^n Cell[i]$\n    - LongAdder在操作后的返回值只是一个**近似准确**的值，但最终返回的是一个准确的值\n        - **LongAdder不适合实时性要求较高的场景**\n\n## 性能对比\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-cas-benchmark.jpg\" width=1000/>\n\n1. **读大于写**，读写锁ReentrantReadWriteLock、读写锁StampedLock、乐观锁LongAdder的性能最好\n2. **写大于读**，乐观锁的性能最好，其他四种锁的性能差不多\n3. **读约等于写**，两种读写锁和乐观锁的性能要优于synchronized和Lock\n\n## 小结\n1. 乐观锁的常见使用场景：**数据库更新**\n    - 为每条数据定义一个版本号，在更新前获取版本号，在更新数据时，再判断版本号是否被更新过，如果没有才更新数据\n2. CAS乐观锁的使用比较**受限**，因为乐观锁_**只能保证单个变量操作的原子性**_\n3. CAS乐观锁在**高并发写大于读**的场景下\n    - 大部分线程的原子操作会失败，失败后的线程将不断重试CAS原子操作，导致**大量线程长时间占用CPU资源**\n    - JDK 1.8中，新增了原子类**LongAdder**，采用**空间换时间**的思路解决了这个问题，但**实时性不高**\n","tags":["CAS"],"categories":["Performance"]},{"title":"Kafka -- 幂等性生产者 + 事务生产者","url":"%2F2019%2F08%2F19%2Fkafka-producer-idempotence-transaction%2F","content":"\n## 消息交付可靠性保障\n1. 消息交付可靠性保障：Kafka对Producer和Consumer要处理的消息所提供的承诺\n2. 常见的承诺\n    - 最多一次（at most once）：消息可能会丢失，但绝不会被重复发送\n    - **至少一次**（at least once）：消息不会丢失，但有可能被重复发送\n    - 精确一次（exactly once）：消息不会丢失，也不会被重复发送\n3. Kafka默认提供的交付可靠性保障：_**至少一次**_\n    - 只有Broker成功**提交**消息且Producer接到Broker的应答才会认为该消息成功发送\n    - 如果Broker成功提交消息，但Broker的应答没有成功送回Producer端，Producer只能选择**重试**\n4. 最多一次\n    - Kafka也可以提供**最多一次**交付可靠性保证，只需要让**Producer禁止重试**即可，但大部分场景下并不希望出现消息丢失\n5. **精确一次**\n    - 消息不会丢失，也不会被重复处理，即使Producer端重复发送了相同的消息，Broker端也能自动去重\n    - 两种机制：**幂等性**、**事务**\n\n<!-- more -->\n\n## 幂等性\n1. 幂等原是数学中的概念：某些操作或者函数能够被执行多次，但每次得到的结果都是**不变**的\n    - 幂等操作：乘1，取整函数；非幂等操作：加1\n2. 计算机领域\n    - 在**命令式**编程语言（如C）中，如果一个子程序是幂等的，那它必然**不能修改系统状态**\n    - 在**函数式**编程语言（如Scala、Haskell）中，很多**纯函数**天然就是幂等的，不执行任何的Side Effect\n3. 幂等性的好处：可以**安全地重试**任何幂等性操作\n\n## 幂等性Producer\n1. 在Kafka中，**Producer默认不是幂等的**，在**0.11.0.0**版本引入了幂等性Producer\n2. **默认情况下**，Producer向Broker发送数据时，可能会出现同一条消息被发送多次，导致**消息重复**\n3. 升级为幂等性Producer\n    - `props.put(\"enable.idempotence\", true)`或\n    - `props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true)`\n4. 基本原理\n    - **空间换时间**，在Broker端多保存一些字段\n    - 当Producer发送了具有相同字段值的消息后，Broker能够自动发现这些重复消息，然后默默**丢弃**\n5. **作用范围**\n    - 幂等性Producer只能保证**单分区**上的幂等性\n        - 即只能保证某个主题上的一个分区上不出现重复消息，无法实现多个分区的幂等性\n    - 幂等性Producer只能实现**单会话**上的幂等性，不能实现跨会话的幂等性\n        - 会话：**Producer进程的一次运行**，如果重启Producer进程，将丢失幂等性保证\n    - 如果要实现**多分区**或者**多会话**的消息无重复，可以采用**事务Producer**\n\n## 事务\n1. 数据库事务提供了**ACID**的安全性保障：**Atomicity**、**Consistency**、**Isolation**、**Durability**\n2. Kafka在**0.11**版本开始提供了对事务的支持，目前主要在**Read Committed**的隔离级别上做事情\n    - 保证**多条消息原子性地写入目标分区**，同时也保证**Consumer只能看到事务成功提交的消息**\n\n## 事务Producer\n1. 事务Producer能够保证**一批消息原子性地写入多个分区**，这批消息要么**全部写入成功**，要么**全部写入失败**\n2. **事务Producer允许进程重启**，Producer重启后，Kafka依然保证它们发送的消息的**精确一次**处理\n3. 升级为事务Producer\n    - `props.put(\"enable.idempotence\", true)`\n    - `props.put(\"transactional.id\", \"my-transactional-id\")`\n4. record1和record2会被当作一个事务统一提交到Kafka，要么全部提交成功，要么全部写入失败\n5. 即使写入失败，Kafka也会把它们写入到**底层日志**中，即Consumer还是会看到这些消息\n6. 因此在Consumer端，读取事务Producer发送的消息，需要设置**isolation.level**参数\n    - **read_uncommitted**\n        - 默认值，Consumer能够读取到Kafka写入的**任何消息**，不论事务Producer提交事务还是终止事务\n    - **read_committed**\n        - Consumer只会读取到**事务Producer成功提交事务写入的消息**，也能读取到**非事务Producer写入的所有消息**\n\n```java\nproducer.initTransactions();\ntry {\n    producer.beginTransaction();\n    producer.send(new ProducerRecord<>(TOPIC, KEY, VALUE + 1));\n    producer.send(new ProducerRecord<>(TOPIC, KEY, VALUE + 2));\n    //\n    producer.commitTransaction();\n} catch (KafkaException e) {\n    producer.abortTransaction();\n}\n```\n\n## 小结\n1. 幂等性Producer和事务Producer都是Kafka社区为了实现**精确一次**处理语义所提供的工具，只是**作用范围**不同而已\n2. 幂等性Producer只能保证**单分区、单会话**上的消息幂等性；而事务Producer能够保证**跨分区、跨会话**的幂等性\n3. 事务Producer与幂等性Producer相比，**性能更差**\n","tags":["Idempotence"],"categories":["Kafka"]},{"title":"Java性能 -- Lock优化","url":"%2F2019%2F08%2F18%2Fjava-performance-lock-opt%2F","content":"\n## Lock / synchronized\nLock锁的基本操作是通过**乐观锁**实现的，由于Lock锁也会在**阻塞**时被**挂起**，依然属于**悲观锁**\n\n| | synchronized | Lock |\n| --- | --- | --- |\n| 实现方式 | JVM层实现 | Java底层代码实现 |\n| 锁的获取 | JVM隐式获取 | lock() / tryLock() / tryLock(timeout, unit) / lockInterruptibly() |\n| 锁的释放 | JVM隐式释放 | unlock() |\n| 锁的类型 | 非公平锁、可重入 | 非公平锁/公平锁、可重入 |\n| 锁的状态 | 不可中断 | 可中断 |\n| 锁的性能 | 高并发下会升级为**重量级锁** | **更稳定** |\n\n<!-- more -->\n\n## 实现原理\n1. Lock锁是基于Java实现的锁，Lock是一个接口\n    - 常见的实现类：**ReentrantLock、ReentrantReadWriteLock**，都是依赖**AbstractQueuedSynchronizer**（AQS）实现\n2. AQS中包含了一个**基于链表实现的等待队列**（即**CLH**队列），用于存储所有**阻塞的线程**\n3. AQS中有一个**state**变量，该变量对ReentrantLock来说表示**加锁状态**\n4. AQS中的**CLH**队列的所有操作均通过**CAS**操作实现的\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-lock-aqs-clh-cas.jpg\" width=600/>\n\n## 锁分离优化\n\n### ReentrantReadWriteLock\n1. ReentrantLock是一个**独占锁**，同一时间只允许一个线程访问\n2. ReentrantReadWriteLock允许多个读线程同时访问，但不允许写线程和读线程、写线程和写线程同时访问\n    - ReentrantReadWriteLock内部维护了两把锁，一把用于读操作的**ReadLock**，一把用于写操作的**WriteLock**\n3. ReentrantReadWriteLock如何保证**共享资源的原子性**？ReentrantReadWriteLock也是基于**AQS**实现的\n    - 自定义同步器（继承AQS）需要在**同步状态state**上维护**多个读线程**和**一个写线程**的状态\n    - ReentrantReadWriteLock利用了**高低位**，来实现**一个整型控制两种状态**的功能\n        - 将**同步状态state**切分为两部分，**高16位表示读**，**低16位表示写**\n\n#### 获取写锁\n1. 一个线程尝试获取**写锁**时，会先判断同步状态state是否为0\n    - 如果state为0，说明暂时没有其他线程获取锁\n    - 如果state不为0，说明其它线程获取了锁\n3. 当state不为0时，会再去判断同步状态state的低16位（**w**）是否为0\n    - 如果w为0，说明其它线程获取了**读锁**，此时直接进入**CLH**队列进行**阻塞等待**（因为读锁与写锁**互斥**）\n    - 如果w不为0，说明有线程获取了**写锁**，此时要判断是不是**当前线程**获取了写锁\n        - 如果不是，进入**CLH**队列进行**阻塞等待**\n        - 如果是，就应该判断当前线程获取写锁是否超过最大次数，如果超过，抛出异常，否则更新同步状态state\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-lock-rrw-w.jpg\" width=600/>\n\n#### 获取读锁\n1. 一个线程尝试获取**读锁**时，同样会先判断同步状态state是否为0\n    - 如果state为0，说明暂时没有其他线程获取锁，此时需要判断是否需要**阻塞**\n        - 如果需要阻塞，则进入**CLH**队列进行阻塞等待\n        - 如果不需要阻塞，则CAS更新state为**读状态**\n    - 如果state不为0，说明其它线程获取了锁\n2. 当state不为0时，会同步判断同步状态state的低16位\n    - 如果存在**写锁**，直接进入**CLH**阻塞队列\n    - 反之，判断当前线程是否应该被阻塞，如果不应该被阻塞则尝试CAS同步状态，获取成功更新同步锁为读状态\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-lock-rrw-r.jpg\" width=600/>\n\n### StampedLock\n1. ReentrantReadWriteLock被很好地应用在**读多写少**的并发场景中，但会存在**写线程饥饿**的问题\n    - Java 8引入**StampedLock**解决了这个问题\n2. **StampedLock不是基于AQS实现的**，但实现原理与AQS类似，都是基于**队列**和**锁状态**\n3. StampedLock有三种模式：**写**、**悲观读**、**乐观读**，StampedLock在**获取锁**时会返回一个**票据stamp**\n4. 一个写线程获取**写锁**的过程中，首先是通过**writeLock**获取一个票据stamp（表示**锁的版本**）\n    - WriteLock是一个**独占锁**，同时只能有一个线程可以获取WriteLock\n    - 当一个线程获取WriteLock后，其他请求的线程必须**等待**\n        - 当没有其他线程持有读锁或者写锁时才可以获得WriteLock\n5. 一个读线程获取**读锁**的过程中，首先会通过**tryOptimisticRead**获取一个票据stamp\n    - 如果**当前没有线程持有写锁**，会返回一个**非0的stamp**\n    - 然后调用**validate**验证之前调用tryOptimisticRead返回的stamp在**当前是否有其他线程持有了写锁**\n        - 如果是，那么validate返回**0**，升级为**悲观锁**\n6. 相对于ReentrantReadWriteLock，StampedLock**获取读锁**只使用了**与或**操作进行校验，**不涉及CAS操作**\n    - 即使第一次乐观锁获取失败，也会马上升级为悲观锁，可以避免一直进行CAS操作而带来的**CPU性能消耗**问题\n7. 但StampedLock并**没有被广泛使用**，有几个主要原因\n    - StampedLock的功能仅仅只是**ReadWriteLock的子集**\n    - StampedLock**不支持重入！！**\n    - StampedLock的**悲观读锁、写锁都不支持条件变量**（不符合**管程模型**）\n\n```java\npublic class Point {\n    private double x, y;\n    private final StampedLock lock = new StampedLock();\n\n    public void move(double deltaX, double deltaY) {\n        // 获取写锁\n        long stamp = lock.writeLock();\n        try {\n            x += deltaX;\n            y += deltaY;\n        } finally {\n            // 释放写锁\n            lock.unlockWrite(stamp);\n        }\n    }\n\n    double distanceFromOrigin() {\n        // 乐观读\n        long stamp = lock.tryOptimisticRead();\n        // 拷贝变量\n        double currentX = x, currentY = y;\n        // 判断读期间是否有写操作\n        if (!lock.validate(stamp)) {\n            // 升级为悲观读\n            stamp = lock.readLock();\n            try {\n                currentX = x;\n                currentY = y;\n            } finally {\n                lock.unlockRead(stamp);\n            }\n        }\n        return Math.sqrt(currentX * currentX + currentY + currentY);\n    }\n}\n```\n\n## 小结\n1. 不管使用**synchronized同步锁**还是**Lock同步锁**，只要存在**锁竞争**就会产生**线程阻塞**，导致**线程频繁切换**，增加**性能消耗**\n2. 优化锁的关键：**降低锁竞争**\n    - synchronized同步锁：**减少锁粒度**、**减少锁占用时间**\n    - Lock同步锁：**锁分离**\n","tags":["StampedLock"],"categories":["Performance"]},{"title":"Spring -- Spring Data JPA","url":"%2F2019%2F08%2F17%2Fspring-spring-data-jpa%2F","content":"\n## O/R Mapping\nRDBMS : **Relational** database management system\n\n| | Object | RDBMS |\n| ---- | ---- | ---- |\n| 粒度 | 类 | 表 |\n| 继承 | 有 | 无 |\n| 唯一性 | a==b<br/>a.equals(b) | 主键 |\n| 关联 | 引用 | 外键 |\n| 数据访问 | 逐级访问 | SQL数量要少 |\n\n<!-- more -->\n\n## Hibernate\n\n### 简介\n1. Hibernate是一款**开源**的**O/R Mapping**框架\n2. 将开发者从95%的常见**数据持久化**（**简单的CRUD**）工作中解放出来\n3. 屏蔽**底层数据库**（MySQL/Oracle/H2）的差异\n\n### 发展历程\n1. 2001年，Hibernate发布第一个版本\n2. 2003年，Hibernate开发团队加入JBoss\n3. 2006年，**Hibernate 3.2成为JPA实现**\n\n## JPA\n1. JPA : **Java Persistence API**\n2. JPA为**O/R Mapping**提供了一种_**基于POJO的持久化模型**_\n    - 简化数据持久化代码的开发工作\n    - 为Java社区屏蔽**不同持久化API**（Hibernate/JDO/EJB）的差异\n3. 在2006年**JPA 1.0**作为**JSR 220**的一部分正式发布（JSR，Java Specification Request）\n\n## Spring Data\n1. Spring将与数据操作相关的内容**剥离出Spring Framework**，统一到**Spring Data**\n2. 在**保留底层存储特性**的同时，提供**相对一致**的，基于**Spring**的编程模型\n3. 主要模块：Spring Data Commons、Spring Data JDBC、**Spring Data JPA**、Spring Data Redis\n    - Spring Data JDBC -- JdbcTemplate\n    - Spring Data Redis -- RedisTemplate\n\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-jpa</artifactId>\n    <version>2.1.7.RELEASE</version>\n</dependency>\n```\n\n## JPA注解\n1. 实体\n    - @Entity\n    - @MappedSuperclass\n    - @Table\n2. 主键\n    - @Id\n        - @GeneratedValue(strategy, generator)\n        - @SequenceGenerator(name, sequenceName)\n3. 映射\n    - @Column(name, nullable, length, insertable, updatable)\n    - @JoinTable(name)、@JoinColumn(name)\n4. 关系\n    - @OneToOne、@OneToMany、@ManyToOne、@ManyToMany\n    - @OrderBy\n\n```java\n@Data\n// 没有@Table注解，表名即为Product\n@Entity(name = \"Product\")\npublic class Product {\n    @Id\n    @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = \"sequence-generator\")\n    @SequenceGenerator(name = \"sequence-generator\", sequenceName = \"product_sequence\")\n    private Long id;\n\n    @Column(name = \"product_name\")\n    private String name;\n}\n```\n\n## SpringBucks\n\n### UML\n\n#### 时序图\n<img src=\"https://spring-1253868755.cos.ap-guangzhou.myqcloud.com/spring-data-jpa-sequence.png\" width=400/>\n\n#### 部署图\n<img src=\"https://spring-1253868755.cos.ap-guangzhou.myqcloud.com/spring-data-jpa-deployment.png\" width=400/>\n\n#### 对象图\n<img src=\"https://spring-1253868755.cos.ap-guangzhou.myqcloud.com/spring-data-jpa-object.png\" width=400/>\n\n#### 状态图\n<img src=\"https://spring-1253868755.cos.ap-guangzhou.myqcloud.com/spring-data-jpa-state.png\" width=200/>\n\n### 依赖\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-jpa</artifactId>\n</dependency>\n<dependency>\n    <groupId>com.h2database</groupId>\n    <artifactId>h2</artifactId>\n    <scope>runtime</scope>\n</dependency>\n<dependency>\n    <groupId>org.projectlombok</groupId>\n    <artifactId>lombok</artifactId>\n    <optional>true</optional>\n</dependency>\n<dependency>\n    <groupId>org.joda</groupId>\n    <artifactId>joda-money</artifactId>\n    <version>1.0.1</version>\n</dependency>\n<dependency>\n    <groupId>org.jadira.usertype</groupId>\n    <artifactId>usertype.core</artifactId>\n    <version>6.0.1.GA</version>\n</dependency>\n```\n\n### Entity\n\n#### BaseEntity\n```java\n@MappedSuperclass\n@Data\n@NoArgsConstructor\n@AllArgsConstructor\npublic class BaseEntity implements Serializable {\n    @Id\n    // 如果strategy采用GenerationType.IDENTITY，使用数据库的自增主键，不会生成sequence表\n    @GeneratedValue\n    private Long id;\n\n    @Column(updatable = false)\n    @CreationTimestamp\n    private Date createTime;\n\n    @UpdateTimestamp\n    private Date updateTime;\n}\n```\n\n#### Coffee\n```java\n@Entity\n@Table(name = \"T_MENU\")\n@Builder\n@Data\n@ToString(callSuper = true)\n@NoArgsConstructor\n@AllArgsConstructor\n@EqualsAndHashCode(callSuper = true)\npublic class Coffee extends BaseEntity {\n    private String name;\n\n    @Column\n    @Type(type = \"org.jadira.usertype.moneyandcurrency.joda.PersistentMoneyMinorAmount\",\n            parameters = {@org.hibernate.annotations.Parameter(name = \"currencyCode\", value = \"CNY\")})\n    private Money price;\n}\n```\n\n#### Order\n```java\n@Entity\n@Table(name = \"T_ORDER\")\n@Builder\n@Data\n@ToString(callSuper = true)\n@NoArgsConstructor\n@AllArgsConstructor\n@EqualsAndHashCode(callSuper = true)\npublic class Order extends BaseEntity {\n    private String customer;\n\n    @ManyToMany\n    @JoinTable(name = \"T_ORDER_COFFEE\") // 映射表\n    private List<Coffee> items;\n\n    @Enumerated // 映射成integer\n    @Column(nullable = false)\n    private OrderState state;\n}\n\npublic enum OrderState {\n    INIT, PAID, BREWING, BREWED, TAKEN, CANCELLED\n}\n```\n\n#### application.properties\n```\nspring.jpa.hibernate.ddl-auto=create-drop\nspring.jpa.properties.hibernate.show_sql=true\nspring.jpa.properties.hibernate.format_sql=true\n```\n\n#### 相关日志\n```\nHibernate:\n\n    drop table t_menu if exists\nHibernate:\n\n    drop table t_order if exists\nHibernate:\n\n    drop table t_order_coffee if exists\nHibernate:\n\n    drop sequence if exists hibernate_sequence\n```\n```\nHibernate: create sequence hibernate_sequence start with 1 increment by 1\nHibernate:\n\n    create table t_menu (\n       id bigint not null,\n        create_time timestamp,\n        update_time timestamp,\n        name varchar(255),\n        price bigint,\n        primary key (id)\n    )\nHibernate:\n\n    create table t_order (\n       id bigint not null,\n        create_time timestamp,\n        update_time timestamp,\n        customer varchar(255),\n        state integer not null,\n        primary key (id)\n    )\nHibernate:\n\n    create table t_order_coffee (\n       order_id bigint not null,\n        items_id bigint not null\n    )\nHibernate:\n\n    alter table t_order_coffee\n       add constraint FKj2swxd3y69u2tfvalju7sr07q\n       foreign key (items_id)\n       references t_menu\nHibernate:\n\n    alter table t_order_coffee\n       add constraint FKjnvwi9aq5s71k7dru924mleq7\n       foreign key (order_id)\n       references t_order\n```\n```\nHibernate:\n\n   drop table t_menu if exists\nHibernate:\n\n   drop table t_order if exists\nHibernate:\n\n   drop table t_order_coffee if exists\nHibernate:\n\n   drop sequence if exists hibernate_sequence\n```\n\n### Repository\n```java\n@EnableJpaRepositories\n\nJpaRepository<T, ID> extends PagingAndSortingRepository<T, ID>\nPagingAndSortingRepository<T, ID> extends CrudRepository<T, ID>\nCrudRepository<T, ID> extends Repository<T, ID>\n```\n\n#### 定义查询\n1. find..by.. / find..by.. / query..by.. / get..by..\n2. count..by..\n3. ..OrderBy..[Asc/Desc]\n4. And / Or / IgnoreCase\n5. Top / First / Distinct\n\n#### 分页查询\n1. PagingAndSortingRepository\\<T, ID\\>\n2. Pageable / Sort\n3. Slice\\<T\\> / Page\\<T\\>\n\n#### 保存Entity\n\n##### CoffeeRepository\n```java\npublic interface CoffeeRepository extends CrudRepository<Coffee, Long> {\n}\n```\n\n##### OrderRepository\n```java\npublic interface OrderRepository extends CrudRepository<Order, Long> {\n}\n```\n\n##### SpringDataJpaApplication\n```java\n@Slf4j\n@EnableJpaRepositories\n@SpringBootApplication\npublic class SpringDataJpaApplication implements ApplicationRunner {\n\n    @Autowired\n    private CoffeeRepository coffeeRepository;\n    @Autowired\n    private OrderRepository orderRepository;\n\n    public static void main(String[] args) {\n        SpringApplication.run(SpringDataJpaApplication.class, args);\n    }\n\n    @Override\n    public void run(ApplicationArguments args) throws Exception {\n        initOrders();\n    }\n\n    private void initOrders() {\n        Coffee espresso = Coffee.builder().name(\"espresso\")\n                .price(Money.of(CurrencyUnit.of(\"CNY\"), 20.0)).build();\n        coffeeRepository.save(espresso);\n        log.info(\"Coffee: {}\", espresso);\n\n        Coffee latte = Coffee.builder().name(\"latte\")\n                .price(Money.of(CurrencyUnit.of(\"CNY\"), 30.0)).build();\n        coffeeRepository.save(latte);\n        log.info(\"Coffee: {}\", latte);\n\n        Order order = Order.builder().customer(\"zhongmingmao\")\n                .items(Arrays.asList(espresso))\n                .state(OrderState.INIT).build();\n        orderRepository.save(order);\n        log.info(\"Order: {}\", order);\n\n        order = Order.builder().customer(\"zhongmingmao\")\n                .items(Arrays.asList(espresso, latte))\n                .state(OrderState.INIT).build();\n        orderRepository.save(order);\n        log.info(\"Order: {}\", order);\n    }\n}\n```\n\n##### 相关日志\n```\nHibernate:\n    call next value for hibernate_sequence\nHibernate:\n    insert\n    into\n        t_menu\n        (create_time, update_time, name, price, id)\n    values\n        (?, ?, ?, ?, ?)\n\nCoffee: Coffee(super=BaseEntity(id=1, createTime=Sat Aug 31 14:27:26 CST 2019, updateTime=Sat Aug 31 14:27:26 CST 2019), name=espresso, price=CNY 20.00)\n```\n```\nHibernate:\n    call next value for hibernate_sequence\nHibernate:\n    insert\n    into\n        t_menu\n        (create_time, update_time, name, price, id)\n    values\n        (?, ?, ?, ?, ?)\n\nCoffee: Coffee(super=BaseEntity(id=2, createTime=Sat Aug 31 14:27:26 CST 2019, updateTime=Sat Aug 31 14:27:26 CST 2019), name=latte, price=CNY 30.00)\n```\n```\nHibernate:\n    call next value for hibernate_sequence\nHibernate:\n    insert\n    into\n        t_order\n        (create_time, update_time, customer, state, id)\n    values\n        (?, ?, ?, ?, ?)\nHibernate:\n    insert\n    into\n        t_order_coffee\n        (order_id, items_id)\n    values\n        (?, ?)\n\nOrder: Order(super=BaseEntity(id=3, createTime=Sat Aug 31 14:27:26 CST 2019, updateTime=Sat Aug 31 14:27:26 CST 2019), customer=zhongmingmao, items=[Coffee(super=BaseEntity(id=1, createTime=Sat Aug 31 14:27:26 CST 2019, updateTime=Sat Aug 31 14:27:26 CST 2019), name=espresso, price=CNY 20.00)], state=INIT)\n```\n```\nHibernate:\n    call next value for hibernate_sequence\nHibernate:\n    insert\n    into\n        t_order\n        (create_time, update_time, customer, state, id)\n    values\n        (?, ?, ?, ?, ?)\nHibernate:\n    insert\n    into\n        t_order_coffee\n        (order_id, items_id)\n    values\n        (?, ?)\nHibernate:\n    insert\n    into\n        t_order_coffee\n        (order_id, items_id)\n    values\n        (?, ?)\n\nOrder: Order(super=BaseEntity(id=4, createTime=Sat Aug 31 14:27:26 CST 2019, updateTime=Sat Aug 31 14:27:26 CST 2019), customer=zhongmingmao, items=[Coffee(super=BaseEntity(id=1, createTime=Sat Aug 31 14:27:26 CST 2019, updateTime=Sat Aug 31 14:27:26 CST 2019), name=espresso, price=CNY 20.00), Coffee(super=BaseEntity(id=2, createTime=Sat Aug 31 14:27:26 CST 2019, updateTime=Sat Aug 31 14:27:26 CST 2019), name=latte, price=CNY 30.00)], state=INIT)\n```\n\n#### 查询Entity\n\n##### BaseRepository\n```java\n@NoRepositoryBean // 告知Spring无需为BaseRepository创建Bean\npublic interface BaseRepository<T, ID> extends PagingAndSortingRepository<T, ID> {\n    List<T> findTop3ByOrderByUpdateTimeDescIdAsc();\n}\n```\n\n##### CoffeeRepository\n```java\npublic interface CoffeeRepository extends BaseRepository<Coffee, Long> {\n}\n```\n\n##### OrderRepository\n```java\npublic interface OrderRepository extends BaseRepository<Order, Long> {\n    List<Order> findByCustomerOrderById(String customer);\n\n    List<Order> findByItems_Name(String name);\n}\n```\n\n##### SpringDataJpaApplication\n```java\nprivate void findOrders() {\n    coffeeRepository.findAll(Sort.by(Sort.Direction.DESC, \"id\"))\n            .forEach(coffee -> log.info(\"Loading {}\", coffee));\n\n    List<Order> orders = orderRepository.findTop3ByOrderByUpdateTimeDescIdAsc();\n    log.info(\"findTop3ByOrderByUpdateTimeDescIdAsc: {}\", getJoinedOrderId(orders));\n\n    orders = orderRepository.findByCustomerOrderById(\"zhongmingmao\");\n    log.info(\"findByCustomerOrderById: {}\", getJoinedOrderId(orders));\n\n    // 不开启事务会因为没有Session而报LazyInitializationException\n    // run方法加上@Transactional注解\n    orders.forEach(order -> {\n        log.info(\"Order: {}\", order.getId());\n        order.getItems().forEach(coffee -> log.info(\" Item {}\", coffee));\n    });\n\n    orders = orderRepository.findByItems_Name(\"latte\");\n    log.info(\"findByItems_Name: {}\", getJoinedOrderId(orders));\n}\n\nprivate String getJoinedOrderId(List<Order> orders) {\n    return orders.stream().map(order -> order.getId().toString()).collect(Collectors.joining(\",\"));\n}\n```\n\n##### 相关日志\n```\nHibernate:\n    select\n        coffee0_.id as id1_0_,\n        coffee0_.create_time as create_t2_0_,\n        coffee0_.update_time as update_t3_0_,\n        coffee0_.name as name4_0_,\n        coffee0_.price as price5_0_\n    from\n        t_menu coffee0_\n    order by\n        coffee0_.id desc\n\nLoading Coffee(super=BaseEntity(id=2, createTime=Sat Aug 31 15:03:49 CST 2019, updateTime=Sat Aug 31 15:03:49 CST 2019), name=latte, price=CNY 30.00)\nLoading Coffee(super=BaseEntity(id=1, createTime=Sat Aug 31 15:03:49 CST 2019, updateTime=Sat Aug 31 15:03:49 CST 2019), name=espresso, price=CNY 20.00)\n```\n```\nHibernate:\n    select\n        order0_.id as id1_1_,\n        order0_.create_time as create_t2_1_,\n        order0_.update_time as update_t3_1_,\n        order0_.customer as customer4_1_,\n        order0_.state as state5_1_\n    from\n        t_order order0_\n    order by\n        order0_.update_time desc,\n        order0_.id asc limit ?\n\nfindTop3ByOrderByUpdateTimeDescIdAsc: 4,3\n```\n```\nHibernate:\n    select\n        order0_.id as id1_1_,\n        order0_.create_time as create_t2_1_,\n        order0_.update_time as update_t3_1_,\n        order0_.customer as customer4_1_,\n        order0_.state as state5_1_\n    from\n        t_order order0_\n    where\n        order0_.customer=?\n    order by\n        order0_.id asc\n\nfindByCustomerOrderById: 3,4\nOrder: 3\n Item Coffee(super=BaseEntity(id=1, createTime=Sat Aug 31 15:03:49 CST 2019, updateTime=Sat Aug 31 15:03:49 CST 2019), name=espresso, price=CNY 20.00)\nOrder: 4\n Item Coffee(super=BaseEntity(id=1, createTime=Sat Aug 31 15:03:49 CST 2019, updateTime=Sat Aug 31 15:03:49 CST 2019), name=espresso, price=CNY 20.00)\n Item Coffee(super=BaseEntity(id=2, createTime=Sat Aug 31 15:03:49 CST 2019, updateTime=Sat Aug 31 15:03:49 CST 2019), name=latte, price=CNY 30.00)\n```\n```\nHibernate:\n    select\n        order0_.id as id1_1_,\n        order0_.create_time as create_t2_1_,\n        order0_.update_time as update_t3_1_,\n        order0_.customer as customer4_1_,\n        order0_.state as state5_1_\n    from\n        t_order order0_\n    left outer join\n        t_order_coffee items1_\n            on order0_.id=items1_.order_id\n    left outer join\n        t_menu coffee2_\n            on items1_.items_id=coffee2_.id\n    where\n        coffee2_.name=?\n\nfindByItems_Name: 4\n```\n","tags":["UML"],"categories":["Spring Boot"]},{"title":"Kafka -- 生产者管理TCP连接","url":"%2F2019%2F08%2F16%2Fkafka-producer-manage-tcp-connection%2F","content":"\n## 建立TCP连接\n\n### 创建KafkaProducer实例\n```java\nProperties properties = new Properties();\nproperties.put(\"bootstrap.servers\", \"localhost:9092\");\nproperties.put(\"key.serializer\", StringSerializer.class.getName());\nproperties.put(\"value.serializer\", StringSerializer.class.getName());\n// try-with-resources\n// 创建KafkaProducer实例时，会在后台创建并启动Sender线程，Sender线程开始运行时首先会创建与Broker的TCP连接\ntry (Producer<String, String> producer = new KafkaProducer<>(properties)) {\n    ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC, KEY, VALUE);\n    Callback callback = (metadata, exception) -> {\n    };\n    producer.send(record, callback);\n}\n```\n\n<!-- more -->\n\n1. `bootstrap.servers`是Producer的核心参数之一，指定了Producer**启动**时要连接的Broker地址\n2. 如果`bootstrap.servers`指定了1000个Broker，那么Producer启动时会首先创建与这1000个Broker的**TCP连接**\n3. 因此不建议把集群中所有的Broker信息都配置到`bootstrap.servers`中，通常配置**3~4台**足够\n    - Producer一旦连接到集群中的**任意一台Broker**，就能拿到**整个集群**的Broker信息（**metadata request**）\n4. 在创建KafkaProducer实例时启动Sender线程是**不合理**的\n    - 在对象构造器中启动线程会造成**this指针逃逸**，理论上Sender线程能够观测到一个**尚未构造完成**的KafkaProducer实例\n    - 在构造对象时创建线程是没有问题的，但最好不要同时启动线程\n\n相关日志\n```\nSender          - Starting Kafka producer I/O thread.\nKafkaProducer   - Kafka producer started\nNetworkClient   - Initialize connection to node localhost:9092 (id: -1 rack: null) for sending metadata request\nNetworkClient   - Initiating connection to node localhost:9092 (id: -1 rack: null)\nSelector        - Created socket with SO_RCVBUF = 326640, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node -1\nNetworkClient   - Completed connection to node -1. Fetching API versions.\nNetworkClient   - Initiating API versions fetch from node -1.\nNetworkClient   - Sending metadata request (type=MetadataRequest, topics=zhongmingmao) to node localhost:9092 (id: -1 rack: null)\nKafkaProducer   - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.\nNetworkClient   - Initiating connection to node 192.168.2.1:9092 (id: 0 rack: null)\nSender          - Beginning shutdown of Kafka producer I/O thread, sending remaining records.\nSender          - Shutdown of Kafka producer I/O thread has completed.\nKafkaProducer   - Kafka producer has been closed\n```\n\n### 其他场景\n1. 其他**可能**创建TCP连接的场景：**更新元数据后**，**消息发送时**\n2. 当Producer更新了**集群的元数据**后，如果发现与某些Broker当前没有连接，那么Producer会创建一个TCP连接\n    - 场景1\n        - 当Producer尝试向**不存在的主题**发送消息时，Broker会告诉Producer这个主题不存在\n        - 此时Producer会发送**metadata request**到**Kafka集群**，去尝试获取最新的元数据信息\n            - 与**集群中所有的Broker**建立TCP连接\n    - 场景2\n        - Producer通过`metadata.max.age.ms`参数**定期**地去更新元数据信息，默认值300000，即**5分钟**\n3. 当Producer要**发送消息**时，Producer发现与**目标Broker**（依赖**负载均衡**算法）还没有连接，也会创建一个TCP连接\n\n## 关闭TCP连接\n1. Producer端关闭TCP连接有两种方式：**用户主动关闭**、**Kafka自动关闭**\n2. **用户主动关闭**\n    - 广义的主动关闭，包括用户调用`kill -9`来\u0010杀掉Producer，最推荐的方式：`producer.close()`\n3. **Kafka自动关闭**\n    - Producer端参数`connections.max.idle.ms`，默认值540000，即**9分钟**\n    - 如果9分钟内**没有任何请求**经过某个TCP连接，Kafka会主动把TCP连接关闭\n    - `connections.max.idle.ms=-1`会**禁用**这种机制，TCP连接将成为**永久长连接**\n        - Kafka创建的Socket连接都开启了**keepalive**\n    - 关闭TCP连接的发起方是**Kafka客户端**，属于**被动关闭**的场景\n        - 被动关闭的后果就是会产生大量的**CLOSE_WAIT**连接\n        - _**Producer端或Client端没有机会显式地观测到此TCP连接已被中断**_\n","tags":["TCP"],"categories":["Kafka"]},{"title":"Java性能 -- synchronized锁升级优化","url":"%2F2019%2F08%2F15%2Fjava-performance-synchronized-opt%2F","content":"\n## synchronized / Lock\n1. **JDK 1.5之前**，Java通过**synchronized**关键字来实现**锁**功能\n    - synchronized是JVM实现的**内置锁**，锁的获取和释放都是由JVM**隐式**实现的\n2. **JDK 1.5**，并发包中新增了**Lock接口**来实现锁功能\n    - 提供了与synchronized类似的同步功能，但需要**显式**获取和释放锁\n3. Lock同步锁是基于**Java**实现的，而synchronized是基于底层操作系统的**Mutex Lock**实现的\n    - 每次获取和释放锁都会带来**用户态和内核态的切换**，从而增加系统的**性能开销**\n    - 在锁竞争激烈的情况下，synchronized同步锁的性能很糟糕\n    - 在**JDK 1.5**，在**单线程重复申请锁**的情况下，synchronized锁性能要比Lock的性能**差很多**\n4. **JDK 1.6**，Java对synchronized同步锁做了**充分的优化**，甚至在某些场景下，它的性能已经超越了Lock同步锁\n\n<!-- more -->\n\n## 实现原理\n```java\npublic class SyncTest {\n    public synchronized void method1() {\n    }\n\n    public void method2() {\n        Object o = new Object();\n        synchronized (o) {\n        }\n    }\n}\n```\n```\n$ javac -encoding UTF-8 SyncTest.java\n$ javap -v SyncTest\n```\n\n### 修饰方法\n```java\npublic synchronized void method1();\n  descriptor: ()V\n  flags: ACC_PUBLIC, ACC_SYNCHRONIZED\n  Code:\n    stack=0, locals=1, args_size=1\n       0: return\n```\n1. JVM使用**ACC_SYNCHRONIZED**访问标识来区分一个方法是否为**同步方法**\n2. 在方法调用时，会检查方法是否被设置了**ACC_SYNCHRONIZED**访问标识\n    - 如果是，执行线程会将先尝试**持有Monitor对象**，再执行方法，方法执行完成后，最后**释放Monitor对象**\n\n### 修饰代码块\n```java\npublic void method2();\n  descriptor: ()V\n  flags: ACC_PUBLIC\n  Code:\n    stack=2, locals=4, args_size=1\n       0: new           #2                  // class java/lang/Object\n       3: dup\n       4: invokespecial #1                  // Method java/lang/Object.\"<init>\":()V\n       7: astore_1\n       8: aload_1\n       9: dup\n      10: astore_2\n      11: monitorenter\n      12: aload_2\n      13: monitorexit\n      14: goto          22\n      17: astore_3\n      18: aload_2\n      19: monitorexit\n      20: aload_3\n      21: athrow\n      22: return\n```\n1. synchronized修饰同步代码块时，由**monitorenter**和**monitorexit**指令来实现同步\n2. 进入**monitorenter**指令后，线程将**持有**该**Monitor对象**，进入**monitorexit**指令，线程将**释放**该**Monitor对象**\n\n### 管程模型\n1. JVM中的**同步**是基于进入和退出**管程**（**Monitor**）对象实现的\n2. **每个Java对象实例都会有一个Monitor**，Monitor可以和Java对象实例一起被创建和销毁\n3. Monitor是由**ObjectMonitor**实现的，对应[ObjectMonitor.hpp](https://github.com/JetBrains/jdk8u_hotspot/blob/master/src/share/vm/runtime/objectMonitor.hpp)\n4. 当多个线程同时访问一段同步代码时，会先被放在**EntryList**中\n5. 当线程获取到Java对象的Monitor时（Monitor是依靠**底层操作系统**的**Mutex Lock**来实现**互斥**的）\n    - 线程申请Mutex成功，则持有该Mutex，其它线程将无法获取到该Mutex\n6. 进入**WaitSet**\n    - 竞争锁**失败**的线程会进入**WaitSet**\n    - 竞争锁**成功**的线程如果调用**wait**方法，就会**释放当前持有的Mutex**，并且该线程会进入**WaitSet**\n    - 进入**WaitSet**的进程会等待下一次唤醒，然后进入EntryList**重新排队**\n7. 如果当前线程顺利执行完方法，也会释放Mutex\n8. Monitor依赖于**底层操作系统**的实现，存在**用户态**和**内核态之间**的**切换**，所以增加了**性能开销**\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-synchronized-monitor.png\" width=800/>\n\n```java\nObjectMonitor() {\n  _header       = NULL;\n  _count        = 0;        // 记录个数\n  _waiters      = 0,\n  _recursions   = 0;\n  _object       = NULL;\n  _owner        = NULL;     // 持有该Monitor的线程\n  _WaitSet      = NULL;     // 处于wait状态的线程，会被加入 _WaitSet\n  _WaitSetLock  = 0 ;\n  _Responsible  = NULL ;\n  _succ         = NULL ;\n  _cxq          = NULL ;\n  FreeNext      = NULL ;\n  _EntryList    = NULL ;    // 多个线程访问同步块或同步方法，会首先被加入 _EntryList\n  _SpinFreq     = 0 ;\n  _SpinClock    = 0 ;\n  OwnerIsThread = 0 ;\n  _previous_owner_tid = 0;\n}\n```\n\n## 锁升级优化\n1. 为了提升性能，在**JDK 1.6**引入**偏向锁、轻量级锁、重量级锁**，用来**减少锁竞争带来的上下文切换**\n2. 借助JDK 1.6新增的**Java对象头**，实现了**锁升级**功能\n\n### Java对象头\n1. 在**JDK 1.6**的JVM中，对象实例在**堆内存**中被分为三部分：**对象头**、**实例数据**、**对齐填充**\n2. 对象头的组成部分：**Mark Word**、**指向类的指针**、**数组长度**（可选，数组类型时才有）\n3. Mark Word记录了**对象**和**锁**有关的信息，在64位的JVM中，Mark Word为**64 bit**\n4. 锁升级功能主要依赖于Mark Word中**锁标志位**和**是否偏向锁标志位**\n5. synchronized同步锁的升级优化路径：_**偏向锁** -> **轻量级锁** -> **重量级锁**_\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-synchronized-mark-word.jpg\" width=800/>\n\n### 偏向锁\n1. 偏向锁主要用来优化**同一线程多次申请同一个锁**的竞争，在某些情况下，大部分时间都是同一个线程竞争锁资源\n2. 偏向锁的作用\n    - 当一个线程再次访问同一个同步代码时，该线程只需对该对象头的**Mark Word**中去判断是否有偏向锁指向它\n    - **无需再进入Monitor去竞争对象**（避免用户态和内核态的**切换**）\n3. 当对象被当做同步锁，并有一个线程抢到锁时\n    - 锁标志位还是**01**，是否偏向锁标志位设置为**1**，并且记录抢到锁的**线程ID**，进入_**偏向锁状态**_\n4. 偏向锁_**不会主动释放锁**_\n    - 当线程1再次获取锁时，会比较**当前线程的ID**与**锁对象头部的线程ID**是否一致，如果一致，无需CAS来抢占锁\n    - 如果不一致，需要查看**锁对象头部记录的线程**是否存活\n        - 如果**没有存活**，那么锁对象被重置为**无锁**状态（也是一种撤销），然后重新偏向线程2\n        - 如果**存活**，查找线程1的栈帧信息\n            - 如果线程1还是需要继续持有该锁对象，那么暂停线程1（**STW**），**撤销偏向锁**，**升级为轻量级锁**\n            - 如果线程1不再使用该锁对象，那么将该锁对象设为**无锁**状态（也是一种撤销），然后重新偏向线程2\n5. 一旦出现其他线程竞争锁资源时，偏向锁就会被**撤销**\n    - 偏向锁的撤销**可能需要**等待**全局安全点**，暂停持有该锁的线程，同时检查该线程**是否还在执行该方法**\n    - 如果还没有执行完，说明此刻有**多个线程**竞争，升级为**轻量级锁**；如果已经执行完毕，唤醒其他线程继续**CAS**抢占\n6. 在**高并发**场景下，当**大量线程**同时竞争同一个锁资源时，偏向锁会被**撤销**，发生**STW**，加大了**性能开销**\n    - 默认配置\n        - `-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=4000`\n        - 默认开启偏向锁，并且**延迟生效**，因为JVM刚启动时竞争非常激烈\n    - **关闭偏向锁**\n        - `-XX:-UseBiasedLocking`\n    - 直接**设置为重量级锁**\n        - `-XX:+UseHeavyMonitors`\n\n红线流程部分：偏向锁的**获取**和**撤销**\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-synchronized-lock-upgrade-1.png\" width=800/>\n\n### 轻量级锁\n1. 当有另外一个线程竞争锁时，由于该锁处于**偏向锁**状态\n2. 发现对象头Mark Word中的线程ID不是自己的线程ID，该线程就会执行**CAS**操作获取锁\n    - 如果获取**成功**，直接替换Mark Word中的线程ID为自己的线程ID，该锁会_**保持偏向锁状态**_\n    - 如果获取**失败**，说明当前锁有一定的竞争，将偏向锁**升级**为轻量级锁\n3. 线程获取轻量级锁时会有两步\n    - 先把**锁对象的Mark Word**复制一份到线程的**栈帧**中（**DisplacedMarkWord**），主要为了**保留现场**!!\n    - 然后使用**CAS**，把对象头中的内容替换为**线程栈帧中DisplacedMarkWord的地址**\n4. 场景\n    - 在线程1复制对象头Mark Word的同时（CAS之前），线程2也准备获取锁，也复制了对象头Mark Word\n    - 在线程2进行CAS时，发现线程1已经把对象头换了，线程2的CAS失败，线程2会尝试使用**自旋锁**来等待线程1释放锁\n5. 轻量级锁的适用场景：线程**交替执行**同步块，_**绝大部分的锁在整个同步周期内都不存在长时间的竞争**_\n\n红线流程部分：升级轻量级锁\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-synchronized-lock-upgrade-2.png\" width=800/>\n\n### 自旋锁 / 重量级锁\n1. 轻量级锁**CAS**抢占失败，线程将会被挂起进入**阻塞**状态\n    - 如果正在持有锁的线程在**很短的时间**内释放锁资源，那么进入**阻塞**状态的线程被**唤醒**后又要**重新抢占**锁资源\n2. JVM提供了**自旋锁**，可以通过**自旋**的方式**不断尝试获取锁**，从而_**避免线程被挂起阻塞**_\n3. 从**JDK 1.7**开始，**自旋锁默认启用**，自旋次数**不建议设置过大**（意味着**长时间占用CPU**）\n    - `-XX:+UseSpinning -XX:PreBlockSpin=10`\n4. 自旋锁重试之后如果依然抢锁失败，同步锁会升级至**重量级锁**，锁标志位为**10**\n    - 在这个状态下，未抢到锁的线程都会**进入Monitor**，之后会被阻塞在**WaitSet**中\n5. 在**锁竞争不激烈**且**锁占用时间非常短**的场景下，自旋锁可以提高系统性能\n    - 一旦锁竞争激烈或者锁占用的时间过长，自旋锁将会导致大量的线程一直处于**CAS重试状态**，**占用CPU资源**\n6. 在**高并发**的场景下，可以通过**关闭自旋锁**来优化系统性能\n    - `-XX:-UseSpinning`\n        - 关闭自旋锁优化\n    - `-XX:PreBlockSpin`\n        - 默认的自旋次数，在**JDK 1.7**后，**由JVM控制**\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-synchronized-lock-upgrade-3.png\" width=800/>\n\n## 小结\n1. JVM在**JDK 1.6**中引入了**分级锁**机制来优化synchronized\n2. 当一个线程获取锁时，首先对象锁成为一个**偏向锁**\n    - 这是为了避免在**同一线程重复获取同一把锁**时，**用户态和内核态频繁切换**\n3. 如果有多个线程竞争锁资源，锁将会升级为**轻量级锁**\n    - 这适用于在**短时间**内持有锁，且分锁**交替切换**的场景\n    - 轻量级锁还结合了**自旋锁**来**避免线程用户态与内核态的频繁切换**\n4. 如果锁竞争太激烈（自旋锁失败），同步锁会升级为重量级锁\n5. 优化synchronized同步锁的关键：**减少锁竞争**\n    - 应该尽量使synchronized同步锁处于**轻量级锁**或**偏向锁**，这样才能提高synchronized同步锁的性能\n    - 常用手段\n        - **减少锁粒度**：降低锁竞争\n        - **减少锁的持有时间**，提高synchronized同步锁在自旋时获取锁资源的成功率，**避免升级为重量级锁**\n6. 在**锁竞争激烈**时，可以考虑**禁用偏向锁**和**禁用自旋锁**\n","tags":["Monitor"],"categories":["Performance"]},{"title":"数据结构与算法 -- 队列","url":"%2F2019%2F08%2F14%2Fdata-structure-algorithm-queue%2F","content":"\n## 简介\n1. 栈支持两个基本操作：**入栈**（push）、**出栈**（pop）\n2. 队列支持两个基本操作：**入队**（enqueue）、**出队**（dequeue）\n3. 队列和栈都是**操作受限的线性表**\n4. 用**数组**实现的队列叫作**顺序队列**，用**链表**实现的队列叫作**链式队列**\n\n<!-- more -->\n\n## 顺序队列\n```java\npublic class ArrayQueue<T> {\n    private Object[] items;\n    private int n;\n    private int head = 0;\n    private int tail = 0;\n\n    public ArrayQueue(int capacity) {\n        items = new Object[capacity];\n        n = capacity;\n    }\n\n    // 入队\n    public boolean enqueue(T t) {\n        if (tail == n) {\n            // 队列已满\n            return false;\n        }\n        items[tail++] = t;\n        return true;\n    }\n\n    // 出队\n    public T dequeue() {\n        if (head == tail) {\n            // 队列为空\n            return null;\n        }\n        return (T) items[head++];\n    }\n}\n```\n存在的问题：随着不停地入队，tail会到达n，即使数组中还有空闲空间，也无法往队列中添加数据，可以优化enqueue\n\n### 优化enqueue\n```java\n// 入队\npublic boolean enqueue(T t) {\n    if (tail == n) {\n        if (head == 0) {\n            // 整个队列已满，只能扩容\n            return false;\n        }\n        // 数据搬移\n        System.arraycopy(items, head, items, 0, tail - head);\n        tail -= head;\n        head = 0;\n    }\n    items[tail++] = t;\n    return true;\n}\n```\n依然有数据搬移的动作，可以采用循环队列\n\n### 循环队列\n循环队列体现出**取模**的思想\n```java\npublic class CircularQueue<T> {\n    private Object[] items;\n    private int n;\n    private int head;\n    private int tail;\n\n    public CircularQueue(int capacity) {\n        // 预留一个位置给tail\n        int realSize = capacity + 1;\n        items = new Object[realSize];\n        this.n = realSize;\n    }\n\n    // 入队\n    public boolean enqueue(T t) {\n        if ((tail + 1) % n == head) {\n            // 队列已满\n            return false;\n        }\n        items[tail] = t;\n        tail = (tail + 1) % n;\n        return true;\n    }\n\n    // 出队\n    public T dequeue() {\n        if (head == tail) {\n            // 队列为空\n            return null;\n        }\n        T t = (T) items[head];\n        head = (head + 1) % n;\n        return t;\n    }\n}\n```\n\n## 链式队列\n```java\n@Data\npublic class Node<T> {\n    private T data;\n    private Node<T> next;\n}\n```\n```java\npublic class LinkedQueue<T> {\n    private Node<T> head = new Node<>();\n    private Node<T> tail = head;\n\n    // 入队\n    private boolean enqueue(T t) {\n        Node<T> node = new Node<>();\n        tail.setData(t);\n        tail.setNext(node);\n        tail = node;\n        return true;\n    }\n\n    // 出队\n    public T dequeue() {\n        if (head == tail) {\n            // 队列为空\n            return null;\n        }\n        T data = head.getData();\n        head = head.getNext();\n        return data;\n    }\n}\n```\n\n## 阻塞队列\n1. 阻塞队列\n    - 在队列为**空**时，从**队头**取数据会被阻塞，直到队列中有数据\n    - 在队列已**满**时，往**队尾**插入数据会被阻塞，直到队列中有空闲位置\n2. 使用阻塞队列，可以很容易地实现**生产者-消费者**模型，有效地**协调**生产和消费的速度\n\n## 并发队列\n1. 并发队列：_**线程安全的队列**_\n2. 最简单的实现方式是直接在enqueue和dequeue方法上**加锁**，但锁粒度太大会是**降低并发度**\n3. **基于数组的循环队列**，利用**CAS**原子操作，可以非常高效地实现并发队列，例如**Disruptor**\n","tags":["Queue"],"categories":["Data Structure & Algorithm"]},{"title":"Kafka -- 拦截器","url":"%2F2019%2F08%2F13%2Fkafka-interceptor%2F","content":"\n## 设计思路\n1. 基本思想：允许应用程序在不修改逻辑的情况下，动态地实现一组**可插拔**的事件处理逻辑链\n2. 拦截器能够在主业务操作的前后多个时间点上插入对应的拦截逻辑\n3. 以配置**拦截器类**的方式**动态**插入到应用程序中，可以快速地切换不同的拦截器，而不影响主程序逻辑\n\n<!-- more -->\n\n## Kafka拦截器\n1. Kafka拦截器自**0.10.0.0**版本被引入后并未得到太多的实际应用\n2. Kafka拦截器分为**生产者拦截器**和**消费者拦截器**\n    - **生产者拦截器**：允许在**发送消息前**以及**消息提交成功后**植入拦截逻辑\n    - **消费者拦截器**：允许在**消费消息前**以及**提交位移后**植入拦截逻辑\n3. Kafka拦截器支持**链式调用**，Kafka会按照**添加顺序**依次执行拦截器逻辑\n4. Kafka拦截器通过参数`interceptor.classes`来配置（生产者和消费者一致）\n    - 指定拦截器类时需要使用**全限定名**\n\n```java\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"key.serializer\", StringSerializer.class.getName());\nprops.put(\"value.serializer\", StringSerializer.class.getName());\nList<String> interceptors = Lists.newArrayList();\ninterceptors.add(AddTimeStampInterceptor.class.getCanonicalName());\ninterceptors.add(UpdateCounterInterceptor.class.getCanonicalName());\nprops.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);\nproducer = new KafkaProducer<>(props);\n```\n\n### 生产者拦截器\n```java\npublic interface ProducerInterceptor<K, V> extends Configurable {\n    // 消息发送之前\n    public ProducerRecord<K, V> onSend(ProducerRecord<K, V> record);\n\n    // 消息成功提交或发送失败之后，onAcknowledgement要早于callback\n    // onAcknowledgement和onSend不是在同一个线程中被调用，需要保证线程安全\n    // onAcknowledgement在Producer发送的主路径中，避免嵌入太重的逻辑，否则会影响TPS\n    public void onAcknowledgement(RecordMetadata metadata, Exception exception);\n}\n```\n\n### 消费者拦截器\n```java\npublic interface ConsumerInterceptor<K, V> extends Configurable {\n    // 消息返回给Consumer之前（即开始正式处理消息之前）\n    public ConsumerRecords<K, V> onConsume(ConsumerRecords<K, V> records);\n\n    // Consumer提交位移之后\n    public void onCommit(Map<TopicPartition, OffsetAndMetadata> offsets);\n}\n```\n\n## 案例：端到端延时\n1. Kafka默认提供的监控指标都是针对单个**客户端**或者**Broker**，缺少**消息维度**的监控\n2. 如何**追踪**一条消息在**集群间的流转路径**\n3. 如何**监控**一条消息从生产到消费的**端到端延时**\n\n### 生产者拦截器\n```java\npublic class AvgLatencyProducerInterceptor implements ProducerInterceptor<String, String> {\n\n    private Jedis jedis;\n\n    @Override\n    public ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {\n        jedis.incr(\"totalSentMessage\");\n        return record;\n    }\n\n    @Override\n    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {\n    }\n\n    @Override\n    public void close() {\n    }\n\n    @Override\n    public void configure(Map<String, ?> configs) {\n    }\n}\n```\n\n### 消费者拦截器\n```java\npublic class AvgLatencyConsumerInterceptor implements ConsumerInterceptor<String, String> {\n\n    private Jedis jedis;\n\n    @Override\n    public ConsumerRecords<String, String> onConsume(ConsumerRecords<String, String> records) {\n        AtomicLong latency = new AtomicLong(0L);\n        records.forEach(record -> latency.addAndGet(System.currentTimeMillis() - record.timestamp()));\n        jedis.incrBy(\"totalLatency\", latency.get());\n        long totalLatency = Long.parseLong(jedis.get(\"totalLatency\"));\n        long totalSentMessage = Long.parseLong(jedis.get(\"totalSentMessage\"));\n        jedis.set(\"avgLatency\", String.valueOf(totalLatency / totalSentMessage));\n        return records;\n    }\n\n    @Override\n    public void onCommit(Map<TopicPartition, OffsetAndMetadata> offsets) {\n    }\n\n    @Override\n    public void close() {\n    }\n\n    @Override\n    public void configure(Map<String, ?> configs) {\n    }\n}\n```\n","tags":["Stream"],"categories":["Kafka"]},{"title":"Java性能 -- NIO","url":"%2F2019%2F08%2F12%2Fjava-performance-nio%2F","content":"\n## BIO / NIO\n1. 在**Tomcat 8.5**之前，默认使用**BIO**线程模型，在高并发的场景下，可以设置为**NIO**线程模型，来提供系统的**网络通信性能**\n2. 页面请求用于模拟**多IO读写**操作的请求，Tomcat在IO读写请求比较多的情况下，使用NIO线程模型有明显的优势\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-bio-rt.png\" width=1000/>\n\n<!-- more -->\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-bio-tps.png\" width=1000/>\n\n## 网络IO模型优化\n网络通信中，最底层的是操作系统**内核**中的网络IO模型，分别为**阻塞式IO**、**非阻塞式IO**、**IO复用**、**信号驱动式IO**、**异步IO**\n\n### TCP工作流程\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-bio-tcp.jpg\" width=800/>\n\n1. 首先，应用程序通过**系统调用socket**，创建一个套接字，它是系统分配给应用程序的一个**文件描述符**\n2. 其次，应用程序通过**系统调用bind**，绑定**地址**和的**端口号**，给套接字**命名**一个名称\n3. 然后，**系统调用listen**，创建一个**队列**用于**存放客户端进来的连接**\n4. 最后，应用程序通过**系统调用accept**来**监听客户端的连接请求**\n5. 当有一个客户端连接到服务端后，服务端会通过**系统调用fork**，创建一个子进程\n    - 通过**系统调用read**监听客户端发来的消息，通过**系统调用write**向客户端返回消息\n\n### 阻塞式IO\n每一个连接**创建**时，都需要一个**用户线程**来处理，并且在IO操作没有**就绪**或者**结束**时，线程会被挂起，进入**阻塞等待**状态\n\n#### connect阻塞\n1. 客户端通过**系统调用connect**发起TCP连接请求，TCP连接的建立需要完成**三次握手**\n2. 客户端需要**阻塞等待**服务端返回的ACK和SYN，服务端需要**阻塞等待**客户端的ACK\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-bio-connect.png\" width=800/>\n\n#### accept阻塞\n服务端通过**系统调用accept**接收客户端请求，如果没有新的客户端连接到达，服务端进程将被挂起，进入**阻塞**状态\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-bio-accept.png\" width=800/>\n\n#### read、write阻塞\nSocket连接创建成功后，服务端调用fork创建子进程，调用read等待客户端写入数据，如果没有，子进程被挂起，进入**阻塞**状态\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-bio-read.png\" width=800/>\n\n### 非阻塞式IO\n1. 使用`fcntl`把上面的操作都设置为**非阻塞**，如果没有数据返回，直接返回`EWOULDBLOCK`或`EAGAIN`错误，进程不会被阻塞\n2. 最传统的非阻塞IO模型：设置一个**用户线程**对上面的操作进行**轮询检查**\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-not-block-io.png\" width=800/>\n\n### IO复用\n1. 传统的非阻塞IO模型使用**用户线程**去**轮询检查**一个IO操作的状态，**无法应对大量请求的情况**\n2. Linux提供了**IO复用函数**：**select**、**poll**、**epoll**\n    - 进程将一个或多个读操作通过**系统调用函数**，阻塞在函数操作上，_**系统内核去侦测多个读操作是否处于就绪状态**_\n\n#### select\n1. 在超时时间内，监听**用户感兴趣的文件描述符**上的**可读可写**和**异常**事件的发生\n2. Linux内核将所有**外部设备**看做**文件**，对文件的读写操作会调用内核提供的系统命令，返回一个**文件描述符**（fd）\n3. select函数监听的文件描述符分为三类：**readset**、**writeset**、**exceptset**（异常事件）\n4. 调用select函数后会**阻塞**，直到**有文件描述符就绪**或**超时**，函数返回\n5. 当select函数返回后，可以通过**FD_ISSET**函数遍历fdset（readset/writeset/exceptset），来找到**就绪**的文件描述符\n\n```c\nint select(int maxfdp1,fd_set *readset,fd_set *writeset,fd_set *exceptset,const struct timeval *timeout)\n\nint FD_ISSET(int fd, fd_set *fdset);    // 检查集合中指定的文件描述符是否可以读写\n```\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-select.png\" width=800/>\n\n#### poll\n1. 每次调用select函数之前，系统需要把fd从**用户态**拷贝到**内核态**（交由内核侦测），带来一定的**性能开销**\n2. 单个进程监视的fd数量默认为**1024**（可以**修改宏定义**或者**重新编译内核**）\n3. 另外**fd_set**是基于**数组**实现的，在**新增**和**删除**fd时，时间复杂度为`O(n)`（因此fd_set不宜过大）\n4. poll的机制与select类似，**本质上差别不大**（轮询），只是**poll没有最大文件描述符数量的限制**\n5. poll和select存在相同的缺点\n    - 包含大量文件描述符的**数组**被**整体复制**到**用户态**和**内核态**的地址空间，**无论这些文件描述符是否就绪**\n    - 系统开销会随着文件描述符的增加而**线性增大**\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-poll.png\" width=800/>\n\n#### epoll\n1. select/poll是**顺序扫描**fd是否就绪，而且支持的**fd数量不宜过大**\n2. Linux 2.6提供了epoll调用，epoll使用**事件驱动**的方式代替轮询扫描fd\n3. epoll事先通过`epoll_ctl`来**注册**一个**文件描述符**，将文件描述符存放在**内核**的一个**事件表**中\n    - 该事件表是基于**红黑树**实现的，在大量IO请求的场景下，其**插入和删除的性能**比select/poll的**数组**fd_set要好\n    - 因此epoll的**性能更好**，而且**没有fd数量的限制**\n4. epoll_ctl函数的参数解析\n    - epfd：由`epoll_create`函数生成的一个**epoll专用文件描述符**\n    - op：操作事件类型\n    - fd：关联的文件描述符\n    - event：监听的事件类型\n5. 一旦某个文件描述符就绪，操作系统**内核**会采用类似**Callback**的回调机制，迅速激活该文件描述符\n    - 当进程调用`epoll_wait`时便得到通知，之后进程将完成相关的IO操作\n\n```c\nint epoll_ctl(int epfd, int op, int fd, struct epoll_event event)\n\nint epoll_wait(int epfd, struct epoll_event events,int maxevents,int timeout)\n```\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-epoll.png\" width=800/>\n\n### 信号驱动式IO\n1. 信号驱动式IO类似于**观察者模式**，**内核是观察者**，**信号回调是通知**\n2. 用户进程发起一个IO请求操作，通过**系统调用sigaction**，给对应的Socket**注册**一个**信号回调**\n    - 此时**不阻塞用户进程**，用户进行继续工作\n3. 当**内核数据就绪**时，操作系统**内核**为**该进程**生成一个**SIGIO信号**，通过信号回调通知进程进行相关IO操作\n4. 相比于前三种IO模型，在**等待数据就绪时进程不被阻塞**，主循环可以继续工作，**性能更佳**\n5. 但对于**TCP**来说，信号驱动式IO**几乎没有被使用**\n    - 因为SIGIO信号是一种**UNIX信号**，**没有附加信息**\n    - 如果一个信号源有多种产生信号的原因，信号接收者无法确定实际发生了什么\n    - 而TCP Socket生产的信号事件有**七种**之多，进程收到SIGIO信号后也根本没法处理\n6. 而对于**UDP**来说，信号驱动式IO**已经有所应用**，例如NTP服务器\n    - 因为UDP**只有一个数据请求事件**\n    - 在**正常**情况下，UDP进程只要捕获到SIGIO信号，就调用`recvfrom`读取到达的数据报\n    - 在**异常**情况下，就返回一个异常错误\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-sig.png\" width=800/>\n\n### 异步IO\n1. 虽然信号驱动式IO在等待数据就绪时，不会阻塞进程，但在**被通知后进行的IO操作还是阻塞的**\n    - 进程会_**等待数据从内核空间复制到用户空间**_\n2. 异步IO实现了**真正的非阻塞IO**\n    - 用户进程发起一个IO请求操作，系统会告知内核启动某个操作，并让内核在**整个操作**完成后通知用户进程\n    - 整个操作包括：**等待数据就绪**、_**数据从内核空间复制到用户空间**_\n3. **Linux不支持异步IO**，Windows支持异步IO，因此生产环境中很少用到异步IO模型\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-aio.png\" width=800/>\n\n### Java NIO\n\n#### Selector\nJava NIO使用了**IO复用器Selector**实现**非阻塞IO**，Selector使用的是**IO复用模型**，**Selector是select/poll/epoll的外包类**\n\n#### SelectionKey\nSocket通信中的connect、accept、read/write是**阻塞**操作，分别对应SelectionKey的四个**监听事件**\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-selectionkey.png\" width=800/>\n\n#### 服务端编程\n1. 首先，创建**ServerSocketChannel**，用于**监听客户端连接**\n2. 然后，创建**Selector**，将ServerSocketChannel**注册**到Selector，应用程序会通过Selector来轮询注册在其上的Channel\n    - 当发现有一个或多个Channel处于就绪状态，返回就绪的监听事件，最后进行相关的IO操作\n3. 在创建Selector时，应用程序会根据**操作系统版本**选择使用哪种IO复用函数\n    - **JDK 1.5 + Linux 2.6 -> epoll**\n    - 由于**信号驱动式IO对TCP通信不支持**，以及**Linux不支持异步IO**，因此大部分框架还是基于**IO复用模型**实现网络通信\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-server.jpg\" width=800/>\n\n```java\n// 功能：向每个接入的客户端发送Hello字符串\n\n// 创建ServerSocketChannel，配置为非阻塞模式\nServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\nserverSocketChannel.configureBlocking(false);\n// 绑定监听\nserverSocketChannel.socket().bind(new InetSocketAddress(8080));\n// 创建单独的IO线程，用于轮询多路复用器Selector\nSelector selector = Selector.open();\n// 创建Selector，将之前创建的serverSocketChannel注册到Selector上，监听OP_ACCEPT\nserverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);\n// 轮询就绪的Channel\nwhile (true) {\n    try {\n        selector.select();\n        Set<SelectionKey> keys = selector.selectedKeys();\n        for (Iterator<SelectionKey> it = keys.iterator(); it.hasNext(); ) {\n            SelectionKey key = it.next();\n            it.remove();\n            try {\n                if (key.isAcceptable()) {\n                    // 新的客户端接入\n                    ServerSocketChannel server = (ServerSocketChannel) key.channel();\n                    SocketChannel client = server.accept();\n                    client.configureBlocking(false);\n                    // 将客户端的Channel注册到Selector上，监听OP_WRITE\n                    client.register(selector, SelectionKey.OP_WRITE);\n                } else if (key.isWritable()) {\n                    SocketChannel client = (SocketChannel) key.channel();\n                    ByteBuffer buffer = ByteBuffer.wrap(\"Hello\".getBytes());\n                    client.write(buffer);\n                    key.cancel();\n                }\n            } catch (IOException e) {\n                key.cancel();\n                try {\n                    key.channel().close();\n                } catch (IOException ignored) {\n                }\n            }\n        }\n    } catch (IOException e) {\n        break;\n    }\n}\n```\n\n## 零拷贝\n1. 在**IO复用模型**中，执行**读写IO**操作依然是**阻塞**的，并且存在多次**内存拷贝**和**上下文切换**，增加**性能开销**\n2. 零拷贝是一种**避免多次内存复制**的技术，用来**优化读写IO操作**\n3. 在网络编程中，通常由read、write来完成一次IO读写操作，每次IO读写操作都需要完成**4次内存拷贝**\n    - 路径：_**IO设备 -> 内核空间 -> 用户空间 -> 内核空间 -> 其他IO设备**_\n\n### Linux mmap\n1. Linux内核中的**mmap**函数可以代替read、write的IO读写操作，实现**用户空间和内核空间共享一个缓存数据**\n2. mmap将用户空间的一块地址和内核空间的一块地址_**同时映射到相同的一块物理内存地址**_\n    - 不管是用户空间还是内核空间都是**虚拟地址**，最终都要映射到**物理内存地址**\n3. 这种方式**避免了内核空间与用户空间的数据交换**\n4. IO复用的**epoll**函数也是利用了**mmap**函数**减少了内存拷贝**\n\n### Java NIO\n1. Java NIO可以使用**Direct Buffer**来实现内存的零拷贝\n2. Java直接在**JVM内存之外**开辟一个**物理内存空间**，这样**内核**和**用户进程**都能**共享**一份缓存数据\n\n## 线程模型优化\n1. 一方面**内核**对**网络IO模型**做了优化，另一方面**NIO**在**用户层**也做了优化\n2. NIO是基于**事件驱动**模型来实现IO操作\n3. Reactor模型是**同步IO事件处理**的一种常见模型\n    - 将IO事件**注册**到多路复用器上，一旦有IO事件触发，多路复用器会将事件**分发**到**事件处理器**中，执行就绪的IO事件操作\n\n### Reactor模型的组件\n1. **事件接收器Acceptor**\n    - 主要负责**接收请求连接**\n2. **事件分离器Reactor**\n    - 接收请求后，会将建立的连接注册到分离器中，依赖于循环监听多路复用器Selector\n    - 一旦监听到事件，就会将事件**分发**到事件处理器\n3. **事件处理器Handler**\n    - 事件处理器主要完成相关的事件处理，比如读写IO操作\n\n### 单线程Reactor\n1. 最开始NIO是基于**单线程**实现的，所有的IO操作都在一个NIO线程上完成\n2. 由于NIO是**非阻塞IO**，理论上一个线程可以完成所有IO操作\n3. 但NIO并**没有真正实现非阻塞IO**，因为**读写IO**操作时用户进程还是处于**阻塞**状态\n4. 在高并发场景下会存在**性能瓶颈**，一个NIO线程也无法支撑**C10K**\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-reactor-single-thread.png\" width=800/>\n\n### 多线程Reactor\n1. 为了解决单线程Reactor在高并发场景下的性能瓶颈，后来采用了**线程池**\n2. 在**Tomcat**和**Netty**中都使用了**一个Acceptor线程**来监听连接请求事件\n    - 当连接成功后，会将建立的连接注册到多路复用器中，一旦监听到事件，将交给**Worker线程池**来负责处理\n    - 在大多数情况下，这种线程模型可以满足性能要求，但如果连接的客户端很多，一个Acceptor线程也会存在性能瓶颈\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-reactor-multi-thread.png\" width=800/>\n\n### 主从Reactor\n1. 现在主流通信框架中的**NIO通信框架**都是基于**主从Reactor线程模型**来实现的\n2. 主从Reactor：Acceptor不再是一个单独的NIO线程，而是一个**线程池**\n    - Acceptor接收到客户端的TCP连接请求，建立连接后，后续的IO操作将交给Worker线程处理\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-reactor-master-slave.png\" width=800/>\n\n### Tomcat\n\n#### 原理\n1. 在Tomcat中，BIO和NIO是基于**主从Reactor线程模型**实现的\n2. 在**BIO**中，Tomcat中的Acceptor只负责监听新的连接，一旦连接建立，监听到IO操作，就会交给Worker线程处理\n3. 在**NIO**中，Tomcat新增一个**Poller线程池**\n    - Acceptor监听到连接后，不是直接使用Worker线程处理请求，而是先将请求发送给**Poller缓冲队列**\n    - 在Poller中，维护了一个**Selector对象**，当Poller从缓冲队列中取出连接后，注册到该Selector中\n    - 然后，通过遍历Selector，找出其中就绪的IO操作，并交给Worker线程处理\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-nio-tomcat.png\" width=800/>\n\n#### 配置参数\n1. **acceptorThreadCount**\n    - Acceptor的线程数量，默认1\n2. **maxThreads**\n    - 专门处理IO操作的Worker线程数量，默认200（不一定越大越好）\n3. **acceptCount**\n    - Acceptor线程负责从**accept队列**中取出连接，然后交给Worker线程处理\n    - acceptCount指的是**accept队列的大小**\n    - 当HTTP**关闭Keep Alive**，并发量会增大，可以适当调大该值\n    - 当HTTP**开启Keep Alive**，而Worker线程数量有限，并且有可能被长时间占用，**连接在accept队列中等待超时**\n        - 如果accept队列过大，很容易造成连接浪费\n4. **maxConnections**\n    - 表示可以有多少个Socket连接到Tomcat上，默认10000\n    - 在**BIO**模式中，一个线程只能处理一个连接，一般maxThreads与maxConnections的值相同\n    - 在**NIO**模式中，一个线程可以同时处理多个连接，maxThreads应该比maxConnections大很多\n","tags":["Reactor"],"categories":["Performance"]},{"title":"架构 -- 概念","url":"%2F2019%2F08%2F11%2Farchitecture-concept%2F","content":"\n## 系统 / 子系统\n1. 系统：由一群**有关联**的个体组成，根据某种**规则**运作，能完成个别元件不能单独完成的工作的群体（体现**系统能力**）\n2. 子系统：由一群**有关联**的个体所组成的系统，多半会是**更大系统中的一部分**\n3. 子系统的定义和系统的定义是一致的，只是**观察的角度**有差异\n\n<!-- more -->\n\n## 模块 / 组件\n1. 模块（**Module**）和组件（**Component**）都是系统的**组成部分**，只是**从不同的角度来拆分系统**\n2. 从**逻辑角度**来拆分系统，得到的单元是**模块**；从**物理角度**来拆分系统，得到的单元是**组件**\n3. 划分**模块**的主要目的是**职责分离**，划分**组件**的主要目的是**单元复用**\n4. 样例：学生信息管理系统\n    - 逻辑角度：登录注册模块、个人信息模块、个人成绩模块\n    - 物理角度：Nginx、Tomcat、MySQL\n\n## 框架 / 架构\n1. 框架（**Framework**）\n    - 框架是**组件规范**，如MVC是常见的开发规范\n    - 框架是**提供基础功能的产品**，如Spring MVC是MVC开发框架\n        - 除了满足MVC的规范外，Spring还提供了很多基础功能（Spring Security，Spring JPA等）\n2. 架构（**Architecture**）\n    - 架构是软件系统的**基础结构**，创建这些基础结构的准则，以及对这些结构的描述\n    - 但基础结构这个概念，并没有明确说从什么角度来分解，采用不同的角度或者维度，可以将系统划分为不同的结构\n        - 逻辑角度（模块）、物理角度（组件）、开发规范角度（MVC框架）\n        - [架构蓝图--软件架构 \"4+1\" 视图模型](https://www.ibm.com/developerworks/cn/rational/r-4p1-view/index.html)\n3. 框架关注的是**规范**，而架构关注的是**结构**\n","tags":["Architecture"],"categories":["Architecture"]},{"title":"数据结构与算法 -- 栈","url":"%2F2019%2F08%2F10%2Fdata-structure-algorithm-stack%2F","content":"\n## 实现\n1. 栈即可以用**数组**实现，也可以用**链表**实现\n2. 用**数组**实现的栈，称为**顺序栈**，用**链表**实现的栈，称为**链式栈**\n\n<!-- more -->\n\n### 顺序栈\n```java\npublic class ArrayStack<T> {\n    private Object[] items;\n    @Getter\n    private int count;\n    @Getter\n    private int size;\n\n    public ArrayStack(int n) {\n        items = new Object[n];\n        count = 0;\n        size = n;\n    }\n\n    public boolean push(T t) {\n        if (count == size) {\n            return false;\n        }\n        items[count++] = t;\n        return true;\n    }\n\n    public T pop() {\n        if (count == 0) {\n            return null;\n        }\n        return (T) items[--count];\n    }\n}\n```\n\n## 复杂度分析\n1. 不管是顺序栈还是链式栈，存储数据只需要大小为n的数组即可\n    - 在入栈和出栈的过程中，只需要固定的临时变量存储空间，所以**空间复杂度**为**`O(1)`**\n    - n个空间是必须的，无法省掉，因此空间复杂度指的是除了原本的数据存储空间外，算法运行还需要**额外的存储空间**\n2. 不管是顺序栈还是链式栈，入栈和出栈只涉及个别数据的操作，所以**时间复杂度**为**`O(1)`**\n\n## 动态扩容\n1. 实现一个支持动态扩容的顺序栈，只需要底层依赖一个**支持动态扩容的数组**即可\n2. 出栈操作\n    - 对于出栈操作来说，不会涉及到内存重新申请和数据搬移，所以出栈的时间复杂度依然为`O(1)`\n3. 入栈操作\n    - 当空间不够时，需要重新申请内存和数据搬移，时间复杂度变成了`O(n)`\n    - 因此，最好时间复杂度为`O(1)`，最坏时间复杂度为`O(n)`，而平均时间复杂度可以用**摊还分析法**来分析\n\n### 摊还分析法\n1. 假设\n    - 栈空间不够时，重新申请一个原来大小2倍的数组\n    - 为了简化分析，只有入栈操作，没有出栈操作\n    - 不涉及内存搬移的入栈操作，时间复杂度为`O(1)`\n2. 当前栈大小为K，并且已满，再有新数据要入栈时，需要申请2倍大小的内存，做K个数据的搬移操作，再入栈\n    - 但后续的K-1次入栈操作，均无需重新申请内存和搬移数据\n    - 因此，K次入栈操作，总共涉及了K次数据搬移，和K次简单入栈\n        - 均摊后，每次入栈操作包括一次数据搬移和一次简单入栈，这样时间复杂度依然为`O(1)`\n3. 大部分情况下，_**均摊时间复杂度 = 最好时间复杂度**_\n","tags":["Stack"],"categories":["Data Structure & Algorithm"]},{"title":"Kafka -- 无消息丢失","url":"%2F2019%2F08%2F09%2Fkafka-no-msg-loss%2F","content":"\n## 持久化保证\n1. Kafka只对**已提交的消息**做**有限度的持久化保证**\n2. **已提交的消息**\n    - 当Kafka的**若干个Broker**成功地**接收**到一条消息并**写入到日志文件**后，会告诉生产者这条消息已经成功提交\n3. **有限度的持久化保证**\n    - Kafka不保证在任何情况下都能做到不丢失消息，例如机房着火等极端情况\n\n<!-- more -->\n\n## 消息丢失\n\n### 生产者丢失\n1. 目前Kafka Producer是**异步**发送消息的，`Producer.send(record)`立即返回，但不能认为消息已经发送成功\n2. 丢失场景：网络抖动，导致消息没有到达Broker；消息太大，超过Broker的承受能力，Broker拒收\n3. 解决方案：Producer永远要使用带有**回调通知**的发送API，即**`Producer.send(record, callback)`**\n    - callback能够准确地告知Producer消息是不是真的提交成功，一旦出现消息提交失败，可以进行针对性的处理\n\n### 消费者丢失\n1. Consumer端丢失数据主要体现在**Consumer端要消费的消息不见了**\n2. Consumer程序有**位移**的概念，表示**该Consumer当前消费到Topic分区的位置**\n3. 丢失原因：Consumer接收一批消息后，在未处理完所有消息之前，就直接更新位移\n4. 解决方案：**先消费消息，再更新位移**\n    - 这种方式能最大限度地保证消息不丢失，但带来了**重复消息**的问题，因此Consumer需要支持**幂等**\n5. 如果采用**多线程异步处理消息**，Consumer程序要关闭自动提交位移，由应用程序**手动提交位移**\n\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-loss-msg-consumer.png\" width=600/>\n\n## 最佳实践\n\n### Producer\n1. 使用带有**回调**的发送API：`Producer.send(record, callback)`\n2. `acks = all`，表示**所有Broker**都要接收到，该消息才算是**已提交**\n3. 将`retries`设置为一个**较大的值**，Producer**自动重试**的次数\n\n### Broker\n1. `unclean.leader.election.enable = false`，控制哪些Broker有资格竞选分区Leader\n    - 如果一个落后很多的Broker也能参与竞选并且成为新的Leader，必然会造成**消息丢失**\n2. `replication.factor >= 3`，将消息多保存几份副本，目前防止消息丢失的主要机制是**冗余**\n3. `min.insync.replicas > 1`，消息至少被写入多少个**副本**才算已提交，生产环境中不能使用默认值1\n4. `replication.factor > min.insync.replicas`，如果两者相等，只要有一个副本宕机，整个**分区**就无法正常工作了\n    - 应该在**不降低可用性**的基础上，改善消息的持久性，防止数据丢失\n    - 推荐设置为**`replication.factor = min.insync.replicas + 1`**\n\n### Consumer\n1. `enable.auto.commit = false`，确保消息消费完再手动提交\n","tags":["Stream"],"categories":["Kafka"]},{"title":"Spring -- JDBC异常","url":"%2F2019%2F08%2F08%2Fspring-jdbc-exception%2F","content":"\n## JDBC异常抽象\nSpring会将**数据操作的异常**转换为**DataAccessException**\n<img src=\"https://spring-1253868755.cos.ap-guangzhou.myqcloud.com/spring-jdbc-exception.png\" width=1000/>\n\n## 解析错误码\n1. **SQLErrorCodeSQLExceptionTranslator**\n2. ErrorCode定义\n    - org/springframework/jdbc/support/**sql-error-codes.xml**\n    - classpath下的**sql-error-codes.xml**（定制）\n\n<!-- more -->\n\norg/springframework/jdbc/support/sql-error-codes.xml\n> Default SQL error codes for well-known databases. Can be overridden by definitions in a \"sql-error-codes.xml\" file in the root of the class path.\n\n```xml\n<bean id=\"H2\" class=\"org.springframework.jdbc.support.SQLErrorCodes\">\n    <property name=\"badSqlGrammarCodes\">\n        <value>42000,42001,42101,42102,42111,42112,42121,42122,42132</value>\n    </property>\n    <property name=\"duplicateKeyCodes\">\n        <value>23001,23505</value>\n    </property>\n    <property name=\"dataIntegrityViolationCodes\">\n        <value>22001,22003,22012,22018,22025,23000,23002,23003,23502,23503,23506,23507,23513</value>\n    </property>\n    <property name=\"dataAccessResourceFailureCodes\">\n        <value>90046,90100,90117,90121,90126</value>\n    </property>\n    <property name=\"cannotAcquireLockCodes\">\n        <value>50200</value>\n    </property>\n</bean>\n\n<bean id=\"MySQL\" class=\"org.springframework.jdbc.support.SQLErrorCodes\">\n    <property name=\"databaseProductNames\">\n        <list>\n            <value>MySQL</value>\n            <value>MariaDB</value>\n        </list>\n    </property>\n    <property name=\"badSqlGrammarCodes\">\n        <value>1054,1064,1146</value>\n    </property>\n    <property name=\"duplicateKeyCodes\">\n        <value>1062</value>\n    </property>\n    <property name=\"dataIntegrityViolationCodes\">\n        <value>630,839,840,893,1169,1215,1216,1217,1364,1451,1452,1557</value>\n    </property>\n    <property name=\"dataAccessResourceFailureCodes\">\n        <value>1</value>\n    </property>\n    <property name=\"cannotAcquireLockCodes\">\n        <value>1205</value>\n    </property>\n    <property name=\"deadlockLoserCodes\">\n        <value>1213</value>\n    </property>\n</bean>\n```\n\norg.springframework.jdbc.support.SQLErrorCodes\n```java\npublic class SQLErrorCodes {\n\n\t@Nullable\n\tprivate String[] databaseProductNames;\n\tprivate boolean useSqlStateForTranslation = false;\n\tprivate String[] badSqlGrammarCodes = new String[0];\n\tprivate String[] invalidResultSetAccessCodes = new String[0];\n\tprivate String[] duplicateKeyCodes = new String[0];\n\tprivate String[] dataIntegrityViolationCodes = new String[0];\n\tprivate String[] permissionDeniedCodes = new String[0];\n\tprivate String[] dataAccessResourceFailureCodes = new String[0];\n\tprivate String[] transientDataAccessResourceCodes = new String[0];\n\tprivate String[] cannotAcquireLockCodes = new String[0];\n\tprivate String[] deadlockLoserCodes = new String[0];\n\tprivate String[] cannotSerializeTransactionCodes = new String[0];\n\t@Nullable\n\tprivate CustomSQLErrorCodesTranslation[] customTranslations;\n\t@Nullable\n\tprivate SQLExceptionTranslator customSqlExceptionTranslator;\n}\n```\n\n## 定制错误码\n\n### 项目路径\n```\n└── src\n    ├── main\n    │   ├── java\n    │   │   └── me\n    │   │       └── zhongmingmao\n    │   │           └── jdbcexception\n    │   │               ├── CustomDuplicateKeyException.java\n    │   │               └── JdbcExceptionApplication.java\n    │   └── resources\n    │       ├── application.properties\n    │       ├── schema.sql\n    │       └── sql-error-codes.xml\n    └── test\n        └── java\n            └── me\n                └── zhongmingmao\n                    └── jdbcexception\n                        └── JdbcExceptionApplicationTests.java\n\n```\n\n### sql-error-codes.xml\nsrc/main/resources/sql-error-codes.xml\n```xml\n<beans>\n    <bean id=\"H2\" class=\"org.springframework.jdbc.support.SQLErrorCodes\">\n        <property name=\"badSqlGrammarCodes\">\n            <value>42000,42001,42101,42102,42111,42112,42121,42122,42132</value>\n        </property>\n        <property name=\"duplicateKeyCodes\">\n            <value>23001,23505</value>\n        </property>\n        <property name=\"dataIntegrityViolationCodes\">\n            <value>22001,22003,22012,22018,22025,23000,23002,23003,23502,23503,23506,23507,23513</value>\n        </property>\n        <property name=\"dataAccessResourceFailureCodes\">\n            <value>90046,90100,90117,90121,90126</value>\n        </property>\n        <property name=\"cannotAcquireLockCodes\">\n            <value>50200</value>\n        </property>\n\n        <!-- 定制：错误码为23001或23505时，不会抛出Spring的DuplicateKeyException，而是抛出CustomDuplicateKeyException -->\n        <property name=\"customTranslations\">\n            <bean class=\"org.springframework.jdbc.support.CustomSQLErrorCodesTranslation\">\n                <property name=\"errorCodes\" value=\"23001,23505\"/>\n                <property name=\"exceptionClass\" value=\"me.zhongmingmao.jdbcexception.CustomDuplicateKeyException\"/>\n            </bean>\n        </property>\n    </bean>\n</beans>\n```\n\n### CustomDuplicateKeyException\n```java\npublic class CustomDuplicateKeyException extends DuplicateKeyException {\n    public CustomDuplicateKeyException(String msg) {\n        super(msg);\n    }\n\n    public CustomDuplicateKeyException(String msg, Throwable cause) {\n        super(msg, cause);\n    }\n}\n```\n\n### 单元测试\n```java\n@RunWith(SpringRunner.class)\n@SpringBootTest\npublic class JdbcExceptionApplicationTests {\n\n    @Autowired\n    private JdbcTemplate jdbcTemplate;\n\n    @Test(expected = CustomDuplicateKeyException.class)\n    public void testThrowCustomDuplicateKeyException() {\n        jdbcTemplate.execute(\"INSERT INTO PERSON (ID, NAME) VALUES ('1', 'zhongmingmao')\");\n        jdbcTemplate.execute(\"INSERT INTO PERSON (ID, NAME) VALUES ('1', 'zhongmingwu')\");\n    }\n}\n```\n","tags":["JDBC"],"categories":["Spring Boot"]},{"title":"Java性能 -- 优化RPC网络通信","url":"%2F2019%2F08%2F07%2Fjava-performance-rpc-network-opt%2F","content":"\n## 服务框架的核心\n1. 大型服务框架的核心：**RPC通信**\n2. 微服务的核心是**远程通信**和**服务治理**\n    - 远程通信提供了**服务之间通信的桥梁**，服务治理提供了**服务的后勤保障**\n3. 服务的拆分增加了**通信的成本**，因此**远程通信**很容易成为**系统瓶颈**\n    - 在满足一定的服务治理需求的前提下，对**远程通信的性能**需求是技术选型的**主要影响因素**\n4. 很多**微服务框架**中的服务通信是基于**RPC通信**实现的\n    - 在没有进行组件扩展的前提下，Spring Cloud是基于Feign组件实现RPC通信（基于**HTTP+JSON**序列化）\n    - Dubbo是基于**SPI**扩展了很多RPC通信框架，包括RMI、Dubbo、Hessian等（默认为**Dubbo+Hessian**序列化）\n\n<!-- more -->\n\n### 性能测试\n基于Dubbo:2.6.4，**单一TCP长连接+Protobuf**（响应时间和吞吐量更优），**短连接的HTTP+JSON序列化**\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-rpc-benchmark-rt.jpg\" width=1000/>\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-rpc-benchmark-tps.jpg\" width=1000/>\n\n## RPC通信\n\n### 架构演化\n无论是微服务、SOA、还是RPC架构，都是**分布式服务架构**，都需要实现**服务之间的互相通信**，通常把这种通信统称为**RPC通信**\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-rpc-architecture-evolution.jpg\" width=1000/>\n\n### 概念\n1. RPC：Remote Process Call，**远程服务调用**，通过网络请求远程计算机程序服务的通信技术\n2. RPC框架封装了**底层网络通信**和**序列化**等技术\n    - 只需要在项目中引入**各个服务的接口包**，就可以在代码中调用RPC服务（如同调用**本地方法**一样）\n\n### RMI\n1. RMI：Remote Method Invocation\n2. RMI是**JDK自带**的RPC通信框架，已经成熟地应用于**EJB**和**Spring**，是**纯Java**网络分布式应用系统的核心解决方案\n3. RMI实现了一台虚拟机应用对远程方法的调用可以同对本地方法调用一样，RMI封装好了远程通信的具体细节\n\n#### 实现原理\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-rpc-rmi-principle.jpg\" width=1000/>\n\n1. RMI**远程代理对象**是RMI中**最核心**的组件，除了对象本身所在的虚拟机，其他虚拟机也可以调用此对象的方法\n2. 这些虚拟机可以分布在**不同的主机**上，通过远程代理对象，远程应用可以用网络协议和服务进行通信\n\n#### 高并发下的性能瓶颈\n1. **Java默认序列化**\n    - RMI的序列化方式采用的是Java默认序列化，**性能不好**，而且**不支持跨语言**\n2. **TCP短连接**\n    - RMI是基于**TCP短连接**实现的，在高并发情况下，大量请求会带来大量TCP连接的**创建**和**销毁**，**非常消耗性能**\n3. **阻塞式网络IO**\n    - Socket编程中使用**传统的IO模型**，在高并发场景下基于**短连接**实现的网络通信就很容易产生**IO阻塞**，**性能将大打折扣**\n\n### 优化路径\n\n#### TCP / UDP\n1. 网络传输协议有**TCP**和**UDP**，两个协议都是基于Socket编程\n2. 基于TCP协议实现的Socket通信是**有连接**的\n    - 传输数据要通过**三次握手**来实现数据传输的**可靠性**，而传输数据是**没有边界**的，采用的是**字节流**模式\n3. 基于UDP协议实现的Socket通信，客户端不需要建立连接，只需要创建一个套接字发送数据给服务端\n    - 基于UDP协议实现的Socket通信具有**不可靠性**\n    - UDP发送的数据采用的是**数据报**模式，每个UDP的数据报都有一个长度，该长度与数据一起发送到服务端\n4. 为了保证**数据传输的可靠性**，通常情况下会采用**TCP协议**\n    - 在局域网且对数据传输的可靠性没有要求的情况下，可以考虑使用UDP协议，UDP协议的效率比TCP协议高\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-rpc-tcp-udp.jpg\" width=1000/>\n\n#### 长连接\n1. 服务之间的通信不同于客户端与服务端之间的通信\n2. 由于客户端数量众多，基于**短连接**实现请求，可以避免长时间地占用连接，导致系统资源浪费\n3. 服务之间的通信，连接的消费端不会像客户端那么多，但消费端向服务端请求的数量却一样多\n    - 基于**长连接**实现，可以省去大量建立TCP连接和关闭TCP连接的操作，从而**减少系统的性能消耗**，节省时间\n\n#### 优化Socket通信\n1. 传统的Socket通信主要存在**IO阻塞，线程模型缺陷以及内存拷贝**等问题，Netty4对Socket通信编程做了很多方面的优化\n2. 实现**非阻塞IO**：多路复用器**Selector**实现了非阻塞IO通信\n3. 高效的**Reactor线程模型**\n    - Netty使用了**主从Reactor多线程模型**\n    - **主线程**：用于客户端的**连接**请求操作，一旦连接建立成功，将会**监听IO事件**，监听到事件后会创建一个**链路请求**\n    - 链路请求将会注册到负责IO操作的**IO工作线程**上，由IO工作线程负责后续的IO操作\n    - Reactor线程模型解决了在**高并发**的情况下，由于单个NIO线程无法监听海量客户端和满足大量IO操作造成的问题\n4. **串行设计**\n    - 服务端在接收消息之后，存在着编码、解码、读取和发送等**链路**操作\n    - 如果这些操作基于**并行**实现，无疑会导致**严重的锁竞争**，进而导致系统的**性能下降**\n    - 为了提升性能，Netty采用**串行无锁化**完成链路操作，提供了**Pipeline**，实现链路的各个操作在运行期间**不会切换线程**\n5. **零拷贝**\n    - 数据从**内存**发到**网络**中，存在**两次拷贝**，先是从**用户空间**拷贝到**内核空间**，再从**内核空间**拷贝到**网络IO**\n    - NIO提供的ByteBuffer可以使用**Direct Buffer**模式\n        - 直接开辟一个**非堆物理内存**，不需要进行字节缓冲区的二次拷贝，可以**直接将数据写入到内核空间**\n6. 优化**TCP参数**配置，提高**网络吞吐量**，Netty可以基于ChannelOption来设置\n    - **TCP_NODELAY**：用于控制是否开启**Nagle算法**\n        - Nagle算法通过**缓存**的方式将小的数据包组成一个大的数据包，从而**避免大量发送小的数据包**，导致**网络阻塞**\n        - 在对**时延敏感**的应用场景，可以选择**关闭**该算法\n    - **SO_RCVBUF** / **SO_SNDBUF**：Socket**接收缓冲区**和**发送缓冲区**的大小\n    - **SO_BACKLOG**：指定**客户端连接请求缓冲队列的大小**\n        - 服务端处理客户端**连接请求**是**按顺序**处理的，_**同一时间只能处理一个客户端连接**_\n        - 当有多个客户端进来的时候，服务端将不能处理的客户端连接请求放在队列中等待处理\n    - **SO_KEEPALIVE**\n        - 连接会检查**长时间没有发送数据的客户端的连接状态**，检测到客户端断开连接后，服务端将**回收**该连接\n        - 将该值设置得小一些，可以提高回收连接的效率\n\n#### 定制报文格式\n1. 设计一套报文，用于描述具体的校验、操作、传输数据等内容\n2. 为了提高传输效率，可以根据实际情况来设计，尽量实现**报体小，满足功能，易解析**等特性\n\n| 字段 | 长度（字节） | 备注 |\n| ---- | ---- | ---- |\n| 魔数 | 4 | **协议的标识**，类似于字节码的魔数，通常为固定数字 |\n| 版本号 | 1 | |\n| 序列化算法 | 1 | Protobuf / Thrift |\n| 指令 | 1 | 类似于HTTP中的增删改查 |\n| 数据长度 | 4 | |\n| 数据 | N | |\n\n#### 编解码\n1. 实现一个通信协议，需要**兼容优秀的序列化框架**\n2. 如果只是单纯的数据对象传输，可以选择性能相对较好的**Protobuf序列化**，有利于提高网络通信的性能\n\n#### Linux的TCP参数设置\n三次握手\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-rpc-3-way-handshake.jpg\" width=600/>\n\n四次挥手\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-rpc-4-way-handshake.jpg\" width=600/>\n\n| 配置项 | 备注 |\n| ---- | ---- |\n| fs.file-max = 194448 / ulimit | Linux默认**单个进程**可以打开的文件数量上限为1024，Socket也是文件  |\n| net.ipv4.tcp_keepalive_time | 与Netty的**SO_KEEPALIVE**配置项的作用一致 |\n| net.ipv4.tcp_max_syn_backlog | **SYN队列的长度**，加大队列长度，可以容纳更多**等待连接**的网络连接数 |\n| net.ipv4.ip_local_port_range | 客户端连接服务器时，需要动态分配源端口号，该配置项表示**向外连接的端口范围** |\n| net.ipv4.tcp_max_tw_buckets | 1. 当一个连接关闭时，TCP会通过**四次挥手**来完成一次关闭连接操作，在请求量比较大的情况下，消费端会有大量**TIME_WAIT**状态的连接<br/>2. 该参数可以限制TIME_WAIT状态的连接数量，如果TIME_WAIT的连接数量超过该值，TIME_WAIT将会立即被清除掉并打印警告信息 |\n| net.ipv4.tcp_tw_reuse | 1. 客户端每次连接服务器时，都会获得一个**新的源端口**以实现**连接的唯一性**，在TIME_WAIT状态的连接数量过大的情况下，会增加端口号的占用时间<br/>2. 由于处于TIME_WAIT状态的连接属于**关闭**连接，所以新创建的连接可以**复用**该端口号 |\n","tags":["Network"],"categories":["Performance"]},{"title":"数据结构与算法 -- 链表","url":"%2F2019%2F08%2F06%2Fdata-structure-algorithm-linked-list%2F","content":"\n## 链表\n\n### 单链表\n1. 数组需要一块**连续**的内存空间来存储，而链表并不需要，而是通过**指针**将一组零散的内存块串联起来\n2. 为了将所有结点串起来，每个链表的结点除了存储**数据**之外，还需要记录**下一个结点的地址**\n    - 将记录下个结点地址的指针称为**后继指针next**\n3. 有两个结点比较特殊，分别是第一个结点和第二个结点，习惯性地称为**头结点**和**尾结点**\n    - 头结点用来记录链表的基地址\n    - 尾结点的指针指向的不是下一个结点，而是指向一个空地址**NULL**，表示这是链表上的最后一个结点\n\n<!-- more -->\n\n#### 插入 + 删除\n1. 数组的插入和删除操作，为了保持内存数据的**连续性**，需要做大量的**数据搬移**，时间复杂度为**`O(n)`**\n2. 链表的插入和删除操作，并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的\n    - 因此在链表中插入和删除一个数据是非常快速的，只需要考虑**相邻结点的指针变化**，时间复杂度为**`O(1)`**\n\n#### 随机访问\n1. 链表中的数据并非连续存储，无法像数组那样，根据**首地址**和**下标**，通过**寻址公式**直接计算出对应的内存地址\n2. 而是需要根据指针一个结点一个结点地**依次遍历**，直到找到相应的结点，时间复杂度为**`O(n)`**\n\n### 循环链表\n1. 循环链表是一种**特殊的单链表**，单链表的尾结点指向空地址NULL，而循环链表的**尾结点指针指向链表的头结点**\n2. 与单链表相比，循环链表的优点是从链尾到链头比较方便，当要处理的数据具有**环型结构**特点时，适合采用循环链表\n\n### 双向链表\n1. 单向链表只有一个方向，结点只有一个**后继指针next**指向后面的结点\n2. 双向链表支持两个方向，每个结点除了有**后继指针next**指向后面的结点，还有**前驱结点prev**指向前面的结点\n3. 双向链表需要额外的空间来储存**后继结点**和**前驱结点**的地址，比单链表占用更多的内存空间，但支持**双向遍历**，**更加灵活**\n4. 双向链表**查找前驱结点**的时间复杂度为`O(1)`，在某些场景下，双向链表的插入和删除操作要比单链表简单高效\n5. 在实际的软件开发中，虽然双向链表占用更多的内存，但还是比单链表有**更广的应用**，体现了**空间换时间**的设计思想\n\n#### 插入 + 删除\n1. 删除结点中“值等于某个给定值”的结点\n    - 不管单链表还是双向链表，都需要从头结点开始一个一个依次**遍历对比**，直到找到的值等于给定值的结点\n    - 单纯的删除操作的时间复杂度为`O(1)`，但遍历查找的时间复杂度为`O(n)`，因此总的时间复杂度为`O(1)`\n2. 删除给定指针指向的结点\n    - 此时已经找到要删除的结点，但删除某个结点需要知道其**前驱结点**，而单链表并不支持直接获取前驱结点\n        - 所以，单链表为了找到前驱结点，还是需要从头结点开始**遍历**链表\n        - 而双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历\n    - 在这种场景下，使用单链表的时间复杂度为`O(n)`，而使用双向链表的时间复杂度为`O(1)`\n3. 同理，在链表中某个指定结点的**前面**插入一个结点，使用双向链表的时间复杂度为`O(1)`，而使用单链表的时间复杂度`O(1)`\n\n#### 查找\n1. 对于一个**有序链表**，双向链表**按值查询**的效率也要比单链表要高一些\n2. 可以记录上次查找的位置，每次查询时，根据情况决定往前查找还是往后查找，平均只需要查找**一半**的数据\n\n## 对比数组\n\n### 时间复杂度\n| 操作 | 数组 | 链表 |\n| ---- | ---- | ---- |\n| 插入/删除 | O(n) | O(1) |\n| 随机访问 | O(1) | O(n) |\n\n### CPU缓存\n1. 数组使用**连续**的内存空间，可以利用**CPU的缓存机制**，预读数组中的数据，**访问效率更高**\n2. 链表在内存中并不是连续存储，对CPU缓存**不友好**，没办法有效预读\n\n### 固定大小\n1. 数组的缺点是大小固定，一经声明就要占用**整块连续**内存空间\n    - 如果声明**过大**，系统就没有足够的连续内存空间来分配，导致**内存不足**\n    - 如果声明**过小**，就有可能出现不够用的情况，这时只能再申请一个更大的内存空间，把原数组**拷贝**过去，**非常耗时**\n2. 链表本身没有大小的限制，**天然支持动态扩容**，这是与数组最大的区别\n3. 如果程序对内存大小非常敏感，数组会是更优的选择\n\n## LRU缓存\n1. 维护一个**有序单链表**，越靠近尾部的结点是越早之前访问的，当有一个新的数据被访问时，从链表头开始遍历**链表**\n2. 如果此数据之前已经被缓存在链表中，遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部\n3. 如果此数据没有缓存在链表中，分为两种情况\n    - 如果此时缓存未满，则将此结点直接插入到链表头部\n    - 如果此时缓存已满，则将链表尾结点删除，并将新结点插入到链表头部\n4. 不管缓存有没有满，都需要**遍历**链表，时间复杂度为**`O(n)`**\n\n## 技巧\n\n### 哨兵\n\n#### 插入\n单链表中，在结点p后插入一个新节点\n```java\n// p有可能为null，例如空链表时，p == head == null\nnewNode.setNext(p.getNext());\np.setNext(newNode);\n```\n\n如果要插入**第一个结点**（空链表），上面代码就不通用了，需要**特殊处理**，head表示链表头结点\n```java\nif (head == null) {\n    head = newNode;\n}\n```\n\n#### 删除\n单链表中，删除结点p的后继结点\n```java\n// p.getNext()有可能为null，例如链表只有一个结点时，p == head\np.setNext(p.getNext().getNext());\n```\n\n如果要删除**最后一个结点**（链表中只有一个结点），上面代码也不通用了，需要**特殊处理**\n```java\nif (head.getNext() == null) {\n    head = null;\n}\n```\n\n#### 哨兵\n1. 针对链表的插入和删除操作，需要对**插入第一个节点**和**删除最后一个结点**的情况进行**特殊处理**，**不简洁且容易出错**\n2. 哨兵用于解决**边界问题**，不直接参与业务逻辑\n3. 引入**哨兵结点**（不存储数据），不管链表是不是为空，**head指针都会一直指向哨兵结点**，有哨兵结点的链表叫作**带头链表**\n4. 引入哨兵结点后，可以**统一**代码实现\n\n### 边界条件\n1. 链表为**空**\n2. 链表只包含**1个结点**\n3. 链表只包含**2个结点**\n4. 处理**头结点**和**尾结点**\n\n## 常见链表操作\n```java\n@Data\n@NoArgsConstructor\n@AllArgsConstructor\npublic class Node<T> {\n    private T data;\n    private Node<T> next;\n}\n```\n\n```java\n@Data\n@NoArgsConstructor\n@AllArgsConstructor\npublic class MyLinkedList<T> {\n    // 哨兵结点\n    private Node<T> head = new Node<>();\n}\n```\n\n### 单链表反转\n```java\npublic void reverse() {\n    Node<T> prev = head;\n    Node<T> cur = head.getNext();\n    Node<T> next;\n    while (cur != null) {\n        // 先保留next\n        next = cur.getNext();\n\n        if (cur == head.getNext()) {\n            // 第一个结点\n            cur.setNext(null);\n        } else {\n            cur.setNext(prev);\n        }\n\n        if (next == null) {\n            // 最后一个结点\n            head.setNext(cur);\n        }\n\n        prev = cur;\n        cur = next;\n    }\n}\n```\n\n### 检测链表中的环\n```java\npublic boolean existRing() {\n    Node<T> fast = head;\n    Node<T> slow = head;\n\n    while (fast != null && fast.getNext() != null) {\n        fast = fast.getNext().getNext();\n        slow = slow.getNext();\n        if (slow == fast) {\n            return true;\n        }\n    }\n    return false;\n}\n```\n\n### 合并两个有序链表\n```java\npublic static <T extends Comparable> MyLinkedList<T> merge(MyLinkedList<T> l1, MyLinkedList<T> l2) {\n    Node<T> head = new Node<>();\n    Node<T> cur = head;\n    Node<T> cur1 = l1.getHead().getNext();\n    Node<T> cur2 = l2.getHead().getNext();\n\n    while (cur1 != null || cur2 != null) {\n        // 遍历完l1，只能遍历l2\n        if (cur1 == null) {\n            cur.setNext(cur2);\n            cur = cur.getNext();\n            cur2 = cur2.getNext();\n            continue;\n        }\n        // 遍历完l2，只能遍历l1\n        if (cur2 == null) {\n            cur.setNext(cur1);\n            cur = cur.getNext();\n            cur1 = cur1.getNext();\n            continue;\n        }\n        // l1和l2均未遍历完，比较大小\n        if (cur1.getData().compareTo(cur2.getData()) < 0) {\n            cur.setNext(cur1);\n            cur = cur.getNext();\n            cur1 = cur1.getNext();\n        } else {\n            cur.setNext(cur2);\n            cur = cur.getNext();\n            cur2 = cur2.getNext();\n        }\n    }\n\n    return new MyLinkedList<>(head);\n}\n```\n\n### 删除链表倒数第n个结点\n```java\npublic MyLinkedList<T> deleteItemReverse(int n) {\n    if (n <= 0) {\n        return this;\n    }\n\n    // 先拉开差距\n    Node<T> first = head;\n    Node<T> second = head;\n    for (int i = 0; i < n; i++) {\n        second = second.getNext();\n        if (second == null) {\n            // 链表不够n格结点\n            return this;\n        }\n    }\n\n    // 遍历到尾结点\n    while (second.getNext() != null) {\n        first = first.getNext();\n        second = second.getNext();\n    }\n\n    // 删除\n    first.setNext(first.getNext().getNext());\n    return this;\n}\n```\n\n### 查找链表的中间结点\n```java\npublic T findMiddle() {\n    Node<T> fast = head;\n    Node<T> slow = head;\n\n    while (fast != null && fast.getNext() != null) {\n        fast = fast.getNext().getNext();\n        slow = slow.getNext();\n    }\n\n    return slow.getData();\n}\n```\n","tags":["LinkedList"],"categories":["Data Structure & Algorithm"]},{"title":"网络协议 -- HTTPS","url":"%2F2019%2F08%2F05%2Fnetwork-protocol-https%2F","content":"\n## 加密\n1. 在**对称加密**算法中，加密和解密使用的密钥是**相同**的，因此，对称加密算法要保证安全的话，密钥需要保密\n2. 在**非对称加密**算法中，加密和解密使用的密钥是**不相同**的，一把是**公钥**，一把是**私钥**\n    - 公钥加密的信息，只有私钥才能解密，私钥加密的信息，只有公钥才能解密\n3. 在**效率**和**性能**方面，_**对称加密算法要优于非对称加密算法**_\n<!-- more -->\n\n### 对称加密\n1. 浏览器与服务器约定一个密钥，浏览器发送请求的时候用这个密钥进行加密，服务器用同样的密钥解密\n2. 但如何约定密钥呢？假设用密钥B的来加密密钥A，但又怎么约定密钥B呢，因此这样会陷入**死循环**\n\n### 非对称加密\n1. 非对称加密的私钥放在服务器，不会在网络上传输，保证**私钥的私密性**，而私钥对应的**公钥**是可以在网上**随意传播**的\n2. 浏览器用服务器的公钥加密信息发送给服务器，中间哪怕被黑客截获，也是无法解密的，因为只能用服务端的私钥解密\n    - 但服务器响应的信息却是**所有人**都能解密，因为是用服务器的私钥加密的，用对应的公钥就能够解密 -- 不安全\n4. 另外，如果只有一对公钥私钥，黑客是可以模拟正常的用户行为，因为服务器的**公钥**是公开的\n5. 由此看来，一对公钥私钥是不够的，浏览器也需要自己的公钥和私钥\n    - _**浏览器请求服务器时，用服务器的公钥加密；而服务器响应浏览器时，用浏览器的公钥加密**_\n    - 这样，黑客就没有办法去模拟浏览器去获取信息，或者截取响应消息，因为黑客没有浏览器或服务器的私钥，无法解密\n\n## 数字证书\n1. _**公钥只能解决你是你的问题，但不能解决你是谁的问题，因此需要借助证书**_\n2. 由于所有人都能创建私钥和公钥，因此需要权威部门介入，而**权威部门**颁发的称为**证书**（Certificate）\n3. 证书的内容包括**公钥**、证书的**所有者**、证书的**发布机构**、证书的**有效期**\n4. 生成证书需要发起一个**证书请求**，然后发给一个权威机构（**CA**，Certificate Authority）去认证\n5. 权威机构会用**自身的私钥**给证书签名（**签名算法**）\n\n### 签名证书\n1. 对信息做一个**Hash计算**，得到一个Hash值，这个过程式**不可逆**的\n2. 用**CA的私钥**将这个Hash值**加密**作为一个**签名**，然后和信息一起发出去\n3. 简单表述：_**`signature = encrypt(hash(msg), ca_private_key)`**_\n4. 背书：_**CA用自己的私钥给网站A的公钥签名!!**_\n\nIssuer：谁颁发的；Subject：证书是颁发给谁的；Validity：证书期限，Public Key：公钥内容；Signature Algorithm：签名算法\n```\nopenssl x509 -in server-cert.pem -noout -text\nCertificate:\n    Data:\n        Version: 1 (0x0)\n        Serial Number: 11689652687981033366 (0xa239fd2f6eccb796)\n    Signature Algorithm: sha256WithRSAEncryption\n        Issuer:\n        Validity\n            Not Before: Aug 19 03:53:44 2019 GMT\n            Not After : Aug 18 03:53:44 2020 GMT\n        Subject: CN=zhongmingmao.me\n        Subject Public Key Info:\n            Public Key Algorithm: rsaEncryption\n                Public-Key: (4096 bit)\n                Modulus:\n                    00:be:75:a7:9d:85:c1:a5:d1:e7:d6:59:66:6e:3a:\n                    ...\n                    3a:6a:e9\n                Exponent: 65537 (0x10001)\n    Signature Algorithm: sha256WithRSAEncryption\n         a5:b9:65:10:4e:46:50:1e:3f:b0:ae:3f:bf:a0:88:94:e4:e2:\n         ...\n         c2:ca:81:06:e4:9c:6b:66\n```\n\n### 层层授信\n1. 这样一来，浏览器从网站A得到的不再是一个公钥，而是会得到一个**证书**，该证书会有一个签发机构CA\n2. 只需要得到该签发机构**CA的公钥**，去解密网站A的证书的签名，如果解密成功，Hash也对的上，说明网站的公钥没什么问题\n3. 验证证书的过程中，需要CA的公钥，那如何确定CA公钥是对的？\n    - CA的公钥需要更高级的CA给它签名，然后形成CA证书\n    - 要想知道某个CA的证书是否可靠，需要查看CA的上级证书的公钥，能不能解开这个CA的签名\n    - 这样层层上去，直到rootCA，做最后的背书，通过这种**层层授信背书**的方式，保证**非对称加密**模式的正常运转\n\n## HTTPS的工作模式\n1. 非对称加密在**性能**上不如对称加密\n2. **非对称加密的公钥密钥主要用于传输对称加密的密钥，而真正的大量数据通信通过对称加密完成**\n\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-https.jpg\" width=800/>\n\n1. 登录HTTPS网站时，客户端会首先发送**Client Hello**消息到服务器\n    - 以**明文**传输**TLS版本信息**、**加密套件候选列表**、**压缩算法候选列表**\n    - 另外还会有一个**随机数**，用户后续的**对称密钥协商**\n2. 网站会返回**Server Hello**消息\n    - 告诉客户端，服务器**选择**使用的**协议版本**、**加密套件**、**压缩算法**\n    - 另外还会有一个**随机数**，用户后续的**对称密钥协商**\n3. 网站会发送**Server Certificate**消息，里面包含**服务器端的证书**，最后网站会发送**Server Hello Done**消息\n4. 客户端肯定不会直接信任该证书，于是会从**它自己信任的CA仓库**中，拿**CA证书的公钥**去解密网站的证书\n    - 如果能成功，说明网站是可信的\n    - 这个过程可能会不断地**往上追溯**，直到一个授信的CA\n5. 客户端在验证完服务端的证书后，会计算产生随机数**pre-master**，发送**Client Key Exchange**\n    - 用**服务器证书中的公钥**加密，再发送给服务器，服务器可以通过私钥进行解密\n    - 到目前为止，无论是客户端还是服务器，都已经有了**三个随机数**\n    - 通过这三个随机数，可以在客户端和服务端产生_**相同的对称密钥**_\n6. 计算出对称密钥后，客户端会发送**Change Cipher Spec**消息，表示后面都采用协商的**通信密钥**和**加密算法**进行加密通信\n7. 客户端发送**Encrypted Handshake Message**消息\n    - 将已经商定好的参数，采用**协商密钥**进行加密，发送给服务器用于_**数据和握手验证**_\n8. 服务器也可以发送**Change Cipher Spec**消息和**Encrypted Handshake Message**消息，目的与客户端的一致\n9. 当**双方握手结束后**，就可以用**对称密钥**进行加密传输了\n    - 这个过程除了**加密解密**外，其他过程与HTTP是一样的\n10. 上面的过程只包含了HTTPS的**单向认证**，即客户端验证服务器端的证书\n    - 在对安全要求更严格的场景下，可以启用**双向认证**，即服务器也会验证客户端的证书\n\n### 重放和篡改\n1. **重放**\n    - 有了加密和解密，黑客即使截获了包，也无法打开，但可以选择**重放**\n    - 解决方案：把**Timestamp**和**Nonce随机数**联合起来，做一个**不可逆的签名**\n    - Nonce随机数保证唯一，或者Timestamp和Nonce随机数联合起来保证唯一，同样的请求只接受一次\n    - 服务器多次收到相同的Timestamp和Nonce随机数，则视为无效\n2. **篡改**\n    - 签名是**不可逆**的，相当于具有了**不可篡改性**\n    - 黑客只能修改Timestamp和Nonce随机数，但无法修改签名，服务器用签名算法解出来会发现两者对不上，会直接丢弃\n\n## 小结\n1. 加密分为对称加密和非对称加密\n    - 对称加密**效率高**，但无法解决**密钥传输问题**\n    - 非对称加密可以解决这个问题，但**效率不高**\n2. 非对称加密需要通过**证书**和**权威机构CA**来验证_**服务端公钥的合法性**_\n3. HTTPS是综合了**对称加密**算法和**非对称加密**算法的HTTP协议，既能保证**传输安全**，又能保证**传输效率**\n","tags":["Encryption"],"categories":["Protocol"]},{"title":"网络协议 -- CA证书签署","url":"%2F2019%2F08%2F04%2Fnetwork-protocol-ca%2F","content":"\n## CA签名的价值\n1. 服务器的公钥是公开的，客户端需要自行判断与之通信的服务器是不是公钥的持有人\n2. 假设客户端想要和163.com建立安全连接，需要用某个**公钥**去验证服务器\n    - 公钥是由服务器发送给客户端的，用服务器发送过来的公钥去验证它自己，并不能证明该服务器是163.com的合法代表\n    - _**公钥本身只能证明你是你，但不能证明你是谁**_\n3. 因此，服务器为了让客户端相信自己是163.com，除了提供自身的**公钥**外，还会提供**CA签名**（用**CA私钥**加密的）\n    - CA签名的内容：_**此公钥是163.com的合法代表**_\n    - CA签名的本质：把一个**公钥**和一个**域名**关联起来，解决了**你是谁**的问题\n4. 怎么证明CA签名就是由CA签署的？\n    - **CA公钥也是公开的**，只要用CA公钥去解密CA签名，就能看到里面的具体内容，也能证明是由CA签署的\n5. 怎么证明拿到的CA公钥就能代表CA？\n    - 回到了CA自身的身份无法确定，这种循环的论证有个源头，那就是**根CA**，而**根CA**的公钥一般**内置**在程序中\n    - 对**根CA**，程序是**无条件信任**的\n\n<!-- more -->\n\n## 生成CA私钥\nCA比较重要，所以密钥长度选择为**4096**，**安全性更高**，`-aes256`会要求输入**私钥保护密码**，私钥本身以**密文**保存\n```\n$ openssl genrsa -aes256 -out ca-key.pem 4096\nGenerating RSA private key, 4096 bit long modulus\nEnter pass phrase for ca-key.pem:\nVerifying - Enter pass phrase for ca-key.pem:\n\n$ cat ca-key.pem\n-----BEGIN RSA PRIVATE KEY-----\nProc-Type: 4,ENCRYPTED\nDEK-Info: AES-256-CBC,38908CEC7277A03CA1C41F8C1B04F27C\n\npoLn6xnmwpHEDfNccDLn8wkm4pjeYORTL+UYWBDkPeLycpBAfbpLEKmJVZ5skXDf\n...\n01wIyHRYXBOyZcf8oL3XX9lunFLSmVGfxnLAyeQyuPEAGti2Ejg90qphn1K7ut/+\n-----END RSA PRIVATE KEY-----\n```\n\n### 解密CA私钥\nca.key是一个_**裸私钥**_\n```\n$ openssl rsa -in ca-key.pem -out ca.key\nEnter pass phrase for ca-key.pem:\nwriting RSA key\n\n$ cat ca.key\n-----BEGIN RSA PRIVATE KEY-----\nMIIJJwIBAAKCAgEAwXyEyA/6JVNgnJHqAqk8cZ2Xgh9/SLh/3T6VnfZTzmByHUT6\n...\nPrpFYs0skhhtqrbdP/pod0VD4ZZLIBtmikuJCTw4ZJ7hPCC9KQJCls1HYg==\n-----END RSA PRIVATE KEY-----\n```\n\n### 生成CA公钥\nRSA密钥都是**一对**的，**公钥是根据私钥生成的**，由于RSA的**非对称性**，_**私钥算出公钥很容易，但公钥算出私钥却很难**_\n```\n$ openssl rsa -in ca.key -pubout -out ca.pub\nwriting RSA key\n\n$ cat ca.pub\n-----BEGIN PUBLIC KEY-----\nMIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEAwXyEyA/6JVNgnJHqAqk8\n...\n1NTBk+ZgGdemt75WzmuTvx8CAwEAAQ==\n-----END PUBLIC KEY-----\n```\n\n## 生成CA证书\n```\n$ openssl req -new -x509 -days 365 -key ca-key.pem -sha256 -subj '/' -out ca.pem\nEnter pass phrase for ca-key.pem:\n\n$ cat ca.pem\n-----BEGIN CERTIFICATE-----\nMIIEfDCCAmQCCQCJX/8al7r/MzANBgkqhkiG9w0BAQsFADAAMB4XDTE5MDgxOTAz\n...\nnSQFJiCLDb0zTItAkZdlxc+C5ZmBx8HethzWrKoMthyP1osm+i4a0ukHYkLa1LBv\n-----END CERTIFICATE-----\n```\n1. 从**证明是谁**的角度来看，该CA证书没有什么意义\n    - 参数里面只提供了CA的私钥（很容易算出对应的公钥），但`-subj`并没有指定公钥是谁，拥有哪个域名\n2. 在这里把该CA证书当成**根CA证书**，而根CA证书是**直接内嵌**到软件中的，**无条件信任**，至于它是谁并不重要\n3. 当验证一个**普通证书**的时候，验证的是**普通证书的签名方是不是根CA**，这只需用**根CA的公钥**去解码签名信息即可\n\n## 生成服务器私钥\n```\n$ openssl genrsa -out server-key.pem 4096\nGenerating RSA private key, 4096 bit long modulus\n\n$ cat server-key.pem\n-----BEGIN RSA PRIVATE KEY-----\nMIIJKgIBAAKCAgEAvnWnnYXBpdHn1llmbjpZ+2Df9n4zDejNLlnLIvuvT4lUzcg2\n...\nnRD5RyqtJFvkwZFTMrB3UhtUIF+dM6z4t2iTsXF7dif9eIZJEVXXG8QtmTlg1g==\n-----END RSA PRIVATE KEY-----\n```\n\n## 生成服务器证书\n\n### 生成证书申请请求\n```\n$ openssl req -subj \"/CN=zhongmingmao.me\" -sha256 -new -key server-key.pem -out server.csr\n\n$ cat server.csr\n-----BEGIN CERTIFICATE REQUEST-----\nMIIEXzCCAkcCAQAwGjEYMBYGA1UEAwwPemhvbmdtaW5nbWFvLm1lMIICIjANBgkq\n...\nV4rOItR6nYLzeGrXVH07DPeIYg==\n-----END CERTIFICATE REQUEST-----\n```\n1. 证书的作用：把一个**公钥**和一个**域名**关联起来\n2. 对浏览器而言，检查一个HTTPS网站是否有效，就是要看**证书里面的`/CN`字段**是否等于**正在访问的域名**\n\n### 用CA证书签名\n```\n$ openssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem -CAcreateserial -out server-cert.pem\nSignature ok\nsubject=/CN=zhongmingmao.me\nGetting CA Private Key\nEnter pass phrase for ca-key.pem:\n\n$ cat server-cert.pem\n-----BEGIN CERTIFICATE-----\nMIIEljCCAn4CCQCiOf0vbsy3ljANBgkqhkiG9w0BAQsFADAAMB4XDTE5MDgxOTAz\n...\nhQCk+kTITJuoH4ADvldnalmAwsqBBuSca2Y=\n-----END CERTIFICATE-----\n```\n1. 签名需要**CA证书**，用来表明该服务器证书是**谁签署**的\n2. 签名需要**CA私钥**，用来**生成摘要**保证**签名内容不被修改**\n3. server-cert.pem就是已经被CA证书签名过的服务器证书，主要包含两部分内容\n    - 服务器的**公钥**（**你是你**）\n    - 服务器的**身份**（**你是谁**，`/CN`）\n\n## 查看服务器证书\n```\n$ openssl x509 -in server-cert.pem -noout -text\nCertificate:\n    Data:\n        Version: 1 (0x0)\n        Serial Number: 11689652687981033366 (0xa239fd2f6eccb796)\n    Signature Algorithm: sha256WithRSAEncryption\n        Issuer:\n        Validity\n            Not Before: Aug 19 03:53:44 2019 GMT\n            Not After : Aug 18 03:53:44 2020 GMT\n        Subject: CN=zhongmingmao.me\n        Subject Public Key Info:\n            Public Key Algorithm: rsaEncryption\n                Public-Key: (4096 bit)\n                Modulus:\n                    00:be:75:a7:9d:85:c1:a5:d1:e7:d6:59:66:6e:3a:\n                    ...\n                    3a:6a:e9\n                Exponent: 65537 (0x10001)\n    Signature Algorithm: sha256WithRSAEncryption\n         a5:b9:65:10:4e:46:50:1e:3f:b0:ae:3f:bf:a0:88:94:e4:e2:\n         ...\n         c2:ca:81:06:e4:9c:6b:66\n```\n\n## 小结\n1. 上述过程中总共两类文件：**密钥**、**证书**（csr是中间文件）\n2. 私钥是保密的，不能分发，可以生成单独的公钥文件发布\n3. 使用证书是更好的选择，因为证书里面不仅包含**公钥**，还提供了该**公钥的身份信息**用于校验\n    - 哪怕签署时什么身份信息都没填，至少也能表明**被某CA签署过**\n\n## 参考资料\n[openssl走一轮CA证书签发的过程和各个文件作用](https://fatfatson.github.io/2018/07/27/openssl%E8%B5%B0%E4%B8%80%E8%BD%AECA%E8%AF%81%E4%B9%A6%E7%AD%BE%E5%8F%91%E7%9A%84%E8%BF%87%E7%A8%8B%E5%92%8C%E5%90%84%E4%B8%AA%E6%96%87%E4%BB%B6%E4%BD%9C%E7%94%A8/)\n","tags":["CA"],"categories":["Protocol"]},{"title":"Spring -- 事务","url":"%2F2019%2F08%2F03%2Fspring-transaction%2F","content":"\n## 事务抽象\n\n### 一致的事务模型\n1. JDBC/Hibernate/MyBatis\n2. DataSource/JTA\n\n<!-- more -->\n\n### 核心接口\n1. PlatformTransactionManager\n    - DataSourceTransactionManager\n    - HibernateTransactionManager\n    - JtaTransactionManager\n2. TransactionDefinition\n    - Propagation\n    - Isolation\n    - Timeout\n    - Read-Only Status\n\n```java\npublic interface PlatformTransactionManager {\n    void commit(TransactionStatus status) throws TransactionException;\n    void rollback(TransactionStatus status) throws TransactionException;\n    TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException;\n}\n\npublic interface TransactionDefinition {\n    int getPropagationBehavior();\n    int getIsolationLevel();\n    int getTimeout();\n    boolean isReadOnly();\n}\n```\n\n### Propagation\n| 传播性 | 值 | 描述 | 备注 |\n| --- | --- | --- | --- |\n| **PROPAGATION_REQUIRED** | 0 | 当前事务有就用当前的，没有就用新的 | 默认 |\n| PROPAGATION_SUPPORTS | 1 | 事务可有可无，非必须 | |\n| PROPAGATION_MANDATORY | 2 | 当前一定要有事务，否则就抛异常 | |\n| **PROPAGATION_REQUIRES_NEW** | 3 | 无论是否有事务，都另起一个新的事务 | 会把旧事务挂起 |\n| PROPAGATION_NOT_SUPPORTED | 4 | 不支持事务，按非事务方式运行 | |\n| PROPAGATION_NEVER | 5 | 不支持事务，如果有事务就抛出异常 | |\n| **PROPAGATION_NESTED** | 6 | 当前有事务就在当前事务再起一个事务 | 1. 里面的事务拥有独立的属性，如回滚状态<br/>2. 里面的事务回滚并不会影响外面的事务 |\n\n#### REQUIRES_NEW / NESTED\n1. **REQUIRES_NEW**：始终启动一个事务，两个事务**没有关联**\n2. **NESTED**：在原事务内启动一个**内嵌事务**，两个事务有关联，**外部事务回滚，内嵌事务也会回滚**\n\n```java\n@Slf4j\n@Component\npublic class PersonServiceImpl implements PersonService {\n    @Autowired\n    private JdbcTemplate jdbcTemplate;\n    @Autowired\n    private PersonService personService;\n}\n```\n\n##### 外部事务回滚\nREQUIRES_NEW：外部事务回滚，不影响内部事务提交\n```java\n@Override\n@Transactional(rollbackFor = RuntimeException.class)\npublic void outerTransaction() {\n    jdbcTemplate.update(\"INSERT INTO PERSON (NAME) VALUES ('A')\");\n    try {\n        personService.innerTransaction();\n    } catch (RollbackException ignored) {\n    }\n    throw new RuntimeException();\n}\n\n@Override\n@Transactional(rollbackFor = RollbackException.class, propagation = Propagation.REQUIRES_NEW)\npublic void innerTransaction() throws RollbackException {\n    jdbcTemplate.update(\"INSERT INTO PERSON (NAME) VALUES ('B')\");\n    //throw new RollbackException();\n}\n```\n_**NESTED：外部事务回滚，会导致内部事务也回滚!!**_\n```java\n@Override\n@Transactional(rollbackFor = RuntimeException.class)\npublic void outerTransaction() {\n    jdbcTemplate.update(\"INSERT INTO PERSON (NAME) VALUES ('A')\");\n    try {\n        personService.innerTransaction();\n    } catch (RollbackException ignored) {\n    }\n    throw new RuntimeException();\n}\n\n@Override\n@Transactional(rollbackFor = RollbackException.class, propagation = Propagation.NESTED)\npublic void innerTransaction() throws RollbackException {\n    jdbcTemplate.update(\"INSERT INTO PERSON (NAME) VALUES ('B')\");\n    //throw new RollbackException();\n}\n```\n\n##### 内部事务回滚\n无论内部事务的propagation为NESTED或者REQUIRES_NEW，内部事务回滚都不影响外部事务提交\n```java\n@Override\n@Transactional(rollbackFor = RuntimeException.class)\npublic void outerTransaction() {\n    jdbcTemplate.update(\"INSERT INTO PERSON (NAME) VALUES ('A')\");\n    try {\n        personService.innerTransaction();\n    } catch (RollbackException ignored) {\n    }\n    //throw new RuntimeException();\n}\n\n@Override\n@Transactional(rollbackFor = RollbackException.class, propagation = Propagation.NESTED)\npublic void innerTransaction() throws RollbackException {\n    jdbcTemplate.update(\"INSERT INTO PERSON (NAME) VALUES ('B')\");\n    throw new RollbackException();\n}\n```\n\n### Isolation\n| 隔离性 | 值 | 脏读 | 不可重复读 | 幻读 | 备注 |\n| --- | --- | --- | --- | --- | --- |\n| **ISOLATION_DEFAULT** | -1 | | | | 取决于数据库配置 |\n| ISOLATION_READ_UNCOMMITTED | 1 | Y | Y | Y | |\n| ISOLATION_READ_COMMITTED | 2 | | Y | Y | |\n| ISOLATION_REPEATABLE_READ | 4 | | | Y | |\n| ISOLATION_SERIALIZABLE | 8 | | | | |\n\n## 编程式事务\n1. **TransactionTemplate**\n    - TransactionCallback\n    - TransactionCallbackWithoutResult\n2. PlatformTransactionManager\n    - 可以传入TransactionDefinition进行定义\n\n### 依赖\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-jdbc</artifactId>\n</dependency>\n<dependency>\n    <groupId>com.h2database</groupId>\n    <artifactId>h2</artifactId>\n    <scope>runtime</scope>\n</dependency>\n<dependency>\n    <groupId>org.projectlombok</groupId>\n    <artifactId>lombok</artifactId>\n    <optional>true</optional>\n</dependency>\n```\n\n### schema.sql\n```sql\nCREATE TABLE PERSON\n(\n    ID   BIGINT PRIMARY KEY AUTO_INCREMENT,\n    NAME VARCHAR(255)\n);\n```\n\n### data.sql\n```sql\nINSERT INTO PERSON (ID, NAME) VALUES ('1', 'zhongmingmao');\n```\n\n### ProgrammaticTransactionApplication\n```java\n@Slf4j\n@SpringBootApplication\npublic class ProgrammaticTransactionApplication implements CommandLineRunner {\n\n    @Autowired\n    private JdbcTemplate jdbcTemplate;\n    @Autowired\n    private TransactionTemplate transactionTemplate;\n\n    public static void main(String[] args) {\n        SpringApplication.run(ProgrammaticTransactionApplication.class, args);\n    }\n\n    @Override\n    public void run(String... args) throws Exception {\n        log.info(\"COUNT BEFORE TRANSACTION : {}\", getCount());\n        transactionTemplate.execute(status -> {\n            jdbcTemplate.update(\"INSERT INTO PERSON (NAME) VALUES ('A')\");\n            log.info(\"COUNT IN TRANSACTION : {}\", getCount());\n            status.setRollbackOnly();\n            return null;\n        });\n        log.info(\"COUNT AFTER TRANSACTION : {}\", getCount());\n        // 输出\n        // COUNT BEFORE TRANSACTION : 1\n        // COUNT IN TRANSACTION : 2\n        // COUNT AFTER TRANSACTION : 1\n    }\n\n    private long getCount() {\n        return jdbcTemplate.queryForObject(\"SELECT COUNT(*) FROM PERSON\", Long.class);\n    }\n}\n```\n\n### TransactionTemplate\n```java\npublic class TransactionTemplate extends DefaultTransactionDefinition implements TransactionOperations, InitializingBean{\n}\n\npublic class DefaultTransactionDefinition implements TransactionDefinition, Serializable {\n    private int propagationBehavior = PROPAGATION_REQUIRED;\n    private int isolationLevel = ISOLATION_DEFAULT; // -1\n    private int timeout = TIMEOUT_DEFAULT; // -1\n    private boolean readOnly = false;\n}\n```\n\n## 声明式事务\nSpring的声明式事务本质上是**通过AOP来增强类的功能**，而AOP本质上是为类做了一个代理，**实际调用的是增强后的代理类**\n<img src=\"https://spring-1253868755.cos.ap-guangzhou.myqcloud.com/spring-transaction-declarative.png\" width=1000/>\n\n### 基于注解的配置\n1. @EnableTransactionManagement\n    - proxyTargetClass\n        - Indicate whether **subclass-based (CGLIB) proxies** are to be created (**true**) as opposed to **standard Java interface-based proxies (false)**.\n        - The default is **false**. Applicable only if mode() is set to **AdviceMode.PROXY**.\n    - mode\n        - The default is **AdviceMode.PROXY**.\n            - Please note that proxy mode **allows for interception of calls through the proxy only**.\n            - _**Local calls within the same class cannot get intercepted that way!!**_\n            - An **Transactional** annotation on such a method within a **local call** will be **ignored** since Spring's interceptor does not even kick in for such a runtime scenario.\n        - For a more advanced mode of interception, consider switching this to **AdviceMode.ASPECTJ**.\n    - order\n        - Indicate the ordering of the execution of the transaction advisor when multiple advices are applied at a specific joinpoint.\n        - The default is **Ordered.LOWEST_PRECEDENCE**.\n2. @Transactional\n    - transactionManager\n    - propagation\n    - isolation\n    - timeout\n    - readOnly\n    - rollbackFor/noRollbackFor\n\n### PersonService接口\n由于@EnableTransactionManagement的mode默认值为**PROXY**，PROXY对应的是**JDK动态代理**（基于**接口**）\n```java\npublic interface PersonService {\n    void insert();\n    void insertThenRollback();\n    void invokeInsertThenRollback();\n}\n```\n\n### PersonServiceImpl\n```java\n@Component\npublic class PersonServiceImpl implements PersonService {\n    @Autowired\n    private JdbcTemplate jdbcTemplate;\n\n    @Override\n    @Transactional\n    public void insert() {\n        jdbcTemplate.update(\"INSERT INTO PERSON (NAME) VALUES ('A')\");\n    }\n\n    @Override\n    @Transactional(rollbackFor = UnexpectedRollbackException.class)\n    public void insertThenRollback() {\n        jdbcTemplate.update(\"INSERT INTO PERSON (NAME) VALUES ('A')\");\n        throw new UnexpectedRollbackException(\"Just For Test\");\n    }\n\n    @Override\n    public void invokeInsertThenRollback() {\n        // 方法的内部调用，没有走到增强的代理类上，因此也没有事务支持（实际是使用了数据库的隐式事务，自动提交）\n        // 不会回滚！！\n        insertThenRollback();\n    }\n}\n```\n\n### DeclarativeTransactionApplication\n```java\n@Slf4j\n@SpringBootApplication\npublic class DeclarativeTransactionApplication implements CommandLineRunner {\n\n    @Autowired\n    private JdbcTemplate jdbcTemplate;\n    @Autowired\n    private PersonService personService;\n\n    public static void main(String[] args) {\n        SpringApplication.run(DeclarativeTransactionApplication.class, args);\n    }\n\n    @Override\n    public void run(String... args) throws Exception {\n        personService.insert();\n        log.info(\"insert, count : {}\", getCount());\n\n        try {\n            personService.insertThenRollback();\n        } catch (Throwable throwable) {\n            log.info(\"insertThenRollback, count : {}\", getCount());\n        }\n\n        try {\n            personService.invokeInsertThenRollback();\n        } catch (Throwable throwable) {\n            log.info(\"invokeInsertThenRollback, count : {}\", getCount());\n        }\n\n        // 输出\n        // insert, count : 2\n        // insertThenRollback, count : 2\n        // invokeInsertThenRollback, count : 3\n    }\n\n    private long getCount() {\n        return jdbcTemplate.queryForObject(\"SELECT COUNT(*) FROM PERSON\", Long.class);\n    }\n}\n```\n","tags":["Transaction"],"categories":["Spring Boot"]},{"title":"Kafka -- 压缩","url":"%2F2019%2F08%2F02%2Fkafka-compression%2F","content":"\n## 压缩的目的\n时间换空间，用**CPU时间**去换**磁盘空间**或**网络IO传输量**\n\n## 消息层次\n1. **消息集合**（Message Set）和**消息**\n2. 一个消息集合中包含若干条**日志项**（Record Item），而日志项用于封装消息\n3. Kafka底层的消息日志由一系列消息集合日志项组成\n4. Kafka不会直接操作具体的消息，而是在**消息集合**这个层面上进行写入操作\n\n<!-- more -->\n\n## 消息格式\n1. 目前Kafka共有两大类消息格式，社区分别称之为**V1**版本和**V2**版本（在0.11.0.0引入）\n2. V2版本主要针对V1版本的一些弊端进行了优化\n3. 优化1：把消息的公共部分**抽取**到外层消息集合里面\n    - 在V1版本中，每条消息都需要执行CRC校验，但在某些情况下，消息的CRC值会发生变化\n        - Broker端可能对消息的**时间戳**字段进行更新，重新计算后的CRC值也会相应更新\n        - Broker端在执行**消息格式转换**时（兼容老版本客户端），也会带来CRC值的变化\n    - 因此没必要对每条消息都执行CRC校验，浪费**空间**和**时间**\n    - 在V2版本中，消息的CRC校验被移到了消息集合这一层\n4. 优化2：对**整个消息集合**进行压缩\n    - 在V1版本中，对**多条消息**进行压缩，然后保存到**外层消息的消息体字段**中\n\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-compression-v1-v2.png\" width=1000/>\n\n## 压缩的时机\n在Kafka中，压缩可能发生在两个地方：**生产者**、**Broker**\n\n### 生产者\n```java\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"acks\", \"all\");\nprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\nprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n// 开启GZIP压缩\n// Producer启动后，生产的每个消息集合都会经过GZIP压缩，能够很好地节省网络传输带宽和Kafka Broker端的磁盘占用\nprops.put(\"compression.type\", \"gzip\");\n\nProducer<String, String> producer = new KafkaProducer<>(props);\n```\n\n### Broker\n大部分情况下，Broker从Producer接收到消息后，仅仅只是**原封不动**地保存，而不会对其进行任何修改，但存在例外情况\n\n#### 不同的压缩算法\n1. Producer采用GZIP压缩算法，Broker采用Snappy压缩算法\n2. Broker接收到GZIP压缩消息后，只能解压后使用Snappy压缩算法**重新压缩**一遍\n3. Broker端也有`compression.type`参数，默认值是**producer**，表示Broker端会**尊重**Producer端使用的压缩算法\n    - 一旦Broker端设置了不同的`compression.type`，可能会发生预料之外的压缩/解压缩操作，导致**CPU使用率飙升**\n\n#### 消息格式转换\n1. 消息格式转换主要是为了兼容**老版本的消费者程序**，在一个Kafka集群中通常同时保存**多种版本的消息格式**（V1/V2）\n    - Broker端会对新版本消息执行向老版本格式的转换，该过程中会涉及消息的**解压缩**和**重新压缩**\n2. 消息格式转换对性能的影响很大，除了增加额外的压缩和解压缩操作之外，还会让Kafka丧失引以为傲的**Zero Copy**特性\n    - Zero Copy：数据在**磁盘**和**网络**进行传输时，**避免昂贵的内核态数据拷贝**，从而实现快速的数据传输\n3. 因此，**尽量保证消息格式的统一**\n\n## 解压缩的时机\n\n### Consumer\n1. 通常来说**解压缩**发生在**消费者**\n2. _**Producer压缩，Broker保持、Consumer解压缩**_\n3. Kafka会将启用的压缩算法封装进**消息集合**中，当Consumer读取到消息集合时，会知道这些消息使用了哪一种压缩算法\n\n### Broker\n1. 与消息格式转换时发生的解压缩是不同的场景（主要为了兼容老版本的消费者）\n2. 每个压缩过的消息集合**在Broker端写入时**都要发生解压缩操作，目的是为了对消息执行**各种验证**（主要影响CPU使用率）\n\n## 压缩算法对比\n1. Kafka 2.1.0之前，Kafka支持三种压缩算法：**GZIP**、**Snappy**、**LZ4**，从2.1.0开始正式支持**zstd**算法\n    - zstd是Facebook开源的压缩算法，能够提供**超高的压缩比**\n2. 评估一个压缩算法的优劣，主要有两个指标：**压缩比**、**压缩/解压缩吞吐量**\n3. 从下面的Benchmarks可以看出\n    - _**zstd具有最高的压缩比**，**LZ4具有最高的吞吐量**_\n4. 在Kafka的实际使用中\n    - 吞吐量：_**LZ4**_ > Snappy > _**zstd**_ > GZIP\n    - 压缩比：_**zstd**_ > _**LZ4**_ > GZIP > Snappy\n5. 物理资源\n    - 带宽：由于Snappy的压缩比最低，因此占用的网络带宽最大\n    - CPU：各个压缩算法差不多，在**压缩**时**Snappy**使用更多的CPU，在**解压缩**时**GZIP**使用更多的CPU\n6. **带宽资源比CPU资源和磁盘资源更吃紧**（千兆网络是标配），_**首先排除Snappy，其次排除GZIP，剩下在LZ4和zstd中选择**_\n    - 如果客户端的CPU资源充足，强烈建议开启**zstd**压缩，可以**极大地节省网络带宽**\n\n[Benchmarks](https://github.com/facebook/zstd)\n\n| Compressor name | Ratio | Compression | Decompress |\n| ---- | ---- | ---- | ---- |\n| _**zstd**_ 1.4.0 -1 | _**2.884**_ | 530 MB/s | 1360 MB/s |\n| zlib 1.2.11 -1 | 2.743 | 110 MB/s | 440 MB/s |\n| brotli 1.0.7 -0 | 2.701 | 430 MB/s | 470 MB/s |\n| quicklz 1.5.0 -1 | 2.238 | 600 MB/s | 800 MB/s |\n| lzo1x 2.09 -1 | 2.106 | 680 MB/s | 950 MB/s |\n| _**lz4**_ 1.8.3 | 2.101 | _**800 MB/s**_ | _**4220 MB/s**_ |\n| snappy 1.1.4 | 2.073 | 580 MB/s | 2020 MB/s |\n| lzf 3.6 -1 | 2.077 | 440 MB/s | 930 MB/s |\n","tags":["Compression"],"categories":["Kafka"]},{"title":"Spring -- JDBC","url":"%2F2019%2F08%2F01%2Fspring-jdbc%2F","content":"\n## Spring JDBC的操作类\n1. core：JdbcTemplate等相关核心接口和类\n2. dataSource：数据源相关的辅助类\n3. object：将基本的JDBC操作封装成对象\n4. support：错误码等其他辅助工具\n\n<!-- more -->\n\n## 常用的Bean注解\n1. @Component -- 通用Bean\n2. @Repository -- 数据操作的仓库\n3. @Service -- 业务服务\n4. @Controller -- Spring MVC\n    - @RestController -- RESTful Web Services\n\n## 简单使用\n1. query\n2. queryForObject\n3. queryForList\n4. update：插入、修改、删除\n5. execute\n\n### 依赖\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-jdbc</artifactId>\n</dependency>\n<dependency>\n    <groupId>com.h2database</groupId>\n    <artifactId>h2</artifactId>\n    <scope>runtime</scope>\n</dependency>\n<dependency>\n    <groupId>org.projectlombok</groupId>\n    <artifactId>lombok</artifactId>\n    <optional>true</optional>\n</dependency>\n```\n\n### schema.sql\n```sql\nCREATE TABLE PERSON\n(\n    ID   BIGINT PRIMARY KEY AUTO_INCREMENT,\n    NAME VARCHAR(255)\n);\n```\n\n### data.sql\n```sql\nINSERT INTO PERSON (ID, NAME) VALUES ('1', 'zhongmingmao');\n```\n\n### Person\n```java\n@Data\n@Builder\npublic class Person {\n    private Long id;\n    private String name;\n}\n```\n\n### PersonDao\n```java\n@Slf4j\n@Repository\npublic class PersonDao {\n    @Autowired\n    private JdbcTemplate jdbcTemplate;\n    @Autowired\n    private SimpleJdbcInsert simpleJdbcInsert;\n\n    public void insert() {\n        Arrays.asList(\"A\", \"B\").forEach(name -> jdbcTemplate.update(\"INSERT INTO PERSON (NAME) VALUES (?)\", name));\n\n        Map<String, String> row = new HashMap<>();\n        row.put(\"NAME\", \"C\");\n        Number id = simpleJdbcInsert.executeAndReturnKey(row);\n        log.info(\"ID of C : {}\", id);\n    }\n\n    public void list() {\n        Long count = jdbcTemplate.queryForObject(\"SELECT COUNT(*) FROM PERSON\", Long.class);\n        log.info(\"count : {}\", count);\n\n        List<String> names = jdbcTemplate.queryForList(\"SELECT NAME FROM PERSON\", String.class);\n        names.forEach(name -> log.info(\"name : {}\", name));\n\n        // 自定义RowMapper\n        List<Person> people = jdbcTemplate.query(\"SELECT * FROM PERSON\",\n                (rs, rowNum) -> Person.builder().id(rs.getLong(1)).name(rs.getString(2)).build());\n        people.forEach(person -> log.info(\"person : {}\", person));\n    }\n}\n```\n\n### JdbcApplication\n```java\n@Slf4j\n@SpringBootApplication\npublic class JdbcApplication implements CommandLineRunner {\n    @Autowired\n    private PersonDao personDao;\n\n    public static void main(String[] args) {\n        SpringApplication.run(JdbcApplication.class, args);\n    }\n\n    @Bean\n    @Autowired\n    public SimpleJdbcInsert simpleJdbcInsert(JdbcTemplate jdbcTemplate) {\n        // SimpleJdbcInsert是Spring JDBC提供的一个辅助类，可以更方便地使用JdbcTemplate\n        return new SimpleJdbcInsert(jdbcTemplate).withTableName(\"PERSON\").usingGeneratedKeyColumns(\"ID\");\n    }\n\n    @Override\n    public void run(String... args) throws Exception {\n        personDao.insert();\n        personDao.list();\n    }\n}\n```\n\n## 批处理\n```java\n// JdbcTemplate\nint[] batchUpdate(String sql, BatchPreparedStatementSetter pss) throws DataAccessException;\n\n// NamedParameterJdbcTemplate\nint[] batchUpdate(String sql, SqlParameterSource[] batchArgs);\nSqlParameterSourceUtils.createBatch\n```\n\n### Bean定义\n```java\n@Bean\n@Autowired\npublic NamedParameterJdbcTemplate namedParameterJdbcTemplate(DataSource dataSource) {\n    return new NamedParameterJdbcTemplate(dataSource);\n}\n```\n\n### 两种方式\n```java\n// jdbcTemplate\njdbcTemplate.batchUpdate(\"INSERT INTO PERSON (NAME) VALUES (?)\", new BatchPreparedStatementSetter() {\n    @Override\n    public void setValues(PreparedStatement ps, int i) throws SQLException {\n        ps.setString(1, \"batch-\" + i);\n    }\n\n    @Override\n    public int getBatchSize() {\n        return 2;\n    }\n});\n\n// namedParameterJdbcTemplate，更优雅！\nList<Person> list = new ArrayList<>();\nlist.add(Person.builder().id(100L).name(\"batch-100\").build());\nlist.add(Person.builder().id(101L).name(\"batch-101\").build());\nnamedParameterJdbcTemplate.batchUpdate(\"INSERT INTO PERSON (ID, NAME) VALUES (:id, :name)\",\n        SqlParameterSourceUtils.createBatch(list));\n```\n","tags":["H2"],"categories":["Spring Boot"]},{"title":"Java性能 -- 序列化","url":"%2F2019%2F07%2F31%2Fjava-performance-serialization%2F","content":"\n## 序列化方案\n1. Java RMI采用的是**Java序列化**\n2. Spring Cloud采用的是_**JSON序列化**_\n3. Dubbo虽然兼容Java序列化，但默认使用的是_**Hessian序列化**_\n\n<!-- more -->\n\n## Java序列化\n\n### 原理\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-java-serialization.png\" width=1000/>\n\n#### Serializable\n1. JDK提供了输入流对象**ObjectInputStream**和输出流对象**ObjectOutputStream**\n2. 它们只能对实现了**Serializable**接口的类的对象进行序列化和反序列化\n\n```java\n// 只能对实现了Serializable接口的类的对象进行序列化\n// java.io.NotSerializableException: java.lang.Object\nObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(FILE_PATH));\noos.writeObject(new Object());\noos.close();\n```\n\n#### transient\n1. ObjectOutputStream的**默认**序列化方式，仅对对象的**非transient的实例变量**进行序列化\n2. 不会序列化对象的transient的实例变量，也不会序列化静态变量\n\n```java\n@Getter\npublic class A implements Serializable {\n    private transient int f1 = 1;\n    private int f2 = 2;\n    @Getter\n    private static final int f3 = 3;\n}\n\n// 序列化\n// 仅对对象的非transient的实例变量进行序列化\nA a1 = new A();\nObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(FILE_PATH));\noos.writeObject(a1);\noos.close();\n\n// 反序列化\nObjectInputStream ois = new ObjectInputStream(new FileInputStream(FILE_PATH));\nA a2 = (A) ois.readObject();\nlog.info(\"f1={}, f2={}, f3={}\", a2.getF1(), a2.getF2(), a2.getF3()); // f1=0, f2=2, f3=3\nois.close();\n```\n\n#### serialVersionUID\n1. 在实现了Serializable接口的类的对象中，会生成一个**serialVersionUID**的版本号\n2. 在反序列化过程中用来验证序列化对象是否加载了反序列化的类\n3. 如果是具有**相同类名**的**不同版本号**的类，在反序列化中是**无法获取对象**的\n\n```java\n@Data\n@AllArgsConstructor\npublic class B implements Serializable {\n    private static final long serialVersionUID = 1L;\n    private int id;\n}\n\n@Test\npublic void test3() throws Exception {\n    // 序列化\n    B b1 = new B(1);\n    ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(FILE_PATH));\n    oos.writeObject(b1);\n    oos.close();\n}\n\n@Test\npublic void test4() throws Exception {\n    // 如果先将B的serialVersionUID修改为1，直接反序列化磁盘上的文件，会报异常\n    // java.io.InvalidClassException: xxx.B; local class incompatible: stream classdesc serialVersionUID = 0, local class serialVersionUID = 1\n    ObjectInputStream ois = new ObjectInputStream(new FileInputStream(FILE_PATH));\n    B b2 = (B) ois.readObject();\n    ois.close();\n}\n```\n\n#### writeObject/readObject\n具体实现序列化和反序列化的是**writeObject**和**readObject**\n```java\n@Data\n@AllArgsConstructor\npublic class Student implements Serializable {\n    private long id;\n    private int age;\n    private String name;\n\n    // 只序列化部分字段\n    private void writeObject(ObjectOutputStream outputStream) throws IOException {\n        outputStream.writeLong(id);\n        outputStream.writeObject(name);\n    }\n\n    // 按序列化的顺序进行反序列化\n    private void readObject(ObjectInputStream inputStream) throws IOException, ClassNotFoundException {\n        id = inputStream.readLong();\n        name = (String) inputStream.readObject();\n    }\n}\n\nStudent s1 = new Student(1, 12, \"Bob\");\nObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(FILE_PATH));\noos.writeObject(s1);\noos.close();\n\nObjectInputStream ois = new ObjectInputStream(new FileInputStream(FILE_PATH));\nStudent s2 = (Student) ois.readObject();\nlog.info(\"s2={}\", s2); // s2=Student(id=1, age=0, name=Bob)\nois.close();\n```\n\n#### writeReplace/readResolve\n1. **writeReplace**：用在**序列化之前**替换序列化对象\n2. **readResolve**：用在**反序列化之后**对返回对象进行处理\n\n```java\n// 反序列化会通过反射调用无参构造器返回一个新对象，破坏单例模式\n// 可以通过readResolve()来解决\npublic class Singleton1 implements Serializable {\n\n    private static final Singleton1 SINGLETON_1 = new Singleton1();\n\n    private Singleton1() {\n    }\n\n    public static Singleton1 getInstance() {\n        return SINGLETON_1;\n    }\n}\n\nSingleton1 s1 = Singleton1.getInstance();\nObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(FILE_PATH));\noos.writeObject(s1);\noos.close();\n\nObjectInputStream ois = new ObjectInputStream(new FileInputStream(FILE_PATH));\nSingleton1 s2 = (Singleton1) ois.readObject();\nlog.info(\"{}\", s1 == s2); // false\nois.close();\n```\n\n```java\npublic class Singleton2 implements Serializable {\n\n    private static final Singleton2 SINGLETON_2 = new Singleton2();\n\n    private Singleton2() {\n    }\n\n    public static Singleton2 getInstance() {\n        return SINGLETON_2;\n    }\n\n    public Object writeRepalce() {\n        // 序列化之前，无需替换\n        return this;\n    }\n\n    private Object readResolve() {\n        // 反序列化之后，直接返回单例\n        return getInstance();\n    }\n}\n\nSingleton2 s1 = Singleton2.getInstance();\nObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(FILE_PATH));\noos.writeObject(s1);\noos.close();\n\nObjectInputStream ois = new ObjectInputStream(new FileInputStream(FILE_PATH));\nSingleton2 s2 = (Singleton2) ois.readObject();\nlog.info(\"{}\", s1 == s2); // true\nois.close();\n```\n\n### 缺陷\n\n#### 无法跨语言\nJava序列化**只适用**于基于Java语言实现的框架\n\n#### 易被攻击\n1. Java序列化是**不安全**的\n    - Java官网：对**不信任数据的反序列化**，本质上来说是**危险**的，应该予以回避\n2. ObjectInputStream.readObject()\n    - _**将类路径上几乎所有实现了Serializable接口的对象都实例化!!**_\n    - 这意味着：在**反序列化字节流**的过程中，该方法**可以执行任意类型的代码**，非常**危险**\n3. 对于需要**长时间进行反序列化**的对象，不需要执行任何代码，也可以发起一次攻击\n    - 攻击者可以创建**循环对象链**，然后将序列化后的对象传输到程序中进行反序列化\n    - 这会导致**haseCode**方法被调用的次数呈**次方爆发式增长**，从而引发**栈溢出**异常\n4. 很多序列化协议都制定了**一套数据结构**来保存和获取对象，如JSON序列化、ProtocolBuf\n    - 它们只支持一些**基本类型**和**数组类型**，可以避免反序列化创建一些**不确定**的实例\n\n```java\nint itCount = 27;\nSet root = new HashSet();\nSet s1 = root;\nSet s2 = new HashSet();\nfor (int i = 0; i < itCount; i++) {\n    Set t1 = new HashSet();\n    Set t2 = new HashSet();\n    t1.add(\"foo\"); // 使t2不等于t1\n    s1.add(t1);\n    s1.add(t2);\n    s2.add(t1);\n    s2.add(t2);\n    s1 = t1;\n    s2 = t2;\n}\n\nObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(FILE_PATH));\noos.writeObject(root);\noos.close();\n\nlong start = System.currentTimeMillis();\nObjectInputStream ois = new ObjectInputStream(new FileInputStream(FILE_PATH));\nois.readObject();\nlog.info(\"take : {}\", System.currentTimeMillis() - start);\nois.close();\n\n// itCount  - take\n// 25       - 3460\n// 26       - 7346\n// 27       - 11161\n```\n\n#### 序列化后的流太大\n1. 序列化后的二进制流大小能体现序列化的能力\n2. 序列化后的二进制数组越大，占用的存储空间就越多，存储硬件的成本就越高\n    - 如果进行网络传输，则占用的**带宽**就越多，影响到系统的**吞吐量**\n3. Java序列化使用ObjectOutputStream来实现对象转二进制编码，可以对比BIO中的ByteBuffer实现的二进制编码\n\n```java\n@Data\nclass User implements Serializable {\n    private String userName;\n    private String password;\n}\n\nUser user = new User();\nuser.setUserName(\"test\");\nuser.setPassword(\"test\");\n\n// ObjectOutputStream\nByteArrayOutputStream os = new ByteArrayOutputStream();\nObjectOutputStream oos = new ObjectOutputStream(os);\noos.writeObject(user);\nlog.info(\"{}\", os.toByteArray().length); // 107\n\n// NIO ByteBuffer\nByteBuffer byteBuffer = ByteBuffer.allocate(2048);\nbyte[] userName = user.getUserName().getBytes();\nbyte[] password = user.getPassword().getBytes();\nbyteBuffer.putInt(userName.length);\nbyteBuffer.put(userName);\nbyteBuffer.putInt(password.length);\nbyteBuffer.put(password);\nbyteBuffer.flip();\nlog.info(\"{}\", byteBuffer.remaining()); // 16\n```\n\n#### 序列化速度慢\n1. 序列化速度是体现序列化性能的重要指标\n2. 如果序列化的速度慢，就会影响**网络通信**的效率，从而增加系统的**响应时间**\n\n```java\nint count = 10_0000;\nUser user = new User();\nuser.setUserName(\"test\");\nuser.setPassword(\"test\");\n\n// ObjectOutputStream\nlong t1 = System.currentTimeMillis();\nfor (int i = 0; i < count; i++) {\n    ByteArrayOutputStream os = new ByteArrayOutputStream();\n    ObjectOutputStream oos = new ObjectOutputStream(os);\n    oos.writeObject(user);\n    oos.flush();\n    oos.close();\n    byte[] bytes = os.toByteArray();\n    os.close();\n}\nlong t2 = System.currentTimeMillis();\nlog.info(\"{}\", t2 - t1); // 731\n\n// NIO ByteBuffer\nlong t3 = System.currentTimeMillis();\nfor (int i = 0; i < count; i++) {\n    ByteBuffer byteBuffer = ByteBuffer.allocate(2048);\n    byte[] userName = user.getUserName().getBytes();\n    byte[] password = user.getPassword().getBytes();\n    byteBuffer.putInt(userName.length);\n    byteBuffer.put(userName);\n    byteBuffer.putInt(password.length);\n    byteBuffer.put(password);\n    byteBuffer.flip();\n    byte[] bytes = new byte[byteBuffer.remaining()];\n}\nlong t4 = System.currentTimeMillis();\nlog.info(\"{}\", t4 - t3); // 182\n```\n\n## ProtoBuf\n1. ProtoBuf是由Google推出且支持多语言的序列化框架\n    - 在序列化框架性能测试报告中，ProtoBuf无论**编解码耗时**，还是**二进制流压缩大小**，都表现很好\n2. ProtoBuf以一个**.proto**后缀的文件为基础，该文件描述了字段以及字段类型，通过工具可以生成不同语言的数据结构文件\n3. 在序列化该数据对象的时候，ProtoBuf通过.proto文件描述来生成Protocol Buffers格式的编码\n\n### 存储格式\n1. Protocol Buffers是一种轻便高效的**结构化**数据存储格式\n2. Protocol Buffers使用**T-L-V**（标识-长度-字段值）的数据格式来存储数据\n    - T代表字段的**正数序列**（tag）\n        - Protocol Buffers将对象中的**字段**与**正数序列**对应起来，对应关系的信息是由生成的代码来保证的\n        - 在**序列化的时候用整数值来代替字段名称**，传输流量就可以**大幅缩减**\n    - L代表Value的**字节长度**，一般也只占用**一个字节**\n    - V代表字段值经过**编码后**的值\n3. 这种格式**不需要分隔符**，也**不需要空格**，同时**减少了冗余字段名**\n\n### 编码方式\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-protobuf-type.jpg\" width=1000/>\n\n1. ProtoBuf定义了一套自己的编码方式，几乎可以映射Java/Python等语言的**所有基础数据类型**\n2. 不同的**编码方式**可以对应不同的**数据类型**，还能采用不同的**存储格式**\n3. 对于Varint编码的数据，由于数据占用的存储空间是**固定**的，因此不需要存储字节长度length，存储方式采用**T-V**\n4. Varint编码是一种**变长**的编码方式，每个数据类型**一个字节的最后一位**是**标志位**（msb）\n    - 0表示当前字节已经是**最后**一个字节\n    - 1表示后面还有一个字节\n5. 对于int32类型的数字，一般需要4个字节表示，如果采用Varint编码，对于很小的int类型数字，用1个字节就能表示\n    - 对于大部分整数类型数据来说，一般都是小于256，所以这样能起到很好的**数据压缩**效果\n\n### 编解码\n1. ProtoBuf不仅**压缩**存储数据的效果好，而且**编解码**的性能也是很好的\n2. ProtoBuf的编码和解码过程结合**.proto**文件格式，加上Protocol Buffers独特的编码格式\n    - 只需要**简单的数据运算**以及**位移**等操作就可以完成编码和解码\n","tags":["ProtoBuf"],"categories":["Performance"]},{"title":"Spring -- Druid","url":"%2F2019%2F07%2F30%2Fspring-druid%2F","content":"\n## HikariCP VS Druid\n1. HikariCP\n    - Fast, simple, reliable. HikariCP is a \"zero-overhead\" production ready JDBC connection pool\n2. Druid\n    - 为**监控**而生的数据库连接池\n\n<!-- more -->\n\n## 依赖\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-jdbc</artifactId>\n    <exclusions>\n        <!-- 需要排除HikariCP -->\n        <exclusion>\n            <groupId>com.zaxxer</groupId>\n            <artifactId>HikariCP</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n<dependency>\n    <groupId>com.alibaba</groupId>\n    <artifactId>druid-spring-boot-starter</artifactId>\n    <version>1.1.18</version>\n</dependency>\n<dependency>\n    <groupId>com.h2database</groupId>\n    <artifactId>h2</artifactId>\n    <scope>runtime</scope>\n</dependency>\n```\n\n## 自定义Filter\n\n### ConnectionLogFilter\n```java\n@Slf4j\npublic class ConnectionLogFilter extends FilterEventAdapter {\n\n    @Override\n    public void connection_connectBefore(FilterChain chain, Properties info) {\n        log.info(\"Before Connection!\");\n    }\n\n    @Override\n    public void connection_connectAfter(ConnectionProxy connection) {\n        log.info(\"After Connection!\");\n    }\n}\n```\n\n### META-INF/druid-filter.properties\n```\ndruid.filters.connectionLog=me.zhongmingmao.druid.ConnectionLogFilter\n```\n\n## 密码加密\n\n### 加密\n```\n$ java -cp druid-1.1.18.jar com.alibaba.druid.filter.config.ConfigTools zhongmingmao\nprivateKey:MIIBVQIBADANBgkqhkiG9w0BAQEFAASCAT8wggE7AgEAAkEA0RCqooKQpXfLjH8rScU0CzNmzSCOcfWfbhs1PsmPpeVpmTJuIGiAc9Fh1ZyMEUu/Ys5WNMOLnoMfk47yxlm9qQIDAQABAkAY8V8aUm+Fflxnn8h/XarO50wNjyPPjtl9nntkyVF9HkGdCIol2rU54BP+w0nIEHQnlQNEUe1xRdF+PoUo47cBAiEA6i+7MnB7OYZmKVxzZPs+LoTtD8e+L8ucDbv2ntK3GAkCIQDkiegmbPGpZHys+Fltbzsqph3y3Eznr5EZoeZWAD6goQIhAMn1W9TF2B7l3tiwl/twCFIJ5H8FXOjPCMd3X9ncEnYxAiEAyAjZVQDYiU72PaPnCn1oiUz7O76N5eDrHUdzR+VQ6+ECIDT/Gfcrv+iCKbRWWHA/5Q8Acjs8XneAo6RuSB01lr5K\npublicKey:MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBANEQqqKCkKV3y4x/K0nFNAszZs0gjnH1n24bNT7Jj6XlaZkybiBogHPRYdWcjBFLv2LOVjTDi56DH5OO8sZZvakCAwEAAQ==\npassword:kasn+cz2VW19LhkoWU2BCGlFziWJR+3Ms/23owalPmV797PSues2cQqMp3OdFPlvonioz4H5Os9jt98hcNwW7Q==\n```\n\n### application.properties\n```\n# JDBC配置\nspring.datasource.url=jdbc:h2:mem:testDb\nspring.datasource.username=SA\nspring.datasource.password=kasn+cz2VW19LhkoWU2BCGlFziWJR+3Ms/23owalPmV797PSues2cQqMp3OdFPlvonioz4H5Os9jt98hcNwW7Q==\nspring.datasource.driver-class-name=org.h2.Driver\n# 连接池配置\nspring.datasource.druid.initial-size=5\nspring.datasource.druid.max-active=5\nspring.datasource.druid.min-idle=5\nspring.datasource.druid.filters=stat,config,wall,connectionLog\nspring.datasource.druid.filter.config.enabled=true\nspring.datasource.druid.connection-properties=druid.stat.logSlowSql=true;druid.stat.slowSqlMillis=0;config.decrypt=true;config.decrypt.key=${public-key}\nspring.datasource.druid.test-on-borrow=true\nspring.datasource.druid.test-on-return=true\nspring.datasource.druid.test-while-idle=true\nspring.datasource.druid.filter.wall.enabled=true\nspring.datasource.druid.filter.wall.db-type=h2\nspring.datasource.druid.filter.wall.config.delete-allow=false\nspring.datasource.druid.filter.wall.config.truncate-allow=false\nspring.datasource.druid.filter.wall.config.drop-table-allow=false\npublic-key=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBANEQqqKCkKV3y4x/K0nFNAszZs0gjnH1n24bNT7Jj6XlaZkybiBogHPRYdWcjBFLv2LOVjTDi56DH5OO8sZZvakCAwEAAQ==\n```\n\n## 慢SQL\napplication.properties\n```\nspring.datasource.druid.connection-properties=druid.stat.logSlowSql=true;druid.stat.slowSqlMillis=0\n```\n\n## 监控\n```java\n@RestController\npublic class DruidStatController {\n\n    @GetMapping(\"/druid/stat\")\n    public Object druidStat() {\n        return DruidStatManagerFacade.getInstance().getDataSourceStatDataList();\n    }\n}\n```\n\n## 运行\n```\n2019-08-16 18:33:07.658  INFO 92273 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)\n2019-08-16 18:33:07.693  INFO 92273 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]\n2019-08-16 18:33:07.693  INFO 92273 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.22]\n2019-08-16 18:33:07.814  INFO 92273 --- [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext\n2019-08-16 18:33:07.815  INFO 92273 --- [           main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2528 ms\n2019-08-16 18:33:07.908  INFO 92273 --- [           main] c.a.d.s.b.a.DruidDataSourceAutoConfigure : Init DruidDataSource\n2019-08-16 18:33:08.207 ERROR 92273 --- [           main] com.alibaba.druid.pool.DruidDataSource   : testOnBorrow is true, testOnReturn is true, testWhileIdle is true, validationQuery not set\n2019-08-16 18:33:08.215  INFO 92273 --- [           main] m.z.druid.ConnectionLogFilter            : Before Connection!\n2019-08-16 18:33:08.357  INFO 92273 --- [           main] m.z.druid.ConnectionLogFilter            : After Connection!\n2019-08-16 18:33:08.382  INFO 92273 --- [           main] m.z.druid.ConnectionLogFilter            : Before Connection!\n2019-08-16 18:33:08.386  INFO 92273 --- [           main] m.z.druid.ConnectionLogFilter            : After Connection!\n2019-08-16 18:33:08.386  INFO 92273 --- [           main] m.z.druid.ConnectionLogFilter            : Before Connection!\n2019-08-16 18:33:08.387  INFO 92273 --- [           main] m.z.druid.ConnectionLogFilter            : After Connection!\n2019-08-16 18:33:08.388  INFO 92273 --- [           main] m.z.druid.ConnectionLogFilter            : Before Connection!\n2019-08-16 18:33:08.388  INFO 92273 --- [           main] m.z.druid.ConnectionLogFilter            : After Connection!\n2019-08-16 18:33:08.389  INFO 92273 --- [           main] m.z.druid.ConnectionLogFilter            : Before Connection!\n2019-08-16 18:33:08.389  INFO 92273 --- [           main] m.z.druid.ConnectionLogFilter            : After Connection!\n2019-08-16 18:33:08.397  INFO 92273 --- [           main] com.alibaba.druid.pool.DruidDataSource   : {dataSource-1} inited\n2019-08-16 18:33:08.851 ERROR 92273 --- [           main] c.alibaba.druid.filter.stat.StatFilter   : slow sql 26 millis. CREATE TABLE PERSON( ID BIGINT PRIMARY KEY AUTO_INCREMENT, FIRST_NAME VARCHAR(255), LAST_NAME VARCHAR(255), ADDRESS VARCHAR(255) )[]\n2019-08-16 18:33:08.898 ERROR 92273 --- [           main] c.alibaba.druid.filter.stat.StatFilter   : slow sql 3 millis. INSERT INTO PERSON (first_Name, Last_Name, Address) VALUES ('Tom', 'Syke', 'Green Valley')[]\n2019-08-16 18:33:09.169  INFO 92273 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'\n2019-08-16 18:33:09.438  INFO 92273 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''\n2019-08-16 18:33:09.444  INFO 92273 --- [           main] me.zhongmingmao.druid.DruidApplication   : Started DruidApplication in 5.007 seconds (JVM running for 7.017)\n2019-08-16 18:33:09.451  INFO 92273 --- [           main] me.zhongmingmao.druid.PersonDao          : dataSource={\n\tCreateTime:\"2019-08-16 18:33:07\",\n\tActiveCount:0,\n\tPoolingCount:5,\n\tCreateCount:5,\n\tDestroyCount:0,\n\tCloseCount:4,\n\tConnectCount:4,\n\tConnections:[\n\t\t{ID:1365163763, ConnectTime:\"2019-08-16 18:33:08\", UseCount:0, LastActiveTime:\"2019-08-16 18:33:08\"},\n\t\t{ID:1414924274, ConnectTime:\"2019-08-16 18:33:08\", UseCount:0, LastActiveTime:\"2019-08-16 18:33:08\"},\n\t\t{ID:957387062, ConnectTime:\"2019-08-16 18:33:08\", UseCount:0, LastActiveTime:\"2019-08-16 18:33:08\"},\n\t\t{ID:666911607, ConnectTime:\"2019-08-16 18:33:08\", UseCount:0, LastActiveTime:\"2019-08-16 18:33:08\"},\n\t\t{ID:55429210, ConnectTime:\"2019-08-16 18:33:08\", UseCount:4, LastActiveTime:\"2019-08-16 18:33:08\"}\n\t]\n}\n2019-08-16 18:33:09.454  INFO 92273 --- [           main] me.zhongmingmao.druid.PersonDao          : connection=com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@34dc85a\n2019-08-16 18:33:09.467 ERROR 92273 --- [           main] c.alibaba.druid.filter.stat.StatFilter   : slow sql 0 millis. INSERT INTO Person (FIRST_NAME, LAST_NAME, ADDRESS) VALUES (?, ?, ?)[\"Dana\",\"Whitley\",\"464 Yellow Drive\"]\n2019-08-16 18:33:09.470 ERROR 92273 --- [           main] c.alibaba.druid.filter.stat.StatFilter   : slow sql 0 millis. INSERT INTO Person (FIRST_NAME, LAST_NAME, ADDRESS) VALUES (?, ?, ?)[\"Robin\",\"Cash\",\"64 Logic Park\"]\n2019-08-16 18:33:09.507 ERROR 92273 --- [           main] c.alibaba.druid.filter.stat.StatFilter   : slow sql 13 millis. SELECT * FROM PERSON[]\n```\n\n### 监控\n```json\n[{\n\t\"Identity\": 1009326765,\n\t\"Name\": \"DataSource-1009326765\",\n\t\"DbType\": \"h2\",\n\t\"DriverClassName\": \"org.h2.Driver\",\n\t\"URL\": \"jdbc:h2:mem:testDb\",\n\t\"UserName\": \"SA\",\n\t\"FilterClassNames\": [\"com.alibaba.druid.filter.config.ConfigFilter\", \"com.alibaba.druid.wall.WallFilter\", \"com.alibaba.druid.filter.stat.StatFilter\", \"me.zhongmingmao.druid.ConnectionLogFilter\"],\n\t\"WaitThreadCount\": 0,\n\t\"NotEmptyWaitCount\": 0,\n\t\"NotEmptyWaitMillis\": 0,\n\t\"PoolingCount\": 5,\n\t\"PoolingPeak\": 5,\n\t\"PoolingPeakTime\": \"2019-08-16T10:33:08.390+0000\",\n\t\"ActiveCount\": 0,\n\t\"ActivePeak\": 1,\n\t\"ActivePeakTime\": \"2019-08-16T10:33:08.445+0000\",\n\t\"InitialSize\": 5,\n\t\"MinIdle\": 5,\n\t\"MaxActive\": 5,\n\t\"QueryTimeout\": 0,\n\t\"TransactionQueryTimeout\": 0,\n\t\"LoginTimeout\": 0,\n\t\"ValidConnectionCheckerClassName\": null,\n\t\"ExceptionSorterClassName\": null,\n\t\"TestOnBorrow\": true,\n\t\"TestOnReturn\": true,\n\t\"TestWhileIdle\": true,\n\t\"DefaultAutoCommit\": true,\n\t\"DefaultReadOnly\": null,\n\t\"DefaultTransactionIsolation\": null,\n\t\"LogicConnectCount\": 8,\n\t\"LogicCloseCount\": 8,\n\t\"LogicConnectErrorCount\": 0,\n\t\"PhysicalConnectCount\": 5,\n\t\"PhysicalCloseCount\": 0,\n\t\"PhysicalConnectErrorCount\": 0,\n\t\"ExecuteCount\": 5,\n\t\"ExecuteUpdateCount\": 2,\n\t\"ExecuteQueryCount\": 1,\n\t\"ExecuteBatchCount\": 0,\n\t\"ErrorCount\": 0,\n\t\"CommitCount\": 0,\n\t\"RollbackCount\": 0,\n\t\"PSCacheAccessCount\": 0,\n\t\"PSCacheHitCount\": 0,\n\t\"PSCacheMissCount\": 0,\n\t\"StartTransactionCount\": 0,\n\t\"TransactionHistogram\": [0, 0, 0, 0, 0, 0, 0],\n\t\"ConnectionHoldTimeHistogram\": [3, 0, 4, 1, 0, 0, 0, 0],\n\t\"RemoveAbandoned\": false,\n\t\"ClobOpenCount\": 0,\n\t\"BlobOpenCount\": 0,\n\t\"KeepAliveCheckCount\": 0,\n\t\"KeepAlive\": false,\n\t\"FailFast\": false,\n\t\"MaxWait\": -1,\n\t\"MaxWaitThreadCount\": -1,\n\t\"PoolPreparedStatements\": false,\n\t\"MaxPoolPreparedStatementPerConnectionSize\": 10,\n\t\"MinEvictableIdleTimeMillis\": 1800000,\n\t\"MaxEvictableIdleTimeMillis\": 25200000,\n\t\"LogDifferentThread\": true,\n\t\"RecycleErrorCount\": 0,\n\t\"PreparedStatementOpenCount\": 2,\n\t\"PreparedStatementClosedCount\": 2,\n\t\"UseUnfairLock\": false,\n\t\"InitGlobalVariants\": false,\n\t\"InitVariants\": false\n}]\n```\n","tags":["Druid"],"categories":["Spring Boot"]},{"title":"Spring -- HikariCP","url":"%2F2019%2F07%2F29%2Fspring-hikaricp%2F","content":"\n## JMH Benchmarks\n详细见：[HikariCP](https://github.com/brettwooldridge/HikariCP)\n<img src=\"https://spring-1253868755.cos.ap-guangzhou.myqcloud.com/spring-single-hikaricp-jmh-benchmarks.png\" width=1000/>\n\n> One **Connection** Cycle is defined as single `DataSource.getConnection()`/`Connection.close()`.\n\n> One **Statement** Cycle is defined as single `Connection.prepareStatement()`, `Statement.execute()`, `Statement.close()`.\n\n<!-- more -->\n\n## 优化\n详细见：[Down-the-Rabbit-Hole](https://github.com/brettwooldridge/HikariCP/wiki/Down-the-Rabbit-Hole)\n\n### 字节码级别优化\n1. In order to make HikariCP as fast as it is, we went down to **bytecode-level** engineering, and beyond.\n2. We pulled out every **trick** we know to help the **JIT** help you.\n3. We studied the **bytecode output of the compiler**, and even the **assembly output of the JIT** to limit **key routines** to less than the **JIT inline-threshold**.\n4. We flattened inheritance hierarchies, shadowed member variables, eliminated casts.\n\n### 大量小优化\n\n#### FastList\nArrayList<Statement> was replaced with a custom class **FastList** which **eliminates range checking** and **performs removal scans from tail to head**.\n\n##### range check\n1. One non-trivial (**performance-wise**) optimization was **eliminating the use of an ArrayList<Statement>** instance in the ConnectionProxy used to **track open Statement instances**.\n2. When a **Statement** is **closed**, it must be **removed** from this collection\n3. When a **Connection** is **closed**, it must **iterate** the collection and close any open Statement instances, and finally must clear the collection.\n4. The Java **ArrayList**, wisely for **general purpose use**, _**performs a range check upon every get(int index) call**_.\n5. However, because we can provide **guarantees** about our ranges, this check is merely **overhead**.\n\n##### remove\n1. Additionally, the **remove**(Object) implementation performs a scan **from head to tail**.\n2. However common patterns in **JDBC** programming are to close Statements immediately after use, or _**in reverse order of opening**_.\n3. For these cases, a scan that starts at the tail will perform better.\n\n#### ConcurrentBag\n1. HikariCP contains a custom **lock-free** collection called a ConcurrentBag.\n2. The idea was borrowed from the **C# .NET ConcurrentBag** class, but the internal implementation **quite different**.\n3. Provides\n    - **A lock-free design**\n    - **ThreadLocal caching**\n    - **Queue-stealing**\n    - **Direct hand-off optimizations**\n4. Resulting\n    - **high degree of concurrency**\n    - **extremely low latency**\n    - **minimized occurrences of false-sharing**\n\n#### invokevirtual -> invokestatic\n\n##### invokevirtual\nIn order to generate **proxies** for Connection, Statement, and ResultSet instances, HikariCP was **initially** using a **singleton factory**, held in the case of ConnectionProxy in a **static field** (PROXY_FACTORY).\n\nThere was a dozen or so methods resembling the following:\n```java\npublic final PreparedStatement prepareStatement(String sql, String[] columnNames) throws SQLException\n{\n    return PROXY_FACTORY.getProxyPreparedStatement(this, delegate.prepareStatement(sql, columnNames));\n}\n```\nUsing the **original singleton factory**, the generated bytecode looked like this:\n```java\npublic final java.sql.PreparedStatement prepareStatement(java.lang.String, java.lang.String[]) throws java.sql.SQLException;\n    flags: ACC_PRIVATE, ACC_FINAL\n    Code:\n      stack=5, locals=3, args_size=3\n         0: getstatic     #59                 // Field PROXY_FACTORY:Lcom/zaxxer/hikari/proxy/ProxyFactory;\n         3: aload_0\n         4: aload_0\n         5: getfield      #3                  // Field delegate:Ljava/sql/Connection;\n         8: aload_1\n         9: aload_2\n        10: invokeinterface #74,  3           // InterfaceMethod java/sql/Connection.prepareStatement:(Ljava/lang/String;[Ljava/lang/String;)Ljava/sql/PreparedStatement;\n        15: invokevirtual #69                 // Method com/zaxxer/hikari/proxy/ProxyFactory.getProxyPreparedStatement:(Lcom/zaxxer/hikari/proxy/ConnectionProxy;Ljava/sql/PreparedStatement;)Ljava/sql/PreparedStatement;\n        18: return\n```\nYou can see that first there is a **getstatic** call to get the value of the static field PROXY_FACTORY, as well as (lastly) the **invokevirtual** call to getProxyPreparedStatement() on the ProxyFactory instance.\n\n##### invokestatic\nWe **eliminated the singleton factory** (which was generated by **Javassist**) and replaced it with a final class having **static methods** (whose bodies are generated by **Javassist**).\n\nThe Java code became:\n```java\n// com.zaxxer.hikari.pool.ProxyConnection\npublic PreparedStatement prepareStatement(String sql, String[] columnNames) throws SQLException\n{\n   return ProxyFactory.getProxyPreparedStatement(this, trackStatement(delegate.prepareStatement(sql, columnNames)));\n}\n\n// com.zaxxer.hikari.pool.ProxyFactory\nstatic PreparedStatement getProxyPreparedStatement(final ProxyConnection connection, final PreparedStatement statement)\n{\n   // Body is replaced (injected) by JavassistProxyFactory\n   throw new IllegalStateException(\"You need to run the CLI build and you need target/classes in your classpath to run.\");\n}\n```\n\nWhere getProxyPreparedStatement() is a **static method** defined in the ProxyFactory class. The resulting bytecode is:\n```java\nprivate final java.sql.PreparedStatement prepareStatement(java.lang.String, java.lang.String[]) throws java.sql.SQLException;\nflags: ACC_PRIVATE, ACC_FINAL\nCode:\n  stack=4, locals=3, args_size=3\n     0: aload_0\n     1: aload_0\n     2: getfield      #3                  // Field delegate:Ljava/sql/Connection;\n     5: aload_1\n     6: aload_2\n     7: invokeinterface #72,  3           // InterfaceMethod java/sql/Connection.prepareStatement:(Ljava/lang/String;[Ljava/lang/String;)Ljava/sql/PreparedStatement;\n    12: invokestatic  #67                 // Method com/zaxxer/hikari/proxy/ProxyFactory.getProxyPreparedStatement:(Lcom/zaxxer/hikari/proxy/ConnectionProxy;Ljava/sql/PreparedStatement;)Ljava/sql/PreparedStatement;\n    15: areturn\n```\n\nThere are three things of note here:\n- The **getstatic** call is gone.\n- The **invokevirtual** call is replaced with a **invokestatic** call that is _**more easily optimized by the JVM**_\n- Lastly, possibly not noticed at first glance is that the **stack size** is **reduced** from 5 elements to 4 elements.\n    - This is because in the case of **invokevirtual** there is an **implicit passing** of the instance of ProxyFactory on the stack (i.e **this**), and there is an **additional (unseen) pop** of that value from the stack when getProxyPreparedStatement() was called.\n\n## 常用配置\n```\nspring.datasource.type=com.zaxxer.hikari.HikariDataSource\nspring.datasource.hikari.pool-name=MyHikariCp\nspring.datasource.hikari.maximum-pool-size=10\nspring.datasource.hikari.minimum-idle=5\nspring.datasource.hikari.idle-timeout=30000\nspring.datasource.hikari.auto-commit=true\nspring.datasource.hikari.connection-timeout=30000\nspring.datasource.hikari.max-lifetime=1800000\nspring.datasource.hikari.connection-test-query=SELECT 1\n```\n\n```\n2019-08-16 08:10:49.897  INFO 21357 --- [           main] com.zaxxer.hikari.HikariDataSource       : MyHikariCp - Starting...\n2019-08-16 08:10:50.236  INFO 21357 --- [           main] com.zaxxer.hikari.HikariDataSource       : MyHikariCp - Start completed.\n2019-08-16 08:10:50.641  INFO 21357 --- [           main] me.zhongmingmao.hikaricp.PersonDao       : dataSource=HikariDataSource (MyHikariCp)\n2019-08-16 08:10:50.642  INFO 21357 --- [           main] me.zhongmingmao.hikaricp.PersonDao       : connection=HikariProxyConnection@1545077099 wrapping conn0: url=jdbc:h2:mem:testdb user=SA\n2019-08-16 08:10:50.678  INFO 21357 --- [       Thread-8] com.zaxxer.hikari.HikariDataSource       : MyHikariCp - Shutdown initiated...\n2019-08-16 08:10:50.681  INFO 21357 --- [       Thread-8] com.zaxxer.hikari.HikariDataSource       : MyHikariCp - Shutdown completed.\n```\n\n## 参考链接\n1. [HikariCP](https://github.com/brettwooldridge/HikariCP)\n2. [Down-the-Rabbit-Hole](https://github.com/brettwooldridge/HikariCP/wiki/Down-the-Rabbit-Hole)\n3. [Springboot 2.0选择HikariCP](https://blog.csdn.net/zxl315/article/details/80420688)\n","tags":["HikariCP"],"categories":["Spring Boot"]},{"title":"数据结构与算法 -- 数组","url":"%2F2019%2F07%2F28%2Fdata-structure-algorithm-array%2F","content":"\n## 随机访问\n数组是一种**线性表**数据结构，用一组**连续**的内存空间，来存储一组具有**相同类型**的数据\n\n### 线性表\n1. 每个线性表上的数据最多只有**前**和**后**两个方向，线性表结构：**数组**、**链表**、**队列**、**栈**\n2. 在非线性表中，数据之间并不是简单的前后关系，非线性表结构：**二叉树**、**堆**、**图**\n\n### 连续内存 + 相同类型\n连续内存 + 相同类型 => **随机访问**，但_**随机访问 ≠ 随机查询**_\n随机访问原理：$a[i]\\\\_address = base\\\\_address + i \\times data\\\\_type\\\\_size$，随机访问的时间复杂度为**$O(1)$**\n\n<!-- more -->_\n\n## 插入 + 删除\n1. 数组为了**保持内存数据的连续性**，会导致插入操作和删除操作**比较低效**\n2. 插入操作\n    - 假设数组长度为n，将一个数据插入到数组的第K个位置，需要将第k~n的元素都顺序往后挪一位\n    - 在数组**末尾**插入元素，最好时间复杂度$O(1)$；在数组**开头**插入元素，最坏时间复杂度$O(n)$\n    - 假设在每个位置插入元素的概率是一样的，平均时间复杂度为$O(\\sum_{i=1}^ni) = O(n)$\n    - 如果数组中存储的数据并**没有任何规律**，数组只是被当做存储数据的集合\n        - 可以直接把第k位的元素移到数组的最后，再把新元素直接放到第k个位置，时间复杂度为$O(1)$\n3. 删除操作\n    - 与插入数据类似，如果要删除第k个位置的数据，为了保证**内存的连续性**，也需要挪动数据\n    - 删除数组末尾的元素，最好时间复杂度为$O(1)$；删除数组开头的元素，最坏时间复杂度为$O(n)$\n    - 假设删除元素的概率是相同的，平均时间复杂度为$O(n)$\n    - 在某些场景，可以接受数组中数据的**不连续**，那可以将多次删除操作集中一起执行，提高删除效率（采用标记删除）\n        - 当数组没有更多的空间来存储数据时，再触发一次真正的删除操作，类似于JVM的Mark Sweep\n\n## 容器 VS 数组\n业务开发，直接使用容器即可；底层开发，需要将性能做到极致，首选数组\n\n## 下标从0开始\n1. 下标的确切含义：_**偏移**_\n2. 历史原因，C语言从0开始计数\n","tags":["Algorithm"],"categories":["Data Structure & Algorithm"]},{"title":"Spring -- 多数据源","url":"%2F2019%2F07%2F27%2Fspring-multi-data-source%2F","content":"\n## 注意事项\n1. 不同数据源的**配置要分开**\n2. 关注每次使用的数据源\n    - 有多个DataSource时系统如何判断\n    - 对应的设施（事务、ORM）如何选择DataSource\n\n<!-- more -->\n\n## 多数据源配置（二选一）\n1. 配置**@Primary**类型的Bean（DataSource）\n2. 排除Spring Boot的自动配置（**手动配置**）\n    - **DataSourceAutoConfiguration**\n    - **DataSourceTransactionManagerAutoConfiguration**\n    - **JdbcTemplateAutoConfiguration**\n\n## 依赖\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-actuator</artifactId>\n</dependency>\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-jdbc</artifactId>\n</dependency>\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-web</artifactId>\n</dependency>\n<dependency>\n    <groupId>com.h2database</groupId>\n    <artifactId>h2</artifactId>\n    <scope>runtime</scope>\n</dependency>\n```\n\n## application.properties\n```\nmanagement.endpoints.web.exposure.include=*\nfoo.datasource.url=jdbc:h2:mem:foo\nfoo.datasource.username=SA\nfoo.datasource.password=\nbar.datasource.url=jdbc:h2:mem:bar\nbar.datasource.username=SA\nbar.datasource.password=\n```\n\n## DataSourceConfig\n```java\n@Slf4j\n@Configuration\npublic class DataSourceConfig {\n\n    @Bean\n    @ConfigurationProperties(\"foo.datasource\")\n    public DataSourceProperties fooDataSourceProperties() {\n        return new DataSourceProperties();\n    }\n\n    @Bean\n    public DataSource fooDataSource() {\n        DataSourceProperties dataSourceProperties = fooDataSourceProperties();\n        log.info(\"foo datasource : {}\", dataSourceProperties.getUrl());\n        return dataSourceProperties.initializeDataSourceBuilder().build();\n    }\n\n    @Bean\n    @Resource\n    public PlatformTransactionManager fooTxManager(DataSource fooDataSource) {\n        return new DataSourceTransactionManager(fooDataSource);\n    }\n\n    @Bean\n    @ConfigurationProperties(\"bar.datasource\")\n    public DataSourceProperties barDataSourceProperties() {\n        return new DataSourceProperties();\n    }\n\n    @Bean\n    public DataSource barDataSource() {\n        DataSourceProperties dataSourceProperties = barDataSourceProperties();\n        log.info(\"bar datasource : {}\", dataSourceProperties.getUrl());\n        return dataSourceProperties.initializeDataSourceBuilder().build();\n    }\n\n    @Bean\n    @Resource\n    public PlatformTransactionManager barTxManager(DataSource barDataSource) {\n        return new DataSourceTransactionManager(barDataSource);\n    }\n\n}\n```\n\n## MultiDatasourceApplication\n```java\n// 排查自动配置\n@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class,\n        DataSourceTransactionManagerAutoConfiguration.class,\n        JdbcTemplateAutoConfiguration.class})\npublic class MultiDatasourceApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(MultiDatasourceApplication.class, args);\n    }\n\n}\n```\n\n```\nfoo datasource : jdbc:h2:mem:foo\nbar datasource : jdbc:h2:mem:bar\n```\n\n## beans\n```json\n\"fooDataSource\": {\n    \"aliases\": [],\n    \"scope\": \"singleton\",\n    \"type\": \"com.zaxxer.hikari.HikariDataSource\",\n    \"resource\": \"class path resource [me/zhongmingmao/multidatasource/DataSourceConfig.class]\",\n    \"dependencies\": [\"fooDataSourceProperties\"]\n}\n\n\"fooTxManager\": {\n    \"aliases\": [],\n    \"scope\": \"singleton\",\n    \"type\": \"org.springframework.jdbc.datasource.DataSourceTransactionManager\",\n    \"resource\": \"class path resource [me/zhongmingmao/multidatasource/DataSourceConfig.class]\",\n    \"dependencies\": [\"fooDataSource\"]\n}\n```\n","tags":["H2"],"categories":["Spring Boot"]},{"title":"网络协议 -- HTTP","url":"%2F2019%2F07%2F26%2Fnetwork-protocol-http%2F","content":"\n## 准备\n1. 浏览器将域名发送给**DNS**服务器，解析成IP地址\n2. HTTP是基于**TCP**协议的，目前使用的HTTP协议版本大部分都是1.1\n    - HTTP 1.1默认开启了**Keep Alive**机制，这样建立的TCP连接，可以在多次请求中复用\n\n<!-- more -->\n\n## HTTP 1.1\n\n### 请求构建\nHTTP请求的报文分为三大部分：**请求行**、**首部**、**实体**\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-http-request-fmt.png\" width=800/>\n\n```\nGET / HTTP/1.1\nHost: www.163.com\nConnection: close\nUser-Agent: Paw/3.1.7 (Macintosh; OS X/10.14.6) GCDHTTPRequest\n```\n\n#### 方法\n| 方法 | 用途 |\n| ---- | ---- |\n| GET | 获取资源 |\n| POST | **创建资源** |\n| PUT | **修改资源** |\n| DELETE | 删除资源 |\n\n#### 首部字段\n1. 首部是Key-Value，通过**冒号**分隔\n2. **Accept-Charset**：表示**客户端可以接受的字符集**\n3. **Content-Type**：正文的格式\n\n##### 缓存\n高并发系统中，在真正的业务逻辑之前，都需要有个**接入层**（Nginx），将这些静态资源的请求拦截在最外面\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-http-architecture.png\" width=500/>\n\n1. 对于静态资源，有**Varnish**缓存层，当缓存过期的时候，才会真正访问Tomcat应用集群\n2. **Cache-Control**\n    - 当客户端发送的请求中包含**max-age**指令时\n        - 如果判定缓存层中，资源的缓存时间数值比指定的**max-age**小，那么客户端可以接受缓存的资源\n    - 当指定**max-age**值为0，那么缓存层需要将请求转发给**应用集群**\n3. **If-Modified-Since**\n    - 如果服务器的资源在某个时间之后更新了，那么客户端就应该下载最新的资源\n    - 如果没有更新，服务端会返回`304 Not Modified`的响应，那么客户端无需下载，**节省带宽**\n\n### 请求发送\n1. HTTP协议是基于**TCP协议**的，使用**面向连接**的方式发送请求，通过**stream二进制流**的方式传给对方\n2. 到了**TCP层**，会把二进制流变成一个个的**报文段**发送给服务器\n3. 发送的每个报文段，都需要对方返回一个**ACK**，来保证报文可靠地到达了对方\n    - 如果没有返回ACK，TCP层会进行**重传**，保证可达\n    - 同一个包有可能被传了很多次，HTTP层是**无感知**的，只是TCP层在埋头苦干\n4. TCP发送每个报文段时，都需要加上**源地址**和**目标地址**，并将这两个信息放到**IP头**，交给**IP层**进行传输\n5. IP层检查**目标地址**与自己是否在同一个**局域网**\n    - 如果**是**，通过**ARP协议**来请求这个目标地址对应的Mac地址，然后将**源Mac地址**和**目标Mac地址**放入**Mac头**，发送出去\n    - 如果**不是**，需要发送到**网关**，还是需要发送**ARP协议**来获取网关的MAC地址\n        - 网关收到包后发现MAC地址符合，取出**目标IP地址**，根据**路由协议**找到下一跳路由器的MAC地址，发送出去\n        - 路由器一跳一跳终于到达了**目标局域网**，最后一跳的路由器发现**目标IP地址**在自己的某个出口的局域网上\n        - 在这个局域网上发送**ARP协议**，获得目标IP地址的MAC地址，将包发出去\n6. 目标机器发现MAC地址符合，将包收起来，发现IP地址符合，解析IP头，发现是TCP协议\n    - 解析TCP头，里面有**序号**，检查该序号是否需要，如果需要就放入**缓存**中，然后返回一个**ACK**，不需要就丢弃\n7. TCP头里有**端口号**，HTTP服务器正在监听该端口号，目标机器将该包发送给HTTP服务器处理\n\n### 响应构建\nHTTP响应的报文分为三大部分：**状态行**、**首部**、**实体**\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-http-response-fmt.png\" width=800/>\n\n```\nHTTP/1.1 200 OK\nDate: Sat, 10 Aug 2019 07:59:10 GMT\nContent-Type: text/html; charset=GBK\nTransfer-Encoding: chunked\nConnection: close\nExpires: Sat, 10 Aug 2019 08:00:30 GMT\nServer: nginx\nVary: Accept-Encoding\nVary: Accept-Encoding\nCache-Control: max-age=80\nVary: User-Agent\nVary: Accept\nX-Ser: BC41_dx-lt-yd-shandong-jinan-5-cache-6, BC41_dx-lt-yd-shandong-jinan-5-cache-6, BC14_lt-guangdong-jiangmen-1-cache-1\ncdn-user-ip: 112.94.5.72\ncdn-ip: 157.122.98.14\nX-Cache-Remote: MISS\ncdn-source: baishan\n\n$body$\n```\n\n1. 状态行会返回HTTP请求的结果\n2. 首部的**Content-Type**，表示返回正文的类型\n\n### 响应返回\n1. 构造好HTTP返回报文，交给**TCP层**，让TCP层将返回的HTML分成一个个报文段，并保证每个报文段都可靠到达\n2. 这些报文段加上**TCP头**后会交给**IP层**，然后把刚才请求发送的过程反向走一遍\n3. 客户端发现**MAC地址**和**IP地址**符合，就会上交给**TCP层**处理\n4. TCP层根据**序号**判断是否是自己需要的，如果是，就会根据TCP头中的**端口号**，发送给相应的进程（**浏览器**）\n5. 浏览器作为客户端会监听某个端口，当浏览器拿到HTTP报文后，会进行渲染\n\n## HTTP 2.0\n1. HTTP 1.1在应用层以**纯文本**的形式进行通信，每次通信都要带**完整的HTTP头部**，这样在**实时性**和**并发性**上都会存在问题\n2. 为了解决这些问题，HTTP 2.0会对HTTP的**头部**进行一定的**压缩**\n    - 将原来每次都要携带的大量Key-Value在两端都建立一个**索引表**，对**相同**的Key-Value只发送索引表中的**索引**\n3. **流** + **帧**\n    - HTTP 2.0协议**将一个TCP连接切分成多个流**\n        - 每个流都有**ID**标识\n        - 流是**双向**的，可以是客户端发往服务端，也可以是服务端发往客户端\n        - 流只是一个**虚拟的通道**\n        - 流具有**优先级**\n    - HTTP 2.0协议将所有的传输信息**分割为更小的消息和帧**，并对它们采用**二进制格式编码**\n        - 常用的帧有**Header帧**和**Data帧**\n        - Header帧：用户传输**Header**，并且会**开启一个新的流**\n        - Data帧：用来传输**Body**，_**多个Data帧属于同一个流**_\n    - 通过**流+帧**这两种机制\n        - HTTP 2.0的客户端可以**将多个请求分到不同的流**中，然后**将请求内容拆分成帧**，进行**二进制传输**\n        - 帧可以**打散乱序发送**，然后**根据每个帧首部的流标识符重新组装**，并且根据**优先级**，决定优先处理哪个流的数据\n\n### 实例\n1. 假设一个页面要发送三个**独立**的请求，分别获取css、js和jpg，如果使用HTTP 1.1就是**串行**的\n2. 如果使用HTTP 2.0，可以在**一个TCP连接**里**客户端**和**服务端**都可以**同时发送多个请求**\n    - HTTP 2.0其实是_**将三个请求变成三个流，将数据分成帧，乱序发送到同一个TCP连接中**_\n3. HTTP 2.0成功解决了HTTP 1.1的_**队首阻塞问题**_\n    - HTTP 1.1：只能**严格串行地返回响应**，不允许一个TCP连接上的多个响应数据交错到达\n4. HTTP 2.0采用**流+帧**的机制来实现**并行**请求和响应\n    - HTTP 1.1：需要借助**Pipeline机制**（**多条TCP连接**）\n5. HTTP 2.0减少了**TCP连接数**对**服务器性能**的影响，同时**将页面的多个HTTP请求通过一个TCP连接进行传输**，加快页面渲染\n\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-http-v2-example-1.png\" width=600/>\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-http-v2-example-2.png\" width=1000/>\n\n## QUIC\n1. HTTP 2.0虽然大大**增加了并发性**，但依然是**基于TCP协议**，而TCP协议处理包时是有**严格顺序**的\n    - 当其中一个数据包出现问题，TCP连接需要等待这个数据包**完成重传**后才能继续进行\n2. HTTP 2.0通过**流+帧**的机制实现了**逻辑上的并行**，但实际还是会**受限于TCP协议**\n    - 样例：一前一后（序号），前面Stream 2的帧没有收到，后面Stream 1的帧也会因此**阻塞**\n    - 即_**多个Stream之间是有依赖关系的**_\n3. 基于这个背景催生了Google的**QUIC**协议（Quick **UDP** Internet Connections），应用场景：**Gmail**\n    - 可参考[HTTP-over-QUIC to be renamed HTTP/3](https://www.zdnet.com/article/http-over-quic-to-be-renamed-http3/)\n    - QUIC协议通过**基于UDP**来自定义**类似TCP**的连接、重传、多路复用、流量控制技术，进一步提高性能\n\n### 自定义连接机制\n1. 标识TCP连接：<源IP，源端口，目标IP、目标端口>，一旦一个元素发生变化，就需要**断开重连**（**三次握手，有一定时延**）\n2. 基于**UDP**的QUIC协议，不再以四元组标识一个连接，而是采用**64位的随机数**（ID）\n    - UDP是**无连接**的，当IP或者端口变化时，只要ID不变，就不需要重新建立连接\n\n### 自定义重传机制\n1. TCP为了保证**可靠性**，通过**序号**和**应答**机制，来解决**顺序**问题和**丢包**问题\n    - 任何一个序号的包发出去，都要在一定的时间内得到应答，否则一旦超时，就会重发该序号的包\n    - 超时时间是通过**采样往返时间RTT**不断调整的（即**自适应重传算法**），但存在**采样不准确**的问题\n        - 样例：发送一个序号为100的包，发现没有返回，于是**重传**，然后收到ACK101，此时怎么计算RTT？\n2. QUIC也有**序列号**，是**递增**的，任何一个序列号的包_**只发送一次**_\n    - 发送一个包，序号为100，发现没有返回，于是重传，序号变成了101\n    - 如果收到ACK100，就是对第1个包的响应，如果收到ACK101，就是对第2个包的响应，因此RTT的计算**相对准确**\n    - 如何知道包100和包101发送的内容是一样的，QUIC定义了**offset**的概念\n3. **QUIC是面向连接的**，跟TCP一样，是一个**数据流**，发送的数据在这个数据流里面是有**偏移量offset**的\n\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-http-quic-rtt.png\" width=900/>\n\n### 无阻塞的多路复用\n1. 有了自定义的**连接**和**重传**机制，就可以解决HTTP 2.0的**多路复用问题**（**阻塞**）\n2. 与HTTP 2.0一样，**同一条QUIC连接上可以创建多个Stream，来发送多个HTTP请求**\n3. QUIC是基于**UDP**的，一个QUIC连接上的_**多个Stream之间是没有依赖关系的**_\n    - 假如前面Stream 2丢了一个UDP包，后面跟着Stream 3的一个UDP包\n    - 虽然Stream 2丢失的那个UDP需要重传，但Stream 3的UDP包可以直接发送给用户，**不会被阻塞**\n\n### 自定义流量控制\n1. TCP的流量控制是通过**滑动窗口协议**\n2. QUIC的流量控制也是通过**window_update**，来告诉发送端它可以接受的**字节数**\n    - QUIC的窗口是**适应自己的多路复用机制的**：不仅在一个**连接**上控制窗口，还在每个**Stream**上控制窗口\n3. 在TCP协议中，**接收端窗口的起始点**：_**下一个要接收并且ACK的包**_\n    - TCP的ACK机制是**基于序列号的累计应答**：_**哪怕后面的包先到，并且已经放在缓存里，窗口也不能右移**_\n    - 这样就会导致后面的包虽然到了，但由于不能ACK，也有可能**超时重传**，**浪费带宽**\n4. QUIC的ACK是**基于offset**的\n    - 每个offset的包来了，放进了缓存，就可以ACK了，ACK后对应的包就不会重发，中间的空档会等待到来或者重发即可\n    - 窗口的起始位置为**当前收到的最大offset**，从该offset到**当前Stream所能容纳的最大缓存**，为**真正的窗口大小**\n    - 显然，这种方式**更加准确**\n5. 而**整个连接**的窗口，需要**统计**所有的Stream的窗口\n\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-http-quic-flow-control.png\" width=800/>\n","tags":["QUIC"],"categories":["Protocol"]},{"title":"Spring -- 单数据源","url":"%2F2019%2F07%2F25%2Fspring-single-data-source%2F","content":"\n## Spring\n\n### 需要配置的Bean\n1. 数据源相关\n    - **DataSource**（根据选择的**连接池**决定）\n2. 事务相关（可选）\n    - **PlatformTransactionManager**（常用的是**DataSourceTransactionManager**）\n    - **TransactionTemplate**\n3. 操作相关（可选）\n    - **JdbcTemplate**\n\n<!-- more -->\n\n### 依赖\n```xml\n<dependency>\n    <groupId>org.apache.commons</groupId>\n    <artifactId>commons-dbcp2</artifactId>\n    <version>2.7.0</version>\n</dependency>\n<dependency>\n    <groupId>com.h2database</groupId>\n    <artifactId>h2</artifactId>\n    <version>1.4.199</version>\n    <scope>runtime</scope>\n</dependency>\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-context</artifactId>\n    <version>5.1.9.RELEASE</version>\n</dependency>\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-jdbc</artifactId>\n    <version>5.1.9.RELEASE</version>\n</dependency>\n```\n\n<img src=\"https://spring-1253868755.cos.ap-guangzhou.myqcloud.com/spring-single-data-source-simple-dependency.png\" width=400/>\n\n### applicationContext.xml\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:c=\"http://www.springframework.org/schema/c\"\n       xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n    http://www.springframework.org/schema/beans/spring-beans-4.1.xsd\n    http://www.springframework.org/schema/context\n    http://www.springframework.org/schema/context/spring-context-4.1.xsd\">\n\n    <context:component-scan base-package=\"me.zhongmingmao\"/>\n\n    <!-- 代码中配置 -->\n    <!--\n    <bean id=\"dataSource\" class=\"org.apache.commons.dbcp2.BasicDataSource\" destroy-method=\"close\">\n        <property name=\"driverClassName\" value=\"org.h2.Driver\"/>\n        <property name=\"url\" value=\"jdbc:h2:mem:testdb\"/>\n        <property name=\"username\" value=\"SA\"/>\n        <property name=\"password\" value=\"\"/>\n    </bean>\n    -->\n\n</beans>\n```\n\n### Java代码\n```java\n@Configuration\n@EnableTransactionManagement\npublic class DataSourceDemo {\n\n    @Autowired\n    private DataSource dataSource;\n\n    public static void main(String[] args) throws SQLException {\n        ApplicationContext applicationContext =\n                new ClassPathXmlApplicationContext(\"applicationContext*.xml\");\n        showBeans(applicationContext);\n        dataSourceDemo(applicationContext);\n    }\n\n    @Bean(destroyMethod = \"close\")\n    public DataSource dataSource() throws Exception {\n        Properties properties = new Properties();\n        properties.setProperty(\"driverClassName\", \"org.h2.Driver\");\n        properties.setProperty(\"url\", \"jdbc:h2:mem:testdb\");\n        properties.setProperty(\"username\", \"SA\");\n        // dbcp2\n        return BasicDataSourceFactory.createDataSource(properties);\n    }\n\n    @Bean\n    public PlatformTransactionManager transactionManager() throws Exception {\n        return new DataSourceTransactionManager(dataSource());\n    }\n\n    private void showDataSource() throws SQLException {\n        System.out.println(\"dataSource=\" + dataSource);\n        Connection connection = dataSource.getConnection();\n        System.out.println(\"connection=\" + connection);\n        connection.close();\n    }\n\n    private static void showBeans(ApplicationContext applicationContext) {\n        System.out.println(\"beans=\" + Arrays.toString(applicationContext.getBeanDefinitionNames()));\n    }\n\n    private static void dataSourceDemo(ApplicationContext applicationContext) throws SQLException {\n        DataSourceDemo dataSourceDemo = applicationContext.getBean(\"dataSourceDemo\", DataSourceDemo.class);\n        dataSourceDemo.showDataSource();\n    }\n}\n```\n\n```\ndataSource=org.apache.commons.dbcp2.BasicDataSource@2a798d51\nconnection=1704237553, URL=jdbc:h2:mem:testdb, UserName=SA, H2 JDBC Driver\n```\n\n## Spring Boot\n\n### 自动配置\n| 需要配置的Bean | 自动配置 |\n| ---- | ---- |\n| DataSource | **DataSourceAutoConfiguration** |\n| DataSourceTransactionManager | **DataSourceTransactionManagerAutoConfiguration** |\n| JdbcTemplate | **JdbcTemplateAutoConfiguration** |\n\n### 依赖\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-actuator</artifactId>\n</dependency>\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-jdbc</artifactId>\n</dependency>\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-web</artifactId>\n</dependency>\n<dependency>\n    <groupId>com.h2database</groupId>\n    <artifactId>h2</artifactId>\n    <scope>runtime</scope>\n</dependency>\n<dependency>\n    <groupId>org.projectlombok</groupId>\n    <artifactId>lombok</artifactId>\n    <optional>true</optional>\n</dependency>\n```\n\n[Maven Scope](https://www.jianshu.com/p/7145f01ac3ad)\n\n### Java代码\n```java\n@Slf4j\n@SpringBootApplication\npublic class SingleDataSourceApplication implements CommandLineRunner {\n\n    // 依据依赖关系，自动配置\n    @Autowired\n    private DataSource dataSource;\n\n    public static void main(String[] args) {\n        SpringApplication.run(SingleDataSourceApplication.class, args);\n    }\n\n    @Override\n    public void run(String... args) throws Exception {\n        showConnection();\n    }\n\n    private void showConnection() throws SQLException {\n        log.info(\"dataSource={}\", dataSource);\n        Connection connection = dataSource.getConnection();\n        log.info(\"connection={}\", connection);\n        connection.close();\n    }\n}\n```\n\n```\ndataSource=HikariDataSource (null)\nconnection=HikariProxyConnection@1903406683 wrapping conn0: url=jdbc:h2:mem:testdb user=SA\n```\n\n### 查看Bean\n路径：`/actuator/beans`\n\n```json\n\"dataSource\": {\n    \"aliases\": [],\n    \"scope\": \"singleton\",\n    \"type\": \"com.zaxxer.hikari.HikariDataSource\",\n    \"resource\": \"class path resource [org/springframework/boot/autoconfigure/jdbc/DataSourceConfiguration$Hikari.class]\",\n    \"dependencies\": [\"spring.datasource-org.springframework.boot.autoconfigure.jdbc.DataSourceProperties\"]\n}\n\n\"transactionManager\": {\n    \"aliases\": [],\n    \"scope\": \"singleton\",\n    \"type\": \"org.springframework.jdbc.datasource.DataSourceTransactionManager\",\n    \"resource\": \"class path resource [org/springframework/boot/autoconfigure/jdbc/DataSourceTransactionManagerAutoConfiguration$DataSourceTransactionManagerConfiguration.class]\",\n    \"dependencies\": [\"spring.datasource-org.springframework.boot.autoconfigure.jdbc.DataSourceProperties\"]\n}\n\n\"jdbcTemplate\": {\n    \"aliases\": [],\n    \"scope\": \"singleton\",\n    \"type\": \"org.springframework.jdbc.core.JdbcTemplate\",\n    \"resource\": \"class path resource [org/springframework/boot/autoconfigure/jdbc/JdbcTemplateAutoConfiguration$JdbcTemplateConfiguration.class]\",\n    \"dependencies\": []\n}\n```\n\n## H2\n\n### 依赖\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-jdbc</artifactId>\n</dependency>\n<dependency>\n    <groupId>com.h2database</groupId>\n    <artifactId>h2</artifactId>\n    <scope>runtime</scope>\n</dependency>\n```\n\n### schema.sql\n```sql\nCREATE TABLE PERSON(\nID BIGINT  PRIMARY KEY AUTO_INCREMENT,\nFIRST_NAME VARCHAR(255),\nLAST_NAME VARCHAR(255),\nADDRESS VARCHAR(255)\n);\n```\n\n### data.sql\n```sql\nINSERT INTO PERSON (first_Name, Last_Name, Address) VALUES ('Tom', 'Syke', 'Green Valley');\n```\n\n### Person\n```java\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\npublic class Person {\n    private Long id;\n    private String firstName;\n    private String lastName;\n    private String address;\n}\n```\n\n### PersonDao\n```java\n@Slf4j\n@Repository\npublic class PersonDao {\n\n    @Autowired\n    private DataSource dataSource;\n    @Autowired\n    private JdbcTemplate jdbcTemplate;\n\n    public void printDataSource() throws SQLException {\n        log.info(\"dataSource={}\", dataSource);\n        Connection connection = dataSource.getConnection();\n        log.info(\"connection={}\", connection);\n        connection.close();\n    }\n\n    public void save(Person person) {\n        String sql = \"INSERT INTO Person (FIRST_NAME, LAST_NAME, ADDRESS) VALUES (?, ?, ?)\";\n        jdbcTemplate.update(sql, person.getFirstName(), person.getLastName(), person.getAddress());\n    }\n\n    public List<Person> loadAll() {\n        return jdbcTemplate.query(\"SELECT * FROM PERSON\", (resultSet, i) -> toPerson(resultSet));\n    }\n\n    private Person toPerson(ResultSet resultSet) throws SQLException {\n        Person person = new Person();\n        person.setId(resultSet.getLong(\"ID\"));\n        person.setFirstName(resultSet.getString(\"FIRST_NAME\"));\n        person.setLastName(resultSet.getString(\"LAST_NAME\"));\n        person.setAddress(resultSet.getString(\"ADDRESS\"));\n        return person;\n    }\n}\n```\n\n### Client\n```java\n@Component\npublic class Client {\n\n    @Autowired\n    private PersonDao personDao;\n\n    public void run() throws SQLException {\n        personDao.printDataSource();\n\n        personDao.save(new Person(null, \"Dana\", \"Whitley\", \"464 Yellow Drive\"));\n        personDao.save(new Person(null, \"Robin\", \"Cash\", \"64 Logic Park\"));\n\n        List<Person> persons = personDao.loadAll();\n        persons.forEach(System.out::println);\n    }\n}\n```\n\n### SingleDatasourceH2Application\n```java\n@SpringBootApplication\npublic class SingleDatasourceH2Application implements CommandLineRunner {\n\n    @Autowired\n    private Client client;\n\n    public static void main(String[] args) {\n        SpringApplication application = new SpringApplication(SingleDatasourceH2Application.class);\n        application.setBannerMode(Banner.Mode.OFF);\n        application.run(args);\n    }\n\n    @Override\n    public void run(String... args) throws SQLException {\n        client.run();\n    }\n}\n```\n\n```java\ndataSource=HikariDataSource (HikariPool-1)\nconnection=HikariProxyConnection@848961421 wrapping conn0: url=jdbc:h2:mem:testdb user=SA\n\nPerson(id=1, firstName=Tom, lastName=Syke, address=Green Valley)\nPerson(id=2, firstName=Dana, lastName=Whitley, address=464 Yellow Drive)\nPerson(id=3, firstName=Robin, lastName=Cash, address=64 Logic Park)\n```\n","tags":["H2"],"categories":["Spring Boot"]},{"title":"Kafka -- 生产者消息分区机制","url":"%2F2019%2F07%2F24%2Fkafka-producer-partitioning%2F","content":"\n## 分区概念\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-producer-partitioning-topic.png\" width=800/>\n\n<!-- more -->\n\n1. 主题是承载真实数据的**逻辑容器**，主题之下分为若干个分区，Kafka的消息组织方式为三级结构：**主题、分区、消息**\n2. 主题下的每条消息只会保存在某个分区中，而不会在多个分区中被保存多份\n3. 分区的作用是提供**负载均衡**的能力，实现系统的**高伸缩性**\n    - 不同的分区能够被放置在不同的机器节点上，而数据读写操作的粒度也是分区\n    - 每个机器节点都能独立地执行各自分区的读写请求处理，还可以通过添加新的机器节点来增加整体系统的吞吐量\n4. 分区在不同的分布式系统有不同的叫法，但分区的思想都是类似的\n    - Kafka -- **Partition**\n    - MongoDB、Elasticsearch -- **Shard**\n    - HBase -- **Region**\n\n## 分区策略\n1. 分区策略：**决定生产者将消息发送到哪个分区的算法**，Kafka提供了默认的分区策略，也支持自定义的分区策略\n2. 自定义的分区策略，需要**显式**地配置生产者端的参数**partitioner.class**\n3. 实现接口：org.apache.kafka.clients.producer.Partitioner\n    - 消息数据：topic、key、keyBytes、value、valueBytes\n    - 集群数据：cluster\n\n```java\npublic interface Partitioner extends Configurable, Closeable {\n\n    /**\n     * Compute the partition for the given record.\n     *\n     * @param topic The topic name\n     * @param key The key to partition on (or null if no key)\n     * @param keyBytes The serialized key to partition on( or null if no key)\n     * @param value The value to partition on or null\n     * @param valueBytes The serialized value to partition on or null\n     * @param cluster The current cluster metadata\n     */\n    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);\n\n    /**\n     * This is called when partitioner is closed.\n     */\n    public void close();\n\n}\n```\n\n### 轮询策略\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-producer-partitioning-strategy-round-robin.png\" width=800/>\n\n1. 轮询策略是Kafka Java生产者的**默认分区策略**\n2. 轮询策略的**负载均衡表现非常优秀**，总能保证消息**最大限度**地被平均分配到所有分区上，默认情况下它是最合理的分区策略\n\n### 随机策略\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-producer-partitioning-strategy-randomness.png\" width=800/>\n\n从实际表现来看，随机策略要逊于轮询策略，**如果追求数据的均匀分布，建议使用轮询策略**\n```java\n@Override\npublic int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {\n    // 获取Topic的分区数量\n    Integer partitionCount = cluster.partitionCountForTopic(topic);\n    return ThreadLocalRandom.current().nextInt(partitionCount);\n}\n```\n\n### 按消息键保序策略\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-producer-partitioning-strategy-key-ordering.png\" width=800/>\n\n1. Kafka允许为每条消息定义**消息键**，简称为Key\n2. Key可以是一个有明确业务含义的字符串：客户代码、部门编号、业务ID、用来表征消息的元数据等\n3. 一旦消息被定义了Key，可以保证**同一个Key的所有消息都进入到相同的分区里**\n    - 由于每个分区下的消息处理都是**顺序**的，所以这个策略被称为**按消息键保序策略**\n4. Kafka Java生产者的默认分区策略\n    - 如果**指定了Key**，采用**按消息键保序策略**\n    - 如果**没有指定Key**，采用**轮询策略**\n\n```java\n@Override\npublic int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {\n    // 获取Topic的分区数量\n    Integer partitionCount = cluster.partitionCountForTopic(topic);\n    return Math.abs(key.hashCode() % partitionCount);\n}\n```\n\n### 基于地理位置的分区策略\n```java\n@Override\npublic int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {\n    List<PartitionInfo> partitionInfos = cluster.partitionsForTopic(topic);\n    return partitionInfos.stream()\n            .filter(partitionInfo -> isSouth(partitionInfo.leader().host()))\n            .map(PartitionInfo::partition)\n            .findAny().get();\n}\n```\n","tags":["Load Balance"],"categories":["Kafka"]},{"title":"Spring -- HelloSpring","url":"%2F2019%2F07%2F23%2Fspring-hello-spring%2F","content":"\n## Spring Initializr\n<img src=\"https://spring-1253868755.cos.ap-guangzhou.myqcloud.com/spring-hellospring-initializr.png\" width=800/>\n\n<!-- more -->\n\n## 项目结构\n<img src=\"https://spring-1253868755.cos.ap-guangzhou.myqcloud.com/spring-hellospring-structure.png\" width=500/>\n\n## 启动类\n```java\n@SpringBootApplication\n@RestController\npublic class HelloSpringApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(HelloSpringApplication.class, args);\n    }\n\n    @RequestMapping(\"/hello\")\n    public String hello() {\n        return \"Hello Spring\";\n    }\n}\n```\n\n## 启动\n```\n.   ____          _            __ _ _\n/\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n\\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n'  |____| .__|_| |_|_| |_\\__, | / / / /\n=========|_|==============|___/=/_/_/_/\n:: Spring Boot ::        (v2.1.7.RELEASE)\n\n2019-08-07 09:36:51.611  INFO 53865 --- [           main] m.z.hellospring.HelloSpringApplication   : Starting HelloSpringApplication on zhongmingmao.local with PID 53865 (/Users/zhongmingmao/Documents/source_code/github/spring_geek/hello-spring/target/classes started by zhongmingmao in /Users/zhongmingmao/Documents/source_code/github/spring_geek/hello-spring)\n2019-08-07 09:36:51.636  INFO 53865 --- [           main] m.z.hellospring.HelloSpringApplication   : No active profile set, falling back to default profiles: default\n2019-08-07 09:36:54.410  INFO 53865 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)\n2019-08-07 09:36:54.509  INFO 53865 --- [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]\n2019-08-07 09:36:54.509  INFO 53865 --- [           main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.22]\n2019-08-07 09:36:54.748  INFO 53865 --- [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext\n2019-08-07 09:36:54.748  INFO 53865 --- [           main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 3041 ms\n2019-08-07 09:36:55.742  INFO 53865 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'\n2019-08-07 09:36:56.002  INFO 53865 --- [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 2 endpoint(s) beneath base path '/actuator'\n2019-08-07 09:36:56.105  INFO 53865 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''\n2019-08-07 09:36:56.110  INFO 53865 --- [           main] m.z.hellospring.HelloSpringApplication   : Started HelloSpringApplication in 5.404 seconds (JVM running for 7.274)\n2019-08-07 09:36:56.437  INFO 53865 --- [on(4)-127.0.0.1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'\n2019-08-07 09:36:56.437  INFO 53865 --- [on(4)-127.0.0.1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'\n2019-08-07 09:36:56.444  INFO 53865 --- [on(4)-127.0.0.1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 7 ms\n```\n\n## 验证\n```\n$ curl http://localhost:8080/hello\nHello Spring\n\n$ curl http://localhost:8080/actuator/health\n{\"status\":\"UP\"}\n```\n\n## pom\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>2.1.7.RELEASE</version>\n        <relativePath/> <!-- lookup parent from repository -->\n    </parent>\n    <groupId>me.zhongmingmao</groupId>\n    <artifactId>hello-spring</artifactId>\n    <version>0.0.1-SNAPSHOT</version>\n    <name>hello-spring</name>\n    <description>Demo project for Spring Boot</description>\n\n    <properties>\n        <java.version>1.8</java.version>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n            </plugin>\n        </plugins>\n    </build>\n\n</project>\n```\n\n## 打包\n```\n$ mvn clean package -Dmaven.test.skip\n\n$ ll target\ntotal 35800\ndrwxr-xr-x  4 zhongmingmao  staff   128B  8  7 09:42 classes\ndrwxr-xr-x  3 zhongmingmao  staff    96B  8  7 09:42 generated-sources\n-rw-r--r--  1 zhongmingmao  staff    17M  8  7 09:42 hello-spring-0.0.1-SNAPSHOT.jar\n-rw-r--r--  1 zhongmingmao  staff   2.8K  8  7 09:42 hello-spring-0.0.1-SNAPSHOT.jar.original\ndrwxr-xr-x  3 zhongmingmao  staff    96B  8  7 09:42 maven-archiver\ndrwxr-xr-x  3 zhongmingmao  staff    96B  8  7 09:42 maven-status\n\n$ java -jar target/hello-spring-0.0.1-SNAPSHOT.jar\n```\n\n## 自定义parent\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>me.zhongmingmao</groupId>\n    <artifactId>hello-spring</artifactId>\n    <version>0.0.1-SNAPSHOT</version>\n    <name>hello-spring</name>\n    <description>Demo project for Spring Boot</description>\n\n    <properties>\n        <java.version>1.8</java.version>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n\n    <!-- 改动点1 -->\n    <dependencyManagement>\n        <dependencies>\n            <dependency>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-starter-parent</artifactId>\n                <version>2.1.7.RELEASE</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n        </dependencies>\n    </dependencyManagement>\n\n    <build>\n        <plugins>\n            <!-- 改动点2 -->\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n                <executions>\n                    <execution>\n                        <goals>\n                            <goal>repackage</goal>\n                        </goals>\n                    </execution>\n                </executions>\n            </plugin>\n        </plugins>\n    </build>\n\n</project>\n```\n","tags":["Spring Boot"],"categories":["Spring Boot"]},{"title":"Java性能 -- IO模型","url":"%2F2019%2F07%2F22%2Fjava-performance-io-model%2F","content":"\n## 什么是IO\n1. IO是机器获取和交换信息的主要渠道，而**流**是完成IO操作的主要方式\n2. 在计算机中，流是一种**信息的转换**\n3. 流是**有序**的\n    - 把机器或者应用程序接收外界的信息称为**输入流**（InputStream）\n    - 从机器或者应用程序向外输出的信息称为**输出流**（OutputStream）\n4. 流可以被看作一种**数据的载体**，通过它可以实现数据的**交换**和**传输**\n\n<!-- more -->\n\n## Java IO\n1. Java IO主要在java.io下，有四个基本类：**InputStream**、**OutputStream**、**Reader**、**Writer**，分别用于处理**字节流**和**字符流**\n2. 字符到字节必须经过**转码**，该过程**非常耗时**，如果不知道**编码类型**就很容易出现**乱码**问题\n    - 因此IO流提供了**直接操作字符的接口**，方便对**字符**进行**流操作**\n\n### 字节流\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-io-byte-stream.jpg\" width=800/>\n\n1. 字节流的抽象类：**InputStream/OutputStream**\n2. 文件的读写操作：FileInputStream/FileOutputStream\n3. 数组的读写操作：ByteArrayInputStream/ByteArrayOutputStream\n4. 普通字符串的读写操作：BufferedInputStream/BufferedOutputStream\n\n### 字符流\n字符流的抽象类：**Reader/Writer**\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-io-char-stream.jpg\" width=800/>\n\n## 传统IO的性能问题\n1. IO操作分为磁盘IO操作和网络IO操作\n2. **磁盘IO操作**：从磁盘读取数据源输入到内存，之后将读取的信息持久化输出到物理磁盘上\n3. **网络IO操作**：从网络中读取信息输入到内存，最终将信息输出到网络中\n\n### 多次内存复制\n输入操作在操作系统中的具体流程\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-io-multi-copy.jpg\" width=800/>\n\n1. JVM发出read**系统调用**，向内核发起读请求\n2. 内核向硬件发出读指令，并等待**读就绪**\n3. 内核把将要读取的数据**复制**到指定的**内核缓存**中\n4. 操作系统内核将数据**复制**到**用户空间缓冲区**，然后read系统调用返回\n5. 数据先从**外部设备**复制到**内核空间**，再从**内核空间**复制到**用户空间**，发生了**两次内存复制**\n    - 导致不必要的**数据拷贝**和**上下文切换**，**降低了IO性能**\n\n### 阻塞\n1. 在传统IO中，InputStream的read()是一个**while循环操作**，会**一直等待数据读取**，直到数据就绪才会返回\n    - 如果没有数据就绪，读取操作将会一直被**挂起**，用户线程将处于**阻塞**状态\n2. 在发生**大量**连接请求时，需要创建大量监听线程，一旦这些线程发生阻塞，就会**不断地抢夺CPU资源**\n    - _**导致大量的CPU上下文切换，增加系统的性能开销**_\n\n## 优化IO操作\n1. 面对上面两个性能问题，不仅**编程语言**进行了优化，在**操作系统**层面也进行了优化\n2. JDK 1.4发布了java.nio包，NIO的发布优化了**内存复制**以及**阻塞**导致的严重性能问题\n3. JDK 1.7发布了NIO2，从**操作系统**层面实现**异步IO**\n\n### 使用缓冲区 -- 优化读写流操作\n1. 在传统IO中，提出**基于流的IO实现**，即InputStream和OutputStream，这种基于流的实现是以**字节**为单位处理数据\n2. NIO与传统IO不同，它是基于**块**（Block）的，以**块**为单位处理数据\n3. NIO中最为重要的两个组件是**缓冲区**（Buffer）和**通道**（Channel）\n    - Buffer是一块**连续的内存块**，是NIO**读写数据的中转地**\n    - Channel表示**缓冲数据的源头或目的地**，用于**读取**缓冲或者**写入**缓冲，是**访问缓冲的接口**\n4. 传统IO与NIO的最大区别：_**传统IO面向流，NIO面向Buffer**_\n    - Buffer可以将文件**一次性读入**内存再做后续处理，传统IO是**边度边处理**数据\n    - 传统IO后来也使用了**缓冲块**，如BufferedInputStream，但仍然**不能和NIO相媲美**\n5. 使用NIO替代传统IO，可以**立竿见影地提升系统的整体性能**\n\n### 使用DirectBuffer -- 减少内存复制\n1. NIO的Buffer除了做了**缓冲区优化**之外，还提供了**直接访问物理内存**的类：DirectBuffer\n2. _**普通的Buffer分配的是JVM堆内存，而DirectBuffer是直接分配物理内存**_\n3. 输出数据到外部设备\n    - 普通Buffer：从用户空间复制到内核空间，再复制到外部设备\n    - DirectBuffer：**简化为从内核空间复制到外部设备**，减少了数据拷贝\n4. DirectBuffer申请的是非JVM堆内存，_**创建和销毁的代价很高**_\n5. DirectBuffer申请的内存并**不直接由JVM负责GC**\n    - 在DirectBuffer包装类被回收时，会通过**Java Reference机制**来释放该内存块\n\n### 避免阻塞\n1. NIO常被称为Non-Block IO，即**非阻塞IO**，这体现了NIO的特点\n2. **传统IO即使使用了缓冲块，依然存在阻塞问题**\n    - 线程池线程数有限，一旦发生**大量并发请求**，超过最大数量的线程就只能**等待**，直到线程池中有**空闲的线程**可以被复用\n    - 对Socket的输入流进行读取时，会一直**阻塞**，直到发生其中一种情况：**有数据可读**、**连接释放**、**空指针或IO异常**\n3. **阻塞问题是传统IO的最大弊端**，NIO通过**通道**和**多路复用器**这两个组件实现了**非阻塞**\n\n#### 通道（Channel）\n1. 传统IO的数据读写是从**用户空间**到**内核空间**来回复制，内核空间的数据是通过**操作系统层面的IO接口**从磁盘或网络读写的\n2. 最开始，在应用程序调用操作系统IO接口时，**由CPU完成分配**，问题：**发生大量IO请求时，非常消耗CPU**\n3. 后来，操作系统引入**DMA**（Direct memory access）\n    - **内核空间与磁盘之间的存取完全由DMA负责**\n    - 但依然需要向CPU申请权限，且需求借助DMA总线来完成数据的复制操作，如果**DMA总线过多**，会造成**总线冲突**\n4. **Channel有自己的处理器**：可以完成**内核空间**和**磁盘**之间的IO操作\n5. 在NIO中，数据的读写都需要通过Channel，Channel是**双向**的，所以**读写可以同时进行**\n\n#### 多路复用器（Selector）\n1. Selector是Java NIO编程的基础，用于_**检查一个或多个NIO Channel的状态是否处于可读、可写**_\n2. Selector是基于**事件驱动**实现的\n    - 在Selector中**注册accept、read监听事件**，Selector会不断**轮询**注册在其上的Channel\n    - 如果某个Channel上面发生**监听事件**，该Channel就处于**就绪**状态，然后进行IO操作\n3. **一个线程使用一个Selector**，通过**轮询**的方式，可以**监听多个Channel上的事件**\n4. 可以在**注册Channel**时设置该Channel为**非阻塞**\n    - 当Channel上**没有IO操作**时，线程**不会一直等待**，而是会**不断轮询所有Channel**，从而**避免发生阻塞**\n5. 目前操作系统的IO多路复用机制都使用了**epoll**\n    - 相比于传统的select机制，epoll没有**最大连接句柄1024**的限制\n    - 所以Selector理论上可以轮询成千上万的客户端\n\n## AIO\n1. JDK 1.7中，Java发布了NIO2，即**AIO**\n2. AIO实现了**真正意义上的异步IO**，直接将IO操作交给操作系统进行异步处理\n3. 但很多通信框架依然使用NIO，这是因为**异步IO模型在Linux内核中没有实现**\n","tags":["Epoll"],"categories":["Performance"]},{"title":"数据结构与算法 -- 复杂度分析","url":"%2F2019%2F07%2F21%2Fdata-structure-algorithm-complexity-analysis%2F","content":"\n## 大O复杂度表示法\n\n### 累加和\n```java\npublic int cal(int n) {\n    int sum = 0;\n    int i = 1;\n    for (; i <= n; ++i) {\n        sum = sum + i;\n    }\n    return sum;\n}\n```\n\n<!-- more -->\n\n1. 假设每行代码执行的时间都一样，为$U$\n2. 第2、3行分别需要1个$U$的执行时间，第4、5行都运行了n遍，需要$2n \\times U$的执行时间\n3. 这段代码总共需要$(2n+2) \\times U$的执行时间，所有整段代码的总执行时间$T(n)$与每行代码的执行次数成正比\n\n```java\npublic int cal(int n) {\n    int sum = 0;\n    int i = 1;\n    int j;\n    for (; i <= n; ++i) {\n        j = 1;\n        for (; j <= n; ++j) {\n            sum = sum + i * j;\n        }\n    }\n    return sum;\n}\n```\n\n1. 第2、3、4行分别需要1个$U$的执行时间\n2. 第5、6行循环执行了$n$遍，需要$2n \\times U$的执行时间、\n3. 第7、8行循环执行了$n^2$遍，需要$2n^2 \\times U$的执行时间\n4. 所有整段代码的总执行时间$T(n) = (2n^2 + 2n + 3) \\times U$\n\n### 大O\n$$\nT(n) = O(f(n))\n$$\n\n$T(n)$代表代码的**总执行时间**，n表示数据规模的大小，$f(n)$表示每行代码执行的**次数总和**，**$O$表示$T(n)$和$f(n)$成正比**\n大O时间复杂度并不具体表示代码真正的执行时间，而是**代码执行时间随数据规模增长的变化趋势**，称为**渐进时间复杂度**\n公式中的低阶、常量、系数这三部分并不左右增长趋势，只需记录**最大的量级**即可，$T(n) = O(2n^2 + 2n + 3) = O(n^2)$\n\n## 时间复杂度分析\n\n### 量级最大\n只关注循环执行次数最多的一段代码\n```java\npublic int cal(int n) {\n    int sum = 0;            // O(1)\n    int i = 1;              // O(1)\n    for (; i <= n; ++i) {   // O(n)\n        sum = sum + i;      // O(n)\n    }\n    return sum;\n}\n```\n\n### 加法法则\n总复杂度等于**量级最大**的那段代码的复杂度\n```java\npublic int cal(int n) {\n    // 执行了100次，与n的规模无关，0(1)\n    int sum_1 = 0;\n    int p = 1;\n    for (; p < 100; ++p) {\n        sum_1 = sum_1 + p;\n    }\n\n    // O(n)\n    int sum_2 = 0;\n    int q = 1;\n    for (; q < n; ++q) {\n        sum_2 = sum_2 + q;\n    }\n\n    // O(n^2)\n    int sum_3 = 0;\n    int i = 1;\n    int j = 1;\n    for (; i < n; ++i) {\n        j = 1;\n        for (; j <= n; ++j) {\n            sum_3 = sum_3 + i * j;\n        }\n    }\n\n    // O(1) + O(n) + O(n^2) = O(n^2)\n    return sum_1 + sum_2 + sum_3;\n}\n```\n\n### 乘法法则\n嵌套代码的复杂度等于嵌套内外代码复杂度的乘积\n```java\n// O(n^2)\npublic int cal(int n) {\n    int ret = 0;\n    int i = 1;\n    for (; i < n; ++i) {\n        ret = ret + f(i);\n    }\n    return ret;\n}\n\n// O(n)\npublic int f(int n) {\n    int sum = 0;\n    int i = 1;\n    for (; i < n; ++i) {\n        sum = sum + i;\n    }\n    return sum;\n}\n```\n\n### 常见的时间复杂度\n\n#### 多项式量级\n1. 常数阶 $O(1)$\n2. 对数阶 $O(\\log_{}n)$\n3. 线性阶 $O(n)$\n4. 线性对数阶 $O(n\\log_{}n)$\n5. 平方阶 $O(n^2)$、立方阶 $O(n^3)$、k次方阶 $O(n^k)$\n\n#### 非多项式量级\n当数据规模越来越大，非多项式量级的执行时间会**急剧增加**，**效率非常低**\n\n1. 指数阶 $O(2^n)$\n2. 阶乘阶 $O(n!)$\n\n#### $O(1)$\n1. $O(1)$是**常量级**时间复杂度的一种表示方法，并不是指只执行一行代码\n2. 只要代码的执行时间不随n的增大而增大，记为$O(1)$\n\n#### $O(\\log_{}n)$、$O(n\\log_{}n)$\n```java\nint i = 1;\nwhile (i <= n) {\n    i = i * 2;\n}\n```\n$T(n) = O(\\log_{2}n) =  O(\\log_{}n)$\n\n#### $O(m+n)$、$O(m \\times n)$\n```java\n// O(m+n)\npublic int cal(int m, int n) {\n    int sum_1 = 0;\n    for (int i = 1; i <= m; i++) {\n        sum_1 = sum_1 + i;\n    }\n\n    int sum_2 = 0;\n    for (int i = 1; i <= n; i++) {\n        sum_2 = sum_2 + i;\n    }\n    return sum_1 + sum_2;\n}\n```\n\n## 空间复杂度分析\n空间复杂度全称为**渐进空间复杂度**，表示算法的**存储空间**与**数据规模**之间的增长关系\n常见的空间复杂度：$O(1)$、$O(n)$、$O(n^2)$\n\n```java\n// 空间复杂度 O(n)\npublic void print(int n) {\n    int[] a = new int[n];\n    for (int i = 0; i < n; ++i) {\n        a[i] = i * i;\n    }\n    for (int i = n - 1; i >= 0; --i) {\n        System.out.println(a[i]);\n    }\n}\n```\n\n## 最好（坏）时间复杂度\n```java\npublic int find(int[] array, int n, int x) {\n    int pos = -1;\n    for (int i = 0; i < n; i++) {\n        if (array[i] == x) {\n            pos = i;\n            break;\n        }\n    }\n    return pos;\n}\n```\n最好时间复杂度：$O(1)$，最坏时间复杂度：$O(n)$\n\n## 平均时间复杂度\n上面代码有n+1种情况，在数组0~n-1位置和不在数组中，假设每种情况出现的**概率相同**，$\\frac{1}{n+1}$\n大部分情况下，并不需要区分最好、最坏、平均时间复杂度，只有同一代码在不同情况下，时间复杂度有**量级的差距**，才需要区分\n\n$$\nO(\\frac{\\sum_{i=1}^{n}i+n}{n+1}) = O(\\frac{n(n+3)}{2(n+1)}) = O(n)\n$$\n\n### 加权平均\n变量x出现在数组中的概率为$\\frac{1}{2}$，出现在数组中特定某个位置的概率为$\\frac{1}{2n}$\n\n$$\nO(\\sum_{i=1}^{n}{\\frac{i}{2n}} + \\frac{n}{2}) = O(\\frac{3n+1}{4}) = O(n)\n$$\n\n## 均摊时间复杂度\n```java\nprivate int n = 10;\nprivate int[] array = new int[n];\nprivate int count = 0;\n\npublic void insert(int val) {\n    if (count == array.length) {\n        int sum = 0;\n        for (int i = 0; i < array.length; i++) {\n            sum = sum + array[i];\n        }\n        // 清空数组，将求和之后的sum值放入到数组的第一个位置\n        array[0] = sum;\n        count = 1;\n    }\n    array[count] = val;\n    ++count;\n}\n```\n最好时间复杂度：$O(1)$，最坏时间复杂度：$O(n)$，平均时间复杂度：$O(1)$\n假设每种情况出现的概率相同，$\\frac{1}{n+1}$\n\n$$\nO(\\sum_{i=1}^{n}{\\frac{1}{n+1}} + \\frac{n}{n+1}) = O(\\frac{2n}{n+1}) = O(1)\n$$\n\n摊还分析：每一次$O(n)$的插入操作，都会跟着$n-1$次$O(1)$的插入操作，均摊下来，一组连续操作的均摊时间复杂度为$O(1)$\n均摊时间复杂度和摊还分析的应用场景比较特殊，不会经常用到，一般**均摊时间复杂度**就等于**最好时间复杂度**\n均摊时间复杂度可以理解为一种特殊的平均时间复杂度，无需区分\n","tags":["Algorithm"],"categories":["Data Structure & Algorithm"]},{"title":"网络协议 -- Socket","url":"%2F2019%2F07%2F20%2Fnetwork-protocol-socket%2F","content":"\n## 概述\n1. Socket编程进行的是**端到端**的通信，并不清楚中间的网络情况，能够设置的参数，只能是**网络层**和**传输层**\n2. 在**网络层**，Socket函数需要指定是**IPV4**还是**IPV6**，分别设置为**AF_INET**和**AF_INET6**\n3. 在**传输层**，Socket函数需要指定是**TCP**还是**UDP**\n    - TCP协议是基于**数据流**的，设置为**SOCK_STREAM**\n    - UDP协议是基于**数据报**的，设置为**SOCKet_DGRAM**\n\n<!-- more -->\n\n## 基于TCP协议\n\n### 函数调用\n1. TCP的服务端需要先**监听**一个端口，一般是调用**bind**函数，给Socket赋予一个**IP地址**和**端口**\n    - 端口：当一个网络包到达的时候，内核要通过TCP头里面的端口来查找应用程序，并把网络包交给它\n    - IP地址：一台机器可能有多个网卡，也就有多个IP地址，只有发送给某个网卡的地址才会被处理\n2. 当服务端有了IP地址和端口号，就可以调用**listen**函数进行监听，服务端进入**listen**状态，此时客户端可以发起连接\n3. 在内核中，为每个Socket维护两个队列\n    - 一个是**已经建立了连接**的队列，已经完成三次握手，处于**established**状态\n    - 一个是**还没有完成建立连接**的队列，此时三次握手还未完成，处于**syn_rcvd**状态\n4. 服务端调用**accept**函数，拿出一个**已经完成的连接**进行处理\n5. 在服务端等待的时候，客户端可以通过**connect**函数发起连接，在参数中指明要连接的IP地址和端口号，然后发起三次握手\n    - 内核会给客户端分配一个**临时端口**，一旦握手成功，服务端的accept函数就会返回**另一个Socket**\n6. 监听的Socket和真正用来传输数据的Socket是两个，一个称为**监听Socket**，一个称为**已连接Socket**\n7. 连接建立成功之后，双方通过**read**和**write**函数来读写数据，跟往一个**文件流**写数据一样\n\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-socket-tcp.png\" width=500/>\n\n### 数据结构\n1. Socket在Linux中是以**文件**的形式存在的，也存在**文件描述符**，写入和读出都是通过文件描述符\n2. 每个**进程**都有一个数据结构task_struct，里面指向一个**文件描述符数组**（fds），列出这个进程**打开**的所有文件的文件描述符\n3. 文件描述符是一个**整数**，是这个数组（fds）的**下标**，数组的内容是一个**指针**，指向**内核中所有打开的文件列表**（File List）\n4. 文件都有inode，Socket对应的inode会保存在**内存**中，而真正的文件系统上文件的indo会保存在**硬盘**上\n    - 在**innode**中，指向了Socket在**内核中的Socket结构**\n    - 在Socket结构中，主要有两个队列，一个是**发送队列**，一个是**接收队列**\n        - 队列里面保存的是**缓存sk_buff**，sk_buff里面能看到**完整的包结构**\n\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-socket-tcp-task-struct.png\" width=1000/>\n\n## 基于UDP协议\n\n### 函数调用\n1. UDP是**面向无连接**，所以**不需要三次握手**，也不需要调用**listen**和**connect**函数\n    - 但依然需要调用**bind**函数来绑定IP地址和端口号\n2. UDP是**没有维护连接状态**的，因此不需要为每对连接都建立一组Socket，而只需**一个Socket**，就能够和**多个客户端**进行通信\n    - 每次通信，都调用**sendto**和**recvfrom**，都可以传入IP地址和端口\n\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-socket-udp.png\" width=500/>\n\n## TCP连接数\n\n### 最大连接数\n1. 用一个**四元组**来标识一个**TCP连接**，`<本机IP,本机端口,对端IP,对端端口>`\n2. 服务端通常固定在某个本地端口上监听，等待客户端的连接请求，因此服务端TCP连接的四元组只有**对端IP**和**对端端口**\n    - 最大TCP连接数 = 客户端IP数 * 客户端端口数 = 2^32 * 2^16 = **2^48**\n3. 服务端最大并发TCP连接数**远远达不到理论上限**\n    - 首先是**文件描述符限制**，Socket是文件，可以通过**ulimit**配置文件描述符的数目\n    - 其次是**内存限制**，每个TCP连接都要占用一定的内存\n\n### 多进程方式\n1. 监听请求，建立连接后，对应一个**已连接的Socket**，创建一个**子进程**，然后将基于已连接Socket的交互交给子进程来处理\n2. 在Linux下，使用**fork**函数来创建子进程，在父进程的基础上**完全拷贝**一个子进程\n3. 在Linux内核中，会复制以下内容\n    - _**文件描述符列表**_\n    - **内存空间**\n    - 记录**当前执行到哪一行**代码\n4. 调用fork函数，复制完毕后，父进程和子进程都会**记录当前刚刚执行完fork函数**\n    - 父子进程**几乎一模一样**，只是根据fork的返回值来区分到底是父进程，还是子进程\n    - 如果返回值是**0**，则是**子进程**，如果返回值是**其他整数**，就是**父进程**\n5. 因为复制了**文件描述符列表**，而文件描述符都是指向**整个内核统一打开的文件列表**\n    - 父进程刚才因为accept创建的**已连接Socket**也是一个**文件描述符**，同样也会被**子进程**获得\n    - 子进程可以通过这个已连接Socket和客户端进行通信，当通信完毕后，就可以退出子进程\n        - 调用fork函数时，会给父进程返回一个整数，即子进程的ID，父进程可以通过这个ID查看子进程是否需要退出\n\n进程复制过程\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-socket-multi-progress.png\" width=1000/>\n\n### 多线程方式\n1. **线程比进程轻量很多**\n2. 在Linux下，通过**pthread_create**创建一个线程，也是调用do_fork，但很多资源是**共享的**\n    - 例如**文件描述符**、**进程空间**，只不过多了一个**引用**而已\n3. 新的线程也可以通过**已连接的Socket**来处理请求，从而达到**并发处理**的目的\n\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-socket-multi-thread.png\" width=1000/>\n\n### C10K问题\n1. 上面基于进程或者线程的模型，依然存在问题，因为新到来一个TCP连接，就需要分配一个进程或者线程\n2. **一台机器无法创建很多进程或者线程**\n    - C10K，即一台机器如果要维护1W个TCP连接，就要创建1W个进程或线程，这是操作系统无法承受的\n\n### IO多路复用\nIO多路复用，即**一个线程维护多个Socket**\n\n#### select\n1. Socket是**文件描述符**，因而某个线程关注的所有Socket都可以放在一个**文件描述符集合fd_set**\n2. 然后调用**select**函数来监听fd_set是否变化，一旦变化，就会依次查看每个文件描述符\n    - 发生变化的文件描述符在fd_set对应的位都设为**1**，表示Socket可读或者可写，从而进行读写操作\n3. 然后再调用select函数，监听**下一轮**的变化\n\n#### epoll\n1. select函数也存在问题，每次Socket所在的文件描述符集合fd_set中有Socket发生变化的时候，都是通过**轮询**的方式\n    - 即**遍历**文件描述符集合fd_se中**所有**的Socket，**效率不高**\n    - 另外使用select，fd_set的大小受限于**FD_SETSIZE**\n2. epoll函数是通过**事件通知**的方式，效率高很多\n    - epoll函数在内核中的实现方式是**注册callback函数**，当某个文件描述符发生变化时，就会主动通知\n3. 假设进程打开Socket m,n,x等多个文件描述符，现在需要通过epoll来监听这些Socket是否都有事件发生\n    - 其中**epoll_create**创建一个epoll对象（epoll fd），也是一个文件，对应一个**文件描述符**，对应打开文件列表中的一项\n    - 在这项里有一个**红黑树**，在该红黑树里要保存这个**epoll需要监听的所有Socket**\n    - 当epoll_ctl添加一个Socket时，其实是加入这个红黑树，同时红黑树中的**节点**指向一个结构\n        - 该结构在**被监听的Socket的事件列表**中\n        - 当Socket来了一个事件后，可以从这个列表中得到epoll对象，并调用call back通知它\n4. 这种**通知方式**使得监听的Socket数据增加的时候，**效率不会大幅度降低**，能够**同时监听非常多的Socket**\n    - 上限就是系统定义的进程可以打开的最大文件描述符个数（**ulimit**）\n5. _**epoll是解决C10K问题的利器**_\n\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-socket-epoll.png\" width=1000/>\n","tags":["Network Protocol"],"categories":["Protocol"]},{"title":"Kafka -- 集群参数","url":"%2F2019%2F07%2F19%2Fkafka-cluster-param%2F","content":"\n## Broker参数\n\n### 存储\n1. log.dir：表示**单个**路径\n2. log.dirs：表示**多个**路径，**推荐使用**\n    - `/home/kafka1,/home/kafka2,/home/kafka3`\n    - 线上生产环境中一定要为log.dirs配置多个路径，格式为**CSV**，**逗号分隔**\n    - 建议把不同的路径**挂载**到不同的**物理磁盘**上\n        - **提升读写性能**，比起单块硬盘，多块物理磁盘同时读写数据有**更高的吞吐量**\n        - 能够实现**故障转移**（Failover），从Kafka 1.1引入，坏掉的磁盘上的数据会自动地转移到其他正常的磁盘上\n\n<!-- more -->\n\n### Zookeeper\n1. Zookeeper是一个**分布式协调框架**，负责协调管理并保存**Kafka集群的所有元数据信息**\n    - 集群有哪些Broker在运行，创建了哪些Topic，每个Topic有多少分区、分区的Leader副本在哪些机器上\n2. zookeeper.connect，CSV格式，`zk1:2181,zk2:2181,zk3:2181`\n3. Zookeeper地chroot，只需写**一次**，`zk1:2181,zk2:2181,zk3:2181/kafka1`和`zk1:2181,zk2:2181,zk3:2181/kafka2`\n\n### 连接\n1. listeners\n    - 监听器，告知外部连接者通过什么协议来访问指定主机名和端口开放的Kafka服务\n    - 逗号分隔的三元组，格式：`<协议名称，主机名，端口号>`\n        - 协议名称可能是标准的名字，如PLAINTEXT表示明文传输，SSL表示使用SSL或者TLS加密传输\n        - 协议名称也可能是自定义的，如`CONTROLLER://localhost:9092`\n            - 如果使用自定义的协议名称，需要通过`listener.security.protocol.map`来说明底层使用的**安全协议**\n            - listener.security.protocol.map=CONTROLLER:PLAINTEXT\n        - **主机名推荐使用域名，而非IP**\n2. advertised.listeners\n    - 对外发布的监听器\n3. host.name/port\n    - 已过期参数，无需设置\n\n### Topic\n1. auto.create.topics.enable\n    - 是否允许自动创建Topic，建议设置为**false**\n    - 在线上环境，每个部门被分配的Topic应该由运维部门严格把控\n2. unclean.leader.election.enable\n    - 是否允许Unclean Leader选举，建议设置为**false**\n    - Kafka的分区有多个副本，这些副本中只能有一个副本对外提供服务，即**Leader副本**\n    - 并不是所有副本都有资格竞选Leader，_**只有保存数据比较多的副本才有资格竞选Leader**_\n    - 如果保存数据比较多的副本挂了，该参数发挥作用\n        - 设置为false，坚决不让落后太多的副本竞选Leader，后果就是这个**分区不可用**了，因为没有Leader\n        - 设置为true，允许从落后太多的副本中选举出一个Leader，后果就是**数据有可能丢失**\n3. auto.leader.rebalance.enable\n    - 是否允许**定期**进行Leader选举，建议设置为**false**\n    - 与上一参数最大的不同是，它不是选Leader，而是_**换Leader**_\n    - 换Leader的**代价很高**，并且本质上**没有任何性能收益**\n        - 原本向A发送请求的所有客户端都要切换成向B发送请求\n\n### 数据留存\n1. log.retention.{hours|minutes|ms}\n    - 控制**一条消息**可以被保存多长时间，优先级：ms > minutes > hours，推荐使用**hours**\n2. log.retention.bytes\n    - 指定Broker为消息保存的**总磁盘容量大小**，默认值为**-1**，表示**不限制**\n    - 应用场景：在云上构建多租户的Kafka集群，每个租户只能使用100GB的磁盘空间，避免租户恶意使用过多的磁盘空间\n3. message.max.bytes\n    - 控制Broker能够接收的**最大消息大小**\n    - 默认值为1000012，小于1MB，实际场景中，消息突破1MB的场景很常见，所以线上环境一般会设置一个比较大的值\n\n## Topic参数\n如果同时设置了Topic级别参数和全局Broker参数，Topic级别参数会**覆盖**全局Broker参数的值\n\n### 数据留存\nretention.ms、retention.bytes、message.max.bytes\n\n```bash\n# 创建Topic时进行设置，保存最近半年的交易数据，单个消息很大，但也不会超过5MB\n$ kafka-topics --bootstrap-server localhost:9092 --create --topic transaction --partitions 1 --replication-factor 1 --config retention.ms=15552000000 --config max.message.bytes=5242880\n\n# 修改Topic级别参数，将消息的最大大小修改为10MB\n# 推荐使用kafka-configs，社区未来很有可能统一使用kafka-configs来调整Topic级别参数\n$ kafka-configs --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760\n```\n\n## JVM参数\n1. Kafka服务端代码是用**Scala**语言编写的，最终要编译成**Class文件**在**JVM**上运行\n2. 不推荐将Kafka运行在Java 6或Java 7的环境上，Kafka从**2.0.0**开始，正式摒弃**对Java 7的支持**\n3. 将JVM的堆大小设置为**6GB**，这是业界比较公认的合理值，默认的1GB太小\n    - Kafka Broker在与客户端交互时，会在JVM堆上创建大量的**ByteBuffer**实例\n4. 垃圾收集器\n    - Java 7\n        - 如果Broker所在机器的**CPU资源非常充裕**，建议使用**CMS收集器**，-XX:+UseCurrentMarkSweepGC\n        - 否则使用**吞吐量收集器**，-XX:+UseParallelGC\n    - Java 8\n        - 使用**G1收集器**，在没有任何调优的情况下，**G1的表现要优于CMS**\n        - 主要体现在**更少的Full GC**，**更少的调整参数**\n\n```bash\n$ export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g\n$ export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true\n$ kafka-server-start config/server.properties\n```\n\n## OS参数\n1. 文件描述符限制\n    - `ulimit -n`，文件描述符系统资源**并没有很昂贵**，设置成一个很大的值也是合理的\n2. 文件系统类型\n    - **日志型文件系统**：ext3、ext4、XFS，**XFS的性能强于ext4**，所以生产环境最好使用**XFS**\n3. Swappiness\n    - 不建议将Swap空间设置为0\n        - 因为一旦设置为0，当物理内存耗尽时，操作系统会触发**OOM Killer**\n        - OOM Killer会**随机**挑选一个进程然后kill掉，**不会给出任何预警**\n    - 可以将Swap空间设置为很小的值，例如1\n        - 当开始使用Swap空间时，至少能够观测到Broker**性能急剧下降**，留有**调优**和**诊断**问题的时间\n4. Flush落盘时间\n    - 向Kafka发送数据并不需要等到数据被写入磁盘才会认为成功，只需被写入到操作系统的**页缓存**（Page Cache）即可\n    - 随后操作系统根据**LRU算法**会**定期**将页缓存上的**脏数据**落盘到物理磁盘上\n    - Flush落盘时间默认是**5秒**，如果页缓存中的数据在写入到磁盘之前，机器宕机了，会造成**数据丢失**\n    - 但Kafka在**软件层面**已经提供了**多副本的冗余机制**，因此**适当地调大**Flush落盘时间是个合理的做法\n","tags":["Stream"],"categories":["Kafka"]},{"title":"Java性能 -- HashMap","url":"%2F2019%2F07%2F18%2Fjava-performance-hashmap%2F","content":"\n## 实现结构\n1. HashMap是基于**哈希表**实现的，继承了AbstractMap并且实现了Map接口\n2. HashMap根据**键的Hash值**来决定对应值的存储位置，通过这种索引方式，HashMap获取数据的速度会非常快\n3. 当发生**哈希冲突**时，有3种常用的解决方法：**开放定址法**、**再哈希函数法**、**链地址法**\n    - **开放定址法**\n        - 当发生哈希冲突时，如果哈希表**未被填满**，说明在哈希表中必然还有空位置\n        - 可以把Key存放到冲突位置后面的空位置上\n        - 该方法存在很多问题，例如查找、扩容等，**不推荐**\n    - **再哈希函数法**\n        - 在同义词产生地址冲突时再计算另一个哈希函数地址，直到不再冲突\n        - 这种方法不容易产生聚集，但却**增加了计算时间**\n    - **链地址法**\n        - HashMap综合考虑了所有因素，采用了链地址法来解决哈希冲突问题\n        - 该方法采用了**数组（哈希表）+链表**的数据结构，当发生哈希冲突时，就用一个链表结构存储**相同Hash值**的数据\n\n<!-- more -->\n\n## 重要属性\n\n### Node\nHashMap是由一个**Node**数组构成的，每个Node包含一个Key-Value键值对\n```java\ntransient Node<K,V>[] table;\n```\n\nNode类是HashMap的一个内部类，定义了一个next指针，指向具有**相同hash值**的Node对象，构成**链表**\n```java\nstatic class Node<K,V> implements Map.Entry<K,V> {\n    final int hash;\n    final K key;\n    V value;\n    Node<K,V> next;\n}\n```\n\n### loadFactor + threshold\n\n```java\nint threshold;\nfinal float loadFactor;\n```\n1. HashMap还有两个重要的属性：加载因子（**loadFactor**）和边界值（**threshold**）\n2. loadFactor用来**间接设置Entry数组（哈希表）的内存空间大小**，默认值为**0.75**\n3. 对于使用链表法的哈希表来说，查找一个元素的平均时间为`O(1+n)`，n为遍历链表的长度\n    - 加载因子越大，对空间的利用越充分，链表的长度越长，查找效率越低\n    - 加载因子太小，哈希表的数据将过于稀疏，对空间造成严重浪费\n4. Entry数组的threshold是通过初始容量和loadFactor计算所得\n\n## 优化\n\n### 添加元素\n根据key的hashCode()返回值，再通过hash()计算出hash值，再通过(n-1)&hash决定Node的存储位置\n```java\npublic V put(K key, V value) {\n    return putVal(hash(key), key, value, false, true);\n}\n\nstatic final int hash(Object key) {\n    int h;\n    // 尽量打乱hashCode真正参与运算的低16位\n    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n}\n\n// n代表哈希表的长度，一般为2的k次方，(n-1)&hash的计算得到的索引值总是位于table数组的索引之内\nif ((p = tab[i = (n - 1) & hash]) == null)\n    tab[i] = newNode(hash, key, value, null);\n```\n\n#### 流程\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-hashmap-put.jpg\" width=1000/>\n\n#### putVal\n在JDK 1.8中，HashMap引入了**红黑树**数据结构来**提升链表的查询效率**（当链表的长度超过**8**，红黑树的查询效率比链表高）\n当链表长度超过8，HashMap会将链表转换为红黑树，此时新增元素会存在**左旋**和**右旋**，因此**效率会降低**\n```java\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n               boolean evict) {\n    Node<K,V>[] tab; Node<K,V> p; int n, i;\n    // 当table为null或者table的长度为0，即table尚未初始化，通过resize()初始化table\n    if ((tab = table) == null || (n = tab.length) == 0)\n        n = (tab = resize()).length;\n    // 通过(n - 1)&hash计算出table的下标i，table[i]为链表的第一个元素，如果为null，则新建一个节点\n    if ((p = tab[i = (n - 1) & hash]) == null)\n        tab[i] = newNode(hash, key, value, null);\n    else {\n        Node<K,V> e; K k;\n        if (p.hash == hash &&\n            ((k = p.key) == key || (key != null && key.equals(k))))\n            // 首节点为链表节点，key相同的条件：hash值相同 + 满足equals方法\n            e = p;\n        else if (p instanceof TreeNode)\n            // 首节点为红黑树节点，新增元素也只能是红黑树节点\n            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);\n        else {\n            // 首节点为链表节点，新增元素后，可能需要红黑树化\n            for (int binCount = 0; ; ++binCount) {\n                if ((e = p.next) == null) {\n                    p.next = newNode(hash, key, value, null);\n                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st\n                        // 链表转换为红黑树\n                        treeifyBin(tab, hash);\n                    break;\n                }\n                if (e.hash == hash &&\n                    ((k = e.key) == key || (key != null && key.equals(k))))\n                    break;\n                p = e;\n            }\n        }\n        if (e != null) { // existing mapping for key\n            V oldValue = e.value;\n            if (!onlyIfAbsent || oldValue == null)\n                e.value = value;\n            afterNodeAccess(e);\n            return oldValue;\n        }\n    }\n    ++modCount;\n    if (++size > threshold)\n        resize();\n    afterNodeInsertion(evict);\n    return null;\n}\n```\n\n### 获取元素\n1. 当HashMap中只存在数组，而数组中没有Node链表时，是HashMap查询数据性能最好的时候\n2. 一旦发生大量的哈希冲突，就会产生Node链表，这时每次查询都可能遍历Node链表，从而降低查询性能\n    - 特别在**链表长度过长**的情况下，**性能将明显降低**，而**红黑树**能很好地解决了这个问题\n    - 使得查询的平均时间复杂度降低到`O(log(n))`，链表越长，使用红黑树替换后的查询效率提升越明显\n3. 也可以**重写Key的hashCode方法**，**降低哈希冲突**，从而减少链表的产生\n\n### 扩容\n1. HashMap也是**数组类型**的数据结构，也一样存在扩容的情况\n2. JDK 1.7\n    - 分别取出数组元素，一般该元素是**最后一个**放入链表的元素\n    - 然后遍历以该元素为头的单向链表元素，依据每个被遍历元素的**hash值**计算其在新数组中的下标，然后进行交换\n    - 将原来哈希冲突的单向链表**尾部**变成扩容后单向链表的**头部**\n3. JDK 1.8\n    - 扩容数组的长度是**2倍**的关系，假设初始tableSize=4要扩容到8，就是**0100**到**1000**的变化\n    - 在扩容时，只需要判断**原来hash值与oldCap的按位与结果，重新分配索引**\n        - `hash & oldCap == 0`，说明旧有的索引就能覆盖\n        - `hash & oldCap == 1`，说明旧有的索引不能覆盖，索引需要+oldCap\n\n```java\n// JDK 1.8\nif (oldTab != null) {\n    for (int j = 0; j < oldCap; ++j) {\n        Node<K,V> e;\n        if ((e = oldTab[j]) != null) {\n            oldTab[j] = null;\n            if (e.next == null)\n                // 链表只有一个节点，直接Hash\n                newTab[e.hash & (newCap - 1)] = e;\n            else if (e instanceof TreeNode)\n                ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);\n            else { // preserve order\n                // 链表有多个节点，需要遍历\n                Node<K,V> loHead = null, loTail = null;\n                Node<K,V> hiHead = null, hiTail = null;\n                Node<K,V> next;\n                do {\n                    next = e.next;\n                    // 与oldCap按位与为0，索引不变，依然为j\n                    if ((e.hash & oldCap) == 0) {\n                        if (loTail == null)\n                            loHead = e;\n                        else\n                            loTail.next = e;\n                        loTail = e;\n                    }\n                    // 与oldCap按位与为1，索引变成j+oldCap\n                    else {\n                        if (hiTail == null)\n                            hiHead = e;\n                        else\n                            hiTail.next = e;\n                        hiTail = e;\n                    }\n                } while ((e = next) != null);\n                if (loTail != null) {\n                    loTail.next = null;\n                    newTab[j] = loHead;\n                }\n                if (hiTail != null) {\n                    hiTail.next = null;\n                    newTab[j + oldCap] = hiHead;\n                }\n            }\n        }\n    }\n}\n```\n\n## 小结\n1. HashMap通过**哈希表**的数据结构来存储**键值对**，好处：**查询效率高**\n2. 如果**查询操作**比较频繁，可以适当**减小loadFactor**，如果对**内存利用率**要求比较高，可以适当**增加loadFactor**\n3. 在预知存储数据量的情况下，可以**提前设置初始容量**（**初始容量 = 预知数据量 / 加载因子**）\n    - 可以**减少resize()操作**，提高HashMap的效率\n4. HashMap使用**数组+链表**方式实现**链地址法**，当有**哈希冲突**时，将**冲突的键值对**链成一个**链表**\n5. 如果链表过长，查询数据的时间复杂度会增加，HashMap在JDK 1.8中使用**红黑树**来解决这个问题\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-hashmap.jpg\" width=1000/>\n","tags":["HashMap"],"categories":["Performance"]},{"title":"网络协议 -- TCP下","url":"%2F2019%2F07%2F17%2Fnetwork-protocol-tcp-2%2F","content":"\n## 累计应答\n1. 为了保证**顺序性**，每一个包都有一个**ID**（序号），在建立连接的时候，会商定起始的ID是多少，然后按照ID一个个发送\n2. 为了保证不丢包，对应发送的包都要进行应答，但不是一个个应答，而是会**应答某个之前的ID**，该模式称为**累计应答**\n\n<!-- more -->\n\n## 缓存\n为了记录所有发送的包和接收的包，TCP需要发送端和接收端分别用**缓存**来保存这些记录\n\n### 发送端\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-tcp-sender-cache.png\" width=1000/>\n\n1. 发送端的缓存是按照包的ID一个个排列的，根据处理的情况分为四部分\n    - **已经发送 + 已经确认**\n    - **已经发送 + 等待确认**\n    - **可以发送 + 等待发送**\n    - **不能发送**\n2. 在TCP里，接收端会给发送端报一个**窗口**的大小，称为**Advertised window**\n    - Advertised window的大小应该等于上面第2部分+第3部分\n    - **Advertised window表征接收端的处理能力**，超过该窗口大小，接收端处理不过来\n3. 分界线\n    - LastByteAcked：第1部分和第2部分的分界线\n    - LastByteSent：第2部分和第3部分的分界线\n    - **LastByteAcked + AdvertisedWindow**：第3部分和第4部分的分界线\n\n### 接收端\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-tcp-receiver-cache.png\" width=1000/>\n\n1. 根据处理情况分为三部分\n    - **已经接收 + 已经确认**\n    - **等待接收 + 尚未确认**\n    - **不能接收**\n2. 常用计算\n    - MaxRcvBuffer：最大缓存的量\n    - LastByteRead之后：已经接收，但还没有被应用层读取\n    - NextByteExpected：第1部分和第2部分的分界线\n    - _**AdvertisedWindow = MaxRcvBuffer - (NextByteExpected - LastByteRead)**_\n    - _**NextByteExpected + AdvertisedWindow = LastByteRead + MaxRcvBuffer**_ ：第2部分和第3部分的分界线\n3. 在第2部分，由于收到的包可能是**乱序**的，会出现空隙，只有**和第1部分连续**的，才能马上进行回复\n    - 中间空着的部分需要**等待**，哪怕后面的包已经来了\n\n## 顺序 + 丢包\n1. 发送端缓存\n    - 1、2、3：已经发送并确认\n    - 4、5、6、7、8、9：都是发送了未确认\n    - 10、11、12：还未发送出去\n    - 13、14、15：接收端没有空间，不准备发送\n2. 接收端缓存\n    - 1、2、3、4、5：已经完成ACK，但没有读取\n    - 6、7：等待接收\n    - 8、9：已经接收，但没有ACK\n3. 当前状态\n    - 1、2、3：没有问题，双方达成一致\n    - 4、5：接收端ACK，发送端还没收到，有可能是丢了，也有可能在路上\n    - 6、7、8、9：发送端都已经发送，到接收端只收到了8、9，而6、7还没到，出现了**乱序**，虽然缓存了8、9但没法ACK\n    - 可见，顺序问题和丢包问题都有可能发生，因此需要考虑**确认**和**重传**机制\n        - 如果4的ACK到了，5的ACK丢了，怎么处理？\n        - 如果6、7的数据包丢了，怎么处理？\n\n\n### 超时重传\n1. 对每一个**已经发送但尚未确认**的包，都有一个**定时器**，超过一定时间，就重新尝试\n    - 不宜过长，这样超时时间会变长，访问变慢\n    - 不宜过短，必须**大于**往返时间**RTT**，否则会引起**不必要的重传**\n        - TCP通过**采样RTT**，然后进行加权平均，该值是**动态变化**的\n        - 除了采样RTT，还要采样RTT的**波动范围**，计算出一个估计的超时时间\n        - 由于重传时间是动态变化的，因此也称为_**自适应重传算法**_\n2. 如果过段时间后，5、6、7都超时了，就会重新发送，接收端发现5原来接收过，直接丢弃\n    - 6到了，发送ACK，要求下一个是7，但7又丢失了，当7再次超时，需要重传的时候，TCP的策略是_**超时间隔加倍**_\n3. 每当遇到一次超时重传的时候，都会将下一次超时重传间隔设置为先前值的_**两倍**_\n    - 两次超时，说明网络环境很差，不宜频繁反复发送\n4. 超时间隔加倍的策略存在的问题：**超时周期可能相对较长**，需要一个补充机制：_**快速重传**_\n5. **快速重传**\n    - 当接收端**收到一个序号大于下一个所预期的报文段**时，就检测到数据流中的**空隙**，于是发送**3个冗余的ACK**\n    - 客户端收到后，会在定时器**过期之前**，重传丢失的报文段\n    - 例如接收端发现6、8、9都已经收到了，但是所预期的7却没有来，明显是丢失了\n        - 于是发送3个6的ACK，要求下一个是7，客户端收到后，不等定时器超时，**马上重发**\n\n## 流量控制\n**在对数据包的ACK中，同时会携带一个窗口的大小**，假设窗口大小不变，依然为9，4的ACK到达，会右移一位，13也可以发送了\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-tcp-flow-control-1.png\" width=1000/>\n\n如果此时发送端发送很快，会将10、11、12、13全部发送完毕，之后就停止发送了，因为可发送的部分为0\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-tcp-flow-control-2.png\" width=1000/>\n\n当5的ACK到达时，在客户端相当于窗口再向右滑动一格，14可以发送了\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-tcp-flow-control-3.png\" width=1000/>\n\n如果接收端处理太慢，导致缓存中没有空间，可以通过ACK携带**修改窗口大小**的信息，可以设置为0，那么发送端将停止发送\n例如接收端的应用一直不读取缓存中的数据，当6确认后，窗口大小需要缩小为8\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-tcp-flow-control-4.png\" width=1000/>\n\n新的窗口大小8通过6的ACK到达发送端的时候，不会平行右移，而是仅仅右移左面的边，把窗口大小从9改为8\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-tcp-flow-control-5.png\" width=1000/>\n\n如果接收端还是一直不处理数据，随着确认包越来越多，窗口越来越小，直到为0\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-tcp-flow-control-6.png\" width=1000/>\n\n新的窗口大小0通过14的ACK到达发送端，发送端也将窗口调整为0，停止发送\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-tcp-flow-control-7.png\" width=1000/>\n\n这种情况下，发送端会定时发送窗口**探测数据包**，看是否有机会调整窗口的大小\n当接收方比较慢时，要防止**低能窗口综合征**：不要空出一个字节就立马告诉发送端，然后马上又被填满了\n当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口\n\n## 拥塞控制\n1. **rwnd**（Receiver Window）：**滑动窗口**，担心发送方把接收方缓存塞满\n2. **cwnd**（Congestion Window）：**拥塞窗口**，担心把网络塞满\n3. 通过滑动窗口和拥塞窗口共同**控制发送的速度**\n    - _**LastByteSent - LastByteAcked <= min {cwnd, rwnd}**_\n4. 对于TCP协议来说，它压根不知道整个网络都经历了什么，**网络对于TCP来说是一个黑盒**\n5. _**TCP拥塞控制就是在不堵塞、不丢包的情况下，尽量发挥带宽**_\n6. 在网络上，**通道的容量 = 带宽 * 往返时间**\n\n设置**发送窗口**，使得**发送但未确认**的包为**通道的容量**，就能**撑满**整个通道\n假设往返时间为8秒，每秒发送一个包，每个包的大小为1KB\n已经过去8秒，8个包都已经发出去，前4个包到达接收端，但ACK还没有返回，后4个包还在路上，还没被接收\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-tcp-congestion-control-1.png\" width=600/>\n\n如果**调大窗口**，使得单位时间内可以发送更多的包\n原来发送一个包，从一端到达另一端，假设一共经过4个设备，每个设备处理一个包需要耗时1S，所以到达另一端需要耗费4S\n如果发送加快，则单位时间内会有更多的包到达这些中间设备，如果这些设备还只能每秒处理一个包的话，多出来的包会被**丢弃**\n如果中间设备增加**缓存**，处理不过来的包会**排队**，这样包就不会丢失了，但缺点是会**增加时延**，时延到达一定程度，就会**超时重传**\n所以，拥塞控制主要避免两种现象：**包丢失**、**超时重传**，一旦出现这些现象，说明发送速度太快\n\n### 慢启动\n1. 一条TCP连接开始，cwnd设置为1，一次只能发送一个\n2. 当这一个的确认到来的时候，每个确认cwnd加1，此时一次能够发送2个\n3. 当这两个的确认到来的时候，每个确认cwnd加1，两个确认cwnd加2，此时一次能够发送4个\n4. 当这四个的确认到来的时候，每个确认cwnd加1，四个确认cwnd加4，此时一次能够发送8个，**指数型增长**\n    - ssthresh=65535 Byte，当超过**ssthresh**，每收到一个确认，cwnd增加**1/cwnd**\n5. 当这八个的确认到来的时候，每个确认cwnd加1/8，八个确认cwnd加1，此时一次能够发送9个，变成了**线性增长**\n6. 线性增长还是会增长，还是有可能会出现网络拥塞，拥塞的一种表现形式就是**丢包**，需要**超时重传**\n    - 此时**将ssthresh设为cwnd/2，将cwnd设为1，重新开始慢启动**\n    - 一旦超时重传，马上回到解放前，过于**激进**，会造成**网络卡顿**\n\n### 快速重传算法\n1. 当接收端发现丢了一个**中间包**的时候，会发送3次前一个包的ACK，于是发送端会**快速的重传**，不必等待超时再重传\n2. TCP认为这种情况**不严重**，因为**大部分没丢**，只丢了中间一部分，将**cwnd减半为cwnd/2，然后ssthresh=cwnd**\n    - 当3个包返回的时候，cwnd=ssthresh+3，也就是还在**比较高**的值，呈**线性增长**\n\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-tcp-congestion-control-2.png\" width=1000/>\n\n### BBR拥塞算法\n1. TCP拥塞控制主要用来避免**丢包**和**超时重传**，但这两个现象都是有问题的\n    - **丢包并不能代表通道是满的**，例如公网上**带宽不满也会丢包**，此时不能认为网络拥塞并且退缩\n    - TCP的拥塞控制要等到**中间设备的缓存**都被填充满了，才会发生丢包，从而降低速度\n        - 其实TCP**只要填满网络通道**即可，不需要等到把所有的中间设备的缓存都填满\n4. 为了优化上面的两个问题，诞生了**TCP BBR拥塞算法**\n    - 它企图找到一个**平衡点**，通过不断的加快发送速度，将通道填满，但不填满中间设备的缓存（这样会增加时延）\n    - 这个平衡点可以很好地达到**高带宽**和**低延时**的平衡\n\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-tcp-congestion-control-bbr.png\" width=1000/>\n\n## 小结\n1. **滑动窗口**（rwnd）解决的问题：**顺序问题、丢包问题、流量控制**\n2. **拥塞窗口**（cwnd）解决的问题：**拥塞控制**\n","tags":["Network Protocol"],"categories":["Protocol"]},{"title":"网络协议 -- TCP上","url":"%2F2019%2F07%2F16%2Fnetwork-protocol-tcp-1%2F","content":"\n## TCP包头格式\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-tcp-fmt.png\" width=1000/>\n\n<!-- more -->\n\n1. 源端口号和目标端口号与UDP的一致\n2. 序号是为了解决**乱序**问题，确认哪个包应该先到，哪个包应该后到\n3. 确认序号，发出去的包应该有确认，如果没有收到确认就应该重新发送，直到送达，用于解决**不丢包**的问题\n4. TCP是可靠的协议\n    - 从IP层面来讲，如果网络状况很差，是没有任何可靠性保证的\n    - 作为IP的上一层TCP也是无能为力的，唯一能做的就是**不断重传**，**通过各种算法保证**\n5. 状态位\n    - _**SYN是发起一个连接，ACK是回复，RST是重新连接，FIN是结束连接**_\n    - TCP是**面向连接**的，因而双方都要**维护连接的状态**，而带状态位的包的发送，会引起双方的状态变更\n6. 窗口大小\n    - TCP会做**流量控制**，通信双方都要各自声明一个窗口，标识自己当前的**处理能力**\n    - TCP还会做**拥塞控制**\n7. 小结\n    - **序号 - 确保有序**\n    - **确认序号 - 防止丢包**\n    - **状态位 - 连接维护**\n    - **窗口大小 -  流量控制 + 拥塞控制**\n\n## TCP三次握手\n1. TCP**建立连接**，被称为三次握手\n    - 你好，我是A\n    - 你好A，我是B\n    - 你好B\n2. **请求** -> **应答** -> _**应答之应答**_\n\n### 为什么不是两次\n1. 假设网络非常不可靠，A要发起一个连接，如果发了第一个请求后没有得到响应，有三种可能：**丢包**、**超时**、**B拒绝响应**\n2. A会不断重发，终于有一个请求达到了B，但请求到达了B这个事情，A目前还不知道，A有可能还会继续重发\n3. B收到请求包后，知道A想要和它建立连接，如果B拒绝响应，过段时间后A会放弃重试，A和B都认为连接没有建立，这OK\n4. 一旦B愿意建立连接，就会发送应答包给A，如果采用两次握手，对于B来说就有问题了，因为B的应答包同样会面临上面问题\n    - B根本就没办法确认应答包是不是真的能顺利到达A，自然就没办法认为连接已经建立好了\n5. 还有另一个诡异的现象，A和B原本建立了连接，简单通信后，结束了连接，而A之前建立时，可能会重发几次请求包\n    - 有的请求包绕了一大圈又回来了，如果基于两次握手，B会认为这也是一个正常的请求，因此建立了连接\n    - 但这个连接不会进行下去，也没有终结的时候\n6. B发送的应答可能会发送多次，但只要有一次到达A，A就可以认为连接已经建立，因为对A来说，它的消息是**有去有回**的\n7. A会给B发送应答之应答，而B也只有等到这个消息，才能认为连接已经建立，因为对于B来说，它的消息也是**有去有回**的\n\n### 为什么不是四次\n1. 因为**没有必要**，因为A发给B的应答之应答也会丢失，如果推演下去，还应该有个应答之应答之应答，这会没有尽头\n2. 所以4次握手是可以的，但哪怕400次握手也**无法保证真的可靠**，只要双方的消息都有去有回，基本就可以了\n3. 而且大部分情况下，A和B建立连接之后，A会马上发送数据，一旦A发送数据，很多问题就能得到解决\n    - 例如A发送给B的应答之应答丢失了，当A后续发送的数据到达时，B也会可以认为这个连接已经建立\n    - 有例如B直接挂了，当A发送数据时，就会报错，提示B不可达\n4. 如果A建立连接后就不发送数据，在程序设计的时候，可以开启**keepalive**机制，即使没有真实的数据包，也会有**探活包**\n5. 作为服务端B的程序设计者，对于长时间不发包的客户端，应该主动关闭，从而节约系统资源\n\n### 沟通序号\n1. A和B需要沟通各自**发起包**的**起始序号位**，不能直接从1开始，因为往往会**出现冲突**\n2. A连上B之后，发送1、2、3三个包，但发送3的时候，绕路了，于是重新发送\n    - 后来A掉线，重新连上B后，序号又从1开始，然后发生2，但没发送3，但上次绕路的3又回来了，B认为这是下一个包\n    - 但这个绕路回来的3并不是A重连后想发送的3，因此会发生**数据错误**\n3. 因此_**每个连接都要有不同的序号**_\n    - 序号的起始序号是随着时间变化的，可以看成**32位**的计数器，需要很长时间才能重复，绕路的包早已死亡（IP TTL）\n\n### 状态变化时序图\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-tcp-three-way-handshake.png\" width=1000/>\n\n1. 一开始，客户端和服务端都处于**CLOSED**状态\n2. 服务端主动监听某个端口，处于**LISTEN**状态\n3. 客户端主动发起连接SYN，处于**SYN-SENT**状态\n4. 服务端收到客户端发起的连接，返回SYN，并且ACK客户端的SYN，之后处于**SYN-RCVD**状态\n5. 客户端收到服务端发送的SYN和ACK之后，发送ACK的ACK，之后处于**ESTABLISHED**状态，此时A的一发一收成功了\n6. 服务端收到ACK的ACK之后，处于**ESTABLISHED**状态，此时B的一发一收也成功了\n\n## TCP四次挥手\n\n### 过程\n1. A：我不玩了，B：我知道了\n2. 此时只是表明A**不会再发送数据**，但B不能在ACK的时候，直接关闭连接\n    - 因为A发送完最后的数据后，B可能还没有做完自己的事情，还可以继续发送数据，称为**半关闭**状态\n    - 此时A**可以选择不再接收数据**，也可以选择最后接收一段数据，**等待B也主动关闭**\n3. B：我也不玩了，A：好的，此时整个连接就关闭了\n\n### 异常情况\n1. **A说“我不玩了”后，A直接跑路**，因为B还没有发起结束，就算B发起结束，也得不到回答，B不知道如何处理\n2. **A说“我不玩了”后，B直接跑路**，A不知道B是有事情要处理，还是过一会会发送结束\n3. TCP协议专门设计了几个**状态**来处理这些异常情况\n\n### 状态变化时序图\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-tcp-four-way-handshake.png\" width=1000/>\n\n1. A说“我不玩了”，进入**FIN_WAIT_1**状态\n2. B收到“A不玩”的消息，进入**CLOSE_WAIT**状态\n3. A收到“B知道”的消息，进入**FIN_WAIT_2**状态，如果此时**B直接跑路**，A将会永远**停留**在这个状态\n    - TCP协议并没有对这个状态进行处理，但Linux有，可以调整**tcp_fin_timeout**参数\n4. 如果B没有跑路，发送了“B也不玩了”的消息，进入**LAST_ACK**状态\n5. “B也不玩了”的消息到达A后，并且A发送“好的”的ACK后，A的**FIN_WAIT_2**状态结束，按理来说A可以直接跑路\n    - 但万一B收不到最后的ACK，B会重发“B也不玩了”，如果此时A已经跑路的话，B就再也收不到ACK了\n    - 因此TCP协议要求A最后等待一段时间，即进入**TIME_WAIT**状态\n        - 这个时间要足够长，长到如果B没有收到ACK的话，B会重发“B不玩了”，A会重发ACK并且有足够时间到达B\n    - A直接跑路还有另外一个问题，就是A的**端口**会直接空出来，但B不知道，B原来发出的很多包可能都还在路上\n        - 如果A的端口被一个新的应用占用了，新的应用会收到上个连接中B发过来的包，可能会产生混乱\n        - 因此要等到足够长的时间，等到原来B发送的所有包都死亡了，再空出端口来\n\n#### 2MSL\n1. MSL：Maximum Segment Lifetime，**报文最大生存时间**，它是任何报文在网络中存在的最长时间\n2. TCP报文是基于IP协议的，而IP头中有一个TTL域，是IP数据报可以经过的最大路由数\n    - 每经过一个处理它的路由器此值减1，当TTL为0时数据报将被丢弃，同时发送ICMP报文通知源主机\n3. TCP协议规定MSL为2分钟，实际中常用的是**30秒**、**1分钟**、**2分钟**\n4. 如果超过2MSL，B依然没有收到它发出的FIN所对应的ACK，B还会重发FIN，但此时A会直接返回**RST**，表明A已经跑路了\n\n## TCP状态机\n加粗实线是客户端A的状态变迁，加粗虚线是服务端B的状态变迁\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-tcp-state-machine.png\" width=1000/>\n","tags":["Network Protocol"],"categories":["Protocol"]},{"title":"Kafka -- 线上部署","url":"%2F2019%2F07%2F15%2Fkafka-deploy-online%2F","content":"\n## 操作系统\nLinux的表现更胜一筹：**IO模型的使用**、**网络传输效率**、**社区支持度**\n\n### IO模型\n1. 主流的IO模型：阻塞式IO、非阻塞式IO、IO多路复用、信号驱动IO、异步IO，后一种模型比前一种**高级**\n    - Java中的Socket对象的阻塞模式和非阻塞模式，对应阻塞式IO和非阻塞式IO\n    - Linux中的系统调用**select**函数属于**IO多路复用**模型\n    - 大名鼎鼎的**epoll**系统调用则介于第三种模型和第四种模型之间\n    - 很少有Linux系统支持异步IO，Windows系统提供的IOCP线程模型属于异步IO\n2. Kafka客户端底层使用了Java的**selector**，selector在**Linux**上的实现机制是**epoll**，在**Windows**上是**select**\n    - Kafka部署在Linux上，能够获得**更高效的IO性能**\n\n<!-- more -->\n\n### 网络传输效率\n1. Kafka生产和消费的消息都是通过网络传输的，而消息是保存在磁盘上的\n    - 因此Kafka需要在**磁盘**和**网络**间进行**大量的数据传输**\n2. Linux支持**零拷贝**技术\n    - 当数据在**磁盘**和**网络**进行传输时，**避免昂贵的内核态数据拷贝**，从而实现快速的数据传输\n    - 在Windows平台必须等待Java 8 Update 60才能享受到类似Linux零拷贝的福利，而Linux早就支持\n\n### 社区支持度\n1. 社区目前对在Windows平台上发现的Bug**不做任何承诺**\n2. WIndows平台上部署Kafka只适用于个人测试或用于功能验证，不能应用于生产环境\n\n## 磁盘类型\n1. Kafka大量使用磁盘，但使用的方式多为**顺序读写**操作，一定程度上规避了机械硬盘的最大劣势，**随机IO**\n    - 所以SSD并没有太大的性能优势，而且机械硬盘物美价廉\n2. 机械硬盘易损坏而造成的**可靠性差**等缺陷，又由Kafka在**软件层面**提供机制来保证，故使用机械硬盘**性价比**很高\n3. RAID的主要优势：提供**冗余的磁盘存储空间**、提供**负载均衡**\n    - Kafka自身实现了**冗余机制**（副本）来提供**高可靠性**\n    - Kafka通过**分区**的概念，在**软件层面**实现了**负载均衡**\n4. 小结\n    - 如果追求性价比，可以不搭建RAID，使用普通磁盘组成存储空间即可\n    - 使用机械硬盘完全能胜任Kafka线上环境\n\n## 磁盘容量\n1. 场景：每天需要向Kafka集群发送**一亿**条消息，每条消息保存**两份**，默认保存**两周**，消息平均大小为**1KB**\n2. 100,000,000 * 1KB * 2 / 1000 / 1000 = 200GB\n3. 一般情况下，Kafka集群除了**消息数据**还有其他类型的数据，比如**索引数据**，为这些数据预留10%的磁盘空间，220GB\n4. 保存两周，220GB * 14 ≈ 3TB\n5. Kafka支持**数据压缩**，假设压缩比为0.75，3TB * 0.75 = 2.25TB\n6. 预留20%的磁盘空间，2.25TB / 0.8 ≈ 2.bTB\n7. 考虑的因素\n    - **新增消息数**\n    - **消息留存时间**\n    - **平均消息大小**\n    - **备份数**\n    - **是否启动压缩**\n\n## 带宽\n1. 常见带宽：**1Gbps**（千兆网络，常见配置）、**10Gbps**（万兆网络）\n2. 场景：机房环境为**1Gbps**，某个业务的SLA是**一个小时**内处理**1TB**的业务数据\n3. 假设每台Kafka服务都部署在专属的机器上，Kafka最多会用到机器上70%的带宽资源（超过70%，可能会**网络丢包**）\n    - 即单台Kafka服务器**最多**能使用700Mbps的带宽资源\n4. 通常情况下，需要额外预留2/3的资源，即单台服务器使用带宽为700Mbps / 3 ≈ 240Mbps\n5. 需要的服务器数量：1TB / 3600s / 240Mbps ≈ 10，如果备份数量为3，那需要的服务器数量为30\n","tags":["Stream"],"categories":["Kafka"]},{"title":"Java性能 -- Stream","url":"%2F2019%2F07%2F14%2Fjava-performance-stream%2F","content":"\n## Stream API\n1. Java 8集合中的Stream相当于**高级版的Iterator**\n    - Stream API通过**Lambda**表达式对集合进行各种非常便利高效的**聚合操作**，或者**大批量数据操作**\n2. Stream的聚合操作与数据库**SQL**的聚合操作sorted、filter、map等非常类似\n3. 在数据操作方面，Stream不仅可以通过**串行**的方式实现数据操作，还可以通过**并行**的方式处理大批量数据，提高处理效率\n\n<!-- more -->\n\n```java\n// java.util.Collection\ndefault Stream<E> stream() {\n    return StreamSupport.stream(spliterator(), false);\n}\n\ndefault Stream<E> parallelStream() {\n    return StreamSupport.stream(spliterator(), true);\n}\n```\n```java\n@Data\nclass Student {\n    private Integer height;\n    private String sex;\n}\n\nMap<String, List<Student>> map = Maps.newHashMap();\nList<Student> list = Lists.newArrayList();\n\n// 传统的迭代方式\nfor (Student student : list) {\n    if (student.getHeight() > 160) {\n        String sex = student.getSex();\n        if (!map.containsKey(sex)) {\n            map.put(sex, Lists.newArrayList());\n        }\n        map.get(sex).add(student);\n    }\n}\n// Stream API，串行实现\nmap = list.stream().filter((Student s) -> s.getHeight() > 160).collect(Collectors.groupingBy(Student::getSex));\n\n// Stream API，并行实现\nmap = list.parallelStream().filter((Student s) -> s.getHeight() > 160).collect(Collectors.groupingBy(Student::getSex));\n```\n\n## 优化遍历\n\n### Stream操作分类\n1. 分为两大类：**中间操作**（Intermediate operations）和**终结操作**（Terminal operations）\n2. 中间操作只对操作进行了**记录**，即只会返回一个流，不会进行计算操作，而终结操作是实现了**计算**操作\n3. 中间操作又分为**无状态**（Stateless）操作和**有状态**（Stateful）操作\n    - 无状态操作：元素的处理不受之前元素的影响\n    - 有状态操作：该操作只有拿到**所有元素**之后才能继续下去\n4. 终结操作又分为**短路**（Short-circuiting）操作与**非短路**（UnShort-circuiting）操作\n    - 短路操作：遇到某些符合条件的元素就可以得到最终结果\n    - 非短路操作：必须处理完**所有元素**才能得到最终结果\n5. 通常会将中间操作称为**懒操作**，正是因为懒操作结合终结操作，数据源构成的**处理管道**（Pipeline），实现了Stream的高效\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-stream-op-type.jpg\" width=1000/>\n\n### Stream源码实现\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-stream-impl.jpg\" width=1000/>\n\n1. BaseStream和Stream为最顶端的接口类\n    - BaseStream定义了**流的基本接口方法**，如spliterator、isParallel等\n    - Stream定义了**流的常用操作方法**，如map、filter等\n2. ReferencePipeline是一个结构类，通过**定义内部类组装各种操作流**\n    - 内部定义了Head、StatelessOp和StatefulOp三个内部类，实现了BaseStream和Stream的接口方法\n3. Sink接口定义**每个Stream操作之间关系**的协议，包含了begin、end、cancellationRequested、accept方法\n    - ReferencePipeline最终会将整个Stream流操作组装成一个**调用链**\n    - 而调用链上的每个Stream操作的**上下文关系**就是通过Sink接口来定义实现的\n\n### Stream操作叠加\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-stream-sink.jpg\" width=1000/>\n\n1. 一个Stream的各个操作是由**处理管道**组装的，并统一完成数据处理\n2. 在JDK中，每次的中断操作都会以**使用阶段**（Stage）命名\n3. 管道结构通常是由ReferencePipeline类实现的，ReferencePipeline包含Head、StatelessOp、StatefulOp三个内部类\n    - Head类主要用来定义**数据源**操作，初次调用.stream()时，会初次加载Head对象\n    - 接着加载**中间操作**，分为StatelessOp对象和StatefulOp对象\n        - 此时的Stage并没有执行，而是通过AbstractPipeline生成了**中间操作的Stage链表**\n    - 当调用**终结操作**时，会生成一个最终的Stage\n        - 通过这个Stage触发之前的中间操作，从最后一个Stage开始，**递归产生一个Sink链**\n\n#### 样例\n```java\nList<String> names = Arrays.asList(\"张三\", \"李四\", \"王老五\", \"李三\", \"刘老四\", \"王小二\", \"张四\", \"张五六七\");\nString maxLenStartWithZ = names.stream()\n        .filter(name -> name.startsWith(\"张\"))\n        .mapToInt(String::length)\n        .max()\n        .toString();\n```\n\nnames是ArrayList集合，names.stream会调用集合类基础接口Collection的stream方法\n```java\ndefault Stream<E> stream() {\n    return StreamSupport.stream(spliterator(), false);\n}\n```\n\nCollection.stream方法会调用StreamSupport.stream方法，方法中初始化了一个ReferencePipeline的Head内部类对象\n```java\npublic static <T> Stream<T> stream(Spliterator<T> spliterator, boolean parallel) {\n    Objects.requireNonNull(spliterator);\n    return new ReferencePipeline.Head<>(spliterator,\n                                        StreamOpFlag.fromCharacteristics(spliterator),\n                                        parallel);\n}\n```\n\n调用filter和map，两者都是**无状态的中间操作**，因此并没有执行任何操作，只是分别创建了一个**Stage**来**标识**用户的每一次操作\n通常情况下，Stream的操作需要一个回调函数，所以一个**完整的Stage**是由**数据来源、操作、回调函数**组成的三元组表示\n```java\n@Override\npublic final Stream<P_OUT> filter(Predicate<? super P_OUT> predicate) {\n    Objects.requireNonNull(predicate);\n    return new StatelessOp<P_OUT, P_OUT>(this, StreamShape.REFERENCE,\n                                 StreamOpFlag.NOT_SIZED) {\n        @Override\n        Sink<P_OUT> opWrapSink(int flags, Sink<P_OUT> sink) {\n            return new Sink.ChainedReference<P_OUT, P_OUT>(sink) {\n                @Override\n                public void begin(long size) {\n                    downstream.begin(-1);\n                }\n\n                @Override\n                public void accept(P_OUT u) {\n                    if (predicate.test(u))\n                        downstream.accept(u);\n                }\n            };\n        }\n    };\n}\n```\n```java\n@Override\n@SuppressWarnings(\"unchecked\")\npublic final <R> Stream<R> map(Function<? super P_OUT, ? extends R> mapper) {\n    Objects.requireNonNull(mapper);\n    return new StatelessOp<P_OUT, R>(this, StreamShape.REFERENCE,\n                                 StreamOpFlag.NOT_SORTED | StreamOpFlag.NOT_DISTINCT) {\n        @Override\n        Sink<P_OUT> opWrapSink(int flags, Sink<R> sink) {\n            return new Sink.ChainedReference<P_OUT, R>(sink) {\n                @Override\n                public void accept(P_OUT u) {\n                    downstream.accept(mapper.apply(u));\n                }\n            };\n        }\n    };\n}\n```\n\nnew StatelessOp会调用父类AbstractPipeline的构造函数，该构造函数会将前后的Stage联系起来，生成一个**Stage链表**\n```java\nAbstractPipeline(AbstractPipeline<?, E_IN, ?> previousStage, int opFlags) {\n    if (previousStage.linkedOrConsumed)\n        throw new IllegalStateException(MSG_STREAM_LINKED);\n    previousStage.linkedOrConsumed = true;\n    previousStage.nextStage = this; // 将当前的Stage的next指针指向之前的Stage\n\n    this.previousStage = previousStage; // 赋值当前Stage当全局变量previousStage\n    this.sourceOrOpFlags = opFlags & StreamOpFlag.OP_MASK;\n    this.combinedFlags = StreamOpFlag.combineOpFlags(opFlags, previousStage.combinedFlags);\n    this.sourceStage = previousStage.sourceStage;\n    if (opIsStateful())\n        sourceStage.sourceAnyStateful = true;\n    this.depth = previousStage.depth + 1;\n}\n```\n\n创建Stage时，会包含opWrapSink方法，该方法把一个**操作的具体实现**封装在Sink类中，Sink采用**处理->转发**的模式来**叠加操作**\n调用max，会调用ReferencePipeline的max方法\n由于max是**终结操作**，会创建一个**TerminalOp操作**，同时创建一个**ReducingSink**，并且将操作封装在Sink类中\n```java\n@Override\npublic final Optional<P_OUT> max(Comparator<? super P_OUT> comparator) {\n    return reduce(BinaryOperator.maxBy(comparator));\n}\n```\n\n最后调用AbstractPipeline的wrapSink方法，生成一个Sink链表，**Sink链表中的每一个Sink都封装了一个操作的具体实现**\n```java\nfinal <P_IN> Sink<P_IN> wrapSink(Sink<E_OUT> sink) {\n    Objects.requireNonNull(sink);\n\n    for ( @SuppressWarnings(\"rawtypes\") AbstractPipeline p=AbstractPipeline.this; p.depth > 0; p=p.previousStage) {\n        sink = p.opWrapSink(p.previousStage.combinedFlags, sink);\n    }\n    return (Sink<P_IN>) sink;\n}\n```\n\n当Sink链表生成完成后，Stream开始执行，通过Spliterator迭代集合，执行Sink链表中的具体操作\n```java\n@Override\nfinal <P_IN> void copyInto(Sink<P_IN> wrappedSink, Spliterator<P_IN> spliterator) {\n    Objects.requireNonNull(wrappedSink);\n\n    if (!StreamOpFlag.SHORT_CIRCUIT.isKnown(getStreamAndOpFlags())) {\n        wrappedSink.begin(spliterator.getExactSizeIfKnown());\n        spliterator.forEachRemaining(wrappedSink);\n        wrappedSink.end();\n    }\n    else {\n        copyIntoWithCancel(wrappedSink, spliterator);\n    }\n}\n```\n1. java 8中的forEachRemaining会迭代集合\n2. 每迭代一次，都会执行一次filter操作，通过后就会触发map操作，然后将结果放入到**临时数组**object中，再进行下一次迭代\n3. 完成中间操作后，最后触发终结操作max\n\n### Stream并行处理\n```java\nList<String> names = Arrays.asList(\"张三\", \"李四\", \"王老五\", \"李三\", \"刘老四\", \"王小二\", \"张四\", \"张五六七\");\nString maxLenStartWithZ = names.stream()\n        .parallel()\n        .filter(name -> name.startsWith(\"张\"))\n        .mapToInt(String::length)\n        .max()\n        .toString();\n```\n\nStream的并行处理在执行终结操作之前，跟串行处理的实现是一样的，在调用终结方法之后，会调用TerminalOp.evaluateParallel\n```java\nfinal <R> R evaluate(TerminalOp<E_OUT, R> terminalOp) {\n    assert getOutputShape() == terminalOp.inputShape();\n    if (linkedOrConsumed)\n        throw new IllegalStateException(MSG_STREAM_LINKED);\n    linkedOrConsumed = true;\n\n    return isParallel()\n           ? terminalOp.evaluateParallel(this, sourceSpliterator(terminalOp.getOpFlags()))\n           : terminalOp.evaluateSequential(this, sourceSpliterator(terminalOp.getOpFlags()));\n}\n```\n1. 并行处理指的是Stream结合了**ForkJoin**框架，对Stream处理进行了**分片**，Spliterator.estimateSize会**估算**出分片的数据量\n2. 通过预估的数据量获取**最小处理单元**的阈值，如果当前分片大小大于最小处理单元的阈值，就继续切分集合\n3. **每个分片都将会生成一个Sink链表**，当所有分片操作完成后，ForkJoin框架将会合并分片任何结果集\n\n## 合理使用Stream\n1. 在循环迭代次数较少的情况下，常规的迭代方式性能反而更好\n2. 在单核CPU服务器配置环境中，也是常规迭代方式更有优势\n3. 在**大数据循环迭代**中，如果服务器是**多核CPU**的情况，采用**Stream的并行迭代**优势明显\n\n## 小结\n1. Stream将整个操作分解成了**链式结构**，不仅**简化**了遍历操作，还为实现**并行计算**奠定了基础\n2. Stream将遍历元素的操作和对元素的计算分为**中间操作**和**终结操作**\n    - 中间操作又根据元素之间状态有无干扰分为**有状态操作**和**无状态操作**，实现了链式结构中的不同阶段\n3. 串行处理\n    - Stream在执行中间操作时，并不会做实际的数据操作处理，而是将这些中间操作串联起来，最终由终结操作触发\n    - 生成一个**数据处理链表**，通过Java 8的**Spliterator迭代器**进行数据处理\n4. 并行处理\n    - 对中间操作的处理跟串行处理的方式是一样的，但在终结操作中，Stream将结合**ForkJoin**框架对集合进行切片处理\n","tags":["Java Stream"],"categories":["Performance"]},{"title":"Spark Streaming -- Scala语法","url":"%2F2019%2F07%2F12%2Fspark-streaming-scala-grammar%2F","content":"\n## 换行符\n1. Scala是面向**行**的语言，语句可以用**分号**或**换行符**结束\n2. Scala中，如果一行仅有一个语句，末尾的分号通常是**可选**的\n\n<!-- more -->\n\n## 统一类型\n<img src=\"https://spark-streaming-1253868755.cos.ap-guangzhou.myqcloud.com/spark-streaming-scala-type.png\" width=1000/>\n\n1. Scala中没有所谓的基本数据类型，**一切皆对象**，所有的数据类型都是以对象形式存在，**函数也是一种对象**\n2. **Any是所有类型的超类型**，定义了一些通用的方法：equals和hashCode等，Any有两个直接子类：**AnyVal**、**AnyRef**\n3. AnyVal代表**值类型**，其中**Unit是不带任何意义的类型**，在函数返回时，可以以Unit作为返回类型\n4. AnyRef代表**引用类型**，所有非值类型都被定义为引用类型，用户声明的**自定义类型**都属于AnyRef的子类型\n    - Java运行环境调用Scala，AnyRef会被当做Object基类\n5. **Nothing是所有类型的子类型**，包括值类型和引用类型，**Nothing也是Null的子类型**，也被称为**底部类型**\n    - **没有一个值是Nothing类型的**，Nothing类型通常用于程序**非正常结束**的信号\n    - 这与Java中返回**null**类似，可以将Nothing理解为不定义值的表达类型，在非正常返回时使用\n6. **Null是所有引用类型的子类型**，它有一个单例值由关键字Null所定义\n    - Null主要是使得Scala满足**和其他JVM语言的互操作性**\n    - 但是Null是非常容易**引发程序崩溃**的类型，Scala代码中采用了各种机制来避免使用Null类型\n\n```scala\nval list: List[Any] = List(\"a string\", 732, 'c', true, () => \"func\")\nlist.foreach(element => println(element))\n```\n\n## 变量 + 常量\n1. 在程序运行过程中值可能改变的量称为变量，不会发生变化的量称为常量\n2. 声明变量关键字**var**，声明常量关键字**val**\n\n```scala\nvar myVar: String = \"Spark Action\"\nval myVal: String = \"Spark Streaming Action\"\n\n// 根据初始值，进行数据类型推断\nvar myInt = 27\nval myStr = \"Hello, Scala\"\n```\n\n## 条件 + 循环\n1. Scala不支持**break**和**continue**语句\n    - 多数情况下，break和continue不是必要的，可以用**小函数**更好地解决\n    - 在循环中使用continue是非常容易理解的，但在Scala的**函数闭包**中是难以理解的\n    - 如果巧妙地使用**函数字面量**代替continue和break，可以使代码更加精简\n    - 可以用**纯库函数**的形式提供对两者的支持\n2. 从Scala 2.8之后，可以通过`scala.util.control.Breaks._`库来使用break操作\n3. 对于continue，Scala原生库还是没有提供支持，可以通过`scala.util.control.Breaks._`来实现\n\n```scala\nimport util.control.Breaks._\n\nobject BreakTests extends App {\n  var sum = 0\n  // 循环之外\n  breakable {\n    for (i <- 0 to 1000) {\n      sum += i\n      if (sum >= 1000) break\n    }\n  }\n}\n```\n```scala\nimport scala.util.control.Breaks._\n\nobject ContinueTests extends App {\n  for (i <- 0 to 1000) {\n    // 循环之内\n    breakable {\n      if (i % 2 == 0) break\n    }\n  }\n}\n```\n\n## 函数 + 方法\n1. 在Scala中，**一切皆对象**，函数在Scala中也是一个对象，借用函数式编程的思想，函数可以作为参数传递给另一个函数\n2. 在Java中，方法和函数并没有区别，但在Scala中，**Method被翻译成方法**，**Function被翻译成函数**\n    - Scala Method：类中定义的方法，属于类的一部分，与Java的方法类似\n    - Scala Function：代表一个对象，可以像值类型一样赋值给一个变量\n        - Function是一个**完整的对象**，本质上是继承了Trait的类的对象\n        - Function是一个对象，可以作为参数传入到方法中，而Method不行\n    - Scala中使用**def语句**定义**方法**，使用**val语句**定义**函数**\n    - 可以在方法名称后面紧跟一个**空格加下划线**，**将方法转换为函数**，通常编译器会自动完成该操作\n        - 例如将一个方法传入接收函数参数的地方，就会自动转换\n    - 函数和方法是可以**相互转换**的\n\n```scala\nabstract class FunctionMethodTests {\n\n  // 方法定义\n  def m1(x: Int): Int = x + 3\n\n  // 方法声明，没有等号和方法主体，方法会被隐式声明为抽象，包含它的类型也是一个抽象类型\n  // 如果方法没有返回值，可以返回Unit，类似于Java的void\n  def m2(x: Int): Unit\n\n  // 函数\n  val f1 = (x: Int) => x + 3\n  val f2 = m1 _ // 方法转函数\n}\n```\n\n### 函数式编程\n\n#### 可变参数列表\n可变参数列表是指在定义方法时，不需要指定函数参数的个数，而在函数被调用时灵活传入，如同传入一个**变长数组**\n\n```scala\ndef main(args: Array[String]): Unit = {\n  printStrings(\"Java\", \"Scala\", \"Python\")\n}\n\n// 可变参数，只有函数的最后一个参数可以设置为可重复的可变参数列表\ndef printStrings(args: String*) = {\n  var i: Int = 0;\n  for (arg <- args) {\n    println(\"Arg value[\" + i + \"] = \" + arg)\n    i = i + 1\n  }\n}\n```\n\n#### 默认参数值\nJava不支持默认参数值，而Scala支持\n```scala\nobject Test2 {\n  def main(args: Array[String]): Unit = {\n    println(addInt())\n  }\n\n  def addInt(a: Int = 5, b: Int = 7): Int = {\n    var sum: Int = 0\n    sum = a + b\n    return sum\n  }\n}\n```\n\n#### 偏应用函数\n偏应用函数指的是**固定方法的某一个参数**，然后重新声明为一个函数，这是Scala提供的**语法糖**\n\n```scala\ndef main(args: Array[String]): Unit = {\n  val date = new Date\n  // 偏应用函数，_表示缺失，将新函数的索引值重新赋值给logWithDateBound\n  val logWithDateBound = log(date, _: String)\n  logWithDateBound(\"message1\")\n  logWithDateBound(\"message2\")\n  logWithDateBound(\"message3\")\n}\n\ndef log(date: Date, message: String) = {\n  println(date + \" --- \" + message)\n}\n```\n\n#### 指定函数参数名\n在Java或C++中，调用函数时只能按照函数定义时指定的顺序将参数传入，而Scala和Python支持指定参数名\n\n```scala\ndef main(args: Array[String]): Unit = {\n  printInt(b = 5, a = 7)\n}\n\ndef printInt(a: Int, b: Int) = {\n  println(\"a=\" + a + \", b=\" + b)\n}\n```\n\n#### 高级函数\n1. 高阶函数指的是_**操作其他函数的函数**_\n2. 在Scala中，可以将函数作为**参数**来传递或者通过运算**返回一个函数的引用**，这种函数就是高阶函数\n3. 在Java 8引入了**Lambda**表达式，也支持这种特性\n\n```scala\ndef main(args: Array[String]): Unit = {\n  println(apply(layout, 10)) // [10]\n}\n\n// apply()函数使用了另外一个函数f()和值v作为参数，而函数f()又调用了参数v\ndef apply(f: Int => String, v: Int) = f(v)\n\ndef layout[A](x: A) = \"[\" + x.toString + \"]\"\n```\n\n#### 函数柯里化\n1. 函数柯里化是**函数式编程**中的一个概念\n2. 函数柯里化\n    - 将原来接收**两个参数**的函数，变成新的接收**一个参数**的函数\n    - 新的函数返回一个**以第二个参数为参数的函数**\n3. Scala支持函数柯里化\n\n```scala\ndef main(args: Array[String]): Unit = {\n  println(add1(1, 2))\n  println(add2(1)(2))\n}\n\ndef add1(x: Int, y: Int) = x + y\n\n// 柯里化本质上是依次调用了两个普通函数（非柯里化函数）的过程\n// 拆解成：def add2(x:Int) = (y:Int) => x+y\ndef add2(x: Int)(y: Int) = x + y\n}\n```\n\n## 特质、单例和样例类\n\n### 特质\n1. **特质**（Traits）用于在类（Class）之间共享程序**接口**（Interface）和**字段**（Field）\n    - 是Scala独有的一种特性，类似于**Java 8的接口**\n2. **类和对象（Objects）可以扩展特质，但特质不能被实例化，因为特质没有参数**\n\n```scala\ntrait Iterator[A] {\n  def hasNext: Boolean\n\n  def next(): A\n}\n\nclass IntIterator(to: Int) extends Iterator[Int] {\n\n  private var current = 0\n\n  override def hasNext: Boolean = current < to\n\n  override def next(): Int = {\n    if (hasNext) {\n      val t = current\n      current += 1\n      t\n    } else 0\n  }\n}\n\n/* 测试代码 */\nval iterator = new IntIterator(10)\nprintln(iterator.next()) // 0\nprintln(iterator.next()) // 1\n```\n\n#### 混入\n当某个特质被用于**组合类**时，被称为**混入**\n```scala\nabstract class A {\n  val message: String\n}\n\nclass B extends A {\n  override val message: String = \"I'm an instance of class B\"\n}\n\ntrait C extends A {\n  def loudMessage = message.toUpperCase\n}\n\n// 类D有一个父类B和一个混入C\n// 一个类只能有一个父类（extends关键字），但可以有多个混入（with关键字）\n// 混入和某个父类可能有相同的父类，例如A\nclass D extends B with C\n\n/* 测试代码 */\nval d = new D\nprintln(d.message) // I'm an instance of class B\nprintln(d.loudMessage) // I'M AN INSTANCE OF CLASS B\n```\n\n### 单例\nScala在**语言特性**中提供单例的支持，即**object**关键字\n\n```scala\nobject Logger {\n  def info(message: String) = println(s\"INFO:$message\")\n}\n\n/* 测试代码 */\n// 不需要new一个Logger对象，直接Logger.info调用，但又区别于静态函数（static）\nLogger.info(\"Scala object\")\n```\n\n#### 伴生对象\n将**类**和**object**放在**同一个文件**中，形成**伴生对象**\n\n```scala\nimport scala.math._\n\ncase class Circle(radius: Double) {\n\n  import Circle._\n\n  // 单例对象Circle具有可用于每个实例的方法calculateArea\n  def area: Double = calculateArea(radius)\n}\n\nobject Circle {\n  private def calculateArea(radius: Double): Double = Pi * pow(radius, 2.0)\n}\n\n/* 测试代码 */\nval circle = new Circle(5.0)\nprintln(circle.area)\n```\n\n### 样例类\n1. 在Java中，有一种类只有**get/set**方法，在网站开发和数据库绑定的DAO设计模式中比较常见\n2. Scala将这种特殊的类**内化在语言特性**中，即样例类，经常与**模式匹配**结合使用\n\n```scala\ncase class Book(isbn: String)\n\ncase class Message(sender: String, recipient: String, body: String)\n\n/* 样例代码 */\n// 没有使用关键字new来实例化Book类，case类默认会是使用apply方法来处理对象构造\nval book = Book(\"123\")\n\nval message = Message(\"A@gmail.com\", \"B@gmail.com\", \"hello scala\")\n// 使用copy来复制对象\nval m = message.copy(sender = message.sender, recipient = \"C@gmail.com\")\nprintln(m.sender) // A@gmail.com\nprintln(m.recipient) // C@gmail.com\nprintln(m.body) // hello scala\n```\n","tags":["Scala"],"categories":["Spark Streaming"]},{"title":"大数据 -- Spark + Flink","url":"%2F2019%2F07%2F12%2Fbig-data-spark-flink%2F","content":"\n## Spark的缺点\n1. Spark流处理（Spark Streaming、Structured Streaming）的**实时性不够**，无法应对一些对实时性要求很高的流处理场景\n2. 根本原因：Spark的流处理是基于**微批处理**思想，**把流处理看成批处理的一种特殊形式**\n    - 每次接收到一个**时间间隔**的数据才会去处理，所以天生就很难在实时性上有所提升\n3. 在Spark 2.3中提出了连续处理模型，但现在只支持有限的功能，并不能在大项目中使用\n\n<!-- more -->\n\n## Apache Flink\nApache Flink采用了**基于操作符（Operator）的连续流模型**，可以做到**微秒级**的延迟\n\n### 核心模型\n1. Flink中最核心的数据结构是**Stream**，代表**一个运行在多个分区上的并行流**，在Stream上同样可以进行各种**转换**操作\n2. 与Spark的RDD不同的是，Stream代表一个**数据流**而不是静态数据的集合\n3. Stream所包含的数据会随着时间增长而变化，而且Stream上的转换操作都是**逐条**进行的\n    - 这种处理模式决定了Flink会比Spark Streaming有**更低的流处理延迟性**\n4. 当一个Flink程序被执行的时候，会被映射成**Streaming Dataflow**\n    - Streaming Dataflow包括**Stream**和**Operator**\n    - 转换操作符**把一个或多个Stream转换成多个Stream**\n    - 每个Dataflow都有一个**输入数据源**（Source）和一个**输出数据源**（Sink）\n    - 与Spark的RDD转换图类似，Streaming Dataflow也会被组合成一个**有向无环图**去执行\n5. 在Flink中，程序天生是**并行**和**分布式**的\n    - 一个Stream可以包含多个**分区**（Stream Partitions）\n    - 一个操作符可以被分成多个**操作符子任务**，每个子任务可以在不同的**线程**或者不同的**机器节点**中独立执行\n6. Stream在操作符之间传输数据的形式有两种：一对一、重新分布\n    - **一对一**\n        - Stream维护着分区以及元素的顺序，与RDD的窄依赖类似\n    - **重新分布**\n        - Stream中数据的分区会发生改变\n        - 操作符的每个子任务把数据发送到不同的目标子任务\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-flink-streaming-dataflow.jpg\" width=800/>\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-flink-streaming-dataflow-map.jpg\" width=800/>\n\n### 架构\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-flink-architecture.png\" width=1000/>\n\n1. 四层：存储层、部署层、核心引擎层、API和库\n2. **存储层**：Flink兼容多种文件系统如HDFS、Amazon S3，多种数据库如HBase、MongoDB，多种数据流Kafka、Flume\n3. **部署层**：Flink不仅支持本地运行，还能在独立集群或者在被YARN或Mesos管理的集群上运行，也能部署在云端\n4. **核心处理引擎**：所有高级的API及应用库都会被翻译成**包含Stream和Operator的Streaming Dataflow**来执行\n5. **API和库**：核心API是DataSet API和DataStream API\n    - **DataSet**：代表有界的数据集，用来做**批处理**\n    - **DataStream**：代表流数据，用来做**流处理**\n    - 在内部，DataSet是用DataStream来表示，_**静态的有界数据页可以被看作特殊的流数据**_\n    - DataSet和DataStream可以无缝切换，_**Flink的核心是DataStream**_\n    - DataSet和DataStream支持各种基本的转换操作，如map、filter、count、groupBy等\n    - 在DataSet和DataStream之上，有更高层次的Table API，类似于Spark SQL，是关系型的API\n        - **Table API同样统一了Flink的批处理和流处理**\n\n## 对比\n\n### 相同点\n1. 都基于**内存计算**\n2. 都有**统一的批处理和流处理API**，都支持**类似SQL的编程接口**\n3. 都支持很多相同的转换操作，编程都是用类似于**Scala Collection API**的函数式编程模式\n4. 都有**完善的错误恢复机制**\n5. 都支持**Exactly Once的语义一致性**\n\n### 不同点\n\n#### 流处理\n1. **延迟性**\n    - Spark基于**微批量处理**\n        - 把流数据看成一个个小的批处理数据块分别处理，所以延迟性只能做到**秒级**\n    - Flink基于**事件**处理，每当有新的数据输入都会立刻处理，是**真正的流式处理**，支持**毫秒级**计算\n2. **窗口操作**\n    - Spark只支持基于**时间**的窗口操作（处理时间或事件时间）\n    - Flink支持的窗口操作则**非常灵活**，不仅支持时间窗口，还支持基于数据本身的窗口，开发者可以自定义窗口操作\n\n#### SQL功能\n1. Spark和Flink分别提供了**Spark SQL**和**Table API**，来提供SQL交互支持\n2. 相比较而言，**Spark对SQL支持更好**，相应的优化、扩展和性能更好\n\n#### 迭代计算\n1. **Spark对机器学习的支持很好**，因为可以**在内存中缓存中间计算结果**来加速机器学习算法的运行\n2. 但大部分机器学习算法其实是一个**有环的数据流**，在Spark中，却是用**无环有向图**来表示的\n3. Flink支持在运行时间中的**有环数据流**，从而可以更加有效地对机器学习算法进行运算\n\n#### 生态\n1. **Spark的社区更加活跃**，Flink诞生较晚，各种库的功能不如Spark全面\n\n## 小结\n1. 适用场景\n    - Spark\n        - 数据量非常大且逻辑复杂的批数据处理，并且对计算效率有较高要求（如推荐系统）\n        - 基于历史数据的交互式查询，要求响应较快\n        - 基于实时数据流的数据处理，延迟性要求在**数百毫秒到数秒**之间\n    - Flink\n        - 适用于**延迟非常低**的实时数据处理场景（如实时日志报表系统）\n2. 思想\n    - Spark：_**用批处理去模拟流处理**_\n    - Flink：_**用流处理去模拟批处理**_，扩展性更好\n","tags":["Flink"],"categories":["Spark"]},{"title":"大数据 -- 线性回归","url":"%2F2019%2F07%2F11%2Fbig-data-linear-regression%2F","content":"\n## 数据集\n1. 下载链接：[cal_housing](http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html)\n2. 数据集格式\n    - longitude：区域中心的纬度\n    - latitude：区域中心的经度\n    - housingMedianAge：区域内所有房屋年龄的中位数\n    - totalRooms：区域内总房间数\n    - totalBedrooms：区域内总卧室数\n    - population：区域内总人口数\n    - households：区域内总家庭数\n    - medianIncome：区域内人均收入中位数\n    - medianHouseValue：区域房价的中位数\n3. 前面8个属性都可能对房价有影响，假设影响是**线性**的，可以得到类似的公式`A=bB+cC+...iI`，A代表房价，B~I代表属性\n\n<!-- more -->\n\n## 数据清洗\n\n### 创建RDD\n把房屋信息数据和每个属性的定义读入到Spark，并创建两个相应的RDD\n```python\nfrom pyspark.sql import SparkSession\n\n# 初始化SparkSession和SparkContext\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"California Housing\") \\\n    .config(\"spark.executor.memory\", \"1GB\") \\\n    .getOrCreate()\nsc = spark.sparkContext\n\n# 读取数据并创建RDD\nrdd = sc.textFile('/Users/zhongmingmao/Downloads/CaliforniaHousing/cal_housing.data')\n\n# 读取数据每个属性的定义并创建RDD\nheader = sc.textFile('/Users/zhongmingmao/Downloads/CaliforniaHousing/cal_housing.domain')\n```\n\n### collect + take\n```python\n# collect函数会把所有数据都加载到内存中，常用方法是用take函数去只读取RDD中的某几个元素\n>>> header.collect()\n[u'longitude: continuous.', u'latitude: continuous.', u'housingMedianAge: continuous. ', u'totalRooms: continuous. ', u'totalBedrooms: continuous. ', u'population: continuous. ', u'households: continuous. ', u'medianIncome: continuous. ', u'medianHouseValue: continuous. ']\n\n# 读取前两个数据\n>>> rdd.take(2)\n[u'-122.230000,37.880000,41.000000,880.000000,129.000000,322.000000,126.000000,8.325200,452600.000000'\n, u'-122.220000,37.860000,21.000000,7099.000000,1106.000000,2401.000000,1138.000000,8.301400,358500.000000']\n```\n\n### map\n用SparkContext.textFile函数创建的RDD，每个数据都是一个大字符串，各个属性用逗号分隔，用**map**函数把大字符串分隔成数组\n```python\nrdd = rdd.map(lambda line: line.split(\",\"))\n\n>>> rdd.take(2)\n[[u'-122.230000', u'37.880000', u'41.000000', u'880.000000', u'129.000000', u'322.000000', u'126.000000', u'8.325200', u'452600.000000']\n, [u'-122.220000', u'37.860000', u'21.000000', u'7099.000000', u'1106.000000', u'2401.000000', u'1138.000000', u'8.301400', u'358500.000000']]\n```\n\n### doDF\nSpark SQL的DataFrame API在查询**结构化数据**时更加方便，且性能更好，先把**RDD转换为DataFrame**\n```python\nfrom pyspark.sql import Row\n\ndf = rdd.map(lambda line: Row(longitude=line[0],\n                              latitude=line[1],\n                              housingMedianAge=line[2],\n                              totalRooms=line[3],\n                              totalBedRooms=line[4],\n                              population=line[5],\n                              households=line[6],\n                              medianIncome=line[7],\n                              medianHouseValue=line[8])).toDF()\n```\n```python\n>>> df.show()\n+-----------+----------------+---------+-----------+----------------+------------+-----------+-------------+-----------+\n| households|housingMedianAge| latitude|  longitude|medianHouseValue|medianIncome| population|totalBedRooms| totalRooms|\n+-----------+----------------+---------+-----------+----------------+------------+-----------+-------------+-----------+\n| 126.000000|       41.000000|37.880000|-122.230000|   452600.000000|    8.325200| 322.000000|   129.000000| 880.000000|\n|1138.000000|       21.000000|37.860000|-122.220000|   358500.000000|    8.301400|2401.000000|  1106.000000|7099.000000|\n| 177.000000|       52.000000|37.850000|-122.240000|   352100.000000|    7.257400| 496.000000|   190.000000|1467.000000|\n| 219.000000|       52.000000|37.850000|-122.250000|   341300.000000|    5.643100| 558.000000|   235.000000|1274.000000|\n| 259.000000|       52.000000|37.850000|-122.250000|   342200.000000|    3.846200| 565.000000|   280.000000|1627.000000|\n| 193.000000|       52.000000|37.850000|-122.250000|   269700.000000|    4.036800| 413.000000|   213.000000| 919.000000|\n| 514.000000|       52.000000|37.840000|-122.250000|   299200.000000|    3.659100|1094.000000|   489.000000|2535.000000|\n| 647.000000|       52.000000|37.840000|-122.250000|   241400.000000|    3.120000|1157.000000|   687.000000|3104.000000|\n| 595.000000|       42.000000|37.840000|-122.260000|   226700.000000|    2.080400|1206.000000|   665.000000|2555.000000|\n| 714.000000|       52.000000|37.840000|-122.250000|   261100.000000|    3.691200|1551.000000|   707.000000|3549.000000|\n| 402.000000|       52.000000|37.850000|-122.260000|   281500.000000|    3.203100| 910.000000|   434.000000|2202.000000|\n| 734.000000|       52.000000|37.850000|-122.260000|   241800.000000|    3.270500|1504.000000|   752.000000|3503.000000|\n| 468.000000|       52.000000|37.850000|-122.260000|   213500.000000|    3.075000|1098.000000|   474.000000|2491.000000|\n| 174.000000|       52.000000|37.840000|-122.260000|   191300.000000|    2.673600| 345.000000|   191.000000| 696.000000|\n| 620.000000|       52.000000|37.850000|-122.260000|   159200.000000|    1.916700|1212.000000|   626.000000|2643.000000|\n| 264.000000|       50.000000|37.850000|-122.260000|   140000.000000|    2.125000| 697.000000|   283.000000|1120.000000|\n| 331.000000|       52.000000|37.850000|-122.270000|   152500.000000|    2.775000| 793.000000|   347.000000|1966.000000|\n| 303.000000|       52.000000|37.850000|-122.270000|   155500.000000|    2.120200| 648.000000|   293.000000|1228.000000|\n| 419.000000|       50.000000|37.840000|-122.260000|   158700.000000|    1.991100| 990.000000|   455.000000|2239.000000|\n| 275.000000|       52.000000|37.840000|-122.270000|   162900.000000|    2.603300| 690.000000|   298.000000|1503.000000|\n+-----------+----------------+---------+-----------+----------------+------------+-----------+-------------+-----------+\nonly showing top 20 rows\n```\n\n### cast\n每一列的数据格式都是string，通过cast()函数把每一列的类型转换成float\n```python\nfrom pyspark.sql.types import FloatType\n\ndef convertColumn(df, names, newType):\n    for name in names:\n        df = df.withColumn(name, df[name].cast(newType))\n    return df\n\ncolumns = ['households', 'housingMedianAge', 'latitude', 'longitude', 'medianHouseValue', 'medianIncome', 'population', 'totalBedRooms', 'totalRooms']\n\ndf = convertColumn(df, columns, FloatType())\n```\n```python\n# 转换成数字有很多优势，例如可以统计出所有建造年限各有多少个房子\n>>> df.groupBy(\"housingMedianAge\").count().sort(\"housingMedianAge\", ascending=False).show()\n+----------------+-----+\n|housingMedianAge|count|\n+----------------+-----+\n|            52.0| 1273|\n|            51.0|   48|\n|            50.0|  136|\n|            49.0|  134|\n|            48.0|  177|\n|            47.0|  198|\n|            46.0|  245|\n|            45.0|  294|\n|            44.0|  356|\n|            43.0|  353|\n|            42.0|  368|\n|            41.0|  296|\n|            40.0|  304|\n|            39.0|  369|\n|            38.0|  394|\n|            37.0|  537|\n|            36.0|  862|\n|            35.0|  824|\n|            34.0|  689|\n|            33.0|  615|\n+----------------+-----+\nonly showing top 20 rows\n```\n\n## 预处理\n1. 房价的值普遍都很大，需要把它们调整成相对较小的数字\n2. 有的属性没太大意义，例如区域内的总房间数和总卧室数，更应该关心的是平均房间数\n3. 房价是结果，其他属性是输入参数，需要把它们**分离处理**\n4. 有的属性最大值和最小值范围很大，需要把它们**标准化处理**\n\n### 调小房价\n大部分房价都是10万起\n```python\nfrom pyspark.sql import functions\n\ndf = df.withColumn(\"medianHouseValue\", functions.col(\"medianHouseValue\") / 100000)\n```\n\n### 添加新列\n1. 每个家庭的平均房间数：roomsPerHousehold\n2. 每个家庭的平均人数：populationPerHousehold\n3. 卧室在总房间的占比：bedroomsPerRoom\n\n```python\ndf = df.withColumn(\"roomsPerHousehold\", functions.col(\"totalRooms\") / functions.col(\"households\")) \\\n    .withColumn(\"populationPerHousehold\", functions.col(\"population\") / functions.col(\"households\")) \\\n    .withColumn(\"bedroomsPerRoom\", functions.col(\"totalBedRooms\") / functions.col(\"totalRooms\"))\n```\n\n### 筛选列\n去除没有太大价值的列，例如经纬度，保留有价值的列\n```python\ndf = df.select(\"medianHouseValue\",\n               \"totalBedRooms\",\n               \"population\",\n               \"households\",\n               \"medianIncome\",\n               \"roomsPerHousehold\",\n               \"populationPerHousehold\",\n               \"bedroomsPerRoom\")\n```\n\n### 分离处理\n先把DataFrame转换到RDD，然后用map函数把每个对象分成两部分，最后再转换回DataFrame\n```python\nfrom pyspark.ml.linalg import DenseVector\n\ninput_data = df.rdd.map(lambda x: (x[0], DenseVector(x[1:])))\n# label代表房价，features代表其余参数的列表\ndf = spark.createDataFrame(input_data, [\"label\", \"features\"])\n```\n\n### 标准化\n数据的标准化，可以借助Spark ML来完成，增加了features_scaled列，里面每个数据都是标准化过的，用于训练模型\n```python\nfrom pyspark.ml.feature import StandardScaler\n\nstandardScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\nscaler = standardScaler.fit(df)\nscaled_df = scaler.transform(df)\n```\n```python\n[Row(label=4.526, features=DenseVector([129.0, 322.0, 126.0, 8.3252, 6.9841, 2.5556, 0.1466]), features_scaled=DenseVector([0.3062, 0.2843, 0.3296, 4.3821, 2.8228, 0.2461, 2.5264]))]\n```\n\n## 创建模型\n1. 把数据集分成**训练集**和**测试集**，训练集用来训练模型，测试集用来评估模型的正确性\n2. DataFrame的randomSplit函数很容易将数据随机分割，将80%的数据用于训练，20%的数据用于测试\n3. Spark ML提供的LinearRegression功能，很容易构建一个线性回归模型\n\n```python\nfrom pyspark.ml.regression import LinearRegression\n\ntrain_data, test_data = scaled_df.randomSplit([.8, .2], seed=123)\nlr = LinearRegression(featuresCol='features_scaled', labelCol=\"label\", maxIter=10, regParam=0.3, elasticNetParam=0.8)\nlinearModel = lr.fit(train_data)\n```\n\n## 模型评估\n可以用linearModel的transform函数来预测测试集中的房价，与真实情况进行对比\n```python\npredicted = linearModel.transform(test_data)\npredictions = predicted.select(\"prediction\").rdd.map(lambda x: x[0])\nlabels = predicted.select(\"label\").rdd.map(lambda x: x[0])\npredictionAndLabel = predictions.zip(labels)\n```\n","tags":["Linear Regression"],"categories":["Spark"]},{"title":"大数据 -- Word Count","url":"%2F2019%2F07%2F10%2Fbig-data-spark-word-wount%2F","content":"\n## 基于RDD API\n\n### SparkContext\n1. 在Spark 2.0之前，**SparkContext是所有Spark任务的入口**\n2. SparkContext包含了**Spark程序的基本配置**，Spark的驱动程序利用SparkContext来连接到集群\n3. 无论Spark集群有多少个节点做并行处理，每个程序都只有**唯一**的SparkContext，它可以被SparkConf初始化\n\n```python\nfrom pyspark import SparkConf, SparkContext, HiveContext\nfrom pyspark.streaming import StreamingContext\n\n# master参数是一个Spark、Y或者YARN的集群URL\nconf = SparkConf().setAppName(\"WordCountApp\").setMaster(\"local\")\nsc = SparkContext(conf=conf)\n\n# 通过SparkContext对象来读取输入文件，创建一个RDD，里面的每一个数据代表文本文件的一行\nlines = sc.textFile(\"sample.txt\")\n\nwords = lines.flatMap(lambda line: line.split(\" \"))\ncounts = words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\ncounts.saveAsTextFile(\"./output\")\n\n# 在Spark 2.0之前，如果要使用Spark提供的其它库，如SQL或者Streaming，需要分别创建相应的context对象\n# hc = HiveContext(sc)\n# ssc = StreamingContext(sc)\n```\n\n<!-- more -->\n\n### SparkSession\n1. 在Spark 2.0之后，随着DataFrame/DataSet API的普及，Spark引入了新的**SparkSession**对象作为所有Spark任务的入口\n2. SparkSession不仅有SparkContext的所有功能，还**集成了所有Spark提供的API**\n    - 例如DataFrame、Spark Streaming和Structured Streaming，无需再为不同的功能定义不同的Context\n3. 由于SparkSession的**普适性**，尽量使用SparkSession作为Spark程序的入口\n\n```python\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName(\"WordCountApp\").getOrCreate()\n# RDD\nlines = spark.read.text(\"sample.txt\").rdd.map(lambda r: r[0])\n\nwords = lines.flatMap(lambda line: line.split(\" \"))\n# counts是包含<word,count>的RDD\ncounts = words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n\noutput = counts.collect()\nfor (word, count) in output:\n    print(\"%s : %i\" % (word, count))\n# 停止SparkSession\nspark.stop()\n```\n\n## 基于DataFrame API\n1. Scala和Java都支持对DataFrame进行flatMap操作，但Python不支持，需要借助两个新操作：**split、explode**\n2. split是pyspark.sql.functions库提供的函数\n    - 作用于DataFrame的某一列，可以把列中的字符串按照某个分隔符**分割**成一个字符串数组\n3. explode也是pyspark.sql.functions库提供的函数\n    - 作用于DataFrame的某一列，可以把**列中的数组**或者**map中的每一个元素**创建一个**新的Row**\n4. DataSet/DataFrame API的便利性：不需要创建<word,count>对作为中间值，可以**直接对数据进行类似SQL的查询**\n\n```python\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\n\nif __name__ == \"__main__\":\n    spark = SparkSession.builder.appName(\"WordCountApp\").getOrCreate()\n    # DataFrame，每一行只有一列，每一列都是包含很多词语的句子\n    lines = spark.read.text(\"sample.txt\")\n    # 先对唯一的一列做split，生成一个新的列，列种的每个元素都是词语的数组\n    # 再对这个列做explode，可以把数组中的每个元素都生成一个新的ROW\n    # split + explode =》 flatMap\n    wordCounts = lines.select(explode(split(lines.value, \" \")).alias(\"word\")).groupBy(\"word\").count()\n    wordCounts.show()\n    spark.stop()\n```\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-spark-split-explode.png\" width=800/>\n","tags":["Spark"],"categories":["Spark"]},{"title":"大数据 -- Structured Streaming","url":"%2F2019%2F07%2F09%2Fbig-data-spark-structured-streaming%2F","content":"\n## 概述\n1. 2016年，Spark在其2.0版本中推出了**结构化流处理**的模块Structured Streaming\n2. Structured Streaming是**基于Spark SQL引擎**实现的\n    - 依靠Structured Streaming，在开发者眼里**流数据和静态数据没有区别**，完全可以像批处理静态数据那样去处理流数据\n    - 随着流数据的持续输入，Spark SQL引擎会持续地处理新数据，并且更新计算结果\n\n<!-- more -->\n\n## Structured Streaming模型\n1. 流数据处理最基本的问题：**对不断更新的无边界数据建模**\n2. Spark Streaming：把流数据按**一定的时间间隔**分割成许多小的数据块进行**批处理**\n3. Structured Streaming\n    - 把数据看成一个**无边界的关系型数据表**，每个数据都是表中的一行，不断会有新的数据行被添加到表里\n    - 可以对表做任何类似**批处理**的查询，Spark会不断对新加入的数据进行处理，并更新计算结果\n4. 与Spark Streaming类似，Structured Streaming也是将输入的数据流按照**时间间隔**划分成数据段\n    - 每一秒都会把新输入的数据添加到表中，Spark也会每秒更新输出结果\n    - 输出结果也是**表**的形式，输出表可以写入**硬盘**或者**HDFS**\n5. Structured Streaming的三种输出模式\n    - **完全模式**（Complete Mode）：整个更新过的输出表都被写入外部存储\n    - **附加模式**（Append Mode）：上一次触发之后**新增加**的行才会被写入外部存储，老数据有改动不适合该模式\n    - **更新模式**（Update Mode）：上一次触发之后**被更新**的行才会被写入外部存储\n6. Structured Streaming并**不会完全存储输入数据**\n    - 每个时间间隔都会读取最新的输入，进行处理，更新输出表，然后把这次的输入**删除**\n    - Structured Streaming**只会存储更新输出表所需要的信息**\n7. Structured Streaming在根据**事件时间**处理数据十分方便\n    - **事件时间**：事件发生的时间，是数据本身的属性\n    - **处理时间**：Spark接收到数据的时间\n8. 在Structured Streaming模型中，每个数据都是输入数据表中的一行，那么**事件时间**就是行中的**一列**\n    - 依靠DataFrame API提供的类似**SQL**的接口，很方便地执行基于**时间窗口**的查询\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-spark-structured-streaming.jpg\" width=800/>\n\n## Streaming DataFrame API\n1. 在Structured Streaming发布之后，DataFrame即可以代表静态的**有边界数据**，也可以代表**无边界数据**\n2. 之前对**静态DataFrame**的各种操作同样适用于**流式DataFrame**\n\n### 创建DataFrame\n1. SparkSession.readStream返回的DataStreamReader可以用于创建**流DataFrame**\n2. 支持多种类型的数据流作为输入，例如**file、Kafka、socket**等\n\n```\nsocketDataFrame = spark\n   .readStream\n   .format(\"socket\"）\n   .option(\"host\", \"localhost\")\n   .option(\"port\", 9999)\n   .load()\n```\n\n### 基本的查询操作\n流DataFrame和静态DataFrame一样，不仅支持**类似SQL的查询操作**，还**支持RDD的转换操作**\n```java\ndf = // 该DataFrame代表学生的数据流，schema是 {name:string, age:number, height:number, grade:string}\ndf.select(\"name\").where(\"age > 10\") // 返回年龄大于10岁的学生名字列表\ndf.groupBy(\"grade\").count() // 返回每个年级学生的人数\ndf.sort_values([\"age\"], ascending=False).head(100) // 返回100个年龄最大的学生\n```\n\n可以通过isStreaming函数来判断一个DataFrame是否代表流数据\n```java\ndf.isStreaming()\n```\n\n基于**事件时间**的时间窗口操作\n```java\nwords = // 该DataFrame代表词语的数据流，schema是 {timestamp:Timestamp, word:String}\n\n// 基于词语的生成时间，创建一个窗口长度为1分钟，滑动间隔为10秒钟的window\n// 然后，把输入的词语根据window和词语本身聚合起来，并统计每个window内每个词语的数量\n// 最后，根据词语的数量进行排序，只返回前10的词语\nwindowedCounts = words.groupBy(\n   window(words.timestamp, \"1 minute\", \"10 seconds\"),\n   words.word\n).count()\n.sort(desc(\"count\"))\n.limit(10)\n```\n\n### 输出结果流\nDataset.writeStream返回的DataStreamWriter支持多种写入位置，例如file、Kafka、console和内存等\n```java\nquery = wordCounts\n   .writeStream\n   .outputMode(\"complete\")\n   .format(\"csv\")\n   .option(\"path\", \"path/to/destination/dir\")\n   .start()\n\nquery.awaitTermination()\n```\n\n## 对比Spark Streaming\n综合来说，**Structured Streaming是比Spark Streaming更好的流处理工具**\n\n### 易用性和性能\n1. Spark Streaming提供的DStream API与RDD API很类似，都是相对**比较底层的API**\n2. 编写Spark Streaming程序时，本质上是要去**构造RDD的DAG执行图**，然后**通过Spark Engine运行**\n    - 开发者的**任务很重**，需要想办法去提高程序的处理效率\n    - 一个好的数据处理框架，开发者只需要**专注于业务逻辑**，而不用操心配置、优化等繁琐事项\n3. Structured Streaming提供的**DataFrame API**是一个**相对高级的API**\n    - 大部分开发者都很熟悉**关系型数据库**和**SQL**\n    - 这样的数据抽象可以让开发者**用一套统一的方案去处理批处理和流处理**，而无需关心具体的执行细节\n    - DataFrame API是在**Spark SQL**的引擎上执行的，Spark SQL有很多优化，所以Structured Streaming的程序**性能很好**\n\n### 实时性\n1. Spark Streaming是**准实时**的，能做到的最小延迟在**1秒**左右\n2. Structured Streaming采用的也是**微批处理**思想，但能做到更小的时间间隔，最小延迟在**100毫秒**左右\n3. 在Spark 2.3中，Structured Streaming引入了**连续处理**模式，可以做到真正的**毫秒级延迟**\n\n### 对事件时间的支持\n1. Structured Streaming**对基于事件时间的处理有很好的支持**\n2. Spark Streaming是把数据按接收到的时间（即**处理时间**）切分成一个个RDD进行批处理\n    - 很难基于数据本身的产生时间（即**事件时间**）进行处理\n    - 如果某个数据的处理时间和事件时间**不一致**的话，很容易出现问题\n","tags":["Structured Streaming"],"categories":["Structured Streaming"]},{"title":"大数据 -- Spark Streaming","url":"%2F2019%2F07%2F08%2Fbig-data-spark-streaming%2F","content":"\n## 原理\n1. Spark Streaming的原理与**微积分**的思想很类似，本质上是将一个**连续**的问题转换成无限个**离散**的问题\n2. Spark Streaming用**时间片**拆分了无限的数据流，然后对每个数据片采用类似**批处理**的方法进行处理\n3. Spark Streaming提供了对**流数据的抽象DStream**\n    - DStream可以由来自**Kafka、Flume、HDFS**的流数据生成，也可以由别的DStream经过各种**转换**得到\n4. 底层DStream是由很多**序列化的RDD**构成，按时间片切分成的每一个数据单位都是一个RDD\n    - Spark核心引擎对DStream的Transformation操作 -> Spark中对RDD的Transformation操作\n    - 将RDD经过操作变成**中间结果**保存在**内存**中\n5. DataFrame和DataSet都是基于RDD的，因此**RDD是Spark最基本的数据抽象**，类似于Java中的基本数据类型\n    - 因此，无论DataFrame、DataSet，还是DStream，都具有RDD的**不可变性、分区性和容错性**\n6. Spark是一个**高度统一的平台**，所有高级API都具有相同的性质，它们之间很容易地相互转换\n    - Spark的野心：**用一套工具统一所有数据处理的场景**\n\n<!-- more -->\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-spark-streaming.png\" width=800/>\n\n## DStream\n\n### 内部形式\nDStream的内部形式是一个**连续的RDD序列**，每个RDD代表一个**时间窗口**的输入数据流\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-spark-streaming-dstream.png\" width=800/>\n\n### 转换\n```java\nsc = SparkContext(master, appName)\nssc = StreamingContext(sc, 1)\nlines = sc.socketTextStream(\"localhost\", 9999)\nwords = lines.flatMap(lambda line: line.split(\" \"))\n```\n1. 创建一个lines的DStream，去监听来自本机9999端口的数据流，每个数据代表一行文本\n2. 然后对lines进行flatMap的转换操作，把每一个文本行拆分成词语\n3. 对一个DStream进行flatMap操作\n    - 本质上就是对它里面的**每一个**RDD进行flatMap操作，生成一系列新的RDD，构成一个新的代表词语的DStream\n4. RDD支持的所有转换操作，DStream都支持，DStream还支持一些特有操作，如**滑动窗口**操作\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-spark-streaming-dstream-transformation.png\" width=800/>\n\n### 滑动窗口\n1. 任何Spark Streaming的程序都要先创建一个StreamingContext对象，它是所有Streaming操作的**入口**\n2. StreamingContext中最重要的参数是**批处理的时间间隔**，即把流数据细分成数据块的**粒度**，决定了**流处理的延迟性**\n3. 样例：每隔10秒输出过去60秒内排名前十的热点词\n4. 滑动窗口操作的两个基本参数\n    - **窗口长度**（window length）：每次统计的数据的时间跨度\n    - **滑动间隔**（sliding interval）：每次统计的时间间隔\n5. Spark Streaming流处理的**最小时间单位**是StreamingContext的时间间隔，窗口长度和滑动间隔是时间间隔的整数倍\n6. 最基本的滑动窗口操作是**window**，可以返回一个新的DStream，该DStream中的每个RDD代表一段时间窗口内的数据\n\n```java\n// 每一个数据块都包含过去60秒的词语，这样的数据块会每10秒钟生成一个\nwindowed_words = words.window(60, 10)\n```\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-spark-streaming-dstream-window.png\" width=800/>\n\n## 优缺点\n1. 优点\n    - 底层是**基于RDD实现**的，能体现RDD的优良特性\n        - **数据容错性**：如果RDD的某些分区丢失了，可以通过依赖信息重新计算恢复\n        - **运算速度**：同样可以通过**persist**方法将数据流存放在**内存**中，在需要多次**迭代计算**时，速度优势明显\n    - Spark Streaming是**Spark生态的一部分**，可以与Spark的核心引擎、Spark SQL、MLib等**无缝衔接**\n        - 对Spark Streaming实时处理出来的中间数据，可以立即在程序中无缝进行批处理、交互式查询等操作\n        - 这大大增强了Spark Streaming的优势和功能，使得基于Spark Streaming的应用程序的**扩展性很好**\n2. 缺点\n    - 主要缺点是**实时计算延迟较高**，一般在**秒**级别，这是因为Spark Streaming**不支持太小的批处理的时间间隔**\n    - Spark Streaming是一个**准实时**系统，而**Storm**的延迟可以做到**毫秒**级\n","tags":["Spark Streaming"],"categories":["Spark Streaming"]},{"title":"大数据 -- Spark SQL","url":"%2F2019%2F07%2F07%2Fbig-data-spark-sql%2F","content":"\n## 发展历史\n1. 几年前，Hadoop/MapReduce在企业生产中大量使用，HDFS上积累了大量数据\n2. 由于MapReduce对于开发者而言使用难度较大，大部分开发者最熟悉的还是传统的关系型数据库，Hive应运而生\n3. Hive提供了类似**SQL**的编程接口，HQL语句经过语法解析、逻辑计划、物理计划转化成MapReduce程序执行\n    - 使得开发人员很容易对HDFS上存储的数据进行查询和分析\n4. Spark刚问世时，Spark团队也开发了**Shark**来支持用SQL语言来查询Spark的数据\n    - **Shark的本质就是Hive**，它修改了Hive的内存管理模块，大幅优化了运行速度，是Hive的10~100倍\n5. Shark对于Hive的依赖严重影响了Spark的发展，Spark想定义的是一个**统一的技术栈**和**完整的生态**\n    - 依赖于Hive还制约了Spark各个组件的相互集成，Shark也无法利用Spark的特性进行深度优化\n6. 2014年7月1日，Spark团队将Shark交给Hive管理，转而开发Spark SQL\n7. Spark SQL放弃了Shark的执行引擎（将SQL语句转化为Spark RDD），重新开发新的执行引擎\n8. Spark SQL不仅将**关系型数据库的处理模式**和**Spark的函数式编程**相结合，还兼容多种数据格式\n    - 包括Hive、RDD、JSON文件、CSV文件等\n9. Spark SQL的问世大大加快了Spark生态的发展\n\n<!-- more -->\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-spark-sql-history.png\" width=1000/>\n\n## Spark SQL的架构\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-spark-sql-architecture.png\" width=1000/>\n\n1. Spark SQL本质上是一个库，运行在Spark的核心执行引擎之上\n2. Spark SQL提供类似SQL的操作接口，允许**数据仓库应用程序**直接获取数据，允许使用者通过**命令行**操作来交互地查询数据\n3. Spark SQL还提供了**DataFrame API**和**DataSet API**\n    - Java、Python、Scala的应用程序可以通过这两个API来**读取和写入RDD**\n4. 使用Spark SQL会让开发者觉得好像在操作一个关系型数据库一样，而不是在操作RDD，优于原生的RDD API\n5. 与基本的Spark RDD API不同，Spark SQL提供的接口为Spark提供了关于**数据结构**和**正在执行的计算**的更多信息\n    - 在内部，Spark SQL使用这些**额外的信息**来执行**额外的优化**\n    - 虽然Spark SQL支持多种交互方式，但在**计算结果**时均**使用相同的执行引擎**\n\n### DataSet\n1. DataSet是**数据集**的意思，是在Spark 1.6新引入的接口\n2. 与RDD类似，DataSet也是**不可变分布式的数据单元**\n3. 有与RDD类似的各种**转换**和**动作**函数定义，**享受Spark SQL优化过的执行引擎**，使得数据搜索效率更高\n4. DataSet上的**转换**操作也不会被立即执行，只是先生成新的DataSet\n    - 只有当遇到**动作**操作，才会把之前的转换操作一并执行，生成结果\n5. DataSet的内部结构包含了**逻辑计划**，即生成该数据集所需要的运算\n6. 当**动作**操作执行时，Spark SQL的**查询优化器**会优化**逻辑计划**，并生成一个可以**分布式执行的、包含分区信息的物理计划**\n7. DataSet和RDD的区别\n    - DataSet API是Spark SQL的一个组件，DataSet也具有关系型数据库中**表**的特性\n    - DataSet所描述的数据都被组织到**有名字的列**中，就如同**关系型数据库中的表**一样\n    - RDD虽然以People为类型参数，但**Spark框架本身并不了解People类的内部结构**，所有操作都以People为单位执行\n    - DataSet提供了数据表的**Schema**信息，这样的结构使得DataSet API的**执行效率更高**\n    - 由于DataSet存储了每列的数据类型，因此，在程序**编译时**可以执行**类型检测**\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-spark-sql-rdd-dataset.png\" width=1000/>\n\n### DataFrame\n1. **DataFrame可以看作一种特殊的DataSet**，也是关系型数据库中表一样的结构化存储机制，也是分布式不可变的数据结构\n2. DataFrame的**每一列并不存储类型信息**，所以在**编译时并不能发现类型错误**\n3. DataFrame的每一行的类型固定为ROW，可以被当做DataSet[ROW]来处理，必须通过**解析**才能获取各列的值\n4. 对于DataSet，用类似`people.name`来访问，对于DataFrame，用类似`people.get As [String](\"name\")`来访问\n\n## RDD、DataFrame、DataSet\n| | RDD | DataFrame | DataSet|\n| ---- | ---- | ---- | ---- |\n| 不可变性 | Y | Y | Y |\n| 分区 | Y | Y | Y |\n| Schema | N | Y | Y |\n| 查询优化器 | N | Y | Y |\n| API级别 | 低 | 高（底层基于RDD实现） | 高（DataFrame的扩展） |\n| 是否存储类型 | Y | N | Y |\n| 何时检测语法错误 | 编译时 | 编译时 | 编译时 |\n| 何时检测分析错误 | 编译时 | 运行时 | 编译时 |\n\n### 发展历史\n1. RDD API在第一代Spark中就存在，是整个Spark框架的**基石**\n2. 为了方便熟悉关系型数据库和SQL的开发者使用，在RDD的基础上，Spark创建了DataFrame API\n3. DataSet最早被加入Spark SQL是在Spark 1.6，在**DataFrame的基础**上添加了对数据的每一列的类型的限制\n4. 在Spark 2.0，DataFrame和DataSet**被统一**，DataFrame作为DataSet[ROW]存在\n    - 在弱类型语言中，如Python，DataFrame API依然存在，但在Java中，DataFrame API已经没有了\n\n### 不变性 + 分区\n1. 由于DataFrame和DataSet都是基于RDD的，所以它们都**拥有RDD的基本特性**\n2. 可以通过简单的API在DataFrame或DataSet与RDD之间进行**无缝切换**\n\n### 性能\n1. **DataFrame和DataSet的性能要比RDD更好**\n2. Spark程序运行时，Spark SQL中的查询优化器会对语句进行分析，并生成**优化过的RDD**在底层执行\n3. 场景：先对一堆数据进行GroupBy，再进行Filter，这**非常低效**，因为并不需要对所有数据都GroupBy\n    - RDD API：只会**机械地按顺序执行**\n    - DataFrame/DataSet API：Spark SQL的Catalyst优化器会将Filter操作和GroupBy操作**调换顺序**，从而**提高执行效率**\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-spark-sql-dataframe-dataset-opt.png\" width=800/>\n\n### 错误检测\n1. **RDD和DataSet都是类型安全的，而DataFrame并不是类型安全的**，因为DataFrame并不存储每一列的信息如名字和类型\n2. 使用DataFrame API，可以选择一个**不存在的列**，只有在**运行时**才会被检测到，而使用DataSet API，在**编译时**就会被检测到\n\n## 小结\n1. DataFrame和DataSet是Spark SQL提供的_**基于RDD的结构化数据抽象**_\n2. DataFrame和DataSet即具有**不可变、分区、存储依赖关系**等特性，又拥有类似关系型数据库的**结构化信息**\n3. 基于DataFrame/DataSet开发出来的程序会被**自动优化**，开发者无需操作底层RDD API来进行手动优化，**大大提升开发效率**\n4. 但使用RDD API对于**非结构化**的数据处理有独特的优势，例如文本**流数据**，而且使用RDD API做**底层的操作**更方便\n","tags":["Spark SQL"],"categories":["Spark SQL"]},{"title":"大数据 -- Spark RDD","url":"%2F2019%2F07%2F06%2Fbig-data-spark-rdd%2F","content":"\n## 新的数据抽象模型\n1. 传统的MapReduce框架运行缓慢\n    - 有向无环图的**中间计算结果**需要写入**硬盘**来防止运行结果丢失\n    - 每次调用中间计算结果都需要重新进行一次硬盘的读取\n        - 反复对硬盘进行**读写**操作以及潜在的**数据复制**和**序列化**操作大大地提高了计算的延迟\n2. RDD是一个基于**分布式内存**的数据抽象，不仅支持基于**工作集**的应用，同时具有**数据流**模型的特点\n\n<!-- more -->\n\n## RDD的定义\nRDD表示**已被分区**、**不可变的**、并能够被**并行操作**的数据集合\n\n### 分区\n1. 分区代表**同一个RDD包含的数据被存储在系统的不同节点中**，这是RDD可以**被并行处理的前提**\n2. 逻辑上，可以认为RDD是一个大数组，数组中的每个元素代表一个分区\n3. 在物理存储中，每个分区指向一个存放在内存或硬盘中的**数据块**，数据块是独立的，可以被存放在系统的不同节点\n4. _**RDD只是抽象意义的数据集合，分区内部并不会存储具体的数据**_\n5. RDD中的每个分区都存有它在该RDD中的index，通过**RDD的ID**和**分区的index**可以唯一确定对应的**数据块编号**\n    - 从而通过**底层存储层的接口**提取到数据进行处理\n6. 在集群中，各个节点上的数据会**尽可能地放在内存**中，只有当内存没有空间时才会存入硬盘，**最大化地减少硬盘读写的开销**\n7. **RDD内部存储的数据是只读的**，但可以修改并行计算单元的划分结构，即**可以修改分区的数量**\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-spark-rdd-partition.jpg\" width=1000/>\n\n### 不可变性\n1. 不可变性代表**每个RDD都是只读的**，它**所包含的分区信息不可以被改变**\n2. 已有的RDD不可以被改变，只能对现有的RDD进行**转换**操作，得到**新的RDD**作为**中间计算结果**\n3. 对于中间结果的RDD，只需记录该RDD是通过哪个RDD进行转换操作得来的，即**依赖关系**，而**不必立刻去具体存储进行计算**\n    - 有助于**提升Spark的计算效率**，并且**使错误恢复更加容易**\n4. **容错特性**\n    - 对于有N步的计算模型，如果记载第N步输出RDD的节点发生故障，数据丢失\n    - 可以从第N-1步的RDD出发，再次计算，**无需重复整个N步计算过程**\n    - 这种容错特性也是RDD为什么是一个**弹性**的数据集的原因\n\n```java\n// 读入文本文件data.txt，创建第一个RDD lines，每个元素是一行文本\nlines = sc.textFile(\"data.txt\")\n\n// 调用map函数去映射产生第二个RDD lineLengths，每个元素代表每一行简单文本的字数\nlineLengths = lines.map(lambda s: len(s))\n\n// 调用reduce函数去得到第三个RDD totalLength，只有一个元素，代表整个文本的总字数\ntotalLength = lineLengths.reduce(lambda a, b: a + b)\n```\n\n### 并行操作\n由于单个RDD的**分区**特性，使得RDD**天然支持并行操作**，即不同节点上的数据可以被分别处理，然后产生一个新的RDD\n\n## RDD的结构\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-spark-rdd-structure.png\" width=800/>\n\n1. SparkContext是**所有Spark功能的入口**，它代表了与Spark节点的连接，用来创建RDD对象以及在节点中的广播变量\n    - 一个线程只有一个SparkContext\n2. Partitions代表RDD中**数据的逻辑结构**，每个Partition都会映射到某个节点内存或硬盘的一个**数据块**\n3. Partitioner决定了RDD的**分区方式**，目前有两种主流的分区方式：**Hash** partitioner、**Range** partitioner\n\n### 依赖关系\n1. Dependencies是RDD中最重要的组件之一\n2. Spark不需要将每个中间计算结果进行数据复制以防止数据丢失，因为每一步产生的RDD里面都会存储它的依赖关系\n3. Spark支持两种依赖关系：**窄依赖**（Narrow Dependency）、**宽依赖**（Wide Dependency）\n    - 窄依赖：父RDD的分区可以**一一对应**到子RDD的分区\n        - 窄依赖允许子RDD的每个分区可以被**并行处理**产生\n    - 宽依赖：**父RDD的分区可以被多个子RDD的分区使用**\n        - 宽依赖_**必须等父RDD的所有分区都被计算好之后才能开始处理**_\n4. 区分窄依赖和宽依赖的原因\n    - 窄依赖可以支持在**同一个节点**上**链式**执行多条命令，而宽依赖需要**所有的父分区**都是**可用**的\n    - **窄依赖的失效恢复更有效**，因为只需要重新计算丢失的父分区即可，而宽依赖涉及到RDD各级的父分区\n\n#### 窄依赖\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-spark-rdd-narrow-dependency.jpg\" width=800/>\n\n#### 宽依赖\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-spark-rdd-wide-dependency.jpg\" width=800/>\n\n### 检查点\n1. 基于RDD的依赖关系，如果任意一个RDD在相应的节点丢失，只需要从上一步的RDD出发再次计算，就能恢复该RDD\n    - 如果一个RDD的**依赖链比较长**，而且**中间又有多个RDD出现故障**的话，进行恢复可能会非常耗费**时间**和**计算资源**\n    - 检查点的引入，就是为了优化这些情况下的数据恢复\n2. 在计算过程中，对于一些计算过程**比较耗时**的RDD\n    - 可以将它**缓存至硬盘或HDFS**中\n    - 标记这个RDD被检查点处理过，并**清空**它的**所有依赖关系**，同时给它新建一个依赖于**CheckpointRDD**的依赖关系\n    - **CheckpointRDD可以用来从硬盘中读取RDD并生成新的分区信息**\n3. 当某个子RDD需要错误恢复时，回溯至该RDD，发现它被检查点记录过\n    - 就可以**直接去硬盘中读取该RDD**，而无需再往前回溯计算\n\n### 存储级别\n1. 存储级别是一个枚举类型，用来记录**RDD持久化**时的存储级别\n    - MEMORY_ONLY：只缓存在内存中，如果内存空间不够则不缓存多出来的部分，**默认值**\n    - MEMORY_AND_DISK：缓存在内存中，如果空间不够则缓存在硬盘中\n    - DISK_ONLY：只缓存在硬盘中\n    - MEMORY_ONLY_2、MEMORY_AND_DISK_2：与上面功能相同，只不过每个分区在集群的两个节点上建立副本\n2. Spark相比于Hadoop在性能上的提升，可以随时把计算好的RDD缓存在内存中，大幅减少磁盘读写的开销\n\n### 迭代函数\n1. 迭代函数（Iterator）和计算函数（Compute）用来表示**RDD怎样通过父RDD计算得到的**\n2. 迭代函数首先会判断**缓存**中是否有想要计算的RDD\n    - 如果有就直接读取，如果没有就查找想要计算的RDD是否被**检查点**处理过，如果有，就直接读取\n    - 如果没有就调用**计算函数**向上**递归**，查找**父RDD**进行计算\n\n## RDD的数据操作\n1. RDD的数据操作分为两种：**转换**（Transformation）和**动作**（Action）\n2. 转换：把一个RDD转换为另一个RDD\n3. 动作：通过计算返回一个结果\n\n### 转换\n\n#### Map\n把一个RDD中的所有数据通过一个函数，映射成一个新的RDD，任何原RDD中的元素在新RDD中都**有且只有一个**元素与之对应\n```java\nrdd = sc.parallelize([\"b\", \"a\", \"c\"])\nrdd2 = rdd.map(lambda x: (x, 1)) // [('b', 1), ('a', 1), ('c', 1)]\n```\n\n#### Filter\n选择原RDD里所有数据中满足特定条件的数据，去返回一个新的RDD\n```java\nrdd = sc.parallelize([1, 2, 3, 4, 5])\nrdd2 = rdd.filter(lambda x: x % 2 == 0) // [2, 4]\n```\n\n#### mapPartitions\n1. mapPartitions是map的变种，\n    - map的输入函数是应用于RDD中每个**元素**\n    - mapPartitions的输入函数式应用于RDD的每个**分区**，将每个分区中的内容作为整体来处理\n\n```java\n// 创建了两个分区的RDD，mapPartitions的输入函数是对每个分区内的元素求和，1+2=3，3+4=7\nrdd = sc.parallelize([1, 2, 3, 4], 2)\ndef f(iterator): yield sum(iterator)\nrdd2 = rdd.mapPartitions(f) // [3, 7]\n```\n\n#### groupByKey\n```java\nrdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 2)])\nrdd.groupByKey().collect()\n//\"a\" [1, 2]\n//\"b\" [1]\n```\n\n### 动作\n\n#### collect\n1. RDD中的collect操作与函数式编程中的collect类似，会以**数组**的形式，返回RDD的**所有元素**\n2. collect操作只有在数组所含的数据量较小的时候使用，如果数据量较大，会占用JVM内存，导致**内存溢出**\n\n```java\nrdd = sc.parallelize([\"b\", \"a\", \"c\"])\nrdd.map(lambda x: (x, 1)).collect() // [('b', 1), ('a', 1), ('c', 1)]\n```\n\n#### reduce\nreduce操作与MapReduce中的reduce类似，会把RDD中的元素根据一个输入函数聚合起来\n```python\nfrom operator import add\nsc.parallelize([1, 2, 3, 4, 5]).reduce(add)  // 15\n```\n\n#### count\ncount操作会返回RDD中元素的个数\n```java\nsc.parallelize([2, 3, 4]).count() // 3\n```\n\n#### countByKey\ncountByKey操作仅适用于**键值对**类型的RDD，返回具有每个Key计数的<Key,Count>的map\n```java\nrdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\nsorted(rdd.countByKey().items()) // [('a', 2), ('b', 1)]\n```\n\n### 区别\n1. 所有**转换操作**都很懒，只是**生成新的RDD**，并且**记录依赖关系**，但Spark**不会立刻计算**出新RDD中各个分区的数值\n2. 直到遇到一个**动作**时，**数据才会被计算，并且输出结果给Driver**\n3. 这种**惰性求值**的方式可以让Spark的运算更加**高效**和**快速**\n\n### 操作流程\n1. Spark在每次**转换**操作时，使用新产生的RDD来**记录计算逻辑**，这样把作用在RDD上的所有计算逻辑串连起来形成一个**链条**\n2. 当对RDD执行**动作**时，Spark会从计算链的**最后一个RDD开始**，依次从上一个RDD获取数据并执行计算逻辑，最后输出结果\n\n## RDD的持久化（缓存）\n1. 每当对一个RDD调用新的**动作**操作时，整个RDD都会**从头开始**运算\n2. 如果某个RDD会被反复重用的话，每次都从头计算是非常低效的，应该对**多次使用的RDD**进行一个**持久化**操作\n3. Spark的**persist**和**cache**（默认：**MEMORY_ONLY**）方法支持将RDD的数据缓存至**内存**或**硬盘**中\n    - 当下次对**同一个RDD**进行**动作**操作时，可以**直接读取**RDD的结果，大幅提高Spark的计算效率\n4. 在缓存RDD时，它**所有的依赖关系**也会被一并存下来，所以**持久化RDD**有_**自动的容错机制**_\n    - 如果RDD的任一分区丢失了，通过使用**原先创建它的转换操作**，它将被**自动重算**\n\n```java\nrdd = sc.parallelize([1, 2, 3, 4, 5])\nrdd1 = rdd.map(lambda x: x+5)\nrdd2 = rdd1.filter(lambda x: x % 2 == 0)\n// 后续对rdd2进行了多个不同的动作操作，先执行persist操作\nrdd2.persist()\n// 无论是count还是first，Spark都不需要从头开始计算\ncount = rdd2.count() // 3\nfirst = rdd2.first() // 6\nrdd2.unpersist()\n```\n","tags":["RDD"],"categories":["Spark"]},{"title":"大数据 -- Spark概述","url":"%2F2019%2F07%2F05%2Fbig-data-spark-overview%2F","content":"\n## MapReduce\n1. MapReduce通过简单的Map和Reduce抽象提供了一个编程模型\n    - 可以在一个由上百台机器组成的集群上并发处理大规模的数据集，并**隐藏**具体的计算细节\n    - **各种各样的复杂数据处理都可以分解为Map或Reduce的基本元素**\n2. 复杂的数据处理可以被分解为由多个Job（一个Mapper + 一个Reducer）组成的**有向无环图**（DAG）\n    - 然后每个Mapper和Reducer在Hadoop集群上执行，就可以得到结果\n\n<!-- more -->\n\n### 缺陷\n1. **高昂的维护成本**\n2. **时间性能达不到用户的预期**\n3. **抽象层次低**，大量的**底层逻辑**都需要开发者手工完成\n    - 类似于用汇编语言去编写一个复杂的游戏\n4. **只提供Map和Reduce两个操作**\n    - 很多实际的数据处理场景并不适合用MapReduce模型来描述\n    - 实现复杂的操作很有技巧性，同时会让整个工程变得**庞大且难以维护**\n    - 如两个数据集的Join操作是很基本且常用的功能\n        - 但如果使用MapReduce模型，需要对两个数据集进行一次Map和Reduce才能得到结果\n        - 维护一个多任务协调的状态机**成本很高**，并且**可扩展性很差**\n5. 在Hadoop中，每个Job的计算结果都会存储在**HDFS**中，所以每一步都会进行**硬盘**的读取和写入，大大增加了**系统延迟**\n    - 因此，MapReduce对于**迭代算法**的处理性能很差，很耗资源，因为迭代的每一步都要对HDFS进行读写\n6. **只支持批数据处理，欠缺对流数据处理的支持**\n\n## Spark的优势\n1. Spark最基本的数据抽象叫作**弹性分布式数据集**（Resilient Distributed Dataset，**RDD**）\n    - RDD代表一个**可以被分区的只读数据集**，RDD内部可以有很多**分区**，每个分区又可以有大量的**数据记录**\n2. RDD是Spark最基本的数据结构，Spark定义了很多对RDD的操作\n    - 对RDD的任何操作都可以像**函数式编程**中操作内存中的集合一样直观简便，使得实现数据处理的代码非常简短高效\n3. Spark提供了很多对RDD的操作，如Map、Filter、flatMap、groupByKey、Union等，**极大地提升了对各种复杂场景的支持**\n    - 开发者不用再绞尽脑汁地挖掘MapReduce模型的潜力，也不用维护复杂的MapReduce状态机\n4. 相对于Hadoop的MapReduce会将中间数据存放到硬盘中，Spark会把**中间数据缓存在内存**中，加快了处理速度\n    - Spark可以把迭代过程中每一步的计算结果都缓存在内存中，所以**非常适用于迭代算法**\n    - Spark**第一次**启动时需要把数据载入内存，之后的迭代可以直接在内存里利用中间结果进行计算，后期的迭代速度很快\n    - 在当今**机器学习**和**人工智能**大热的环境下，**Spark无疑是更好的数据处理引擎**\n5. 在任务级别上，**Spark的并行机制是多线程模型，而MapReduce是多进程模型**\n    - 多进程模型便于细粒度地控制每个任务占用的资源，但会消耗较多的启动时间\n    - Spark同一节点上的任务以**多线程**的方式运行在**同一个JVM进程**中\n        - **更快的启动速度，更高的CPU利用率、更好的内存共享**\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-spark-hadoop-compare.png\" width=1000/>\n\n## 与Hadoop的关系\n1. **Spark并不是一个完全替代Hadoop的全新工具**\n2. Hadoop生态\n    - **数据存储层**：分布式文件系统HDFS、分布式数据库HBase\n    - **数据处理层**：进行数据处理的MapReduce、负责集群和资源管理的YARN\n    - **数据访问层**：Hive、Pig、Mahout\n3. 从狭义上来看，_**Spark只是MapReduce的替代方案**_\n    - 大部分应用场景中，Spark还需要依赖HDFS和HBase来存储数据，依赖YARN来管理集群和资源\n    - Spark不一定依附于Hadoop才能生存，它可以运行在Apache Mesos、Kubernetes等云平台\n\n## Spark生态\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-spark.jpg\" width=800/>\n\n1. Spark作为**通用的数据处理平台**，有5个主要的扩展库\n    - 支持结构化数据的**Spark SQL**\n    - 处理实时数据的**Spark Streaming**\n    - 用于机器学习的**MLib**\n    - 用于图计算的**GraphX**\n    - 用于统计分析的**SparkR**\n2. 扩展库与Spark核心API高度整合，使得Spark平台可以广泛地应用在不同的数据处理场景中\n","tags":["Spark"],"categories":["Spark"]},{"title":"大数据 -- Kappa架构","url":"%2F2019%2F07%2F04%2Fbig-data-kappa%2F","content":"\n## Lambda架构\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-lambda.jpg\" width=1000/>\n\n<!-- more -->\n\n1. Lambda架构结合了**批处理**和**流处理**的架构思想\n    - 将进入系统的大规模数据同时送入两套架构中，分别是**批处理层**和**速度层**，同时产生**两套数据结果**并存入**服务层**\n2. 批处理层有很好的**容错性**，同时因为保存着所有的历史记录，使得产生的数据具有很好的**准确性**\n3. 速度层可以**及时**地处理流入的数据，因此具有**低延迟性**\n4. 最终服务层将这两套数据结合，并生成一个**完整**的数据视图\n5. Lambda架构具有很好的**灵活性**，但**维护很复杂**\n    - 因为需要维护两个复杂的分布式系统，并且保证它们在**逻辑**上产生相同的结果输出到服务层中\n        - 可以部署**Apache Hadoop**到批处理层上，同时部署**Apache Flink**到速度层上\n    - 在分布式框架中进行编程是十分复杂的，尤其还会针对不同的框架进行专门的优化\n6. 改进方向\n    - 改进批处理层的系统，让它具有更低的延时性\n    - 改进速度层的系统，让它产生的数据视图更具准确性和更接近历史数据\n\n## Kappa架构\n1. Kappa架构是由前LinkedIn的前首席工程师Jay Kreps提出来的一种架构思想\n    - Jay Kreps是Apache Kafka和Apache Samza的作者之一，也是Confluent公司的CEO\n2. Jay Kreps提出了一个改进Lambda架构的观点\n    - 改进速度层的系统性能，使得它可以处理好数据的**完整性**和**准确性**问题\n    - 改进速度层，使它既能进行**实时数据处理**，也能在业务逻辑更新的情况下**重新处理以前处理过的历史数据**\n\n## Apache Kafka\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-kappa.png\" width=1000/>\n\n1. 部署Apache Kafka，并设置**数据日志的保留期**\n    - 保留期：你希望能够**重新处理**的历史数据的时间区间\n2. 如果需要改进现有的逻辑算法，那就表示需要对历史数据进行重新处理，处理措施如下\n    - 重新启动一个Kafka作业实例，该实例将**重头开始，重新计算**保留好的历史数据，并将结果输出到一个新的数据视图中\n    - Apache Kafka的底层是使用**Log Offset**来判断现在已经处理到了哪个数据块\n        - 因此只需要将Log Offset**置为0**，新的作业实例就会重头开始处理历史数据\n3. 当新的数据视图处理过的数据进度**赶上**旧的数据视图时，应用可以切换到从新的数据视图中读取数据\n4. 停止旧版本的作业实例，并删除旧的数据视图\n    - 也可以不删除旧的数据视图，出错时可以回滚或者做AB测试\n\n## 优缺点\n1. **Kappa架构只保留了速度层**，只需在业务逻辑变更或者代码更改时进行数据的重新处理\n2. Kappa架构缺少了批处理层，在速度层上处理大规模数据可能会有数据更新出错的情况，需要花费更多的时间在**异常处理**上\n3. Kappa架构的批处理和流处理都放在了速度层，因此**不适用于批处理和流处理代码逻辑不一致的场景**\n\n## 应用场景\n1. Lambda架构\n    - 设计一种稳健的机器学习模型来预测即将发生的事情，应该优先考虑使用Lambda架构\n    - 因为Lambda架构拥有批处理层和速度层来确保**更少的错误**\n2. Kappa架构\n    - 客户端需要根据运行时发生的实时事件来做出响应，应该优先考虑Kappa架构\n","tags":["Big Data"],"categories":["Big Data"]},{"title":"大数据 -- Lambda架构","url":"%2F2019%2F07%2F03%2Fbig-data-lambda%2F","content":"\n## 广告精准投放\n1. 拥有**海量**的用户网站访问行为，需要进行用户行为分析来建立模型，然后依据该模型来投放用户喜好的广告\n2. 批处理架构：**高延时**\n    - 互联网用户行为数据能达到PB或EB级别，甚至为ZB级别，这种分析挖掘用户行为的任务，能耗时几小时甚至几天\n    - 根据模型精准投放给特定用户的广告就会有一定的延时\n3. 流处理架构：**可能错误投放**\n    - 只用流处理架构会造成**忽略**用户的历史网站访问行为，一些异常行为会导致投放错误的广告\n    - 场景：用户B借用了用户A访问了用户A不感兴趣的网站类型，但仅仅依据新的浏览记录无法判断用户A是否真的感兴趣\n\n<!-- more -->\n\n## Lambda架构\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-lambda.jpg\" width=1000/>\n\n1. Lambda架构由三层系统组成：**批处理层**（Batch Layer）、**速度处理层**（Speed Layer）、**服务层**（Serving Layer）\n2. 批处理层：**存储管理主数据集**（不可变数据集） + **预先批处理计算好的视图**\n    - 批处理层通过处理**所有的已有历史数据**来实现数据的**准确性**\n    - 基于**完整**的数据集来重新计算的，能够**修复任何错误**，然后更新现有的数据视图\n    - 输出通常只存储在**只读数据库**中，更新则是**完全取代**现有的预先计算好的视图\n3. 速度处理层：实时处理新来的大数据\n    - 速度处理层通过提供**最新数据的实时视图**来**最小化延迟**\n    - 速度处理层所生成的数据视图可能不如批处理层最终生成的视图那么准确或完整，但几乎在收到数据后就立即可用的\n    - **同样的数据在批处理层处理完成后，在速度处理层的数据就可以被替代掉**\n    - 本质上，速度处理层**弥补**了批处理层所导致的**数据视图滞后**\n4. 服务层：**响应查询**\n    - 所有在批处理层和速度处理层处理完的结果都输出**存储**在服务层中\n    - 服务层通过返回**批处理层预先计算的数据视图**或**速度处理层处理构建好数据视图**来响应查询\n\n### 回到业务\n1. 所有新的用户行为数据都可以**同时流入**批处理层和速度处理层\n2. 批处理层会**永久保存**数据并对数据进行预处理，得到用户行为模型并写入服务层\n3. 速度处理层对新的用户行为数据进行处理，并得到**实时**的用户行为模型\n4. 服务层查询：应该对用户投放怎样的广告\n    - 从服务层中既查询批处理的输出模型，也查询速度处理层的输出模型，这样就能构建**完整**地用户行为历史\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-lambda-ad.jpg\" width=800/>\n\n## Twitter Hashtag\n用户所发的Twitter里面的Hashtag经常能引爆一些热搜词汇，即Most Popular Hashtags\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-lambda-twitter-hashtag.jpg\" width=1000/>\n\n1. 用**twitter4J**的流处理API**实时抓取**Twitter推文，同时用**Kafka**将抓取到的数据保存并**实时推送**给批处理层和速度处理层\n    - Apache Spark既有批处理架构也兼容流处理架构\n2. 批处理层和速度处理层在分析处理好数据后，将数据视图输出存储在服务层，使用**Apache Cassandra**来存储\n    - Apache Cassandra将批处理层的视图数据和速度处理层的实时视图数据结合起来\n","tags":["Big Data"],"categories":["Big Data"]},{"title":"大数据 -- CAP定理","url":"%2F2019%2F07%2F02%2Fbig-data-cap%2F","content":"\n## CAP定理\n1. 在任意的分布式系统中，一致性、可用性、分区容错性最多只能同时存在**两个**属性\n2. 一致性（Consistency）、可用性（Availability）、分区容错性（Partition-tolerance）\n\n<!-- more -->\n\n### C：一致性\n1. 这里的一致性指的是**线性一致性**（Linearizability Consistency）\n2. 在线性一致性的保证下，所有分布式环境的操作都像跟在**单机**上操作\n3. 下图中，Server A、B、C的状态**一直是一致**的\n    - 在同一个分布式系统上完成操作A和操作B\n    - 操作A作用在系统上的时候，系统状态为状态A，操作B作用在系统上的时候，系统状态为状态B\n    - 操作A在操作B之前发生，并且操作A成功了，那么系统状态B**必须**比系统状态A更新\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-cap-consistency.jpg\" width=600/>\n\n### A：可用性\n1. 可用性：在分布式系统中，任意**非故障**的服务器都必须响应客户的请求\n2. 当系统满足可用性时，不管出现什么状况（除非所有服务器全部崩溃），都能返回消息\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-cap-availability.jpg\" width=600/>\n\n### P：分区容错性\n1. 在一个分布式系统里，如果出现故障，可能会导致部分节点之间无法连通，造成整个网络被分成几块区域，发生了分区错误\n2. 下图中，如果需要的数据只在Server A中保存，当系统出现分区错误，无法直接连接Server A，无法获取数据\n    - 分区容错：即使出现这样的错误，系统也能容忍，也必须能够返回消息\n3. 分区容错性：**系统允许网络丢失从一个节点发送到另一个节点的任意多条消息**\n4. P本质：_**发生网络分区后，无论后面网络分区是否会恢复，分离出来的子系统都可以正常运行**_\n5. 在现代网络通信中，节点出现故障或者网络出现丢包的情况**时常发生**\n    - 如果没有分区容错性，也就是系统不允许这些节点之间的通讯出现任何错误，那很多系统就不能再继续工作了\n    - 因此在大部分情况，系统设计会_**保留P，在C和A之间二选一**_\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-cap-partition-tolerance.jpg\" width=600/>\n\n### CP + AP + CA\n1. CP系统：Google BigTable、HBase、MongoDB、Redis、MemCacheDB，这些**存储**架构都放弃了高可用性\n2. AP系统：Amazon Dynamo及其衍生存储系统Apache Cassandra\n3. CA系统：**Kafka Replication**\n\n## Kafka Replication\n1. Kafka在0.8版本，引入了Replication的概念\n    - 通过将数据复制到不同的节点上，从而增强了数据在系统中的**持久性**（Durability）和**可用性**（Availability）\n2. 在Kafka Replication的系统设计中，所有的数据日志存储是设计在**同一个数据中心**里面的，**出现网络分区的可能性很小**\n3. P属性：当任意节点断开后，系统还可以正常的运行\n    - 对于整个Kafka系统来说，P属性是要保留的\n    - 对于Kafka Replication来说，如果**领导者**挂了，再多的副本都无法运行了，所以_**Kafka Replication没有保留P属性**_\n\n### 具体架构\n1. 在Kafka数据副本（Data Replication）的设计中，先通过Zookeeper选举出一个**领导者节点**（Leader）\n2. 领导者节点负责维护一组被称作**同步数据副本**（In-Sync-Replica）的节点，所有的数据写入都必须在这个领导者节点中记录\n\n#### 场景1\n1. 有三台服务器，一台被选为作为领导者节点，另外两台服务器用来保存数据副本，分别是Replication1和Replication2\n2. 用户想写入一个数据D\n    - 用户发请求到领导者节点想写入数据D\n    - 领导者节点收到请求后先在**本地**保存，然后也同时发消息通知Replication1和Replication2\n    - Replication1和Replication2收到消息后也进行保存并回复领导者节点写入成功\n    - 领导者节点记录Replication1和Replication2都是**健康**的，并回复用户写入成功\n3. 往后用户想查询写入的数据，无论是领导者节点还是Replication1和Replication2都可以返回正确同步的结果\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-cap-kafka-case-1.jpg\" width=600/>\n\n#### 场景2\n1. 假设出现了**网络分区**，领导者节点和Replication1无法通信\n2. 用户想写入一个数据D\n    - 用户发请求到领导者节点想写入数据D\n    - 领导者节点收到请求后先在**本地**保存，然后也同时发消息通知Replication1和Replication2\n    - 只有Replication2收到消息，进行保存并回复领导者节点写入成功\n    - 领导者节点记录Replication2是**健康**的，并回复用户写入成功\n3. 红色的部分是领导者节点的**本地日志**，记录着**哪些数据同步副本是健康**的\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-cap-kafka-case-2.jpg\" width=600/>\n\n#### 场景3\n1. 领导者节点和Replication1/2都无法通信，**Apache Kafka允许系统只有一个节点工作**，即领导者节点\n2. 用户想写入一个数据D\n    - 用户发请求到领导者节点想写入数据D\n    - 领导者节点收到请求后先在**本地**保存，然后也同时发消息通知Replication1和Replication2\n    - 没有任何副本回复领导者节点写入成功\n    - 领导者节点记录没有副本是**健康**的，并回复用户写入成功\n3. 在最坏情况下，领导者节点也挂了，Zookeeper会重新去寻找健康的服务器节点来当选新的领导者节点\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-cap-kafka-case-3.jpg\" width=600/>\n","tags":["CAP"],"categories":["Big Data"]},{"title":"大数据 -- 发布订阅模式","url":"%2F2019%2F07%2F01%2Fbig-data-pub-sub%2F","content":"\n## 消息 + 消息队列\n1. 在分布式架构中，各个组件通过**发送消息**来互相通信，消息可以是**任意格式**的\n2. 消息队列在发布订阅模式中起到一个**持久化缓冲**（Durable Buffer）的作用\n    - 消息的发送方可以发送任意消息至这个消息队列中，消息队列在接收到消息之后会将消息保存起来\n    - 直到消息的接收方确认已经从这个消息队列中拿到了这条消息，才会将这条消息从消息队列中删除\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-pub-sub-message-queue.jpg\" width=1000/>\n\n<!-- more -->\n\n## 发布订阅模式\n1. 发布订阅模式：消息的发送方可以将消息**异步**地发送给一个系统中的不同组件，而无需知道接收方是谁\n2. 发送方被称为**发布者**（Publisher），接收方被称为**订阅者**（Subscriber）\n3. 在发布订阅模式里，可以有**任意多个**发布者发送消息，也可以有**任意多个**订阅者接收消息\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-pub-sub-pattern.jpg\" width=1000/>\n\n### 优点\n1. **松耦合**：消息的发布者和消息的订阅者在开发的时候完全不需要事先知道对方的存在，可以独立地进行开发\n2. **高伸缩性**：发布订阅模式中的消息队列可以**独立**的作为一个**数据存储中心**存在\n    - 在分布式环境中，消息队列可以扩展至上千台服务器\n3. **组件间通信更简洁**：不需要为每个消息的订阅者定制专门的消息格式\n\n### 缺点\n1. 不能保证发布者发送的消息一定会送达订阅者，如果保证送达，需要开发者自己实现响应机制\n\n## Apache Kafka\n1. 消息的发送方被称为**Producer**，消息的接收方被称为**Consumer**，消息队列被称为**Topic**\n2. Apache Kafka在判断**消息是否被接收方接收**时利用了**Log Offset**机制\n    - 假设发送方连续发送5条数据到消息队列Topics中，这5条消息被编码为10000、10001、10002、10003、10004\n    - 如果接收方读取数据之后回应消息队列它接收到的Log Offset是10000、**10001**、10003\n    - 那么消息队列会认为接收方最多只接收了消息10000和10001，剩下的消息10002、10003、10004会继续发送给接收方\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-pub-sub-kafka.jpg\" width=1000/>\n\n## 适用场景\n1. 系统的发送方需要向大量的接收方**广播**消息\n2. 系统中某一组件需要与**多个独立开发的组件或服务**进行通信\n    - 这些独立开发的组件或服务可以使用不同的编程语言和通信协议\n3. 系统的发送方在向接收方发送消息之后**无需接收方进行实时响应**\n4. 系统中对数据一致性的要求只需要支持数据的**最终一致性**（Eventual Consistency）模型\n","tags":["Big Data"],"categories":["Big Data"]},{"title":"大数据 -- Workflow设计模式","url":"%2F2019%2F06%2F30%2Fbig-data-workflow%2F","content":"\n## 工作流系统\n将由多个不同的处理模块连接在一起，最后得到一个**有向无环图**（DAG），称为一个**工作流系统**（Workflow System）\n\n## 复制模式 -- Copier Pattern\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-workflow-copier-pattern.jpg\" width=800/>\n\n<!-- more -->\n\n1. 将单个数据处理模块中的数据，完整地复制到两个或更多的数据处理模块中，然后再由不同的数据处理模块进行处理\n2. 应用场景：需要对同一个数据集采取多种不同的数据处理转换\n3. 样例：Youtube处理视频\n    - 依据带宽提供不同分辨率的视频\n    - 生成视频的动画缩略图\n    - 利用NLP技术分析视频的数据集，自动生成视频字幕\n    - 分析视频内容，产生更好的内容推荐\n4. 每个数据处理模块的输入都是**相同**的，每个数据处理模块可以**单独且同时**运行处理\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-workflow-copier-pattern-youtube.jpg\" width=800/>\n\n## 过滤模式 -- Filter Pattern\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-workflow-filter-pattern.jpg\" width=800/>\n\n1. 过滤模式：过滤掉不符合特定条件的数据\n2. 应用场景：需要针对一个数据集中某些特定的数据采用数据处理\n3. 样例：电商会员系统\n    - 根据用户特征，将用户划分为五星会员（Five Star）、金牌会员（Golden）、钻石会员（Diamond）\n    - 通过邮件，针对钻石会员发出活动邀请\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-workflow-filter-pattern-member.jpg\" width=800/>\n\n## 分离模式 -- Splitter Pattern\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-workflow-splitter-pattern-1.jpg\" width=800/>\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-workflow-splitter-pattern-2.jpg\" width=800/>\n\n1. 应用场景：处理数据集时，把数据分类成不同的类别分别进行处理\n2. 分离模式不会过滤任何数据，只是将原来的数据集分组\n3. 样例：电商会员系统\n    - 通过邮件，针对全部会员发送符合他们身份的活动邀请\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-workflow-splitter-pattern-member.jpg\" width=800/>\n\n## 合并模式 -- Joiner Pattern\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-workflow-joiner-pattern.jpg\" width=800/>\n\n合并模式：将多个不同的数据集转换集中到一起，成为一个总数据集，然后将这个总数据集放在一个工作流中进行处理\n","tags":["Big Data"],"categories":["Big Data"]},{"title":"Kafka -- “发行版”","url":"%2F2019%2F06%2F29%2Fkafka-distribution%2F","content":"\n## Kafka Connect\n> Kafka Connect, an open source component of Kafka, is a framework for connecting Kafka with external systems such as databases, key-value stores, search indexes, and file systems.\n\n> Using Kafka Connect you can use existing connector implementations for common data sources and sinks to move data into and out of Kafka.\n\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-connect.png\" width=1000/>\n\n<!-- more -->\n\n## Apache Kafka\n1. Apache Kafka是最正宗的Kafka，被称为社区版Kafka，是其他发行版的基础\n2. 优点：**开发人数最多，版本迭代速度最快，社区响应度高**\n3. 缺点：**仅仅提供最基础的组件，没有提供任何监控框架或工具，缺失高级功能**\n4. 应用场景：仅仅需要一个消息引擎系统或者简单的流处理应用场景，同时需要对系统有较大的把控度\n\n## Confluent Kafka\n1. 2014年，Kafka的3个创始人离开LinkedIn创办了Confluent公司，专注于提供基于Kafka的企业级流处理解决方案\n2. Confluent公司主要从事商业化Kafka工具开发，并在此基础上发布了Confluent Kafka\n3. Confluent Kafka提供了一些Apache Kafka没有的高级特性，例如**跨数据中心备份**、**Schema注册中心**、**集群监控工具**\n4. Confluent Kafka分为免费版和企业版\n    - 免费版：与Apache Kafka非常类似，但包含**Schema注册中心**和**REST Proxy**两大功能，免费版还包含更多的**连接器**\n        - Schema注册中心：集中管理Kafka的**消息格式**以实现数据**前向/后向兼容**\n        - REST Proxy：用开放HTTP接口的方式允许你通过网络访问Kafka的各种功能\n    - 企业版：\n        - **跨数据中心备份**\n        - **集群监控**\n5. 缺点：Confluent暂无发展国内业务的计划，相关的资料和技术支持都比较欠缺，Confluent Kafka在国内的普及率比较低\n6. 应用场景：需要用到Kafka的高级特性\n\n## Cloudera/Hortonworks Kafka\n1. Cloudera提供的**CDH**和Hortonworks提供的**HDP**是非常著名的**大数据平台**，里面集成了目前主流的大数据框架\n2. CDH和HDP都集成了Apache Kafka，简称为CDH Kafka和HDP Kafka\n3. 2018年10月，Cloudera和Hortonworks宣布合并\n4. CDH/HDP Kafka天然集成了Apache Kafka\n5. 优点：通过便捷化的界面操作将Kafka的安装、运维、管理、监控**全部统一**在控制台\n6. 缺点：降低对Kafka集群的**掌控程度**，演进速度较慢\n7. 应用场景：需要快速地搭建消息引擎系统，或者需要搭建的是多框架构成的数据平台，且Kafka只是其中一个组件\n","tags":["Stream"],"categories":["Kafka"]},{"title":"大数据 -- 批处理 + 流处理","url":"%2F2019%2F06%2F28%2Fbig-data-batching-streaming%2F","content":"\n## 无边界数据 + 有边界数据\n1. **无边界数据**（Unbounded Data）：一种不断增长、无限的数据集，也叫**流数据**（Streaming Data）\n2. **有边界数据**（Bounded Data）：一种有限的数据集\n3. 把无边界数据按照时间窗口提取一部分，将成为有边界数据，有边界数据可以看作无边界数据的一个**子集**\n\n<!-- more -->\n\n## 事件时间 + 处理时间\n1. 事件时间（Event Time）：数据**实际产生**的时间点\n2. 处理时间（Processing Time）：处理数据的系统架构**实际接收**到这个数据的时间点\n\n## 批处理\n1. 批处理：一系列相关联的任务按顺序（或并行）一个接一个地执行\n2. 批处理的输入是在一段时间内已经收集保存好的数据，每次批处理所产生的输出也可以作为下一次批处理的输入\n3. 绝大部分情况下，批处理的输入数据都是**有边界数据**，输出结果也一样是有边界数据，批处理更多关注的是**事件时间**\n4. 在许多情况下，批处理任务会被安排，以**预先定义好的时间间隔**来运行，例如信用卡消费账单\n5. 批处理架构的应用场景：日志分析、计费应用程序、数据仓库\n6. 开源项目（由Google MapReduce衍生）：Apache **Hadoop**、Apache **Spark**\n7. 批处理任务具有**高延迟性**\n\n## 流处理\n1. 流处理：系统需要接收并处理一系列连续不断变化的数据\n2. 流处理的输入数据基本上都是**无边界数据**，而流处理系统将依据具体的应用场景来关注数据的事件时间还是处理时间\n3. 流处理的特点：**高吞吐**、**低延迟**，流处理所需的响应时间应该以**毫秒**（或**微秒**）来进行计算\n4. 流处理速度快的原因：在数据**到达磁盘之前**就已经对其进行了分析\n5. 实时处理 + 准实时处理\n    - **实时处理**：系统架构拥有在**一定**时间间隔（**毫秒**）内产生逻辑上正确的结果\n    - **准实时处理**：系统架构可以接受以**分钟**为单位的处理**延时**\n6. 流处理架构的应用场景：实时监控、实时商业智能（如智能汽车）、实时分析\n7. 开源项目：Apache **Kafka**、Apache **Flink**、Apache **Storm**、Apache **Samza**\n","tags":["Big Data"],"categories":["Big Data"]},{"title":"大数据 -- 分布式系统","url":"%2F2019%2F06%2F27%2Fbig-data-distributed-system%2F","content":"\n## SLA\n1. SLA：Service-level Agreement，**服务等级协议**\n    - 指的是系统服务提供者（Provider）对客户（Customer）的一个**服务承诺**\n2. SLA是衡量一个大型分布式系统是否**健康**的常用方法\n3. SLA是一种服务承诺，指标可以多种多样，常见的有：**可用性**、**准确性**、**系统容量**、**延迟**\n\n<!-- more -->\n\n### 可用性 -- Availability\n1. 可用性指的是系统服务能正常运行所占的时间百分比\n2. 不存在可用性100%的系统服务，即使是AWS也出现过服务中断的情况\n3. 对于许多系统而言，99.99%的可用性即可被认为是**高可用**，一天只能中断8.64秒\n\n### 准确性 -- Accuracy\n1. 准确性指的是系统服务是否允许数据是不准确的或者是丢失的，如果允许，用户可以接受的百分比是多少\n2. 错误率 = **导致系统产生内部错误的有效请求数 / 期间的有效请求总数**\n3. 可以**用错误率来定义准确性**\n    - Google Cloud Platform：每个月系统的错误率超过5%的时间要少于0.1%，时间单位为分钟\n    - AWS：以每5分钟为单位，错误率不会超过0.1%\n4. 评估系统准确性的方法：**性能测试**、**查看系统日志**\n\n### 系统容量 -- Capacity\n1. 在数据处理中，系统容量通常指的是**系统能够支持的预期负载量**是多少，一般会以QPS或RPS来表示\n2. 例如，Twitter系统可以响应30W的QPS来读取Twitter Timelines\n3. 给系统定义准确QPS的方式\n    - 限流：假设每台服务器都定义了每秒最多处理N个请求的限流器，那M台机器在最理想的情况下，QPS可以达到N*M\n    - 性能测试：特别需要考虑**命中缓存**的情况\n    - 分析系统日志：这种方式不一定可以得到系统可以承载的最大QPS\n\n### 延迟 -- Latency\n1. 延迟指的是系统收到用户请求到响应这个请求之间的时间间隔\n2. 常见指标p95和p99，p95=1S表示95%请求的响应时间都少于1S\n3. 场景\n    - 为了降低系统延迟，会将数据库内容放进缓存，以此来减少数据库的读取时间\n    - 系统运行一段时间后，可以得到**缓存命中率**为90%，此时p95或p99恰好衡量了系统的最长时间，即数据库读取时间\n    - 可以通过优化数据库的Schema或者索引来降低p95或p99\n\n## 可扩展性 -- Scalability\n1. 分布式系统的核心是可扩展性，扩展方式：水平扩展（Horizontal Scaling）、垂直扩展（Vertical Scaling）\n2. **水平扩展**：在现有的系统中增加新的机器节点\n    - 适用范围更广，操作更简单，提升系统的**可用性**\n    - 无节制地增加机器数量：机器的管理、调度、通信会变得更加复杂，出错概率加大，数据一致性更难保证\n3. **垂直扩展**：在不改变系统机器数量的情况下，升级现有机器的性能\n    - 并没有让整个系统变得更加复杂，控制系统的代码也不需要做任何调整\n    - 单个机器的性能提升非常有限，而且受制于摩尔定律，_**提高机器的性能往往比购买新的机器更加昂贵**_\n4. 数据存储系统\n    - 传统的关系型数据库如MySQL，因为表与表之间的数据有关联，经常需要进行Join操作\n        - 所有数据都要存放在一个单机系统中，很难支持水平扩展\n    - NoSQL数据库如BigTable、MongoDB和Redis等，天生支持水平扩展，所以应用越来越广\n5. **构成分布式系统的机器节点的可用性低于系统的可用性**\n    - 如果要构建一个可用性为99.999%的分布式系统，可以使用可用性为99.9%的机器节点\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-scalability-horizontal-scaling.jpg\" width=800/>\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-scalability-vertical-scaling.jpg\" width=800/>\n\n## 一致性 -- Consistency\n1. 一致性模型：强一致性（Strong Consistency）、弱一致性（Weak Consistency）、最终一致性（Eventual Consistency）\n2. **强一致性**\n    - 系统中的某个数据被成功更新后，后续任何对该数据的读取操作都将得到更新后的值\n    - 在任意时刻，同一系统所有节点中的数据是一样的\n    - 强一致性会牺牲部分**延迟性**，而且对于**全局时钟**的要求很高\n    - Google Spanner：具备强一致性的全球分布式企业级数据库服务\n3. **弱一致性**\n    - 系统中的某个数据被成功更新后，后续对该数据的读取可能得到更新后的值，也可能是更新前的值\n    - 但经过“不一致时间窗口”后，后续对该数据的读取都是更新后的值\n4. **最终一致性**\n    - 最终一致性是弱一致性的特殊形式，存储系统保证，在没有新的更新条件下，最终所有的访问都是最后更新的值\n    - 最终一致性系统支持**异步读取**，**延迟较小**\n    - AWS DynamoDB：支持最终一致性的数据读取\n5. 在实际应用系统中，强一致性是很难实现的，_**应用最广的是最终一致性**_\n\n## 持久性 -- Durability\n1. 数据持久性：数据一旦被成功存储就可以一直使用，即使系统中的节点下线、宕机或者数据损坏\n2. 持久性级别：节点级别、集群级别\n3. 提高持久性的通用做法：**数据复制**，把同一份数据存储在不同的节点上\n4. 消息持久性（**消息不丢失**）\n    - 当消息服务的节点发生错误，对于**已经发送的消息**仍然会在错误解决之后被处理\n    - 如果一个消息队列声明了持久性，那么即使队列在**消息发送之后**掉线，仍然会在重新上线之后收到这条消息\n","tags":["Big Data"],"categories":["Big Data"]},{"title":"Java性能 -- ArrayList + LinkedList","url":"%2F2019%2F06%2F26%2Fjava-performance-arraylist-linkedlist%2F","content":"\n## List接口\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-list.jpg\" width=1000/>\n\n<!-- more -->\n\n1. ArrayList、Vector、LinkedList继承了AbstractList，AbstractList实现了List，同时继承了AbstractCollection\n2. ArrayList和Vector使用了**数组**实现，LinkedList使用了**双向链表**实现\n\n## ArrayList\n\n### 常见问题\n1. ArrayList的对象数组elementData使用了**transient**（表示不会被序列化）修饰，为什么？\n2. ArrayList在大量新增元素的场景下，效率一定会变慢？\n3. 如果要循环遍历ArrayList，采用**for循环**还是**迭代循环**？\n\n### 类签名\n```java\npublic class ArrayList<E> extends AbstractList<E>\n        implements List<E>, RandomAccess, Cloneable, java.io.Serializable {\n}\n```\n1. ArrayList实现了List接口，继承了AbstractList抽象类，底层是**数组**实现，并且实现了**自增扩容**\n2. ArrayList实现了Cloneable和Serializable接口，可以实现**克隆**和**序列化**\n3. ArrayList实现了RandomAccess接口，RandomAccess接口是一个**标志**接口，可以实现**快速随机访问**\n\n### 属性\n```java\n// 默认初始化容量\nprivate static final int DEFAULT_CAPACITY = 10;\n// 对象数组\ntransient Object[] elementData;\n// 数组长度\nprivate int size;\n\nprivate void writeObject(java.io.ObjectOutputStream s)\nprivate void readObject(java.io.ObjectInputStream s)\n```\n1. transient关键字修饰elementData，表示elementData不会被序列化，而ArrayList又实现了Serializable接口，这是为什么？\n2. 由于ArrayList的数组是**动态扩容**的，所以并不是所有被分配的内存空间都存储了数据\n    - 如果采用**外部序列化**实现数组的序列化，会序列化_**整个数组**_\n3. ArrayList为了避免这些没有存储数据的内存空间被序列化\n    - 内部提供了两个私有方法**writeObject**和**readObject**，来自我完成序列化和反序列化，节省了**空间**和**时间**\n4. 因此使用transient关键字修饰对象数组，是防止对象数组被其他外部方法序列化\n\n### 构造函数\n```java\nprivate static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};\n\npublic ArrayList() {\n    this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;\n}\n\n// 指定合理的初始大小，有助于减少数组的扩容次数，提供系统性能\npublic ArrayList(int initialCapacity) {\n    if (initialCapacity > 0) {\n        this.elementData = new Object[initialCapacity];\n    } else if (initialCapacity == 0) {\n        this.elementData = EMPTY_ELEMENTDATA;\n    } else {\n        throw new IllegalArgumentException(\"Illegal Capacity: \" + initialCapacity);\n    }\n}\n\npublic ArrayList(Collection<? extends E> c) {\n    elementData = c.toArray();\n    if ((size = elementData.length) != 0) {\n        // c.toArray might (incorrectly) not return Object[] (see 6260652)\n        if (elementData.getClass() != Object[].class)\n            elementData = Arrays.copyOf(elementData, size, Object[].class);\n    } else {\n        // replace with empty array.\n        this.elementData = EMPTY_ELEMENTDATA;\n    }\n}\n```\n\n### 新增元素\n```java\n// 直接将元素添加到数组的末尾\npublic boolean add(E e) {\n    ensureCapacityInternal(size + 1);  // Increments modCount!!\n    // 如果一开始就指定了合理的初始大小，不会发生动态扩容，添加元素，只需要在数组末尾添加元素，性能也会很好\n    // ArrayList在大量新增元素的场景下，效率一定会变慢？ -- 不一定，看场景\n    elementData[size++] = e;\n    return true;\n}\n\n// 添加元素到任意位置\npublic void add(int index, E element) {\n    rangeCheckForAdd(index);\n    ensureCapacityInternal(size + 1);  // Increments modCount!!\n    // 数组拷贝\n    System.arraycopy(elementData, index, elementData, index + 1, size - index);\n    elementData[index] = element;\n    size++;\n}\n\n// 如果容量不够大，会按原来数组的1.5倍大小进行扩容\n// 在扩容之后需要将数组复制到新分配的内存地址\nprivate void ensureExplicitCapacity(int minCapacity) {\n    modCount++;\n    // overflow-conscious code\n    if (minCapacity - elementData.length > 0)\n        grow(minCapacity);\n}\n\nprivate static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;\n\nprivate void grow(int minCapacity) {\n    // overflow-conscious code\n    int oldCapacity = elementData.length;\n    int newCapacity = oldCapacity + (oldCapacity >> 1); // 1.5倍\n    if (newCapacity - minCapacity < 0)\n        newCapacity = minCapacity;\n    if (newCapacity - MAX_ARRAY_SIZE > 0)\n        newCapacity = hugeCapacity(minCapacity);\n    // minCapacity is usually close to size, so this is a win:\n    elementData = Arrays.copyOf(elementData, newCapacity);\n}\n```\n\n### 删除元素\n```java\npublic E remove(int index) {\n    rangeCheck(index);\n    modCount++;\n    E oldValue = elementData(index);\n    int numMoved = size - index - 1;\n    if (numMoved > 0)\n        // 数组重组，删除的元素位置越靠前，数组重组的开销就越大\n        System.arraycopy(elementData, index+1, elementData, index, numMoved);\n    elementData[--size] = null; // clear to let GC do its work\n    return oldValue;\n}\n\npublic boolean remove(Object o) {\n    if (o == null) {\n        for (int index = 0; index < size; index++)\n            if (elementData[index] == null) {\n                fastRemove(index);\n                return true;\n            }\n    } else {\n        // 遍历数组\n        for (int index = 0; index < size; index++)\n            if (o.equals(elementData[index])) {\n                fastRemove(index);\n                return true;\n            }\n    }\n    return false;\n}\n\nprivate void fastRemove(int index) {\n    modCount++;\n    int numMoved = size - index - 1;\n    if (numMoved > 0)\n        // 同样也要数组重组\n        System.arraycopy(elementData, index+1, elementData, index, numMoved);\n    elementData[--size] = null; // clear to let GC do its work\n}\n```\n\n### 获取元素\n```java\n// ArrayList是基于数组实现的，所以在获取元素的时候非常快\npublic E get(int index) {\n    rangeCheck(index);\n    return elementData(index);\n}\n\nE elementData(int index) {\n    return (E) elementData[index];\n}\n```\n\n## LinkedList\nLinkedList是基于**双向链表**实现的，LinkedList种定义了一个Node结构\n```java\n// 1. 清晰地表达了链表中链头和链尾概念\n// 2. 在链头和链尾的插入删除操作更加快捷\ntransient Node<E> first;\ntransient Node<E> last;\n\nprivate static class Node<E> {\n    E item;\n    Node<E> next;\n    Node<E> prev;\n\n    Node(Node<E> prev, E element, Node<E> next) {\n        this.item = element;\n        this.next = next;\n        this.prev = prev;\n    }\n}\n```\n\n### 类签名\n```java\npublic class LinkedList<E>\n    extends AbstractSequentialList<E>\n    implements List<E>, Deque<E>, Cloneable, java.io.Serializable {\n}\n```\n1. LinkedList实现了List接口和Deque接口，同时继承了AbstractSequentialList抽象类\n2. LinkedList实现了Cloneable和Serializable接口，可以实现**克隆**和**序列化**\n3. LinkedList存储数据的内存地址是**非连续**的，只能通过**指针**来定位\n    - 因此LinkedList**不支持随机快速访问**，也不能实现RandomAccess接口\n\n### 属性\n```java\n// LinkedList也实现了自定义的序列化和反序列化\ntransient int size = 0;\ntransient Node<E> first;\ntransient Node<E> last;\n\nprivate void writeObject(java.io.ObjectOutputStream s)\nprivate void readObject(java.io.ObjectInputStream s)\n```\n\n### 新增元素\n```java\n// 添加到队尾\npublic boolean add(E e) {\n    linkLast(e);\n    return true;\n}\n\nvoid linkLast(E e) {\n    final Node<E> l = last;\n    final Node<E> newNode = new Node<>(l, e, null);\n    last = newNode;\n    if (l == null)\n        first = newNode;\n    else\n        l.next = newNode;\n    size++;\n    modCount++;\n}\n```\n\n```java\npublic void add(int index, E element) {\n    checkPositionIndex(index);\n\n    if (index == size)\n        linkLast(element);\n    else\n        linkBefore(element, node(index));\n}\n\n// 从链头或者链尾查找元素\nNode<E> node(int index) {\n    if (index < (size >> 1)) {\n        Node<E> x = first;\n        for (int i = 0; i < index; i++)\n            x = x.next;\n        return x;\n    } else {\n        Node<E> x = last;\n        for (int i = size - 1; i > index; i--)\n            x = x.prev;\n        return x;\n    }\n}\n\nvoid linkBefore(E e, Node<E> succ) {\n    // assert succ != null;\n    final Node<E> pred = succ.prev;\n    final Node<E> newNode = new Node<>(pred, e, succ);\n    succ.prev = newNode;\n    if (pred == null)\n        first = newNode;\n    else\n        pred.next = newNode;\n    size++;\n    modCount++;\n}\n```\n\n### 删除元素\n```java\n// 从链头或者链尾查找元素\npublic boolean remove(Object o) {\n    if (o == null) {\n        for (Node<E> x = first; x != null; x = x.next) {\n            if (x.item == null) {\n                unlink(x);\n                return true;\n            }\n        }\n    } else {\n        for (Node<E> x = first; x != null; x = x.next) {\n            if (o.equals(x.item)) {\n                unlink(x);\n                return true;\n            }\n        }\n    }\n    return false;\n}\n\npublic E remove(int index) {\n    checkElementIndex(index);\n    return unlink(node(index));\n}\n```\n\n### 获取元素\n```java\npublic E get(int index) {\n    checkElementIndex(index);\n    return node(index).item;\n}\n```\n1. for循环遍历时，每次循环都会遍历半个List，效率非常低\n2. 因此在循环遍历LinkedList时，采用iterator方式迭代循环，效率更高，直接拿到元素，而不需要通过循环查找List\n\n## 性能测试\n\n### 新增元素\n| | 头部 | 中间 | 尾部 |\n| ---- | ---- | ---- | ---- |\n| ArrayList | 1660 | 769 | 17 |\n| LinkedList | 15 | 9463 | 14 |\n\n**LinkedList新增元素的效率未必高于ArrayList**\n\n### 删除元素\n| | 头部 | 中间 | 尾部 |\n| ---- | ---- | ---- | ---- |\n| ArrayList | 1235 | 559 | 5 |\n| LinkedList | 14 | 6349 | 5 |\n\n### 遍历元素\n| | For Loop | Iterator Loop |\n| ---- | ---- | ---- |\n| ArrayList | 97 | 73 |\n| LinkedList | 371 | 251 |\n\n**LinkedList切忌使用for循环遍历**\n","tags":["Java Performance"],"categories":["Performance"]},{"title":"Kafka -- 分布式流处理平台","url":"%2F2019%2F06%2F24%2Fkafka-distributed-streaming-platform%2F","content":"\n## 历史\n\n### 消息引擎系统\n1. Kafka在刚诞生时是以**消息引擎系统**的面目出现在大众视野中\n2. Kafka在0.10.0.0之前的定位：分布式、分区化且带备份功能的**提交日志**（Commit Log）服务\n3. Kafka在设计之初的功能特性\n    - 提供一套API实现**生产者**和**消费者**\n    - 降低**网络传输**和**磁盘存储**开销\n    - 实现**高伸缩**架构\n\n<!-- more -->\n\n### 分布式流处理平台\n1. Kafka于2011年正式进入Apache基金会孵化并于次年10月成为Apache顶级项目\n2. Kafka社区于0.10.0.0版本正式推出流处理组件**Kafka Streams**，定位变成了**分布式流处理平台**\n3. 同等级的实时流处理平台：Apache **Kafka**、Apache **Storm**、Apache **Spark**、Apache **Flink**\n4. 目前国内对Kafka是流处理平台的认知还不普及，其核心的流处理组件Kafka Streams更是少有大厂在使用\n\n## 优势\n\n### 端到端的正确性\n1. Kafka更容易实现**端到端的正确性**（Correctness）\n2. 流处理要替代批处理需要具备两个核心优势\n    - **实现正确性**（正确性是流处理能够匹敌批处理的基石）\n    - **提供能够推导时间的工具**\n3. 正确性一直都是批处理的强项，而实现正确性的基石是要求框架能提供_**精确一次处理语义**_\n    - 即处理一条消息**有且只有**一次机会能够影响系统状态\n4. 目前主流的大数据流处理框架都宣称实现了精确一次处理语义，但这是有**限定条件**的\n    - 即它们只能实现**框架内**的精确一次处理语义，无法实现**端到端**的\n    - 当这些框架与外部消息引擎系统结合使用时，它们无法影响到外部系统的处理语义\n    - 例如搭建一套环境使得Spark或Flink从Kafka读取消息之后进行**有状态**的数据计算，最后写回Kafka\n    - 这种情况只能保证在Spark或Flink内部，这条消息对于状态的影响只有一次\n    - 但计算结果有可能**多次**写入到Kafka，因为它们不能控制Kafka的语义处理\n5. 对于Kafka，因为**所有的数据流转和计算**都在Kafka内部完成，所以Kafka可以实现_**端到端的精确一次处理语义**_\n\n### 自身定位\n1. Kafka官网：Kafka Streams是一个用于搭建实时流处理的**客户端库**而不是一个完整的功能系统\n    - 不提供类似集群调度、弹性部署等开箱即用的运维特性\n2. 大公司的流处理平台一定是大规模部署的，因此具备集群调度功能以及灵活的部署方案是不可或缺的要素\n3. 但世界上还存在很多**中小企业**，它们的流处理数据量并不巨大，逻辑也不复杂，部署几台机器即可应付\n    - 针对这样的需求，没必要搭建**重量级的完整性平台**，这也正是Kafka Streams的用武之地\n","tags":["Stream"],"categories":["Kafka"]},{"title":"大数据 -- 热销榜","url":"%2F2019%2F06%2F24%2Fbig-data-hot-list%2F","content":"\n## 简化问题\n1. 某电商网站销售10亿件商品，已经跟踪了网站的销售记录，格式：`<product_id, timestamp>`\n2. 整个交易记录有1000亿行，TB级别，如何根据销售记录去统计销量前10的商品\n\n## 小规模经典算法\n1. 统计每个商品的销量：可以用**哈希表**来解决， 这是一个`O(n)`的算法，n=1000亿\n2. 找出销量前10：可以用**Top K**算法，时间复杂度也是`O(n)`\n3. 大规模会面临的问题：**内存占用**、**磁盘IO延时**\n\n<!-- more -->\n\n## 大规模分布式解决方案\n\n### 统计销量\n假如有1000台机器，每台机器一次可以处理1W条销售记录，对于单台机器来说，处理规模减少，可以回归到用传统算法解决\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-hot-list-distributed-count.jpg\" width=1000/>\n\n### 销量前K\n1. 需要把分散在各个机器上的产品销量汇总出来，例如把所有product_id=1的销量全部叠加\n2. K=1时\n    - 每台机器把所有product_id相同的销量（分散在不同的机器）叠加在一起，再找出自己机器上销量Top 1的商品\n    - 对于每台机器而言，输出的就是最终排名Top 1的商品候选者\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-hot-list-distributed-topk.jpg\" width=1000/>\n\n### 结果汇总\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-hot-list-distributed-summary.jpg\" width=1000/>\n","tags":["Big Data"],"categories":["Big Data"]},{"title":"Java性能 -- 正则表达式","url":"%2F2019%2F06%2F23%2Fjava-performance-regex%2F","content":"\n## 元字符\n<img src=\"\thttps://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-regex-meta-char.jpg\" width=1000/>\n\n1. 正则表达式使用一些**特定的元字符**来检索、匹配和替换符合规则的字符串\n2. 元字符：**普通字符**、**标准字符**、**限定字符**（量词）、**定位字符**（边界字符）\n\n<!-- more -->\n\n## 正则表达式引擎\n1. 正则表达式是一个用**正则符号**写出来的公式\n    - 程序对正则表达式进行**语法分析**，建立**语法分析树**\n    - 再根据**语法分析树**结合**正则表达式引擎**生成执行程序（**状态机**），用于字符匹配\n        - 正则表达式引擎是一套核心算法，用于**建立状态机**\n    - 小结\n        - 正则表达式 => 语法分析树\n        - 语法分析树 + 正则表达引擎 => 状态机 => 用于字符匹配\n2. 目前实现正则表达式引擎的方式有两种\n    - **DFA自动机**（Deterministic Finite Automaton，确定有限状态自动机）\n    - **NFA自动机**（Nondeterministic Finite Automaton，非确定有限状态自动机）\n3. DFA自动机的**构造代价**远大于NFA自动机，但DFA自动机的**执行效率**高于NFA自动机\n    - 假设一个字符串的长度为n，如果采用DFA自动机作为正则表达式引擎，则匹配的时间复杂度为`O(n)`\n    - 如果采用NFA自动机作为正则表达式引擎，NFA自动机在**匹配过程**中存在大量的**分支**和**回溯**，假设NFA的状态数为s，\n        - 则匹配的时间复杂度为**`O(ns)`**\n4. NFA自动机的优势是**支持更多高级功能**，但都是基于_**子表达式独立进行匹配**_\n    - 因此在**编程语言**里，使用的正则表达式库都是基于**NFA自动机**实现的\n\n## NFA自动机\n\n### 匹配过程\n1. NFA自动机会读取正则表达式的每一个字符，拿去和目标字符串匹配\n2. 匹配成功则换正则表达式的下一个字符，反之就继续就和目标字符串的下一个字符进行匹配\n\n```\ntext=\"aabcab\"\nregex=\"bc\"\n```\n\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-regex-nfa-match-1.jpg\" width=600/>\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-regex-nfa-match-2.jpg\" width=600/>\n\n### 回溯\n1. 用NFA自动机实现的比较复杂的正则表达式，在匹配过程中经常会引起回溯问题\n2. 大量的回溯会**长时间占用CPU**，从而带来系统性能开销\n\n```\ntext=\"abbc\"\nregex=\"ab{1,3}c\"\n```\n\n读取正则表达式第一个匹配符a和字符串第一个字符a进行比较，a对a，匹配\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-regex-nfa-backtracking-1.jpg\" width=600/>\n读取正则表达式第二个匹配符b{1,3}和字符串的第二个字符b进行比较，匹配，但b{1,3}表示1~3个字符，而NFA自动机具有**贪婪**特性，所以不会读取正则表达式的下一个匹配符c\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-regex-nfa-backtracking-2.jpg\" width=600/>\n使用b{1,3}和字符串的第四个字符c进行比较，发现不匹配，此时就会发生**回溯**，已经读取的字符串第四个字符c将被吐出去，指针回到第三个字符b的位置\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-regex-nfa-backtracking-3.jpg\" width=600/>\n发生回溯后，读取正则表达式的下一个匹配符c，和字符串的第四个字符c进行比较，结果匹配\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-regex-nfa-backtracking-4.jpg\" width=600/>\n\n### 避免回溯\n避免回溯的方法：使用**懒惰**模式和**独占**模式\n\n#### 贪婪模式（Greedy）\n1. 在数量匹配中，如果单独使用`+、？、*、{min,max}`等量词，正则表达式会匹配**尽可能多**的内容\n2. `text=\"abbc\" , regex=\"ab{1,3}c\"`，发生了一次匹配失败，就会引起一次回溯\n3. `text=\"abbbc\" , regex=\"ab{1,3}c\"`，匹配成功\n\n#### 懒惰模式（Reluctant）\n1. 在懒惰模式下，正则表达式会**尽可能少**地重复匹配字符，如果匹配成功，会继续匹配剩余的字符串\n2. 使用`?`开启懒惰模式，`text=\"abc\" , regex=\"ab{1,3}?c\"`\n    - 匹配结果是`\"abc\"`，在该模式下NFA自动机首先选择**最小**的匹配范围，即匹配1个b字符，**避免了回溯问题**\n\n#### 独占模式（Possessive）\n1. 和贪婪模式一样，独占模式一样会**最大限度**地匹配更多内容，但在匹配失败时会**结束匹配**，**不会发生回溯问题**\n2. 使用`+`开启懒惰模式，`text=\"abbc\" , regex=\"ab{1,3}+bc\"`\n    - 结果是不匹配，结束匹配，不会发生回溯问题\n\n#### 代码\n```java\nmatch(\"ab{1,3}c\", \"abbc\"); // abbc，贪婪模式，产生回溯\nmatch(\"ab{1,3}c\", \"abbbc\"); // abbbc，贪婪模式，不产生回溯\nmatch(\"ab{1,3}?\", \"abbbb\"); // ab，懒惰模式，不产生回溯\nmatch(\"ab{1,3}+bc\", \"abbc\"); // null，独占模式，不产生回溯\n```\n\n## 正则表达式的优化\n1. 少用贪婪模式，**多用独占模式**（避免回溯）\n2. **减少分支选择**，分支选择类型`\"(X|Y|Z)\"`的正则表达式会**降低性能**，尽量减少使用，如果一定要使用\n    - 考虑选择的顺序，将比较常用的选择放在前面，使它们可以较快地被匹配\n    - 提取共用模式，`(abcd|abef)` => `ab(cd|ef)`\n    - 如果是简单的分支选择类型，可以用三次index代替`(X|Y|Z)`\n3. **减少捕获嵌套**\n    - 捕获组：把正则表达式中，子表达式匹配的内容保存到以数字编号或显式命名的数组中，一般一个`()`就是一个捕获组\n        - 每个捕获组都有一个编号，编号0代表整个匹配到的内容\n    - 非捕获组：参与匹配却**不进行分组编号**的捕获组，其表达式一般由`(?:exp)`组成\n    - 减少不需要获取的分组，可以提高正则表达式的性能\n\n### 捕获组\n```java\nString text = \"<input high=\\\"20\\\" weight=\\\"70\\\">test</input>\";\nString reg = \"(<input.*?>)(.*?)(</input>)\";\nPattern p = Pattern.compile(reg);\nMatcher m = p.matcher(text);\nwhile (m.find()) {\n    System.out.println(m.group(0));// 整个匹配到的内容\n    System.out.println(m.group(1));//(<input.*?>)\n    System.out.println(m.group(2));//(.*?)\n    System.out.println(m.group(3));//(</input>)\n    // 输出：\n    //  <input high=\"20\" weight=\"70\">test</input>\n    //  <input high=\"20\" weight=\"70\">\n    //  test\n    //  </input>\n}\n```\n\n### 非捕获组\n```java\nString text = \"<input high=\\\"20\\\" weight=\\\"70\\\">test</input>\";\nString reg = \"(?:<input.*?>)(.*?)(?:</input>)\";\nPattern p = Pattern.compile(reg);\nMatcher m = p.matcher(text);\nwhile (m.find()) {\n    System.out.println(m.group(0));// 整个匹配到的内容\n    System.out.println(m.group(1));//(.*?)\n    // 输出\n    //  <input high=\"20\" weight=\"70\">test</input>\n    //  test\n}\n```\n\n## 小结\n在做好性能测试的前提下，可以使用正则表达式，否则**能不用就不用**，避免造成更多的性能问题\n","tags":["Java Performance"],"categories":["Performance"]},{"title":"Kafka -- 术语","url":"%2F2019%2F06%2F22%2Fkafka-term%2F","content":"\n## 主题 + 客户端\n1. 发布订阅的对象是**主题**（Topic）\n2. 向主题发布消息的客户端应用程序称为**生产者**（Producer），生产者可以持续不断地向**多个主题**发送消息\n3. 订阅这些主题消息的客户端应用程序称为**消费者**（Consumer），消费者能够同时订阅**多个主题**的消息\n4. 生产者和消费者统称为**客户端**\n\n<!-- more -->\n\n## 服务端\n1. Kafka的服务端由被称为**Broker**的**服务进程**构成，一个Kafka集群由多个Broker组成\n2. Broker负责**接收和处理**客户端发送过来的请求，以及对消息进行**持久化**\n3. 多个Broker进程能够运行在同一台机器上，但更常见的做法是将不同的Broker**分散运行在不同的机器**上\n    - 这样如果集群中某一台机器宕机了，即使在它上面运行的所有Broker进程都挂掉了\n    - 其他机器上的Broker也依然能够对外提供服务，这是Kafka提供**高可用**的手段之一\n\n## 备份\n1. 实现**高可用**的另一个手段是**备份机制**（Replication）\n2. 备份：把**相同的数据**拷贝到多台机器上，这些相同的数据拷贝在Kafka中被称为**副本**（Replica）\n3. 副本的数量是可以配置的，Kafka定义了两类副本：**领导者副本**（Leader Replica）和**追随者副本**（Follower Replica）\n    - 领导者副本：**对外提供服务**，对外指的是与客户端程序进行交互\n        - 生产者总是向领导者副本写消息\n        - 消费者总是从领导者副本读消息\n    - 追随者副本：**被动地追随领导者副本**，不能与外界交互\n        - 向领导者副本发送请求，请求领导者副本把最新生产的消息发给它，进而与领导者副本保持同步\n        - MySQL的从库是可以处理读请求的\n    - Master-Slave => Leader-Follower\n4. 副本机制可以保证**数据的持久化**或者**消息不丢失**，但没有解决**伸缩性**（Scalability）的问题\n    - 如果领导者副本积累了太多的数据以至于单台Broker机器无法容纳，该如何处理？\n    - 可以把数据分割成多份，然后保存在不同的Broker上，这种机制就是**分区**（Partitioning）\n        - MongoDB、Elasticsearch -- Sharding\n        - HBase -- Region\n\n## 分区\n1. Kafka中的分区机制是将每个**主题**划分成多个**分区**（Partition），每个分区是_**一组有序的消息日志**_\n2. 生产者生产的每条消息只会被发送到一个分区中，Kafka的分区编号是从0开始的\n3. 副本是在分区这个层级定义的，每个分区下可以配置N个副本，只能有1个领导者副本和N-1个追随者副本\n4. 生产者向分区（**分区的领导者副本**）写入消息，每条消息在分区中的位置由**位移**（Offset）来表征，而**分区位移**总是从0开始\n5. 三层消息架构\n    - 第一层是**主题**层，每个主题可以配置M个分区，而每个分区又可以配置N个副本\n    - 第二层是**分区**层\n        - 每个分区的N个副本中只能有1个领导者副本，**对外提供服务**\n        - 其他N-1个副本是追随者副本，只能提供**数据冗余**\n    - 第三层是**消息**层，分区中包含若干条消息，每条消息的位移从0开始，依次递增\n    - 最后，客户端程序只能与**分区的领导者副本**进行交互\n\n## 持久化\n1. Kafka使用消息**日志**（Log）来保存数据，一个日志是磁盘上一个**只能追加写**（Append-Only）消息的物理文件\n    - 只能追加写入，避免了缓慢的随机IO操作，改为性能较好的**顺序IO操作**，这是实现Kafka**高吞吐量**的一个重要手段\n2. Kafka需要**定期删除消息**以回收磁盘空间，可以通过**日志片段**（Log Segment）机制来实现\n    - 在Kafka底层，一个日志又被细分成多个日志段，消息被追加到**当前最新的日志段**中\n    - 当写满一个日志段后，Kafka会自动切分出一个新的日志段，并将老的日志段封存起来\n    - Kafka在后台有定时任务定期地检查这些老的日志段是否能够被删除，从而实现回收磁盘空间的目的\n\n## 消费者\n1. 点对点模型（Peer to Peer，P2P）：**同一条消息只能被下游的一个消费者消费**，其他消费者不能染指\n2. Kafka通过**消费者组**（Consumer Group）来实现**P2P模型**\n    - 消费者组：多个消费者实例共同组成一个组来消费一组主题\n    - 这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它\n        - 即**消费者对分区有所有权**\n3. 引入消费者组的目的：**提高消费者端的吞吐量**（TPS）\n4. 消费者实例（Consumer Instance）：即可以是运行消费者应用的**进程**，也可以是一个**线程**\n5. **重平衡**（Rebalance）\n    - 若组内的某个实例挂了，Kafka能够自动检测到，然后把这个挂掉的实例之前负责的分区转移给组内其他存活的消费者\n    - 重平衡引发的消费者问题很多，目前很多重平衡的Bug社区都无力解决\n6. **消费者位移**（Consumer Offset）：记录消费者当前消费到了分区的哪个位置，**随时变化**\n    - 分区位移：表征的是消息在分区内的位置，一旦消息被成功写入到一个分区上，消息的分区位移就**固定**了\n\n## 小结\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/geek-time/kafka-term.png\" width=1000/>\n\n1. 消息（Record）：消息是Kafka处理的主要对象\n2. 主题（Topic）：主题是承载消息的**逻辑容器**，实际使用中多用来区分具体的业务\n3. 分区（Partition）：一个**有序不变的消息序列**，每个主题下有多个分区\n4. 消息位移（Offset）：也叫分区位移，表示一条消息在分区中的位置，是一个**单调递增且不变**的值\n5. 副本（Replica）\n    - Kafka中同一条消息能够被拷贝到多个地方以提供**数据冗余**\n    - 副本分为领导者副本和追随者副本，副本在分区的层级下，每个分区可配置多个副本实现**高可用**\n6. 生产者（Producer）：向主题发布消息的应用程序\n7. 消费者（Consumer）：从主题订阅消息的应用程序\n8. 消费者位移（Consumer Offset）：表征消费者的**消费进度**，每个消费者都有自己的消费者位移\n9. 消费者组（Consumer Group）：多个消费者实例共同组成一个组，同时消费多个分区以实现**高吞吐**\n10. 重平衡（Rebalance）\n    - 消费者组内某个消费者实例挂掉后，其他消费者实例自动**重新分配订阅分区**的过程\n    - 重平衡是Kafka**消费者端**实现**高可用**的重要手段\n","tags":["Stream"],"categories":["Kafka"]},{"title":"大数据 -- 下一代数据处理技术","url":"%2F2019%2F06%2F21%2Fbig-data-next-generation%2F","content":"\n## MapReduce\n1. 2014年之前，MapReduce是数据处理的默认标准，其主要缺点：_**维护成本高**、**时间性能不足**_\n2. 2008年，FlumeJava诞生于Google西雅图研发中心，成为Google内部的数据处理新宠\n3. 假设在2008年，已知MapReduce的主要问题，应该如何设计下一代大规模数据处理技术？\n\n<!-- more -->\n\n## 让多步骤数据处理易于维护\n1. 维护协调多个步骤的数据处理在业务中非常常见，但复杂的数据处理在MapReduce中的维护成本很高\n2. 可以利用**有向无环图**（DAG，Directed Acyclic Graph）来抽象表达\n3. DAG能为多步骤的数据处理依赖关系，建立很好的模型\n\n### DAG\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-next-generation-dag-tomato-egg.png\" width=500/>\n\n1. 如果用MapReduce实现，图中的每个箭头都会是一个独立的Map或者Reduce\n    - 为了协调那么多的Map和Reduce，需要做很多检查，系统将不堪重负\n2. 如果采用DAG建模\n    - 每一个**节点**都可以被抽象表达成一种通用的**数据集**\n    - 每一条**边**都可以被抽象表达成一种通用的**数据变换**\n    - 可以用数据集和数据变换描述一个极为宏大复杂的数据处理流程，而不会迷失在依赖关系中\n\n## 简单配置 + 性能自动优化\n1. MapReduce的配置过于复杂，以至于错误的配置最终导致数据处理任务的效率低下\n2. 得益于上一步使用DAG对数据处理进行了高度抽象，这也成为了自动化性能优化的一个突破口\n3. 理想情况下，计算引擎要能够自动发现红框中的两条数据处理流程是重复的，并进行合并处理\n4. 另一种自动的优化：**计算资源的自动弹性分配**，在数据处理开始前，需要有一个自动优化的步骤和能力\n\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-next-generation-dag-tomato-egg-burdock.jpg\" width=600/>\n\n## 解耦：数据描述 + 计算引擎\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-next-generation-data-engine-client.png\" width=400/>\n\n1. 除了**DAG表达**需要**数据处理描述语言**和**计算引擎**协商一致外，其他的实现都是灵活可拓展的\n2. 例如，数据描述可以用Python描述，由业务团队使用，计算引擎用C++实现，可以由数据底层架构团队维护并且高度优化\n3. 例如，数据描述在本地写，计算引擎在云端执行\n\n## 统一的编程模型：批处理 + 流处理\n1. 批处理处理的是**有界离散**的数据，而流处理处理的是**无界连续**的数据\n2. MapReduce的一个局限是它是为了批处理而设计的，不善于流处理\n    - 即便是后面的Apache Storm、Apache Flink也有类似的问题\n    - Apache Flink进行批处理时用的是DataSet，而进行流处理时用的是DataStream\n3. 真正的业务系统，批处理和流处理常常是**混合共生**的，或者**频繁变换**的\n    - 因此在设计数据处理框架时，需要有更高层级的数据抽象\n    - 不管批处理还是流处理，都用**统一的数据结构**表示，也需要**统一的编程API**\n    - 即使业务需求改变，开发者也不需要频繁修改代码\n\n## 异常处理 + 数据监控\n1. 在一个复杂的数据处理系统中，难的并不是开发系统，而是**异常处理**\n    - 一个Google内部调研中表明，在大规模的数据处理系统中，90%的时间都花在了异常处理上\n2. 在数据处理系统，数据就是金钱，不能丢失\n    - 因此需要设计一套具备基本的数据监控能力，对数据处理的每一步提供自动监控的平台\n\n## 小结\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-next-generation.png\" width=800/>\n","tags":["Big Data"],"categories":["Big Data"]},{"title":"大数据 -- MapReduce","url":"%2F2019%2F06%2F20%2Fbig-data-map-reduce%2F","content":"\n## 时间线\n<img src=\"https://big-data-1253868755.cos.ap-guangzhou.myqcloud.com/big-data-timeline.png\" width=1000/>\n\n<!-- more -->\n\n### 石器时代\n1. 石器时代：MapReduce诞生之前的时期\n2. 数据的大规模处理问题早已存在，但数据的大规模处理技术还处于彷徨阶段\n    - 每个公司或个人都可能有自己的一套工具处理数据，但没有提炼抽象出一个系统的方法\n\n### 青铜时代\n1. 2003年，MapReduce的诞生标志了超大规模数据处理的第一次革命\n2. 论文：《MapReduce: Simplified Data Processing on Large Clusters》\n    - Jeff Dean和Sanjay Ghemawat从纷繁复杂的业务逻辑中，抽象出通用的编程模型：Map和Reduce\n3. 后来的Hadoop是对GFS、BigTable、MapReduce的开源实现\n\n### 蒸汽机时代\n1. 从2016年开始，Google在新员工的培训中把MapReduce替换成内部称为**FlumeJava**的数据处理技术\n2. FlumeJava不等同于Apache Flume，这标志着青铜时代的终结，同时标志着蒸汽机时代的开始\n3. Google FlumeJava对应的开源版本为**Apache Beam**\n\n## MapReduce的缺点\n\n### 高昂的维护成本\n1. 使用MapReduce，需要严格地遵循分步的Map和Reduce步骤\n2. 当构造复杂的处理架构时，往往需要**协调**多个Map和多个Reduce任务\n3. 但是每一步的MapReduce都有可能出错，为了处理这些异常，很多人开始设计自己的**协调系统**，大大**增加整个系统的复杂度**\n4. 真实的商业MapReduce场景**极端复杂**\n    - 在应用过程中，每个MapReduce任务都可能出错，都需要重试和异常处理的机制\n    - 而协调这些子MapReduce的任务往往需要与业务逻辑**紧密耦合**的状态机\n\n### 时间性能差\n1. MapReduce性能优化配置非常复杂，Google关于MapReduce的性能优化手册有500多页\n2. Google曾在2007年到2012年做过对1PB数据的大规模排序实验，用来测试MapReduce的性能\n    - 2007年为12小时，2012年为0.5小时，Google花了5年的时间才不断优化了一个MapReduce流程的效率\n","tags":["MapReduce"],"categories":["MapReduce"]},{"title":"Go -- 扩展","url":"%2F2019%2F06%2F19%2Fgo-extend%2F","content":"\n## Java的扩展\n面向对象的扩展可以通过**继承**和**复合**来实现，但Go并不支持继承\n```java\nclass Pet {\n    public void speak() {\n        System.out.println(\"Pet Speak\");\n    }\n}\n\nclass Dog extends Pet {\n    @Override\n    public void speak() {\n        System.out.println(\"Dog Speak\");\n    }\n}\n```\n\n<!-- more -->\n\n```java\npublic class InheritTest {\n    @Test\n    public void subClassAccessTest() {\n        Pet dog = new Dog();\n        dog.speak(); // Dog Speak\n    }\n\n    @Test\n    // LSP : Liskov substitution principle\n    // 里氏替换原则：派生类（子类）对象可以在程式中代替其基类（超类）对象\n    public void lspTest() {\n        makePetSpeak(new Dog()); // Dog Speak\n    }\n\n    private void makePetSpeak(Pet pet) {\n        pet.speak();\n    }\n}\n```\n\n## Go的扩展\n\n### 复合\n```go\ntype Pet struct {\n}\n\nfunc (p *Pet) speak() {\n    fmt.Println(\"Pet Speak\")\n}\n\ntype Dog struct {\n    // 复合：通过Pet扩展Dog的功能\n    p *Pet\n}\n\nfunc (d *Dog) speak() {\n    d.p.speak()\n    fmt.Println(\"Dog Speak\")\n}\n\nfunc TestComplex(t *testing.T) {\n    t.Logf(\"%T\", Dog{})    // extension.Dog\n    t.Logf(\"%T\", &Dog{})   // *extension.Dog\n    t.Logf(\"%T\", new(Dog)) // *extension.Dog\n    dog := new(Dog)\n    dog.speak()\n    // 输出\n    //\tPet Speak\n    //\tDog Speak\n}\n```\n\n### 匿名嵌套类型\n```go\ntype Pet struct {\n}\n\nfunc (p *Pet) speak() {\n    fmt.Println(\"Pet Speak\")\n}\n\nfunc (p *Pet) eat() {\n    fmt.Println(\"Pet Eat\")\n}\n\ntype Dog struct {\n    // 匿名嵌套类型，不能当成继承使用\n    Pet\n}\n\nfunc (d *Dog) speak() {\n    fmt.Println(\"Dog Speak\")\n}\n\nfunc TestAnonymousNestedType(t *testing.T) {\n    dog := new(Dog)\n    dog.eat()   // Pet Eat\n    dog.speak() // Dog Speak\n}\n\nfunc TestNotInherit(t *testing.T) {\n    // 不符合LSP\n    // var d1 Pet = new(Dog)         // cannot use new(Dog) (type *Dog) as type Pet in assignment\n    // var d2 Pet = Dog{}            // cannot use Dog literal (type Dog) as type Pet in assignment\n    // var d3 Pet = (*Pet)(new(Dog)) // cannot convert new(Dog) (type *Dog) to type *Pet\n}\n```\n","tags":["Go"],"categories":["Go"]},{"title":"Kafka -- 消息引擎系统","url":"%2F2019%2F06%2F18%2Fkafka-messaging-system%2F","content":"\n## 术语\n1. Apache Kafka是一款开源的**消息引擎系统**\n2. 消息队列：给人某种暗示，仿佛Kafka是利用**队列**实现的\n3. 消息中间件：过度强调中间件，而不能清晰地表达实际解决的问题\n\n<!-- more -->\n\n## 解决的问题\n1. 系统A发送消息给消息引擎系统，系统B从消息引擎系统中读取A发送的消息\n2. 消息引擎传输的对象是消息\n3. 如何传输消息属于消息引擎设计机制的一部分\n\n## 消息格式\n1. 成熟解决方案：CSV、XML、JSON\n2. 序列化框架：Google Protocol Buffer、Facebook Thrift\n3. Kafka：纯二进制的字节序列\n\n## 消息引擎模型\n1. 点对点模型\n    - 即消息队列模型，系统A发送的消息只能被系统B接收，其他任何系统不能读取A发送的消息\n2. 发布订阅模型\n    - 主题（Topic）、发布者（Publisher）、订阅者（Subscriber）\n    - 多个发布者可以向相同的主题发送消息，多个订阅者可以接收相同主题的消息\n3. Kafka同时支持上面两种消息引擎模型\n\n## JMS\n1. JMS：Java Message Service\n2. JMS也支持上面的两种消息引擎模型\n3. JMS并非传输协议，而是一组API\n4. JMS非常出名，很多主流的消息引擎系统都支持JMS规范\n    - ActiveMQ、RabbitMQ、IBM WebSphere MQ、Apache Kafka（并未完全遵照）\n\n## 优点\n1. **削峰填谷**\n2. **解耦**\n","tags":["Stream"],"categories":["Kafka"]},{"title":"Go -- 接口","url":"%2F2019%2F06%2F17%2Fgo-interface%2F","content":"\n## Duck Type式接口\n```go\ntype Programmer interface {\n    writeHelloWorld() string\n}\n\n// 不需要关键字：implements\ntype GoProgrammer struct {\n}\n\n// Duck Type式接口，与Programmer里面的方法签名完全一致\nfunc (p *GoProgrammer) writeHelloWorld() string {\n    return \"fmt.Println(\\\"Hello World\\\")\"\n}\n\nfunc TestInterface(t *testing.T) {\n    var p Programmer\n    p = new(GoProgrammer)\n    t.Log(p.writeHelloWorld()) // fmt.Println(\"Hello World\")\n}\n```\n\n<!-- more -->\n\n1. _**接口为非侵入性，实现不依赖于接口定义**_\n2. 接口的定义可以包含在接口使用者包内\n    - 即GoProgrammer在一个单独的包，使用的时候再定义接口Programmer，也是没问题的，因为是**Duck Type**\n\n## 接口变量\n```go\nfunc TestInterfaceVar(t *testing.T) {\n    var programmer Programmer = &GoProgrammer{}\n    t.Logf(\"%T\", programmer) // *interface_test.GoProgrammer\n}\n```\n\n<img src=\"https://go-1253868755.cos.ap-guangzhou.myqcloud.com/go-interface-var.png\" width=800/>\n\n## 自定义类型\n```go\n// 自定义类型（别名）\ntype IntConvert func(op int) int\n\nfunc timeSpent(inner IntConvert) IntConvert {\n    return func(op int) int {\n    \tstart := time.Now()\n    \tret := inner(op)\n    \tfmt.Println(\"time spent : \", time.Since(start).Seconds())\n    \treturn ret\n    }\n}\n\nfunc slowFunc(op int) int {\n    time.Sleep(time.Second * 1)\n    return op\n}\n\nfunc TestFuncAsParam(t *testing.T) {\n    f := timeSpent(slowFunc)\n    t.Log(f(10))\n}\n```\n","tags":["Go"],"categories":["Go"]},{"title":"Go -- 行为","url":"%2F2019%2F06%2F16%2Fgo-behavior%2F","content":"\n## 面向对象\n[Is Go an object-oriented language?](https://golang.google.cn/doc/faq#Is_Go_an_object-oriented_language)\n\n> **Yes and no.** Although Go has types and methods and allows an object-oriented style of programming, **there is no type hierarchy. The concept of “interface” in Go provides a different approach that we believe is easy to use and in some ways more general.** There are also ways to embed types in other types to provide something analogous—but not identical—to subclassing.Moreover, methods in Go are more general than in C++ or Java: they can be defined for any sort of data, even built-in types such as plain, “unboxed” integers. They are not restricted to structs (classes).\n\n> Also, the lack of a type hierarchy makes “objects” in Go feel much more lightweight than in languages such as C++ or Java.\n\n<!-- more -->\n\n## 结构体定义\n```go\ntype Employee struct {\n    Id   string\n    Name string\n    Age  int\n}\n```\n\n## 实例初始化\n```go\nfunc TestStructInit(t *testing.T) {\n    e1 := Employee{0, \"N1\", 1}\n    t.Logf(\"%T\", e1) // field.Employee\n\n    e2 := Employee{Name: \"N2\", Age: 2}\n    t.Log(e2) // {0 N2 2}\n\n    e3 := new(Employee) // 返回指向实例的指针，相当于e3 := &Employee{}\n    e3.Id = 1           // 与其他语言的差异：通过实例的指针访问成员不需要使用->\n    e3.Name = \"N3\"\n    e3.Age = 3\n    t.Logf(\"%T\", &e2) // *field.Employee\n    t.Logf(\"%T\", e3)  // *field.Employee\n}\n```\n\n## 行为定义\n```go\n// 第一种方式：方法被调用时，实例的成员会进行值复制\nfunc (e Employee) s1() string {\n    fmt.Printf(\"s1 address is %X\\n\", unsafe.Pointer(&e.Name)) // 地址会发生变化\n    return fmt.Sprintf(\"Id:%d - Name:%s - Age:%d\", e.Id, e.Name, e.Age)\n}\n\n// 第二种方式：可以避免内存拷贝\nfunc (e *Employee) s2() string {\n    fmt.Printf(\"s2 address is %X\\n\", unsafe.Pointer(&e.Name)) // 地址不变\n    return fmt.Sprintf(\"Id:%d = Name:%s = Age:%d\", e.Id, e.Name, e.Age)\n}\n\nfunc TestStructOperations(t *testing.T) {\n    e1 := Employee{1, \"N1\", 1}\n    fmt.Printf(\"Address is %X\\n\", unsafe.Pointer(&e1.Name))\n    t.Log(e1.s1()) // Id:1 - Name:N1 - Age:1\n    t.Log(e1.s2()) // Id:1 = Name:N1 = Age:1\n\n    fmt.Println()\n\n    e2 := &Employee{2, \"N2\", 2}\n    fmt.Printf(\"Address is %X\\n\", unsafe.Pointer(&e2.Name))\n    t.Log(e2.s1()) // Id:2 - Name:N2 - Age:2\n    t.Log(e2.s2()) // Id:2 = Name:N2 = Age:2\n\n    // fmt输出\n    // Address is C000090188\n    // s1 address is C0000901A8\n    // s2 address is C000090188\n    //\n    // Address is C000090248\n    // s1 address is C000090268\n    // s2 address is C000090248\n}\n```\n","tags":["Go"],"categories":["Go"]},{"title":"Go -- 函数","url":"%2F2019%2F06%2F15%2Fgo-func%2F","content":"\n## \u0010Go函数\n1. 可以有**多个返回值**\n2. 所有参数都是**值传递**：slice、map、channel会有传引用的错觉\n3. 一等公民\n    - 函数可以作为**变量的值**\n    - 函数可以作为**参数**和**返回值**\n\n<!-- more -->\n\n## 多返回值\n```go\nfunc returnMultiValues() (int, int) {\n    return rand.Intn(10), rand.Intn(20)\n}\n\nfunc TestReturnMultiValues(t *testing.T) {\n    a, b := returnMultiValues()\n    t.Log(a, b) // 1 7\n}\n```\n\n## 一等公民\n函数可以作为**参数**和**返回值**\n```go\n// 入参：func(op int) int\n// 出参：func(op int) int\nfunc timeSpent(inner func(op int) int) func(op int) int {\n    // 函数式编程\n    return func(op int) int {\n    \tstart := time.Now()\n    \tret := inner(op)\n    \tfmt.Println(\"time spent : \", time.Since(start).Seconds())\n    \treturn ret\n    }\n}\n\nfunc slowFunc(op int) int {\n    time.Sleep(time.Second * 1)\n    return op\n}\n\nfunc TestFuncAsParam(t *testing.T) {\n    // f是通过函数式编程封装后的函数，增强了原有函数的功能\n    f := timeSpent(slowFunc)\n    t.Log(f(10))\n\n    // 输出：\n    // time spent :  1.004157729\n    // 10\n}\n```\n\n## 可变参数\n```go\nfunc sum(ops ...int) int {\n    ret := 0\n    for _, op := range ops {\n    \tret += op\n    }\n    return ret\n}\n\nfunc TestVarParam(t *testing.T) {\n    t.Log(sum(1, 2, 3, 4)) // 10\n}\n```\n\n## defer\n延迟运行，类似于Java中的**finally**，主要用于释放某些资源\n```go\nfunc TestDefer(t *testing.T) {\n    defer clear()\n    fmt.Println(\"Start\")\n    panic(\"Fatal Error\") // 依然会执行clear()\n    fmt.Println(\"End\")   // 不可达\n\n    //\tStart\n    //\tClear Resources.\n    //\t--- FAIL: TestDefer (0.00s)\n    //\tpanic: Fatal Error [recovered]\n    //\tpanic: Fatal Error\n}\n```\n","tags":["Go"],"categories":["Go"]},{"title":"网络协议 -- UDP","url":"%2F2019%2F06%2F14%2Fnetwork-protocol-udp%2F","content":"\n## TCP VS UDP\n1. TCP是**面向连接**的，而UDP是**面向无连接**的\n    - 在互通之前，面向连接的协议会先**建立连接**，例如TCP会进行**三次握手**\n    - 建立连接\n        - 建立连接，是为了在客户端和服务端之间**维护连接**，而建立一定的数据结构来**维护双方交互的状态**\n        - 用这样的数据结构来保证所谓的面向连接的特性\n2. TCP提供**可靠交付**\n    - 通过TCP连接传输的数据，**无差错、不丢失、不重复、按序到达**\n    - IP包没有任何可靠性保证，**UDP继承了IP包的特性**，不保证不丢失，不保证按序到达\n3. TCP是面向**字节流**的，发送的时候是一个流，没头没尾，IP包不是一个流，而是一个个的IP包\n    - UDP继承类IP的特性，基于**数据报**的，一个一个地发，一个一个地收\n4. TCP支持**拥塞控制**，当它意识到包丢失或者网络环境不好时，会根据情况调整自己的行为\n    - UDP不会理会网络环境的好坏，只管发\n5. 因此，TCP是**有状态服务**，而UDP是**无状态服务**\n\n<!-- more -->\n\n## UDP Header\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-udp-fmt.png\" width=1000/>\n\n1. IP头里面有一个8位字段，会区分传输层使用的是UDP还是TCP\n2. 处理完传输层的事情，内核的事情就基本处理完了，然后按照**端口号**，将里面的数据交给对应的应用程序去处理\n\n## UDP的特点\n1. **沟通简单**：不需要大量的数据结构、处理逻辑、包头字段，相信网络环境是美好的，数据报很容易送达\n2. **轻信他人**：不会建立连接，监听某个端口，所有人都能给它发数据，它也可以给任何人发数据\n3. **愣头青**：不会根据网络环境的好坏进行发包的拥塞控制，无论网络丢包如何，该怎么发还是怎么发\n\n## UDP的使用场景\n1. **需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用**\n    - DHCP就是基于UDP协议，一般获取IP地址都是内网请求，而且一次获取失败影响不大\n2. **不需要建立连接进行一对一沟通，而是可以广播的应用**\n    - UDP面向非连接的功能，可以承载广播或者多播的协议，DHCP是广播的一种形式\n3. **需要处理速度快、延时低，可以容忍少数丢包，但要求即使网络拥塞，也要继续发包**\n    - TCP在网络不好出现丢包时，拥塞控制策略会主动退缩，降低发送速度，这会让用户感觉更卡\n    - 现在很多应用都要求低延时，并不想使用TCP那么复杂的机制，而是根据实际场景，实现**自定义的可靠性和连接保证**\n","tags":["UDP"],"categories":["Protocol"]},{"title":"Go -- 字符串","url":"%2F2019%2F06%2F13%2Fgo-string%2F","content":"\n## string\n1. string是数据类型，**不是引用或指针类型**\n2. string是**只读的byte slice**，len()返回它所包含的**byte数**（并不等同于**字符数**）\n3. string的byte数组可以存放**任何数据**\n\n```go\nfunc TestStringBasic(t *testing.T) {\n    var s string\n    t.Log(s) // 初始化为默认零值“”\n\n    s = \"hello\"\n    t.Log(len(s)) // 5\n\n    // string是不可变的byte slice\n    // s[1] = '3' // cannot assign to s[1]\n\n    // 可以存储任何二进制数据\n    s = \"\\xE4\\xB8\\xAD\"\n    t.Log(s) // 中\n}\n```\n\n<!-- more -->\n\n## 编码与存储\nUnicode是一种**字符集**（code point，字符编码），UTF-8是Unicode的**存储实现**（转换为**字节序列**的规则）\n```go\nfunc TestStringEncode(t *testing.T) {\n    s := \"中\"\n\tt.Log(len(s)) // 3，byte数\n\n\t// rune：取出string中的Unicode\n\tc := []rune(s)\n\tt.Log(len(c))                    // 1\n\tt.Log(unsafe.Sizeof(c[0]))       // 4\n\tt.Logf(\"%s Unicode %X\", s, c[0]) // 中 Unicode 4E2D\n\tt.Logf(\"%s UTF-8 %X\", s, s)      // 中 UTF-8 E4B8AD\n}\n\nfunc TestStringToRune(t *testing.T) {\n    s := \"中山市\"\n    // range遍历，迭代输出的是rune，而不是byte\n    for _, c := range s {\n    \t// [1]表示都格式化第1个参数\n    \tt.Logf(\"%[1]c %[1]X\", c)\n    \t// 中 4E2D\n    \t// 山 5C71\n    \t// 市 5E02\n    }\n}\n```\n\n| 字符 | \"中\" |\n| ---- | ---- |\n| Unicode | 0x4E2D |\n| UTF-8 | 0xE4B8AD |\n| string/[]byte | [0xE4,0xB8,0xAD] |\n\n## 字符串函数\n常用的字符串函数包：strings和strconv\n```go\nimport (\n    \"strconv\"\n    \"strings\"\n    \"testing\"\n)\n\nfunc TestStrings(t *testing.T) {\n    s := \"A,B,C\"\n    // 分割\n    parts := strings.Split(s, \",\")\n    for _, part := range parts {\n    \tt.Log(part)\n    }\n    // 连接\n    t.Log(strings.Join(parts, \"-\")) // A-B-C\n}\n\nfunc TestStringConvert(t *testing.T) {\n    s := strconv.Itoa(10)\n    t.Log(\"str\" + s) // str10，Go不支持隐式转换，证明10是字符串\n    if i, err := strconv.Atoi(\"10\"); err == nil {\n    \tt.Log(10 + i) // 20\n    }\n}\n```\n","tags":["Go"],"categories":["Go"]},{"title":"Java并发 -- CSP模型","url":"%2F2019%2F06%2F12%2Fjava-concurrent-csp%2F","content":"\n## Go\n1. Go是一门号称从**语言层面支持并发**的编程语言，支持并发也是Go非常重要的特性之一\n2. Go支持**协程**，协程可以类比Java中的线程，解决并发问题的难点在于线程（协程）之间的**协作**\n3. Go提供了两种方案\n    - 支持协程之间以**共享内存**的方式通信，Go提供了**管程**和**原子类**来对协程进行同步控制，该方案与Java类似\n    - 支持协程之间以**消息传递**的方式通信，本质上是要**避免共享**，该方案是基于**CSP模型**实现的，Go推荐该方案\n\n<!-- more -->\n\n## CSP模型\n1. CSP：Communicating Sequential Processes\n2. _**Do not communicate by sharing memory; instead, share memory by communicating.**_\n\n### 累加器\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc main() {\n    singleCoroutine()\n    multiCoroutine()\n}\n\n// 单协程，只能用到CPU的一个核\nfunc singleCoroutine() {\n    var result, i uint64\n    start := time.Now()\n    for i = 1; i <= 10000000000; i++ {\n    \tresult += i\n    }\n    elapsed := time.Since(start)\n    fmt.Println(elapsed, result) // 4.330357206s 13106511857580896768\n}\n\n// 多协程\nfunc multiCoroutine() {\n    var result uint64\n    start := time.Now()\n    ch1 := calc(1, 2500000000)\n    ch2 := calc(2500000001, 5000000000)\n    ch3 := calc(5000000001, 7500000000)\n    ch4 := calc(7500000001, 10000000000)\n    // 主协程需要与子协程通信，Go中协程之间的通信推荐使用channel\n    result = <-ch1 + <-ch2 + <-ch3 + <-ch4\n    // ch1只能读取数据，如果通过ch1写入数据，编译时会报错\n    // ch1 <- 7 // invalid operation: ch1 <- 7 (send to receive-only type <-chan uint64)\n    elapsed := time.Since(start)\n    fmt.Println(elapsed, result) // 1.830920702s 13106511857580896768\n}\n\n// 返回一个只能接收数据的channel\n// 方法创建的子协程会把计算结果发送到这个channel，而主协程会通过channel把计算结果取出来\nfunc calc(from uint64, to uint64) <-chan uint64 {\n    // channel用于协程间的通信，这是一个无缓冲的channel\n    channel := make(chan uint64)\n    go func() {\n    \tresult := from\n    \tfor i := from + 1; i <= to; i++ {\n    \t\tresult += i\n    \t}\n    \t// 将结果写入channel\n    \tchannel <- result\n    }()\n    // 返回用于通信的channel\n    return channel\n}\n```\n\n### 生产者-消费者模式\n1. 可以把Go实现的CSP模式类比成**生产者-消费者模式**，而channel类比成生产者-消费者模式中的**阻塞队列**\n2. Go中channel的容量可以为0，容量为0的channel被称为**无缓冲的channel**，容量大于0的channel被称为**有缓冲的channel**\n3. 无缓冲的channel类似于Java中提供的**SynchronousQueue**，主要用途是在两个协程之间做**数据交换**\n4. Go中的channel是**语言层面**支持的，使用左向箭头`<-`完成**向channel发送数据**和**读取数据**的任务\n5. Go中的channel是支持**双向传输**的，即一个协程既可以通过它**发送数据**，也可以通过它**接收数据**\n6. Go中的双向channel可以变成一个**单向channel**\n    - calc中创建了一个双向channel，但是返回的是一个只能接收数据的单向channel\n    - 所以在主协程中，只能通过该channel接收数据，而不能通过它发送数据\n\n```go\n// 创建一个容量为4的channel\nchannel := make(chan int, 4)\n\n// 创建4个协程，作为生产者\nfor i := 0; i < 4; i++ {\n    go func() {\n        channel <- 7\n    }()\n}\n\n// 创建4个协程，作为消费者\nfor i := 0; i < 4; i++ {\n    go func() {\n        o := <-channel\n        fmt.Println(\"received : \", o)\n    }()\n}\n```\n\n### Actor模式\n1. Go实现的CSP模式和Actor模式都是通过**消息传递**的方式来**避免共享**，主要有以下三个区别\n2. **Actor模型中没有channel**，Actor模型中的Mailbox与channel非常类似，看起来都是FIFO队列，但本质区别很大\n    - Actor模型\n        - Mailbox对程序员是**透明**的，Mailbox明确归属于某一个特定的Actor，是Actor模型的**内部机制**\n        - Actor之间可以**直接通信**，不需要通信媒介\n    - CSP模型\n        - channel对于程序员来说是**可见**的\n        - channel是**通信媒介**，传递的消息都直接发送到channel中\n3. Actor模型中发送消息是**非阻塞**的，而CSP模型中是**阻塞**的\n    - Go实现的CSP模型，channel是一个**阻塞队列**\n    - 当阻塞队列已满的时候，向channel发送数据，会导致发送消息的协程阻塞\n4. Actor模型理论上不保证消息百分比送达，而Go实现的CSP模型中，是能保证**消息百分百送达**的（代价：可能导致**死锁**）\n\n```go\nfunc main() {\n    // 无缓冲的channel\n    channel := make(chan int)\n    // fatal error: all goroutines are asleep - deadlock!\n    // 主协程会阻塞在此处，发生死锁\n    <-channel\n}\n```\n\n## 小结\n1. CSP模型是Tony Hoare在1978年提出的，该模型一直都在发展，**其理论远比Go实现的复杂得多**\n    - Tony Hoare在并发领域还有另一项重要成就，即**霍尔管程模型**，这是**Java**解决并发问题的**理论基础**\n2. Java可以借助第三方类库**JCSP**来支持CSP模型，相比Go的实现，**JCSP更接近理论模型**\n    - JCSP并没有经过广泛的生产环境检验，因此**不推荐在生产环境使用**\n","tags":["CSP"],"categories":["Concurrent"]},{"title":"Go -- Map","url":"%2F2019%2F06%2F11%2Fgo-map%2F","content":"\n## 声明\n```go\nfunc TestInitMap(t *testing.T) {\n    m1 := map[int]int{1: 1, 2: 4, 3: 9}\n    t.Log(m1[2])   // 4\n    t.Log(len(m1)) // 3\n\n    m2 := map[int]int{}\n    m2[4] = 16\n    t.Log(len(m2)) // 1\n\n    // 10为cap，没有使用len，因为len会初始化为“0”值，但map没法预设“0”值\n    m3 := make(map[int]int, 10)\n    t.Log(len(m3)) // 0\n    //t.Log(cap(m3)) // invalid argument m3 (type map[int]int) for cap\n}\n```\n\n<!-- more -->\n\n## 元素访问\n```go\nfunc TestAccessNotExistingKey(t *testing.T) {\n    m1 := map[int]int{}\n    // 不存在，返回0，避免了其他语言中的空指针异常\n    t.Log(m1[1]) // 0\n    m1[2] = 0\n    // 存在0，返回0，无法区分\n    t.Log(m1[2]) // 0\n\n    if v, ok := m1[3]; ok {\n    \tt.Log(\"Key exists, value=\", v)\n    } else {\n    \tt.Log(\"Key not exists \")\n    }\n}\n```\n\n## 遍历\n```go\nfunc TestTravelMap(t *testing.T) {\n    m := map[int]int{1: 1, 2: 4, 3: 9}\n    for k, v := range m {\n    \tt.Log(k, v)\n    \t// 1 1\n    \t// 2 4\n    \t// 3 9\n    }\n}\n```\n\n## 工厂模式\n1. Map的value可以是一个**方法**\n2. 与Go的**Dock type**接口方式一起，可以方便地实现**单一方法对象的工厂模式**\n3. 在Go语言，_**函数是一等公民**_\n\n```go\nfunc TestMapWithFunValue(t *testing.T) {\n    m := map[int]func(op int) int{}\n    m[1] = func(op int) int { return op }\n    m[2] = func(op int) int { return op * op }\n    m[3] = func(op int) int { return op * op * op }\n    t.Log(m[1](2), m[2](2), m[3](2)) // 2 4 8\n}\n```\n\n## 实现Set\n1. **Go的内置集合没有Set实现**，可以使用**map[type]bool**\n2. 元素的**唯一性**\n3. 基本操作：添加元素、判断元素是否存在、删除元素、元素个数\n\n```go\nfunc TestMapForSet(t *testing.T) {\n    mySet := map[int]bool{}\n    n := 1\n    mySet[n] = true\n    if mySet[n] {\n    \tt.Logf(\"%d is exists\", n) // 1 is exists\n    } else {\n    \tt.Logf(\"%d is not exists\", n)\n    }\n\n    mySet[2] = true\n    t.Log(len(mySet)) // 2\n\n    delete(mySet, 1)\n    if mySet[n] {\n    \tt.Logf(\"%d is exists\", n)\n    } else {\n    \tt.Logf(\"%d is not exists\", n) // 1 is not exists\n    }\n}\n```\n","tags":["Go"],"categories":["Go"]},{"title":"Go -- 数组 + 切片","url":"%2F2019%2F06%2F10%2Fgo-array-slice%2F","content":"\n## 数组\n\n### 声明\n```go\nfunc TestArrayInit(t *testing.T) {\n    var a [3]int // 声明并初始化为默认零值\n    t.Log(a)     // [0 0 0]\n    a[0] = 1\n    t.Log(a) // [1 0 0]\n\n    b := [3]int{1, 2, 3}           // 声明并初始化\n    c := [2][2]int{{1, 2}, {3, 4}} // 多维数组初始化\n    t.Log(a, b, c)                 // [1 0 0] [1 2 3] [[1 2] [3 4]]\n\n    d := [...]int{1, 2, 3, 4, 5} // 使用...，不用指定初始化数组的长度\n    t.Log(len(d), d[2])          // 5 3\n}\n```\n\n<!-- more -->\n\n### 遍历\n```go\nfunc TestArrayTravel(t *testing.T) {\n    a := [...]int{1, 2, 3, 4, 5}\n\n    // 不推荐\n    for i := 0; i < len(a); i++ {\n    \tt.Log(a[i])\n    }\n\n    // foreach\n    for index, item := range a {\n    \t// index为索引，item为元素值\n    \tt.Log(index, item)\n    }\n\n    // foreach\n    for _, item := range a {\n    \t// Go是有严格编程约束的语言，_是占位符，表示不关心这个值\n    \tt.Log(item)\n    }\n}\n```\n\n### 截取\n```go\nfunc TestArraySection(t *testing.T) {\n    // [包含，不包含]\n    // 不支持负数索引\n    a := [...]int{1, 2, 3, 4, 5}\n    a_sec := a[:3]      // [1 2 3]\n    a_sec = a[3:]       // [4 5]\n    a_sec = a[2:len(a)] // [3 4 5]\n    //a_sec = a[-1]       // invalid array index -1 (index must be non-negative)\n    t.Log(a_sec)\n}\n```\n\n## 切片\n\n### 内部结构\n<img src=\"https://go-1253868755.cos.ap-guangzhou.myqcloud.com/go-slice-internal-structure.png\" width=1000/>\n\n### 初始化\n```go\nfunc TestSliceInit(t *testing.T) {\n    // 与数组声明非常类似，但没有指定长度，切片是可变长的\n    var s0 []int\n    t.Log(len(s0), cap(s0)) // 0 0\n\n    s0 = append(s0, 1)\n    t.Log(len(s0), cap(s0)) // 1 1\n\n    s1 := []int{1, 2, 3, 4}\n    t.Log(len(s1), cap(s1)) // 4 4\n\n    s2 := make([]int, 3, 5)\n    t.Log(len(s2), cap(s2))    // 3 5\n    t.Log(s2[0], s2[1], s2[2]) // 0 0 0\n    //t.Log(s2[0], s2[1], s2[2], s2[3]) // panic: runtime error: index out of range\n    s2 = append(s2, 1)\n    t.Log(s2[0], s2[1], s2[2], s2[3]) // 0 0 0 1\n    t.Log(len(s2), cap(s2))           // 4 5\n}\n```\n\n### 增长\n```go\nfunc TestSliceGrowing(t *testing.T) {\n    s := []int{}\n    for i := 0; i < 10; i++ {\n    \ts = append(s, i)\n    \tt.Log(len(s), cap(s))\n    \t// 1 1\n    \t// 2 2\n    \t// 3 4\n    \t// 4 4\n    \t// 5 8\n    \t// 6 8\n    \t// 7 8\n    \t// 8 8\n    \t// 9 16\n    \t// 10 16\n    }\n}\n```\n\n### 共享存储结构\n<img src=\"https://go-1253868755.cos.ap-guangzhou.myqcloud.com/go-slice-share-structure.png\" width=800/>\n\n```go\nfunc TestSliceShareMemory(t *testing.T) {\n    months := []string{\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"}\n\n    Q2 := months[3:6]\n    t.Log(Q2, len(Q2), cap(Q2)) // [Apr May Jun] 3 9\n\n    summer := months[5:8]\n    t.Log(len(summer), cap(summer)) // 3 7\n    summer[0] = \"unknown\"\n    t.Log(Q2)     // [Apr May unknown]\n    t.Log(months) // [Jan Feb Mar Apr May unknown Jul Aug Sep Oct Nov Dec]\n}\n```\n\n## 对比\n1. 容量是否**可伸缩**，切片是可伸缩的\n2. 是否可以进行**比较**，数组可以用==比较\n\n```go\nfunc TestSliceComparing(t *testing.T) {\n    s1 := []int{1, 2, 3, 4}\n    s2 := []int{1, 2, 3, 4}\n    t.Log(s1 == s2) // invalid operation: s1 == s2 (slice can only be compared to nil)\n}\n```\n","tags":["Go"],"categories":["Go"]},{"title":"Java性能 -- 字符串","url":"%2F2019%2F06%2F09%2Fjava-performance-string%2F","content":"\n## 实现\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-string-impl.jpg\" width=1000/>\n\n<!-- more -->\n\n1. 在Java 6以及之前的版本中，String对象是对char数组进行了封装实现的对象\n    - 主要四个成员变量：char数组、偏移量offset、字符数量count、哈希值hash\n    - String对象通过offset和count两个属性来定位char数组，获取字符串\n        - 这样可以高效快速地共享数组对象，同时节省内存空间，但也有可能会导致**内存泄露**\n2. Java 7/8，String类中不再有offset和count两个变量\n    - 这样String对象占用的内存稍微少了一点\n    - 另外，String.substring不再共享char[]，从而解决了使用该方法可能导致的内存泄露问题\n3. 从Java 9开始，将char[]修改为byte[]，同时维护了一个新的属性coder，它是一个**编码格式**的标识\n    - 一个char字符占用16位，2个字节，用一个char去存储**单字节编码**的字符会非常浪费\n    - Java 9的String类为了节约内存空间，使用了占用8位，1个字节的byte数组来存放字符串\n    - coder的作用：使用length()或者indexOf()\n        - coder有两个默认值：0代表LATIN1，1代表UTF16\n\n## 不可变性\n1. String是final类，char[]也是被private final修饰，这样实现了String对象的**不可变性**\n2. 好处\n    - 保证了String对象的**安全性**\n    - 保证了**hash属性不会频繁变更**，确保了唯一性，使得HashMap等容器得以实现相应的Key-Value缓存功能\n    - 可以实现**字符串常量池**\n\n## 创建字符串对象\n\n### 字面值\n1. `String s = \"abc\";`\n2. JVM首先会检查该对象是否在字符串常量池中，如果在，就返回该对象引用，否则新的字符串将在常量池中被创建\n3. 这种方式可以减少同一个值的字符串对象被重复创建，**节约内存**\n\n### new\n1. `String s = new String(\"abc\");`\n2. 首先，在**编译**类文件时，`\"abc\"`常量字符串将会放入到**常量结构**中，在**类加载**时，`\"abc\"`将会在**常量池**中创建\n3. 其次，在调用new时，JVM会调用String的构造函数，同时将引用常量池中的`\"abc\"`字符串，在**堆内存**中创建一个String对象\n4. 最后，s将引用刚刚创建的String对象\n\n## 优化\n\n### 拼接\n1. `String s = \"ab\" + \"cd\" + \"ef\";`\n    - 编译器优化：`String s = \"ab\" + \"cd\" + \"ef\";`\n2. `String s = \"abcdef\"; for ( int i = 0; i < 1000 ; i++ ) { str = str +  i; }`\n    - 编译器优化：采用**StringBuilder**进行字符串拼接\n    - 但每次循环都会生成一个新的StringBuilder实例，同样也会降低系统性能\n    - 因此做字符串拼接时，最好**显式**使用StringBuilder\n\n### intern\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-string-memory.jpg\" width=1000/>\n\n1. 在**字符串常量**中，默认会将对象放入到**常量池**中\n2. 在**字符串变量**中，对象是会创建在**堆内存**中，同时也会在**常量池**中创建一个字符串对象\n    - 并将常量池中字符串对象的char[]引用赋值给堆内存对象中，并返回堆内存对象引用\n3. 如果调用intern方法，会去查看字符串常量池中是否有等于该对象的字符串\n    - 如果没有，就在常量池中新增该对象，并返回该对象引用\n    - 如果有，就返回常量池中的字符串对象引用\n    - 而堆内存中原有的对象由于没有引用指向它，将会被回收掉\n4. 常量池的实现类似于一个**HashTable**，存量的数据越多，遍历的时间复杂度会增加\n\n\n```java\n// 1. 在类加载时，在常量池中创建一个字符串对象“abc”\n// 2. 创建a变量时，会在堆内存中创建一个字符串对象，该对象的char[]引用会指向常量池中的字符串对象的char[]\n//      在调用intern方法之后，会去常量池中查找是否有等于该字符串的对象，这里是有的，直接返回，刚创建的堆对象会被回收\n// 3. 创建b变量的逻辑类似\nString a = new String(\"abc\").intern();\nString b = new String(\"abc\").intern();\nSystem.out.println(a == b); // true\n```\n\n```java\nString s1 = \"abc\"; // 常量池\nString s2 = new String(\"abc\"); // 堆内存\nString s3 = s2.intern(); // 常量池\nSystem.out.println(s1 == s2); // false\nSystem.out.println(s2 == s3); // false\nSystem.out.println(s1 == s3); // true\n```\n\n### split\n1. split使用正则表达式实现了强大的分割功能，但_**正在表达式的性能非常不稳定**_\n    - 使用不恰当会引起**回溯**问题，导致CPU居高不下\n2. 所以应该谨慎使用split方法，可以考虑用indexOf来替代\n","tags":["Java Performance"],"categories":["Performance"]},{"title":"Java并发 -- 协程","url":"%2F2019%2F06%2F08%2Fjava-concurrent-coroutine%2F","content":"\n## 协程\n1. 协程可以理解为一种**轻量级的线程**\n2. 从操作系统的角度来看，线程是在**内核态**中调度的，而**协程**是在**用户态**调度的，协程的切换成本更低\n3. 协程栈比线程栈要小得多，典型的线程栈在1M左右，而协程栈一般在几K或者几十K左右\n4. 因此无论在时间维度还是在空间维度，协程都比线程轻量很多\n5. 支持协程的语言：Go、Python、Lua、Kotlin\n    - Java OpenSDK的Loom项目的目标是为了支持协程\n\n<!-- more -->\n\n## Go中的协程\n```go\nfunc hello(msg string) {\n    fmt.Println(\"Hello \" + msg)\n}\n\nfunc TestCoroutine(t *testing.T) {\n    // 在新的协程中执行hello方法\n    go hello(\"Go\")\n    // 等待100毫秒让协程执行结束\n    time.Sleep(100 * time.Millisecond)\n}\n```\n1. Java中的线程是一个重量级对象，因此无法很好地实现Thread-Per-Message模式，而协程可以\n2. Thread-Per-Message模式非常简单，模式越简单，功能就越稳定，可理解性也越好\n\n### echo程序\n```go\nimport (\n    \"log\"\n    \"net\"\n)\n\n// 使用Thread-Per-Message模式，为每个成功建立连接的Socket分配一个协程\n// 相对于Java线程池的实现方案，Go协程的方案更简单\nfunc main() {\n    // 监听本地9090端口\n    socket, err := net.Listen(\"tcp\", \"127.0.0.1:9090\")\n    if err != nil {\n    \tlog.Panicln(err)\n    }\n    defer socket.Close()\n    for {\n    \t// 处理连接请求\n    \tconn, err := socket.Accept()\n    \tif err != nil {\n            log.Panicln(err)\n    \t}\n    \t// 处理已经成功连接的请求\n    \tgo handleRqeust(conn)\n    }\n}\n\n// 处理已经成功连接的请求\nfunc handleRqeust(conn net.Conn) {\n    defer conn.Close()\n    for {\n    \tbuf := make([]byte, 1024)\n    \t// 读取请求数据\n    \tsize, err := conn.Read(buf)\n    \tif err != nil {\n            return\n    \t}\n    \t// 回写读取到的数据\n    \t_, _ = conn.Write(buf[:size])\n    }\n}\n```\n","tags":["Coroutine"],"categories":["Concurrent"]},{"title":"Go -- 基本程序结构","url":"%2F2019%2F06%2F07%2Fgo-basic-program-structure%2F","content":"\n## 单元测试\n1. 源代码以_test结尾：xxx_test.go\n2. 测试方法名以Test开头：`func TestXxx(t *testing.T) {}`，大写的方法表示**包外**可以访问\n\n```go\n// first_test.go\npackage try_test\n\nimport \"testing\"\n\nfunc TestFirstTry(t *testing.T) {\n    t.Log(\"My First try!\")\n}\n```\n\n<!-- more -->\n\n## 变量 + 常量\n\n### 变量\n```go\n// fib_test.go\npackage fib\n\nimport (\n    \"fmt\"\n    \"testing\"\n)\n\n// var一般用于全局变量或者外部变量\nvar g = 1\n\nfunc TestFibList(t *testing.T) {\n    g = 2\n\n    // 第1种方式\n    //var a int = 1\n    //var b int = 1\n\n    // 第2种方式，具有一定的类型推断能力\n    //var a = 1\n    //var b = 2\n\n    // 第3种方式\n    //var (\n    //\ta = 1\n    //\tb = 2\n    //)\n\n    // 第4种方式\n    a := 1\n    b := 2\n\n    t.Log(a)\n    for i := 0; i < 5; i++ {\n    \tt.Log(b)\n    \ttmp := a\n    \ta = b\n    \tb = tmp + a\n    }\n    fmt.Println()\n}\n\nfunc TestExchange(t *testing.T) {\n    a := 1\n    b := 2\n    // 同时赋值\n    a, b = b, a\n    t.Log(a, b)\n}\n```\n1. 赋值可以进行**自动类型推断**\n2. 在一个赋值语句中可以对多个变量进行**同时赋值**\n\n### 常量\n```go\n// constant_test.go\npackage constant\n\nimport \"testing\"\n\n// 快速设置连续值\nconst (\n    // const iota int = 0\n    Monday = iota + 1\n    Tuesday\n    Wednesday\n    Thursday\n    Friday\n    Saturday\n    Sunday\n)\n\nconst (\n    Readable   = 1 << iota // 0001\n    Writable               // 0010\n    Executable             // 0100\n)\n\nfunc TestConstant1(t *testing.T) {\n    t.Log(Monday, Tuesday) // 1,2\n}\n\nfunc TestConstant2(t *testing.T) {\n    a := 1 // 0001\n    // & 按位与\n    t.Log(a&Readable == Readable, a&Writable == Writable, a&Executable == Executable) // true,false,false\n}\n```\n\n## 数据类型\n\n### 基本数据类型\n1. bool\n2. string\n3. int int8 int16 int32 int64\n4. uint uint8 uint16 uint32 uint64 uintptr\n5. byte // alias for uint8\n6. rune // alias for uint32, represents a Unicode code point\n7. float32 float64\n8. complex64 complex128\n\n### 类型转换\n1. Go语言_**不允许隐式类型转换**_\n2. 别名和原有类型也不能进行隐式类型转换\n\n```go\n// 别名\ntype MyInt int64\n\nfunc TestImplicit1(t *testing.T) {\n    var a1 int = 1 // 64位机器，int占用64位\n    var a2 int32 = 1\n    var b int64\n    b = a1 // cannot use a1 (type int) as type int64 in assignment\n    b = a2 // cannot use a2 (type int32) as type int64 in assignment\n}\n\nfunc TestImplicit2(t *testing.T) {\n    var a int32 = 1\n    var b int64\n    b = int64(a) // 显式类型转换\n    var c MyInt\n    c = b        // cannot use b (type int64) as type MyInt in assignment\n    c = MyInt(b) // 显式类型转换\n    t.Log(a, b, c)\n}\n```\n\n### 类型的预定义值\n1. math.MaxInt64\n2. math.MaxFloat64\n3. math.MaxUint32\n\n### 指针类型\nGO语言_**不支持指针运算**_\n```go\nfunc TestPoint(t *testing.T) {\n    a := 1\n    aPtr := &a\n    t.Log(a, aPtr)           // 1 0xc00001a210\n    t.Logf(\"%T %T\", a, aPtr) // int *int\n    aPtr = aPtr + 1          // invalid operation: aPtr + 1 (mismatched types *int and int)\n}\n```\n\n### 字符串\n1. 在大多数编程语言中（例如Java），字符串是**引用类型**或**指针类型**\n2. 而在Go语言中，string是**值类型**，默认的初始化值为**空字符串**，而不是nil\n\n```go\nfunc TestString(t *testing.T) {\n    var s string\n    t.Log(\"*\" + s + \"*\") // **\n    t.Log(len(s))        // 0\n    t.Log(s == \"\")       // true\n}\n```\n\n## 运算符\n\n### 算术运算符\nA=10,B=20，Go语言没有前置的++，\\-\\-\n\n| 运算符 | 描述 | 实例 |\n| ---- | ---- | ---- |\n| + | 相加 | A+B => 30 |\n| - | 相减 | A-B => -20 |\n| * | 相乘 | A*B => 200 |\n| / | 相除 | A/B => 2 |\n| % | 求余 | A%B => 0 |\n| ++ | 自增 | A++ => 11 |\n| \\-\\- | 自减 | A\\-\\- => 9 |\n\n### 比较运算符\nA=10,B=20\n\n| 运算符 | 描述 | 实例 |\n| ---- | ---- | ---- |\n| == | 检查左边值是否**等于**右边值，若是返回True，否则返回False | (A == B) => False |\n| != | 检查左边值是否**不等于**右边值，若是返回True，否则返回False | (A != B) => True |\n| > | 检查左边值是否**大于**右边值，若是返回True，否则返回False | (A > B) => False |\n| < | 检查左边值是否**小于**右边值，若是返回True，否则返回False | (A < B) => True |\n| >= | 检查左边值是否**大于等于**右边值，若是返回True，否则返回False | (A >= B) => False |\n| <= | 检查左边值是否**小于等于**右边值，若是返回True，否则返回False | (A <= B) => True |\n\n#### 数组\n1. 相同维数且含有相同个数元素的数组才可以比较\n2. 每个元素都相同才相等\n\n```go\nfunc TestCompareArray(t *testing.T) {\n    a := [...]int{1, 2, 3, 4}\n    b := [...]int{1, 4, 2, 3}\n    c := [...]int{1, 2, 3, 4, 5}\n    d := [...]int{1, 2, 3, 4}\n    t.Log(a == b) // false\n    t.Log(a == c) // invalid operation: a == c (mismatched types [4]int and [5]int)\n    t.Log(a == d) // true\n}\n```\n\n### 逻辑运算符\nA=true,B=false\n\n| 运算符 | 描述 | 实例 |\n| ---- | ---- | ---- |\n| && | 逻辑AND运算符 | (A && B) => False |\n| \\|\\| | 逻辑OR运算符 | (A \\|\\| B) => True |\n| ! | 逻辑NOT运算符 | !(A && B) => True |\n\n### 位运算符\n\n| 运算符 | 描述 |\n| ---- | ---- |\n| & | 按位与运算符 |\n| \\| | 按位或运算符 |\n| ^ | 按位异或运算符 |\n| << | 左移运算符 |\n| >> | 右移运算符 |\n\n#### 按位置零&^\n1. &^：右边操作数的二进制为1的位会把左边操作数的对应的二进制位**重置为0**\n2. 在其他编程语言中（如Java），需要组合多个位运算符才能完成\n\n```go\nconst (\n    Readable   = 1 << iota // 0001\n    Writable               // 0010\n    Executable             // 0100\n)\n\nfunc TestBitClear(t *testing.T) {\n    a := 7                                                                            // 0111 = Readable + Writable + Executable\n    t.Log(a&Readable == Readable, a&Writable == Writable, a&Executable == Executable) // true true true\n    a = a &^ Readable                                                                 // 清空Readable\n    t.Log(a&Readable == Readable)                                                     // false\n    a = a &^ Writable                                                                 // 清空Writable\n    t.Log(a&Writable == Writable)                                                     // false\n    a = a &^ Executable                                                               // 清空Executable\n    t.Log(a&Executable == Executable)                                                 // false\n}\n```\n\n## 循环 + 条件\n\n### 循环\nGo语言仅支持循环关键字for\n```go\nfunc TestWhileLoop(t *testing.T) {\n    n := 0\n    // while(n<5)\n    for n < 5 {\n    \tt.Log(n)\n    \tn++\n    }\n\n    // while(true)\n    for {\n    \tt.Log(n)\n    \tn++\n    }\n}\n```\n\n### 条件\n\n#### if\n1. condition表达式结果必须为布尔值\n2. 支持**变量赋值**\n\n```go\nfunc TestIfMultiSec(t *testing.T) {\n    if a := 1 == 1; a {\n    \tt.Log(\"1==1\")\n    }\n}\n```\n\n#### switch\n1. 条件表达式不限制为**常量**或者**整数**\n2. 单个case中，可以出现**多个结果选项**，使用逗号分隔\n3. 与C语言等规则相反，Go语言不需要用**break**来明确退出一个case\n4. 可以不设定switch之后的条件表达式，此时整个switch结构与多个if/else的逻辑作用等同\n\n```go\nfunc TestSwitchMultiCase(t *testing.T) {\n    for i := 0; i < 5; i++ {\n    \tswitch i {\n    \tcase 0, 2: // 多个结果选项\n            t.Log(\"Even\")\n    \tcase 1, 3:\n            t.Log(\"Odd\")\n    \tdefault:\n            t.Log(\"Not 0~3\")\n    \t}\n    }\n}\n\nfunc TestSwitchCondition(t *testing.T) {\n    for i := 0; i < 5; i++ {\n    \tswitch {\n    \tcase i%2 == 0:\n            t.Log(\"Even\")\n    \tcase i%2 == 1:\n            t.Log(\"Odd\")\n    \tdefault:\n            t.Log(\"Unknown\")\n    \t}\n    }\n}\n```\n","tags":["Go"],"categories":["Go"]},{"title":"Java并发 -- 软件事务内存","url":"%2F2019%2F06%2F06%2Fjava-concurrent-stm%2F","content":"\n## STM\n1. STM：Software Transactional Memory，软件事务内存，借鉴于数据库的事务管理\n2. 传统的数据库事务支持**ACID**，即原子性（A）、一致性（C）、隔离性（I）和持久性（D）\n3. STM不支持持久化，即只支持ACI\n\n<!-- more -->\n\n## 数据库事务\n数据库保证在并发情况下不会发生死锁，而且还能保证ACID\n```java\nConnection conn = null;\ntry{\n    // 获取数据库连接\n    conn = DriverManager.getConnection();\n    // 设置手动提交事务\n    conn.setAutoCommit(false);\n    // 执行转账SQL\n    ...\n    // 提交事务\n    conn.commit();\n} catch (Exception e) {\n    // 出现异常回滚事务\n    conn.rollback();\n}\n```\n\n## synchronized转账\n```java\n@AllArgsConstructor\npublic class UnsafeAccount {\n    private long balance;\n\n    // 转账，存在死锁问题\n    public void transfer(UnsafeAccount to, long amt) {\n        synchronized (this) {\n            synchronized (to) {\n                if (this.balance > amt) {\n                    this.balance -= amt;\n                    to.balance += amt;\n                }\n            }\n        }\n    }\n}\n```\n\n## STM转账\nJava语言并不支持STM，可以借助第三方类库来Multiverse实现\n```java\npublic class Account {\n    // 余额\n    private TxnLong balance;\n\n    public Account(long balance) {\n        this.balance = StmUtils.newTxnLong(balance);\n    }\n\n    // 转账\n    public void transfer(Account to, int amt) {\n        // 原子化操作\n        StmUtils.atomic(() -> {\n            if (this.balance.get() > amt) {\n                this.balance.decrement(amt);\n                to.balance.increment(amt);\n            }\n        });\n    }\n}\n```\n\n### MVCC\n1. MVCC可以简单地理解为数据库事务在开始的时候，给数据库打一个**快照**，以后所有的读写都是基于这个快照\n2. 当提交事务的时候，如果所有读写过的数据在该事务执行期间没有发生过变化，那么可以提交\n3. 如果发生了变化，说明该事务与其他事务读写的数据冲突了，那就不能提交了\n4. 为了记录数据是否发生了变化，可以给每条数据增加一个版本号，每次成功修改数据都会增加版本号的值\n5. 不少STM的实现方案都是基于MVCC，例如Clojure STM\n\n## 小结\n1. STM借鉴的是数据库的经验，数据库仅仅存储数据，而编程语言除了共享变量之外，还会执行各种IO操作（很难支持回滚）\n2. 因此，STM不是万能的，目前支持STM的编程语言主要是**函数式语言**，因为函数式语言里的数据天生具备**不可变性**\n","tags":["MVCC"],"categories":["Concurrent"]},{"title":"Java性能 -- 性能调优策略","url":"%2F2019%2F06%2F05%2Fjava-performance-opt-strategy%2F","content":"\n## 性能测试\n\n### 测试方法\n1. 微基准性能测试\n    - 可以精准定位到某个模块或者某个方法的性能问题，例如对比一个方法使用同步实现和非同步实现的性能差异\n2. 宏基准性能测试\n    - 宏基准性能测试是一个**综合测试**，需要考虑到**测试环境、测试场景和测试目标**\n    - 测试环境：模拟线上的真实环境\n    - 测试场景：在测试某个接口时，是否有其他业务的接口也在平行运行，进而造成干扰\n    - 测试目标\n        - 可以通过**吞吐量**和**响应时间**来衡量系统是否达标，如果不达标，就需要进行优化\n        - 如果达标，就继续加大测试的并发数，探底接口的TPS\n        - 除了关注接口的吞吐量和响应时间外，还需要关注**CPU、内存和IO**的使用率情况\n\n<!-- more -->\n\n### 干扰因素\n\n#### 热身问题\n1. 在Java编程语言和环境中，.java文件编译成.class文件后，需要通过解析器将字节码转换成本地机器码才能运行\n2. 为了节约内存和执行效率，代码在最初被执行时，解析器会率先**解析执行**这段代码\n3. 随着代码被执行的次数增加，当JVM发现某个方法或代码块运行得很频繁时，就会把这些代码认定为**热点代码**\n    - 为了提高热点代码的执行效率，在运行时，JVM将通过**即时编译器**（JIT）把这些代码编译成与本地平台相关的**机器码**\n    - 并进行各层次的优化，然后存储在内存中，之后每次运行代码时，直接从内存中获取\n4. 因此在刚开始运行的阶段，JVM会花费很长的时间来全面优化代码，后面就能以最高性能运行了\n\n#### 测试结果不稳定\n1. 不稳定因素：机器其他进程的影响、网络波动、JVM GC的不确定性\n2. 解决方案：通过**多次测试**，将测试结果求平均，只要能保证平均值在一个合理的范围之内，并且波动不大即可\n\n#### 多JVM\n1. 任意一个JVM都拥有**整个系统**的资源使用权\n2. 如果一台机器上只部署单独的一个JVM，在做性能测试时，测试结果会很好，但一台机器上有多个JVM，则不一定\n3. 尽量避免线程环境一台机器部署多个JVM\n\n## 性能分析\n1. 完成性能测试之后，需要输出一份性能测试报告，测试结果需要包括\n    - 测试接口的吞吐量和响应时间（平均、最大、最小）\n    - 服务器的CPU、内存、磁盘IO、网络IO使用率、JVM的GC情况\n2. 通过观察性能指标，可以发现性能瓶颈，再通过自下而上的方式分析查找问题\n    - 首先从操作系统层面，查看系统的CPU、内存、磁盘IO、网络IO的使用率是否存在异常\n    - 再通过命令查找异常日志，通过分析日志，寻找导致性能瓶颈的原因\n    - 还可以从Java应用的JVM层面下手，查看JVM的GC频率以及内存分配情况是否存在异常\n    - 如果系统和JVM层面都没有出现异常情况，可以查看应用服务业务层是否存在性能瓶颈\n        - 例如Java编程的问题、读写数据瓶颈\n3. 分析查找性能问题可以采用**自下而上**的方式，而解决性能问题，一般采用**自上而下**的方式**逐级优化**\n\n## 性能调优\n思路：_**业务调优 -> 编程调优 -> 系统调优**_\n\n### 优化代码\n1. 应用层的问题代码往往会因为**耗尽系统资源**而暴露出来\n2. 例如某段代码导致内存溢出，这往往是将JVM的内存耗尽了\n    - 这会引发JVM频繁地发生GC，导致CPU居高不下，此时也会耗尽系统的CPU资源\n3. 还有一些非问题代码导致的性能问题，比较难以发现\n    - 例如如果对LinkedList进行for循环遍历，每次循环获取元素时，都会**遍历**一次list，读效率很低\n    - 优化方案：可以采用Iterator\n\n### 优化设计\n1. 面向对象有很多设计模式，可以用于优化业务层以及中间件层的代码设计，进而达到精简代码和提高整体性能的目的\n2. 例如单例模式在频繁创建对象的场景中，可以共享一个对象，减少频繁创建和销毁对象带来的性能开销\n\n### 优化算法\n1. 合适的算法可以大大提升系统性能\n2. 例如在不同的场景中，使用合适的查找算法可以降低时间复杂度\n\n### 时间换空间\n1. 如果系统对查询的速度没有很高的要求，但对存储空间要求苛刻，可以考虑用时间换空间\n2. 例如String的intern方法，可以将重复率比较高的数据存储在常量池，重复使用相同的对象，大大节省内存空间\n    - 但由于常量池使用的是HashMap类型，如果存储数据过多，就会导致查询性能下降\n\n### 空间换时间\n1. 使用存储空间来提升访问速度\n2. 例如MySQL的分库分表\n\n### 参数调优\n1. 根据业务场景，合理地设置JVM的内存空间和GC算法\n2. 另外，合理地设置Web容器的线程池大小和Linux操作系统的内核参数\n\n## 兜底策略\n1. 性能优化策略，主要为了提高系统性能，而兜底策略，主要为了确保系统的**稳定性**\n2. **限流**\n    - 对系统的入口设置最大访问限制，参考性能测试中探底的接口TPS\n    - 同时采用**熔断**措施，友好地返回没有成功的请求\n3. **智能横向扩容**\n    - 当访问量超过某一个阈值时，系统可以根据需求**自动**横向扩容\n4. **提前扩容**\n    - 常用于**高并发**系统，例如瞬时抢购\n    - 此时智能横向扩容无法满足大量发生在瞬间的请求\n5. Kubernetes可以实现智能横向扩容和提前扩容Docker服务\n\n## 小结\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-opt-strategy.jpg\" width=1000/>\n","tags":["Java Performance"],"categories":["Performance"]},{"title":"Java并发 -- Actor模型","url":"%2F2019%2F06%2F04%2Fjava-concurrent-actor%2F","content":"\n## Actor模型\n1. Actor模型在本质上是一种**计算模型**，基本的计算单元称为Actor，在Actor模型中，所有的计算都在Actor中执行\n2. 在面向对象编程里，一切都是对象，在Actor模型里，**一切都是Actor**，并且Actor之间是**完全隔离**的，不会共享任何变量\n3. Java本身并不支持Actor模型，如果需要在Java里使用Actor模型，需要借助第三方类库，比较完备的是**Akka**\n\n<!-- more -->\n\n## Hello Actor\n```java\npublic class HelloActor extends UntypedAbstractActor {\n    // 该Actor在收到消息message后，会打印Hello message\n    @Override\n    public void onReceive(Object message) throws Throwable {\n        System.out.printf(\"Hello %s%n\", message);\n    }\n\n    public static void main(String[] args) {\n        // 创建Actor系统，Actor不能脱离ActorSystem存在\n        ActorSystem system = ActorSystem.create(\"HelloSystem\");\n        // 创建HelloActor\n        ActorRef actorRef = system.actorOf(Props.create(HelloActor.class));\n        // 发送消息给HelloActor\n        actorRef.tell(\"Actor\", ActorRef.noSender());\n    }\n}\n```\n\n## 消息 VS 对象方法\n1. Actor模型是**完全异步**的，而对象方法调用是**同步**的\n    - Actor内部的工作模式可类比成_**只有一个消费者线程的生产者-消费者模式**_\n    - 在Actor模型中，发送消息仅仅是把消息发生出去而已，接收消息的Actor在接收到消息后，也不会立马处理\n2. 并发计算 + **分布式计算**\n    - 调用对象方法，需要持有对象的引用，并且所有的对象都必须在同一个进程中\n    - 在Actor中发送消息，只需要知道对方的地址即可\n        - 发送消息和接收消息的Actor可以不在一个进程中，也可以不在同一台机器上\n        - 因此Actor模型不但适用于并发计算，也适用于分布式计算\n\n## Actor的规范定义\n1. Actor是一种**基础的计算单元**，具体来讲包括三部分能力\n    - **处理能力**：处理接收到的消息\n    - **存储能力**：Actor可以存储自己的内部状态，并且内部状态在不同Actor之间是绝对隔绝的\n    - **通信能力**：Actor可以和其它Actor之间通信\n2. 当一个Actor接收到一条消息后，该Actor可以执行三种操作\n    - 创建更多的Actor\n        - 最终会呈现出一个**树状**结构\n    - 发消息给其它Actor\n    - 确定如何处理**下一条**消息\n        - Actor具备存储能力，有自己的内部状态，可以将Actor看作一个_**状态机**_\n        - 可以把Actor处理消息看作触发状态机的状态变化\n        - 在Actor模型里，由于是**单线程**处理的，所以在确定下一条消息如何处理是**不存在竟态条件问题**的\n\n## 累加器\n```java\npublic class CounterActor extends UntypedAbstractActor {\n    private int counter = 0;\n\n    @Override\n    public void onReceive(Object message) throws Throwable {\n        if (message instanceof Number) {\n            counter += ((Number) message).intValue();\n        } else {\n            System.out.println(counter);\n        }\n    }\n\n    // 没有锁，也没有CAS，但程序是线程安全的\n    public static void main(String[] args) throws InterruptedException {\n        ActorSystem system = ActorSystem.create(\"CounterSystem\");\n        ExecutorService pool = Executors.newFixedThreadPool(4);\n        ActorRef actorRef = system.actorOf(Props.create(CounterActor.class));\n        // 生成4*100_000个消息\n        for (int i = 0; i < 4; i++) {\n            pool.execute(() -> {\n                for (int j = 0; j < 100_000; j++) {\n                    actorRef.tell(1, ActorRef.noSender());\n                }\n            });\n        }\n        pool.shutdown();\n        // 等待actorRef处理完所有消息\n        TimeUnit.SECONDS.sleep(5);\n        // 打印结果\n        actorRef.tell(\"\", ActorRef.noSender()); // 400_000\n    }\n}\n```\n\n## 小结\n1. Actor模型是**异步**模型\n    - 不保证消息百分百送达\n    - 不保证消息送达的顺序与发送的顺序是一致的\n    - 不保证消息会被百分百处理\n2. 实现Actor模型的厂商都在尝试解决上面三个问题，但解决得并不完美，所以使用Actor模型是有**成本**的\n","tags":["Akka"],"categories":["Concurrent"]},{"title":"Go -- 语言简介","url":"%2F2019%2F06%2F03%2Fgo-introduction%2F","content":"\n## 诞生背景\n1. 多核硬件架构\n2. 超大规模分布式计算集群\n3. Web模式导致的前所未有的开发规模和更新速度\n\n<!-- more -->\n\n## 创始人\n1. Rob Pike：Unix早期开发者、UTF-8创始人\n2. Ken Thompson：Unix创始人、C语言创始人、1983年获图灵奖\n3. Robert Griesemer：Google V8 Js Engine、Hot Spot开发者\n\n## 特点\n1. 简单：C 37关键字、C++ 84关键字、Go 25个关键字\n2. 高效：垃圾回收、支持指针\n3. 生产力：复合（不支持继承）\n4. 云计算语言：Docker、Kubernetes\n5. 区块链语言：Ethereum、Hyperledger\n\n## Hello Go\n从Go 1.8开始，GOPATH默认为$HOME/go\n```golang\n// /src/ch1/hello/hello_world.go\npackage main // 包\n\nimport ( // 代码依赖\n    \"fmt\"\n    \"os\"\n)\n\n// 程序入口\n//  1. 必须是main包：package main\n//  2. 必须是main方法：func main()\n//  3. 文件名不一定是main.go\n// main函数不支持传入参数，通过os.Args获取命令行参数\nfunc main() {\n    fmt.Println(os.Args)\n    if len(os.Args) > 1 {\n    \tfmt.Println(\"Hello World\", os.Args[1])\n    }\n    // Go中的main函数不支持任何返回值，通过os.Exit来返回状态\n    os.Exit(0)\n}\n```\n```shell\n$ go run hello_world.go zhongmingmao\n[/var/folders/gm/y_bbs_5s62zgml6rlmtb07rc0000gn/T/go-build812653812/b001/exe/hello_world zhongmingmao]\nHello World zhongmingmao\n\n$  go build hello_world.go\nhello_world    hello_world.go\n```\n","tags":["Go"],"categories":["Go"]},{"title":"Java性能 -- 性能调优标准","url":"%2F2019%2F06%2F02%2Fjava-performance-opt-std%2F","content":"\n## 性能瓶颈\n1. CPU\n    - 如果应用需要大量计算，会长时间占用CPU资源，导致其它应用因无法争夺到CPU而响应缓慢\n    - 场景：代码递归导致的无限循环，JVM频繁的Full GC、多线程编程造成的大量上下文切换\n2. 内存\n    - Java程序一般通过JVM对内存进行分配管理，主要使用JVM中的堆内存来存储Java创建的对象\n    - 但内存空间有限，当内存空间被占满，对象无法回收，会导致内存溢出，内存泄露等问题\n3. 磁盘IO\n4. 网络：带宽\n5. 异常：Java应用中，抛出异常需要构建异常栈，对异常进行捕获和处理，这个过程非常消耗系统性能\n6. 数据库：数据库的操作往往涉及到磁盘IO的读写，大量的数据库读写操作，会导致磁盘IO的性能瓶颈\n7. 锁竞争\n    - 在并发编程中，经常需要使用到多线程，并发读写同一个共享资源，为了保证数据原子性，会用到锁\n    - 锁的使用会带来上下文切换，从而给系统带来性能开销\n\n<!-- more -->\n\n## 性能指标\n\n### 响应时间\n<img src=\"https://java-performance-1253868755.cos.ap-guangzhou.myqcloud.com/java-performance-response-time.jpg\" width=1000/>\n\n1. 一个接口的响应时间一般在**毫秒级**\n2. 数据库响应时间：数据库操作所消耗的时间，往往是整个请求链中**最耗时**的\n3. 服务端响应时间：包括Nginx分发请求所消耗的时间以及服务端程序执行所消耗的时间\n4. 网络响应时间：在网络传输时，网络硬件对需要传输的请求进行解析等操作所消耗的时间\n5. 客户端响应时间：对于普通的Web、App客户端来说，该阶段的消耗时间是可以忽略不计的\n\n### 吞吐量\n1. 在测试中，比较关注**TPS**（Transactions per second）\n2. 在系统中，可以把吞吐量分为两种：**磁盘吞吐量**、**网络吞吐量**\n3. 磁盘吞吐量\n    - **IOPS**：每秒的输入输出量（或读写次数），关注的是**随机读写性能**\n        - 小文件存储、OLTP数据库、邮件服务器\n    - **数据吞吐量**：单位时间内可以成功传输的数据量，对于大量顺序读写的应用，会传输大量连续数据\n        - 视频编辑、视频点播\n4. 网络吞吐量\n    - 在网络传输没有帧丢失的情况下，设备能够接受的最大数据速率\n    - 网络吞吐量的大小主要由**网卡的处理能力、带宽大小、内部程序算法**决定\n\n### 资源使用率\nCPU占用率、内存使用率、磁盘IO、网络IO\n\n### 负载承受能力\n当系统压力上升时，系统响应时间的上升曲线是否平缓\n\n## 参考标准\n将**上一迭代版本**的性能指标作为参考标准\n","tags":["Java Performance"],"categories":["Performance"]},{"title":"网络协议 -- 物理层 + 数据链路层","url":"%2F2019%2F06%2F01%2Fnetwork-protocol-physical-data-link%2F","content":"\n## HUB\n1. HUB即集线器，有多个端口，完全工作在**物理层**\n2. HUB采用的是**广播**模式，会将自己收到的每一个字节，都**复制**到其他端口\n3. 广播模式存在问题，需要解决三个问题（在**数据链路层**解决）\n    - 数据包发给谁，由谁接收\n        - **MAC地址**\n    - 数据包谁先发，谁后发\n        - MAC子层，以太网为**随机接入协议**\n    - 如果发送时出现错误，应该怎么处理\n        - 以太网数据包的最后有**CRC校验**\n\n<!-- more -->\n\n## 数据链路层\n1. 数据链路层分成LLC（Logical Link Control）子层和MAC（Media Access Control）子层\n    - LLC子层实现数据链路层**与硬件无关**的功能，比如流量控制、差错恢复等\n    - MAC子层提供LLC子层和物理层之间的接口\n2. MAC地址解决了第一个问题：数据包发给谁，由谁接收\n3. MAC子层解决了第二个问题：数据包谁先发，谁后发的问题，学名为**多路访问**\n    - 可用方式：信道划分、轮流协议、**随机接入协议**（以太网）\n    - 这个与MAC地址没什么关系\n\n### 数据包格式\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-package-fmt-2nd.png\" width=600/>\n\n1. 开头为目标MAC地址和源MAC地址\n2. 接下来是类型，大部分的类型是IP数据包（0x0800），IP数据包里面会包含TCP、UDP、HTTP等内容（层层封装）\n3. 数据包中有目标MAC地址，数据包在链路上**广播**，目标MAC地址的网卡发现这个包是给它的，就会把数据包接收进来\n    - 然后打开数据包，发现是IP数据包，并且IP地址也是自己，再打开TCP包，发现目标端口是80，Nginx在监听80端口\n    - 于是将请求提交给Nginx，Nginx会返回一个网页，然后将网页发回请求的机器，经过层层封装，最后到了MAC层\n        - 原先的源MAC地址变成了目标MAC地址\n4. 对于以太网，数据包的最后是**CRC**（循环冗余校验，采用XOR异或算法）\n    - 计算整个数据包在发送过程中是否出现错误，这解决第三个问题\n\n## ARP协议\nARP：Address Resolution Protocol，**已知IP地址，求MAC地址**\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-arp-1.png\" width=700/>\n\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-arp-2.png\" width=700/>\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-arp-fmt.png\" width=700/>\n勘误：0x8086 -> 0x0806\n\n## 交换机\n1. 交换机是**二层设备**，工作在**数据链路层**\n2. 学习过程\n    - 交换机有4个口，分别是A、B、C、D，有两台机器，MAC地址为MAC1和MAC2，MAC1连着A口，MAC2连着B口\n    - MAC1机器将数据包发送给MAC2机器，当数据包到达交换机的时候，并不知道MAC2机器连着交换机的哪个端口\n        - 因此，只能将该数据包转发给B、C、D口，但是交换机会记住MAC1连着A口\n        - 以后有数据包要发送给MAC1，直接转发到A口即可\n3. 交换机学习的结果叫**转发表**，有过期时间\n\n<!-- indicate-the-source -->\n","tags":["Network Protocol"],"categories":["Protocol"]},{"title":"Java并发 -- Disruptor","url":"%2F2019%2F05%2F31%2Fjava-concurrent-disruptor%2F","content":"\n## 有界队列\n1. JUC中的有界队列ArrayBlockingQueue和LinkedBlockingQueue，都是基于**ReentrantLock**\n2. 在高并发场景下，锁的效率并不高，Disruptor是一款**性能更高**的有界内存队列\n3. Disruptor高性能的原因\n    - 内存分配更合理，使用**RingBuffer**，数组元素在初始化时**一次性**全部创建\n        - **提升缓存命中率**，对象循环利用，**避免频繁GC**\n    - 能够**避免伪共享**，提升缓存利用率\n    - 采用**无锁算法**，避免频繁加锁、解锁的性能消耗\n    - 支持**批量消费**，消费者可以以无锁的方式消费多个消息\n\n<!-- more -->\n\n## 简单使用\n```java\npublic class DisruptorExample {\n    public static void main(String[] args) throws InterruptedException {\n        // RingBuffer大小，必须是2的N次方\n        int bufferSize = 1024;\n        // 构建Disruptor\n        Disruptor<LongEvent> disruptor = new Disruptor<>(LongEvent::new, bufferSize, DaemonThreadFactory.INSTANCE);\n        // 注册事件处理器\n        disruptor.handleEventsWith((event, sequence, endOfBatch) -> System.out.println(\"E: \" + event));\n        // 启动Disruptor\n        disruptor.start();\n\n        RingBuffer<LongEvent> ringBuffer = disruptor.getRingBuffer();\n        // 生产Event\n        ByteBuffer bb = ByteBuffer.allocate(8);\n        for (long l = 0; true; l++) {\n            bb.putLong(0, l);\n            // 生产者生产消息\n            ringBuffer.publishEvent((event, sequence, buffer) -> event.setValue(buffer.getLong(0)), bb);\n            TimeUnit.SECONDS.sleep(1);\n        }\n    }\n}\n\n@Data\nclass LongEvent {\n    private long value;\n}\n```\n1. 在Disruptor中，生产者生产的对象和消费者消费的对象称为Event，使用Disruptor必须定义Event\n2. 构建Disruptor对象需要传入EventFactory（LongEvent::new）\n3. 消费Disruptor中的Event需要通过handleEventsWith方法注册一个事件处理器\n4. 发布Event需要通过publishEvent方法\n\n## 优点\n\n### RingBuffer\n\n#### 局部性原理\n1. 在一段时间内程序的执行会限定在一个局部范围内，包括时间局部性和空间局部性\n2. **时间局部性**\n    - 程序中的某条**指令**一旦被执行，不久之后这条指令很可能被再次执行\n    - 如果某条**数据**被访问，不久之后这条数据很可能被再次访问\n3. **空间局部性**\n    - 某块**内存**一旦被访问，不久之后这块内存**附近**的内存也有可能被访问\n4. CPU缓存利用了程序的局部性原理\n    - CPU从内存中加载数据X时，会将数据X及其**附近**的数据缓存在高速Cache中\n5. 如果程序能够很好地体现出局部性原理，就能更好地利用CPU缓存，从而提升程序的性能\n\n#### ArrayBlockingQueue\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-disruptor-array-blocking-queue.png\" width=800/>\n\n1. 生产者向ArrayBlockingQueue增加一个元素之前，都需要先创建对象E\n2. 创建这些元素的时间基本上是**离散**的，所以这些元素的内存地址大概率也**不是连续**的\n\n#### Disruptor\n```java\n// com.lmax.disruptor.RingBufferFields\nfor (int i = 0; i < bufferSize; i++)\n{\n    entries[BUFFER_PAD + i] = eventFactory.newInstance();\n}\n```\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-disruptor-ring-buffer.png\" width=800/>\n\n1. Disruptor内部的RingBuffer也是用数组实现的\n2. 但这个数组中的所有元素在初始化时是**一次性**全部创建，所以这些元素的内存地址大概率是**连续**的\n3. 如果数组中所有元素的内存地址是**连续**的，能够提升性能\n    - 消费者线程在消费的时候，遵循**空间局部性原理**，消费完第1个元素，很快就会消费第2个元素\n    - 而在消费第1个元素的时候，CPU会把内存中E1后面的数据也加载进高速Cache\n    - 如果E1和E2是连续的，那么E2也就会被加载进高速Cache\n    - 当消费第2个元素的时候，由于E2已经在高速Cache中了，不再需要从内存中加载，能大大提升性能\n4. 另外在Disruptor中，生产者线程通过publishEvent发布Event时，并不是创建一个新的Event\n    - 而是通过event.setValue来修改Event，即**循环利用**RingBuffer中的Event\n    - 这样能避免频繁创建和销毁Event而导致的**GC问题**\n\n### 避免伪共享\n\n#### 伪共享\n1. CPU缓存内部是按照**缓存行**（Cache Line）进行管理的，一个缓存行通常为**64 Bytes**\n2. CPU从内存中加载数据X，会同时加载后面（64-size(X)）个字节的数据\n\n##### ArrayBlockingQueue\n```java\n/** The queued items */\nfinal Object[] items;\n/** items index for next take, poll, peek or remove */\nint takeIndex;\n/** items index for next put, offer, or add */\nint putIndex;\n/** Number of elements in the queue */\nint count;\n```\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-disruptor-array-blocking-queue-false-sharing.png\" width=800/>\n\n1. 当CPU从内存中加载takeIndex时，会同时将putIndex和count都加载进高速Cache\n2. 假设线程A运行在CPU-1上，执行入队操作，入队操作会修改putIndex\n    - 而修改putIndex会导致CPU-2上putIndex所在的缓存行失效\n3. 假设线程B运行在CPU-2上，执行出队操作，出队操作需要读取takeIndex\n    - 但由于takeIndex所在的缓存行已经失效，所以CPU-2必须从**内存**中重新读取\n4. 入队操作本身不会修改takeIndex，但由于takeIndex和putIndex共享同一个缓存行\n    - 导致出队操作不能很好地利用Cache，这就是伪共享\n5. 伪共享：由于**共享缓存行而导致缓存无效**的场景\n6. ArrayBlockingQueue的入队操作和出队操作是用**锁**来保证互斥的，所以入队和出队不会同时发生\n7. 如果允许入队和出队同时发生，可以采用**缓存行填充**，保证每个变量**独占一个缓存行**\n    - 如果想让takeIndex独占一个缓存行，可以在takeIndex的前后各填充**56**个字节\n\n##### Disruptor\n```java\n// 前：填充56字节\nclass LhsPadding\n{\n    protected long p1, p2, p3, p4, p5, p6, p7;\n}\n\nclass Value extends LhsPadding\n{\n    protected volatile long value;\n}\n\n// 后：填充56字节\nclass RhsPadding extends Value\n{\n    protected long p9, p10, p11, p12, p13, p14, p15;\n}\n\npublic class Sequence extends RhsPadding\n{\n}\n```\n\n##### Contended\n1. Java 8引入了@sun.misc.Contended注解，能够轻松避免伪共享，需要设置JVM参数-XX:RestrictContended\n2. 避免伪共享是以**牺牲内存**为代价的\n\n### 无锁算法\n1. ArrayBlockingQueue利用**管程**实现，生产和消费都需要**加锁**，实现简单，但**性能不太理想**\n2. Disruptor采用的是**无锁**算法，实现复杂，核心操作是生产和消费，最复杂的是入队操作\n3. 对于入队操作，不能覆盖没有消费的元素，对于出队操作，不能读取没有写入的元素\n4. Disruptor中的RingBuffer维护了入队索引，但没有维护出队索引\n    - 因为Disruptor支持多个消费者同时消费，每个消费者都会有一个出队索引\n    - 所以RingBuffer的**出队索引**是所有消费者里**最小**的一个\n5. 入队逻辑：_**如果没有足够的空余位置，就出让CPU使用权，然后重新计算，反之使用CAS设置入队索引**_\n\n```java\n// com.lmax.disruptor.MultiProducerSequencer\npublic long next(int n)\n{\n    if (n < 1)\n    {\n        throw new IllegalArgumentException(\"n must be > 0\");\n    }\n\n    long current;\n    long next;\n\n    // 生产者获取n个写入位置\n    do\n    {\n        // current相当于入队索引，表示上次生产到这里\n        current = cursor.get();\n        // 目标是再生产n个\n        next = current + n;\n        // 减掉一个循环\n        long wrapPoint = next - bufferSize;\n        // 获取上一次的最小消费位置\n        long cachedGatingSequence = gatingSequenceCache.get();\n        //  没有足够的空余位置\n        if (wrapPoint > cachedGatingSequence || cachedGatingSequence > current)\n        {\n            // 重新计算所有消费者里面的最小值位置\n            long gatingSequence = Util.getMinimumSequence(gatingSequences, current);\n            // 仍然没有足够的空余位置，出让CPU使用权，重新执行下一循环\n            if (wrapPoint > gatingSequence)\n            {\n                LockSupport.parkNanos(1); // TODO, should we spin based on the wait strategy?\n                continue;\n            }\n            // 重新设置上一次的最小消费位置\n            gatingSequenceCache.set(gatingSequence);\n        }\n        else if (cursor.compareAndSet(current, next))\n        {\n            // 获取写入位置成功，跳出循环\n            break;\n        }\n    }\n    while (true);\n\n    return next;\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["Disruptor"],"categories":["Concurrent"]},{"title":"Java并发 -- Netty线程模型","url":"%2F2019%2F05%2F30%2Fjava-concurrent-netty%2F","content":"\n## BIO\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-netty-bio.png\" width=800/>\n\n\n<!-- more -->\n\n1. BIO即**阻塞式IO**，使用BIO模型，一般会**为每个Socket分配一个独立的线程**\n    - 为了避免频繁创建和销毁线程，可以采用线程池，但Socket和线程之间的对应关系不会发生变化\n2. BIO适用于Socket连接不是很多的场景，但现在上百万的连接是很常见的，而创建上百万个线程是不现实的\n    - 因此**BIO线程模型无法解决百万连接的问题**\n3. 在互联网场景中，连接虽然很多，但每个连接上的请求并不频繁，因此线程大部分时间都在**等待IO就绪**\n\n## 理想的线程模型\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-netty-ideal.png\" width=800/>\n\n1. 用一个线程来处理多个连接，可以提高线程的利用率，降低所需要的线程\n2. 使用BIO相关的API是无法实现的，BIO相关的Socket读写操作都是**阻塞式**的\n    - 一旦调用了阻塞式的API，在IO就绪前，调用线程会**一直阻塞**，也就无法处理其他的Socket连接\n3. 利用NIO相关的API能够实现一个线程处理多个连接，通过**Reactor模式**实现\n\n## Reactor模式\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-netty-reactor.png\" width=800/>\n\n1. Handle指的是**IO句柄**，在Java网络编程里，本质上是一个**网络连接**\n2. Event Handler是事件处理器，handle_event()处理IO事件，**每个Event Handler处理一个IO Handle**\n    - get_handle()方法可以返回这个IO Handle\n3. Synchronous Event Demultiplexer相当于操作系统提供的_**IO多路复用API**_\n    - 例如POSIX标准里的**select**()以及Linux里的**epoll**()\n4.  Reactor是Reactor模式的核心\n    - register_handler()和remove_handler()可以注册和删除一个事件处理器\n    - handle_events()是核心\n        - 通过同步事件多路选择器提供的select()方法_**监听网络事件**_\n        - 当有网络事件就绪后，就**遍历事件处理器**来处理该网络事件\n\n```cpp\nvoid Reactor::handle_events(){\n    // 通过同步事件多路选择器提供的select()方法监听网络事件\n    select(handlers);\n    // 处理网络事件\n    for(h in handlers){\n        h.handle_event();\n    }\n}\n// 在主程序中启动事件循环\nwhile (true) {\n    handle_events();\n}\n```\n\n## Netty的线程模型\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-netty.png\" width=800/>\n\n1. Netty参考了Reactor模式，Netty中最核心的概念是**事件循环**（EventLoop），即Reactor模式中的Reactor\n    - _**负责监听网络事件并调用事件处理器进行处理**_\n2. 在Netty 4.x中，网络连接 : EventLoop : Java线程 = _**N:1:1**_\n    - 所以，_**一个网络连接只会对应到一个Java线程**_\n    - 优点：对于一个网络连接的事件处理都是**单线程**的，这样能**避免各种并发问题**\n\n### EventLoopGroup\n1. EventLoopGroup由一组EventLoop组成\n    - 实际使用中，一般会创建两个EventLoopGroup，一个是**bossGroup**，一个是**workerGroup**\n2. Socket处理TCP网络连接请求，是在一个独立的Socket中\n    - 每当有一个TCP连接成功建立，都会创建一个新的Socket\n    - 之后对TCP连接的读写都是由新创建处理的Socket完成的\n    - 处理TCP**连接请求**和**读写请求**是通过两个不同的Socket完成的\n3. 在Netty中，bossGroup用来处理连接请求的，workerGroup用来处理读写请求的\n    - bossGroup处理完连接请求后，会将这个连接提交给workerGroup来处理\n    - workerGroup中会有多个EventLoop，通过均衡负载算法（**轮询**）来分配某一个EventLoop\n\n## Echo程序\n```java\npublic class Echo {\n\n    public static void main(String[] args) {\n        // 事件处理器\n        EchoServerHandler serverHandler = new EchoServerHandler();\n        // boss线程组\n        EventLoopGroup bossGroup = new NioEventLoopGroup(1);\n        // worker线程组\n        EventLoopGroup workerGroup = new NioEventLoopGroup(1);\n\n        try {\n            ServerBootstrap bootstrap = new ServerBootstrap();\n            bootstrap.group(bossGroup, workerGroup)\n                    .channel(NioServerSocketChannel.class)\n                    .childHandler(new ChannelInitializer<SocketChannel>() {\n                        @Override\n                        protected void initChannel(SocketChannel socketChannel) throws Exception {\n                            socketChannel.pipeline().addLast(serverHandler);\n                        }\n                    });\n            // 绑定端口号\n            ChannelFuture future = bootstrap.bind(9090).sync();\n            future.channel().closeFuture().sync();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            // 终止worker线程组\n            workerGroup.shutdownGracefully();\n            // 终止boss线程组\n            bossGroup.shutdownGracefully();\n        }\n    }\n}\n\n// Socket连接处理器\nclass EchoServerHandler extends ChannelInboundHandlerAdapter {\n\n    // 处理读事件\n    @Override\n    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n        ctx.write(msg);\n    }\n\n    // 处理读完成事件\n    @Override\n    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {\n        ctx.flush();\n    }\n\n    // 处理异常事件\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\n        cause.printStackTrace();\n        ctx.close();\n    }\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["Netty"],"categories":["Concurrent"]},{"title":"网络协议 -- DHCP","url":"%2F2019%2F05%2F29%2Fnetwork-protocol-dhcp%2F","content":"\n## 手动配置IP\n```sh\n# ifconfig - net-tools\n$ sudo ifconfig eth1 172.16.36.131/24\n$ sudo ifconfig eth1 up\n\n# ip - iproute2\n$ sudo ip addr add 172.16.36.131/24 dev eth1\n$ sudo ip link set up eth1\n```\n\n<!-- more -->\n\n## DHCP\nDHCP（Dynamic Host Configuration Protocol）：动态主机配置协议\n\n### DHCP Discover\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-dhcp-discover.png\" width=500/>\n\n1. 当一台新设备加入到一个网络时，只知道自己的Mac地址\n2. 使用IP地址**0.0.0.0**发送一个**广播包**，目的IP地址为**255.255.255.255**\n3. 广播包封装在**UDP**里，UDP封装在**BOOTP**里，其实DHCP是BOOTP的增强版\n\n### DHCP Offer\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-dhcp-offer.png\" width=500/>\n\n1. 如果网络里配置了DHCP Server，只要Mac地址唯一，DHCP Server就会为新设备**分配并保留**一个IP地址\n2. DHCP Server仍然使用**广播地址**作为目标地址，因为此时新设备还没有自己的IP地址\n\n### DHCP Request\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-dhcp-request.png\" width=500/>\n\n1. 新设备会收到多个DHCP Server的Offer，选择**最先到达**的那个，并向网络发送一个**DHCP Request广播包**\n2. 告诉所有的DHCP Server，该新设备将接受哪一台DHCP Server的Offer\n    - 告知其他DHCP Server撤销它们提供的Offer，以便提供给下一个新设备\n3. 此时还没有得到DHCP Server的确认，还是使用源IP地址0.0.0.0，目标IP地址255.255.255.255，进行广播\n\n### DHCP Ack\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-dhcp-ack.png\" width=500/>\n\n1. 当DHCP Server接收到DHCP Request后，会**广播**返回一个DHCP Ack\n2. 把IP地址的合法租用信息和其他配置信息都放入该广播包，发送给新设备\n\n<!-- indicate-the-source -->\n","tags":["Network Protocol"],"categories":["Protocol"]},{"title":"网络协议 -- ifconfig","url":"%2F2019%2F05%2F28%2Fnetwork-protocol-ifconfig%2F","content":"\n## 安装命令：ifconfig + ip\n```sh\n# 安装ifconfig命令\n$ apt-get install net-tools\n\n# 安装ip命令\n$ apt-get install iproute2\n```\n\n<!-- more -->\n\n## ip a\n```sh\n$ ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n2: ens32: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000\n    link/ether 00:0c:29:e3:05:05 brd ff:ff:ff:ff:ff:ff\n    inet 172.16.36.129/24 brd 172.16.36.255 scope global dynamic ens32\n       valid_lft 1507sec preferred_lft 1507sec\n    inet6 fe80::20c:29ff:fee3:505/64 scope link\n       valid_lft forever preferred_lft forever\n```\n1. 该命令显示了机器上的所有**网卡**，大部分网卡都会有一个IP地址\n2. IP地址是一个网卡在网络世界里的通信地址\n3. 网卡ens32的IP地址为172.16.36.129，总共32位\n    - IPV6的地址为fe80::20c:29ff:fee3:505，总共**128**位\n\n## IP地址分类\n<img src=\"https://network-protocol-1253868755.cos.ap-guangzhou.myqcloud.com/network-protocol-ifconfig-ip-classification.png\" width=800/>\n\n\n| 类别 | IP地址范围 | 最大主机数 | 私有IP地址范围 |\n| ---- | ---- | ---- | ---- |\n| A | 0.0.0.0 ~ 127.255.255.255 | 2^24-2 | 10.0.0.0 ~ 10.255.255.255 |\n| B | 128.0.0.0 ~ 191.255.255.255 | 2^16-2 | 172.16.0.0 ~ 172.31.255.255 |\n| C | 192.0.0.0 ~ 223.255.255.255 | 2^8-2 | 192.168.0.0 ~ 192.168.255.255 |\n\nC类地址能包含的最大主机数太少了，而B类地址能包含的最大主机数又太多了，由此催生了**CIDR**\n\n## CIDR\n1. CIDR（Classless Inter-Domain Routing）：**无类型域间选路**\n2. 将32位的IP地址一分为二，前面是**网络号**，后面是**主机号**\n3. 172.16.36.129/24，就是CIDR的表示方式，网络号为172.16.36，主机号为129\n4. 伴随CIDR存在的，一个是**广播地址**，一个是**子网掩码**，以172.16.36.129/24为例\n    - 广播地址为：172.16.36.255，如果发送消息到这个地址，所有172.16.36网段内的机器都可以收到\n    - 子网掩码：255.255.255.0\n        - 将**IP地址**和**子网掩码**进行**按位与**操作，可以得到**网络号**\n        - 172.16.36.129 & 255.255.255.0 = 172.16.36\n5. 实际工作中，几乎不划分A类、B类和C类地址，主要使用CIDR\n\n### 16.158.165.91/22\n1. 165 = <10100101>\n2. 16.158.165.91/22 == 16.158.<101001,01>.91/22\n3. 网络号：16.158.<101001,00> == 16.158.164\n4. 子网掩码：255.255.<111111,00>.0 == 255.255.252.0\n5. 网络的第一个地址：16.158.<101001,00>.1 == 16.158.164.1\n6. 网络的广播地址：16.158.<101001,11>.255 == 16.158.167.255\n\n## 私有IP地址\n1. 192.168.0.X/24是最常用的私有IP地址，例如家里的Wi-Fi，一般上网设备不会超过254个，因此/24足够了\n    - 192.168.0是网络号，X是主机号\n2. 网段内的**第一个**IP地址192.168.0.1，往往是私有网络的出口地址（**网关**）\n3. 网段内的**最后一个**IP地址192.168.0.255，就是**广播地址**\n\n## scope\n1. 对于网卡ens32，IPV4的scope为**global**，说明这张网卡可以对外的，接收来自各个地方的数据包\n2. 对于网络lo，IPV4的scope为**host**，说明这张网卡仅供本机相互通信\n    - lo全称为loopback，又称环回接口，往往被分配IP地址127.0.0.1/8\n    - 该地址用于本机通信，经过内核处理后直接返回，不会在任何网络中出现\n\n## Mac地址\n1. Mac地址（6 Bytes）：link/ether 00:0c:29:e3:05:05 brd ff:ff:ff:ff:ff:ff\n2. Mac地址**全局唯一**，不会有两个网卡有相同的Mac地址\n3. 一个网络包从A传到B，除了要有确定的地址（Mac地址），还需要有**远程定位功能**（IP地址）\n4. Mac地址更像一个身份证，是唯一的标识\n    - Mac地址的唯一性设计是为了在组网的时候，不同的网卡在同一个网络中不会发生冲突\n    - Mac地址的通信范围很小（在**子网**内），而IP地址的通信范围大很多（可以跨子网）\n        - 192.168.0.2/24访问192.168.0.3/24，使用Mac地址即可\n        - 192.168.0.2/24访问192.168.1.2/24，只能通过IP地址\n\n## 网络设备的状态标识\n1. <BROADCAST,MULTICAST,UP,LOWER_UP>\n    - UP：网卡处于启动状态\n    - BROADCAST：该网卡有广播地址，可以发送广播包\n    - MULTICAST：该网卡可以发送多播包\n    - LOWER_UP：L1是启动的，即网线是插着的\n2. mtu 1500\n    - MTU：Maximum Transmission Unit，1500是**以太网**的默认值，MTU是二层**MAC层**的概念\n    - 以太网规定：连MAC头带正文（包含IP头/TCP头/HTTP头等）合起来，不允许超过1500个字节\n        - 否则需要**分片**传输\n3. qdisc fq_codel\n    - qdisc：queueing discipline，即**排队规则**\n    - 内核如果需要通过某个网络接口**发送**数据包，都需要为这个网络接口配置qdisc，把数据包加入队列\n    - 最简单的qdisc是pfifo，该规则不对进入的数据包做任何处理，数据包采用先进先出的方式通过队列\n\n<!-- indicate-the-source -->\n","tags":["Network Protocol"],"categories":["Protocol"]},{"title":"Java并发 -- Guava RateLimiter","url":"%2F2019%2F05%2F27%2Fjava-concurrent-guava-rate-limiter%2F","content":"\n## RateLimiter\n```java\n// 限流器流速：2请求/秒\nRateLimiter limiter = RateLimiter.create(2.0);\nExecutorService pool = Executors.newFixedThreadPool(1);\nfinal long[] prev = {System.nanoTime()};\nfor (int i = 0; i < 20; i++) {\n    // 限流器限流\n    limiter.acquire();\n    pool.execute(() -> {\n        long cur = System.nanoTime();\n        System.out.println((cur - prev[0]) / 1000_000);\n        prev[0] = cur;\n    });\n}\n// 输出\n//  499\n//  499\n//  497\n//  502\n//  496\n```\n\n<!-- more -->\n\n## 令牌桶算法\n1. Guava RateLimiter采用的是**令牌桶算法**，核心思想：_**通过限流器的前提是拿到令牌**_\n2. **令牌桶算法**\n    - 令牌以**固定的速率**添加到令牌桶中，假设限流的速率为r/s，则令牌每1/r秒会添加一个\n    - 假设令牌桶的容量是b，如果令牌桶已满，则新的令牌会被**丢弃**\n        - b是burst的简写，意义是限流器**允许的最大突发流量**\n        - 例如b=10，且令牌桶中的令牌已满，此时限流器允许10个请求同时通过限流器，这只是突发流量\n    - 请求能通过限流器的前提是**令牌桶中有令牌**\n\n### 生产者-消费者\n1. 一个生产者定时向阻塞队列中添加令牌，消费者线程从阻塞队列中获得令牌，才允许通过限流器\n2. 用生产者-消费者实现限流器的方案仅适用于并发量不大的场景，但实际情况是使用限流器的场景大部分都是**高并发**场景\n3. 主要问题是**定时器**，在**高并发**场景下，当系统压力已经临近**极限**的时候，定时器的**精度误差**会非常大\n    - 另外定时器本身也会创建**调度线程**，也会对系统的性能产生影响\n\n### Guava\n1. Guava实现令牌桶算法：_**记录并动态计算下一令牌发放的时间**_\n2. 假设令牌桶的容量为b=1，限流速率为r=1/s\n\n#### 简要分析\n\n##### Case 1\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-guava-token-bucket-c1s1.png\" width=800/>\n\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-guava-token-bucket-c1s2.png\" width=800/>\n\n1. 当前令牌桶中没有令牌，下一令牌的发放时间在第3秒，而在第2秒的时候线程T1请求令牌\n2. 线程T1需要等待1秒，由于原本在第3秒发放的令牌已经被线程T1**预占**了，下一个令牌发放的时间也需要增加1秒\n\n##### Case 2\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-guava-token-bucket-c2s1.png\" width=800/>\n\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-guava-token-bucket-c2s2.png\" width=800/>\n\n1. 假设T1在预占第3秒的令牌后，马上又有一个线程T2请求令牌\n2. 由于下一个令牌产生的时间是第4秒，所以线程T2需要等待2秒才能获得令牌\n3. 由于T2预占了第4秒的令牌，所以下一令牌产生的时间还要增加1秒\n\n##### Case 3\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-guava-token-bucket-c3s1.png\" width=800/>\n\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-guava-token-bucket-c3s2.png\" width=800/>\n\n1. 假设在线程T1请求令牌之后的5秒，也就是第7秒，线程T3请求令牌\n2. 由于在第5秒已经产生了一个令牌，此时线程T3可以直接拿到令牌，无需等待\n3. 在第7秒，实际上限流器能产生3个令牌，分别在第5、6、7秒各产生一个令牌\n    - 但由于令牌桶的容量为1，所以第6、7秒产生的令牌丢弃了（也可以认为丢弃的是第5、6秒产生的令牌）\n4. 因此，下一个令牌的产生时间应该是第8秒\n\n#### 代码实现\n```java\npublic class SimpleLimiter {\n    // 令牌发放间隔\n    private static final long INTERVAL = 1000_000_000;\n    // 下一令牌发放时间\n    private long next = System.nanoTime();\n\n    // 预占令牌，返回能够获取令牌的时间\n    private synchronized long reserve(long now) {\n        if (now > next) {\n            // 请求时间在下一令牌产生时间之后\n            // 重新计算下一令牌产生时间\n            next = now;\n        }\n        // 能够获取令牌的时间\n        long at = next;\n        // 更新下一个令牌产生的时间\n        next += INTERVAL;\n        // 返回线程需要等待的时间\n        return Math.max(at, 0L);\n    }\n\n    // 申请令牌\n    public void acquire() {\n        long now = System.nanoTime();\n        // 预占令牌\n        long at = reserve(now);\n        long waitTime = Math.max(at - now, 0);\n        if (waitTime > 0) {\n            try {\n                TimeUnit.NANOSECONDS.sleep(waitTime);\n            } catch (InterruptedException ignored) {\n            }\n        }\n    }\n}\n```\n\n## 小结\n1. 经典的限流算法有两个：一个是**令牌桶算法**（Token Bucket），另一个是**漏桶算法**（Leaky Bucket）\n2. 令牌桶算法：定时向令牌桶发放令牌，请求能够从令牌桶中拿到令牌，然后才能通过限流器\n3. 漏桶算法：请求就像水一样注入漏桶，漏桶会按照一定的速率自动将水漏掉\n    - 只有漏桶里还能注入水的时候，请求才能通过限流器\n4. 令牌桶算法和漏桶算法很像一个硬币的正反面\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- 生产者-消费者模式","url":"%2F2019%2F05%2F26%2Fjava-concurrent-producer-consumer%2F","content":"\n## 生产者-消费者模式\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-producer-consumer.png\" width=800/>\n\n\n<!-- more -->\n\n1. 生产者-消费者模式的核心是一个_**任务队列**_\n    - 生产者线程生产任务，并将任务添加到任务队列中，消费者线程从任务队列中获取任务并执行\n2. 从**架构设计**的角度来看，生产者-消费者模式有一个很重要的优点：_**解耦**_\n3. 生产者-消费者模式另一个重要的优点是**支持异步**，并且能够**平衡**生产者和消费者的**速度差异**（任务队列）\n\n## 支持批量执行\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-dynamic-sampling-batch-insert.png\" width=800/>\n\n1. 往数据库INSERT 1000条数据，有两种方案\n    - 第一种方案：用1000个线程并发执行，每个线程INSERT一条数据\n    - 第二种方案（更优）：用1个线程，执行一个批量的SQL，一次性把1000条数据INSERT进去\n2. 将原来直接INSERT数据到数据库的线程作为生产者线程，而生产者线程只需将数据添加到任务队列\n    - 然后消费者线程负责将任务从任务队列中批量取出并批量执行\n\n```java\n// 任务队列\nprivate BlockingQueue<Task> queue = new LinkedBlockingQueue<>(2000);\n\n// 启动5个消费者线程，执行批量任务\npublic void start() {\n    ExecutorService pool = Executors.newFixedThreadPool(5);\n    for (int i = 0; i < 5; i++) {\n        pool.execute(() -> {\n            try {\n                while (true) {\n                    // 获取批量任务\n                    List<Task> tasks = pollTasks();\n                    // 执行批量任务\n                    execTasks(tasks);\n                }\n            } catch (InterruptedException ignored) {\n            }\n        });\n    }\n}\n\n// 从任务队列中获取批量任务\nprivate List<Task> pollTasks() throws InterruptedException {\n    List<Task> tasks = new LinkedList<>();\n    // 阻塞式获取一个任务\n    // 首先采用阻塞式的方式，如果任务队列中没有任务，能够避免无谓的循环\n    Task task = queue.take();\n    while (task != null) {\n        tasks.add(task);\n        // 非阻塞式获取一个任务\n        task = queue.poll();\n    }\n    return tasks;\n}\n\n// 批量执行任务\nprivate void execTasks(List<Task> tasks) {\n}\n```\n\n## 支持分阶段提交\n1. 写文件如果同步刷盘性能会很慢，对于不是很重要的数据，往往采用**异步刷盘**的方式\n2. 异步刷盘的时机\n    - ERROR级别的日志需要立即刷盘\n    - 数据累积到500条需要立即刷盘\n    - 存在未刷盘数据，且5秒钟内未曾刷盘，需要立即刷盘\n3. 该日志组件的异步刷盘本质上是一种**分阶段提交**\n\n```java\npublic class Logger {\n    // 批量异步刷新的数量\n    private static final int FLUSH_BATCH_SIZE = 500;\n    // 任务队列\n    private final BlockingQueue<LogMsg> queue = new LinkedBlockingQueue<>();\n    // 只需要一个线程写日志\n    private ExecutorService pool = Executors.newFixedThreadPool(1);\n\n    // 启动写日志线程\n    public void start() throws IOException {\n        File file = File.createTempFile(\"test\", \".log\");\n        FileWriter writer = new FileWriter(file);\n        pool.execute(() -> {\n            // 未刷盘日志数量\n            int curIdx = 0;\n            long preFlushTime = System.currentTimeMillis();\n            while (true) {\n                try {\n                    LogMsg logMsg = queue.poll(5, TimeUnit.SECONDS);\n                    // 写日志\n                    if (logMsg != null) {\n                        writer.write(logMsg.toString());\n                        ++curIdx;\n                    }\n                    // 如果不存在未刷盘数据，则无需刷盘\n                    if (curIdx <= 0) {\n                        continue;\n                    }\n                    // 异步刷盘规则\n                    if (logMsg != null && logMsg.getLevel() == LEVEL.ERROR ||\n                            curIdx == FLUSH_BATCH_SIZE ||\n                            System.currentTimeMillis() - preFlushTime > 5_000) {\n                        writer.flush();\n                        curIdx = 0;\n                        preFlushTime = System.currentTimeMillis();\n                    }\n                } catch (InterruptedException | IOException ignored) {\n                } finally {\n                    try {\n                        writer.flush();\n                        writer.close();\n                    } catch (IOException ignored) {\n                    }\n                }\n            }\n        });\n    }\n\n    private void info(@NonNull String msg) throws InterruptedException {\n        queue.put(new LogMsg(LEVEL.INFO, msg));\n    }\n\n    private void error(@NonNull String msg) throws InterruptedException {\n        queue.put(new LogMsg(LEVEL.ERROR, msg));\n    }\n}\n\n@Data\n@AllArgsConstructor\nclass LogMsg {\n    private LEVEL level;\n    private String msg;\n}\n\nenum LEVEL {\n    INFO, ERROR\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- 两阶段终止模式","url":"%2F2019%2F05%2F25%2Fjava-concurrent-two-phase-stop%2F","content":"\n## 两阶段终止模式\n第一阶段线程T1向线程T2**发送终止指令**，第二阶段是线程T2**响应终止指令**\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-two-phase-stop.png\" width=800/>\n\n\n<!-- more -->\n\n## Java线程生命周期\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-thread-life-cycle-java.png\" width=800/>\n\n1. Java线程进入终止状态的前提是线程进入RUNNABLE状态，而实际上线程可能处于休眠状态\n2. 因为如果要终止处于休眠状态的线程，要先通过**interrupt**把线程的状态从休眠状态转换到RUNNABLE状态\n3. RUNNABLE状态转换到终止状态，优雅的方式是让Java线程自己执行完run方法\n    - 设置一个**标志位**，然后线程会在**合适的时机**检查这个标志位\n        - 如果发现符合终止条件，就会自动退出run方法\n    - 第二阶段：响应终止指令\n\n## 终止监控操作\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-dynamic-sampling.png\" width=800/>\n\n1. 监控系统需要动态采集一些数据，监控系统发送采集指令给被监控系统的的监控代理\n2. 监控代理接收到指令后，从监控目标收集数据，然后回传给监控系统\n3. 处于性能的考虑，动态采集一般都会有终止操作\n\n```java\npublic class Proxy {\n    private boolean started = false;\n    // 采集线程\n    private Thread rptThread;\n\n    // 启动采集线程\n    public synchronized void start() {\n        // 不允许同时启动多个采集线程\n        if (started) {\n            return;\n        }\n        started = true;\n        rptThread = new Thread(() -> {\n            // 第二阶段：响应终止指令\n            while (!Thread.currentThread().isInterrupted()) {\n                // 采集、回传\n                report();\n                try {\n                    TimeUnit.SECONDS.sleep(2);\n                } catch (InterruptedException ignored) {\n                    // JVM的异常处理会清除线程的中断状态\n                    // 重置线程中断状态\n                    Thread.currentThread().interrupt();\n                }\n            }\n            started = false;\n        });\n        rptThread.start();\n    }\n\n    // 终止采集功能\n    public synchronized void stop() {\n        // 第一阶段：发送终止指令\n        // 将rptThread从休眠状态切换至RUNNABLE状态\n        rptThread.interrupt();\n    }\n\n    private void report() {\n    }\n}\n```\n\n### 自定义线程终止标志位\n很可能在run方法中调用了第三方类库提供的方法，但没办法保证第三方类库都正确地处理了线程的中断状态\n```java\npublic class Proxy {\n    // 线程终止状态\n    private volatile boolean terminated = true;\n    private boolean started = false;\n    // 采集线程\n    private Thread rptThread;\n\n    // 启动采集线程\n    public synchronized void start() {\n        // 不允许同时启动多个采集线程\n        if (started) {\n            return;\n        }\n        started = true;\n        terminated = false;\n        rptThread = new Thread(() -> {\n            // 第二阶段：响应终止指令\n            while (!terminated) {\n                // 采集、回传\n                report();\n                try {\n                    TimeUnit.SECONDS.sleep(2);\n                } catch (InterruptedException ignored) {\n                    // JVM的异常处理会清除线程的中断状态\n                    // 重置线程中断状态\n                    Thread.currentThread().interrupt();\n                }\n            }\n            started = false;\n        });\n        rptThread.start();\n    }\n\n    // 终止采集功能\n    public synchronized void stop() {\n        // 设置中断标志位\n        terminated = true;\n        // 第一阶段：发送终止指令\n        // 将rptThread从休眠状态切换至RUNNABLE状态\n        rptThread.interrupt();\n    }\n\n    private void report() {\n    }\n}\n```\n\n## 优雅地终止线程池\n1. Java线程池是**生产者-消费者**模式的一种实现\n    - 提交到线程池的任务，首先进入一个**阻塞队列**，然后线程池中的线程从阻塞队列中取出任务执行\n2. shutdown()是一种很**保守**的关闭线程池的方法\n    - 方法签名：`void shutdown();`\n    - **拒绝接收新的任务**\n    - 但会**等待**线程池中**正在执行**的任务和**已经进入阻塞队列**的任务都执行完后才关闭线程池\n3. shutdownNow()相对**激进**\n    - 方法签名：`List<Runnable> shutdownNow();`\n    - **拒绝接收新的任务**\n    - 会**中断**线程池中正在执行的任务（因此需要优雅地结束，并正确地处理线程中断）\n    - 已经进入阻塞队列中的任务会被**剥夺**执行的机会，并且作为shutdownNow()的返回值返回\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- Worker Thread模式","url":"%2F2019%2F05%2F24%2Fjava-concurrent-worker-thread%2F","content":"\n## Worker Thread模式\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-worker-thread.png\" width=800/>\n\n1. Worker Thread模式可以类比现实世界里车间的工作模式，Worker Thread对应车间里的工人（人数确定）\n2. 用**阻塞队列**做任务池，然后创建**固定数量的线程**消费阻塞队列中的任务 -- 这就是Java中的**线程池**方案\n\n<!-- more -->\n\n## echo服务\n```java\nprivate ExecutorService pool = Executors.newFixedThreadPool(500);\n\npublic void handle() throws IOException {\n    // 处理请求\n    try (ServerSocketChannel ssc = ServerSocketChannel.open().bind(new InetSocketAddress(8080))) {\n        while (true) {\n            // 接收请求\n            SocketChannel sc = ssc.accept();\n            // 将请求处理任务提交给线程池\n            pool.execute(() -> {\n                try {\n                    // 读Socket\n                    ByteBuffer rb = ByteBuffer.allocateDirect(1024);\n                    sc.read(rb);\n                    TimeUnit.SECONDS.sleep(1);\n                    // 写Socket\n                    ByteBuffer wb = (ByteBuffer) rb.flip();\n                    sc.write(wb);\n                    sc.close();\n                } catch (IOException | InterruptedException ignored) {\n                }\n            });\n        }\n    } finally {\n        pool.shutdown();\n    }\n}\n```\n\n## 正确地创建线程池\n1. Java线程池既能避免无限制地**创建线程**导致OOM，也能避免无限制地**接收任务**导致OOM（**有界队列**）\n2. 当请求量大于有界队列的容量时，应该合理地拒绝请求，在创建线程池时，应该清晰地指明**拒绝策略**\n3. 为了便于调试和诊断问题，在实际工作中应该给线程赋予一个**业务相关的命名**\n\n```java\nprivate ExecutorService pool = new ThreadPoolExecutor(50, 500, 60L, TimeUnit.SECONDS,\n        new LinkedBlockingQueue<>(2000), // 有界队列\n        runnable -> new Thread(runnable, \"echo-\" + runnable.hashCode()), // ThreadFactory\n        new ThreadPoolExecutor.CallerRunsPolicy()); // 拒绝策略\n```\n\n## 避免线程死锁\n1. 如果提交到**相同线程池**的任务不是相互独立的，而是有**依赖**关系的，有可能会导致线程**死锁**\n2. 通用解决方案：**为不同的任务创建不同的线程池**，提交到**相同线程池**中的任务一定是**相互独立**的\n3. 下图中第一阶段的任务会等待第二阶段的子任务完成\n\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-worker-thread-dead-lock.png\" width=800/>\n\n```java\n// L1、L2阶段共用线程池\nExecutorService pool = Executors.newFixedThreadPool(2);\nCountDownLatch l1 = new CountDownLatch(2);\nfor (int i = 0; i < 2; i++) {\n    System.out.println(\"L1\");\n    pool.execute(() -> {\n        CountDownLatch l2 = new CountDownLatch(2);\n        for (int j = 0; j < 2; j++) {\n            pool.execute(() -> {\n                System.out.println(\"L2\");\n                l2.countDown();\n            });\n        }\n        try {\n            // 线程池中的2个线程都阻塞在l2.await()，没有多余线程去执行L2阶段的任务（在线程池的任务队列中等待）\n            l2.await(); // line 28\n        } catch (InterruptedException ignored) {\n        }\n        l1.countDown();\n    });\n}\nl1.await();\n// 输出\n//  L1\n//  L1\n```\n\n### jstack\n```java\n// 阻塞在l2.await()\n\"pool-1-thread-2\" #11 prio=5 os_prio=31 tid=0x00007f934e8f5000 nid=0x4303 waiting on condition [0x000070000792d000]\n   java.lang.Thread.State: WAITING (parking)\n\tat sun.misc.Unsafe.park(Native Method)\n\t- parking to wait for  <0x000000079609bd58> (a java.util.concurrent.CountDownLatch$Sync)\n\tat java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)\n\tat java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231)\n\tat time.geek.worker.thread.DeadLock.lambda$deadLockTest$1(DeadLock.java:28)\n\tat time.geek.worker.thread.DeadLock$$Lambda$1/1221555852.run(Unknown Source)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\n// 阻塞在l2.await()\n\"pool-1-thread-1\" #10 prio=5 os_prio=31 tid=0x00007f9350142800 nid=0x3c03 waiting on condition [0x000070000782a000]\n   java.lang.Thread.State: WAITING (parking)\n\tat sun.misc.Unsafe.park(Native Method)\n\t- parking to wait for  <0x0000000795ff56a8> (a java.util.concurrent.CountDownLatch$Sync)\n\tat java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)\n\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)\n\tat java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231)\n\tat time.geek.worker.thread.DeadLock.lambda$deadLockTest$1(DeadLock.java:28)\n\tat time.geek.worker.thread.DeadLock$$Lambda$1/1221555852.run(Unknown Source)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n```\n\n## 对比Thread-Per-Message模式\n1. Thread-Per-Message模式：主线程直接创建子线程，主子线程之间可以直接通信\n2. Worker Thread模式：主线程提交任务到线程池，但主线程并不关心任务被哪个线程执行\n    - 能够避免线程频繁创建、销毁的问题，并且能够限制线程的最大数量\n    - Java利用Worker Thread模式来实现线程池\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- Thread-Per-Message模式","url":"%2F2019%2F05%2F23%2Fjava-concurrent-thread-per-message%2F","content":"\n## 概述\nThread-Per-Message模式：为每个任务分配一个**独立**的线程\n\n<!-- more -->\n\n## Thread\n```java\n// 处理请求\ntry (ServerSocketChannel ssc = ServerSocketChannel.open().bind(new InetSocketAddress(8080))) {\n    while (true) {\n        // 接收请求\n        SocketChannel sc = ssc.accept();\n        // 每个请求都创建一个线程\n        new Thread(() -> {\n            try {\n                // 读Socket\n                ByteBuffer rb = ByteBuffer.allocateDirect(1024);\n                sc.read(rb);\n                TimeUnit.SECONDS.sleep(1);\n                // 写Socket\n                ByteBuffer wb = (ByteBuffer) rb.flip();\n                sc.write(wb);\n                sc.close();\n            } catch (IOException | InterruptedException ignored) {\n            }\n        }).start();\n    }\n}\n```\n1. Java中的线程是一个重量级的对象，创建成本很高（创建过程比较**耗时** + 线程占用的**内存**也较大）\n2. 所以在Java中为每个请求创建一个新的线程并**不适合高并发**场景\n3. 语言、工具和框架本身是帮助我们更敏捷地实现方案的\n    - 而Thread-Per-Message模式是最简单的**分工**方案，只是Java无法有效支持\n4. Java线程和操作系统线程是**一一对应**的，Java将Java线程的调度权完全委托给操作系统\n    - 操作系统在线程调度方面非常成熟、稳定和可靠，但创建线程的**成本**很高\n    - 为此，JUC提供了线程池等工具类\n5. 业界还有另外一种解决方案，叫作_**轻量级线程**_\n    - 在Go语言，Lua语言里的**协程**，本质上是一种轻量级线程\n    - 轻量级线程的创建成本很低，基本上和创建一个普通对象的成本类似\n        - 创建速度和内存占用相比操作系统线程**至少有一个数量级**的提升\n        - 因此，基于轻量级线程实现Thread-Per-Message模式是没有问题的\n    - OpenJdk的[**Loom**](https://wiki.openjdk.java.net/display/loom/Main)项目，是为了解决Java语言的轻量级线程问题，Loom项目中的轻量级线程叫作**Fiber**\n6. Thread-Per-Message模式在Java领域并不知名\n    - 根本原因：Java线程是一个**重量级对象**，线程的创建成本太高，在高并发领域，**基本不具备可行性**\n    - _**Java在未来一定会提供轻量级线程**_\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- Balking模式","url":"%2F2019%2F05%2F22%2Fjava-concurrent-balking%2F","content":"\n## 关于Guarded Suspension模式\n可以用“多线程版本的if”来理解Guarded Suspension模式，必须等到条件为真，但很多场景需要**快速放弃**\n\n<!-- more -->\n\n## 自动保存\n```java\npublic class AutoSaveEditor {\n    // 文件是否被修改\n    // 非线程安全，对共享变量change的读写没有使用同步\n    private boolean changed = false;\n    // 定时任务线程池\n    private ScheduledExecutorService service = Executors.newSingleThreadScheduledExecutor();\n\n    @PostConstruct\n    public void startAutoSave() {\n        service.scheduleWithFixedDelay(() -> autoSave(), 5, 5, TimeUnit.SECONDS);\n    }\n\n    // 编辑操作\n    public void edit() {\n        changed = true;\n    }\n\n    // 自动保存\n    private void autoSave() {\n        // 没有修改，快速放弃\n        if (!changed) {\n            return;\n        }\n        changed = false;\n        save();\n    }\n\n    private void save() {\n    }\n}\n```\n\n## synchronized\n```java\n// 编辑操作\npublic void edit() {\n    synchronized (this) {\n        changed = true;\n    }\n}\n\n// 自动保存\nprivate void autoSave() {\n    synchronized (this) {\n        // 没有修改，快速放弃\n        if (!changed) {\n            return;\n        }\n        changed = false;\n    }\n    save();\n}\n```\n1. 共享变量changed是一个状态变量，业务逻辑依赖于这个状态变量的状态，本质上是if\n2. 在多线程领域，就是一种“多线程版本的if”，总结成一种设计模式，就是_**Balking模式**_\n\n## Balking模式\nBalking模式本质上是一种**规范化**地解决“多线程版本的if”的方案\n```java\n// 编辑操作\npublic void edit() {\n    // 仅仅将对共享变量changed的赋值操作抽取到change()\n    // 将并发处理逻辑和业务逻辑分开\n    change();\n}\n\n// 改变状态\nprivate void change() {\n    synchronized (this) {\n        changed = true;\n    }\n}\n\n// 自动保存\nprivate void autoSave() {\n    synchronized (this) {\n        // 没有修改，快速放弃\n        if (!changed) {\n            return;\n        }\n        changed = false;\n    }\n    save();\n}\n```\n\n## volatile + Balking模式\n1. 上面用synchronized实现Balking模式的方式最为**稳妥**，建议在实际工作中采用\n2. 如果**对原子性没有要求**，可以使用volatile（仅能保证**可见性**）来实现Balking模式\n\n```java\n// 能够用volatile实现Balking模式，是因为changed和rt的写操作不存在原子性要求\npublic class RouterTable {\n    // <Key, Value> = <接口名，路由集合>\n    private Map<String, CopyOnWriteArraySet<Router>> rt = new ConcurrentHashMap<>();\n    // 路由表是否发生变化\n    private volatile boolean changed;\n    // 将路由表写入本地文件的线程池\n    private ScheduledExecutorService service = Executors.newSingleThreadScheduledExecutor();\n\n    @PostConstruct\n    public void startLocalSaver() {\n        service.scheduleWithFixedDelay(this::autoSave, 1, 1, TimeUnit.MINUTES);\n    }\n\n    // 保存路由表到本地文件\n    private void autoSave() {\n        // 没有修改，快速放弃\n        if (!changed) {\n            return;\n        }\n        changed = false;\n        save2Local();\n    }\n\n    private void save2Local() {\n    }\n\n    // 增加路由\n    public void add(Router router) {\n        CopyOnWriteArraySet<Router> routers = rt.computeIfAbsent(router.getIFace(), iFace -> new CopyOnWriteArraySet<>());\n        routers.add(router);\n        changed = true;\n    }\n\n    // 删除路由\n    public void remove(Router router) {\n        Set<Router> routers = rt.get(router.getIFace());\n        if (routers != null) {\n            routers.remove(router);\n            // 路由表发生变化\n            changed = true;\n        }\n    }\n}\n```\n\n## 单次初始化\nBalking模式有一个非常典型的应用场景就是**单次初始化**\n```java\npublic class SingleInit {\n    private boolean inited = false;\n\n    public synchronized void init() {\n        if (inited) {\n            return;\n        }\n        doInit();\n        inited = true;\n    }\n\n    private void doInit() {\n    }\n}\n```\n\n### 单例模式\n线程安全的单例模式本质上也是单次初始化，可以用Balking模式实现线程安全的单例模式\n```java\npublic class Singleton {\n    private static Singleton singleton;\n\n    // 私有构造函数\n    private Singleton() {\n    }\n\n    // 获取实例（单例），性能很差\n    public synchronized static Singleton getInstance() {\n        if (singleton == null) {\n            singleton = new Singleton();\n        }\n        return singleton;\n    }\n}\n```\n\n### 双重检查\n```java\npublic class Singleton {\n    // volatile保证可见性\n    private static volatile Singleton singleton;\n\n    // 私有构造函数\n    private Singleton() {\n    }\n\n    // 获取实例（单例）\n    public static Singleton getInstance() {\n        // 第一次检查\n        if (singleton == null) {\n            synchronized (Singleton.class) {\n                // 第二次检查\n                if (singleton == null) {\n                    singleton = new Singleton();\n                }\n            }\n        }\n        return singleton;\n    }\n}\n```\n\n## Guarded Suspension + Balking\n1. Balking模式只需要**互斥锁**就能实现，而Guarded Suspension模式则需要用到**管程**（高级并发原语）\n2. 从应用角度来看，两者都是为了解决“线程安全的if”\n    - _**Guarded Suspension模式会等待if条件为真（利用管程模型来实现），而Balking模式不会等待**_\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- Guarded Suspension模式","url":"%2F2019%2F05%2F21%2Fjava-concurrent-guarded-suspension%2F","content":"\n## 概述\n1. Guarded Suspension模式是**等待唤醒**机制的**规范实现**\n2. Guarded Suspension模式也被称为Guarded Wait 模式、Spin Lock 模式\n\n<!-- more -->\n\n## Web版的文件浏览器\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-file-browsing-mq.png\" width=800/>\n\n1. 用户可以在浏览器里查看服务器上的目录和文件\n2. 该项目依赖运维部门提供的文件浏览服务，而文件浏览服务仅支持MQ接入\n3. 用户通过浏览器发送请求，会被转换成消息发送给MQ，等MQ返回结果后，再将结果返回至浏览器\n\n```java\npublic class FileBrowser {\n    // 发送消息\n    private void send(Message message) {\n    }\n\n    // MQ消息返回后调用该方法\n    public void onMessage(Message message) {\n    }\n\n    public Response handleWebReq() {\n        Message message = new Message(1L, \"123\");\n        // 发送消息\n        send(message);\n        // 如何等待MQ返回消息？\n        return new Response();\n    }\n}\n\n@AllArgsConstructor\nclass Message {\n    private Long id;\n    private String content;\n}\n\nclass Response {\n}\n```\n\n## Guarded Suspension模式\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-guarded-suspension.png\" width=800/>\n\n1. Guarded Suspension直译为_**保护性暂停**_\n2. 通过onChange方法可以产生一个事件，而这个事件往往能改变前提条件p的计算结果\n\n```java\npublic class GuardedObject<T> {\n    private static final int TIMEOUT = 1;\n\n    // 受保护对象\n    private T obj;\n    private final Lock lock = new ReentrantLock();\n    private final Condition done = lock.newCondition();\n\n    // 获取受保护对象\n    public T get(Predicate<T> p) {\n        lock.lock();\n        try {\n            // MESA管程推荐写法\n            while (!p.test(obj)) {\n                done.await(TIMEOUT, TimeUnit.SECONDS);\n            }\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        } finally {\n            lock.unlock();\n        }\n        return obj;\n    }\n\n    // 事件通知方法\n    public void onChange(T obj) {\n        lock.lock();\n        try {\n            this.obj = obj;\n            done.signalAll();\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n```\n\n## 扩展Guarded Suspension模式\n```java\npublic class GuardedObject<T> {\n    private static final int TIMEOUT = 1;\n    // 保存所有的GuardedObject\n    private static final Map<Object, GuardedObject> goMap = new ConcurrentHashMap<>();\n\n    // 受保护对象\n    private T obj;\n    private final Lock lock = new ReentrantLock();\n    private final Condition done = lock.newCondition();\n\n    public static <K> GuardedObject create(K key) {\n        GuardedObject go = new GuardedObject();\n        goMap.put(key, go);\n        return go;\n    }\n\n    public static <K, T> void fireEvent(K key, T obj) {\n        GuardedObject go = goMap.remove(key);\n        if (go != null) {\n            go.onChange(obj);\n        }\n    }\n\n    // 获取受保护对象\n    public T get(Predicate<T> p) {\n        lock.lock();\n        try {\n            // MESA管程推荐写法\n            while (!p.test(obj)) {\n                done.await(TIMEOUT, TimeUnit.SECONDS);\n            }\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        } finally {\n            lock.unlock();\n        }\n        return obj;\n    }\n\n    // 事件通知方法\n    public void onChange(T obj) {\n        lock.lock();\n        try {\n            this.obj = obj;\n            done.signalAll();\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n```\n```java\npublic class FileBrowser {\n    // 发送消息\n    private void send(Message message) {\n    }\n\n    // MQ消息返回后调用该方法\n    public void onMessage(Message message) {\n        // 唤醒等待的线程\n        GuardedObject.fireEvent(message.getId(), message);\n    }\n\n    public Response handleWebReq() {\n        Long id = 1L;\n        Message message = new Message(id, \"123\");\n        GuardedObject go = GuardedObject.create(id);\n        // 发送消息\n        send(message);\n        // 等待MQ消息\n        go.get(Objects::nonNull);\n        return new Response();\n    }\n}\n\n@Data\n@AllArgsConstructor\nclass Message {\n    private Long id;\n    private String content;\n}\n\nclass Response {\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- ThreadLocal模式","url":"%2F2019%2F05%2F20%2Fjava-concurrent-thread-local%2F","content":"\n## 并发问题\n1. 多个线程同时读写同一个共享变量会存在并发问题\n2. Immutability模式和Copy-on-Write模式，突破的是**写**\n3. ThreadLocal模式，突破的是**共享变量**\n\n<!-- more -->\n\n## ThreadLocal的使用\n\n### 线程ID\n```java\npublic class ThreadLocalId {\n    private static final AtomicLong nextId = new AtomicLong(0);\n    private static final ThreadLocal<Long> TL = ThreadLocal.withInitial(\n            () -> nextId.getAndIncrement());\n\n    // 为每个线程分配一个唯一的ID\n    private static long get() {\n        return TL.get();\n    }\n}\n```\n\n### SimpleDateFormat\n```java\npublic class SafeDateFormat {\n    private static final ThreadLocal<DateFormat> TL = ThreadLocal.withInitial(\n            () -> new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"));\n\n    private static DateFormat get() {\n        return TL.get();\n    }\n}\n```\n\n## ThreadLocal的工作原理\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-thread-local.png\" width=800/>\n\n```java\npublic class Thread implements Runnable {\n    // 线程内部持有ThreadLocalMap\n    ThreadLocal.ThreadLocalMap threadLocals = null;\n}\n\npublic class ThreadLocal<T> {\n    public T get() {\n        // 获取当前线程持有的ThreadLocalMap\n        Thread t = Thread.currentThread();\n        ThreadLocalMap map = getMap(t);\n        if (map != null) {\n            // 在ThreadLocalMap中查找变量\n            ThreadLocalMap.Entry e = map.getEntry(this);\n            if (e != null) {\n                @SuppressWarnings(\"unchecked\")\n                T result = (T)e.value;\n                return result;\n            }\n        }\n        return setInitialValue();\n    }\n\n    ThreadLocalMap getMap(Thread t) {\n        return t.threadLocals;\n    }\n\n    static class ThreadLocalMap {\n        // 内部是数组而不是Map\n        private Entry[] table;\n        // 根据ThreadLocal查找Entry\n        private Entry getEntry(ThreadLocal<?> key) {\n        }\n\n        static class Entry extends WeakReference<ThreadLocal<?>> {\n            Object value;\n        }\n    }\n}\n```\n1. ThreadLocal仅仅是一个代理工具类，内部并不持有任何与线程相关的数据（存储在Thread里面）\n2. 不容易产生**内存泄露**，Thread持有ThreadLocalMap，而ThreadLocalMap对ThreadLocal的引用是**弱引用**\n    - 只要Thread被回收，那么ThreadLocalMap就能被回收\n3. 在**线程池**中使用ThreadLocal也有可能会导致内存泄露\n    - 因为线程池中线程的存活时间太长了，往往与程序同生共死\n    - 意味着Thread持有的ThreadLocalMap一直都不会被回收\n    - 可以通过try/finally手动释放\n\n```java\nprivate static final ExecutorService pool = Executors.newFixedThreadPool(1);\nprivate static final ThreadLocal<Object> TL = ThreadLocal.withInitial(() -> new Object());\n\npublic static void main(String[] args) {\n\n    pool.execute(() -> {\n        try {\n            TL.set(new Object());\n        } finally {\n            // 手动清理ThreadLocal\n            TL.remove();\n        }\n    });\n}\n```\n\n## InheritableThreadLocal\n1. 通过ThreadLocal创建的线程变量，其子线程是无法继承的，如果需要继承，则采用InheritableThreadLocal\n2. 不建议在线程池中使用InheritableThreadLocal\n    - 一方面，InheritableThreadLocal具有和ThreadLocal相同的缺点，可能会导致内存泄露\n    - 另一方面，线程池中的线程创建是动态的，容易导致**继承关系错乱**\n        - 如果业务逻辑依赖InheritableThreadLocal，有可能导致业务逻辑计算错误，比内存泄露更致命\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- Copy-on-Write模式","url":"%2F2019%2F05%2F19%2Fjava-concurrent-copy-on-write%2F","content":"\n## fork\n1. 类Unix操作系统调用fork()，会创建父进程的一个**完整副本**，很**耗时**\n2. Linux调用fork()，创建子进程时并不会复制整个进程的地址空间，而是让父子进程共享同一个地址空间\n    - 只有在父进程或者子进程需要写入时才会**复制**地址空间，从而使父子进程拥有各自**独立**的地址空间\n3. 本质上来说，父子进程的地址空间和数据都是要隔离的，使用Copy-on-Write更多体现的是一种**延时策略**\n4. Copy-on-Write还支持**按需复制**，因此在操作系统领域能够**提升性能**\n5. Java提供的Copy-on-Write容器，会复制**整个容器**，所以在**提升读操作性能**的同时，是以**内存复制**为代价的\n    - CopyOnWriteArrayList / CopyOnWriteArraySet\n\n<!-- more -->\n\n## RPC框架\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-copy-on-write-route-table.png\" width=500/>\n\n1. 服务提供方是**多实例分布式**部署的，服务的客户端在调用RPC时，会选定一个服务实例来调用\n2. 这个过程的本质是**负载均衡**，而做负载均衡的前提是客户端要有**全部的路由信息**\n3. 一个核心任务就是**维护服务的路由关系**，当服务提供方上线或者下线的时候，需要更新客户端的路由表信息\n4. RPC调用需要通过负载均衡器来计算目标服务的IP和端口号，负载均衡器通过路由表获取所有路由信息\n    - 访问路由表这个操作对**性能**的要求很高，但路由表对**数据一致性**要求不高\n\n```java\n// 采用Immutability模式，每次上线、下线都创建新的Router对象或删除对应的Router对象\n@Data\n@AllArgsConstructor\npublic class Router {\n    private final String ip;\n    private final Integer port;\n    private final String iFace;\n\n    @Override\n    public boolean equals(Object o) {\n        if (this == o) return true;\n        if (o == null || getClass() != o.getClass()) return false;\n        Router router = (Router) o;\n        return Objects.equals(ip, router.ip) &&\n                Objects.equals(port, router.port) &&\n                Objects.equals(iFace, router.iFace);\n    }\n\n    @Override\n    public int hashCode() {\n        return Objects.hash(ip, port, iFace);\n    }\n}\n\nclass RouterTable {\n    // <接口名 , 路由集合>\n    private ConcurrentHashMap<String, CopyOnWriteArraySet<Router>> routingTable = new ConcurrentHashMap<>();\n\n    // 获取路由\n    public Set<Router> get(String iFace) {\n        return routingTable.get(iFace);\n    }\n\n    // 增加路由\n    public void add(Router router) {\n        CopyOnWriteArraySet<Router> set = routingTable.computeIfAbsent(router.getIFace(),\n                iFace -> new CopyOnWriteArraySet<>());\n        set.add(router);\n    }\n\n    // 删除路由\n    public void remove(Router router) {\n        CopyOnWriteArraySet<Router> set = routingTable.get(router.getIFace());\n        if (set != null) {\n            set.remove(router);\n        }\n    }\n}\n```\n\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- Immutability模式","url":"%2F2019%2F05%2F18%2Fjava-concurrent-immutability%2F","content":"\n## Immutability模式\nImmutability模式：对象一旦被创建之后，状态就不再发生变化\n\n## 不可变类\n1. 将一个类**所有的属性**都设置成**final**，并且只允许存在**只读**方法\n2. 将**类**也设置成**final**的，因为子类可以重写父类的方法，有可能改变不可变性\n\n<!-- more -->\n\n## 包装类\n1. String、Integer、Long和Double等基础类型的包装类都具备不可变性\n2. 这些对象的线程安全都是靠不可变性来保证的\n3. 严格遵守：_**类和属性都是final的，所有方法均是只读的**_\n4. 如果具备不可变性的类，需要提供**修改**的功能，那会**创建一个新的不可变对象**\n    - 这会浪费内存空间，可以通过**享元模式**来优化\n\n```java\nprivate final char value[];\n\npublic String replace(char oldChar, char newChar) {\n    if (oldChar != newChar) {\n        int len = value.length;\n        int i = -1;\n        char[] val = value; /* avoid getfield opcode */\n\n        while (++i < len) {\n            if (val[i] == oldChar) {\n                break;\n            }\n        }\n        if (i < len) {\n            char buf[] = new char[len];\n            for (int j = 0; j < i; j++) {\n                buf[j] = val[j];\n            }\n            while (i < len) {\n                char c = val[i];\n                buf[i] = (c == oldChar) ? newChar : c;\n                i++;\n            }\n            // 创建一个新的String对象，原String对象不会发生变化\n            return new String(buf, true);\n        }\n    }\n    return this;\n}\n```\n\n## 享元模式\n1. 享元模式本质上是一个_**对象池**_\n2. Long内部维护了一个静态的对象池，仅缓存[-128,127]（利用率最高）之间的数字\n\n```java\npublic static Long valueOf(long l) {\n    final int offset = 128;\n    if (l >= -128 && l <= 127) { // will cache\n        return LongCache.cache[(int)l + offset];\n    }\n    return new Long(l);\n}\n\n// 缓存，等价于对象池\nprivate static class LongCache {\n    private LongCache(){}\n\n    static final Long cache[] = new Long[-(-128) + 127 + 1];\n\n    static {\n        for(int i = 0; i < cache.length; i++)\n            cache[i] = new Long(i - 128);\n    }\n}\n```\n\n### 锁\n基本上所有基础类型的包装类都不适合做锁，因为它们内部用到了享元模式\n```java\n// al和bl是同一个对象\nclass A {\n    private Long al = Long.valueOf(1);\n\n    public void set() {\n        synchronized (al) {\n        }\n    }\n}\n\nclass B {\n    private Long bl = Long.valueOf(1);\n\n    public void set() {\n        synchronized (bl) {\n        }\n    }\n}\n```\n\n## 注意事项\n\n### 不可变性的边界\n1. 对象的所有属性都是final，也并不能保证不可变性\n2. 需要明确不可变性的**边界**，是否要求属性对象也具有不可变性\n\n```java\n@Data\nclass Foo {\n    private int age = 0;\n    private String name = \"abc\";\n}\n\nfinal class Bar {\n    private final Foo foo = new Foo();\n\n    public void setAge(int age) {\n        // 属性foo虽然是final，但依然可以通过setAge修改foo的属性age\n        foo.setAge(age);\n    }\n}\n```\n\n### 正确发布\n不可变对象是线程安全的，但并不意味着引用这些不可变对象的对象也是线程安全的\n```java\n// C 线程安全\n@Data\nfinal class C {\n    final int age = 0;\n    final String name = \"abc\";\n}\n\n// D 线程不安全\nclass D {\n    private C c;\n\n    // 在多线程环境下，并不能保证可见性和原子性\n    // 如果仅需保证可见性，无需保证原子性，可以用volatile修饰c\n    // 如果需要保证原子性，可以通过原子类来实现\n    public void setC(C c) {\n        this.c = c;\n    }\n}\n```\n\n## 无状态\n1. 具备**不可变性**的对象，**只有一种状态**，这个状态由对象内部所有的不可变属性共同决定的\n2. 还有一种更简单的不可变对象，即**无状态**，无状态对象内部**没有属性**，只有方法\n3. 无状态的核心优势是**性能**\n    - 在多线程领域，无状态对象没有线程安全问题，无需同步处理\n    - 在分布式领域，无状态服务可以无限地水平扩展\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- Fork + Join","url":"%2F2019%2F05%2F17%2Fjava-concurrent-fork-join%2F","content":"\n## 任务视角\n1. 线程池+Future：**简单并行任务**\n2. CompletableFuture：**聚合任务**\n3. CompletionService：**批量并行任务**\n4. Fork/Join：_**分治**_\n\n<!-- more -->\n\n## 分治任务模型\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-divide.png\" width=800/>\n\n1. 分治任务模型分为两个阶段：任务分解 + 结果合并\n2. **任务分解**：将任务迭代地分解为子任务，直至子任务可以**直接计算**出结果\n    - 任务和分解后的子任务具有**相似性**（算法相同，只是计算的数据规模不同，往往采用**递归**算法）\n3. **结果合并**：逐层合并子任务的执行结果，直至获得最终结果\n\n## Fork/Join\n\n### 概述\n1. Fork/Join是**并行计算**的框架，主要用来支持分治任务模型，Fork对应任务分解，Join对应结果合并\n2. Fork/Join框架包含两部分：分治任务**ForkJoinTask** + 分治任务线程池**ForkJoinPool**\n    - 类似于Runnable + ThreadPoolExecutor\n3. ForkJoinTask最核心的方法是**fork**和**join**\n    - fork：异步地执行一个子任务\n    - join：阻塞当前线程，等待子任务的执行结果\n4. ForkJoinTask有两个子类：RecursiveAction + RecursiveTask\n    - Recursive：通过**递归**的方式来处理分治任务\n    - RecursiveAction.compute：没有返回值\n    - RecursiveTask.compute：有返回值\n\n### 简单使用\n```java\n// 递归任务\n@AllArgsConstructor\nclass Fibonacci extends RecursiveTask<Integer> {\n    private final int n;\n\n    @Override\n    protected Integer compute() {\n        if (n <= 1) {\n            return n;\n        }\n        // 创建子任务\n        Fibonacci f1 = new Fibonacci(n - 1);\n        f1.fork();\n        Fibonacci f2 = new Fibonacci(n - 2);\n        f2.fork();\n        // 等待子任务结果并合并\n        return f1.join() + f2.join();\n    }\n}\n\n// 创建分治任务线程池\nForkJoinPool pool = new ForkJoinPool(4);\n// 创建分治任务\nFibonacci fibonacci = new Fibonacci(30);\n// 启动分治任务\nSystem.out.println(pool.invoke(fibonacci)); // 832040\n```\n\n### ForkJoinPool的工作原理\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-fork-join-pool.png\" width=800/>\n\n1. Fork/Join并行计算的核心组件是ForkJoinPool\n2. ThreadPoolExecutor本质上是**生产者-消费者**模式的实现\n    - 内部有一个**任务队列**，该任务队列是生产者和消费者通信的媒介\n    - ThreadPoolExecutor可以有**多个工作线程**，但这些工作线程都_**共享一个任务队列**_\n3. ForkJoinPool本质上也是**生产者-消费者**模式的实现，但更加**智能**\n    - ThreadPoolExecutor内部只有一个任务队列，而ForkJoinPool内部有**多个任务队列**\n    - 当通过invoke或submit**提交任务**时，ForkJoinPool会根据一定的**路由规则**把任务提交到一个任务队列\n        - 如果任务在执行过程中**创建子任务**，那么该子任务被会提交到**工作线程对应的任务队列**中\n    - ForkJoinPool支持**任务窃取**，如果工作线程空闲了，那么它会窃取其他任务队列里的任务\n    - ForkJoinPool的任务队列是_**双端队列**_\n        - 工作线程**正常获取任务**和**窃取任务**分别从任务队列**不同的端**消费，避免不必要的数据竞争\n\n## 统计单词数量\n```java\n@AllArgsConstructor\nclass MapReduce extends RecursiveTask<Map<String, Long>> {\n    private String[] fc;\n    private int start;\n    private int end;\n\n    @Override\n    protected Map<String, Long> compute() {\n        if (end - start == 1) {\n            return calc(fc[start]);\n        } else {\n            int mid = (start + end) / 2;\n            // 前半部分数据fork一个递归任务\n            MapReduce mr1 = new MapReduce(fc, start, mid);\n            mr1.fork();\n            // 后半部分数据在当前任务中递归处理\n            MapReduce mr2 = new MapReduce(fc, mid, end);\n            // 计算子任务，返回合并的结果\n            return merge(mr2.compute(), mr1.join());\n        }\n    }\n\n    // 统计单词数量\n    private Map<String, Long> calc(String line) {\n        Map<String, Long> result = new HashMap<>();\n        String[] words = line.split(\"\\\\s+\");\n        for (String word : words) {\n            if (result.containsKey(word)) {\n                result.put(word, result.get(word) + 1);\n            } else {\n                result.put(word, 1L);\n            }\n        }\n        return result;\n    }\n\n    // 合并结果\n    private Map<String, Long> merge(Map<String, Long> r1, Map<String, Long> r2) {\n        Map<String, Long> result = new HashMap<>(r1);\n        r2.forEach((word, count) -> {\n            if (result.containsKey(word)) {\n                result.put(word, result.get(word) + count);\n            } else {\n                result.put(word, count);\n            }\n        });\n        return result;\n    }\n}\n\nString[] fc = {\"hello world\",\n        \"hello me\",\n        \"hello fork\",\n        \"hello join\",\n        \"fork join in world\"};\nForkJoinPool pool = new ForkJoinPool(3);\nMapReduce mapReduce = new MapReduce(fc, 0, fc.length);\nMap<String, Long> result = pool.invoke(mapReduce);\nresult.forEach((word, count) -> System.out.println(word + \" : \" + count));\n```\n\n## 小结\n1. Fork/Join并行计算框架主要解决的是**分治任务**，分治的核心思想是_**分而治之**_\n2. Fork/Join并行计算框架的核心组件是**ForkJoinPool**，支持**任务窃取**，让所有线程的工作量基本**均衡**\n3. Java 1.8提供的**Stream API**里的并行流是以ForkJoinPool为基础的\n    - 默认情况下，所有并行流计算都**共享一个ForkJoinPool**，该共享的ForkJoinPool的线程数是**CPU核数**\n    - 如果存在**IO密集型**的并行流计算，那可能会因为一个很慢的IO计算而影响整个系统的**性能**\n    - 因此，建议_**用不同的ForkJoinPool执行不同类型的计算任务**_\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- CompletionService","url":"%2F2019%2F05%2F15%2Fjava-concurrent-completion-service%2F","content":"\n## 场景\n```java\n// 从3个电商询价，保存到数据库，串行执行，性能很慢\nint p1 = getPriceByS1();\nsave(p1);\nint p2 = getPriceByS2();\nsave(p2);\nint p3 = getPriceByS3();\nsave(p3);\n```\n\n<!-- more -->\n\n## ThreadPoolExecutor + Future\n```java\nExecutorService pool = Executors.newFixedThreadPool(3);\nFuture<Integer> f1 = pool.submit(() -> getPriceByS1());\nFuture<Integer> f2 = pool.submit(() -> getPriceByS2());\nFuture<Integer> f3 = pool.submit(() -> getPriceByS3());\n\nint p1 = f1.get(); // 阻塞，如果f2.get()很快，但f1.get()很慢，依旧需要等待\npool.execute(() -> save(p1));\nint p2 = f2.get();\npool.execute(() -> save(p2));\nint p3 = f3.get();\npool.execute(() -> save(p3));\n```\n\n## BlockingQueue\n```java\nExecutorService pool = Executors.newFixedThreadPool(3);\nFuture<Integer> f1 = pool.submit(() -> getPriceByS1());\nFuture<Integer> f2 = pool.submit(() -> getPriceByS2());\nFuture<Integer> f3 = pool.submit(() -> getPriceByS3());\n\nBlockingQueue<Integer> queue = new LinkedBlockingQueue<>();\npool.execute(() -> {\n    try {\n        // 先执行完先入队\n        queue.put(f1.get());\n    } catch (Exception ignored) {\n    }\n});\n\npool.execute(() -> {\n    try {\n        queue.put(f2.get());\n    } catch (Exception ignored) {\n    }\n});\n\npool.execute(() -> {\n    try {\n        queue.put(f3.get());\n    } catch (Exception ignored) {\n    }\n});\n\nfor (int i = 0; i < 3; i++) {\n    int price = queue.take();\n    pool.execute(() -> save(price));\n}\n```\n\n## CompletionService\n1. CompletionService的实现原理：内部维护了一个**阻塞队列**，把任务执行结果的**Future对象**加入到阻塞队列中\n2. CompletionService的实现类是ExecutorCompletionService\n\n### 构造函数\n```java\n// 默认使用无界的LinkedBlockingQueue\npublic ExecutorCompletionService(Executor executor);\npublic ExecutorCompletionService(Executor executor, BlockingQueue<Future<V>> completionQueue);\n```\n\n### 简单使用\n```java\nExecutorService pool = Executors.newFixedThreadPool(3);\nCompletionService service = new ExecutorCompletionService(pool);\n// 异步执行\npool.submit(() -> getPriceByS1());\npool.submit(() -> getPriceByS2());\npool.submit(() -> getPriceByS3());\nfor (int i = 0; i < 3; i++) {\n    // take会阻塞线程，先执行完先消费\n    Object price = service.take().get();\n    pool.execute(() -> {\n        try {\n            save((Integer) price);\n        } catch (Exception ignored) {\n        }\n    });\n}\n```\n\n### take + poll\n```java\n// 如果阻塞队列为空，线程阻塞\npublic Future<V> take() throws InterruptedException;\n// 如果阻塞队列为空，返回null\npublic Future<V> poll();\n// 等待一段时间，阻塞队列依然为空，返回null\npublic Future<V> poll(long timeout, TimeUnit unit) throws InterruptedException;\n```\n\n### Forking Cluster\n支持**并行**地调用多个查询服务，只要有一个成功返回结果，整个服务就可以返回了，利用CompletionService可以实现\n```java\nExecutorService pool = Executors.newFixedThreadPool(3);\nCompletionService<Integer> service = new ExecutorCompletionService<>(pool);\nList<Future<Integer>> futures = new ArrayList<>(3);\n\nfutures.add(service.submit(() -> geoCoderByS1()));\nfutures.add(service.submit(() -> geoCoderByS2()));\nfutures.add(service.submit(() -> geoCoderByS3()));\n\ntry {\n    // 获取第一个返回（take会阻塞）\n    Integer price = service.take().get();\n} catch (Exception ignored) {\n    // 取消所有任务\n    for (Future<Integer> future : futures) {\n        future.cancel(true);\n    }\n}\n```\n\n## 小结\n1. CompletionService的应用场景：_**批量提交异步任务**_\n2. CompletionService将线程池**Executor**和阻塞队列**BlockingQueue**融合在一起，使得批量异步任务的管理更简单\n3. CompletionService能够让异步任务的执行结果有序化，**先执行完的先进入阻塞队列**，避免无谓的等待\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- CompletableFuture","url":"%2F2019%2F05%2F15%2Fjava-concurrent-completable-future%2F","content":"\n## 泡茶烧水\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-completable-future-tea.png\" width=800/>\n\n\n<!-- more -->\n\n```java\nCompletableFuture<Void> f1 = CompletableFuture.runAsync(() -> {\n    System.out.println(\"T1: 洗水壶\");\n    sleep(1, TimeUnit.SECONDS);\n    System.out.println(\"T1: 烧开水\");\n    sleep(15, TimeUnit.SECONDS);\n});\n\nCompletableFuture<String> f2 = CompletableFuture.supplyAsync(() -> {\n    System.out.println(\"T2: 洗茶壶\");\n    sleep(1, TimeUnit.SECONDS);\n    System.out.println(\"T2: 洗茶杯\");\n    sleep(2, TimeUnit.SECONDS);\n    System.out.println(\"T2: 拿茶叶\");\n    sleep(1, TimeUnit.SECONDS);\n    return \"龙井\";\n});\n\nCompletableFuture<String> f3 = f1.thenCombine(f2, (__, tea) -> {\n    System.out.println(\"T3: 拿到茶叶: \" + tea);\n    System.out.println(\"T3: 泡茶\");\n    return \"上茶: \" + tea;\n});\n\nSystem.out.println(f3.join());\n```\n\n## 创建CompletableFuture对象\n```java\n// 默认线程池，采用公共的ForkJoinPool线程池，线程数为CPU核数\n// 如果所有的CompletableFuture共享同一个线程池，一旦有任务有慢IO操作，会导致其他线程饥饿，影响系统性能\n// 所以，应该根据不同的业务类型创建不同的线程池，避免相互干扰\npublic static CompletableFuture<Void> runAsync(Runnable runnable);\n// Runnable.run没有返回值，Supplier.get有返回值\npublic static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier);\n\n// 指定线程池\npublic static CompletableFuture<Void> runAsync(Runnable runnable, Executor executor);\npublic static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier, Executor executor);\n\n// 创建完CompletableFuture对象之后，会自动地异步执行Runnable.run或者Supplier.get\n```\n\n## CompletionStage\n```\n// CompletionStage接口可以清晰地描述任务之间的时序关系，例如串行关系、并行关系和汇聚关系（AND、OR）等\n// CompletionStage接口也可以方便地描述异常处理\npublic class CompletableFuture<T> implements Future<T>, CompletionStage<T>\n```\n\n### 串行关系\n```java\npublic <U> CompletableFuture<U> thenApply(Function<? super T,? extends U> fn);\npublic <U> CompletionStage<U> thenApplyAsync(Function<? super T,? extends U> fn);\npublic <U> CompletionStage<U> thenApplyAsync(Function<? super T,? extends U> fn, Executor executor);\n\npublic CompletableFuture<Void> thenAccept(Consumer<? super T> action);\npublic CompletionStage<Void> thenAcceptAsync(Consumer<? super T> action);\npublic CompletionStage<Void> thenAcceptAsync(Consumer<? super T> action, Executor executor);\n\npublic CompletableFuture<Void> thenRun(Runnable action);\npublic CompletionStage<Void> thenRunAsync(Runnable action);\npublic CompletionStage<Void> thenRunAsync(Runnable action, Executor executor);\n\n// 新建一个子流程，最终结果与thenApply相同\npublic <U> CompletableFuture<U> thenCompose(Function<? super T, ? extends CompletionStage<U>> fn);\npublic <U> CompletionStage<U> thenComposeAsync(Function<? super T, ? extends CompletionStage<U>> fn);\npublic <U> CompletionStage<U> thenComposeAsync(Function<? super T, ? extends CompletionStage<U>> fn, Executor executor);\n```\n```java\n// supplyAsync会启动一个异步流程，步骤1、2、3是串行执行的\nCompletableFuture<String> f = CompletableFuture\n        .supplyAsync(() -> \"Hello World\") // 1\n        .thenApply(s -> s + \" QQ\") // 2\n        .thenApply(String::toUpperCase); // 3\nSystem.out.println(f.join()); // HELLO WORLD QQ\n```\n\n### AND 汇聚关系\n```java\npublic <U,V> CompletionStage<V> thenCombine (CompletionStage<? extends U> other, BiFunction<? super T,? super U,? extends V> fn);\npublic <U,V> CompletionStage<V> thenCombineAsync(CompletionStage<? extends U> other, BiFunction<? super T,? super U,? extends V> fn);\npublic <U,V> CompletionStage<V> thenCombineAsync(CompletionStage<? extends U> other, BiFunction<? super T,? super U,? extends V> fn, Executor executor);\n\npublic <U> CompletionStage<Void> thenAcceptBoth(CompletionStage<? extends U> other, BiConsumer<? super T, ? super U> action);\npublic <U> CompletionStage<Void> thenAcceptBothAsync(CompletionStage<? extends U> other, BiConsumer<? super T, ? super U> action);\npublic <U> CompletionStage<Void> thenAcceptBothAsync(CompletionStage<? extends U> other, BiConsumer<? super T, ? super U> action, Executor executor);\n\npublic CompletionStage<Void> runAfterBoth(CompletionStage<?> other, Runnable action);\npublic CompletionStage<Void> runAfterBothAsync(CompletionStage<?> other, Runnable action);\npublic CompletionStage<Void> runAfterBothAsync(CompletionStage<?> other, Runnable action, Executor executor);\n```\n\n### OR 汇聚关系\n```java\npublic <U> CompletionStage<U> applyToEither(CompletionStage<? extends T> other, Function<? super T, U> fn);\npublic <U> CompletionStage<U> applyToEitherAsync(CompletionStage<? extends T> other, Function<? super T, U> fn);\npublic <U> CompletionStage<U> applyToEitherAsync(CompletionStage<? extends T> other, Function<? super T, U> fn, Executor executor);\n\npublic CompletionStage<Void> acceptEither(CompletionStage<? extends T> other, Consumer<? super T> action);\npublic CompletionStage<Void> acceptEitherAsync(CompletionStage<? extends T> other, Consumer<? super T> action);\npublic CompletionStage<Void> acceptEitherAsync(CompletionStage<? extends T> other, Consumer<? super T> action, Executor executor);\n\npublic CompletionStage<Void> runAfterEither(CompletionStage<?> other, Runnable action);\npublic CompletionStage<Void> runAfterEitherAsync(CompletionStage<?> other, Runnable action);\npublic CompletionStage<Void> runAfterEitherAsync(CompletionStage<?> other, Runnable action, Executor executor);\n```\n```java\nCompletableFuture<String> f1 = CompletableFuture.supplyAsync(() -> {\n    int t = getRandom();\n    System.out.println(\"f1 need \" + t);\n    sleep(t, TimeUnit.SECONDS);\n    System.out.println(\"f1 done\");\n    return \"f1 takes \" + String.valueOf(t);\n});\n\nCompletableFuture<String> f2 = CompletableFuture.supplyAsync(() -> {\n    int t = getRandom();\n    System.out.println(\"f2 need \" + t);\n    sleep(t, TimeUnit.SECONDS);\n    System.out.println(\"f2 done\");\n    return \"f2 takes \" + String.valueOf(t);\n});\n\nCompletableFuture<String> f3 = f1.applyToEither(f2, s -> s);\nf3.join();\n\n// f1 need 9\n// f2 need 1\n// f2 done\n```\n\n### 异常处理\n```java\npublic CompletionStage<T> exceptionally(Function<Throwable, ? extends T> fn);\n\npublic CompletionStage<T> whenComplete(BiConsumer<? super T, ? super Throwable> action);\npublic CompletionStage<T> whenCompleteAsync(BiConsumer<? super T, ? super Throwable> action);\npublic CompletionStage<T> whenCompleteAsync(BiConsumer<? super T, ? super Throwable> action, Executor executor);\n\npublic <U> CompletionStage<U> handle(BiFunction<? super T, Throwable, ? extends U> fn);\npublic <U> CompletionStage<U> handleAsync(BiFunction<? super T, Throwable, ? extends U> fn);\npublic <U> CompletionStage<U> handleAsync(BiFunction<? super T, Throwable, ? extends U> fn, Executor executor);\n```\n```java\nCompletableFuture<Integer> f = CompletableFuture\n        .supplyAsync(() -> 1 / 0)\n        .thenApply(i -> i * 10)\n        .exceptionally(t -> 0) // 类似于catch{}\n        .whenComplete((i, t) -> { // 类似于finally，whenComplete不支持返回结果，handle支持返回结果\n        });\n\nSystem.out.println(f.join()); // 0\n```\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- Future","url":"%2F2019%2F05%2F14%2Fjava-concurrent-future%2F","content":"\n## ThreadPoolExecutor\n```java\n// 无法获取任务的执行结果\npublic void execute(Runnable command);\n\n// 可以获取任务的执行结果\n// Runnable接口的run()方法没有返回值，返回的Future只能断言任务是否已经结束，类似于Thread.join()\npublic Future<?> submit(Runnable task)\n// Callable接口的call()方法有返回值，可以通过调用返回的Future对象的get()方法获取任务的执行结果\npublic <T> Future<T> submit(Callable<T> task);\n// 返回的Future对象f，f.get()的返回值就是传给submit方法的参数result\npublic <T> Future<T> submit(Runnable task, T result)\n```\n\n<!-- more -->\n\n## Future\n```java\n// 取消任务\nboolean cancel(boolean mayInterruptIfRunning);\n// 判断任务是否已取消\nboolean isCancelled();\n// 判断任务是否已结束\nboolean isDone();\n// 获取任务执行结果\nV get() throws InterruptedException, ExecutionException;\n// 获取任务执行结果，支持超时\nV get(long timeout, TimeUnit unit)\n        throws InterruptedException, ExecutionException, TimeoutException;\n```\n\n```java\nExecutorService pool = Executors.newFixedThreadPool(1);\nResult result1 = new Result();\nFuture<Result> future = pool.submit(new Task(result1), result1); // Task implements Runnable\nResult result2 = future.get();\nSystem.out.println(result1 == result2); // true\n```\n\n## FutureTask\n```java\n// 继承关系\n// 实现了Runnable接口，可以将FutureTask对象作为任务提交给ThreadPoolExecutor，也可以被Thread执行\n// 实现了Future接口，也能获取任务的执行结果\nFutureTask<V> implements RunnableFuture<V>\nRunnableFuture<V> extends Runnable, Future<V>\n// 构造函数\npublic FutureTask(Callable<V> callable);\npublic FutureTask(Runnable runnable, V result);\n```\n```java\n// 线程池\nFutureTask<Integer> futureTask = new FutureTask<>(() -> 1 + 2);\nExecutorService pool = Executors.newCachedThreadPool();\npool.submit(futureTask);\nSystem.out.println(futureTask.get()); // 3\n```\n```java\n// 手动创建线程\nFutureTask<Integer> futureTask = new FutureTask<>(() -> 1 + 2);\nThread thread = new Thread(futureTask);\nthread.start();\nSystem.out.println(futureTask.get()); // 3\n```\n\n## 烧水泡茶\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-future-tea.png\" width=800/>\n\n```java\n// 创建两个FutureTask，ft1和ft2\n// ft1完成洗水壶、烧开水、泡茶的任务\n// ft2完成洗茶壶、洗茶杯、拿茶叶的任务\n// ft1在执行泡茶前，需要等待ft2把茶叶拿来\npublic class Tea {\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n        FutureTask<String> ft2 = new FutureTask<>(new T2());\n        FutureTask<String> ft1 = new FutureTask<>(new T1(ft2));\n        Thread t1 = new Thread(ft1);\n        t1.start();\n        Thread t2 = new Thread(ft2);\n        t2.start();\n        System.out.println(ft1.get());\n    }\n}\n\n@AllArgsConstructor\nclass T1 implements Callable<String> {\n    private FutureTask<String> ft2;\n\n    @Override\n    public String call() throws Exception {\n        System.out.println(\"T1: 洗水壶\");\n        TimeUnit.SECONDS.sleep(1);\n\n        System.out.println(\"T1: 烧开水\");\n        TimeUnit.SECONDS.sleep(15);\n\n        String tea = ft2.get();\n        System.out.println(\"T1: 拿到茶叶 \" + tea);\n        TimeUnit.SECONDS.sleep(1);\n\n        System.out.println(\"T1: 泡茶\");\n        return \"上茶：\" + tea;\n    }\n}\n\nclass T2 implements Callable<String> {\n    @Override\n    public String call() throws Exception {\n        System.out.println(\"T2: 洗茶壶\");\n        TimeUnit.SECONDS.sleep(1);\n\n        System.out.println(\"T2: 洗茶杯\");\n        TimeUnit.SECONDS.sleep(2);\n\n        System.out.println(\"T2: 拿茶叶\");\n        TimeUnit.SECONDS.sleep(1);\n        return \"龙井\";\n    }\n}\n```\n\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- 线程池","url":"%2F2019%2F05%2F14%2Fjava-concurrent-thread-pool%2F","content":"\n## 创建线程\n1. 创建普通对象，只是在JVM的**堆里**分配一块内存而已\n2. 创建线程，需要调用**操作系统内核的API**，然后操作系统需要为线程分配一系列资源，成本很高\n    - 线程是一个**重量级对象**，应该避免频繁创建和销毁，采用**线程池**方案\n\n<!-- more -->\n\n## 一般的池化资源\n```java\n// 假设Java线程池采用一般意义上池化资源的设计方法\nclass ThreadPool {\n    // 获取空闲线程\n    Thread acquire() {\n    }\n    // 释放线程\n    void release(Thread t) {\n    }\n}\n// 期望的使用\nThreadPool pool；\nThread T1 = pool.acquire();\n// 传入Runnable对象\nT1.execute(() -> {\n    // 具体业务逻辑\n});\n```\n\n## 生产者-消费者模式\n业界线程池的设计，普遍采用**生产者-消费者模式**，线程池的使用方是生产者，线程池本身是消费者\n```java\npublic class MyThreadPool {\n    // 工作线程负责消费任务并执行任务\n    class WorkerThread extends Thread {\n        @Override\n        public void run() {\n            // 循环取任务并执行\n            while (true) {\n                Runnable task = null;\n                try {\n                    task = workQueue.take();\n                } catch (InterruptedException e) {\n                }\n                task.run();\n            }\n        }\n    }\n\n    // 利用阻塞队列实现生产者-消费者模式\n    private BlockingQueue<Runnable> workQueue;\n    // 内部保存工作线程\n    List<WorkerThread> threads = new ArrayList<>();\n\n    public MyThreadPool(int poolSize, BlockingQueue<Runnable> workQueue) {\n        this.workQueue = workQueue;\n        for (int i = 0; i < poolSize; i++) {\n            WorkerThread work = new WorkerThread();\n            work.start();\n            threads.add(work);\n        }\n    }\n\n    // 提交任务\n    public void execute(Runnable command) throws InterruptedException {\n        workQueue.put(command);\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        // 创建有界阻塞队列\n        BlockingQueue<Runnable> workQueue = new LinkedBlockingQueue<>(2);\n        // 创建线程池\n        MyThreadPool pool = new MyThreadPool(10, workQueue);\n        // 提交任务\n        pool.execute(() -> {\n            System.out.println(\"hello\");\n        });\n    }\n}\n```\n\n## Java线程池\n\n### ThreadPoolExecutor\n```java\npublic ThreadPoolExecutor(int corePoolSize,\n                          int maximumPoolSize,\n                          long keepAliveTime,\n                          TimeUnit unit,\n                          BlockingQueue<Runnable> workQueue,\n                          ThreadFactory threadFactory,\n                          RejectedExecutionHandler handler)\n\n// 让所有线程都支持超时，如果线程池很闲，那么将撤销所有线程\npublic void allowCoreThreadTimeOut(boolean value)\n```\n1. corePoolSize：线程池保有的**最小**线程数\n2. maximumPoolSize：线程池创建的**最大**线程数\n3. keepAliveTime & unit\n    - 如果一个线程空闲了keepAliveTime & unit，并且线程池的线程数大于corePoolSize，那么这个空闲的线程就要被**回收**\n4. workQueue：工作队列\n5. threadFactory：自定义如何创建线程\n6. handler\n    - 线程池中的所有线程都很忙碌，并且工作队列也满了（工作队列是**有界**队列），此时提交任务，线程池会**拒绝接收**\n    - CallerRunsPolicy：提交任务的线程自己去执行该任务\n    - AbortPolicy：默认的拒绝策略，抛出RejectedExecutionException\n    - DiscardPolicy：直接丢弃任务，不会抛出任何异常\n    - DiscardOldestPolicy：丢弃最老的任务，然后把新任务加入到工作队列中\n\n### Executors\n1. 不建议使用Executors，因为Executors提供的很多默认方法使用的是**无界队列**LinkedBlockingQueue\n2. 在高负载的情况下，无界队列容易导致**OOM**，而OOM会导致所有请求都无法处理\n3. 因此强烈建议使用**有界队列**\n\n### 拒绝策略\n1. 使用**有界队列**，当任务过多时，线程池会触发**拒绝策略**\n2. 线程池默认的拒绝策略会抛出RejectedExecutionException，这是一个**运行时异常**，开发时很容易忽略\n3. 如果线程池处理的任务非常重要，可以自定义拒绝策略\n\n### 异常处理\n1. 使用ThreadPoolExecutor.execute()方法提交任务时，如果任务在执行过程中出现**运行时异常**\n    - 会导致执行任务的线程**终止**，并且**无法获得任何通知**\n2. 因此最稳妥的方法还是**捕获所有异常**并处理\n\n```java\ntry {\n    // 业务逻辑\n} catch (RuntimeException x) {\n    // 按需处理\n} catch (Throwable x) {\n    // 按需处理\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- 原子类","url":"%2F2019%2F05%2F13%2Fjava-concurrent-atomic%2F","content":"\n## add\n```java\nprivate long count = 0;\n\npublic void add() {\n    int idx = 0;\n    while (idx++ < 10_000) {\n        count += 1;\n    }\n}\n```\n1. add()方法不是线程安全的，主要原因是count的**可见性**和count+=1的**原子性**\n2. 可见性的问题可以用**volatile**来解决，原子性的问题一般采用**互斥锁**来解决\n\n<!-- more -->\n\n## 无锁方案\n```java\nprivate AtomicLong atomicCount = new AtomicLong(0);\n\npublic void atomicAdd() {\n    int idx = 0;\n    while (idx++ < 10_000) {\n        atomicCount.getAndIncrement();\n    }\n}\n```\n1. 无锁方案相对于互斥锁方案，最大的好处是_**性能**_\n2. 互斥锁方案为了保证互斥性，需要执行**加锁、解锁**操作，而加锁、解锁操作本身会消耗性能\n    - 拿不到锁的线程会进入**阻塞**状态，进而触发**线程切换**，线程切换对性能的消耗也很大\n3. 无锁方案则完全没有加锁、解锁的性能消耗，同时能保证**互斥性**\n\n### 实现原理\n1. CPU为了解决并发问题，提供了**CAS**（Compare And Swap）指令\n2. CAS指令包含三个参数：共享变量的内存地址A，用于比较的值B、共享变量的新值C\n3. _**只有当内存地址A处的值等于B时，才能将内存地址A处的值更新为新值C**_\n4. CAS指令是一条**CPU指令**，本身能保**证原子性**\n\n### 自旋\n```java\npublic class SimulatedCAS {\n    private volatile int count;\n\n    public void addOne() {\n        // 自旋\n        int newValue;\n        do {\n            newValue = count + 1; // 1\n        } while (count != cas(count, newValue)); // 2\n    }\n\n    // 模拟实现CAS\n    private synchronized int cas(int expect, int newValue) {\n        // 读取当前count的值\n        int curValue = count;\n        // 比较 当前count的值 是否等于 期望值\n        if (curValue == expect) {\n            count = newValue;\n        }\n        // 返回旧值\n        return curValue;\n    }\n}\n```\n1. 使用CAS解决并发问题，一般都会伴随着**自旋**（循环尝试）\n2. 首先计算newValue=count+1，如果count!=cas(count, newValue)\n    - 说明线程执行完代码1之后，在执行代码2之前，count的值被其他线程更新过，此时采用**自旋**（循环尝试）\n3. 通过**CAS+自旋**实现的无锁方案，完全没有加锁、解锁操作，不会阻塞线程，相对于互斥锁方案来说，性能提升了很多\n\n### ABA问题\n1. 上面的count==cas(count, newValue)，并不能说明执行完代码1之后，在执行代码2之前，count的值没有被其他线程更新过\n2. 假设count原本为A，线程T1在执行完代码1之后，执行代码2之前，线程T2将count更新为B，之后又被T3更新回A\n\n### count+=1 原子化\n```java\n// AtomicLong\npublic final long getAndIncrement() {\n    // this和valueOffset这两个参数可以唯一确定共享变量的内存地址\n    return unsafe.getAndAddLong(this, valueOffset, 1L);\n}\n\n// Unsafe\npublic final long getAndAddLong(Object o, long offset, long delta) {\n    long v;\n    do {\n        // 读取内存中的值\n        v = getLongVolatile(o, offset);\n    } while (!compareAndSwapLong(o, offset, v, v + delta));\n    return v;\n}\n\npublic native long getLongVolatile(Object o, long offset);\n\n// 原子性地将变量更新为x，条件是内存中的值等于expected，更新成功则返回true\n// compareAndSwapLong的语义和CAS指令的语义的差别，仅仅只是返回值不同而已\npublic final native boolean compareAndSwapLong(Object o, long offset, long expected, long x);\n```\n\n## 原子类\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-atomic.png\" width=1000/>\n\n\n### 原子化的基本类型\n相关实现有AtomicBoolean、AtomicInteger和AtomicLong\n```java\ngetAndIncrement() // 原子化 i++\ngetAndDecrement() // 原子化的 i--\nincrementAndGet() // 原子化的 ++i\ndecrementAndGet() // 原子化的 --i\n// 当前值 +=delta，返回 += 前的值\ngetAndAdd(delta)\n// 当前值 +=delta，返回 += 后的值\naddAndGet(delta)\n// CAS操作，返回是否成功\ncompareAndSet(expect, update)\n\n// 以下四个方法\n// 新值可以通过传入func函数来计算\ngetAndUpdate(func)\nupdateAndGet(func)\ngetAndAccumulate(x,func)\naccumulateAndGet(x,func)\n```\n\n### 原子化的对象引用类型\n1. 相关实现有AtomicReference、AtomicStampedReference和AtomicMarkableReference，可以实现**对象引用的原子化更新**\n2. 对象引用的更新需要重点关注**ABA问题**，而**AtomicStampedReference**和**AtomicMarkableReference**可以解决ABA问题\n\n#### AtomicStampedReference\n```java\npublic boolean compareAndSet(V   expectedReference,\n                             V   newReference,\n                             int expectedStamp,\n                             int newStamp)\n```\n1. 通过增加一个**版本号**即可解决ABA问题\n2. 每次执行CAS操作时，附加再更新一个版本号，只要保证版本号是**递增**的，即使A->B->A，版本号也不会回退\n\n#### AtomicMarkableReference\n将版本号简化成一个**Boolean值**\n```java\npublic boolean compareAndSet(V       expectedReference,\n                             V       newReference,\n                             boolean expectedMark,\n                             boolean newMark)\n```\n\n### 原子化的数组\n1. 相关实现有AtomicIntegerArray、AtomicLongArray和AtomicReferenceArray\n2. 利用这些原子类，可以原子化地更新数组里面的每一个**元素**\n\n### 原子化的对象属性更新器\n1. 相关实现有AtomicIntegerFieldUpdater、AtomicLongFieldUpdater和AtomicReferenceFieldUpdater\n2. 利用这些原子类，都可以原子化地更新对象的属性，这三个方法都是利用**反射机制**实现的\n3. 对象属性必须是**volatile**类型，只有这样才能保证**可见性**\n    - 如果对象属性不是volatile类型的，newUpdater会抛出IllegalArgumentException\n\n```java\n// AtomicLongFieldUpdater\npublic static <U> AtomicLongFieldUpdater<U> newUpdater(Class<U> tclass, String fieldName);\n// AtomicLongFieldUpdater#CASUpdater\npublic final boolean compareAndSet(T obj, long expect, long update)\n// AtomicLongFieldUpdater#LockedUpdater\npublic final boolean compareAndSet(T obj, long expect, long update)\n```\n\n### 原子化的累加器\n1. 相关实现有DoubleAccumulator、DoubleAdder、LongAccumulator和LongAdder\n2. 这几个原子类仅仅用来执行累加操作，相比于原子化的基本数据类型，**速度更快**，但不支持**compareAndSet**\n3. 如果仅仅需要累加操作，使用原子化的累加器的性能会更好\n\n## 小结\n1. 无锁方案相对于互斥锁方案，性能更好，不会出现死锁问题，但可能出现**饥饿**和**活锁**问题（由于**自旋**）\n2. Java提供的原子类只能够解决一些**简单**的原子性问题\n    - 所有原子类的方法都是针对**单个共享变量**的，如果需要解决多个变量的原子性问题，还是要采用**互斥锁**的方案\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- 并发容器","url":"%2F2019%2F05%2F12%2Fjava-concurrent-concurrent-container%2F","content":"\n## 同步容器\n1. Java 1.5之前提供的**同步容器**虽然也能保证**线程安全**，但**性能很差**\n2. Java中的容器主要分为四大类，分别为List、Map、Set和Queue，并不是所有的Java容器都是线程安全的\n3. 将**非线程安全**的容器变成**线程安全**的容器的简单方案：**synchronized**\n    - 把非线程安全的容器封装在对象内部，然后控制好**访问路径**即可\n\n<!-- more -->\n\n### 线程安全的ArrayList\n```java\npublic class SafeArrayList<T> {\n    private List<T> list = new ArrayList<>();\n\n    public synchronized T get(int idx) {\n        return list.get(idx);\n    }\n\n    public synchronized void add(int idx, T t) {\n        list.add(idx, t);\n    }\n\n    public synchronized boolean addIfNotExist(T t) {\n        if (!list.contains(t)) {\n            list.add(t);\n            return true;\n        }\n        return false;\n    }\n}\n```\n\n### Collections.synchronized\n```java\nCollections.synchronizedList(new ArrayList());\nCollections.synchronizedSet(new HashSet());\nCollections.synchronizedMap(new HashMap());\n```\n\n### 组合操作存在竟态条件问题\n1. 上面的addIfNotExist就包含**组合操作**\n2. 组合操作往往隐藏着**竟态条件问题**，即便每个操作都能保证原子性，也不能保证组合操作的原子性\n3. 用迭代器遍历同步容器也存在竟态条件问题，因为_**组合操作不具备原子性**_\n\n```java\n// 存在竟态条件问题\nList<Object> list = Collections.synchronizedList(new ArrayList<>());\nIterator<Object> iterator = list.iterator();\nwhile (iterator.hasNext()) {\n    process(iterator.next());\n}\n\n// 并发安全，先锁住list再执行遍历操作\nList<Object> list = Collections.synchronizedList(new ArrayList<>());\nsynchronized (list) {\n    Iterator<Object> iterator = list.iterator();\n    while (iterator.hasNext()) {\n        process(iterator.next());\n    }\n}\n```\n## 并发容器\n1. Java在1.5之前所谓的**线程安全**容器，主要指的是**同步容器**\n2. 同步容器最大的问题是**性能差**，所有方法都用**synchronized**来保证互斥，**串行度太高**\n3. 在Java 1.5提供了性能更高的容器，称为**并发容器**\n\n### 分类\n并发容器数量众多，但依旧可以分成四大类：List、Map、Set和Queue\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-concurrent-container.png\" width=1000/>\n\n\n### List\n1. List里面只有一个实现类就是**CopyOnWriteArrayList**\n2. CopyOnWrite即在执行**写操作**的时候会将共享变量**重新复制**一份出来，这样的好处是**读操作**是**完全无锁**的\n3. CopyOnWriteArrayList内部维护一个**数组**，成员变量array指向这个内部数组，所有的读操作都是基于array进行的\n4. 如果在遍历array的同时，还有一个写操作\n    - 会将array复制一份，然后在新复制的数组上执行写操作，执行完之后再将array指向这个新的数组\n5. **因此读写是并行的， 遍历操作一直都是基于原array执行的，而写操作则是基于新array执行的**\n6. 应用场景：仅适用于**写操作非常少**的场景，而且能够容忍**读写的短暂不一致**\n7. CopyOnWriteArrayList的迭代器是**只读**的，不支持增删改，因为对**快照**进行增删改是没有意义的\n\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-concurrent-copyonwritearraylist-iteration.png\" width=800/>\n\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-concurrent-copyonwritearraylist-add.png\" width=800/>\n\n\n### Map\n1. Map接口的两个实现：ConcurrentHashMap和ConcurrentSkipListMap\n2. ConcurrentHashMap的key是**无序**的，而ConcurrentSkipListMap的key是**有序**的\n3. ConcurrentSkipListMap里面的SkipList本身是一种数据结构，翻译成**跳表**\n    - 跳表执行插入、删除和查询操作的平均复杂度为**O(log n)**\n    - 理论上**与并发线程数无关**，适用于**并发度非常高**的情况（ConcurrentHashMap的性能也不能满足要求）\n\n| 集合类 | Key | Value | 线程安全 |\n| ---- | ---- | ---- | ---- |\n| HashMap | _**允许为null**_ | _**允许为null**_ | 否 |\n| TreeMap | 不允许为null | _**允许为null**_ | 否 |\n| HashTable | 不允许为null | 不允许为null | 是 |\n| ConcurrentHashMap | 不允许为null | 不允许为null | 是 |\n| ConcurrentSkipListMap | 不允许为null | 不允许为null | 是 |\n\n### Set\n1. Set接口的两个实现：CopyOnWriteArraySet和ConcurrentSkipListSet\n2. 原理与CopyOnWriteArrayList和ConcurrentSkipListMap类似\n\n### Queue\n1. JUC中的Queue类的并发容器是最复杂的，可以从两个维度分类，**阻塞/非阻塞**、**单端/双端**\n2. 阻塞/非阻塞：阻塞指的是当队列已满时，入队操作阻塞；当队列已空时，出队操作阻塞\n3. 单端/双端：单端指的是只能队尾入队，队首出队；双端指的是队首队尾皆可出队入队\n4. 在JUC中，阻塞队列用**Blocking**关键字标识，单端队列用**Queue**标识，双端队列用**Qeque**标识\n\n#### 单端阻塞队列\n1. 其实现包括\n    - ArrayBlockingQueue\n    - LinkedBlockingQueue\n    - SynchronousQueue\n    - LinkedTransferQueue\n    - PriorityBlockingQueue\n    - DelayQueue\n2. 内部一般都会持有一个**队列**\n    - 该队列可以是**数组**（ArrayBlockingQueue）\n    - 也可以是**链表**（LinkedBlockingQueue）\n    - 甚至**不持有**队列（SynchronousQueue），_**生产者线程的入队操作必须等待消费者线程都出队操作**_\n3. LinkedTransferQueue融合了LinkedBlockingQueue和SynchronousQueue的功能，性能比LinkedBlockingQueue更好\n4. PriorityBlockingQueue支持按**优先级**出队\n5. DelayQueue支持**延时**队列\n\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-single-ended-blocking-queue.png\" width=800/>\n\n\n#### 双端阻塞队列\n其实现是LinkedBlockingDeque\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-double-ended-blocking-queue.png\" width=800/>\n\n\n#### 单端非阻塞队列\n其实现是ConcurrentLinkedQueue\n\n#### 双端非阻塞队列\n其实现是ConcurrentLinkedDeque\n\n#### 是否有界\n1. 使用队列时，要格外注意队列是否支持**有界**\n2. 实际工作中，一般不建议使用**无界**的队列，因为有可能会导致_**OOM**_\n3. 上面提到的Queue，只有**ArrayBlockingQueue**和**LinkedBlockingQueue**是支持有界的\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- CountDownLatch + CyclicBarrier","url":"%2F2019%2F05%2F11%2Fjava-concurrent-countdown-latch-cyclic-barrier%2F","content":"\n## 对账系统\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-reconciliation-system.png\" width=800/>\n\n\n<!-- more -->\n\n```java\n// 存在未对账订单\nwhile (existUnreconciledOrders()) {\n    // 查询未对账订单\n    pOrder = getPOrder();\n    // 查询派送订单\n    dOrder = getDOrder();\n    // 执行对账操作\n    Order diff = check(pOrder, dOrder);\n    // 将差异写入差异库\n    save(diff);\n}\n```\n\n## 性能瓶颈\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-reconciliation-system-single-thread.png\" width=800/>\n\ngetPOrder()和getDOrder()最为耗时，并且两个操作没有先后顺序的依赖，可以**并行处理**\n\n## 简单并行 - join\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-reconciliation-system-multi-thread-join.png\" width=800/>\n\n```java\n// 存在未对账订单\n// 存在未对账订单\nwhile (existUnreconciledOrders()) {\n    // 查询未对账订单\n    Thread t1 = new Thread(() -> {\n        pOrder = getPOrder();\n    });\n    t1.start();\n\n    // 查询派送订单\n    Thread t2 = new Thread(() -> {\n        dOrder = getDOrder();\n    });\n    t2.start();\n\n    // 等待t1和t2结束\n    t1.join();\n    t2.join();\n\n    // 执行对账操作\n    Order diff = check(pOrder, dOrder);\n    // 将差异写入差异库\n    save(diff);\n}\n```\nwhile循环里每次都会创建新的线程，而创建线程是一个**耗时**的操作，可以考虑**线程池**来优化\n\n## 线程池\n```java\nExecutor executor = Executors.newFixedThreadPool(2);\n// 存在未对账订单\nwhile (existUnreconciledOrders()) {\n    // 查询未对账订单\n    executor.execute(() -> {\n        pOrder = getPOrder();\n    });\n\n    // 查询派送订单\n    executor.execute(() -> {\n        dOrder = getDOrder();\n    });\n\n    // 采用线程池方案，线程根本就不会退出，join()已经失效\n    // 如何实现等待？？\n\n    // 执行对账操作\n    Order diff = check(pOrder, dOrder);\n    // 将差异写入差异库\n    save(diff);\n}\n```\n1. 实现等待的简单方案：**计数器** + **管程**\n2. 计数器的初始值为2，当执行完getPOrder()或getDOrder()后，计数器减1，主线程会等待计数器等于0\n3. 等待计数器等于0其实是一个**条件变量**，可以利用**管程**来实现，在JUC中提供了类似的工具类_**CountDownLatch**_\n\n## CountDownLatch\n```java\nExecutor executor = Executors.newFixedThreadPool(2);\n// 存在未对账订单\nwhile (existUnreconciledOrders()) {\n    // 计数器初始化为2\n    CountDownLatch latch = new CountDownLatch(2);\n    // 查询未对账订单\n    executor.execute(() -> {\n        pOrder = getPOrder();\n        latch.countDown();\n    });\n\n    // 查询派送订单\n    executor.execute(() -> {\n        dOrder = getDOrder();\n        latch.countDown();\n    });\n\n    // 等待两个查询操作结束\n    latch.await();\n\n    // 执行对账操作\n    Order diff = check(pOrder, dOrder);\n    // 将差异写入差异库\n    save(diff);\n}\n```\n1. 此时， getPOrder()和getDOrder()两个查询操作是并行的，但两个查询操作和对账操作check和save还是串行的\n2. 实际上，在执行对账操作的时候，可以同时去执行下一轮的查询操作，达到_**完全的并行**_\n\n## 完全并行\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-reconciliation-system-multi-fully-parallel.png\" width=800/>\n\n1. 两次查询操作能够和对账操作并行，对账操作还依赖于查询操作的结果，类似于_**生产者-消费者**_\n    - 两次查询操作是生产者，对账操作是消费者\n2. 既然是生产者-消费者模型，就需要用到**队列**，用来保存生产者生成的数据，而消费者从这个队列消费数据\n3. 针对对账系统，可以设计两个队列，这两个队列之间的元素是有**一一对应**的关系\n    - 订单查询操作将订单查询结果插入到**订单队列**\n    - 派送单查询操作将派送单插入到**派送单队列**\n4. 用双队列实现**完全的并行**\n    - 线程T1执行订单查询工作，线程T2执行派送单查询工作，当T1和T2各自生产完1条数据后，通知线程T3执行对账\n    - 隐藏条件：T1和T2工作的**相互等待**，步调要一致\n5. 实现方案\n    - 计数器初始化为2，线程T1和线程T2生产完1条数据后都将计数器减1\n        - 如果计数器**大于0**，则线程T1或者T2**等待**\n        - 如果计数器**等于0**，则**通知**线程T3，并**唤醒**等待的线程T1或者T2，与此同时，将计数器**重置**为2\n    - JUC提供了类似的工具类_**CyclicBarrier**_\n\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-reconciliation-system-multi-double-queue.png\" width=800/>\n\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-reconciliation-system-multi-sync.png\" width=800/>\n\n\n## CyclicBarrier\n```java\n// 订单队列\nprivate Vector<Order> pos;\n// 派送单队列\nprivate Vector<Order> dos;\n// 执行回调的线程池\nprivate Executor executor = Executors.newFixedThreadPool(1);\n\n// 传入回调函数\nprivate final CyclicBarrier barrier = new CyclicBarrier(2, () -> {\n    executor.execute(this::check);\n});\n\n// 回调函数\nprivate void check() {\n    Order p = pos.remove(0);\n    Order d = dos.remove(0);\n    // 执行对账操作\n    Order diff = check(p, d);\n    // 差异写入差异库\n    save(diff);\n}\n\n// 两个查询操作\nprivate void getOrders() {\n    Thread t1 = new Thread(() -> {\n        // 循环查询订单库\n        while (existUnreconciledOrders()) {\n            pos.add(getDOrder());\n            try {\n                // 等待\n                barrier.await();\n            } catch (InterruptedException | BrokenBarrierException e) {\n                e.printStackTrace();\n            }\n        }\n    });\n    t1.start();\n\n    Thread t2 = new Thread(() -> {\n        // 循环查询派单库\n        while (existUnreconciledOrders()) {\n            dos.add(getDOrder());\n            try {\n                // 等待\n                barrier.await();\n            } catch (InterruptedException | BrokenBarrierException e) {\n                e.printStackTrace();\n            }\n        }\n    });\n    t2.start();\n}\n```\n\n### 回调线程池\n```java\nint index = --count;\nif (index == 0) {  // tripped\n    boolean ranAction = false;\n    try {\n        final Runnable command = barrierCommand;\n        if (command != null)\n            command.run(); // 调用回调函数\n        ranAction = true;\n        nextGeneration(); // 唤醒等待的线程\n        return 0;\n    } finally {\n        if (!ranAction)\n            breakBarrier(); // 唤醒等待的线程\n    }\n}\n```\n1. CyclicBarrier是**同步调用回调函数**后才**唤醒**等待的线程的，如果不采用回调线程池，**无法提升性能**\n2. 遇到回调函数时，需要考虑执行回调的线程是哪一个\n    - 执行CyclicBarrier的回调函数线程是将CyclicBarrier**内部计数器减到0**的那个线程\n\n## 小结\n1. CountDownLatch：主要用来解决**一个线程等待多个线程**的场景\n2. CyclicBarrier：主要用来解决**一组线程之间互相等待**的场景\n3. CountDownLatch的计数器不能循环利用，一旦计数器减到0，再有线程调用await()，该线程会**直接通过**\n4. CyclicBarrier的计数器是可以**循环利用**的，具备**自动重置**的功能，还支持设置**回调函数**\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- StampedLock","url":"%2F2019%2F05%2F10%2Fjava-concurrent-stamped-lock%2F","content":"\n## StampedLock VS ReadWriteLock\n1. StampedLock同样适用于**读多写少**的场景，性能比ReadWriteLock好\n2. ReadWriteLock支持两种模式：**写锁**、**读锁**\n3. StampedLock支持三种模式：**写锁**、**悲观读锁**、_**乐观读**_（关键）\n    - StampedLock的**写锁、悲观读锁**的语义和ReadWriteLock的**写锁、读锁**的语义非常**类似**\n        - 允许多个线程同时获取悲观读锁，只允许一个线程获取写锁，写锁和悲观读锁是**互斥**的\n    - 但StampedLock里的写锁和悲观读锁加锁成功之后，都会返回一个**stamp**，然后解锁的时候需要传入这个stmap\n\n<!-- more -->\n\n```java\npublic class StampedLockExample {\n    private final StampedLock stampedLock = new StampedLock();\n\n    @Test\n    // 悲观读锁\n    public void pessimisticReadLockTest() {\n        long stamp = stampedLock.readLock();\n        try {\n            // 业务逻辑\n        } finally {\n            stampedLock.unlockRead(stamp);\n        }\n    }\n\n    @Test\n    // 写锁\n    public void writeLockTest() {\n        long stamp = stampedLock.writeLock();\n        try {\n            // 业务逻辑\n        } finally {\n            stampedLock.unlockWrite(stamp);\n        }\n    }\n}\n```\n\n## 乐观读\n1. StampedLock的性能比ReadWriteLock要好的关键是StampedLock支持**乐观读**的方式\n2. ReadWriteLock支持多个线程同时读，但当多个线程同时读的时候，所有写操作都会被阻塞\n3. StampedLock提供的乐观读，是**允许一个线程获取写锁**的，并不是所有的写操作都会被阻塞\n4. 乐观读这个操作是**无锁**的，相对于ReadWriteLock的读锁，乐观读的性能要更好一点\n\n```java\npublic class Point {\n    private int x, y;\n    private final StampedLock stampedLock = new StampedLock();\n\n    // 计算到原点的距离\n    public double distanceFromOrigin() {\n        // 乐观锁（无锁算法，共享变量x和y读入方法局部变量时，x和y有可能被其他线程修改）\n        long stamp = stampedLock.tryOptimisticRead();\n        // 读入局部变量，读的过程中，数据可能被修改\n        int curX = x;\n        int curY = y;\n        // 判断执行读操作期间，是否存在写操作，如果存在，validate会返回false\n        if (!stampedLock.validate(stamp)) {\n            // 升级为悲观读锁\n            // 如果不升级，有可能反复执行乐观读，浪费大量CPU\n            stamp = stampedLock.readLock();\n            try {\n                curX = x;\n                curY = y;\n            } finally {\n                // 释放悲观读锁\n                stampedLock.unlockRead(stamp);\n            }\n        }\n        return Math.sqrt(curX * curX + curY * curY);\n    }\n}\n```\n\n## 数据库的乐观锁\n```sql\n-- 假设version=9\nSELECT id,...,version FROM product_doc WHERE id=777;\n\n-- version类似于StampedLock的stamp\nUPDATE product_doc SET version=version+1,... WHERE id=777 AND version=9;\n```\n\n## 注意事项\n1. StampedLock的功能仅仅是ReadWriteLock的_**子集**_\n2. StampedLock在命名上并没有增加Reentrant关键字，_**不支持重入**_\n3. StampedLock的**悲观读锁、写锁**都不支持**条件变量**\n4. 假设线程阻塞在StampedLock的**readLock**或者**writeLock**上\n    - 如果此时调用该阻塞线程的**interrupt**，会导致_**CPU飙升**_\n5. 使用StampedLock**不要调用中断操作**\n    - 如果需要支持中断功能，使用**可中断**的**readLockInterruptibly**或**writeLockInterruptibly**\n\n```java\nStampedLock lock = new StampedLock();\nThread t1 = new Thread(() -> {\n    // 获取写锁\n    lock.writeLock();\n    // 永远阻塞，不释放写锁\n    LockSupport.park();\n});\nt1.start();\n// 保证t1获得写锁\nTimeUnit.SECONDS.sleep(1);\n\nThread t2 = new Thread(() -> {\n    // 阻塞在悲观读锁\n    lock.readLock();\n});\nt2.start();\n// 保证t2阻塞在悲观读锁\nTimeUnit.SECONDS.sleep(1);\n\n// 导致t2所在的CPU飙升\nt2.interrupt();\nt2.join();\n```\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- ReadWriteLock","url":"%2F2019%2F05%2F09%2Fjava-concurrent-readwrite-lock%2F","content":"\n## 读多写少\n1. 理论上，利用**管程**和**信号量**可以解决所有并发问题，但JUC提供了很多工具类，_**细分场景优化性能，提升易用性**_\n2. 针对**读多写少**的并发场景，JUC提供了**读写锁**，即ReadWriteLock\n\n<!-- more -->\n\n## 读写锁\n1. 读写锁是一种广泛使用的**通用技术**，并非Java所特有\n2. 所有读写锁都遵守3条基本原则\n    - 允许**多个线程同时读**共享变量 -- 与互斥锁的重要区别\n    - 只允许**一个线程写**共享变量\n    - 如果一个写线程正常执行写操作，此时禁止读线程读取共享变量\n\n## 缓存\n```java\npublic class Cache<K, V> {\n    private final Map<K, V> map = new HashMap<>();\n    private final ReadWriteLock readWriteLock = new ReentrantReadWriteLock();\n    // 读锁\n    private final Lock readLock = readWriteLock.readLock();\n    // 写锁\n    private final Lock writeLock = readWriteLock.writeLock();\n\n    // 读缓存 -- 懒加载\n    public V get(K key) {\n        V v = null;\n        // 读缓存\n        readLock.lock(); // 1\n        try {\n            v = map.get(key); // 2\n        } finally {\n            readLock.unlock(); // 3\n        }\n        // 缓存中存在，直接返回\n        if (v != null) { // 4\n            return v;\n        }\n        // 缓存中不存在，查询数据库\n        writeLock.lock(); // 5\n        try {\n            // 再次验证，其他线程可能已经查询过数据库了\n            // 避免在高并发场景下重复查询数据库的问题\n            v = map.get(key); // 6\n            if (v == null) { // 7\n                // 查询数据库\n                v = loadFromDb(key);\n                map.put(key, v);\n            }\n        } finally {\n            writeLock.unlock();\n        }\n        return v;\n    }\n\n    private V loadFromDb(K key) {\n        return null;\n    }\n\n    // 写缓存\n    public V put(K key, V value) {\n        writeLock.lock();\n        try {\n            return map.put(key, value);\n        } finally {\n            writeLock.unlock();\n        }\n    }\n}\n```\n\n### 锁升级\nReadWriteLock不支持锁升级（**读锁升级为写锁**），readLock还没有释放，因此无法获取writeLock，这会导致_**线程阻塞**_\n```java\nreadLock.lock();\ntry {\n    V v = map.get(key);\n    if (v == null) {\n        writeLock.lock();\n        try {\n            map.put(key, loadFromDb(key));\n        } finally {\n            writeLock.unlock();\n        }\n    }\n} finally {\n    readLock.unlock();\n}\n```\n\n### 锁降级\n```java\nreadLock.lock();\nif (!cacheValid) {\n    // 因为不允许读锁升级为写锁，先释放读锁\n    readLock.unlock();\n    writeLock.lock();\n    try {\n        if (!cacheValid) {\n            cacheValid = true;\n        }\n        // 释放写锁前，允许降级为读锁！！\n        readLock.lock(); // 1\n    } finally {\n        writeLock.unlock();\n    }\n}\n\n// 此时仍然持有读锁\ntry {\n    // 使用数据\n} finally {\n    readLock.unlock();\n}\n```\n\n## 小结\n1. 读写锁类似于ReentrantLock（**可重入**），支持**公平**模式和**非公平**模式\n2. 读锁和写锁都实现了java.util.concurrent.locks.Lock接口\n2. 但只有写锁支持条件变量，**读锁是不支持条件变量的**，读锁调用newCondition，会抛出UnsupportedOperationException\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- Semaphore","url":"%2F2019%2F05%2F08%2Fjava-concurrent-semaphore%2F","content":"\n## 历史\n1. 信号量是由计算机科学家Dijkstra在1965年提出，在之后的15年，信号量一直都是并发编程领域的终结者\n2. 直到1980年管程被提出来，才有了第二选择，目前所有支持并发编程的语言都支持信号量机制\n\n<!-- more -->\n\n## 信号量模型\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-semaphore-model.png\" width=800/>\n\n1. 在信号量模型里，计数器和等待队列对外都是**透明**的，只能通过信号量模型提供的三个方法来访问它们，即init/down/up\n2. init()：设置计数器的初始值\n3. down()：计数器的值**减1**，如果此时计数器的值**小于0**，则当前线程将**阻塞**，否则当前线程可以继续执行\n4. up()：计数器**加1**，如果此时计数器的值**大于或等于0**，则**唤醒**等待队列中的一个线程，并将其从等待队列中移除\n5. init/down/up都是**原子性**的，这个原子性由信号量模型的实现方保证\n    - 在JUC中，信号量模型由java.util.concurrent.Semaphore实现，Semaphore能够保证这三个方法的原子性操作\n6. 在信号量模型里，down/up这两个操作最早被称为P操作和V操作，因此信号量模型也被称为_**PV原语**_\n    - 在JUC中，down和up对应的是acquire和release\n\n## 使用信号量\n\n### 互斥\n```java\npublic class Counter {\n    private static final Semaphore SEMAPHORE = new Semaphore(1);\n    private static int count;\n\n    // 用信号量保证互斥\n    public static void addOne() throws InterruptedException {\n        // 原子操作\n        SEMAPHORE.acquire();\n        try {\n            count += 1;\n        } finally {\n            // 原子操作\n            SEMAPHORE.release();\n        }\n    }\n}\n```\n1. 假设两个线程T1和T2同时访问addOne，当两个线程同时调用acquire的时候，由于acquire是一个原子操作\n    - 只能一个线程（T1）把信号量的计数器减为0，另一个线程（T2）把信号量的计数器减为-1\n2. 对于T1，信号量里计数器值为0，大于等于0，T1会继续执行，对于T2，信号量里计数器值为-1，小于0，T2将被阻塞\n    - 因此此时只有T1能够进入临界区执行count += 1\n3. 当T1执行release，此时信号量里计数器的值为-1，加1之后的值为0，大于等于0，唤醒信号量里等待队列中的线程（T2）\n4. 于是T2在T1执行完临界区代码后才有机会进入临界区执行代码，从而保证了_**互斥性**_\n\n\n### 限流器\n1. Semaphore对比Lock：Semaphore**允许多个线程访问同一个临界区**\n2. 常见场景为各种**池化资源**，例如**连接池、对象池和线程池**\n3. 对象池需求：一次性创建N个对象，之后所有的线程都重用这N个对象，在对象被释放前，不允许其他线程使用\n\n```java\npublic class ObjPool<T, R> {\n    private final List<T> pool;\n    // 用信号量实现限流器\n    private final Semaphore semaphore;\n\n    public ObjPool(int size, T t) {\n        // 信号量允许多个线程进入临界区，因此采用并发安全的Vector\n        pool = new Vector<T>();\n        for (int i = 0; i < size; i++) {\n            pool.add(t);\n        }\n        semaphore = new Semaphore(size);\n    }\n\n    // 利用对象池中的对象，调用func\n    public R exec(Function<T, R> func) throws InterruptedException {\n        T t = null;\n        semaphore.acquire();\n        try {\n            // 分配对象\n            t = pool.remove(0);\n            return func.apply(t);\n        } finally {\n            // 释放对象\n            pool.add(t);\n            semaphore.release();\n        }\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        // 创建对象池\n        ObjPool<Long, String> objPool = new ObjPool<>(10, 2L);\n        // 通过对象池获取t后执行\n        objPool.exec(t -> {\n            System.out.println(t);\n            return t.toString();\n        });\n    }\n}\n```\n\n## 小结\n1. 信号量在Java中的名气并不算大，在其他语言中有很高的知名度\n2. Java在并发领域**重点支持**的还是**管程模型**\n3. 管程模型理论上解决了信号量模型的一些不足，主要体现在**易用性**和**工程化**方面\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- Condition","url":"%2F2019%2F05%2F07%2Fjava-concurrent-condition%2F","content":"\n## Condition\n1. Condition实现了管程模型中的_**条件变量**_\n2. Java内置的管程（**synchronized**）只有**一个条件变量**，而**Lock&Condition**实现的管程支持**多个条件变量**\n3. 在很多并发场景下，支持多个条件变量能够让并发程序的**可读性更好**，也**更容易实现**\n\n<!-- more -->\n\n## 阻塞队列\n```java\n// 下列三对操作的语义是相同的\n// Condition.await()        Object.wait()\n// Condition.signal()       Object.notify()\n// Condition.signalAll()    Object.notifyAll()\npublic class BlockedQueue<T> {\n    private static final int MAX_SIZE = 10;\n    // 可重入锁\n    private final Lock lock = new ReentrantLock();\n    // 条件变量：队列不满\n    private final Condition notFull = lock.newCondition();\n    // 条件变量：队列不空\n    private final Condition notEmpty = lock.newCondition();\n    // 队列实际存储：栈\n    private final Stack<T> stack = new Stack<>();\n\n    // 入队\n    public void enq(T t) {\n        // 先获得互斥锁，类似于管程中的入口\n        lock.lock();\n        try {\n            while (stack.size() >= MAX_SIZE) {\n                // 队列已满，等待队列不满，才可入队\n                notFull.await();\n            }\n            // 入队后，通知队列不空，可出队\n            stack.push(t);\n            notEmpty.signalAll();\n        } catch (InterruptedException ignored) {\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    // 出队\n    public T deq() {\n        // 先获得互斥锁，类似于管程中的入口\n        lock.lock();\n        try {\n            while (stack.isEmpty()) {\n                // 队列已空，等待队列不空，才可出队\n                notEmpty.await();\n            }\n            // 出队后，通知队列不满，可入队\n            T pop = stack.pop();\n            notFull.signalAll();\n            return pop;\n        } catch (InterruptedException ignored) {\n        } finally {\n            lock.unlock();\n        }\n        return null;\n    }\n}\n```\n1. 一个阻塞队列，需要两个条件变量，一个是**队列不空**（空队列不允许出队），一个是**队列不满**（队列已满不允许入队）\n2. Lock&Condition实现的管程，线程等待和通知需要调用_**await/signal/signalAll**_\n3. Java内置的管程（synchronized），线程等待和通知需要调用_**wait/notify/notifyAll**_\n\n## 同步 + 异步\n1. 区别：_**调用方是否需要等待结果**_\n2. **异步调用**：调用方创建一个子线程，在子线程中执行方法调用\n3. **异步方法**：在方法实现的时候，创建一个新的线程执行逻辑，主线程直接return\n\n## Dubbo\n在TCP协议层面，发送完RPC请求后，系统线程是不会等待RPC的响应结果的，需要RPC框架完成**异步转同步**的操作\n\n### DubboInvoker\n```java\nprotected Result doInvoke(final Invocation invocation) throws Throwable {\n    ...\n    return (Result) currentClient\n                .request(inv, timeout) // 发送RPC请求，默认返回DefaultFuture\n                .get(); // 等待RPC返回结果\n}\n```\n\n### DefaultFuture\n当RPC返回结果之前，阻塞调用线程，让调用线程等待；当RPC返回结果后，唤醒调用线程，让调用线程重新执行\n```java\n// 锁和条件变量\nprivate final Lock lock = new ReentrantLock();\nprivate final Condition done = lock.newCondition();\n// RPC结果\nprivate volatile Response response;\n// 回调\nprivate volatile ResponseCallback callback;\n```\n\n#### get\n```java\n// RPC结果是否已经返回\npublic boolean isDone() {\n    return response != null;\n}\n\n// 调用方通过该方法等待RPC结果\npublic Object get(int timeout) throws RemotingException {\n    ...\n    if (!isDone()) {\n        long start = System.currentTimeMillis();\n        lock.lock();\n        try {\n            while (!isDone()) {\n                done.await(timeout, TimeUnit.MILLISECONDS);\n                if (isDone() || System.currentTimeMillis() - start > timeout) {\n                    break;\n                }\n            }\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        } finally {\n            lock.unlock();\n        }\n        ...\n    }\n    return returnFromResponse();\n}\n```\n#### doReceived\n```java\n// RPC结果返回时调用该方法\nprivate void doReceived(Response res) {\n    lock.lock();\n    try {\n        response = res;\n        if (done != null) {\n            done.signalAll();\n        }\n    } finally {\n        lock.unlock();\n    }\n    if (callback != null) {\n        invokeCallback(callback);\n    }\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java核心 -- Vector + ArrayList + LinkedList","url":"%2F2019%2F05%2F06%2Fjava-core-vector-arraylist-linkedlist%2F","content":"\n## 概述\n1. Vector、ArrayList、LinkedList都实现了**java.util.List**接口，即**有序集合**\n2. Vector是Java早期提供的**线程安全**的**动态数组**，同步有一定的**额外开销**\n    - Vector内部使用**对象数组**来保存数据，可以**自动扩容**（创建新的数组，拷贝原有数组的数据）\n3. ArrayList是**应用更加广泛**的**动态数组**，本身并不是线程安全的，性能比Vector要好很多\n    - Vector的自动扩容是增加1倍，而ArrayList的自动扩容是增加**50%**\n4. LinkedList是**双向链表**，不是线程安全的，也不需要动态调整容量\n\n<!-- more -->\n\n## 适用场景\n1. Vector和ArrayList都是**动态数组**，其内部元素是以**数组**的形式存储的，非常适合**随机访问**的场合\n    - 除了在**尾部**插入和删除元素，性能都比较差，因为要移动后续所有的元素\n2. LinkedList进行元素的插入和删除操作会高效很多，但随机访问性能要比动态数组差\n\n## 集合\n<img src=\"https://java-core-1253868755.cos.ap-guangzhou.myqcloud.com/java-core-collection.png\" width=800/>\n\n1. 容器包括**集合**和**Map**，_**Map并不是真正的集合**_\n2. List：**有序结合**\n3. Set：不允许重复元素（equals判断）\n4. Queue/Deque：标准队列，支持**FIFO**或者**LIFO**\n5. 每种集合的**通用逻辑**，都被抽象到相应的抽象类之中，例如**AbstractList、AbstractSet、AbstractQueue**\n6. 集合并不是完全孤立的，例如LinkedList既是List，也是Deque\n7. TreeSet实际是利用TreeMap实现的，HashSet实际是利用HashMap实现的\n\n## TreeSet、HashSet、LinkedHashSet\n1. TreeSet：支持**自然顺序**访问，但添加、删除和包含等操作相对低效（`O(log(n))`）\n2. HashSet：利用**哈希**算法，如果哈希散列正常，可以提供`O(1)`的添加、删除和包含等操作，但**不保证有序**\n3. LinkedHashSet\n    - 内部构建了一个**记录插入顺序的双向链表**，因此提供了**按照插入顺序遍历**的能力\n    - 同时也提供了`O(1)`的添加、删除和包含等操作，但性能略低于HashSet，因为需要额外维护双向链表\n\n## Collections.synchronized\n```java\npublic static <T> Collection<T> synchronizedCollection(Collection<T> c)\npublic static <T> List<T> synchronizedList(List<T> list)\npublic static <T> Set<T> synchronizedSet(Set<T> s)\n```\n1. 将每个基本方法都通过**synchronized**添加基本的同步支持\n2. 通过这些方法创建的线程安全集合，都符合**fail-fast**，当发生意外的**并发修改**时，会抛出ConcurrentModificationException\n\n<!-- indicate-the-source -->\n","tags":["Java Core"],"categories":["Core"]},{"title":"Java并发 -- Lock","url":"%2F2019%2F05%2F05%2Fjava-concurrent-lock%2F","content":"\n## 管程\n1. 并发领域的两大核心问题：**互斥** + **同步**\n2. 互斥：同一时刻只允许一个线程访问共享资源\n3. 同步：线程之间的通信和协作\n4. JUC通过Lock和Condition两个接口**实现管程**，其中**Lock**用于解决**互斥**问题，而**Condition**用于解决**同步**问题\n\n<!-- more -->\n\n## 再造管程的理由\n1. Java语言对管程的原生实现：**synchronized**\n2. 在Java 1.5中，synchronized的**性能**不如JUC中的Lock，在Java 1.6中，synchronized做了很多的性能优化\n3. 再造管程的**核心理由**：synchronized无法**破坏不可抢占条件**（死锁的条件之一）\n    - synchronized在申请资源的时候，如果申请不到，线程**直接进入阻塞状态**，也**不会释放线程已经占有的资源**\n    - 更合理的情况：占用部分资源的线程如果进一步申请其它资源的时，如果申请不到，可以**主动释放**它所占有的资源\n4. 解决方案\n    - **能够响应中断**\n        - synchronized：持有锁A的线程在尝试获取锁B失败，进入**阻塞**状态，如果发生**死锁**，将**没有机会唤醒**阻塞线程\n        - 如果处于阻塞状态的线程能够响应中断信号，那阻塞线程就有机会释放曾经持有的锁A\n    - **支持超时**\n        - 如果线程在一段时间内没有获得锁，不是进入阻塞状态，而是**返回一个错误**\n        - 那么该线程也有机会释放曾经持有的锁\n    - **非阻塞地获取锁**\n        - 如果尝试获取锁失败，不是进入阻塞状态，而是**直接返回**，那么该线程也有机会释放曾经持有的锁\n\n```java\n// java.util.concurrent.locks.Lock接口\n// 能够响应中断\nvoid lockInterruptibly() throws InterruptedException;\n// 支持超时（同时也能够响应中断）\nboolean tryLock(long time, TimeUnit unit) throws InterruptedException;\n// 非阻塞地获取锁\nboolean tryLock();\n```\n\n## 保证可见性\n```java\npublic class Counter {\n    private final Lock lock = new ReentrantLock();\n    private int value;\n\n    public void addOne() {\n        // 获取锁\n        lock.lock();\n        try {\n            // 可见性：线程T1执行value++，后续的线程T2能看到正确的结果\n            value++;\n        } finally {\n            // 释放锁\n            lock.unlock();\n        }\n    }\n}\n```\n```java\n// ReentrantLock的伪代码\npublic class SimpleLock {\n    // 利用了volatile相关的Happens-Before规则\n    private volatile int state;\n\n    // 加锁\n    public void lock() {\n        // 读取state\n        state = 1;\n    }\n\n    // 解锁\n    public void unlock() {\n        // 读取state\n        state = 0;\n    }\n}\n```\n1. Java多线程的**可见性**是通过**Happens-Before**规则来保证的\n    - synchronized的可见性保证：synchronized的解锁Happens-Before于后续对这个锁的加锁\n    - JUC中Lock的可见性保证：_**利用了volatile相关的Happens-Before规则**_\n2. ReentrantLock内部持有一个**volatile**的成员变量state，加锁和解锁时都会**读写state**\n    - 执行value++之**前**，执行**lock**，会**读写**volatile变量state\n    - 执行value++之**后**，执行**unlock**，会**读写**volatile变量state\n    - 相关的Happens-Before规则\n        - **顺序性规则**\n            - 对于线程T1，`value++` Happens-Before `unlock()`\n            - 对于线程T2，`lock()` Happens-Before `读取value`\n        - **volatile变量规则**\n            - 对于线程T1，unlock()会执行`state=1`\n            - 对于线程T2，lock()会先**读取state**\n            - volatile变量的写操作 Happens-Before volatile变量的读操作\n            - 因此**线程T1的unlock** Happens-Before **线程T2的lock**，与synchronized非常类似\n        - 传递性规则：线程T1的value++ Happens-Before 线程T2的lock()\n\n## 可重入锁\n```java\npublic class X {\n    private final Lock lock = new ReentrantLock();\n    private int value;\n\n    private int get() {\n        lock.lock(); // 2\n        try {\n            return value;\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public void addOne() {\n        lock.lock();\n        try {\n            value = get() + 1; // 1\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n```\n1. 可重入锁：线程可以_**重复获取同一把锁**_\n2. 执行路径：addOne -> get，在执行到2时，如果锁是可重入的，那么线程会再次加锁成功，否则会被阻塞\n\n## 公平锁和非公平锁\n```java\n// java.util.concurrent.locks.ReentrantLock\npublic ReentrantLock() {\n    // 默认非公平锁\n    sync = new NonfairSync();\n}\npublic ReentrantLock(boolean fair) {\n    sync = fair ? new FairSync() : new NonfairSync();\n}\n```\n1. 在管程模型中，每把锁都对应着一个_**入口等待队列**_\n2. 如果一个线程没有获得锁，就会进入入口等待队列，当有线程释放锁的时候，需要从入口等待队列中唤醒一个等待的线程\n3. 唤醒策略：如果是**公平锁**，唤醒**等待时间最长**的线程，如果是非公平锁，随机唤醒\n\n## 锁的最佳实践\n1. 永远只在**更新对象的成员变量**时加锁\n2. 永远只在**访问可变的成员变量**时加锁\n3. 永远不在**调用其它对象的方法**时加锁，因为调用其它对象的方法是**不安全**的（对其它对象的方法不了解）\n    - 可能有Thread.sleep()，也有可能有慢IO，这会**严重影响性能**\n    - 甚至还会加锁，这有可能导致**死锁**\n4. 减少锁的**持有时间**\n5. 减少**锁粒度**\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java核心 -- int + Integer","url":"%2F2019%2F05%2F04%2Fjava-core-int-integer%2F","content":"\n## 包装类\n1. Integer是int对应的**包装类**，里面有一个int类型的字段存储数据，并提供了基本的操作\n2. 在Java 5，引入了**自动装箱**和**自动拆箱**（boxing/unboxing），Java可以根据上下文，自动进行转换\n3. 在Java 5，还引入了**值缓存**（静态工厂方法valueOf），默认缓存范围为**-128 ~ 127**\n    - Boolean，缓存**Boolean.TRUE/Boolean.FALSE**\n    - Short，缓存**-128 ~ 127**\n    - Byte，数值有限，**全部缓存**\n    - Character，缓存**\\u0000 ~ \\u007F**\n\n<!-- more -->\n\n## 自动装箱 + 自动拆箱\n```java\nInteger integer = 1;\nint unboxing = integer++;\n```\n```\n1: invokestatic     // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer;\n8: invokevirtual    // Method java/lang/Integer.intValue:()I\n11: iconst_1\n12: iadd\n13: invokestatic    // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer;\n21: invokevirtual   // Method java/lang/Integer.intValue:()I\n```\n1. 自动装箱和自动拆箱是一种**语法糖**，发生在**编译阶段**（生成**一致的字节码**）\n2. javac自动把**装箱**转换为**Integer.valueOf**（可以利用**值缓存**机制），把**拆箱**转换为**Integer.intValue**\n3. 在**性能敏感**的场合，要尽量避免无意中的自动装箱和自动拆箱；但在大多数产品代码里，还是以**开发效率**优先\n\n### 线程安全的计数器\n\n#### 原子类实现\n```java\n// 简单明了\npublic class Counter {\n    private final AtomicLong counter = new AtomicLong();\n\n    public void increase() {\n        counter.incrementAndGet();\n    }\n}\n```\n\n#### 原始类型实现\n```java\n// 复杂\npublic class CompactCounter {\n    private volatile long counter;\n    private static final AtomicLongFieldUpdater<CompactCounter> UPDATER =\n            AtomicLongFieldUpdater.newUpdater(CompactCounter.class, \"counter\");\n\n    public void increase() {\n        UPDATER.incrementAndGet(this);\n    }\n}\n```\n\n## 不变类\n```java\nprivate final int value;\n```\n\n## BYTES\n```java\n// Integer\n@Native public static final int SIZE = 32;\npublic static final int BYTES = SIZE / Byte.SIZE;\n\n// Byte\npublic static final int SIZE = 8;\n```\n\n## 原始类型的线程安全\n1. 原始类型的变量，需要使用并发相关手段，才能保证线程安全\n2. 如果有线程安全的计算需要，优先考虑**AtomicInteger、AtomicLong**等线程安全类\n3. 部分比较宽的数据类型，如**float、double**，都**不能保证更新操作的原子性**（可能读到只更新了一半数据位的数值）\n\n## 局限性\n1. 原始类型与Java泛型不能配合使用\n    - Java的泛型是**伪泛型**，属于**编译期的技巧**（_**类型擦除+强制转换**_）\n    - 原始类型无法转换为Object，因此无法与泛型配合使用\n2. 无法高效表达数据\n    - **原始类型数组**，在内存里是一段**连续的内存**\n    - **引用类型数组**，存储的是引用，实际的对象分散在堆里，导致**低效的数据操作**，也**无法充分利用CPU缓存**\n\n<!-- indicate-the-source -->\n","tags":["Java Core"],"categories":["Core"]},{"title":"Java核心 -- 动态代理","url":"%2F2019%2F05%2F03%2Fjava-core-dynamic-proxy%2F","content":"\n## 编程语言分类\n1. 动态类型和静态类型：语言类型是**运行时**检查，还是**编译期**检查\n2. 强类型和弱类型：为**不同类型**的变量赋值时，是否需要进行**显式的类型转换**\n3. Java是**静态的强类型语言**，但提供了类似**反射**等机制，因此也具备了**部分**动态类型语言的能力\n\n<!-- more -->\n\n## 反射\n1. 反射机制是Java语言提供的一种基础功能，赋予程序**在运行时自省**的能力\n2. 通过反射可以**直接操作类或者对象**\n    - 获取某个对象的类定义\n    - 获取类声明的属性和方法\n    - 调用方法或者构造函数\n    - 运行时修改类定义\n\n### setAccessible\n1. AccessibleObject.setAccessible(boolean flag)：可以在**运行时**修改成员的**访问限制**\n2. setAccessible的应用遍布在日常开发、测试、依赖注入等框架中\n    - 在O/R Mapping框架中，为一个Java实体对象，运行时自动生成getter/setter方法\n    - 绕过API的访问控制，来调用内部API\n\n## 动态代理\n1. 动态代理是一种方便**运行时动态构建代理、动态处理代理方法调用**的机制\n2. 很多场景都是利用类似的机制来实现的，例如用来**包装RPC调用**和**AOP**\n3. 实现动态代理的方式\n    - JDK自身提供的动态代理，主要利用**反射**机制\n    - **字节码操作机制**，类似ASM、cglib（基于ASM）和Javassist\n\n### 解决的问题\n1. 动态代理是一种**代理**机制，代理可以看作对调用目标的**包装**，对目标代码的调用是通过代理完成的\n2. 通过代理可以让**调用者和实现者解耦**，例如RPC调用，框架内部的寻址、序列化、反序列化等，对调用者没什么意义\n\n### 发展历程\n1. 静态代理 -> 动态代理\n2. 静态代理：需要引入**额外的工作**，而这些工作与实际的业务逻辑没有关系\n    - 古董技术RMI，需要rmic之类的工具生成静态stub等文件，增加了很多繁琐的准备工作\n3. 动态代理：相应的stub等类，可以在运行时生成，对应的调用操作也是动态生成的，极大地提高生产力\n\n### JDK Proxy + cglib\n```java\npublic class MyDynamicProxy {\n    public static void main(String[] args) {\n        Hello hello = new HelloImpl();\n        MyInvocationHandler handler = new MyInvocationHandler(hello);\n        // 构造代理实例\n        Hello proxyHello = (Hello) Proxy.newProxyInstance(Hello.class.getClassLoader(), hello.getClass().getInterfaces(), handler);\n        // 调用代理方法\n        proxyHello.sayHello();\n\n        // 输出\n        //  MyInvocationHandler Invoking HelloImpl#sayHello\n        //  HelloImpl : Hello World\n    }\n}\n\ninterface Hello {\n    void sayHello();\n}\n\nclass HelloImpl implements Hello {\n    @Override\n    public void sayHello() {\n        System.out.println(getClass().getSimpleName() + \" : Hello World\");\n    }\n}\n\n@AllArgsConstructor\nclass MyInvocationHandler implements InvocationHandler {\n    private Object target;\n\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        System.out.println(getClass().getSimpleName() + \" Invoking \" + target.getClass().getSimpleName() + \"#\" + method.getName());\n        Object result = method.invoke(target, args);\n        return result;\n    }\n}\n```\n1. 实现InvocationHandler，添加**额外**逻辑\n2. 以Hello接口为纽带，为被调用目标构建**代理对象**，可以使用代理对象**间接**运行调用目标的逻辑\n3. 以**接口**为中心，相当于添加了一种**对被调用者没有太大意义的限制**\n4. 另外实例化的是**Proxy对象**，而不是真正的被调用类型，可能会带来各种不变和能力退化\n5. 如果**被调用者没有实现接口**，可以通过**cglib**来实现动态代理（克服了对接口的依赖）\n    - cglib动态代理的方式：创建目标类的**子类**，可以达到**近似使用被调用者本身**的效果\n\n### 优势对比\n\n#### JDK Proxy\n1. **最小化依赖关系**，简化开发和维护，JDK本身的支持\n2. **JDK平滑升级**，而字节码类库通常需要进行**更新**以保证在新版Java上能够使用\n3. **代码实现简单**\n\n#### cglib\n1. **侵入性更小**，JDK Proxy是基于**接口**的，而**限定被调用者实现特定接口**是有侵入性的实践\n2. **只需操作关心的类**，而不必为其它相关类增加工作量\n3. **高性能**\n\n### 性能对比\n1. 在**主流**的JDK版本中，JDK Proxy在**典型场景**可以提供**对等的性能水平**，在数量级的差距并不是广泛存在的\n2. 反射机制的性能在**现代**JDK中，已经得到了**极大的改进和优化**，同时JDK的很多功能同样使用了**ASM**进行字节码操作\n3. 在选型时，性能并不是唯一考量，而**可靠性、可维护性和编程工作量**才是更主要的考虑因素\n\n<!-- indicate-the-source -->\n","tags":["Java Core"],"categories":["Core"]},{"title":"架构 -- 自我迭代的计算机","url":"%2F2019%2F05%2F02%2Farchitecture-self-iterative-computer%2F","content":"\n## MVP\n1. 驱动程序：**键盘**和**显示器**\n2. 驱动程序：**外置存储**\n3. 汇编程序**编辑器**：可以从存储中读取汇编程序代码，修改并保存到存储中\n4. 汇编程序**编译器**：可以将汇编代码编译成机器代码，并保存在存储中\n5. **执行机器代码的程序**：可以执行一段保存在外置存储设备中的机器代码\n\n<!-- more -->\n\n## 需求分析\n1. _**准确的需求分析是做出良好架构设计的基础**_，在整个架构的过程中，至少应该花费**1/3**的精力在需求分析上\n2. 在需求分析时，需要区分需求的**变化点**和**稳定点**：稳定点是系统的**核心能力**，变化点则需要对应地去考虑**扩展性**上的设计\n\n## 核心部件\n1. **中央处理器**：计算能力的核心\n2. **存储**：除了作为计算的输入输出，还可作为**计算本身**的承载（程序，**主要变数**，主要分两类：**BIOS** + **外置存储的程序**）\n    - 需要考虑BIOS和外置存储的程序的**具体职责**是什么\n3. **输入输出设备**：键盘 + 显示器 + 外置存储（**主要变数**）\n    - 对于键盘和显示器，只需要准备好驱动程序即可\n    - 对于外置存储，准备好了驱动程序以后，需要考虑如何设计外置存储的**数据格式**\n\n## 外置存储\n1. 对比MVP的需求，外置存储需要保存的内容：汇编程序的**源代码**，汇编编译器编译出来的**可执行程序**\n2. 因此，外置存储需要支持保存**多个文件**，衍生出来的问题：**如何组织多个文件**，可行的解决方案如下\n    - **文件系统**，种类很多，但有**统一的抽象**\n        - 文件系统是一棵树；节点要么是目录，要么是文件；文件必然是叶子节点；根目录是目录，目录可以有子节点\n    - **键值存储系统**，可以做**统一的抽象**\n        - 每个文件都有名字（Key），通过名字可以唯一定位到该文件，从而对文件内容进行读写\n        - 支持对文件名做模糊查询（通配符）\n        - 允许每个文件设定额外的元数据，通过元数据可以检索到相关的文件\n\n## BIOS + 外置存储的程序\n1. BIOS是刻在计算机主板**ROM**上的启动程序，变更BIOS是非常麻烦的，所以BIOS只做**稳定不变**的事情\n2. 只要键盘、显示器和外置存储没有太大的演进，驱动程序是不需要变动的，比较**稳定**，可以交给BIOS负责\n3. 汇编程序编辑器，编辑器的需求是模糊的，包含很多额外的交互细节，因此这应该交给外置存储的程序负责\n4. 汇编程序编译器，依然有很大的不确定性，也应该交给外置存储的程序负责\n    - CPU的指令会增加，汇编指令也会相应地增加，汇编语言及其编译器需要完整地呈现CPU的能力，因此需要及时跟进\n    - 虽然汇编指令与机器指令基本是一一对应，但汇编指令是面向程序员的生产力工具，还是会演进出一些高阶的语法\n    - 因此汇编语言并不稳定，也会迭代变化，这意味着汇编程序的编译器也会相应地迭代变化\n5. 执行机器代码的程序，这也需要进一步细化，例如执行程序的方式是基于外置存储的物理地址还是基于文件系统的文件\n    - 前者只需要依赖外置存储的驱动程序即可，后者还需要理解文件系统的格式\n\n### BIOS交接控制权\n1. CPU加电启动时，会从存储的一个**固定地址**（指向**BIOS**）开始执行指令\n2. BIOS也会从一个**外置存储的固定地址**（**引导区**）来加载程序并执行，而**无需关心磁盘的数据格式**\n3. _**引导区是BIOS和操作系统的边界**_\n4. 对于BIOS来说，为了把控制权交给外置存储的程序，必须要能够执行外置存储的程序\n    - BIOS只需要执行**引导区**的程序，该程序不会很长，可以直接读入到内存中，然后再执行\n\n### 引导程序取得控制权后的需求\n1. 支持识别外置存储的数据格式，提供统一的功能给其它程序使用，无论是文件系统还是键值存储系统\n2. 提供管理外置存储的基础能力，例如查询外置存储里有什么文件，这可以实现为一个独立的程序_**ls**_\n3. 支持执行外置存储上的可执行程序，这可以实现为一个独立的程序_**sh**_\n4. 汇编程序编辑器，该程序与汇编语言没什么关系，是一个纯文本编辑器，这可以实现为一个独立的程序_**vi**_\n5. 汇编程序编译器，这可以实现为一个独立的程序_**asm**_\n6. 引导程序取得控制权后，最终需要把控制权交给sh程序，**sh程序是自我迭代的计算机扩展性的体现**\n\n### BIOS的职责\n1. 驱动程序：**键盘**和**显示器**\n2. 驱动程序：**外置存储**\n3. 支持跳转到外置存储的固定地址，把控制权交给该地址上的**引导程序**\n\n### 外置存储程序的职责\n1. 汇编程序编辑器（vi）\n2. 汇编程序编译器（asm）\n3. 执行机器代码的程序（sh）\n\n## 需求变化点小结\n1. 外置存储的**数据格式**，通过设计文件系统或键值存储系统来解决，另外提供ls等程序**管理外置存储中的文件**\n2. 执行**引导程序**后会迭代出怎样的能力：设计了sh程序，支持执行外置存储上的任何程序\n3. **编辑器的交互范式**，对此设计了vi程序，让它迭代编辑器的能力\n4. **汇编语言的使用范式**，对此设计了asm程序，让它响应CPU指令集和汇编语言的迭代\n\n<!-- indicate-the-source -->\n","tags":["Architecture"],"categories":["Architecture"]},{"title":"Java并发 -- 面向对象","url":"%2F2019%2F05%2F01%2Fjava-concurrent-object-oriented%2F","content":"\n## 封装共享变量\n1. 面向对象思想里面有一个很重要的特性：_**封装**_\n2. 封装：将**属性**和**实现细节**封装在**对象内部**，外部对象只能通过目标对象的**公共方法**来**间接访问**目标对象的内部属性\n3. 利用**面向对象**思想写**并发程序**的思路：将**共享变量**作为**对象属性**封装在内部，对**所有公共方法**制定_**并发访问策略**_\n\n<!-- more -->\n\n### Counter\nvalue为**共享变量**，作为Counter的**实例属性**，将get()和addOne()声明为**synchronized方法**，Counter就是一个**线程安全**的类\n```java\npublic class Counter {\n    private long value;\n\n    public synchronized long get() {\n        return value;\n    }\n\n    public synchronized long addOne() {\n        return ++value;\n    }\n}\n```\n\n### 不可变的共享变量\n1. 实际场景中，会有很多共享变量，如银行账户有卡号、姓名、身份证、信用额度等，其中卡号、姓名和身份证是不会变的\n2. 对于**不可变的共享变量**，可以使用**final**关键字修饰，从而_**避免并发问题**_\n\n## 识别共享变量间的约束条件\n1. 共享变量间的**约束条件**决定了_**并发访问策略**_\n2. 场景：库存管理中有个**合理库存**的概念，即库存有一个**上限**和一个**下限**\n\n### 忽略约束条件\n下面代码忽略了约束条件：即库存下限要**小于**库存上限\n```java\npublic class SafeWM {\n    // 库存下限\n    private final AtomicLong lower = new AtomicLong(0);\n    // 库存上限\n    private final AtomicLong upper = new AtomicLong(0);\n\n    // 设置库存下限\n    public void setLower(long v) {\n        lower.set(v);\n    }\n\n    // 设置库存上限\n    public void setUpper(long v) {\n        upper.set(v);\n    }\n}\n```\n\n### 存在竟态条件\n```java\npublic class SafeWM {\n    // 库存下限\n    private final AtomicLong lower = new AtomicLong(0);\n    // 库存上限\n    private final AtomicLong upper = new AtomicLong(0);\n\n    // 设置库存下限\n    public void setLower(long v) {\n        // 检验参数合法性\n        if (v > upper.get()) {\n            throw new IllegalArgumentException();\n        }\n        lower.set(v);\n    }\n\n    // 设置库存上限\n    public void setUpper(long v) {\n        // 检验参数合法性\n        if (v < lower.get()) {\n            throw new IllegalArgumentException();\n        }\n        upper.set(v);\n    }\n}\n```\n1. 上述代码存在_**竟态条件**_\n2. 假设库存的下限和上限分别为2和10，线程A调用setUpper(5)，线程B调用setLower(7)\n3. 线程A和线程B并发执行的结果可能是(7,5)，**不符合约束条件**\n\n### 使用管程\n```java\npublic class SafeWM {\n    // 库存下限\n    private final AtomicLong lower = new AtomicLong(0);\n    // 库存上限\n    private final AtomicLong upper = new AtomicLong(0);\n\n    // 设置库存下限\n    public synchronized void setLower(long v) {\n        // 检验参数合法性\n        if (v > upper.get()) {\n            throw new IllegalArgumentException();\n        }\n        lower.set(v);\n    }\n\n    // 设置库存上限\n    public synchronized void setUpper(long v) {\n        // 检验参数合法性\n        if (v < lower.get()) {\n            throw new IllegalArgumentException();\n        }\n        upper.set(v);\n    }\n}\n```\n\n## 制定并发访问策略\n1. **避免共享**：ThreadLocal + 为每个任务分配独立的线程\n2. **不变模式**：Java领域应用得很少\n3. **管程和其它同步工具**：管程是万能解决方案，但针对特定场景，使用JUC提供的读写锁、并发容器等同步工具性能会更好\n\n### 宏观原则\n1. **优先使用成熟的工具类**（JUC）\n2. **尽量少使用低级的同步原语**（synchronized、Lock、Semaphore）\n3. **避免过早优化**\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- 局部变量","url":"%2F2019%2F04%2F30%2Fjava-concurrent-local-var%2F","content":"\n## 斐波那契数列\n```java\nint[] fibonacci(int n) {\n    // 创建结果数组\n    int[] r = new int[n];\n    // 初始化第一、第二个数\n    r[0] = r[1] = 1; // ①\n    // 计算 2..n\n    for (int i = 2; i < n; i++) {\n        r[i] = r[i - 2] + r[i - 1];\n    }\n    return r;\n}\n```\n\n<!-- more -->\n\n## 方法调用过程\n```java\nint a = 7；\nint[] b = fibonacci(a);\nint[] c = b;\n```\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-local-var-call-process.png\" width=800/>\n\n1. 当调用fibonacci(a)的时候，CPU需要先找到方法fibonacci()的地址，然后跳转到这个地址去执行代码\n2. 最后CPU执行完fibonacci()方法之后，要能够返回，需要找到调用fibonacci()方法的下一条语句的地址\n3. 即int[] c = b;然后跳转到这个地址去执行\n\n### 栈寄存器\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-local-var-call-stack.png\" width=800/>\n\n1. CPU支持一种**栈结构**，与**方法调用**相关，称为**调用栈**，Java虽然靠JVM解释执行，但方法调用也是利用**栈结构**来解决的\n2. 有三个方法A、B、C，调用关系为A->B->C，在运行时会构建出类似上图的调用栈\n3. 每个方法在调用栈里都有自己的**独立空间**，称为**栈帧**，每个**栈帧**都有**对应方法所需要的参数**和**返回地址**\n4. 当**调用**方法时，会**创建**新的栈帧，并**压入**调用栈，当方法**返回**时，对应的栈帧会被**自动弹出**，即_**栈帧与方法是同生共死的**_\n\n## 局部变量\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-local-var-storage.png\" width=800/>\n\n1. 局部变量的作用域是**方法内部**，所以**局部变量**应该与方法同生共死，另外调用栈的**栈帧**和方法也是同生共死的\n2. 因此，_**局部变量是放在调用栈的栈帧里的**_\n\n## 调用栈与线程\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-local-var-call-stack-thread.png\" width=800/>\n\n1. 每个线程都有_**独立的调用栈**_\n2. 局部变量保存在线程各自独立的调用栈里（栈帧），不会在线程间共享，因此_**局部变量没有并发问题**_\n\n## 线程封闭\n1. 局部变量的思路是解决并发问题的一个重要技术：**线程间不共享**，更专业的名词叫**线程封闭**：_仅在**单线程**内访问数据_\n2. **数据库连接池**\n    - 通过线程封闭技术，保证一个Connection一旦被一个线程获取之后，在这个线程关闭Connection之前\n    - 不会再分配给其他线程，从而保证了Connection不会有并发问题\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- 线程数量","url":"%2F2019%2F04%2F29%2Fjava-concurrent-thread-count%2F","content":"\n## 多线程的目的\n1. 使用多线程的目的是为了_**提高程序性能**_\n2. 度量程序性能的**核心指标**：_**延迟** + **吞吐量**_\n    - **延迟**：发出请求到收到响应的**时间**，延迟越短，意味着程序执行得越快，性能越好\n    - **吞吐量**：在**单位时间**内能处理请求的数量，吞吐量越大，意味着程序能处理的请求越多，性能越好\n    - **同等条件下，延迟越短，吞吐量越大**，但两者隶属于不同的维度（一个**时间**维度，一个**空间**维度），并**不能互相转换**\n3. 提升程序性能：_**降低延迟，提高吞吐量**_\n\n<!-- more -->\n\n## 多线程的应用场景\n1. 要达到**降低延迟，提高吞吐量**的目的，有两个方向：一个是**优化算法**，一个是_**将硬件的性能发挥到极致**_\n    - 前者属于**算法**范畴，后者与**并发编程**息息相关\n2. 在**并发编程**领域，_**提高性能本质上就是要提高硬件的利用率**_，主要是提升**IO利用率**和**CPU利用率**\n3. 操作系统解决**硬件利用率**问题的对象往往是**单一的硬件设备**，而**并发编程**要解决**CPU和IO设备综合利用率**的问题\n\n### 综合利用率\n假设程序按照**CPU计算**和**IO操作**交叉执行的方式运行，而且CPU计算和IO操作的耗时是**1:1**\n\n#### 单线程\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-thread-count-utilization-rate-single-thread.png\" width=800/>\n\n1. 单线程时，执行CPU计算的时候，IO设备空闲，执行IO操作时，CPU空闲，所以CPU利用率和IO设备的利用率都是**50%**\n\n#### 两线程\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-thread-count-utilization-rate-two-thread.png\" width=800/>\n\n1. 两个线程时，当线程A执行CPU计算时，线程B执行IO操作，当线程A执行IO操作时，线程B执行CPU计算\n2. 这样CPU利用率和IO设备的利用率都达到了100%，相对于单线程**吞吐量**提高了1倍\n3. 逆向思维：如果CPU和IO设备的利用率都**很低**，可以通过**增加线程**来**提高吞吐量**\n\n#### 多核\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-thread-count-utilization-rate-multi-core.png\" width=800/>\n\n1. 在**单核**时代，多线程主要用来_**平衡CPU和IO设备**_\n    - 如果程序**只有CPU计算**，那么多线程反而会让**性能变差**，因为增加了**线程切换**的成本\n2. 在**多核**时代，纯CPU计算的程序可以利用多线程来**提升性能**，因为利用多核可以_**降低响应时间**_\n    - 例如对于4核CPU，可以将一个计算任务拆分成4个**独立**的子任务，交由4个线程分别在4个核上执行\n    - 采用单线程时CPU的利用率只有25%，而采用4线程时能将CPU的利用率提高到100%\n\n## 线程数量\n需要依据**具体的应用场景**来确定**线程数量**：_**CPU密集型**_ + _**IO密集型**_\n\n### CPU密集型\n1. 对于CPU密集型来说，多线程本质上是要_**提升CPU的利用率**_\n2. 为了减少**线程切换**的成本，理论上设置为**CPU核数**即可\n3. 但在工程上，一般会设置成**CPU核数+1**，这是为了**保证CPU的利用率**（在某个线程阻塞时，额外的线程能够补上）\n\n### IO密集型\n\n#### 单核\n> 最佳线程数 = 1 + (IO耗时 / CPU耗时)\n\n##### 三线程\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-thread-count-utilization-rate-three-thread.png\" width=800/>\n\n1. 如果CPU计算和IO操作的耗时比是1:2\n2. 对于线程A，当CPU从线程B、C切换回来时，线程A正好执行完IO操作，这样CPU和IO设备的利用率都达到了100%\n\n#### 多核\n> 最佳线程数 = CPU核数 * [1 + (IO耗时 / CPU耗时)]\n\n#### 关键参数\n1. 对于IO密集型的应用场景，关键参数是**IO耗时/CPU耗时**，但这个参数是**动态变化**的\n2. 因此，如果要估算这个参数，需要做各个不同场景下的**压测**\n    - 在压测的过程中，要重点关注**CPU、IO设备的利用率**和性能指标（**延迟+吞吐量**）之间的关系\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- 线程生命周期","url":"%2F2019%2F04%2F28%2Fjava-concurrent-thread-life-cycle%2F","content":"\n## 通用的线程生命周期\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-thread-life-cycle-common.png\" width=800/>\n\n\n<!-- more -->\n1. **初始状态**\n    - 线程已经被创建，但还不允许分配CPU执行\n    - 该状态属于**编程语言**所特有，仅仅在编程语言层面被创建，在操作系统层面，真正的线程还没有创建\n2. **可运行状态**\n    - 线程可以分配CPU执行，该状态下真正的操作系统线程已经被创建\n3. **运行状态**\n    - 当有空闲的CPU时，操作系统会将其分配给处于**可运行状态**的线程，被分配到CPU的线程的状态就转换为**运行状态**\n4. **休眠状态**\n    - 处于**运行状态**的线程如果调用一个**阻塞的API**或者**等待某个事件**，那么线程状态就会切换为**休眠状态**\n    - 切换为休眠状态的同时会**释放CPU使用权**，_**处于休眠状态的线程永远没有机会获得CPU使用权**_\n    - 当等待的事件出现后，线程就会从休眠状态切换到**可运行状态**\n5. **终止状态**\n    - 线程**执行完**或者**出现异常**就会进入**终止状态**，处于终止状态的线程不会切换到其它状态\n    - 进入终止状态意味着线程生命周期的**结束**\n\n### 简化合并\n1. 通用的线程生命周期里的5种状态在不同的编程语言会有**简化合并**\n2. Java把**可运行状态**和**运行状态**合并了\n    - 这两个状态对操作系统调度层是有价值的，但**JVM把线程调度交给了操作系统处理**，JVM并不关心这两个状态\n3. JVM同时也细化了**休眠状态**\n\n\n## Java线程的生命周期\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-thread-life-cycle-java.png\" width=800/>\n\n1. Java线程的状态可以参照代码`java.lang.Thread.State`\n2. 在操作系统层，Java线程状态的**BLOCKED、WAITING、TIMED_WAITING**都是**休眠状态**，永远无法获得CPU的使用权\n3. BLOCKED、WAITING、TIMED_WAITING可以理解为导致线程**进入休眠状态**的三个**原因**\n\n### RUNNABLE + BLOCKED\n1. 唯一场景：**线程等待synchronized的隐式锁**\n2. synchronized修饰的方法（代码块）在同一时刻只允许一个线程执行，其它线程只能等待（**RUNNABLE -> BLOCKED**）\n3. 当等待的线程获得synchronized隐式锁时，**BLOCKED -> RUNNABLE**\n\n#### 阻塞式API\n1. 在**操作系统**层面，操作系统线程调用**阻塞式API**，会转换到_**休眠状态**_\n2. 在**JVM**层面，Java线程调用**阻塞式API**，Java线程的状态会_**保持RUNNABLE**_\n    - _**JVM层面并不关心操作系统调度相关的状态**_\n    - 在JVM看来，等待**CPU使用权**（操作系统层面为**可执行状态**）和等待**IO**（操作系统层面为**休眠状态**）没有区别\n        - 都是在等待某个资源，所以都归入RUNNABLE状态\n\n### RUNNABLE + WAITING\n1. 获得synchronized隐式锁的线程，调用无参数的`Object.wait()`方法\n2. 调用无参数的`Thread.join()`方法，join是一种**线程同步**的方式\n    - 有线程A，当线程B调用A.join()时，线程B会等待线程A执行完，线程B的状态切换：**RUNNABLE -> WAITING**\n    - 当线程A执行完后，线程B的状态切换：**WAITING -> RUNNABLE**\n3. 调用`LockSupport.park()`方法，**当前线程会阻塞**，线程状态切换：**RUNNABLE -> WAITING**\n    - 调用`LockSupport.unpark(Thread thread)`方法可以唤醒**目标线程**\n    - 目标线程的状态切换：**WAITING -> RUNNABLE**\n\n### RUNNABLE + TIMED_WAITING\n1. 调用**带超时参数**的`Thread.sleep(long millis)`方法\n2. 获得synchronized隐式锁的线程，调用**带超时参数**的`Object.wait(long timeout)`方法\n3. 调用**带超时参数**的`Thread.join(long millis)`方法\n4. 调用**带超时参数**的`LockSupport.parkNanos(Object blocker, long nanos)`方法\n5. 调用**带超时参数**的`LockSupport.parkUntil(long deadline)`方法\n\n### NEW + RUNNABLE\n```java\n// 方式1\nclass MyThread extends Thread {\n    @Override\n    public void run() {\n        super.run();\n    }\n}\nThread myThread = new MyThread();\n\n// 方式2\nclass Runner implements Runnable {\n    @Override\n    public void run() {\n        // task code\n    }\n}\nThread thread = new Thread(new Runner());\n```\n1. Java刚创建出来的Thread对象就是处于NEW状态，创建Thread对象的两种方式：继承Thread + 实现Runnable\n2. NEW状态的线程，_**不会被操作系统调度**_，所以不会执行，调用线程对象的start()方法：**NEW -> RUNNABLE**\n\n### RUNNABLE + TERMINATED\n当线程**执行完**run()方法后，会自动切换到TERMINATED状态；在执行run()方法的过程中**抛出异常**，也会导致线程终止\n\n#### stop() + interrupt()\n1. stop()方法会**直接杀死线程**，不给线程喘息的机会\n    - 如果线程持有ReentrantLock锁，被stop()的线程**不会自动调用**ReentrantLock.unlock()去释放锁\n    - 类似的方法还有suspend()和resume()\n2. interrupt()方法仅仅**通知线程**，收到通知的线程可以选择**无视**这个通知，继续选择执行后续操作\n3. 被interrupt的线程，收到通知的两种方式：_**InterruptedException**_ + _**主动检测**_\n4. **InterruptedException**\n    - 当线程A处于**WAITING**或**TIMED_WAITING**状态时，其它线程调用A.interrupt()方法时\n        - 会使线程A返回**RUNNABLE**状态，同时线程A的代码会触发InterruptedException异常\n        - Thread.sleep(long millis)、Thread.join()、Object.wait()的方法签名都有throw InterruptedException\n    - 当线程A处于**RUNNABLE**状态时，并且阻塞在java.nio.channels.InterruptibleChannel上时\n        - 如果其它线程调用A.interrupt()方法，线程A会触发java.nio.channels.ClosedByInterruptException\n    - 当线程A处于**RUNNABLE**状态时，并且阻塞在java.nio.channels.Selector上时\n        - 如果其它线程调用A.interrupt()方法，线程A会立即返回\n    - **线程中断状态**\n        - 线程A抛出InterruptedException后，会_**重置线程中断状态**_\n5. **主动检测**\n    - 当线程A处于**RUNNABLE**状态，并且**没有阻塞**在某个IO操作上，此时需要依赖线程A**主动检测**自己的中断状态\n        - 如果其它线程调用A.interrupt()方法，那么线程A可以通过isInterrupted()方法来检测自己是否被中断了\n\n```java\nThread th = Thread.currentThread();\nwhile (true) {\n    if (th.isInterrupted()) {\n        // 死循环，永远无法break\n        break;\n    }\n    try {\n        Thread.sleep(100);\n    } catch (InterruptedException e) {\n        // 抛出InterruptedException会重置线程中断状态，导致死循环\n        // 正确的做法是重新设置中断标志位\n        th.interrupt();\n    }\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java核心 -- 字符串","url":"%2F2019%2F04%2F27%2Fjava-core-string%2F","content":"\n## String\n1. String是Java语言非常**基础**和**重要**的类，提供了构造和管理字符串的各种基本逻辑，是典型的**Immutable**类\n    - String是Immutable类的典型实现，原生的保证了**基础线程安全**，因为无法对它内部数据进行任何修改\n2. 被声明为final class，由于String的**不可变**性，类似拼接、裁剪字符串等动作，都会**产生新的String对象**\n3. 由于字符串操作的普遍性，所以相关操作的效率往往对**应用性能**有明显影响\n\n<!-- more -->\n\n## StringBuffer\n1. StringBuffer是为了解决拼接产生太多中间对象的问题而提供的一个类\n2. StringBuffer本质是一个**线程安全**的可修改字符串序列，保证了线程安全，但也带来了额外的**性能开销**\n3. StringBuffer的线程安全是通过把各种修改数据的方法都加上synchronized关键字实现的\n    - 这种方式非常适合常见的线程安全类的实现，不必纠结于synchronized的性能\n    - **过早的优化是万恶之源**，可靠性、正确性和代码可读性才是大多数应用开发的首要考虑因素\n\n## StringBuilder\n1. StringBuilder在能力上和StringBuffer没有本质区别，但去掉了线程安全的部分，有效减小了开销\n2. StringBuffer和StringBuilder底层都是利用可修改的数组（Java 8为char[]，Java 9为byte[]），都继承AbstractStringBuilder\n    - 区别仅在于最终的方法是否有synchronized关键字\n3. 内部数组初始大小为初始字符串长度+16\n    - 如果确定拼接会发生多次，并且是可预计的，最好指定**合适的初始大小**，避免多次**扩容的开销**（arraycopy）\n\n## 字符串拼接\n```java\npublic class StringConcat {\n    public static void main(String[] args) {\n        String str = \"aa\" + \"bb\" + \"cc\" + \"dd\";\n        System.out.println(\"str : \" + str);\n    }\n}\n```\n先用**javac**编译，再用**javap**反编译\n\n### Java 8\n```\npublic static void main(java.lang.String[]);\n  descriptor: ([Ljava/lang/String;)V\n  flags: ACC_PUBLIC, ACC_STATIC\n  Code:\n    stack=3, locals=2, args_size=1\n       0: ldc           #2                  // String aabbccdd\n       2: astore_1\n       3: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;\n       6: new           #4                  // class java/lang/StringBuilder\n       9: dup\n      10: invokespecial #5                  // Method java/lang/StringBuilder.\"<init>\":()V\n      13: ldc           #6                  // String str :\n      15: invokevirtual #7                  // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;\n      18: aload_1\n      19: invokevirtual #7                  // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;\n      22: invokevirtual #8                  // Method java/lang/StringBuilder.toString:()Ljava/lang/String;\n      25: invokevirtual #9                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n      28: return\n```\n1. \"aa\" + \"bb\" + \"cc\" + \"dd\"会被当成常量\"aabbccdd\"\n2. 字符串的拼接操作会自动被javac转换成StringBuilder操作\n\n### Java 11\n```\npublic static void main(java.lang.String[]);\n  descriptor: ([Ljava/lang/String;)V\n  flags: ACC_PUBLIC, ACC_STATIC\n  Code:\n    stack=2, locals=2, args_size=1\n       0: ldc           #2                  // String aabbccdd\n       2: astore_1\n       3: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;\n       6: aload_1\n       7: invokedynamic #4,  0              // InvokeDynamic #0:makeConcatWithConstants:(Ljava/lang/String;)Ljava/lang/String;\n      12: invokevirtual #5                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n      15: return\n```\n1. \"aa\" + \"bb\" + \"cc\" + \"dd\"同样会被当成常量\"aabbccdd\"\n2. Java 11为了更加统一字符串操作优化，提供了StringConcatFactory，作为一个统一的入口\n3. javac自动生成的代码，未必是最优的，但针对普通场景已经足够了\n\n## 字符串缓存\n1. 把常见应用进行Heap Dump，然后分析对象组成，大约25%的对象是字符串，并且其中约50%是**重复**的\n    - 如果能避免创建重复字符串，可以有效降低**内存消耗**和**对象创建开销**\n2. String在Java 6提供了intern()，目的是提示JVM把相应的字符串缓存起来\n    - 创建String对象并且调用intern()，如果已经有缓存的字符串，就会返回缓存里的实例，否则将其缓存起来\n    - 被缓存的字符串会存储在**PermGen**（永久\u0010代），PermGen的**空间非常有限**，只有**FullGC**会处理PermGen\n    - 所以，如果使用不当，会触发OOM\n    - 另外，intern()是一种**显式**地排重机制，但这也是一种_**代码污染**_\n3. 在后续的Java版本中，字符串缓存被放置在**堆**中，极大的避免了PermGen占满的问题\n    - 在Java 8中被**MetaSpace**（元数据区）取代了\n4. 默认缓存大小也在不断地扩大，可以通过`-XX:+PrintStringTableStatistics`查看\n    - 也可以通过`-XX:StringTableSize=N`调整大小，但绝大部分情况下不需要调整\n5. 在Oracle JDK 8u20出现了G1 GC的字符串排重，通过**将相同数据的字符串指向同一份数据**来实现的\n    - 这是JVM底层的改变，并不需要Java类库做修改\n    - 该功能目前是默认关闭的，启动参数`-XX:+UseStringDeduplication`\n\n```java\n$ java -XX:+PrintStringTableStatistics -version\njava version \"1.8.0_191\"\nJava(TM) SE Runtime Environment (build 1.8.0_191-b12)\nJava HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)\nSymbolTable statistics:\nNumber of buckets       :     20011 =    160088 bytes, avg   8.000\nNumber of entries       :      9616 =    230784 bytes, avg  24.000\nNumber of literals      :      9616 =    380296 bytes, avg  39.548\nTotal footprint         :           =    771168 bytes\nAverage bucket size     :     0.481\nVariance of bucket size :     0.483\nStd. dev. of bucket size:     0.695\nMaximum bucket size     :         5\nStringTable statistics:\nNumber of buckets       :     60013 =    480104 bytes, avg   8.000\nNumber of entries       :       672 =     16128 bytes, avg  24.000\nNumber of literals      :       672 =     45472 bytes, avg  67.667\nTotal footprint         :           =    541704 bytes\nAverage bucket size     :     0.011\nVariance of bucket size :     0.011\nStd. dev. of bucket size:     0.106\nMaximum bucket size     :         2\n```\n\n## Intrinsic\n1. 在运行时，字符串的一些基础操作会直接利用JVM内部的**Intrinsic机制**\n    - 往往运行的是**特殊优化的本地代码**，而不是Java代码生成的字节码\n2. Intrinsic：是一种**利用native方式hard-coded**的逻辑，算是一种特殊的内联，很多优化还需要使用**特定的CPU指令**\n3. 通过`-XX:+PrintCompilation -XX:+UnlockDiagnosticVMOptions -XX:+PrintInlining`查看\n\n```java\n$ java -XX:+PrintCompilation -XX:+UnlockDiagnosticVMOptions -XX:+PrintInlining -version\n    64    1       3       java.lang.String::hashCode (55 bytes)\n    66    2       3       java.lang.String::charAt (29 bytes)\n                             @ 18  java/lang/StringIndexOutOfBoundsException::<init> (not loaded)   not inlineable\n    67    3       3       java.lang.String::length (6 bytes)\n    68    4     n 0       java.lang.System::arraycopy (native)   (static)\n    68    5       3       java.lang.String::equals (81 bytes)\n    java version \"1.8.0_191\"\n    Java(TM) SE Runtime Environment (build 1.8.0_191-b12)\n    Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)\n```\n\n## 字符串压缩\n1. 在Java的历史版本中，使用了char[]来存储数据\n2. 但char占用**2个byte**，而拉丁语系语言的字符，不需要太宽的char，这会造成一定的浪费\n3. 在Java 9中引入了**Compact Strings**的设计\n    - 将存储方式从char[]数组改变为一个byte[]加上一个标识编码的coder\n    - 并且将相关字符串操作类都进行了修改，所有相关的Intrinsic都进行了重写，保证没有任何性能损失\n    - 该特性对绝大部分应用来说是**透明**的\n\n<!-- indicate-the-source -->\n","tags":["Java Core"],"categories":["Core"]},{"title":"Java并发 -- 管程","url":"%2F2019%2F04%2F27%2Fjava-concurrent-monitor%2F","content":"\n## 概述\n1. Java语言在1.5之前，唯一提供的**并发原语**是**管程**\n2. 在Java 1.5提供的JUC包中，也是以**管程**技术为基础的\n3. _**管程是一把解决并发问题的万能钥匙**_\n\n<!-- more -->\n\n## 管程\n1. 在Java 1.5之前，仅仅提供synchronized关键字和wait/notify/notifyAll方法\n2. Java采用的是**管程**技术，synchronized关键字以及wait/notify/notifyAll方法都是**管程的组成部分**\n3. **管程和信号量是等价的**（即用管程能实现信号量，用信号量也能实现管程），但管程**更容易使用**，所以Java选择了管程\n4. **Monitor**，在**Java**领域会翻译成**监视器**，在**操作系统**领域会翻译成**管程**\n5. 管程：_**管理共享变量以及对共享变量的操作过程，让它们支持并发**_\n    - 对应Java领域：管理类的**成员变量**和**成员方法**，让这个类是**线程安全**的\n\n## MESA模型\n1. 在管程的发展史上，先后出现了三种不同的管程模型，分别是：Hasen模型、Hoare模型和MESA模型\n2. 现在广泛应用的是**MESA**模型，Java管程的实现也参考了MESA模型\n3. 管程可以解决并发领域的两大**核心**问题：_**互斥+同步**_\n    - **互斥**：在同一时刻**只允许一个线程**访问共享资源\n    - **同步**：线程之间如何**通信**、**协作**\n\n### 互斥\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-monitor-exclusive.png\" width=800/>\n\n1. 管程解决互斥问题的思路：将**共享变量以及对共享变量的操作**统一封装起来\n2. 管程X将共享变量queue和相关的操作enq()和deq()都封装起来\n3. 线程A和线程B如果想要访问共享变量queue，只能通过调用管程X提供的enq()和deq()方法来实现\n4. enq()和deq()保持互斥性，只允许一个线程进入管程X\n5. **管程模型与面向对象高度契合**\n\n### 同步\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-monitor-sync.png\" width=800/>\n\n1. 在管程模型里，共享变量和对共享变量的操作是被封装起来的，最外层的框是代表封装的意思\n    - 框的上面只有一个入口，并且在入口旁边还有一个_**入口等待队列**_\n    - 当多个线程同时试图进入管程内部时，只允许一个线程进入，其他线程就在**入口等待队列**中等待\n2. 管程里还引入了**条件变量**的概念，_**每个条件变量都对应一个等待队列**_\n    - 条件变量和其对应等待队列的作用：**线程同步**\n\n#### 实例：出队入队\n```java\n// 下列三对操作的语义是相同的\n// Condition.await()        Object.wait()\n// Condition.signal()       Object.notify()\n// Condition.signalAll()    Object.notifyAll()\npublic class BlockedQueue<T> {\n    private static final int MAX_SIZE = 10;\n    // 可重入锁\n    private final Lock lock = new ReentrantLock();\n    // 条件变量：队列不满\n    private final Condition notFull = lock.newCondition();\n    // 条件变量：队列不空\n    private final Condition notEmpty = lock.newCondition();\n    // 队列实际存储：栈\n    private final Stack<T> stack = new Stack<>();\n\n    // 入队\n    public void enq(T t) {\n        // 先获得互斥锁，类似于管程中的入口\n        lock.lock();\n        try {\n            while (stack.size() >= MAX_SIZE) {\n                // 队列已满，等待队列不满，才可入队\n                notFull.await();\n            }\n            // 入队后，通知队列不空，可出队\n            stack.push(t);\n            notEmpty.signalAll();\n        } catch (InterruptedException ignored) {\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    // 出队\n    public T deq() {\n        // 先获得互斥锁，类似于管程中的入口\n        lock.lock();\n        try {\n            while (stack.isEmpty()) {\n                // 队列已空，等待队列不空，才可出队\n                notEmpty.await();\n            }\n            // 出队后，通知队列不满，可入队\n            T pop = stack.pop();\n            notFull.signalAll();\n            return pop;\n        } catch (InterruptedException ignored) {\n        } finally {\n            lock.unlock();\n        }\n        return null;\n    }\n}\n```\n1. 假设线程T1执行出队操作，执行出队操作的前提条件是队列不空，而**队列不空**就是管程里的**条件变量**\n2. 如果线程T1进入管程后恰巧发现队列为空，就会到**队列不空这个条件变量的等待队列**里等待\n3. 当线程T1**进入条件变量的等待队列后**，是**允许其他线程进入管程**的\n4. 再假设线程T2执行入队操作，执行成功后，队列不空这个条件对于线程T1来说是已经满足了的，线程T2会通知线程T1\n5. 当线程T1得到通知后，会从**等待队列**里面出来，但**不能马上执行**，需要重新进入到**入口等待队列**\n\n### 编程范式\n1. 对于**MESA管程**，有一个编程范式：`while(条件不满足){wait();}`，这是MESA管程**特有**的\n2. Hasen模型、Hoare模型和MESA模型的**核心**区别：_**当条件满足时，如何通知相关线程**_\n3. 管程要求同一时刻只允许一个线程执行，当线程T2的操作使线程T1等待的条件满足时\n    - **Hasen模型**：要求notify()放在**代码的最后**，这样T2通知完T1后，T2也就结束了，然后T1再执行\n        - 缺点：**不灵活**\n    - **Hoare模型**：T2通知完T1后，T2阻塞，T1马上执行，等T1执行完，再唤醒T2\n        - 缺点：相比Hasen模型模型，**多了一次阻塞唤醒操作**\n    - **MESA模型**：T2通知完T1后，T2接着执行，T1不会立即执行，仅仅是从**条件变量的等待队列**进入到**入口等待队列**\n        - 优点：notify()不用放在代码的最后，也没有多余的唤醒阻塞操作\n        - 缺点：当T1再次执行的时候，**曾经满足的条件可能已经不满足了**，所以才有上面特有的编程范式\n\n## notify的使用场景\n1. 一般情况下，_**尽量使用notifyAll()**_\n2. 满足3个条件，也可以使用notify()\n    - 所有等待线程拥有**相同的等待条件**\n    - 所有等待线程**被唤醒后执行相同的操作**\n    - **只需要唤醒一个线程**\n\n## Java的管程实现\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-monitor-built-in-synchronized.png\" width=800/>\n\n1. Java参考了MESA模型，语言内置的管程（synchronized）对MESA模型进行了**精简**\n2. 在MESA模型中，条件变量可以有多个，_**但Java语言内置的管程只有一个条件变量**_\n3. Java内置的管程方案（synchronized）使用很简单\n    - synchronized关键字修饰的代码块，在**编译期**会自动生成相关加锁和解锁的代码，但**仅支持一个条件变量**\n4. JUC包实现的管程**支持多个条件变量**（例如ReentrantLock），但需要开发人员手动进行加锁和解锁操作\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"架构 -- 编程语言","url":"%2F2019%2F04%2F25%2Farchitecture-programming-language%2F","content":"\n## 编程范式\n\n### 过程式\n1. 过程式就是按一条条命令的方式执行，而**机器语言**本身就是由一条条指令构成的，也是**过程式**的\n2. 过程式是**最为常见**的，每个编程语言都有过程式的影子，代表为Fortran、C/C++、JavaScript、Go\n3. 过程式编程中**最核心**的两个概念：**结构体**（自定义类型）和**过程**（函数）\n    - 通过**结构体**对数据进行**组合**，可以构建出**任意复杂的自定义数据结构**\n    - 通过**过程**可以抽象出**任意复杂的自定义指令**，复用之前的成果，简化意图的表达\n\n<!-- more -->\n\n### 函数式\n1. 函数式本质上是**对过程式编程的一种约束**，最核心的主张是**变量不可变**，**函数尽可能没有副作用**\n    - 对于通用语言而言，所有函数都没有副作用是不可能的，例如内部有IO行为的函数就有副作用\n2. 既然变量不可变，函数没有副作用，那么出错的机会就会减少，代码质量也就变高，代表为Haskell、Erlang\n3. 大部分语言都比较**难以彻底实施**函数式的编程思想，但在思想上会有所借鉴\n4. 函数式编程相对小众，写代码质量高，但**学习门槛高**\n\n### 面向对象\n1. 面向对象是在过程式的基础上，引入了**对象**（**类**）和**对象方法**（**类成员函数**）\n2. 面向对象主张尽可能把方法（过程）**归纳到合适的对象**（**类**）上，不主张全局函数（过程），代表为Java、C#、C++、Go\n3. 面向对象的核心思想是引入**契约**，基于**对象**的概念对代码的使用界面进行抽象和封装，主要优点如下\n    - **清晰的使用界面**：某种类型的对象有哪些方法一目了然，不像过程式编程，数据结构和过程的关系非常松散\n    - **信息封装**：面向对象不主张绕过对象的使用接口侵入到对象的内部实现细节\n4. 面向对象还有一个至关重要的概念是**接口**，通过接口可以**优雅**地实现**多态**，多态的概念如下\n    - 对象和对象方法是**强关联**的，可以引入接口来**抽象不同对象的行为**\n    - 这样不同对象就可以用**相同的代码**来实现类似的复杂行为\n5. 多数面向对象语言还会引入**继承**的概念，虽然继承带来了编码上的便捷性，但也带来了不必要的负担\n    - 何时使用**组合**？何时使用**继承**？Go给出了最完美的答案：_**放弃继承，全面强化组合**_\n    - 继承属于**过度设计**，会产生复杂的对象继承树\n\n### 面向连接\n1. 不同的编程范式**并不互斥**，某些编程语言会有**明确的编程范式主张**，如Java是纯正的面向对象语言，反对全局过程\n2. 某些编程语言主张自己是**多范式**的，典型代表是C++，但C++太复杂，以至于让人**误以为**多范式会大大增加了语言的复杂度\n3. Go是多范式更好的例子，Go本身并没有声称自己是多范式的，但实际上_**Go保留了每种编程范式的精华部分**_\n    - Go没有声称自己是多范式的，而是认为自己是一门**面向连接**的语言\n4. 面向连接即**朴素的组合思想**，研究连接就是研究人和人的组合，代码和代码的组合\n5. 面向对象创造性地把**契约**的重要性提到了非常重要的高度，但**并不是只有对象需要契约**，_**语言设计的方方面面都需要契约**_\n    - 代码规范约束了人的行为，是人与人的连接契约\n    - 消息传递约束了进程（这里的进程是抽象的，Go中叫goroutine）的行为，是进程与进程的连接契约\n        - 消息传递是**多核背景**下流行起来的编程思想\n        - 核心主张：尽可能用**消息传递来取代共享内存**，从而尽可能**避免显式地锁**，降低编程负担\n        - Go不只是提供**语言内建**的消息传递机制，同时它的消息传递是**类型安全**的，大大较低犯错机会\n\n## 工程化能力\n1. 包（package）：代码的发布单元\n2. 版本（version）：包的依赖管理\n3. 文档生成（doc）\n4. 单元测试（test）\n\n## 执行器行为\n1. 编译的目标文件是可执行程序，代表为Fortran、C/C++、Go\n2. 生成跨平台的虚拟机字节码，有独立的执行器（虚拟机）执行字节码，代表为Java、Erlang\n3. 直接解释执行，代表为JavaScript\n    - 纯解释执行的语言已经不多了，大多数语言也只是看起来直接执行\n    - 内部还是会基于字节码的虚拟机，目的是为了提高性能\n\n## 语言对架构的影响\n<img src=\"https://architecture-1253868755.cos.ap-guangzhou.myqcloud.com/architecture-programming-language.png\" width=800/>\n\n1. 淡紫色是**硬件层次的依赖**，是程序工作的**物理基础**，浅绿色是**软件层次的依赖**，是程序工作的**生态环境**\n2. 桔色是**库或源代码层次的依赖**，是**程序本身的组成部分**，细分为两部分：业务无关的框架和基础库，业务架构\n3. **业务架构与语言无关**，但语言的选择对业务架构的决策会有深远的影响，主要体现在两方面：_**开发效率**和**维护成本**_\n\n<!-- indicate-the-source -->\n","tags":["Architecture"],"categories":["Architecture"]},{"title":"Java核心 -- 引用","url":"%2F2019%2F04%2F24%2Fjava-core-reference%2F","content":"\n## 强引用、软引用、弱引用、幻象引用\n主要差别：对象不同的**可达性**（reachable）和对**垃圾收集**的影响\n\n### 强引用 - Strong\n1. 最常见的**普通对象引用**，只要还有强引用指向一个对象，就表明该对象还存活，垃圾收集器不会处理这种对象\n2. 一个普通的对象，如果没有其他的引用关系，一旦超过了引用的作用域或者显式地将强引用赋值为null，就有可能被收集\n\n### 软引用 - Soft\n1. 软引用是一种相对于强引用**弱化**一些的引用，可以让对象**豁免一些垃圾收集**（内存不足）\n2. 只有当JVM认为**内存不足**时，才会去试图回收软引用指向的对象\n3. JVM会确保在抛出OutOfMemoryError之前，清理软引用指向的对象，软引用通常用来实现**内存敏感的缓存**\n\n<!-- more -->\n\n### 弱引用 - Weak\n1. 弱引用**不能使对象豁免垃圾收集**，仅仅只是提供一种**访问在弱引用状态下对象**的途径\n2. 弱引用可以用来构建一种**没有特定约束的关系**，例如维护一种**非强制性的映射关系**\n    - 如果试图获取时对象还在，就使用它，否则重新实例化\n3. 弱引用也是很多**缓存**实现的选择\n\n### 虚引用 - Phantom\n1. **不能通过虚引用访问到对象**，虚引用仅仅只是提供一种机制：_**确保对象被finalize以后执行某些事情**_\n2. 可以利用虚引用**监控对象的创建和销毁**\n\n## 可达性状态\n<img src=\"https://java-core-1253868755.cos.ap-guangzhou.myqcloud.com/java-core-reference-flow.png\" width=600/>\n\n1. 强可达（Strongly Reachable）\n    - 当一个对象可以有一个或多个线程**可以不通过各种引用访问到**的情况\n    - 例如，新创建一个对象，那么创建该对象的线程对它就是强可达\n2. 软可达（Softly Reachable）\n    - 只能通过**软引用**才能访问到对象的状态\n3. 弱可达（Weakly Reachable）\n    - 无法通过**强引用**或者**软引用**访问，只能通过**弱引用**访问时对象的状态\n    - 这是十分**临近finalize**的时机，当**弱引用被清除**时，就符合finalize的条件了\n4. 虚可达（Phantom Reachable）\n    - 没有强引用、软引用和弱引用关联\n    - 对象被**finalize**过，只有**虚引用**指向该对象\n5. 不可达（UnReachable）\n    - 意味着对象可以被**清除**了\n\n## Reference\n1. 所有的引用类型，都是`java.lang.ref.Reference`的子类，提供`T get()`方法\n    - The object to which this reference refers, or null if this reference object has been cleared\n2. 除了**虚引用**（get()永远返回null），如果对象还没有被**销毁**，都可以通过get()获取**原对象**\n    - _**利用软引用和弱引用，可以将访问到的对象，重新指向强引用，即人为的改变对象的可达性状态**_\n    - 因此垃圾收集器会存在**二次确认**的问题，以保证处于**弱引用状态**的对象，没有改变为强引用\n\n## ReferenceQueue\n```java\nObject counter = new Object();\nReferenceQueue referenceQueue = new ReferenceQueue();\nPhantomReference<Object> p = new PhantomReference<>(counter, referenceQueue);\ncounter = null;\nSystem.gc();\ntry {\n    // 限时阻塞\n    Reference<Object> reference = referenceQueue.remove(1000L);\n    if (reference != null) {\n        // do something\n    }\n} catch (Exception e) {\n}\n```\n1. 创建各种引用关系并**关联到相应对象**时，可以选择是否需要**关联到引用队列**\n2. JVM会在**特定时机**将引用enqueue到引用队列里\n3. 我们可以从引用队列里获取引用（remove方法）后进行后续逻辑\n4. 尤其对于**虚引用**，get方法只会返回null，如果再不关联引用队列，基本没什么意义了\n5. 利用引用队列，可以在对象处于**相应状态**时，执行后续的处理逻辑\n    - 对于**虚引用**来说，相应的状态指的是对象被**finalize**后，处于**虚可达**状态\n\n## PrintReferenceGC\n\n```java\n// -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintReferenceGC\n1.926: [GC (Allocation Failure) 1.929: [SoftReference, 0 refs, 0.0000249 secs]1.929: [WeakReference, 439 refs, 0.0000364 secs]1.929: [FinalReference, 1187 refs, 0.0017734 secs]1.931: [PhantomReference, 0 refs, 0 refs, 0.0000126 secs]1.931: [JNI Weak Reference, 0.0000120 secs][PSYoungGen: 33280K->3068K(38400K)] 33280K->3140K(125952K), 0.0059535 secs] [Times: user=0.01 sys=0.01, real=0.00 secs]\n```\n\n<!-- indicate-the-source -->\n","tags":["Java Core"],"categories":["Core"]},{"title":"Java并发 -- 安全性、活跃性、性能","url":"%2F2019%2F04%2F23%2Fjava-concurrent-safety-active-performance%2F","content":"\n## 安全性问题\n1. 线程安全的本质是**正确性**，而正确性的含义是**程序按照预期执行**\n2. 理论上**线程安全**的程序，应该要避免出现**可见性问题（CPU缓存）、原子性问题（线程切换）和有序性问题（编译优化）**\n3. 需要分析是否存在线程安全问题的场景：_**存在共享数据且数据会发生变化，即有多个线程会同时读写同一个数据**_\n4. 针对该理论的解决方案：不共享数据，采用**线程本地存储**（Thread Local Storage，TLS）；**不变模式**\n\n<!-- more -->\n\n### 数据竞争\n数据竞争（**Data Race**）：多个线程**同时访问**同一数据，并且**至少有一个**线程会写这个数据\n\n#### add\n```java\nprivate static final int MAX_COUNT = 1_000_000;\nprivate long count = 0;\n\n// 非线程安全\npublic void add() {\n    int index = 0;\n    while (++index < MAX_COUNT) {\n        count += 1;\n    }\n}\n```\n\n#### add + synchronized\n```java\nprivate static final int MAX_COUNT = 1_000_000;\nprivate long count = 0;\n\npublic synchronized long getCount() {\n    return count;\n}\n\npublic synchronized void setCount(long count) {\n    this.count = count;\n}\n\n// 非线程安全\npublic void add() {\n    int index = 0;\n    while (++index < MAX_COUNT) {\n        setCount(getCount() + 1);\n    }\n}\n```\n1. 假设count=0，当两个线程同时执行getCount()，都会返回0\n2. 两个线程执行getCount()+1，结果都是1，最终写入内存是1，不符合预期，这种情况为**竟态条件**\n\n### 竟态条件\n1. 竟态条件（**Race Condition**）：程序的执行结果依赖于_**线程执行的顺序**_\n2. 在并发环境里，线程的执行顺序是不确定的\n    - 如果程序存在**竟态条件**问题，那么意味着程序的**执行结果是不确定**的\n\n#### 转账\n```java\npublic class Account {\n    private int balance;\n\n    // 非线程安全，存在竟态条件，可能会超额转出\n    public void transfer(Account target, int amt) {\n        if (balance > amt) {\n            balance -= amt;\n            target.balance += amt;\n        }\n    }\n}\n```\n\n### 解决方案\n面对**数据竞争**和**竟态条件**问题，可以通过**互斥**的方案来实现**线程安全**，互斥的方案可以统一归为_**锁**_\n\n## 活跃性问题\n活跃性问题：**某个操作无法执行下去**，包括三种情况：_**死锁**、**活锁**、**饥饿**_\n\n### 死锁\n1. 发生死锁后线程会**相互等待**，表现为线程_**永久阻塞**_\n2. 解决死锁问题的方法是**规避死锁**（破坏发生死锁的条件之一）\n    - **互斥**：不可破坏，锁定目的就是为了互斥\n    - **占有且等待**：一次性申请**所有**需要的资源\n    - **不可抢占**：当线程持有资源A，并尝试持有资源B时失败，线程**主动释放**资源A\n    - **循环等待**：将资源编号**排序**，线程申请资源时按**递增**（或递减）的顺序申请\n\n### 活锁\n1. 活锁：线程并没有发生阻塞，但由于**相互谦让**，而导致执行不下去\n2. 解决方案：在谦让时，尝试**等待一个随机时间**（分布式一致算法Raft也有采用）\n\n### 饥饿\n1. 饥饿：线程因**无法访问所需资源**而无法执行下去\n    - 线程的**优先级**是不相同的，在CPU繁忙的情况下，优先级低的线程得到执行的机会很少，可能发生线程饥饿\n    - 持有锁的线程，如果**执行的时间过长**（持有的资源不释放），也有可能导致饥饿问题\n2. 解决方案\n    - 保证资源充足\n    - 公平地分配资源（**公平锁**） -- 比较可行\n    - 避免持有锁的线程长时间执行\n\n## 性能问题\n1. 锁的**过度使用**可能会导致**串行化的范围过大**，这会影响多线程优势的发挥（并发程序的目的就是为了**提升性能**）\n2. **尽量减少串行**，假设**串行百分比**为5%，那么**多核多线程**相对于**单核单线程**的提升公式（Amdahl定律）\n    - $S = \\frac{1}{(1-p)+\\frac{p}{n}}$，n为CPU核数，p为并行百分比，(1-p)为串行百分比\n    - 假如p=95%，n无穷大，加速比S的极限为20，即无论采用什么技术，最高只能提高20倍的性能\n\n### 解决方案\n1. **无锁算法和数据结构**\n    - 线程本地存储（Thread Local Storage，TLS）\n    - 写入时复制（Copy-on-write）\n    - 乐观锁\n    - JUC中的原子类\n    - Disruptor（无锁的内存队列）\n2. **减少锁持有的时间**，互斥锁的本质是将并行的程序串行化，要增加并行度，一定要减少持有锁的时间\n    - 使用**细粒度锁**，例如JUC中的ConcurrentHashMap（分段锁）\n    - 使用**读写锁**，即读是无锁的，只有写才会互斥的\n\n### 性能指标\n1. **吞吐量**：在**单位时间**内能处理的请求数量，吞吐量越高，说明性能越好\n2. **延迟**：从发出请求到收到响应的时间，延迟越小，说明性能越好\n3. **并发量**：能**同时**处理的请求数量，一般来说随着并发量的增加，延迟也会增加，所以**延迟一般是基于并发量来说的**\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"架构 -- 汇编语言","url":"%2F2019%2F04%2F22%2Farchitecture-assembly-language%2F","content":"\n## 史前时代\n1. 在第一门面向程序员的编程语言出现前，只能通过理解**CPU指令的二进制表示**，将程序以**二进制数据的方式**刻录到存储上\n2. 这个时期，**编程的效率极其低下**，软件和硬件的边界还非常**模糊**，把程序刻录到存储上往往还涉及到硬件的**电气操作**\n\n<!-- more -->\n\n## 汇编语言\n1. 为了解决**编程效率**的问题，诞生了汇编语言（和解释它的编译器）\n2. 汇编语言的编译器将汇编语言写的程序编译成**CPU指令序列**，并将其保存到**外置存储**上\n3. 汇编语言**非常接近**计算机的CPU指令，一条汇编指令基本和一条CPU指令**一一对应**\n\n### 意义\n1. 汇编语言的出现，让编程成为了一个**纯软件**行为\n2. 程序员可以**反复修改**汇编程序，然后通过汇编编译器将其翻译成机器语言，并写入到外置存储中\n\n### 效率优化\n1. 用**文本符号**表达**机器指令**\n    - 例如add表示加法运算，而不用记忆对应的CPU指令的二进制表示\n2. 用**文本符号**表达要操作的**内存地址**，并支持**内存地址的自动分配**\n    - 例如使用了一段文本Hello，那么汇编编译器将为程序开辟一段**静态存储区**（数据段）来存放这段文本\n    - 并用一个文本符号（变量名）指向它，用**变量名**去表达一段内存数据\n    - 这样就**不用关注内存的物理地址**，而把精力放在程序的逻辑表达上\n3. 用**文本符号**表达要调用的**函数地址**\n    - 对**CPU指令**来说，_**函数只有地址没有名字**_\n    - 从**编程**的角度来说，_**函数是机器指令的扩展**_\n    - 和机器指令需要用文本符号助记一样，函数的名称也需要用文本符号来助记\n4. 用**文本符号**表达要**跳转的目标地址**\n    - 在高级语言里，流程控制的语法很多，例如goto/if/else/for/while/until等\n    - 在**汇编语言**里，只有两个基本的跳转指令：无条件跳转（**jmp**）和条件跳转（**je/jne**）\n    - 同样，跳转的目标地址用文本符号有助于程序逻辑的表达，而无需把精力放在具体的指令跳转地址上\n5. 小结\n    - 汇编从**指令能力**上来说，和**机器指令**是**一致**的\n    - 汇编把人们从**物理硬件地址**中解脱出来，_**专注于程序逻辑的表达**_\n\n## MVP\n1. 键盘和显示器的驱动程序\n2. 当时最主流的外置存储设备的驱动程序\n3. 汇编程序**编辑器**：可以从存储中读取汇编程序代码，修改并保存到存储中\n4. 汇编程序**编译器**：可以将汇编代码编译成机器代码，并保存在存储中\n5. 执行机器代码的程序：可以执行一段保存在外置存储设备中的机器代码\n\n## 汇编与操作系统\n1. 汇编程序的出现要**早于**操作系统\n2. 操作系统的**核心目标**是**软件治理**，只有在计算机需要管理很多任务时，才需要操作系统\n\n<!-- indicate-the-source -->\n","tags":["Architecture"],"categories":["Architecture"]},{"title":"Java并发 -- 等待-通知机制","url":"%2F2019%2F04%2F22%2Fjava-concurrent-wait-notify%2F","content":"\n## 循环等待\n1. 在《Java并发 -- 死锁》中，通过破坏**占用且等待**条件来规避死锁，核心代码如下\n    - `while (!allocator.apply(this, target)) {}`\n2. 如果apply()操作的时间非常短，并且并发不大，该方案还能应付\n3. 一旦apply()操作比较耗时，或者并发比较大，该方案就不适用了\n    - 因为这可能需要循环上万次才能获得锁，非常_**消耗CPU**_\n4. 最好的方案：_**等待-通知**_\n    - 当线程要求的条件不满足，则线程**阻塞**自己，进入**等待**状态\n    - 当线程要求的条件满足后，通知等待的线程，重新开始执行\n    - 线程阻塞能够避免因循环等待而消耗CPU的问题\n5. Java语言原生支持**等待-通知机制**\n    - 线程**首先获取互斥锁**，当线程要求的条件**不满足**时，**释放互斥锁**，进入等待状态\n    - 当要求的条件满足时，通知等待的线程，**重新获取互斥锁**\n\n<!-- more -->\n\n## 等待-通知机制\nJava语言原生支持的等待-通知机制：**`synchronized + wait + notify/notifyAll`**\n\n### wait\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-synchronized-wait.png\" width=800/>\n\n1. **每个互斥锁有两个独立的等待队列**，如上图所示，等待队列L和等待队列R\n1. 左边有一个**等待队列**（等待队列L），_**在同一时刻，只允许一个线程进入synchronized保护的临界区**_\n2. 当已经有一个线程进入synchronized保护的临界区后，其他线程就只能进入等待队列L进行等待\n3. 当一个线程**进入临界区后**，由于某些条件**不满足**，需要进入**等待**状态，可以调用wait()方法\n4. 当调用wait()方法后，当前线程就会被**阻塞**，并且进入到**右边的等待队列**（等待队列R）\n    - 线程在进入等待队列R的同时，会**释放持有的互斥锁**，其他线程就有机会获得锁，并进入临界区\n4. 关键点：_**sleep不会释放互斥锁**_\n\n### notify/notifyAll\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-synchronized-notify.png\" width=800/>\n\n1. 当线程要求的条件满足时，可以通过`notify/notifyAll`来通知等待的线程\n2. 当条件满足时调用notify()，会通知等待队列R（**将等待队列L中第1个节点移到等待队列R**）中的线程，告知它_**条件曾经满足**_\n    - _**notify()只能保证在通知的时间点，条件是满足的**_\n    - 而**被通知线程的执行时间点**与**通知时间点**基本上**不会重合**，当线程执行的时候，条件很可能已经不满足了\n3. 被通知的线程如果想要**重新执行**，仍然需要先获取到**互斥锁**\n    - 因为曾经获取到的锁在调用wait()时已经**释放**了\n4. 关键点：_**执行notify/notifyAll并不会释放互斥锁，在synchronized代码块结束后才真正的释放互斥锁**_\n\n#### 编码范式\n```java\nwhile (条件不满足) {\n    wait();\n}\n```\n1. 可以解决**条件曾经满足**的问题\n2. 当wait()返回时，条件有可能已经改变了，需要重新检验条件是否满足，如果不满足，继续wait()\n\n#### notifyAll\n1. _**尽量使用notifyAll()**_\n2. notify()：会**随机**地通知等待队列R中的**一个**线程\n    - 隐含动作：先将等待队列L的**第一个节点**移动到等待队列R\n3. notifyAll()：会通知等待队列R中的**所有**线程\n    - 隐含动作：先将等待队列L的**所有节点**移动到等待队列R（待确定是否正确）\n4. notify()的风险：_**可能导致某些线程永远不会被通知到**_\n    - 假设有资源A、B、C、D，线程1~4都对应**同一个**互斥锁L\n    - 线程1申请到了AB，线程2申请到了CD\n    - 此时线程3申请AB，会进入互斥锁L的等待队列L，线程4申请CD，也会进入互斥锁L的等待队列L\n    - 线程1归还AB，通过notify()来通知互斥锁L的等待队列R中的线程，假设为线程4（先被移动到等待队列R）\n    - 但线程4申请的是CD，不满足条件，执行wait()，而真正该被唤醒的线程3就再也没有机会被唤醒了\n\n### 等待队列\n1. wait/notify/notifyAll操作的等待队列都是_**互斥锁的等待队列**_\n2. 如果synchronized锁定的是this，那么对应的一定是this.wait()/this.notify()/this.notifyAll()\n3. 如果synchronized锁定的是target，那么对应的一定是target.wait()/target.notify()/target.notifyAll()\n4. 上面这3个方法能够被调用的前提是**已经获取了相应的互斥锁**，都必须在synchronized内部被调用\n5. 如果在synchronized外部调用，或者锁定的是this，而调用的是target.wait()，JVM会抛出IllegalMonitorStateException\n\n```java\npublic class IllegalMonitorStateExceptionTest {\n    private Object lockA = new Object();\n    private Object lockB = new Object();\n\n    @Test\n    public void test1() throws InterruptedException {\n        // java.lang.IllegalMonitorStateException\n        lockA.wait();\n    }\n\n    @Test\n    public void test2() throws InterruptedException {\n        synchronized (lockA) {\n            // java.lang.IllegalMonitorStateException\n            lockB.wait();\n        }\n    }\n}\n```\n\n## 转账实例\n\n### Allocator\n```java\npublic class Allocator {\n\n    private static class Holder {\n        private static Allocator allocator = new Allocator();\n    }\n\n    public static Allocator getInstance() {\n        return Holder.allocator;\n    }\n\n    private Allocator() {\n    }\n\n    private List<Object> als = new ArrayList<>();\n\n    // 一次性申请所有资源\n    public synchronized void apply(Object from, Object to) {\n        // 编程范式\n        while (als.contains(from) || als.contains(to)) {\n            try {\n                wait(); // this，单例\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        als.add(from);\n        als.add(to);\n    }\n\n    // 归还资源\n    public synchronized void free(Object from, Object to) {\n        als.remove(from);\n        als.remove(to);\n        notifyAll(); // this，单例\n    }\n}\n```\n\n### Account\n```java\npublic class Account {\n    // 必须是单例，因为要分配和释放资源\n    private Allocator allocator = Allocator.getInstance();\n    // 账户余额\n    private int balance;\n\n    // 转账\n    public void transfer(Account target, int amt) {\n        // 一次性申请转出账户和转入账户\n        allocator.apply(this, target);\n\n        try {\n            // 锁定转出账户\n            synchronized (this) {\n                // 锁定转入账户\n                synchronized (target) {\n                    if (balance > amt) {\n                        balance -= amt;\n                        target.balance += amt;\n                    }\n                }\n            }\n        } finally {\n            allocator.free(this, target);\n        }\n    }\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- 死锁","url":"%2F2019%2F04%2F21%2Fjava-concurrent-dead-lock%2F","content":"\n## Account.class\n1. 在《Java并发 -- 互斥锁》中，使用了Account.class作为**互斥锁**来解决银行业务的转账问题\n2. 虽然不存在并发问题，但所有账户的转账操作都是**串行**的，**性能太差**\n    - 例如账户A给账户B转账，账户C给账户D转账，在现实世界中是可以并行的，但该方案中只能串行\n\n<!-- more -->\n\n## 账户和账本\n1. 每个账户都对应一个**账本**，账本统一存放在**文件架**上\n2. 银行柜员进行转账操作时，需要到文件架上取出转出账本和转入账本，然后转账操作，会遇到三种情况\n    - 如果文件架上有转出账本和转入账本，都同时拿走\n    - 如果文件架上只有转出账本或只有转入账本，那需要等待那个缺失的账本\n    - 如果文件架上没有转出账本和转入账本，那需要等待两个账本\n\n## 两把锁\n```java\npublic class Account {\n    // 账户余额\n    private int balance;\n\n    // 转账\n    public void transfer(Account target, int amt) {\n        // 锁定转出账户\n        synchronized (this) { // 1\n            // 锁定转入账户\n            synchronized (target) { // 2\n                if (balance > amt) {\n                    balance -= amt;\n                    target.balance += amt;\n                }\n            }\n        }\n    }\n}\n```\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-deadlock-two-lock.png\" width=1000/>\n\n\n### 死锁\n1. 两把锁是**细粒度锁**的方案，使用细粒度锁可以**提高并发度**，是**性能优化**的一个重要手段，但可能会导致**死锁**\n2. 死锁：_**一组相互竞争资源的线程因互相等待，导致永久阻塞的现象**_\n3. 场景\n    - 假设线程T1执行账户A给账户B转账的操作，同时线程T2执行账户B给账户A转账的操作\n        - 即A.transfer(B)，B.transfer(A)\n    - 当T1和T2同时执行完1处的代码，此时，T1获得了账户A的锁，T2获得了账户B的锁\n    - 之后T1和T2在执行2处的代码时\n        - T1试图获取账户B的锁，发现账户B已经被锁定，T1等待\n        - T2试图获取账户A的锁，发现账户A已经被锁定，T2等待\n        - T1和T2会无限期地等待，形成死锁\n\n### 规避死锁\n1. 并发程序一旦死锁，一般只能**重启应用**，解决死锁问题最好的办法是_**规避死锁**_\n2. 死锁发生的条件\n    - **互斥**：共享资源X和共享资源Y只能被一个线程占用\n    - **占有且等待**：线程T1占有共享资源X，在等待共享资源Y的时候，不会释放共享资源X\n    - **不可抢占**：其他线程不能强行抢占线程已经占有的共享资源\n    - **循环等待**：线程T1等待线程T2占有的资源，线程T2等待线程T1占有的资源\n3. 规避死锁的思路：破坏死锁发生的条件\n    - **互斥**：无法破坏，因为用锁的目的就是为了互斥\n    - **占有且等待**：一次性申请**所有**的共享资源，不存在等待\n    - **不可抢占**：占有部分共享资源的线程进一步申请其他共享资源时，如果申请不到，可以**主动释放**它所占用的共享资源\n    - **循环等待**：按序申请共享资源（共享资源是有**线性顺序**的）\n\n#### 破坏 -- 占有且等待\n\n##### Allocator\n```java\npublic class Allocator {\n\n    private static class Holder {\n        private static Allocator allocator = new Allocator();\n    }\n\n    public static Allocator getInstance() {\n        return Holder.allocator;\n    }\n\n    private Allocator() {\n    }\n\n    private List<Object> als = new ArrayList<>();\n\n    // 一次性申请所有资源\n    public synchronized boolean apply(Object from, Object to) {\n        if (als.contains(from) || als.contains(to)) {\n            return false;\n        } else {\n            als.add(from);\n            als.add(to);\n            return true;\n        }\n    }\n\n    // 归还资源\n    public synchronized void free(Object from, Object to) {\n        als.remove(from);\n        als.remove(to);\n    }\n}\n```\n\n##### Account\n```java\npublic class Account {\n    // 必须是单例，因为要分配和释放资源\n    private Allocator allocator = Allocator.getInstance();\n    // 账户余额\n    private int balance;\n\n    // 转账\n    public void transfer(Account target, int amt) {\n        // 一次性申请转出账户和转入账户，直至成功\n        while (!allocator.apply(this, target)) {\n        }\n\n        try {\n            // 锁定转出账户\n            synchronized (this) {\n                // 锁定转入账户\n                synchronized (target) {\n                    if (balance > amt) {\n                        balance -= amt;\n                        target.balance += amt;\n                    }\n                }\n            }\n        } finally {\n            allocator.free(this, target);\n        }\n    }\n}\n```\n\n#### 破坏 -- 不可抢占\n1. 破坏不可抢占条件的核心是**主动释放**它所占有的共享资源，这一点synchronized是做不到的\n2. synchronized在申请资源的时候，如果申请不到，线程直接进入**阻塞**状态，并不会释放已占有的共享资源\n3. Java在语言层次并没有解决该问题，但在**SDK层面**解决了（JUC提供的LOCK）\n\n#### 破坏 -- 循环等待\n比破坏占有且等待条件的成本低\n```java\npublic class Account {\n    // 资源有线性顺序\n    private int id;\n    // 账户余额\n    private int balance;\n\n    // 转账\n    public void transfer(Account target, int amt) {\n        Account left = this;\n        Account right = target;\n        if (this.id > target.id) {\n            left = target;\n            right = this;\n        }\n\n        // 锁定序号小的账号\n        synchronized (left) {\n            // 锁定序号大的账号\n            synchronized (right) {\n                if (balance > amt) {\n                    balance -= amt;\n                    target.balance += amt;\n                }\n            }\n        }\n    }\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Linux -- 系统调用过程","url":"%2F2019%2F04%2F20%2Flinux-system-call-process%2F","content":"\n## glibc\n1. glibc更熟悉系统调用的细节，封装成更加友好的接口，可以直接调用\n2. 在**用户态**进程调用glibc的open函数（函数定义如下）\n\n```cpp\nint open(const char *pathname, int flags, mode_t mode)\n```\n\n<!-- more -->\n\n### syscalls.list\nsyscalls.list记录了所有glibc函数所对应的系统调用\n```\n# File name\tCaller\tSyscall name\tArgs\tStrong name\tWeak names\nopen\t\t-\topen\t\tCi:siv\t__libc_open __open open\n```\n\n### make-syscalls.sh\n1. make-syscalls.sh会根据上面的配置文件，对于每个封装好的系统调用，生成一个文件F\n2. 文件F里面会定义一些宏，例如`#define SYSCALL_NAME open`\n    - make-syscalls.sh中对应的代码为`echo '#define SYSCALL_NAME $syscall'`\n\n### syscall-template.S\nsyscall-template.S会使用文件F里面的宏，定义这个系统调用的**调用方式**\n```c\n// PSEUDO是伪代码的意思\nT_PSEUDO (SYSCALL_SYMBOL, SYSCALL_NAME, SYSCALL_NARGS)\n\tret\nT_PSEUDO_END (SYSCALL_SYMBOL)\n\n#define T_PSEUDO(SYMBOL, NAME, N)\t\tPSEUDO (SYMBOL, NAME, N)\n```\n\n### sysdep.h\nPSEUDO也是一个宏，定义如下（sysdeps/unix/sysv/linux/i386/sysdep.h）\n```c\n#define\tPSEUDO(name, syscall_name, args)\t\t\t\t      \\\n  .text;\t\t\t\t\t\t\t\t      \\\n  ENTRY (name)\t\t\t\t\t\t\t\t      \\\n    DO_CALL (syscall_name, args);\t\t\t\t\t      \\\n    cmpl $-4095, %eax;\t\t\t\t\t\t\t      \\\n    jae SYSCALL_ERROR_LABEL\n```\n里面对于任何一个系统调用，都会调用**DO_CALL**，DO_CALL也是一个宏（32位和64位的定义是不一样的）\n\n## 32位系统调用\n\n### sysdep.h\nsysdeps/unix/sysv/linux/i386/sysdep.h\n```c\n// glibc源码\n/* Linux takes system call arguments in registers:\n\tsyscall number %eax\t     call-clobbered\n\targ 1          %ebx\t     call-saved\n\targ 2          %ecx\t     call-clobbered\n\targ 3          %edx\t     call-clobbered\n\targ 4          %esi\t     call-saved\n\targ 5          %edi\t     call-saved\n\targ 6          %ebp\t     call-saved\n*/\n\n#define DO_CALL(syscall_name, args)\t\t\t      \t\t      \\\n    PUSHARGS_##args\t\t\t\t\t\t\t      \\\n    DOARGS_##args\t\t\t\t\t\t\t      \\\n    movl $SYS_ify (syscall_name), %eax;\t\t\t\t\t      \\\n    ENTER_KERNEL\t\t\t\t\t\t\t      \\\n    POPARGS_##args\n```\n1. 将请求参数放在**寄存器**里面（PUSHARGS）\n2. 根据**系统调用的名称**，得到**系统调用号**（SYS_ify (syscall_name)），_**放在寄存器`%eax`里面**_\n3. 然后执行`ENTER_KERNEL`\n\n### ENTER_KERNEL\n```c\n// glibc源码\n# define ENTER_KERNEL int $0x80\n```\n1. int是**interrupt**的意思，`int $0x80`就是触发一个**软中断**，通过它可以陷入（trap）内核\n2. 在内核启动过程中，有一个`trap_init()`函数，其中有代码`SYSG(IA32_SYSCALL_VECTOR,\tentry_INT80_32)`\n    - 这是一个软中断的陷入门，当接收到一个系统调用时，`entry_INT80_32`就会被调用\n\n### entry_INT80_32\n```c\n// Linux源码\nENTRY(entry_INT80_32)\n\tASM_CLAC\n\tpushl\t%eax\t\t\t/* pt_regs->orig_ax */\n\tSAVE_ALL pt_regs_ax=$-ENOSYS switch_stacks=1\t/* save rest */\n\tmovl\t%esp, %eax\n\tcall\tdo_int80_syscall_32\n.Lsyscall_32_done:\n...\n.Lirq_return:\n\tINTERRUPT_RETURN\n...\nENDPROC(entry_INT80_32)\n\n/* Handles int $0x80 */\n__visible void do_int80_syscall_32(struct pt_regs *regs)\n{\n\tdo_syscall_32_irqs_on(regs);\n}\n```\n在进入内核之前，通过push和SAVE_ALL将当前**用户态的寄存器**，保存在**pt_regs**结构里面，然后调用do_int80_syscall_32\n\n### do_syscall_32_irqs_on\n```c\n// Linux源码\nstatic __always_inline void do_syscall_32_irqs_on(struct pt_regs *regs)\n{\n\tstruct thread_info *ti = current_thread_info();\n\tunsigned int nr = (unsigned int)regs->orig_ax;\n    ...\n\tif (likely(nr < IA32_NR_syscalls)) {\n\t\tregs->ax = ia32_sys_call_table[nr](\n\t\t\t(unsigned int)regs->bx, (unsigned int)regs->cx,\n\t\t\t(unsigned int)regs->dx, (unsigned int)regs->si,\n\t\t\t(unsigned int)regs->di, (unsigned int)regs->bp);\n\t}\n\tsyscall_return_slowpath(regs);\n}\n\n#define ia32_sys_call_table sys_call_table\n```\n1. 将**系统调用号**从寄存器`%eax`中取出，然后根据系统调用号，在**系统调用表**中找到相应的函数进行调用\n2. 将寄存器中保存的参数取出来，作为函数参数\n3. 根据宏定义，`#define ia32_sys_call_table sys_call_table`，系统调用就放在这个表里面\n\n### INTERRUPT_RETURN\n```c\n// Linux源码\n#define INTERRUPT_RETURN\t\tiret\n```\niret指令将原来**用户态**保存的现场恢复回来，包括代码段、指令指针寄存器等，此时用户态进程**恢复执行**\n\n### 小结\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-system-call-32.jpg\" width=800/>\n\n\n## 64位系统调用\n\n### sysdep.h\nsysdeps/unix/sysv/linux/x86_64/sysdep.h\n```c\n// glibc源码\n/* The Linux/x86-64 kernel expects the system call parameters in\n   registers according to the following table:\n\n    syscall number\trax\n    arg 1\t\trdi\n    arg 2\t\trsi\n    arg 3\t\trdx\n    arg 4\t\tr10\n    arg 5\t\tr8\n    arg 6\t\tr9\n*/\n\n#define DO_CALL(syscall_name, args)\t\t\t\t\t      \\\n  lea SYS_ify (syscall_name), %rax;\t\t\t\t\t      \\\n  syscall\n```\n1. 与32位的系统调用类似，首先将**系统调用名称**转换为**系统调用号**，_**放在寄存器`%rax`**_\n2. 在这里是**进行真正调用**，而不是采用**中断**模式，改用`syscall`指令（传递参数的寄存器也改变了）\n\n### syscall\n1. syscall指令使用了一种特殊的寄存器，称为**特殊模块寄存器**（Model Specific Registers，**MSR**）\n2. MSR是CPU为了完成某些**特殊控制功能**为目的的寄存器，例如_**系统调用**_\n3. 在Linux系统初始化时，trap_init除了初始化上面的**中断模式**外，还会调用cpu_init()，而cpu_init()会调用**syscall_init()**\n\n### syscall_init()\n```c\n// Linux源码\nvoid syscall_init(void)\n{\n\twrmsrl(MSR_LSTAR, (unsigned long)entry_SYSCALL_64);\n}\n```\n1. rdmsr和wrmsr是用来读写特殊模块寄存器的，MSR_LSTAR就是一个特殊模块寄存器\n2. 当syscall指令调用的时候，会从MSR_LSTAR寄存器里取出函数地址来调用，即调用entry_SYSCALL_64\n\n### entry_SYSCALL_64\narch/x86/entry/entry_64.S\n```c\n// Linux源码\nENTRY(entry_SYSCALL_64)\n    /* Construct struct pt_regs on stack */\n    pushq\t$__USER_DS\t\t\t\t/* pt_regs->ss */\n    pushq\tPER_CPU_VAR(cpu_tss_rw + TSS_sp2)\t/* pt_regs->sp */\n    pushq\t%r11\t\t\t\t\t/* pt_regs->flags */\n    pushq\t$__USER_CS\t\t\t\t/* pt_regs->cs */\n    pushq\t%rcx\t\t\t\t\t/* pt_regs->ip */\nGLOBAL(entry_SYSCALL_64_after_hwframe)\n    pushq\t%rax\t\t\t\t\t/* pt_regs->orig_ax */\n    PUSH_AND_CLEAR_REGS rax=$-ENOSYS\n    TRACE_IRQS_OFF\n\t/* IRQs are off. */\n\tmovq\t%rax, %rdi\n\tmovq\t%rsp, %rsi\n\tcall\tdo_syscall_64\t\t/* returns with IRQs disabled */\n...\n    cmpq\t%rcx, %r11\t/* SYSRET requires RCX == RIP */\n    jne\tswapgs_restore_regs_and_return_to_usermode\n...\nsyscall_return_via_sysret:\n    ...\n    USERGS_SYSRET64\nEND(entry_SYSCALL_64)\n```\n首先保存很多寄存器到**pt_regs**结构里面，例如用户态的代码段、数据段、保存参数的寄存器，然后调用do_syscall_64\n\n### do_syscall_64\n```c\n// Linux源码\n__visible void do_syscall_64(unsigned long nr, struct pt_regs *regs)\n{\n\tstruct thread_info *ti;\n    ...\n\tti = current_thread_info();\n\tif (READ_ONCE(ti->flags) & _TIF_WORK_SYSCALL_ENTRY)\n\t\tnr = syscall_trace_enter(regs);\n    ...\n\tnr &= __SYSCALL_MASK;\n\tif (likely(nr < NR_syscalls)) {\n\t\tnr = array_index_nospec(nr, NR_syscalls);\n\t\tregs->ax = sys_call_table[nr](regs);\n\t}\n\n\tsyscall_return_slowpath(regs);\n}\n```\n1. 从寄存器`%rax`里面取出**系统调用号**，然后根据系统调用号，在**系统调用表**sys_call_table中找到相应的函数进行调用\n2. 并将寄存器中保存的参数取出来，作为函数参数\n\n### USERGS_SYSRET64\n```c\n// Linux源码\n#define USERGS_SYSRET64\t\t\t\t\\\n\tswapgs;\t\t\t\t\t\\\n\tsysretq;\n```\n返回用户态的指令变成了sysretq\n\n### 小结\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-system-call-64-perfect.jpg\" width=800/>\n\n\n## 系统调用表\n\n### 32位 VS 64位\n```\n// Linux源码 -- arch/x86/entry/syscalls/syscall_32.tbl\n5\ti386\topen\t\t\tsys_open\t\t\t__ia32_compat_sys_open\n\n// Linux源码 -- arch/x86/entry/syscalls/syscall_64.tbl\n2\tcommon\topen\t\t\t__x64_sys_open\n```\n1. 第1列的数字是**系统调用号**，32位和64位的系统调用号是不一样的\n2. 第3列是**系统调用名称**\n3. 第4列是系统调用在_**内核中的实现函数**_\n\n### 实现函数\n\n#### 声明\n系统调用在内核中的实现函数需要有一个**声明**，该声明一般在`include/linux/syscalls.h`文件中\n```java\n// Linux源码\nasmlinkage long sys_open(const char __user *filename, int flags, umode_t mode);\n```\n\n#### 实现\n系统调用的真正实现，一般在.c文件中，sys_open的实现在`fs/open.c`里面，但里面只有SYSCALL_DEFINE3\n```java\n// Linux源码\nSYSCALL_DEFINE3(open, const char __user *, filename, int, flags, umode_t, mode)\n{\n\tif (force_o_largefile())\n\t\tflags |= O_LARGEFILE;\n\n\treturn do_sys_open(AT_FDCWD, filename, flags, mode);\n}\n```\n\n#### 宏展开\nSYSCALL_DEFINE3是一个宏，**系统调用最多6个参数**，根据参数的数量选择宏，具体的宏定义如下\n```c\n// Linux源码\n#define SYSCALL_DEFINE1(name, ...) SYSCALL_DEFINEx(1, _##name, __VA_ARGS__)\n#define SYSCALL_DEFINE2(name, ...) SYSCALL_DEFINEx(2, _##name, __VA_ARGS__)\n#define SYSCALL_DEFINE3(name, ...) SYSCALL_DEFINEx(3, _##name, __VA_ARGS__)\n#define SYSCALL_DEFINE4(name, ...) SYSCALL_DEFINEx(4, _##name, __VA_ARGS__)\n#define SYSCALL_DEFINE5(name, ...) SYSCALL_DEFINEx(5, _##name, __VA_ARGS__)\n#define SYSCALL_DEFINE6(name, ...) SYSCALL_DEFINEx(6, _##name, __VA_ARGS__)\n\n#define __PROTECT(...) asmlinkage_protect(__VA_ARGS__)\n\n#define SYSCALL_DEFINEx(x, sname, ...)\t\t\t\t\\\n\tSYSCALL_METADATA(sname, x, __VA_ARGS__)\t\t\t\\\n\t__SYSCALL_DEFINEx(x, sname, __VA_ARGS__)\n\n    #define __SYSCALL_DEFINEx(x, name, ...)\t\t\t\t\t\\\n    \t__diag_push();\t\t\t\t\t\t\t\\\n    \t__diag_ignore(GCC, 8, \"-Wattribute-alias\",\t\t\t\\\n    \t\t      \"Type aliasing is used to sanitize syscall arguments\");\\\n    \tasmlinkage long sys##name(__MAP(x,__SC_DECL,__VA_ARGS__))\t\\\n    \t\t__attribute__((alias(__stringify(__se_sys##name))));\t\\\n    \tALLOW_ERROR_INJECTION(sys##name, ERRNO);\t\t\t\\\n    \tstatic inline long __do_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__));\\\n    \tasmlinkage long __se_sys##name(__MAP(x,__SC_LONG,__VA_ARGS__));\t\\\n    \tasmlinkage long __se_sys##name(__MAP(x,__SC_LONG,__VA_ARGS__))\t\\\n    \t{\t\t\t\t\t\t\t\t\\\n    \t\tlong ret = __do_sys##name(__MAP(x,__SC_CAST,__VA_ARGS__));\\\n    \t\t__MAP(x,__SC_TEST,__VA_ARGS__);\t\t\t\t\\\n    \t\t__PROTECT(x, ret,__MAP(x,__SC_ARGS,__VA_ARGS__));\t\\\n    \t\treturn ret;\t\t\t\t\t\t\\\n    \t}\t\t\t\t\t\t\t\t\\\n    \t__diag_pop();\t\t\t\t\t\t\t\\\n    \tstatic inline long __do_sys##name(__MAP(x,__SC_DECL,__VA_ARGS__))\n```\n宏展开后，实现如下，与声明的是一致的\n```java\n// Linux源码\nasmlinkage long sys_open(const char __user * filename, int flags, int mode)\n{\n    long ret;\n\n    if (force_o_largefile())\n        flags |= O_LARGEFILE;\n\n    ret = do_sys_open(AT_FDCWD, filename, flags, mode);\n    asmlinkage_protect(3, ret, filename, flags, mode);\n    return ret;\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["Linux"],"categories":["Linux"]},{"title":"架构 -- 冯·诺伊曼体系结构","url":"%2F2019%2F04%2F19%2Farchitecture-von%2F","content":"\n## 目标与组件\n1. 目标：_**解决一切可以用计算解决的问题**_\n2. 组件：**中央处理器**、**存储**、**输入输出设备**\n\n<!-- more -->\n\n## 组件\n\n### 存储\n1. 存储负责存放计算涉及的相关数据，作为计算的输入参数和输出结果\n2. 从**中央处理器**的角度，存储可以分为两类\n    - 一类是**内置存储**，通过**常规的处理器指令**可以**直接**访问，例如寄存器、内存和主板上的ROM\n    - 一类是**外置存储**，中央处理器本身并不能直接读写其中的数据\n3. 冯·诺伊曼体系结构中涉及的存储指的是_**内置存储**_\n\n### 输入输出设备\n1. 输入输出设备是计算机**开放性**的体现，大大地**拓展**了计算机的能力\n2. 每个设备通过一个**端口**与中央处理器连接，通过这个端口，中央处理器可以和设备进行_**数据交换**_\n3. 数据交换涉及的**数据格式**由**设备定义**，中央处理器并不能理解，但这不影响设备的接入\n4. 设备数据交换的发起方（**设备使用方**）通常**理解并可以解释**所接收的数据含义\n    - 设备厂商或操作系统厂商通常会提供设备相关的**驱动程序**，把**设备数据交换的细节**隐藏起来\n    - 设备的使用方只需要调用相关的**接口函数**就可以操作设备\n\n### 中央处理器\n1. 中央处理器负责程序（指令序列）的执行，指令序列存放在存储\n2. 计算机加电启动后，中央处理器会从一个**固定的存储地址**开始执行\n3. 中央处理器支持的指令分类：**计算类**、**IO类**、**指令跳转类**\n\n## 实现目标\n1. 目标：解决一切可以用计算解决的问题\n2. 需求的变化点：要解决的问题是五花八门的，需要以一种**稳定且可扩展的架构**来支持这种变化\n3. 需求的稳定点：电脑的核心能力是固定的，即_**计算**_\n\n### 实现计算\n1. 电脑的核心能力是**计算**\n2. 计算：_对一个数据（输入）进行变换，变为另一个数据（输出）_，对应数学中的函数：`y=F(x)`\n    - x和y都是数据，可能是一个简单的数值，也可能是文本、图片和视频等\n    - 无论逻辑含义为何，物理上都可以用一段**连续的字节**来表达\n    - x和y物理上存放在**存储**上\n\n#### 具体计算的表达\n1. 逻辑上来看，无论多么复杂的自定义函数，都是**内置函数、循环和条件分支、子函数**的**组合**定义\n2. 对于任意的具体计算来说，都可以用**一组指令序列**来表达，并且以指令序列的形式存放在**存储**里面\n    - 因此，存储不仅存放计算所要操作的数据，也存放\"计算\"本身\n    - 只是存储里面存放的计算只是数据，需要中央处理器**理解并执行**这些数据背后的计算行为，才能变成真正意义的计算\n\n#### CPU + 存储\n中央处理器+存储，就能够支持**任意复杂**的计算了\n<img src=\"https://architecture-1253868755.cos.ap-guangzhou.myqcloud.com/architecture-von-cpu-storage.png\" width=600/>\n\n\n### 实现IO\n<img src=\"https://architecture-1253868755.cos.ap-guangzhou.myqcloud.com/architecture-von-cpu-storage-io.png\" width=600/>\n\n1. 交互，抽象来看就是输入输出，对电脑来说，输入输出可能是千变外化的\n2. 除了纯正的**计算能力**之外，中央处理器还需要具备**IO能力**\n3. 此时，电脑可以看成：**中央处理器 + 存储 + 一系列的输入输出设备**\n\n#### 解决的根本问题\n1. 输入输出设备从根本上解决的是电脑_**无限扩展的能力**_\n2. 输入输出设备和电脑是**完全异构**的，输入输出设备对电脑来说只是实现了某项能力的_**黑盒子**_\n3. 可以只是一个原始的数字化元器件，也可以是另一台冯.诺依曼架构的电脑，还可以是完全**异构**的电脑（GPU电脑）\n\n## 小结\n1. 架构的第一步是**需求分析**，关键是要抓住需求的**稳定点**和**变化点**\n    - 需求的**稳定点**，往往是系统的_**核心价值点**_\n    - 需求的**变化点**，往往需要去做相应的_**开放性设计**_\n2. 对于电脑而言\n    - 需求的稳定点：计算能力（中央处理器的指令集，可以单独演进）\n    - 需求的变化点：具体计算的多样性（存储中的指令序列），交互的多样性（外部设备与中央处理器的数据交换协议）\n\n<!-- indicate-the-source -->\n","tags":["Architecture"],"categories":["Architecture"]},{"title":"Java并发 -- 互斥锁","url":"%2F2019%2F04%2F17%2Fjava-concurrent-mutex-lock%2F","content":"\n## 解决什么问题\n互斥锁解决了并发程序中的**原子性**问题\n\n<!-- more -->\n\n## 禁止CPU中断\n1. 原子性：一个或多个操作在CPU执行的过程中**不被中断**的特性\n2. 原子性问题点源头是**线程切换**，而操作系统依赖**CPU中断**来实现线程切换的\n3. 单核时代，禁止CPU中断就能禁止线程切换\n    - **同一时刻，只有一个线程执行**，禁止CPU中断，意味着操作系统不会重新调度线程，也就禁止了线程切换\n    - 获得CPU使用权的线程可以**不间断**地执行\n4. 多核时代\n    - 同一时刻，有可能有两个线程同时在执行，一个线程执行在CPU1上，一个线程执行在CPU2上\n    - 此时禁止CPU中断，只能保证CPU上的线程不间断执行，**但并不能保证同一时刻只有一个线程执行**\n5. _**互斥：同一时刻只有一个线程执行**_\n    - 如果能保证对**共享变量**的修改是**互斥**的，无论是单核CPU还是多核CPU，都能保证原子性\n\n## 简易锁模型\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-atomic-simple-lock-model.png\" width=1000/>\n\n1. 临界区：一段需要**互斥**执行的代码\n2. 线程在进入临界区之前，首先尝试加锁lock()\n    - 如果成功，则进入临界区，此时该线程只有锁\n    - 如果不成功就等待，直到持有锁的线程解锁\n3. 持有锁的线程执行完临界区的代码后，执行解锁unlock()\n\n## 锁和资源\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-atomic-improved-lock-model.png\" width=1000/>\n\n\n## synchronized\n```java\npublic class X {\n    // 修饰非静态方法\n    synchronized void foo() {\n        // 临界区\n    }\n\n    // 修饰静态方法\n    synchronized static void bar() {\n        // 临界区\n    }\n\n    // 修饰代码块\n    Object obj = new Object();\n\n    void baz() {\n        synchronized (obj) {\n            // 临界区\n        }\n    }\n}\n```\n1. 锁是一种通用的技术方案，Java语言提供的锁实现：`synchronized`\n2. Java编译器会在synchronized修饰的方法或代码块前后自动加上lock()和unlock()\n    - lock()和unlock()一定是成对出现的\n3. 当synchronized修饰**静态方法**时，锁定的是_**当前类的Class对象**_\n4. 当synchronized修饰**实例方法**时，锁定的是_**当前实例对象this**_\n\n## count += 1\n```java\npublic class SafeCalc {\n    private long value = 0L;\n\n    public long get() {\n        return value;\n    }\n\n    public synchronized void addOne() {\n        value += 1;\n    }\n}\n```\n1. 原子性\n    - synchronized修饰的临界区是**互斥**的\n    - 因此无论是单核CPU还是多核CPU，只有一个线程能够执行addOne，能保证原子性\n2. 可见性\n    - 管程中锁的规则：对一个锁的**解锁**Happens-Before于后续对这个锁的**加锁**\n    - 结合Happens-Before的**传递性**原则，易得下面的结论\n    - _前一线程在临界区修改的共享变量（该操作在解锁之前），对后续进入临界区（该操作在加锁之后）的线程是**可见**的_\n    - 因此，多个线程同时执行addOne，可以**保证可见性**，即假如有N个线程并发调用addOne，最终结果一定是N\n3. get\n    - 执行addOne方法后，value的值对get方法的可见性是**无法保证**的\n    - 解决方案：get方法也用synchronized修饰\n\n### 锁模型\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-atomic-improved-lock-model-count.png\" width=1000/>\n\n1. get()和addOne()都需要访问资源value，而资源value是用this这把锁来保护的\n2. 线程要进入临界区get()和addOne()，必须先获得this这把锁，因此get()和addOne()也是**互斥**的\n\n## 锁与受保护资源\n受保护资源和锁之间**合理**的关联关系应该是`N:1`的关系\n\n### 不同的锁\n```java\npublic class SafeCalc {\n    private static long value = 0L;\n\n    public long get() {\n        return value;\n    }\n\n    public synchronized static void addOne() {\n        value += 1;\n    }\n}\n```\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-atomic-count-two-lock.png\" width=1000/>\n\n1. 用两个锁（this和SafeCalc.class）保护同一个资源value（静态变量）\n2. 临界区get()和addOne()是用两个锁来保护的，因此两个临界区没有**互斥**关系\n3. 临界区addOne()对value的修改对临界区get()也没有**可见性**保证，因此会导致并发问题\n\n### 多个资源\n_**可以用同一把锁保护多个资源，但不能用多把锁保护一个资源**_\n\n#### 无关联资源\n1. 无关联资源\n    - 针对账户**余额**（余额是一种资源）的取款操作\n    - 针对账户**密码**（密码是一种资源）的更改操作\n2. 可以为账户余额和账户密码分配**不同的锁**来解决并发问题，不同的资源用不同的锁来保护\n    - 也可以用**同一把锁**保护多个资源，例如可以用this这把锁保护账户余额和账户密码，但这样**性能太差**\n3. 用不同的锁对受保护资源进行**精细化管理**，能够**提升性能**，这种锁称为**细粒度锁**\n\n```java\npublic class Account {\n    // 锁：保护账户余额\n    private final Object balLock = new Object();\n    // 锁：保护账户密码\n    private final Object pwLock = new Object();\n    // 账户余额\n    private Integer balance;\n    // 账户密码\n    private String password;\n\n    // 取款\n    public void withdraw(Integer amt) {\n        synchronized (balLock) {\n            if (balance > amt) {\n                balance -= amt;\n            }\n        }\n    }\n\n    // 查看余额\n    public Integer getBalance() {\n        synchronized (balLock) {\n            return balance;\n        }\n    }\n\n    // 更改密码\n    public void updatePassword(String pw) {\n        synchronized (pwLock) {\n            password = pw;\n        }\n    }\n\n    // 查看密码\n    public String getPassword() {\n        synchronized (pwLock) {\n            return password;\n        }\n    }\n}\n```\n\n#### 有关联资源\n账户A的余额和账户B的余额是有**关联关系**的，需要保证转账操作没有并发问题\n```java\npublic class Account {\n    // 账户余额\n    private int balance;\n\n    // 转账\n    public void transfer(Account target, int amt) {\n        if (balance > amt) {\n            balance -= amt;\n            target.balance += amt;\n        }\n    }\n}\n```\n\n##### synchronized this\n```java\npublic class Account {\n    // 账户余额\n    private int balance;\n\n    // 转账\n    public synchronized void transfer(Account target, int amt) {\n        if (balance > amt) {\n            balance -= amt;\n            target.balance += amt;\n        }\n    }\n}\n```\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-atomic-account-error-synchronized.png\" width=1000/>\n\n1. 上述代码中，临界区内有**两个资源**，分别是`this.balance`和`target.balance`\n2. this这把锁可以保护自己的余额`this.balance`，但无法保护他人的余额`target.balance`\n3. 场景\n    - 假设有A、B、C三个账户，余额都是200\n    - 用两个线程分别执行两个转账操作：线程1执行账户A给账户B转账100，线程2执行账户B给账户C转账100\n    - 预期结果：账户A余额为100，账户B余额为200，账户C余额为300\n4. 假设线程1和线程2分别在**两颗CPU上同时执行**，实际上两个线程**并不互斥**\n    - 线程1锁定的是账户A的实例A.this，线程2锁定的是账户B的实例B.this，因此，两个线程可以**同时进入临界区**transfer\n    - 线程1和线程2刚开始执行时都有可能读到账户B的余额是200，导致账户B最终的余额是300或100，**但绝不会是200**\n        - 300：线程2写B.balance -> 线程1写B.balance\n        - 100：线程1写B.balance -> 线程2写B.balance\n\n##### 同一把锁\n1. 条件：_**锁能覆盖所有受保护的资源（粒度更大）**_\n2. 方案1：让所有对象都**持有一个唯一性的对象**，该对象在**创建**Account时传入\n    - 很难保证传入共享的lock，_**缺乏实践的可行性**_\n3. 方案2：Class对象作为共享的锁\n    - Account.class是所有Account实例共享的，并且Class对象时JVM在加载类时创建的，能保证**唯一性**，代码也更简单\n\n```java\n// 方案1\npublic class Account {\n    private Object lock;\n    private int balance;\n\n    // 默认构造函数为private\n    private Account() {\n    }\n\n    // 传入相同lock，所有Account实例共享\n    public Account(Object lock) {\n        this.lock = lock;\n    }\n\n    // 转账\n    public void transfer(Account target, int amt) {\n        synchronized (lock) {\n            if (balance > amt) {\n                balance -= amt;\n                target.balance += amt;\n            }\n        }\n    }\n}\n\n// 方案2\npublic class Account {\n    private int balance;\n\n    // 转账\n    public void transfer(Account target, int amt) {\n        synchronized (Account.class) {\n            if (balance > amt) {\n                balance -= amt;\n                target.balance += amt;\n            }\n        }\n    }\n}\n```\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-atomic-solution-class.png\" width=1000/>\n\n\n\n## 原子性的本质\n1. 原子性的**外在表现**：**不可分割**\n2. 原子性的**本质**：_**多个资源之间有一致性的要求，操作的中间状态对外不可见**_\n    - 中间状态：例如在32位机器上写long型变量，转账操作（账户A减少100，但账户B还未增加100）\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- Java内存模型","url":"%2F2019%2F04%2F15%2Fjava-concurrent-memory-model%2F","content":"\n\n## 解决什么问题\nJava内存模型解决了并发程序中的**可见性问题**和**有序性问题**\n\n## Java内存模型\n\n### 按需禁用\n1. _CPU缓存会导致可见性问题，编译优化会导致有序性问题_\n2. 解决可见性和有序性**最直接**的办法：_**禁用CPU缓存和编译优化**_\n    - 问题虽然解决了，但程序性能会大大下降\n3. 合理的方案：_**按需禁用CPU缓存和编译优化**_\n    - 为了解决可见性和有序性的问题，只需要给程序员**提供按需禁用CPU缓存和编译优化的方案**即可\n\n<!-- more -->\n\n### 程序员视角\n1. Java内存模型规范了_**JVM如何提供按需禁用CPU缓存和编译优化的方法**_\n2. 具体方法包括：`volatile`、`synchronized`和`final`关键字，以及六个`Happens-Before`规则\n\n### volatile\n1. volatile关键字不是Java语言的特产，在\u0010古老的C语言也有，最原始的意义就是_**禁用CPU缓存**_\n2. `volatile int x = 0`：告诉编译器，对这个变量的读写，不能使用CPU缓存，**必须从内存中读取或者写入**\n\n#### Java代码\n```java\npublic class VolatileExample {\n    private int x = 0;\n    private volatile boolean v = false;\n\n    // 线程A\n    public void writer() {\n        x = 42;\n        v = true;\n    }\n\n    // 线程B\n    public void reader() {\n        if (v) {\n            // 这里 x 会是多少呢？\n        }\n    }\n}\n```\n1. 假设线程A执行writer()，按照volatile语义，会把变量`v=true`写入内存\n2. 假设线程B执行reader()，同样按照volatile语义，线程B会从内存读取变量v\n3. 如果线程B看到`v==true`\n    - 如果Java低于1.5，x可能是42，也可能是0\n        - CPU缓存导致的**可见性**问题\n    - 如果Java高于等于1.5，x是42\n        - JMM在Java 1.5通过**Happens-Before**对volatile语义进行了**增强**\n\n### Happens-Before规则\n\n#### 理解\n1. 望文生义的理解：前面一个操作发生在后续操作的前面\n2. 正确的理解：_**前面一个操作的结果对后续操作是可见的**_\n3. 正式的说法：Happens-Before_**约束了编译器的优化行为**_\n    - 虽然允许编译器优化，但要求编译器优化后一定要遵循Happens-Before规则\n4. Happens-Before规则是JMM里面比较难理解的内容，与程序员相关的规则有六项，都与**可见性**相关\n\n#### 程序的顺序性规则\n在**同一个线程**中，按照程序顺序，前面的操作Happens-Before于后面的任意操作\n\n#### volatile变量规则\n1. 对一个volatile变量的**写操作**，Happens-Before于后续对这个volatile变量的**读操作**\n2. 对一个volatile变量的写操作相对于后续对这个volatile变量的读操作_**可见**_\n\n#### 传递性规则\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-happens-before-transitive.png\" width=800/>\n\n1. 如果A Happens-Before B，并且B Happens-Before C，那么A Happens-Before C\n2. 程序的顺序性规则：`x=42`Happens-Before`v=true`\n3. volatile变量规则：写变量`v=true`Happens-Before读变量`v=true`\n4. 传递性规则：`x=42`Happens-Before读变量`v=true`\n    - 如果线程B读到了`v=true`，那么线程A设置的`x=42`对线程B是可见的，即线程B能看到`x==42`\n5. 这就是Java 1.5**对volatile语义的增强**，该版本的JUC就是靠**volatile语义**实现**可见性**的\n\n#### 管程中锁的规则\n```java\npublic void fun() {\n    synchronized (this) { // 此处自动加锁\n        // x 是共享变量, 初始值 =10\n        if (this.x < 12) {\n            this.x = 12;\n        }\n    } // 此处自动解锁\n}\n```\n1. 对一个锁的**解锁**Happens-Before于后续对这个锁的**加锁**\n2. 管程是一种**通用的同步原语**，Java中的`synchronized`就是Java对**管程的实现**\n3. 管程中的锁在Java里是**隐式**实现的\n    - 在进入代码块之前，会自动加锁，而在代码块执行完会自动释放锁\n    - 加锁和释放锁都是**编译器**帮我们实现的\n4. x的初始值是10，线程A执行完代码块后，x的值变成了12（执行完自动释放锁）\n5. 线程B进入代码块时，能够看到线程A对x的写操作，即线程B能够看到x==12\n\n#### 线程start()规则\n```java\nThread B = new Thread(() -> {\n    // 主线程调用 B.start() 之前\n    // 所有对共享变量的修改，此处皆可见\n    // 此例中，var==77\n    System.out.println(var);\n});\n// 此处对共享变量 var 修改\nvar = 77;\n// 主线程启动子线程\nB.start();\n```\n1. **主线程A启动子线程B后，子线程B能够看到主线程A在启动子线程B之前的操作**\n2. 即线程A调用线程B的start()方法，那么该start()方法Happens-Before于B中的任意操作\n\n#### 线程join()规则\n```java\nThread B = new Thread(() -> {\n    // 此处对共享变量 var 修改\n    System.out.println(var); // 77\n    var = 66;\n});\n// 例如此处对共享变量修改，\n// 则这个修改结果对线程 B 可见\n// 主线程启动子线程\nvar = 77;\nB.start();\n\nB.join();\n// 子线程所有对共享变量的修改\n// 在主线程调用 B.join() 之后皆可见\n// 此例中，var==66\nSystem.out.println(var); // 66\n```\n1. 主线程A等待子线程B完成（主线程A通过调用子线程B的join()方法来实现）\n    - 当子线程B完成后（主线程A中join()方法返回），**主线程A能够看到子线程B的操作**\n2. 即如果在线程A中调用线程B的join()并成功返回，那么线程B中的任意操作Happens-Before于该join()方法的**返回**\n\n### final\n1. volatile的目的：禁用**CPU缓存**（可见性）和**编译优化**（有序性）\n2. final修饰变量时，初衷是告诉编译器，该变量是**一直不变**的，可以**尽量优化**\n3. 曾经优化过度，导致异常\n    - 例如在利用双重检查创建单例时，构造函数的**错误重排列**会导致线程可能会看到**final变量的值会变化**\n    - 在Java 1.5的JMM对final类型变量的**重排**进行了**约束**\n        - 只要提供**没有逸出的构造函数**，就不会出现问题\n\n#### 逸出\n```java\npublic class EscapeExample {\n\n    public static Object global_obj;\n    final int x;\n    final int y;\n\n    // 错误的构造函数，尽量避免\n    public EscapeExample() {\n        x = 3;\n        y = 4;\n        // 此处就是将 this 逸出\n        // 其他线程通过global_obj读取的x可能是0，不满足x被修饰为final的语义\n        global_obj = this;\n    }\n}\n```\n\n## 小结\n1. Happens-Before的语义是一种_**因果关系**_\n    - 如果事件A是导致B事件的起因，那么事件A一定Happens-Before事件B\n2. _**在Java里，Happens-Before的语义本质是一种可见性**_\n    - A Happens-Before B意味着A对B来说是可见的，**不论A和B是否发生在同一个线程里**\n3. Java内存模型的受众\n    - JVM的开发人员\n    - 编写并发程序的应用开发人员\n        - _**核心：Happens-Before规则**_\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- 问题源头","url":"%2F2019%2F04%2F15%2Fjava-concurrent-bug-source%2F","content":"\n## CPU、内存、IO设备\n1. 核心矛盾：三者的_**速度差异**_\n2. 为了合理利用CPU的高性能，平衡三者的速度差异，计算机体系结构、操作系统和编译程序都做出了贡献\n    - 计算机体系结构：CPU增加了**缓存**、以均衡**CPU与内存**的速度差异\n    - 操作系统：增加了**进程、线程**，分时复用CPU，以平衡**CPU和IO设备**的速度差异\n    - 编译程序：优化**指令执行次序**，使得缓存能够得到更加合理地利用\n\n<!-- more -->\n\n## CPU缓存 -> 可见性问题\n\n### 单核\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-bug-visibility-single-core.png\" width=800/>\n\n1. 在单核时代，所有的线程都在一颗CPU上执行，CPU缓存与内存的**数据一致性**很容易解决\n2. 因为所有线程操作的都是同一个CPU的缓存，一个线程对CPU缓存的写，对另外一个线程来说一定是**可见**的\n3. **可见性**：一个线程对**共享变量**的修改，另一个线程能够**立即看到**\n\n### 多核\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-bug-visibility-multi-core.png\" width=800/>\n\n1. 在多核时代，每颗CPU都有自己的缓存，此时CPU缓存与内存的**数据一致性**就没那么容易解决了\n2. 当多个线程在不同的CPU上执行时，操作的是不同的CPU缓存\n3. 线程A操作的是CPU-1上的缓存，线程B操作的是CPU-2上的缓存，此时线程A对变量V的操作对于线程B而言**不具备可见性**\n\n#### 代码验证\n```java\npublic class VisibilityTest {\n    private static final long MAX = 100_000_000;\n    private long count = 0;\n\n    private void add() {\n        int idx = 0;\n        while (idx++ < MAX) {\n            count += 1;\n        }\n    }\n\n    @Test\n    public void calc() throws InterruptedException {\n        // 创建两个线程，执行 add() 操作\n        Thread t1 = new Thread(this::add);\n        Thread t2 = new Thread(this::add);\n\n        // 启动两个线程\n        t1.start();\n        t2.start();\n\n        // 等待两个线程执行结束\n        t1.join();\n        t2.join();\n\n        // count=100_004_429 ≈ 100_000_000\n        System.out.println(\"count=\" + count);\n    }\n}\n```\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-bug-visibility-multi-core-count.png\" width=800/>\n\n1. 假设线程A和线程B同时开始执行，那么第一次都会将count=0读到各自的CPU缓存中\n2. 之后由于各自的CPU缓存里都有了count的值，两个线程都是**基于CPU缓存里的count值来进行计算**的\n3. 所以导致最终count的值小于2MAX，这就是**CPU缓存导致的可见性问题**\n\n## 线程切换 -> 原子性问题\n\n### 分时复用\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-bug-atomic-thread-switch.png\" width=800/>\n\n1. 由于**IO太慢**，早期的操作系统发明了**多进程**，并支持**分时复用**（时间片）\n2. 在一个时间片内，如果进程进行一个IO操作，例如读文件，该进程可以把自己标记为**休眠状态**并让出CPU的使用权\n    - 待文件读进内存后，操作系统会把这个休眠的进程**唤醒**，唤醒后的进程就有机会重新获得CPU的使用权了\n3. 进程在等待IO时释放CPU的使用权，可以让CPU在这段等待时间里执行其他任务，_**提高CPU的使用率**_\n4. 另外，如果此时另外一个进程也在读文件，而读文件的操作会先**排队**\n    - 磁盘驱动在完成一个进程的读操作后，发现有其他任务在排队，会立即启动下一个读操作，_**提高磁盘IO的使用率**_\n\n### 线程切换\n1. 早期的操作系统基于进程来调度CPU，**不同进程间是不共享内存空间的**，进程切换需要_**切换内存映射地址**_\n2. 一个进程创建的所有线程，都是**共享**同一个内存空间的，因此线程切换的成本很低\n3. 现代的操作系统都是基于更轻量的线程来调度的，而Java并发程序都是基于**多线程**的\n\n#### count+=1\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-bug-atomic-thread-switch-count.png\" width=800/>\n\n1. 线程切换的时机大多在**时间片结束**的时候，而高级语言里的一条语句往往需要**多条CPU指令**完成，如`count+=1`\n    - 把变量count从内存加载到CPU的寄存器\n    - 在寄存器中执行+1操作\n    - 将结果写入**CPU缓存**（最终会回写到内存）\n2. 操作系统做线程切换，可以发生在任何一条**CPU指令**（而非高级语言的语句）执行完\n3. 按照上图执行，线程A和线程B都执行了`count+=1`，但得到的结果却是1，而不是2，因为Java中的+1操作**不具有原子性**\n4. **原子性**：一个或多个操作在CPU执行的过程中**不被中断**的特性\n5. CPU能保证的原子操作是**CPU指令级别**的，而不是高级语言的操作符\n\n## 编译优化 -> 有序性问题\n1. **有序性**：程序按照代码的先后顺序执行\n2. 编译器为了优化性能，有时会改变程序中语句的先后顺序\n\n### 双重检查\n```java\nclass Singleton {\n    private static Singleton instance;\n\n    // 双重检查\n    public static Singleton getInstance() {\n        if (instance == null) {\n            synchronized (Singleton.class) {\n                if (instance == null)\n                    instance = new Singleton();\n            }\n        }\n        return instance;\n    }\n}\n```\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-bug-order-double-check.png\" width=800/>\n\n1. 直觉\n    - 线程A和B同时调用getInstance()方法，同时发现instance==null，同时对Singleton.class加锁\n    - 此时JVM保证只有一个线程能够加锁成功（假设是线程A），另一个线程则会进入等待状态（假设线程B）\n    - 线程A会创建一个Singleton实例，然后释放锁，线程B被唤醒并再次尝试加锁，此时加锁成功\n    - 线程B检查instance==null，发现已经创建过Singleton实例了，不会再创建Singleton实例了\n2. 直觉上的new操作\n    - 分配一块内存M\n    - 在内存M上初始化Singleton对象\n    - 将M的地址赋值给instance变量\n3. 编译器优化后的new操作可能是\n    - 分配一块内存M\n    - 将M的地址赋值给instance变量\n    - 在内存M上初始化Singleton对象\n4. 因此，实际情况可能是\n    - 假设线程A先执行getInstance()方法，当执行完指令2时恰好发生了**线程切换**，切换到线程B\n    - 线程B也在执行getInstance()方法，线程B会执行第一个判断，发现instance!=null，直接返回instance\n    - 但此时返回的instance是**没有初始化过**的，如果此时访问instance的成员变量就有可能触发_**空指针异常**_\n\n## 小结\n1. _**CPU缓存 -> 可见性问题，线程切换 -> 原子性问题，编译优化 -> 有序性问题**_\n2. CPU缓存、线程和编译优化的目的与并发程序的目一致，都是为了**提高程序性能**\n    - 但技术在解决一个问题的同时，必然会带来另一个问题，因此需要权衡\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Linux -- 内核初始化","url":"%2F2019%2F04%2F13%2Flinux-kernel-init%2F","content":"\n## start_kernel()\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-kernel-init-start-kernel.jpeg\" width=800/>\n\n\n<!-- more -->\n\n```c\n// init/main.c\nasmlinkage __visible void __init start_kernel(void)\n{\n    // 0号进程（创始进程）\n    set_task_stack_end_magic(&init_task);\n    // 设置中断门（系统调用是通过中断的方式触发）\n    trap_init();\n    // 初始化内存管理模块\n    mm_init();\n    // 初始化调度模块\n    sched_init();\n    // 初始化基于内存的文件系统rootfs\n    vfs_caches_init();\n    // 创建1号进程（用户态总管）和2号进程（内核态总管）\n    arch_call_rest_init();\n    ...\n}\n```\n1. 内核的启动是从入口函数start_kernel()开始，相当于内核的main函数\n2. start_kernel()函数里面有各种各样的初始化函数（XXX_init）\n\n## 0号进程\n1. `set_task_stack_end_magic(&init_task)`，这是系统创建的第一个进程，称为**0号进程**\n2. 0号进程是**唯一**一个没有通过`fork`或者`kernel_thread`产生的进程，是进程列表的第一个进程\n\n## trap_init()\n1. trap_init()里面设置了很多**中断门**（Interrupt Gate），用于处理各种中断\n2. 系统调用的也是通过**发送中断**的方式进行的，系统调用的中断门\n    - 32位：`SYSG(IA32_SYSCALL_VECTOR,\tentry_INT80_32)`\n    - 64位的有另外的系统调用方法\n\n## mm_init() + sched_init()\n1. mm_init()：初始化**内存管理模块**\n2. sched_init()：初始化**调度模块**\n\n## vfs_caches_init()\n```c\n// fs/dcache.c\nvoid __init vfs_caches_init(void)\n{\n    mnt_init();\n}\n\n// init/do_mounts.c\nvoid __init mnt_init(void)\n{\n    init_rootfs();\n}\n\n// init/do_mounts.c\nint __init init_rootfs(void)\n{\n    // 在VFS虚拟文件系统里面注册一种类型\n    int err = register_filesystem(&rootfs_fs_type);\n}\n```\n1. vfs_caches_init()：初始化**基于内存的文件系统**`rootfs`\n2. 在vfs_caches_init()中会依次调用：mnt_init() -> init_rootfs() -> register_filesystem(&rootfs_fs_type)\n\n### VFS\n1. VFS: **Virtual File System**，虚拟文件系统\n2. 为了兼容各种各样的文件系统，需要将文件的相关数据结构和操作**抽象**出来，形成一个抽象层并对上提供统一的接口\n\n## rest_init()\nstart_kernel()最后调用的是rest_init()，用来进行其他方面的初始化\n```c\n// init/main.c\nnoinline void __ref rest_init(void)\n{\n    // 初始化1号进程，用户态总管，systemd\n    pid = kernel_thread(kernel_init, NULL, CLONE_FS);\n    ...\n    // 初始化2号进程，内核态总管，kthreadd\n    pid = kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES);\n}\n```\n```\n$ top\nPID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND\n103587 root      20   0  162004   2284   1612 R  0.3  0.2   0:00.42 top\n103801 root      20   0       0      0      0 S  0.3  0.0   0:00.08 kworker/0:1\n     1 root      20   0  127976   6544   4136 S  0.0  0.7   0:25.99 systemd\n     2 root      20   0       0      0      0 S  0.0  0.0   0:00.03 kthreadd\n```\n\n### 1号进程\n1. 通过`kernel_thread(kernel_init, NULL, CLONE_FS)`创建第二个线程，即**1号进程**\n2. 1号进程对于操作系统来说，具有划时代的意义，因为1号进程将运行一个_**用户进程**_\n\n#### 权限\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-x86-ring-permission.jpeg\" width=800/>\n\n1. 原来只有0号进程，所有资源都可以使用，没有竞争关系，也无须担心被恶意破坏\n2. 现在有了1号进程，需要区分核心资源和非核心资源，而x86提供了_**分层的权限机制**_\n    - 把区域分成了4个Ring，越往里权限越高\n3. 操作系统很好地利用了x86的分层权限机制\n    - 将能够访问**关键资源**的代码放在**Ring0**，称为**内核态**（Kernel Mode）\n    - 将普通的程序代码放在Ring3，称为**用户态**（User Mode）\n4. 回忆Linux的启动过程，易知此时系统是处于**保护模式**的\n    - 保护模式除了**寻址空间变大**以外，还有另外一个重要功能就是**保护**\n    - 保护：_**禁止处于用户态的代码执行更高权限的指令**_\n5. 如果用户态的代码需要访问核心资源，需要通过_**系统调用**_\n\n#### 状态切换\n_**用户态 -> 系统调用 -> 保存寄存器 -> 内核态执行系统调用 -> 恢复寄存器 -> 返回用户态**_\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-user-kernel-switch.jpeg\" width=800/>\n\n\n##### 发送网络包\n1. 场景\n    - 当一个用户态程序运行到一半时，要访问一个核心资源，例如访问网卡发送一个网络包\n    - 此时需要暂停当前运行的用户态程序，调用**系统调用**，切换到**内核态**，接下来就是运行内核中的代码了\n    - 内核将从系统调用传过来的包，在网卡上排队，等待发送\n    - 发送完了，系统调用就结束，返回**用户态**，让暂停运行的用户态程序继续运行\n2. 如何实现暂停？\n    - 在暂停的那一刻，需要把当时CPU**寄存器**的值**全部**暂存到一个地方（进程管理系统很容易获取）\n    - 当系统调用执行完毕，准备返回的时候，再从这个地方将寄存器的值恢复回去，就能接着运行了\n\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-send-network-packet.jpeg\" />\n\n#### 内核态 -> 用户态\n```c\n// init/main.c\nstatic int __ref kernel_init(void *unused)\n{\n    // 将ramdisk_execute_command设置为/init\n    kernel_init_freeable();\n\n    // 执行ramdisk的/init\n    if (ramdisk_execute_command) {\n    \tret = run_init_process(ramdisk_execute_command);\n    }\n\n    // 执行根文件系统的/sbin/init、/etc/init、/bin/init、/bin/sh\n    if (execute_command) {\n    \tret = run_init_process(execute_command);\n    }\n    if (!try_to_run_init_process(\"/sbin/init\") ||\n        !try_to_run_init_process(\"/etc/init\") ||\n        !try_to_run_init_process(\"/bin/init\") ||\n        !try_to_run_init_process(\"/bin/sh\"))\n    \treturn 0;\n}\n\n// init/main.c\nstatic noinline void __init kernel_init_freeable(void)\n{\n    if (!ramdisk_execute_command)\n    \tramdisk_execute_command = \"/init\";\n}\n\n// init/main.c\nstatic int run_init_process(const char *init_filename)\n{\n    // 系统调用，运行一个可执行文件，do_xxx往往是内核系统调用的实现\n    return do_execve(getname_kernel(init_filename)...);\n}\n\n// init/main.c\nstatic int try_to_run_init_process(const char *init_filename)\n{\n    ret = run_init_process(init_filename);\n}\n\n// fs/exec.c\nint do_execve(struct filename *filename...)\n{\n    return do_execveat_common(AT_FDCWD, filename, argv, envp, 0);\n}\n\n// fs/exec.c\nstatic int do_execveat_common(int fd, struct filename *filename,...)\n{\n    return __do_execve_file(fd, filename, argv, envp, flags, NULL);\n}\n\n// fs/exec.c\nstatic int __do_execve_file(int fd, struct filename *filename,...)\n{\n    retval = exec_binprm(bprm);\n}\n\n// fs/exec.c\nstatic int exec_binprm(struct linux_binprm *bprm)\n{\n    ret = search_binary_handler(bprm);\n}\n\n// fs/exec.c\nint search_binary_handler(struct linux_binprm *bprm)\n{\n    struct linux_binfmt *fmt;\n    retval = fmt->load_binary(bprm);\n}\n\n// fs/binfmt_elf.c\nstatic struct linux_binfmt elf_format = {\n    .module         = THIS_MODULE,\n    .load_binary    = load_elf_binary,\n    .load_shlib     = load_elf_library,\n    .core_dump      = elf_core_dump,\n    .min_coredump   = ELF_EXEC_PAGESIZE,\n};\n\n// fs/binfmt_elf.c\nstatic int load_elf_binary(struct linux_binprm *bprm)\n{\n    start_thread(regs, elf_entry, bprm->p);\n}\n\n// arch/x86/kernel/process_32.c\nvoid start_thread(struct pt_regs *regs, unsigned long new_ip, unsigned long new_sp)\n{\n    set_user_gs(regs, 0);\n    regs->fs\t\t= 0;\n    regs->ds\t\t= __USER_DS;\n    regs->es\t\t= __USER_DS;\n    regs->ss\t\t= __USER_DS;\n    regs->cs\t\t= __USER_CS;\n    regs->ip\t\t= new_ip;\n    regs->sp\t\t= new_sp;\n    regs->flags\t\t= X86_EFLAGS_IF;\n    force_iret();\n}\n```\n1. 在1号进程的启动过程中，当执行kernel_thread函数时，还处于**内核态**，需要切换到**用户态**去运行程序\n2. kernel_thread的第一个参数是一个函数kernel_init，kernel_init函数会调用kernel_init_freeable()\n3. 1号进程运行的是一个**文件**，在run_init_process函数中，可见它实际调用的是do_execve\n    - execve是一个系统调用，作用是运行一个**可执行文件**，do_xxx往往是内核系统调用的实现\n4. 尝试运行ramdisk上的/init，或者普通文件系统上的/sbin/init、/etc/init、/bin/init、/bin/sh\n    - 不同版本的Linux会选择不同的文件启动，只要有一个能起来即可\n5. 利用执行init文件的机会，从内核态回到用户态\n    - 调用do_execve，恰好是上面系统调用过程的后半部分：_**内核态执行系统调用 -> 恢复寄存器 -> 返回用户态**_\n    - `load_binary`\n        - 运行一个程序，需要加载**二进制文件**\n        - 而二进制文件也是有一定的格式，Linux下的常用格式为**ELF**（Executable and Linkable Format）\n    - `.load_binary\t= load_elf_binary`：先调用load_elf_binary，最后调用start_thread\n        - start_thread的第一个参数`struct pt_regs`为**寄存器**\n        - 这个结构是在**系统调用**时，_内核中用于保存**用户态运行上下文**_\n        - 将用户态代码段CS设置为`__USER_CS`，将用户态的数据段DS设置为`__USER_DS`\n            - 以及指令指针寄存器IP和栈指针寄存器SP\n        - force_iret()用于从系统调用中返回，此时会**恢复寄存器**\n        - CS和指令指针寄存器IP恢复了，指向用户态下一个要执行的指令\n        - DS和函数栈指针SP也恢复了，指向用户态函数栈的栈顶\n\n#### ramdisk\n1. init终于从内核态到用户态了，一开始到用户态的是ramdisk的init\n    - 后来会启动**真正根文件系统**上的init，成为_**所有用户态进程的祖先**_\n2. Grub启动配置\n    - `initrd16 /initramfs-3.10.0-957.el7.x86_64.img` -- 基于**内存**的文件系统\n3. 刚才的init程序是在**文件系统**上的，而文件系统一定是在**存储设备**上的，例如硬盘\n4. Linux需要**驱动**才能访问存储设备\n    - 如果存储系统的数量很有限，那么驱动可以直接放到内核里面，内核会被加载到内存里，进而对存储系统进行访问\n    - 但现在存储系统很多，如果把所有存储系统的驱动都放进内核，那内核会很大\n5. 因此可以先弄一个基于**内存**的文件系统，**内存访问是不需要驱动的**，这就是ramdisk，此时的**ramdisk是根文件系统**\n6. 然后开始运行ramdisk上的/init，运行完毕后就已经是用户态的\n7. ramdisk上的/init程序会**根据存储系统类型加载驱动**，加载驱动后就可以**设置真正的根文件系统**了\n8. 有了真正的根文件系统，ramdisk上的/init会启动文件系统上的init\n9. 接下来就是各种系统的初始化，如启动系统服务，控制台等，用户就可以登录进来了\n\n### 2号进程\n1. 通过`kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES)`创建第三个进程，即2号进程\n2. 进程与线程\n    - 从**用户态**来看，创建的是**进程**\n    - 从**内核态**来看，无论进程还是线程，都可以统称为**任务**，使用**相同的数据结构**，**平放在同一个链表中**\n3. kthreadd负责所有内核态线程的调度和管理，是_**内核态所有线程的祖先**_\n\n<!-- indicate-the-source -->\n","tags":["Linux"],"categories":["Linux"]},{"title":"Linux -- 启动过程","url":"%2F2019%2F04%2F10%2Flinux-boot-process%2F","content":"\n## BIOS\n\n### ROM + RAM\n1. 主板上有ROM，是**只读**的，上面固化了BIOS程序\n2. ROM：Read Only Memory\n3. RAM：Read Access Memory\n4. BIOS：Basic Input and Output System\n\n<!-- more -->\n\n### 1M寻址空间\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-bios-bootloader-1m.jpg\" width=800/>\n\n1. 在x86系统，将1M的**内存空间**最上面的`0xF0000~0xFFFFF`这**64K**空间映射给ROM\n2. 电脑在刚启动时，会做一些重置的工作，将CPU的CS设置为`0xFFFF`，将CPU的IP设置为`0x0000`\n    - 因此，第一条指令将指向`0xFFFF0`（0xFFFF << 4 + 0x0000），在ROM的范围内\n    - 在这里，有一个**JMP**命令（约定）会跳到ROM中执行初始化工作的代码，接着BIOS开始进行**初始化**的工作\n        - BIOS检查一下**系统硬件**是否都正常\n        - 建立一个**中断向量表**和**中断服务程序**，因为要使用键盘和鼠标，这些都是要通过中断来进行的\n        - 在内存空间映射显存的空间，在显示器上显示一些字符\n\n## bootloader\n1. BIOS在做完自己的事情后，便开始打听操作系统的下落\n2. 操作系统一般会安装在磁盘上，在BIOS界面，有一个选择**启动盘**的选项\n    - 启动盘的特点：一般在**第一个扇区**（512字节），以`0xAA55`结束\n    - 这是一个**约定**，当满足这个条件时，说明这是一个启动盘，在512字节以内会**启动**相关的代码\n\n## Grub\nGrub：_**Grand Unified Bootloader Version 2**_\n\n### 启动列表\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-centos-grub-boot-menu.png\" width=1000/>\n\n```shell\n$ cat /boot/grub2/grub.cfg\n\n### BEGIN /etc/grub.d/10_linux ###\nmenuentry 'CentOS Linux (3.10.0-957.el7.x86_64) 7 (Core)' --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option 'gnulinux-3.10.0-957.el7.x86_64-advanced-d29269ec-9932-4955-9c91-22cf19b96f1b' {\n        load_video\n        set gfxpayload=keep\n        insmod gzio\n        insmod part_msdos\n        insmod xfs\n        set root='hd0,msdos1'\n        if [ x$feature_platform_search_hint = xy ]; then\n          search --no-floppy --fs-uuid --set=root --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1 --hint='hd0,msdos1'  426233b2-066b-4537-b029-5abf3aca8a06\n        else\n          search --no-floppy --fs-uuid --set=root 426233b2-066b-4537-b029-5abf3aca8a06\n        fi\n        linux16 /vmlinuz-3.10.0-957.el7.x86_64 root=/dev/mapper/centos-root ro crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet\n        initrd16 /initramfs-3.10.0-957.el7.x86_64.img\n}\nmenuentry 'CentOS Linux (0-rescue-b73c751c3f7145f995aa2c110745e89b) 7 (Core)' --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option 'gnulinux-0-rescue-b73c751c3f7145f995aa2c110745e89b-advanced-d29269ec-9932-4955-9c91-22cf19b96f1b' {\n        load_video\n        insmod gzio\n        insmod part_msdos\n        insmod xfs\n        set root='hd0,msdos1'\n        if [ x$feature_platform_search_hint = xy ]; then\n          search --no-floppy --fs-uuid --set=root --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1 --hint='hd0,msdos1'  426233b2-066b-4537-b029-5abf3aca8a06\n        else\n          search --no-floppy --fs-uuid --set=root 426233b2-066b-4537-b029-5abf3aca8a06\n        fi\n        linux16 /vmlinuz-0-rescue-b73c751c3f7145f995aa2c110745e89b root=/dev/mapper/centos-root ro crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet\n        initrd16 /initramfs-0-rescue-b73c751c3f7145f995aa2c110745e89b.img\n}\nif [ \"x$default\" = 'CentOS Linux (3.10.0-957.el7.x86_64) 7 (Core)' ]; then default='Advanced options for CentOS Linux>CentOS Linux (3.10.0-957.el7.x86_64) 7 (Core)'; fi;\n### END /etc/grub.d/10_linux ###\n```\n\n### grub2-mkconfig\n```\n$ grub2-mkconfig -o /boot/grub2/grub.cfg\nGenerating grub configuration file ...\nFound linux image: /boot/vmlinuz-3.10.0-957.el7.x86_64\nFound initrd image: /boot/initramfs-3.10.0-957.el7.x86_64.img\nFound linux image: /boot/vmlinuz-0-rescue-b73c751c3f7145f995aa2c110745e89b\nFound initrd image: /boot/initramfs-0-rescue-b73c751c3f7145f995aa2c110745e89b.img\ndone\n```\n\n## grub2-install\n```shell\n# 将启动程序安装到相应的位置\n$ grub2-install /dev/sdb\nInstalling for i386-pc platform.\nInstallation finished. No error reported.\n```\n\n### imgs\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-centos-grub2-install.jpeg\" width=800/>\n```\n$ ll /boot/grub2/i386-pc/*.img\n-rw-r--r--. 1 root root   512 4月  11 22:16 /boot/grub2/i386-pc/boot.img\n-rw-r--r--. 1 root root 27810 4月  11 22:16 /boot/grub2/i386-pc/core.img\n\nll /usr/lib/grub/i386-pc/*img\n-rw-r--r--. 1 root root   512 11月  8 19:58 /usr/lib/grub/i386-pc/boot_hybrid.img\n-rw-r--r--. 1 root root   512 11月  8 19:58 /usr/lib/grub/i386-pc/boot.img\n-rw-r--r--. 1 root root  2048 11月  8 19:58 /usr/lib/grub/i386-pc/cdboot.img\n-rw-r--r--. 1 root root   512 11月  8 19:58 /usr/lib/grub/i386-pc/diskboot.img\n-rw-r--r--. 1 root root 28120 11月  8 19:58 /usr/lib/grub/i386-pc/kernel.img\n-rw-r--r--. 1 root root  1024 11月  8 19:58 /usr/lib/grub/i386-pc/lnxboot.img\n-rw-r--r--. 1 root root  2896 11月  8 19:58 /usr/lib/grub/i386-pc/lzma_decompress.img\n-rw-r--r--. 1 root root  1024 11月  8 19:58 /usr/lib/grub/i386-pc/pxeboot.img\n```\n\n### boot.img\n1. grub2第一个要安装的是boot.img，它由boot.S编译而成，一共**512**字节，被安装到**启动盘的第一个扇区**\n    - 这个扇区通常称为**MBR**（Master Boot Record，**主引导记录/扇区**）\n2. BIOS完成任务后，会将boot.img从硬盘加载到内存中的`0x7c00`来运行\n3. 由于boot.img只有512字节，因此能做的事情非常有限，它能做的最重要的一件事情是加载grub2的另一个镜像**core.img**\n\n### core.img\n1. core.img由**diskboot.img、lzma_decompress.img、kernel.img**（Grub内核）和一系列模块组成\n2. boot.img先加载core.img的**第一个扇区**，如果从硬盘启动，这个扇区里面的是diskboot.img，对应的代码是diskboot.S\n3. boot.img将**控制权**交给diskboot.img后，diskboot.img的任务就是将**core.img的其他部分**加载进来\n    - 先加载lzma_decompress.img，再加载kernel.img（Grub内核），最后是各个module对应的img\n4. lzma_decompress.img对应的代码是startup_raw.S，kernel.img是压缩过的，因此在执行之前，需要先**解压缩**\n5. 在这之前，所有遇到过的程序都非常小，完全可以在**实模式**下运行\n    - 但随着加载的东西越来越大，实模式的1M地址空间最终会放不下了\n    - 所以在**真正的解压缩之前**，lzma_decompress.img会调用**real_to_prot**，切换到**保护模式**\n    - 这样就能使用更大的寻址空间，加载更大的内容\n\n#### 实模式 -> 保护模式\n切换到**保护模式**需要执行很多工作，大部分工作都与**内存的访问方式**有关\n\n##### 分段 + 分页\n1. _**启动分段**：在内存里建立**段描述符**，将**段寄存器**变成**段选择子**，指向**段描述符**，这样就能实现**不同进程的切换**_\n2. _**启动分页**：能够管理的内存变大了，就需要将内存分成**相等大小的块**_\n\n##### real_to_prot\n1. 在**实模式**下，一共有20根地址线，可以访问1M的地址空间\n2. 在**保护模式**下，第21根就要起作用了，需要打开Gate A20，即第21根地址线的**控制线**\n3. 函数：`DATA32 call real_to_prot`（startup_raw.S）\n4. 此时此刻，有的是空间，接下来需要对压缩过的kernel.img进行**解压缩**，然后跳转到kernal.img开始执行\n\n#### kernal.img\n1. kernal.img对应的代码是startup.S以及一堆c文件，在startup.S中会调用grub_main函数\n    - 在grub_main函数中，首先从`grub_load_config ()`开始解析`grub.conf`\n    - 如果能够正常启动，grub_main函数会调用`grub_command_execute(\"normal\", 0, 0)`\n    - 最终会调用`grub_normal_execute()`函数\n        - 在这个函数里，`grub_show_menu()`会列出可选择的操作系统列表\n2. 选择了一项，就要开始启动某个操作系统，调用`grub_menu_execute_entry()`\n    - `linux16`命令\n        - **装载指定的内核文件**，**传递内核启动参数**，调用`grub_cmd_linux`函数\n        - 首先读取**Linux内核镜像头部**的一些数据结构，放到内存中的数据结构来检查\n        - 如果检测通过，就会读取**整个Linux内核镜像**到内存\n    - `initrd`命令\n        - 用于为即将启动的内核传递`init ramdisk`路径\n        - 调用`grub_cmd_initrd`函数，将`initramfs`加载到内存中\n    - 最后，调用`grub_command_execute(\"boot\",0,0)`函数，这才开始_**真正地启动内核**_\n\n## 启动过程小结\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-boot-process.jpeg\" width=800/>\n\n<!-- indicate-the-source -->\n","tags":["Linux"],"categories":["Linux"]},{"title":"Java并发 -- 概述","url":"%2F2019%2F04%2F09%2Fjava-concurrent-overview%2F","content":"\n## 核心问题\n\n### 分工\n1. JUC中的`Executor`、`Fork/Join`和`Future`本质上都是一种**分工**方法\n2. 并发编程领域还总结了一些**设计模式**，基本上都是和**分工**方法相关\n    - 生产者-消费者\n    - `Thread-Per-Message`\n    - `Worker Thread`\n\n<!-- more -->\n\n### 同步\n1. 在并发编程领域里的**同步**，主要指的就是_**线程间的协作**_\n    - 一个线程执行完了一个任务，如何通知执行后续任务的线程开始工作\n2. 协作一般是与分工相关的\n    - JUC中的`Executor`、`Fork/Join`和`Future`本质上都是一种**分工**方法\n    - 但同时也能解决**线程协作**的问题\n3. 例如，用`Future`可以发起一个**异步**调用\n    - 当主线程调用get()方法取结果时，主线程会等待\n    - 当异步执行的结果返回时，get()方法就自动返回了\n    - `Future`工具类已经帮我们解决了_**主线程和异步线程之间的协作**_\n4. JUC中的`CountDownLatch`、`CyclicBarrier`、`Phaser`和`Exchanger`都是用来解决**线程协作**问题的\n5. 但很多场景还是需要自己处理线程之间的协作，问题基本可以描述为\n    - _**当某个条件不满足时，线程需要等待，当某个条件满足时，线程需要被唤醒执行**_\n6. 在Java并发编程领域，解决**协作**问题的**核心技术**是**管程**（Monitor）\n    - 上面提到的所有线程协作技术**底层**都是利用**管程**来解决的\n    - 管程是一种解决并发问题的**通用模型**，除了能解决**线程协作**问题，还能解决**互斥**问题\n    - _**管程是解决并发问题的万能钥匙**_\n\n### 互斥\n1. 分工和同步主要强调的是**性能**，线程安全关注的是_**并发程序的正确性**_\n2. 在并发程序里，当多个线程**同时访问**同一个共享变量时，结果是**不确定**的\n    - 导致**不确定的主要源头**是**可见性问题，有序性问题和原子性问题**，为了解决这三个问题，Java引进来_**Java内存模型**_\n    - Java内存模型提供了一系列规则，可以避免可见性问题，有序性问题和原子性问题，但_**不能完全解决线程安全的问题**_\n3. 解决**线程安全**问题的**核心方案**还是**互斥**，互斥的定义：_**在同一时刻，只允许一个线程访问共享变量**_\n4. 实现互斥的**核心技术**是**锁**，`synchronized`、JUC中的各种`Lock`都能解决互斥问题\n5. 锁解决了**线程安全**的问题，但同时也带来了**性能问题**，可以针对场景进行优化\n    - JUC中的`ReadWriteLock`、`StampedLock`可以优化在**读多写少**的场景下锁的性能\n    - 无锁的数据结构，例如JUC中的**原子类**都是基于**无锁**技术实现的\n    - 使用`Copy-On-Write`模式\n    - **不共享变量**（ThreadLocal）或者**变量只允许读**（final）\n6. 使用锁除了要注意性能之外，还需要注意**死锁**问题\n\n## 小结\n<img src=\"https://java-concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/java-concurrent-overview.png\" width=800/>\n\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Linux -- x86架构","url":"%2F2019%2F04%2F09%2Flinux-x86%2F","content":"\n## 计算机的工作模式\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-computer-working-mode.jpg\" width=800/>\n\n\n<!-- more -->\n\n1. 对于一个计算机来说，最**核心**的是CPU，CPU是计算机的大脑，所有设备都围绕其展开\n2. CPU通过**总线**（Bus）与其他设备连接，在这些设备中，最为重要的是**内存**（Memory）\n3. 单靠CPU是无法完成计算任务的，很多复杂的计算任务都需要将**中间结果**保存下来，然后基于中间结果进行下一步的计算\n    - CPU本身无法保存这么多的中间结果，因此需要依赖于内存\n4. CPU和内存是**完成计算**的核心组件\n\n### CPU\n1. CPU包含三部分：_**运算单元、数据单元和控制单元**_\n2. 运算单元只管计算，但它不知道应该算哪些数据，运算结果应该放在哪里\n3. 运算单元计算的数据如果每次都要经过总线，直接到内存里面现拿，速度会很**慢**，因此出现了_**数据单元**_\n4. 数据单元包括CPU内部的**缓存**和**寄存器组**，空间很小，但速度很快\n5. 控制单元是一个**统一的指挥中心**，可以获得下一条指令，然后执行这条指令\n    - 这个指令会指导运算单元取出数据单元中的某几个数据，计算出结果，然后放在数据单元的某个地方\n\n### 计算过程\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-cal-process.jpg\" width=800/>\n1. 每个进程都有一个程序放在**硬盘**上，是**二进制**的，在里面存储的是一行一行的**指令**，这些指令会操作一些数据\n2. 进程开始运行，会有**独立**的内存空间，_**相互隔离但不连续**_\n    - 程序会分别加载到进程A和进程B的内存空间里面，形成各自的_**代码段**_\n3. 程序在运行过程中要操作的数据和产生的计算结果，都会放在**数据段**（内存）里\n4. 在CPU的**控制单元**里面，有一个**指令指针寄存器**，记录的是_**下一条指令在内存中的地址**_\n    - 控制单元会不停地将**代码段的指令**拿进来，先放入_**指令寄存器**_\n5. 指令的组成部分：_**做什么操作**_ + _**操作哪些数据**_\n    - 要执行指令，需要将第一部分交给**运算单元**，将第二部分交给**数据单元**\n6. 数据单元根据**数据的地址**，从**数据段**里读取数据到**数据寄存器**，最终会有指令将数据写回到**内存中的数据段**\n7. CPU里有两个寄存器，专门保存**当前处理进程**的**代码段起始地址**和**数据段起始地址**，图中的当前进程为进程A\n8. CPU和内存通过**总线**传输数据，总线上有两类数据\n    - _**地址总线**_（Address Bus）：地址数据，位数决定了**能访问的地址**有多广\n    - _**数据总线**_（Data Bus）：真正的数据，位数决定了**一次性能拿多少数据**\n\n## x86架构\n\n### 型号\n| 型号 | 总线位宽 | 地址位 | 寻址空间 |\n| ---- | ---- | ---- | ---- |\n| 8080 | 8 | 16 | 64K |\n| 8086 | 16 | 20 | 1M |\n| 8088 | 8 | 20 | 1M |\n| 80386 | 32 | 32 | 4G |\n\n### 8086的原理\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-8086.jpg\" width=800/>\n\n#### 通用寄存器\n1. 为了**暂存数据**，8086处理器内部有8个16位的**通用寄存器**，属于CPU内部的_**数据单元**_\n2. 分别是AX、BX、CX、DX、SP、BP、SI和DI\n3. 其中AX、BX、CX和DX可以分成两个8位的寄存器来使用，其中H就是High，L就是Low\n4. 这样，比较长的数据也能暂存，比较短的数据也能暂存\n\n#### 控制单元\n- IP寄存器（Instruction Pointer Register）即_**指令指针寄存器**_\n    - 指向**代码段**中**下一条指令的位置**\n    - CPU会根据**IP寄存器**不断地将指令从**内存的代码段**中，加载到CPU的**指令队列**中，然后交给**运算单元**去执行\n- _**切换进程**_\n    - 每个进程都分为**代码段**和**数据段**\n    - 为了指向不同进程的地址空间，有4个16位的**段寄存器**，分别是CS、DS、SS和ES\n- CS（Code Segment Register）是**代码段寄存器**，通过它可以找到代码在内存中的位置\n- DS（Data Segment Register）是**数据段寄存器**，通过它可以找到数据在内存中的位置\n- SS（Stack Segment Register）是**栈寄存器**，但凡与**函数调用**相关的操作，都与栈紧密相关\n    - A调用B，B调用C\n    - 当A调用B的时候，要执行B函数的逻辑，因而A运行的相关信息会被push到栈里\n    - 当B调用C的时候，同理，B运行的相关信息会被push到栈里，然后才运行C函数的逻辑\n    - 当C运行完毕后，先pop出来的是B，B接着调用C函数之后的指令运行下去\n    - B运行完毕后，再pop出来的是A，A接着运行，直至结束\n\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-8086-ss-function-call.jpg\" width=600/>\n\n#### 加载内存数据\n1. 如果需要加载内存中的数据，可以通过DS找到内存中的数据，加载到_**通用寄存器**_\n2. 对于一个段，有一个**起始地址**，而**段内**的具体位置，称为_**偏移量**_\n3. CS和DS都存放着一个_**段的起始地址**_\n    - 代码段的偏移量放在**IP寄存器**\n    - 数据段的偏移量放在**通用寄存器**\n4. CS和DS都是16位的（**起始地址**），IP寄存器和通用寄存器也都是16位的（**偏移量**），但8086的地址总线是20位的\n    - 凑20位：_**起始地址 << 4 + 偏移量**_\n5. 无论真正的内存有多大，对于只有20位地址总线的8086来说，能够区分的地址也就`2^20=1M`（寻址单位为**Byte**）\n    - 如果想访问1M+X的地方，在总线上超过20位的部分根本发不出去，最后访问的还是1M内的X位置\n6. 偏移量只有16位的，所以一个段的最大大小为`2^16=64K`\n7. 因此对于8086的CPU来说，最多只能访问1M的内存空间，还要分成多个段，每个段最大为64K\n\n## 32位处理器\n1. 在32位的CPU中，有32根地址总线，可以访问`2^32=4G`的内存\n2. x86架构是开放的，因此32位的CPU需要兼容原来的架构\n\n### 兼容\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-8086-32bit-compatible.jpg\" width=800/>\n1. 通用寄存器\n    - 将8个16位的通用寄存器扩展到8个32位的通用寄存器，但依然保留16位和8位的使用方式\n    - **高16位不能分成两个8位使用**，因为这是**不兼容**的\n2. IP寄存器\n    - 指向下一条指令的**指令指针寄存器**IP，会扩展成32位的，同样兼容16位\n3. 段寄存器（Segment Register）\n    - CS、DS、SS和ES仍然是16位，但**不再是段的起始地址**，段的起始地址放在内存的某个地方（**表格**）\n    - 表格中的一项是**段描述符**（Segment Descriptor），里面才是_**段真正的起始地址**_\n    - 而**段寄存器**里面保存的是这个表格中的某一项，称为**选择子**（Selector）\n    - 获取段起始地址的流程：先**间接**地从段寄存器中找到表格中的一项，再从表格中的一项拿到_**段真正的起始地址**_\n    - 为了快速拿到段的起始地址，段寄存器会从内存中拿到CPU的**描述符高速缓存器**中\n    - 这种模式与8086的模式不兼容，但**非常灵活**，可以_**保持未来的兼容性**_\n\n### 实模式 VS 保护模式\n1. 在32位的架构下，将前一种模式称为**实模式**（Real Pattern），后一种模式称为**保护模式**（Protected Pattern）\n2. 系统**刚刚启动**的时候，CPU处于**实模式**，此时和原来的模式是**兼容**的\n    - 即32位的CPU，也支持在原来的模式下运行，速度会快一点\n3. 当需要更多内存时，可以遵循一定的规则，进行一系列的操作，然后切换到**保护模式**，就能够用到32位CPU更强大的能力\n4. 如果不能无缝兼容，但**通过切换模式兼容**，也是**可以接受**的\n\n### 系统交互\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-8086-32bit-interaction.jpg\" width=800/>\n\n## 常用汇编指令\n```\nmov, call, jmp, int, ret, add, or, xor, shl, shr, push, pop, inc, dec, sub, cmp\n```\n\n<!-- indicate-the-source -->\n","tags":["Linux"],"categories":["Linux"]},{"title":"Linux -- 系统调用分类","url":"%2F2019%2F04%2F07%2Flinux-system-call-category%2F","content":"\n## 进程管理\n1. 在Linux里，创建一个新进程，需要老进程调用`fork`来实现\n2. 老进程叫作**父进程**（`Parent Process`），新进程叫作**子进程**（`Child Process`）\n3. 当父进程调用`fork`创建进程的时候，子进程将**各个子系统**为父进程创建的数据结构也**全部**拷贝一份（包括程序代码）\n    - 如果不进行特殊处理，父进程和子进程都按相同的代码逻辑进行下去\n4. `fork`系统调用的返回值\n    - 如果**当前进程**是**子进程**，就返回**0**\n    - 如果**当前进程**是**父进程**，返回_**子进程的进程号**_\n5. 依据`fork`的返回值执行不同的逻辑分支\n    - 如果是**父进程**，执行原始逻辑\n    - 如果是**子进程**，请求系统调用`execve`来执行另一个程序\n        - 至此，子进程和父进程就彻底**分道扬镳**了，产生了一个fork（分支）\n6. 操作系统在**启动**时会先创建**所有用户进程**的_**祖宗进程**_\n7. 父进程如果需要知道子进程的运行情况，\n    - 父进程可以请求系统调用`waitpid`，将**子进程的进程号**作为参数传给它\n    - 这样父进程就知道子进程是否运行成功\n\n<!-- more -->\n\n## 内存管理\n1. 在操作系统中，每个进程都有自己的内存，**互不干扰**，有_**独立的进程内存空间**_\n2. **代码段**（`Code Segment`）：存放_**程序代码**_\n3. **数据段**（`Data Segment`）：存放_**进程在运行过程中产生的数据**_\n    - 其中**局部变量**的部分，在当前函数执行的时候才起作用，当进入另一个函数时，局部变量就会被释放\n    - 也有**动态分配**的，会**较长时间保存**，指明才销毁的，这部分称为**堆**（`Heap`）\n4. 一个进程的内存空间是很大的，32位的是4G，但不可能有那么多的物理内存，到**真正需要**的时候再分配\n    - 进程自己不用的部分就不用管了，只有进程去使用部分内存的时候，才会使用**内存管理的系统调用**来登记\n    - 但这不代表真的就对应到了物理内存，只有在**真的写入数据**的时候，发现没有对应的物理内存\n        - 才会触发一个**中断**，_**现分配物理内存**_\n5. 在**堆里**分配内存的系统调用：`brk`和`mmap`\n    - 当分配的内存数量**比较小**的时候，使用`brk`，会**和原来的堆的数据连在一起**\n        - brk, sbrk - _**change data segment size**_\n    - 当分配到内存数量**比较大**的时候，使用`mmap`，会**重新划分一块区域**\n        - mmap, munmap - _**map or unmap files or devices into memory**_\n\n## 文件管理\n1. 系统调用\n    - 对于已经存在的文件，使用`open`打开这个文件，使用`close`关闭这个文件\n    - 对于不存在的文件，使用`create`创建文件\n    - 打开文件以后，使用`lseek`跳到文件的某个位置\n    - 可以对文件的内容进行读写，读的系统调用是`read`，写的系统调用是`write`\n2. _**一切皆文件**_\n    - 启动一个进程，需要一个程序文件，这是一个**二进制文件**\n    - 启动的时候，需要加载一些配置文件，例如yml、properties等，这是**文本文件**\n        - 启动之后会打印一些日志，如果写到硬盘上，也是**文本文件**\n        - 如果把日志打印到交互控制台上，也是一个文件，是**stdout文件**\n    - 这个进程的输出可以作为另一个进程的输入，这种方式称为**管道**，**管道也是一个文件**\n    - 进程之间可以通过网络进行进行通信，建立`Socket`，**`Socket`也是一个文件**\n    - 进程需要访问外部设备，**设备也是一个文件**\n    - 文件都被存储在文件夹里面，**文件夹也是一个文件**\n    - 进程运行起来，进程X的运行情况会在`/proc/${X}`目录体现出来，该目录下也是一系列的文件\n3. Linux会为**每个文件**分配一个**文件描述符**（`File Descriptor`，是一个**整数**）\n4. 文件操作是贯穿始终的，一切皆文件的优势：_**统一了操作的入口**_\n\n## 信号处理\n1. 常见信号\n    - 在执行一个程序的时候，在键盘上输入`CTRL+C`，这是**中断信号**，正在执行的命令就会中止退出\n    - 非法访问内存\n    - 硬件故障，设备出现了问题\n    - 用户进程通过`kill`函数，将一个用户信号发送给另一个进程\n2. 对于一些不严重的信号，可以忽略，但类似`SIGKILL`和`SIGSTOP`是不能忽略的，可以执行**信号的默认动作**\n    - 每种信号都定义了默认的动作，例如硬件故障，默认终止\n    - 也可以提供**信号处理函数**，通过请求系统调用`sigaction`，注册一个信号处理函数\n        - sigaction, rt_sigaction - _**examine and change a signal action**_\n\n## 进程间通信\n1. **消息队列**（`Message Queue`）\n    - 两个进程间交互的信息**较小**，这个消息队列在**内核**里\n    - `msgget`：创建一个新队列，_**get a System V message queue identifier**_\n    - `msgsnd`：将消息发送到消息队列，_**XSI message send operation**_\n    - `msgrcv`：消息接收方从队列中取数据，_**XSI message receive operation**_\n2. **共享内存**\n    - 两个进程间交互的信息**较大**\n    - `shmget`：创建一个共享内存块\n        - shmget - _**allocates a System V shared memory segment**_\n    - `shmat`：将共享内存**映射**到自己的进程内存空间，然后就可以进行**读写**了\n        - shmat — _**XSI shared memory attach operation**_\n    - 存在**竞争**问题，解决方案：_**信号量机制**_（`Semaphore`）\n        - 对于只允许一个进程访问的资源，可以将信号量设为1\n        - 当进程A要访问的时候，会先请求系统调用`sem_wait`，如果此时没有其他进程访问，则**占用**这个信号量\n        - 如果此时进程B要访问，也会调用`sem_wait`，进程B必须等待\n        - 当进程A访问完毕，会调用`sem_post`将信号量**释放**，进程B就可以访问这个资源了\n\n## 网络通信\n1. 不同机器通过网络相互通信，需要遵循相同的网络协议，即**TCP/IP网络协议栈**，Linux内核有对网络协议栈的实现\n2. 网络服务是通过套接字`Socket`来提供服务的，可以通过`Socket`系统调用来创建一个`Socket`\n3. `Socket`是一个**文件**，也有一个**文件描述符**，也可以通过**读写函数**进行通信\n\n## 系统调用定义\n路径：`linux-5.0.7/arch/sh/include/uapi/asm/unistd_64.h`\n```\n#define __NR_restart_syscall      0\n#define __NR_exit                 1\n#define __NR_fork                 2\n#define __NR_read                 3\n#define __NR_write                4\n#define __NR_open                 5\n#define __NR_close                6\n#define __NR_waitpid              7\n#define __NR_creat                8\n...\n```\n\n## glibc\n1. `glibc`是Linux下开源的标准C库，由`GNU`发布\n2. `glibc`提供了丰富的API\n    - 封装了例如字符串处理、数学运算等**用户态服务**\n    - 封装了操作系统提供的系统服务，即_**系统调用的封装**_\n3. 每个系统调用都对应至少一个`glibc`封装的库函数\n    - 打开文件系统调用，操作系统->`sys_open`，`glibc`->`open`\n4. `glibc`中一个单独的API可能会调用多个系统调用\n    - `glibc`提供的`printf`函数就会调用如`sys_open`、`sys_mmap`、`sys_write`和`sys_close`等系统调用\n5. 多个`glibc API`也可能只对应一个系统调用\n    - `glibc`的`malloc`、`calloc`和`free`等函数用来分配和释放内存，都调用了内核的`sys_brk`的系统调用\n\n## 小结\n<img src=\"https://linux-1253868755.cos.ap-guangzhou.myqcloud.com/linux-system-call.jpg\" width=800/>\n\n\n<!-- indicate-the-source -->\n","tags":["Linux"],"categories":["Linux"]},{"title":"Kafka -- 可靠性","url":"%2F2019%2F03%2F31%2Fkafka-reliability%2F","content":"\n## 可靠性保证\n1. 可靠性保证：确保系统在**各种不同的环境**下能够发生**一致**的行为\n2. Kafka的保证\n    - 保证_**分区消息的顺序**_\n        - 如果使用**同一个生产者**往**同一个分区**写入消息，而且消息B在消息A之后写入\n        - 那么Kafka可以保证消息B的偏移量比消息A的偏移量大，而且消费者会先读取消息A再读取消息B\n    - 只有当消息被写入分区的**所有同步副本**时（文件系统缓存），它才被认为是**已提交**\n        - 生产者可以选择接收不同类型的确认，控制参数`acks`\n    - 只要还有一个副本是活跃的，那么**已提交的消息就不会丢失**\n    - _**消费者只能读取已经提交的消息**_\n\n<!-- more -->\n\n## 复制\n1. Kafka可靠性保证的核心：_**复制机制**_ + _**分区的多副本架构**_\n2. 把消息写入**多个副本**，可以使Kafka在发生**崩溃**时仍能**保证消息的持久性**\n3. Kafka的主题被分成多个分区，分区是基本的数据块，分区存储在**单个磁盘**上\n4. Kafka可以保证分区里的事件总是**有序**的，分区可以**在线**（可用），也可以**离线**（不可用）\n5. 每个分区可以有多个副本，其中一个副本是首领副本\n    - 所有的事件都直接发送给首领副本，或者直接从首领副本读取事件\n    - 其他副本只需要与首领副本**保持同步**，并**及时复制最新的事件**即可\n    - 当首领副本不可用时，其中一个**同步副本**将成为新的首领\n6. _**分区首领是同步副本**_，对于跟随者副本来说，需要满足下列的**全部条件**才被认为是**同步**的\n    - 与**ZooKeeper**之间有一个**活跃的会话**（6S内的心跳）\n    - 在过去的10S内从首领副本那里获取过**最新的消息**（几乎**零延迟**）\n7. 一个不同步的副本通过与ZooKeeper重新建立连接，并从首领副本那里获取最新的消息，可以重新变成同步的\n    - 这个过程在网络出现临时问题时很快就能得到修复，但如果Broker发生崩溃就需要较长的时间\n8. 如果一个或多个副本在**同步**和**非同步**状态之间_**快速切换**_\n    - 说明集群内部出现了问题，通常是由于Java不恰当的**垃圾回收配置**导致的\n    - 不恰当的垃圾回收配置会造成几秒钟的停顿，从而导致Broker和ZooKeeper之间断开连接\n    - 最后变成不同步，进而发生状态切换\n9. 一个**滞后的同步副本**会导致生产者和消费者**变慢**\n    - 因为消息在被认为**已提交**之前，客户端会等待**所有同步副本**接收消息\n    - 如果一个副本不再同步了，那么我们将不再关心它是否已经接收到消息\n        - 因此，_**非同步副本不会对性能造成任何影响**_\n        - 但更少的同步副本意味着**更低的有效复制系数**，在发生宕机时**丢失数据**的风险就会变大\n\n## Broker配置\nBroker有3个配置参数会影响到Kafka消息存储的**可靠性**，可以应用于**Broker级别**（所有主题），也可以应用于**主题级别**\n\n### 复制系数\n1. 主题级别的配置参数为`replication.factor`，Broker级别的配置参数为`default.replication.factor`\n2. Kafka的默认复制系数为3，即使在主题创建后，仍然可以通过**新增**或**移除**副本来改变复制系数\n3. 如果复制系数为`N`，那么在`N-1`个Broker**失效**的情况下，仍然能够从主题**读取**数据或向主题**写入**数据\n    - 更高的复制系数可以带来_**更高的可用性、可靠性和更少的故障**_\n    - 但会占用_**更多的磁盘空间**_\n4. 主题的**复制系数**与主题的**重要程度**成**正相关**\n    - 在要求**可用性**的场景下，把复制系数设置为**3**，已经**足够安全**了，银行可能会使用5个副本\n5. 副本的**分布**也很重要\n    - Kafka会确保分区的每个副本被放在**不同**的Broker上\n    - 同时，为了避免**机架级别**的故障，建议把Broker分布在不同的机架上，控制参数为`broker.rack`\n\n### 不完全的首领选举\n1. `unclean.leader.election.enable`只能在**Broker级别**进行设置，默认值为false\n2. 当分区首领不可用时，一个**同步副本**会被选为新的分区首领\n    - 如果**选举过程中没有丢失数据**，即提交到旧首领的数据同时存在于所有的同步副本上，那么这个选举过程是**完全**的\n3. 在首领不可用时，其他副本**都不同步**的场景\n    - 分区有3个副本，其中两个跟随者**不可用**，这时如果生产者继续往首领写入数据，所有消息都会得到确认并被提交\n        - 因为首领是**唯一同步**的副本\n        - 如果首领也不可用了，恰巧之前的一个跟随者重新启动，该跟随者就成为分区的唯一不同步副本\n    - 分区有3个副本，因为网络问题导致两个跟随者**复制消息滞后**，尽管它们还在复制消息，但已经**不同步**了\n        - 首领作为**唯一同步**的副本继续接收消息\n        - 如果首领变为不可用，另外两个副本再也无法变成同步的了\n\n#### 两难选择\n1. 如果不同步的副本**不能**被提升为新首领，那么分区在旧首领恢复之前是**不可用**的，牺牲了可用性\n2. 如果不同步的副本**可以**被提升为新首领，那么这个副本变为不同步之后写入旧首领的消息会全部消失，导致**数据不一致**\n    - 假设在副本0和副本1不可用时，偏移量100~200的消息被写入副本2（首领）\n    - 现在副本2也变为不可用，而副本0变成了可用，副本0只包含0~100的消息，不包含偏移量100~200的消息\n    - 如果允许副本0成为新首领，生产者可以继续写入数据，消费者可以继续读取数据，保证了可用性\n        - 于是，新首领（副本0）就有了偏移量100~200的新消息\n    - 但是，部分消费者会读到100~200的**旧消息**，部分消费者会读到为100~200的**新消息**，部分消费者读到**两者的混合**\n3. 小结\n    - 如果**不允许**不同步的副本成为新首领，那么就要接受**较低的可用性**\n    - 如果**允许**不同步的副本成为新首领，就要承担**丢失数据**和出现**数据不一致**的风险\n\n### 最少同步副本\n1. `min.insync.replicas`，可以在**主题级别**和**Broker级别**上进行配置\n2. 尽管为一个主题配置了3个副本，但还是会出现**只有一个同步副本**的情况\n3. Kafka对**可靠性保证**的定义：消息只有被写入到**所有同步副本**之后才被认为是**已提交**的\n    - 如果**所有同步副本**只剩下一个，那么在这个副本变为**不可用**时，数据就会**丢失**\n4. 如果`min.insync.replicas=2`，那么_**至少要存在两个同步副本才能向分区写入数据**_\n    - 如果只有一个同步副本，那么Broker就会停止接受生产者的请求\n    - 此时Broker变成了**只读**\n        - 尝试发送数据的生产者会收到`NotEnoughReplicasException`异常\n        - 消费者仍然可以继续读取已有的数据\n    - 这是为了避免发生**不完全选举**时数据的写入和读取出现非预期的行为\n\n## 在可靠的系统里使用生产者\n\n### 反例\n\n#### 反例1\n1. 为Broker配置了**3个副本**，并且禁用了**不完全首领选举**\n2. 把生产者的`acks`设置为`1`（只要首领接收到消息就可以认为消息写入成功）\n3. 生产者发送一个消息给首领，首领成功写入，但跟随者副本还没有收到这个消息\n4. 首领向生产者发送一个响应，告诉生产者消息写入成功，然后首领崩溃了，此时消息还没有被其他副本复制过去\n    - 此时另外两个副本**仍然**被认为是**同步**的（判断一个副本不同步需要一小段时间）\n    - 其中一个副本成为了新的首领，因为消息还没有被写入这个副本，所以消息**丢失**了\n        - 但**生产者**却认为消息已经**成功写入**了\n5. 因为**消费者**看不到丢失的消息，所以此时的系统仍然是**一致**的（因为副本没有收到这个消息，所以消息不算已提交）\n    - 但从生产者角度来看，它丢失了一个消息\n\n#### 反例2\n1. 为Broker配置了**3个副本**，禁用了**不完全首领选举**，并且把生产者的`acks`设置为`all`\n2. 假设现在往Kafka发送给消息，分区的首领刚好崩溃，新的首领正在选举当中，Kafka会往生产者返回**首领不可用**的响应\n3. 此时，如果生产者没能正确处理这个错误，也没有重试发送消息直到发送成功，那么消息也有可能**丢失**\n4. 但这不能算是Broker的可靠性问题，因为Broker并没有收到这个消息\n5. 也不是一致性问题，因为消费者并没有读到这个消息\n\n#### 小结\n1. 根据**可靠性需求**配置恰当的`acks`值\n2. 在参数配置和代码里正确地处理错误\n\n### 发送确认\n1. `acks=0`：如果生产者能够通过网络把消息发送出去，那么就认为消息已经成功写入Kafka\n    - 如果**分区离线**或者**整个集群长时间不可用**，那么就**不会收到任何错误**\n    - 即使在完全首领选举的情况下，仍有可能丢失消息，因为在新首领选举过程中，生产者并不知道首领已经不可用了\n    - 在该模式下，运行速度是非常快的，可以得到惊人的**吞吐量**和**带宽利用率**，但会**丢失**一些数据\n2. `acks=1`：首领在收到消息并把它写入到分区数据文件（Linux文件系统缓存）时返回确认或错误响应\n    - 在该模式下，如果发生正常的首领选举，生产者会在选举时收到`LeaderNotAvailableException`异常\n    - 如果生产者能够恰当地处理该异常，那么它就会重试发送消息，最终消息会安全到达新首领\n    - 但仍有可能**丢失**数据，例如消息已经成功写入首领，但在消息被复制到跟随者副本之前首领发生崩溃\n3. `acks=all`：首领在返回确认或者错误响应之前，会等待**所有同步副本**都收到消息\n    - 如果和`min.insync.replicas`结合，就能决定在返回确认前至少有多少个副本能够收到消息\n    - 这是**最保险**的做法，生产者会**一直重试**直到消息被成功提交\n    - 但这也是**最慢**的做法，生产者在继续发送其他消息之前需要等待**所有副本**都收到当前的消息\n    - 可以通过使用**异步模式**和**更大的批次**来**加快速度**，但这样通常会**降低吞吐量**\n\n### 重试配置\n1. 生产者向Broker发送消息时，Broker可以返回一个**成功响应码**或者一个**错误响应码**\n2. 错误响应码分类：一种是可以通过重试解决，一种是无法通过重试解决\n    - 如果Broker返回的是`LeaderNotAvailableException`，生产者可以通过尝试重新发送消息来解决\n    - 如果Broker返回的是`InvalidConfigurationException`，即使通过重试也无法改变配置选项\n3. 如果目标是**不丢失任何消息**，最好让生产者遇到**可重试错误**时能够_**保持重试**_\n4. 重试发送一个已经失败的消息会带来一些风险，如果两个消息都写入成功，会导致_**消息重复**_\n    - 重试和恰当的错误处理可以保证每个消息**至少被保存一次**\n    - 目前的Kafka版本无法保证每个消息只被保存一次\n    - 现实中的很多应用程序在消息里加入**唯一标识符**，用于**检测重复消息**\n    - 另外还需要应用程序可以做到消息的**幂等**\n\n## 在可靠的系统里使用消费者\n1. 只有被提交到Kafka（已经被写入所有同步副本）的消息，对消费者才是可用的\n    - 对消费者而言，读取到的消息已经具备了**一致性**\n    - 消费者唯一要做的是要跟踪哪些消息已经读取过，哪些没有被读取过\n2. 从分区读取数据时，消费者会获取一批事件，检查这批事件里**最大的偏移量**，然后从这个偏移量开始读取另一批事件\n    - 这样保证消费者总能以**正确的顺序**获取新数据，不会错过任何事件\n3. 如果一个消费者退出，另一个消费者需要知道前一个消费者在**退出前**处理的**最后一个偏移量**是多少\n    - 因此消费者需要提交偏移量\n4. 消费者把当前读取的偏移量保存起来，在退出之后，同一个群组里的其他消费者就可以接手它的工作\n    - 如果消费者提交了偏移量却未能处理完消息，那么就可能会造成_**消息丢失**_\n5. 已提交消息 VS 已提交偏移量\n    - 已提交消息：已经被写入**所有同步副本**并且对消费者可见的消息\n    - 已提交偏移量：消费者发送给Kafka的偏移量，用于确认它已经**收到并处理好**的消息位置\n\n### 消费者的可靠性配置\n1. group.id\n    -  如果两个消费者具有相同的`group.id`，并且订阅了**同一个主题**，那么每个消费者会分到主题分区的一个_**子集**_\n2. auto.offset.reset\n    - 指定了在**没有偏移量可提交**时或者**请求的偏移量在Broker不存在**时，消费者的行为\n    - `earliest`：消费者会从分区的开始位置读取数据，不管偏移量是否有效\n        - 导致消费者读取大量的**重复**数据，但可以保证最少的数据丢失\n    - `latest`：消费者会从分区的末尾开始读取数据\n        - 可以减少重复处理消息，也有可能会错过一些消息\n3. enable.auto.commit\n    - 消费者基于任务调度自动提交偏移量\n    - 如果消费者在轮询操作里处理完所有的数据，那么自动提交可以保证_**只提交已经处理过的偏移量**_\n    - 自动提交的主要缺点\n        - 无法控制**重复处理消息**（比如消费者在自动提交偏移量之前停止处理消息）\n        - 如果把消息交给另一个后台线程去处理，自动提交机制可能会在消息还没处理完毕就提交偏移量\n4. auto.commit.interval.ms\n    - 默认是每5S提交一次，频繁提交会增加额外的开销，但也会降低重复处理消息的概率\n\n### 显式提交偏移量\n1. **总是在处理完事件后再提交偏移量**\n    - 如果所有的处理都在**轮询里**完成，并且不需要在**轮询之间**维护状态（例如为了实现聚合操作）\n    - 那么可以使用自动提交，或者在轮询结束后进行手动提交\n2. 提交频率是**性能**和**重复消息**之间的权衡\n    - 即使在最简单的场景里，仍然可以在一个循环里多次提交偏移量\n    - 也可以在每处理完一个事件之后，或者多个循环里只提交一次\n3. 确保对提交的偏移量心里有数\n    - 在轮询过程中提交偏移量有个不好的地方\n        - 就是提交的偏移量有可能是读取到的最新偏移量，而不是处理过的最新偏移量\n    - 因此，必须确保**处理完消息后再提交偏移量**，否则会导致消费者错过消息\n4. 再均衡\n    - 在设计应用程序时要注意处理消费者的再均衡问题\n    - 例如，一般要在分区被撤销之前提交偏移量，并在分配到新分区时清理之前的状态\n5. 消费者可能需要**重试**\n    - 场景：在进行轮询之后，有些消息没有被**完全处理**，需要稍候再来处理\n        - 例如要把Kafka的数据写到数据库里，不过在那个时间数据库恰好不可用，需要稍候再试\n    - _**提交的是偏移量，而不是对消息的确认**_\n        - 如果记录#30处理失败，但记录#31处理成功，那么就不应该提交#31\n        - 否则会导致#31以内的偏移量都被提交，包括#30\n    - 解决方案\n        - 方案1\n            - 在遇到可重试错误时，提交最后一个处理成功的偏移量，然后把还没有处理好的消息保存到缓存区里\n            - 调用消费者的`pause()`方法来确保其他的轮询不会返回数据，_**在保持轮询的同时尝试重新处理**_\n            - 如果重试成功，或者重试次数达到上限并决定放弃，那么把错误记录下来并丢弃消息\n            - 然后调用`resume()`方法让消费者继续从轮询里获取新数据\n        - 方案2\n            - 在遇到可重试错误时，把错误写入一个独立的主题，然后继续\n            - 一个独立的消费者群组负责从该主题上读取错误消息，并进行重试\n            - 该模式有点类似其他消息系统的`dead-letter-queue`\n6. 消费者可能需要维护状态\n    - 有时会希望在多个轮询之间维护状态\n        - 例如想计算消息的移动平均数，希望在首次轮询之后计算平均数，然后在后续的轮询中更新这个结果\n    - 提交偏移量的同时把最近计算的平均数写到一个结果的主题上\n    - 消费者线程在重新启动之后，就可以拿到最近的平均事并接着计算\n    - 由于Kafka并没有提供**事务支持**，消费者有可能写入平均数之后来不及提交偏移量就崩溃了\n7. 长时间处理\n    - 有时候处理数据需要很长时间\n    - 但是暂停轮询的时间不能超过几秒钟，即使不想获得更多的数据，也要**保持轮询**，这样客户端才能往Broker发送**心跳**\n    - 解决方案\n        - 使用一个线程池来处理数据，使用多个线程可以进行并行处理，从而加快处理速度\n        - 把数据移交给线程池去处理之后，就可以暂停消费者，然后**保持轮询**，但**不获取新数据**，直到处理完成\n        - 在工作线程处理完成之后，让消费者继续获取新数据\n        - _**消费者一直保持轮询，心跳会正常发送，就不会发生再均衡**_\n8. 仅一次传递\n    - 应用程序不仅仅需要**至少一次**（`at-least-once`，没有数据丢失）语义，还需要**仅一次**（`exactly-once`）语义\n    - 目前Kafka还不能完全支持仅一次语义，消费者采用其他办法来保证Kafka里的每个消息只被写到外部系统一次\n        - 但不会处理向Kafka**写入数据**时可能出现的重复数据\n    - 实现**仅一次**处理最简单且最常用的办法是把结果写到一个支持**唯一键**的系统里，比如键值存储引擎，关系型数据库等\n        - 这种情况下\n            - 要么**消息本身**包含一个唯一键\n            - 要么使用**主题、分区和偏移量**的组合来创建唯一键（唯一标识一个Kafka记录）\n        - 如果你把消息和一个唯一键写入系统，然后恰巧又读到一个相同的消息，只要把原先的键值覆盖掉即可\n        - 数据存储引擎会**覆盖**已经存在的键值对，就像没有出现过重复数据一样，这个模式叫作_**幂等性写入**_\n    - 如果写入消息的系统**支持事务**\n        - 最简单的是使用关系型数据库，把**消息**和**偏移量**放到**同一个事务**里，这样它们就能保持**同步**\n        - 在消费者启动时，会获取最近处理过的消息偏移量，然后调用`seek()`方法从该偏移量继续读取数据\n\n<!-- indicate-the-source -->\n","tags":["Stream"],"categories":["Kafka"]},{"title":"Kafka -- 内部原理","url":"%2F2019%2F03%2F26%2Fkafka-internal-principle%2F","content":"\n## 群组成员关系\n1. Kakfa使用ZooKeeper来维护集群成员的信息\n2. 每个Broker都有一个**唯一的ID**，这个ID可以在**配置文件**里面指定，也可以**自动生成**\n3. 在Broker启动的时候，通过创建**临时节点**把自己的ID注册到ZooKeeper\n4. Kakfa组件订阅ZooKeeper的`/brokers/ids`路径，当有Broker加入集群或者退出集群时，Kafka组件能获得**通知**\n5. 如果要启动另一个具有**相同ID**的Broker，会得到一个错误，这个Broker会尝试进行注册，但会失败\n6. 在Broker停机，出现网络分区或者长时间垃圾回收停顿时，Broker会从ZooKeeper上_**断开连接**_\n    - 此时，Broker在启动时创建的**临时节点**会从ZooKeeper上自动移除（ZooKeeper特性）\n    - 订阅Broker列表的Kafka组件会被告知该Broker已经被移除\n7. 在关闭Broker时，它对应的临时节点也会消失，不过它的ID会继续存在于其他数据结构中\n    - 例如，主题的副本列表里可能会包含这些ID\n8. 在完全关闭了一个Broker之后，如果使用**相同的ID**启动另一个全新的Broker\n    - 该Broker会立即加入集群，并拥有与旧Broker**相同**的**分区**和**主题**\n\n<!-- more -->\n\n```\n[zk: localhost:12181(CONNECTED) 5] ls /brokers/ids\n[1, 2, 3]\n[zk: localhost:12181(CONNECTED) 6] get /brokers/ids/1\n{\"listener_security_protocol_map\":{\"PLAINTEXT\":\"PLAINTEXT\"},\"endpoints\":[\"PLAINTEXT://kafka1:9092\"],\"jmx_port\":-1,\"host\":\"kafka1\",\"timestamp\":\"1553847899655\",\"port\":9092,\"version\":4}\ncZxid = 0x100000042\nctime = Fri Mar 29 16:24:59 CST 2019\nmZxid = 0x100000042\nmtime = Fri Mar 29 16:24:59 CST 2019\npZxid = 0x100000042\ncversion = 0\ndataVersion = 0\naclVersion = 0\nephemeralOwner = 0x200025dc7770001\ndataLength = 182\nnumChildren = 0\n```\n\n## 控制器\n1. 控制器其实就是一个Broker，除了具备普通Broker的一般功能之外，还负责_**分区首领的选举**_\n2. 集群里**第一个启动**的Broker通过在ZooKeeper里创建一个**临时节点**`/controller`让自己成为控制器\n    - 其他Broker在启动时也会尝试创建这个临时节点，但会收到**节点已经存在**的异常\n3. 其他Broker在`/controller`节点上创建`watch`对象，可以收到这个节点的变更通知\n    - 可以确保集群里在某一时刻只有一个控制器存在\n4. 如果控制器被关闭或者与ZooKeeper断开连接，ZooKeeper上的`/controller`节点就会消失\n    - 集群里的其他Broker通过`watch`对象会得到控制器节点消失的通知，并尝试让自己成为新的控制器\n    - 第一个在ZooKeeper里成功创建`/controller`节点的Broker就会成为新的控制器\n    - 其他Broker会收到**节点已存在**的异常，然后在新的`/controller`节点上创建`watch`对象\n    - 每个新选举出来的控制器通过ZooKeeper的**条件递增操作**获得一个**全新的且数值更大**的`controller epoch`\n    - 其他Broker知道当前`controller epoch`后，如果收到包含**较旧**`epoch`的消息，会直接忽略\n5. 当控制器发现一个普通Broker已经离开集群（观察ZooKeeper路径：`/brokers/ids`）\n    - 那些**失去首领的分区**需要一个**新的分区首领**（这些分区的首领恰好是这个Broker）\n    - 控制器遍历这些分区，并确定谁应该成为新首领（分区副本列表里的**下一个**副本）\n    - 然后向所有**包含新分区首领的Broker**或者**现有跟随者的Broker**发送请求\n        - 请求的内容包括：**谁是新的分区首领**，**谁是分区跟随者**\n        - 随后**新的分区首领**开始**处理来自生产者和消费者的请求**\n        - 而**跟随者**开始从**新的分区首领**那里**复制消息**\n6. 当控制器发现一个新的Broker加入集群时，它会使用`Broker ID`来检查新加入的Broker是否包含**现有分区的副本**\n    - 如果有，控制器就把变更通知发送给新加入的Broker和其他Broker\n    - 新Broker上的副本开始从分区首领那里复制消息\n7. 简而言之，Kakfa使用ZooKeeper的**临时节点**来选举控制器，并在Broker加入集群或者退出集群时通知控制器\n    - 控制器负责在Broker加入或离开集群时进行_**分区首领选举**_\n    - 控制器使用`epoch`来避免**脑裂**，脑裂指的是两个节点同时认为自己是当前的控制器\n\n```\n[zk: localhost:12181(CONNECTED) 10] get /controller\n{\"version\":1,\"brokerid\":1,\"timestamp\":\"1553847900310\"}\ncZxid = 0x100000046\nctime = Fri Mar 29 16:25:00 CST 2019\nmZxid = 0x100000046\nmtime = Fri Mar 29 16:25:00 CST 2019\npZxid = 0x100000046\ncversion = 0\ndataVersion = 0\naclVersion = 0\nephemeralOwner = 0x200025dc7770001\ndataLength = 54\nnumChildren = 0\n```\n\n## 复制\n1. 复制功能是Kafka架构的**核心**，在**个别节点**失效时仍能保证Kafka的**可用性**和**持久性**\n2. Kafka使用**主题**来组织数据，每个主题被分为若干个**分区**，每个分区有多个**副本**（主题 -> 分区 -> 副本）\n3. 每个Broker可以保存多个属于不同主题和不同分区的副本\n\n### 副本类型\n\n#### 首领副本\n1. 每个分区都有一个**首领副本**\n2. 为了保证**一致性**，所有**生产者请求**和**消费者请求**都会经过**首领副本**\n3. 首领的另一个任务：弄清楚哪个**跟随者的状态**与自己的状态是一致的\n4. 跟随者为了保持与首领的状态一致，在有新消息到达时尝试从首领那里**复制**消息，但也有可能同步失败\n    - 例如网络拥塞导致变慢，Broker发生崩溃导致复制滞后，直到重启Broker后复制才会继续\n\n#### 跟随者副本\n1. 跟随者副本：**首领副本以外的副本**\n2. 跟随者副本**不处理**来自客户端的请求\n    - 唯一的任务：从**首领副本**那里**复制**消息，保持与首领副本**状态一致**\n3. 如果首领副本发生崩溃，其中的一个跟随者副本就会被**晋升**为新的首领副本\n4. 跟随者为了与首领保持同步，跟随者向首领发送**获取数据**的请求\n    - 这种请求与**消费者为了读取消息而发送的请求**是一样的\n    - 请求消息里面包含了跟随者想要获取消息的**偏移量**（偏移量总是**有序**的）\n    - 首领将响应消息发送给跟随者\n5. 一个跟随者依次请求消息1、消息2和消息3，在收到这3个请求的响应之前，跟随者是不会发送第4个请求\n    - 如果跟随者请求了消息4，那么首领就会知道它已经收到了前面3个请求的响应\n6. _**通过查看每个跟随者请求的最新偏移量，首领就会知道每个跟随者复制的进度**_\n7. 跟随者会被首领认为**不同步**的情况\n    - 跟随者在10S内**没有请求任何消息**（_**可能死亡**_）\n    - 虽然跟随者在请求消息，但在10S内**没有请求到首领最新的数据**（_**滞后**_）\n8. 同步的跟随者：_**持续请求得到的最新消息**_\n    - 在首领发生失效时，只有同步的跟随者才有可能被选为**新首领**\n9. `replica.lag.time.max.ms`：正常的跟随者允许的不活跃时间，默认10S\n\n### 首选首领\n1. 除了**当前首领**之外，每个分区都有一个_**首选首领**_\n    - 首选首领：_创建主题时指定的首领_\n2. 默认情况下，`auto.leader.rebalance.enable=true`\n    - Kafka会检查首选首领是不是当前首领，如果不是并且该首选首领是**同步**的\n    - 那么就会触发**首领选举**，让首选首领成为当前首领\n3. 找到首选首领\n    - 从分区的副本清单里可以很容易找到首选首领，清单里的**第一个**副本一般就是首选首领\n        - 不管当前首领是哪一个副本，都不会改变这一事实\n    - 如果是手动进行副本分配，第一个指定的副本就是首选首领，_**要确保首选首领被传播到其他Broker**_\n        - 避免让包含了首选首领的Broker负载过重，而其他Broker却无法为它们分担负载\n\n## 处理请求\n\n### 概述\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/kafka-handle-request-procedure.png\" width=500/>\n\n1. Broker的大部分工作就是处理**客户端、分区副本和控制器**发送给**分区首领**的请求\n2. Kafka提供了一个**基于TCP的二进制协议**，指定了**请求消息的格式**以及Broker如何对请求做出响应\n    - 客户端发起连接并发送请求，Broker处理请求并做出响应\n3. Broker按照**请求到达的顺序**来处理它们\n    - 这种顺序保证让Kafka具有了消息队列的特性，同时保证保存的消息也是有序的\n4. 所有请求消息都包含一个**标准消息头**\n    - `Request type`（即 API Key）\n    - `Request version`（Broker可以处理不同版本的客户端请求，并依据客户端版本做出不同的响应）\n    - `Correlation ID`一个具有**唯一性**的数字，用于**标识请求消息**，同时也会出现在响应消息和错误日志里\n5. Broker会在它所监听的每一个端口上运行一个`Acceptor`线程\n    - 这个线程会创建一个**连接**，并把它交给`Processor`线程去处理\n    - `Processor`线程（网络线程）的数量是可配置的\n    - 网络线程负责从客户端获取请求消息，把它们放进**请求队列**，然后从**响应队列**获取响应消息，把它们发送给客户端\n6. 请求消息被放到请求队列后，IO线程会负责处理他们，主要的请求类型如下\n    - **生产请求**：生产者发送的请求，它包含客户端要写入Broker的消息\n    - **获取请求**：在**消费者**和**跟随者副本**需要从Broker读取消息时发送的请求\n7. 生产请求和获取请求都必须发送给分区的**首领副本**\n    - 如果Broker收到一个针对特定分区的请求，而该分区的首领副本在另一个Broker上\n        - 那么发送请求的客户端会收到一个**非分区首领**的错误响应\n    - 客户端要自己负责把**生产请求**和**获取请求**发送到正确的Broker上\n        - 客户端通过发送**元数据请求**来确定分区的首领副本在哪个Broker上\n\n### 生产请求\n1.  生产者配置参数`acks`：指定了需要多少个Broker确认才可以认为一个消息的写入是成功的\n    - `acks=1`：只要**分区首领**收到消息就认为写入成功\n    - `acks=all`：需要**所有同步的副本**收到消息才算写入成功\n    - `acks=0`：生产者把消息发出去之后，完全不需要等待Broker的响应\n2. 包含首领副本的Broker在收到生产请求时，会做一些验证动作\n    - 发送数据的用户是否有对主题的**写入权限**\n    - 请求里包含的acks值是否有效（0、1或all）\n    - 如果`acks=all`，判断是否有足够多的同步副本保证消息已经被安全写入\n3. 随后，消息会被写入**本地磁盘**\n    - 在`Linux`系统上，消息会被写到**文件系统缓存**里，并不保证它们何时会被刷新到磁盘上\n    - Kafka不会一直等待数据被写到磁盘上（Kafka依赖**复制功能**来保证消息的**持久性**）\n4. 在消息被**写入分区首领之后**，Broker开始检查`acks`的配置参数\n    - 如果`acks`被设为0或者1，Broker立即返回响应\n    - 如果`acks`被设为all，那么请求会被保存在一个叫做**炼狱**的**缓冲区**里\n        - 直到分区首领发现**所有跟随者副本**都复制了消息，响应才会被返回给客户端\n\n### 获取请求\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/kafka-consume-min-size.png\" width=600/>\n\n1. 客户端发送获取请求，向Broker请求主题分区里具有**特定偏移量**的消息\n2. 获取请求需要先到达指定的**分区首领**上，然后客户端通过**查询元数据**来确保请求的路由是正确的\n3. 分区首领在收到获取请求时，分区首领首先会检查获取请求是否有效（例如指定的偏移量在分区上是否存在）\n4. 如果请求的偏移量存在，Broker将按照**客户端指定的数量上限**从分区里读取消息，再把消息返回给客户端\n5. 客户端除了可以设置Broker返回数据的上限外，还可以设置**下限**\n    - 如果把下限设置为10KB，相当于告诉Broker：等到有10KB数据的时候再把他们发送给我\n    - 在主题消息的流量不是很大的情况下，可以减少**CPU开销**和**网络开销**\n    - Kafka也不会让客户端一直等待Broker积累数据\n        - 客户端定义一个**超时时间**，告诉Broker：如果无法在X毫秒内积累满足要求的数据量，就把当前数据返回给我\n\n#### 零复制\n1. Kafka使用**零复制**技术向客户端发送消息\n2. Kafka直接把消息从**Linux文件系统缓存**里发送到**网络通道**，而不需要经过任何中间缓冲区\n    - 这是Kafka与其他大部分数据库系统不一样的地方\n    - 其他数据库在将数据发送给客户端之前会先把它们保存在本地缓存里\n4. 这项技术**避免了字节复制**，**不需要管理内存缓冲区**，从而获得**更好的性能**\n\n#### 高水位\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/kafka-consume-isr.png\" width=600/>\n\n1. 并不是所有保存在**分区首领**上的数据都可以被客户端读取\n2. 分区首领知道每个消息会被复制到哪个副本上，_**在消息还没有被写入所有同步副本之前，是不会发送给消费者的**_\n    - 尝试获取这些消息的请求会得到**空响应**而不是错误\n3. 还没有被足够多的副本复制的消息被认为是**不安全**的\n    - 如果分区首领发生崩溃，另一个跟随者副本成为新首领，那么有些消息就可能会_**丢失**_\n    - 如果允许消费者读取这些消息，可能会_**破坏一致性**_\n    - 一个消费者读取并处理了这样的一个消息，但另外一个消费者发现这个消息其实并不存在\n    - 所以会等到**所有同步副本**复制了这些消息，才允许消费者读取它们\n    - 这就意味着，如果Broker间的**消息复制**因为某些原因变慢了\n        - 那么消息到达消费者的时间就会随之变长（因为需要先等待消息复制完毕）\n    - 参数`replica.lag.time.max.ms`，默认值为10S\n        - 指定了副本在复制消息时可被允许的最大延时时间\n        - 如果超过了该时间，跟随者会被分区首领认为是**不同步**的，会被移出`ISR`\n4. 消费者只能看到已经复制到`ISR`(in-sync replica)的消息\n\n### 元数据请求\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/kafka-client-route.png\" width=500/>\n\n1. 元数据请求包含了客户端感兴趣的**主题列表**\n2. 服务端的响应消息包含：这些主题所包含的分区，每个分区都有哪些副本，以及哪个分区副本是首领\n3. 元数据请求可以发送给任意一个Broker，因为所有的Broker都缓存了这些信息\n4. 一般情况下，客户端会把这些信息缓存起来，并直接往目标Broker发送生产请求和获取请求\n5. 客户端需要不定时通过元数据请求刷新这些信息，刷新间隔由参数`metadata.max.age.ms`（默认为5分钟）控制\n6. 如果客户端收到**非分区首领**的错误，客户端会在尝试重新发送请求之前先刷新元数据\n\n### 其他请求\n1. 客户端在网络上使用的是**通用二进制协议**\n    - Kakfa内置了Java客户端，但也有其他语言实现的客户端，如C，Python和Go\n    - 这些客户端就是使用这个二进制协议与Broker通信的\n2. Broker之间也使用同样的通信协议，它们之间的请求发生在Kafka内部，客户端不应该使用这些请求\n    - 例如当一个新分区首领被选举出来，控制器会发送`LeaderAndIsr`请求给新分区首领和跟随者\n    - 新分区首领：可以开始接收和处理来自客户端的请求\n    - 跟随者：开始跟随新分区首领\n3. 协议在持续演化\n    - 随着客户端功能的不断增加，需要改进协议来满足需求\n    - 修改已有请求类型来增加新功能\n\n## 物理存储\n1. Kafka的**基本存储单元**是**分区**\n    - _**一个分区只能属于一个Broker**_\n    - _**一个分区只能属于一个磁盘**_\n2. 因此，分区的大小受到**单个挂载点可用空间**的限制，一个挂载点由单个磁盘或多个磁盘组成\n3. 在配置Kafka时，`log.dirs`指定了一个用于存储分区的目录列表\n\n### 分区分配\n\n#### Broker间分配分区\n1. 假设有6个Broker，打算创建一个包含10个分区的主题，并且复制系数为3，那么Kafka就会有30个分区副本\n2. 在进行分区分配的时候，要达到如下目标\n    - 在Broker间**平均分布**分区副本，保证每个Broker可以分到5个副本\n    - **每个分区的每个副本分布到不同的Broker上**\n        - 假设分区0的首领副本在Broker 2上\n        - 那么可以把跟随者副本放在Broker 3和Broker 4上\n        - 但不能放在Broker 2上，也不能两个都放在Broker 3上\n    - 如果Broker指定了机架信息，那么尽可能把每个分区的副本分配到不同机架的Broker上\n        - 保证在一个机架不可用时不会导致整体的分区不可用\n3. 分配策略\n    - 先**随机选择**一个Broker（假设是4），然后使用**轮询**的方式给每个Broker分配分区来确定**分区首领**的位置\n        - 分区0的首领副本会在Broker 4，分区1的首领副本会在Broker 5，分区2的首领副本会在Broker 0，以此类推\n    - 然后从分区首领开始，依次分配**跟随者副本**\n        - 如果分区0的首领在Broker 4，那么它的第一个跟随者会在Broker 5，第二个跟随者会在Broker 0\n        - 如果分区1的首领在Broker 5，那么它的第一个跟随者会在Broker 0，第二个跟随者会在Broker 1\n    - 如果设置了机架信息，那就不是按照数字顺序来选择Broker，而是按照**交替机架**的方式来选择Broker\n        - 假设Broker 0~2放置在同一个机架上，Broker 3~5放置在另一个机架上\n        - 不是按照0~5的顺序来选择Broker，而是按照0、3、1、4、2、5的顺序选择\n        - 这样每个相邻的Broker都在不同的机架上\n        - 在机架下线时依然能保证**可用性**\n\n#### Broker内分配分区\n1. 为分区首领和跟随者副本选好的Broker后，接下来需要决定这些分区使用哪个目录（`log.dirs`）\n2. _**一个分区只能属于某一个目录**_\n3. 规则：计算每个目录里的**分区数量**，新的分区总是被添加到**数量最少**的那个目录里\n\n#### 小结\n1. 在Broker间分配分区时并没有考虑**可用空间**和**工作负载**的问题\n2. 在为分区分配到磁盘上时会考虑**分区数量**，但也不会考虑**分区大小**\n\n### 文件管理\n1. Kafka的一个基本特性：**保留数据**\n2. Kafka不会一直保留数据，也不会等到所有消费者都读取消息之后才删除消息\n3. Kafka为每个主题配置了数据保留期限\n    - 数据被删除之前可以保留多长**时间**\n    - 清理数据之前可以保留数据量的**大小**\n4. 由于在一个大文件里查找和删除消息是很费时间的，也很容易出错，因此把分区分成若干个**片段**\n    - 默认情况下，每个片段包含**1GB**或**一周**的数据，以**较小**的那个为准\n    - 在Broker往分区写入数据时，如果达到片段上限，就关闭当前文件，并打开一个新文件\n    - 当前**正在写入数据的片段**叫作**活跃片段**，_**活跃片段永远不会被删除**_\n        - 如果你要保留1天数据，但活跃片段里包含5天的数据，那么这些数据会被保留5天\n        - 因为在片段被关闭之前这些数据是无法被删除的\n5. Broker会为分区里的**每个片段**打开一个**文件句柄**，哪怕片段时不活跃的\n    - 这样会导致打开过多的文件句柄，操作系统必须根据实际情况做一些调优\n\n### 文件格式\n1. Kafka的**消息**和**偏移量**保存在文件中\n2. _**磁盘上的数据格式 == 生产者发送过来的消息格式 == 发送给消费者的消息格式**_\n    - Kafka可以使用**零复制**技术给消费者发送消息\n    - 避免了对生产者已经压缩过的消息进行**解压**和**再压缩**\n3. 消息里还包含了**消息大小**、**校验和**、**消息格式版本号**、**压缩算法**（`Snappy`、`GZip`和`LZ4`）和**时间戳**\n    - 时间戳可以是生产者发送消息的时间，也可以是消息到达Broker的时间，可配置的\n4. 可以用`DumpLogSegments`工具来查看日志片段的内容\n\n```\n$ kafka-run-class kafka.tools.DumpLogSegments --files 00000000000000000000.log\nDumping 00000000000000000000.log\nStarting offset: 0\nbaseOffset: 0 lastOffset: 0 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 0 CreateTime: 1553172809994 isvalid: true size: 98 magic: 2 compresscodec: NONE crc: 898077232\nbaseOffset: 1 lastOffset: 2 count: 2 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 98 CreateTime: 1553172813953 isvalid: true size: 76 magic: 2 compresscodec: NONE crc: 4107488416\nbaseOffset: 3 lastOffset: 3 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 174 CreateTime: 1553172817170 isvalid: true size: 79 magic: 2 compresscodec: NONE crc: 1335719899\nbaseOffset: 4 lastOffset: 4 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 253 CreateTime: 1553172846668 isvalid: true size: 69 magic: 2 compresscodec: NONE crc: 4157562046\nbaseOffset: 5 lastOffset: 5 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 322 CreateTime: 1553172857356 isvalid: true size: 79 magic: 2 compresscodec: NONE crc: 3694331330\nbaseOffset: 6 lastOffset: 6 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 401 CreateTime: 1553219688039 isvalid: true size: 73 magic: 2 compresscodec: NONE crc: 3459522042\nbaseOffset: 7 lastOffset: 7 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 474 CreateTime: 1553219691963 isvalid: true size: 80 magic: 2 compresscodec: NONE crc: 2634324074\nbaseOffset: 8 lastOffset: 8 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 554 CreateTime: 1553219762539 isvalid: true size: 71 magic: 2 compresscodec: NONE crc: 950257936\nbaseOffset: 9 lastOffset: 9 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 625 CreateTime: 1553429752873 isvalid: true size: 92 magic: 2 compresscodec: NONE crc: 1719404601\nbaseOffset: 10 lastOffset: 10 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 717 CreateTime: 1553435686204 isvalid: true size: 92 magic: 2 compresscodec: NONE crc: 1667790229\nbaseOffset: 11 lastOffset: 11 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false position: 809 CreateTime: 1553435686355 isvalid: true size: 92 magic: 2 compresscodec: NONE crc: 1615137336\n```\n\n#### 消息压缩\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/kafka-compressed-message.png\" width=800/>\n\n1. 如果生产者发送的是**压缩过**的消息，那么**同一批次**的消息会被压缩在一起，然后被当做**包装消息**进行发送\n    - Broker收到这样的消息后，会直接把它发送给消费者\n2. 消费者在解压这个消息后，会看到**整个批次**的消息，它们都有自己的时间戳和偏移量\n3. 如果**生产者**使用了**压缩功能**（**极力推荐**）\n    - _**如果发送的批次越大，那么在网络传输和磁盘存储方面会获得越好的压缩性能**_\n    - 同时意味着如果修改了消费者使用的消息格式，那么网络传输和磁盘存储的格式也要随之修改\n        - 而且Broker要知道如何处理包含这两种消息格式的文件\n\n### 索引\n1. 消费者可以从Kafka的**任意可用偏移量位置**开始读取消息\n2. 假设消费者要读取从偏移量100开始的1MB消息\n    - 那么Broker必须**立即定位**到偏移量100（可以是分区的任意一个片段），然后从这个位置读取消息\n3. 为了帮助Broker**快速地定位**到指定的偏移量，_**Kafka为每个分区维护了一个索引**_\n    - _**索引结构：偏移量 -> 日志片段名（file） + 偏移量在日志片段中的位置（pos）**_\n4. 索引也被分成**片段**，在**删除消息**时，也可以**删除相应的索引**\n5. **Kafka不维护索引的校验和**\n    - 如果索引出现损坏，Kafka会通过**重新读取消息并生成索引**，因此**删除索引**是**绝对安全**的\n\n### 清理\n1. 一般情况下，Kafka会根据设置的时间保留数据，把超过时效的旧数据删除\n2. 早于保留时间的旧事件会被删除，**为每个键保留最新的值**，从而达到清理的效果\n\n#### 工作原理\n1. 每个日志片段都可以分为以下两部分\n    - **干净的部分**：这些消息之前被清理过，**每个键只有一个对应的值**，这个值是上一次清理时保留下来的\n    - **污浊的部分**：这些消息是在上一次清理**之后**写入的\n2. 如果Kafka在启动时启用了清理功能（`log.cleaner.enable=true`）\n    - 每个Broker会启动**一个清理管理线程**和**多个清理线程**，它们负责执行清理任务\n    - 这些线程会优先选择**污浊率较高**（污浊消息占分区总大小的比例）的分区进行清理\n3. 为了清理分区，清理线程会读取分区的**污浊部分**，并在内存里创建一个**map**\n    - map里的每个元素包含了**消息键的散列值**和**消息的偏移量**，即`<hash(key),offset>`\n    - 消息键的散列值为**16 Bytes**，消息的偏移量为**8 Bytes**\n    - 如果要清理一个1GB的日志片段，并假设每个消息为1KB，那么这个日志片段包含100W个消息\n        - 但最多只需要24MB就可以清理这个片段（在键的散列值不重复的情况）\n4. 在配置Kafka时可以对map使用的内存大小进行配置\n    - 每个清理线程都有自己的map，而上面的这个参数指定的是**所有清理线程**可使用的内存总大小\n    - 如果为map分配了1GB的内存，并使用5个清理线程，每个线程可以使用200MB内存来创建自己的map\n5. Kafka不要求分区的整个污浊部分来适应这个map的大小，但要求**至少一个完整的日志片段**必须符合\n    - 如果不符合，那么Kafka就会报错，要么分配更多的内存，要么减少清理线程的数量\n6. 如果只有少部分片段完全符合，Kafka将从**最旧**的片段开始清理，等待下一次再清理剩余的部分\n\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/kafka-clean-log-before-after.png\" width=400/>\n\n\n#### 删除事件\n1. 为了**彻底**把一个键从系统里删除，客户端必须发送一个包含该键且**值为null**的消息\n2. 清理线程发现该消息时，会先进行常规的清理，只保留值为null的消息\n3. 该消息（**墓碑消息**）会被保留一段时间（可配置）\n    - 在这期间，消费者可以看到这个墓碑消息，并且发现它的值已经被删除了\n    - 这段时间过后，清理线程会移除这个墓碑信息，这个键也将从Kafka分区里消失\n    - 重要的是要留给消费者足够多的时间，让它们能够看到墓碑消息\n\n<!-- indicate-the-source -->\n","tags":["Stream"],"categories":["Kafka"]},{"title":"Kafka -- Docker + Schema Registry","url":"%2F2019%2F03%2F26%2Fkafka-docker-schema-registry%2F","content":"\n## Avro\n1. Avro的数据文件里包含了**整个Schema**\n2. 如果每条Kafka记录都嵌入了`Schema`，会让记录的大小**成倍地增加**\n3. 在读取记录时，仍然需要读到**整个Schema**，所以需要先找到`Schema`\n4. 可以采用**通用的结构模式**并使用**Schema注册表**的方案\n    - 开源的`Schema`注册表实现：`Confluent Schema Registry`\n\n<!-- more -->\n\n## Confluent Schema Registry\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/kafka-confluent-schema-registry.png\" width=500/>\n\n1. 把所有**写入数据**需要用到的`Schema`保存在**注册表**里，然后在_**记录里引用Schema ID**_\n2. 负责读数据的应用程序使用`Schema ID`从注册表拉取`Schema`来**反序列化**记录\n3. 序列化器和反序列化器分别负责处理Schema的**注册**和**拉取**\n\n### Confluent Schema Registry\n```bash\n# Start Zookeeper and expose port 2181 for use by the host machine\n$ docker run -d --name zookeeper -p 2181:2181 confluent/zookeeper\n\n# Start Kafka and expose port 9092 for use by the host machine\n$ docker run -d --name kafka -p 9092:9092 --link zookeeper:zookeeper confluent/kafka\n\n# Start Schema Registry and expose port 8081 for use by the host machine\n$ docker run -d --name schema-registry -p 8081:8081 --link zookeeper:zookeeper \\\n    --link kafka:kafka confluent/schema-registry\n\n# Start REST Proxy and expose port 8082 for use by the host machine\n$ docker run -d --name rest-proxy -p 8082:8082 --link zookeeper:zookeeper \\\n    --link kafka:kafka --link schema-registry:schema-registry confluent/rest-proxy\n\n$ docker ps\nCONTAINER ID        IMAGE                       COMMAND                  CREATED             STATUS              PORTS                                        NAMES\n38e5a908c954        confluent/rest-proxy        \"/usr/local/bin/rest…\"   4 hours ago         Up 4 hours          0.0.0.0:8082->8082/tcp                       rest-proxy\na6110eab7a84        confluent/schema-registry   \"/usr/local/bin/sche…\"   4 hours ago         Up 4 hours          0.0.0.0:8081->8081/tcp                       schema-registry\nc33c9268e4da        confluent/kafka             \"/usr/local/bin/kafk…\"   4 hours ago         Up 4 hours          0.0.0.0:9092->9092/tcp                       kafka\nbe6f2a3b6a2c        confluent/zookeeper         \"/usr/local/bin/zk-d…\"   4 hours ago         Up 4 hours          2888/tcp, 0.0.0.0:2181->2181/tcp, 3888/tcp   zookeeper\n```\n\n## 注册Schema\n\n### user.json\n```json\n{\n    \"type\": \"record\",\n    \"name\": \"User\",\n    \"fields\": [\n        {\"name\": \"id\", \"type\": \"int\"},\n        {\"name\": \"name\",  \"type\": \"string\"},\n        {\"name\": \"age\", \"type\": \"int\"}\n    ]\n}\n```\n\n### 注册\n```bash\n$ curl -X POST -H \"Content-Type: application/vnd.schemaregistry.v1+json\" \\\n--data '{\"schema\": \"{\\\"type\\\": \\\"record\\\", \\\"name\\\": \\\"User\\\", \\\"fields\\\": [{\\\"name\\\": \\\"id\\\", \\\"type\\\": \\\"int\\\"}, {\\\"name\\\": \\\"name\\\",  \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"age\\\", \\\"type\\\": \\\"int\\\"}]}\"}' \\\nhttp://localhost:8081/subjects/zhongmingmao/versions\n{\"id\":1}\n\n$ curl http://localhost:8081/subjects/zhongmingmao/versions\n[1]\n```\n\n## ConfluentProducer\n```java\nprivate static final String TOPIC = \"zhongmingmao\";\nprivate static final String USER_SCHEMA = \"{\\\"type\\\": \\\"record\\\", \\\"name\\\": \\\"User\\\", \" +\n        \"\\\"fields\\\": [{\\\"name\\\": \\\"id\\\", \\\"type\\\": \\\"int\\\"}, \" +\n        \"{\\\"name\\\": \\\"name\\\",  \\\"type\\\": \\\"string\\\"}, {\\\"name\\\": \\\"age\\\", \\\"type\\\": \\\"int\\\"}]}\";\n\npublic static void main(String[] args) throws Exception {\n    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    // 使用Confluent实现的KafkaAvroSerializer\n    props.put(\"key.serializer\", KafkaAvroSerializer.class.getName());\n    props.put(\"value.serializer\", KafkaAvroSerializer.class.getName());\n    // 添加Schema服务的地址，用于获取Schema\n    props.put(\"schema.registry.url\", \"http://localhost:8081\");\n\n    // 因为没有使用Avro生成的对象，因此需要提供Avro Schema\n    Schema.Parser parser = new Schema.Parser();\n    Schema schema = parser.parse(USER_SCHEMA);\n\n    // 对象类型为Avro GenericRecord\n    Producer<String, GenericRecord> producer = new KafkaProducer<>(props);\n\n    Random rand = new Random();\n    int id = 0;\n\n    try {\n        while (id < 100) {\n            id++;\n            String name = \"name\" + id;\n            int age = rand.nextInt(40) + 1;\n            // ProducerRecord.value是GenericRecord类型，包含了Schema和数据\n            // 序列化器知道如何从记录获取Schema，把它保存到注册表里，并用它序列化对象数据\n            GenericRecord user = new GenericData.Record(schema);\n            user.put(\"id\", id);\n            user.put(\"name\", name);\n            user.put(\"age\", age);\n\n            ProducerRecord<String, GenericRecord> record = new ProducerRecord<>(TOPIC, user);\n            producer.send(record);\n            TimeUnit.SECONDS.sleep(1);\n        }\n    } finally {\n        producer.close();\n    }\n}\n```\n\n## ConfluentConsumer\n```java\nprivate static final String TOPIC = \"zhongmingmao\";\nprivate static final String GROUP_ID = \"zhongmingmao\";\n\npublic static void main(String[] args) {\n    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"group.id\", GROUP_ID);\n    // 使用Confluent实现的KafkaAvroDeserializer\n    props.put(\"key.deserializer\", KafkaAvroDeserializer.class.getName());\n    props.put(\"value.deserializer\", KafkaAvroDeserializer.class.getName());\n    // 添加Schema服务的地址，用于获取Schema\n    props.put(\"schema.registry.url\", \"http://localhost:8081\");\n    Consumer<String, GenericRecord> consumer = new KafkaConsumer<>(props);\n\n    consumer.subscribe(Collections.singletonList(TOPIC));\n    try {\n        while (true) {\n            ConsumerRecords<String, GenericRecord> records = consumer.poll(100);\n            for (ConsumerRecord<String, GenericRecord> record : records) {\n                GenericRecord user = record.value();\n                log.info(\"value=[id={}, name={}, age={}], partition={}, offset={}\",\n                        user.get(\"id\"), user.get(\"name\"), user.get(\"age\"), record.partition(), record.offset());\n            }\n        }\n    } finally {\n        consumer.close();\n    }\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["Docker"],"categories":["Kafka"]},{"title":"MySQL -- 自增ID耗尽","url":"%2F2019%2F03%2F19%2Fmysql-self-increase-id-run-out%2F","content":"\n## 显示定义ID\n表定义的自增值ID达到上限后，在申请下一个ID时，得到的值保持不变\n```sql\n-- (2^32-1) = 4,294,967,295\n-- 建议使用 BIGINT UNSIGNED\nCREATE TABLE t (id INT UNSIGNED AUTO_INCREMENT PRIMARY KEY) AUTO_INCREMENT=4294967295;\nINSERT INTO t VALUES (null);\n\n-- AUTO_INCREMENT没有改变\nmysql> SHOW CREATE TABLE t;\n+-------+------------------------------------------------------+\n| Table | Create Table                                         |\n+-------+------------------------------------------------------+\n| t     | CREATE TABLE `t` (\n  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=4294967295 DEFAULT CHARSET=utf8 |\n+-------+------------------------------------------------------+\n\nmysql> INSERT INTO t VALUES (null);\nERROR 1062 (23000): Duplicate entry '4294967295' for key 'PRIMARY'\n```\n\n<!-- more -->\n\n## InnoDB row_id\n1. 如果创建的InnoDB表没有指定主键，那么InnoDB会创建一个不可见的，长度为**6 Bytes**的`row_id`\n2. InnoDB维护一个全局的`dict_sys.row_id`值，**所有无主键的InnoDB表**，每插入一行数据\n    - 都将当前的`dict_sys.row_id`值作为要插入数据的`row_id`，然后把`dict_sys.row_id`的值+1\n3. 代码实现上，row_id是一个`8 Bytes`的`BIGINT UNSIGNED`\n    - 但InnoDB设计时，给`row_id`只保留了`6 Bytes`的空间，写到数据表时只会存放最后的`6 Bytes`\n    - `row_id`的取值范围：`0 ~ 2^48-1`\n    - 达到上限后，下一个值就是0\n4. 在InnoDB里面，申请到`row_id=N`后，就将这行数据写入表中\n    - 如果表中已经有`row_id=N`的行，新写入的行就会**覆盖**原有的行\n5. 推荐**显示创建**自增主键\n    - 表自增ID达到上限后，再插入数据时会报**主键冲突**的错误，影响的是_**可用性**_\n    - 而覆盖数据，意味着**数据丢失**，影响的是_**可靠性**_\n    - 一般来说，_**可靠性优于可用性**_\n\n## XID\n1. `redolog`和`binlog`相配合的时候，有一个共同的字段`XID`，_**对应一个事务**_\n2. 生成逻辑\n    - MySQL内部维护一个全局变量`global_query_id`\n    - 每次执行语句的时候将`global_query_id`赋值给`Query_id`，然后`global_query_id`+1\n    - 如果当前语句是这个**事务执行的第一条语句**，把`Query_id`赋值给这个事务的`XID`\n3. `global_query_id`是一个**纯内存变量**，**重启之后清零**\n    - 因此，在同一个数据库实例中，**不同事务的`XID`也有可能是相同的**\n    - MySQL**重启**之后，会**重新生成新的`binlog`**\n        - 保证：_**同一个binlog文件里，XID是唯一的**_\n    - `global_query_id`达到上限后，就会继续从**0**开始计数\n        - 因此**理论**上，同一个`binlog`还是会出现相同的`XID`，只是**概率极低**\n4. `global_query_id`是`8 Bytes`，上限为`2^64-1`\n    - 执行一个事务，假设`XID`是A\n    - 接下来执行`2^64`次查询语句，让`global_query_id`回到A\n    - 再启动一个事务，这个事务的`XID`也是A\n\n## InnoDB trx_id\n1. `XID`是由**Server层**维护的\n2. InnoDB内部使用的是`trx_id`，为的是能够在**InnoDB事务**和**Server层**之间做关联\n3. InnoDB内部维护一个`max_trx_id`的**全局变量**\n    - 每次需要申请一个新的`trx_id`，就获得`max_trx_id`的当前值，然后`max_trx_id`+1\n4. InnoDB**数据可见性**的核心思想\n    - 每一行数据都记录了更新它的`trx_id`\n    - 当一个事务读到一行数据的时候，判断数据可见性的方法\n        - 事务的**一致性视图**和这行数据的`trx_id`做对比\n5. 对于正在执行的事务，可以通过`information_schema.innodb_trx`看到事务的`trx_id`\n\n### 操作序列\n| 时刻 | session A | session B |\n| ---- | ---- | ---- |\n| T1 | BEGIN;<br/>SELECT * FROM t LIMIT 1; | |\n| T2 | | USE information_schema;<br/>SELECT trx_id,trx_mysql_thread_id FROM innodb_trx; |\n| T3 | INSERT INTO t VALUES (null); | |\n| T4 | | SELECT trx_id,trx_mysql_thread_id FROM innodb_trx; |\n\n```sql\n-- T2时刻\nmysql> SELECT trx_id,trx_mysql_thread_id FROM innodb_trx;\n+-----------------+---------------------+\n| trx_id          | trx_mysql_thread_id |\n+-----------------+---------------------+\n| 281479812572992 |                  30 |\n+-----------------+---------------------+\n\n-- T4时刻\nmysql> SELECT trx_id,trx_mysql_thread_id FROM innodb_trx;\n+-----------------+---------------------+\n| trx_id          | trx_mysql_thread_id |\n+-----------------+---------------------+\n| 7417540         |                  30 |\n+-----------------+---------------------+\n\nmysql> SHOW PROCESSLIST;\n+----+-----------------+-----------+--------------------+---------+--------+------------------------+------------------+\n| Id | User            | Host      | db                 | Command | Time   | State                  | Info             |\n+----+-----------------+-----------+--------------------+---------+--------+------------------------+------------------+\n|  4 | event_scheduler | localhost | NULL               | Daemon  | 344051 | Waiting on empty queue | NULL             |\n| 30 | root            | localhost | test               | Sleep   |    274 |                        | NULL             |\n| 31 | root            | localhost | information_schema | Query   |      0 | starting               | SHOW PROCESSLIST |\n+----+-----------------+-----------+--------------------+---------+--------+------------------------+------------------+\n```\n1. `trx_mysql_thread_id=30`就是线程ID，即session A所在的线程\n2. T1时刻，`trx_id`的值其实为**0**，而很大的值只是为了**显示**用的（区别于普通的读写事务）\n3. T2时刻，`trx_id`是一个很大的数字，因为在T1时刻，session A并未涉及更新操作，是一个**只读事务**\n    - 对于**只读事务**，InnoDB**不会分配`trx_id`**\n4. session A在T3时刻执行`INSERT`语句时，InnoDB才**真正分配`trx_id`**\n\n#### 只读事务\n1. 在上面的T2时刻，很大的`trx_id`是由系统**临时计算**出来的\n    - 把**当前事务的`trx`变量的指针地址转成整数**，再加上`2^48`\n2. 同一个只读事务在执行期间，它的指针地址是不会变的\n    - 不论是在`innodb_trx`还是`innodb_locks`表里，同一个只读事务查出来的`trx_id`都是一样的\n3. 如果有多个**并行**的只读事务，每个事务的trx变量的指针地址肯定是不同的\n    - 不同的并发只读事务，查出来的trx_id是不同的\n4. 加上`2^48`的目的：保证只读事务显示的`trx_id`值比较大，用于**区别普通的读写事务**\n5. `trx_id`与`row_id`的逻辑类似，定义长度为`8 Bytes`\n    - 在理论上，可能会出现一个**读写事务**与一个**只读事务**显示的**trx_id相同**的情况\n    - 但**概率极低**，并且没有什么实质危害\n6. 只读事务不分配`trx_id`的好处\n    - 可以减少**事务视图里面活跃数组的大小**\n        - 当前正在运行的**只读事务**，是**不影响数据的可见性判断**\n        - 因此，在创建事务的一致性视图时，只需要拷贝**读写事务**的`trx_id`\n    - 可以减少`trx_id`的申请次数\n        - 在InnoDB里，即使只执行一条普通的`SELECT`语句，在执行过程中，也要对应一个**只读事务**\n        - 如果普通查询语句不申请`trx_id`，就可以**大大减少并发事务申请`trx_id`的锁冲突**\n        - 由于只读事务不分配`trx_id`，`trx_id`的增加速度会**变慢**\n7. `max_trx_id`会**持久化存储**，重启不会重置为0，只有到达`2^48-1`的上限后，才会重置为0\n\n## thread_id\n1. `SHOW PROCESSLIST`的第一列就是`thread_id`\n2. 系统保存了一个环境变量`thread_id_counter`\n    - **每新建一个连接**，就将`thread_id_counter`赋值给这个新连接的线程变量\n3. `thread_id_counter`定义为`4 Bytes`，因此达到`2^32-1`后就会重置为0\n    - 但不会在`SHOW PROCESSLIST`里面看到两个**相同的thread_id**\n    - 因为MySQL设计了一个**唯一数组**的逻辑，给新线程分配thread_id，逻辑代码如下\n\n```cpp\ndo {\n    new_id= thread_id_counter++;\n} while (!thread_ids.insert_unique(new_id).second);\n```\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 分区表","url":"%2F2019%2F03%2F17%2Fmysql-partition-table%2F","content":"\n## 表初始化\n```sql\nCREATE TABLE `t` (\n    `ftime` DATETIME NOT NULL,\n    `c` int(11) DEFAULT NULL,\n    KEY (`ftime`)\n) ENGINE=InnoDB DEFAULT CHARSET=latin1 PARTITION BY RANGE (YEAR(ftime))\n    (PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB,\n    PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB,\n    PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB,\n    PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB);\n\nINSERT INTO t VALUES ('2017-4-1',1),('2018-4-1',1);\n\nmysql> SYSTEM ls /usr/local/var/mysql/test\nt#P#p_2017.ibd\t\tt#P#p_2018.ibd\t\tt#P#p_2019.ibd\t\tt#P#p_others.ibd\n```\n\n<!-- more -->\n\n1. 在表t中初始化插入两行记录，按照分区规则，分别落在`p_2018`和`p_2019`两个分区上\n2. 包含4个ibd文件，_**每个分区对应一个ibd文件**_\n    - 对于**Server层**来说，只是**1**个表\n    - 对于**引擎层**来说，这是**4**个表\n\n## 引擎层行为\n\n### InnoDB\n| session A | session B |\n| ---- | ---- |\n| BEGIN;<br/>SELECT * FROM t WHERE ftime='2017-05-01' FOR UPDATE; | |\n| | INSERT INTO t VALUES ('2018-02-01',1);<br/>(Query OK)<br/>INSERT INTO t VALUES ('2017-12-01',1);<br/>(Blocked) |\n\n```sql\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| ftime        | RECORD      | X                 | X                  |\n+--------------+-------------+-------------------+--------------------+\n\n\nmysql> SHOW ENGINE INNODB STATUS\\G;\nINSERT INTO t VALUES ('2017-12-01',1)\n------- TRX HAS BEEN WAITING 49 SEC FOR THIS LOCK TO BE GRANTED:\nRECORD LOCKS space id 104 page no 5 n bits 72 index ftime of table `test`.`t` /* Partition `p_2018` */ trx id 7417349 lock_mode X insert intention waiting\nRecord lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0\n 0: len 8; hex 73757072656d756d; asc supremum;;\n```\n\n对于普通表，session A持有的锁为`ftime:Next-Key Lock:('2017-4-1','2018-4-1']`\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-partition-table-common-gap-lock.jpg\" width=800/>\n\n但对于**引擎**来说，分区表的分区是**不同的表**，即`2017-4-1`的下一个记录是`p_2018`分区的`supremum`\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-partition-table-real-gap-lock.jpg\" width=800/>\n\n\n### MyISAM\n| session A | session B | session C |\n| ---- | ---- | ---- |\n| ALTER TABLE t ENGINE=MyISAM;<br/>(MySQL 5.7) | | |\n| UPDATE t SET c=SLEEP(100) WHERE ftime='2017-04-01'; | | |\n| | SELECT * FROM t WHERE ftime='2018-4-1';<br/>(Query OK) | |\n| | SELECT * FROM t WHERE ftime='2017-5-1';<br/>(Blocked) | SHOW PROCESSLIST; |\n\n```sql\nmysql> SHOW PROCESSLIST;\n+----+------+-----------+------+---------+------+------------------------------+----------------------------------------------------+\n| Id | User | Host      | db   | Command | Time | State                        | Info                                               |\n+----+------+-----------+------+---------+------+------------------------------+----------------------------------------------------+\n|  2 | root | localhost | test | Query   |   49 | User sleep                   | UPDATE t SET c=SLEEP(100) WHERE ftime='2017-04-01' |\n|  3 | root | localhost | test | Query   |   27 | Waiting for table level lock | SELECT * FROM t WHERE ftime='2017-5-1'             |\n|  4 | root | localhost | test | Query   |    0 | starting                     | SHOW PROCESSLIST                                   |\n+----+------+-----------+------+---------+------+------------------------------+----------------------------------------------------+\n```\n\n1. 对于MyISAM引擎来说，分区表是4个表\n2. MyISAM**只支持表锁**，_**MyISAM的表锁是在引擎层实现的**_，session A加的表锁，其实是锁在分区`p_2018`上\n\n## 手工分表 VS 分区表\n1. 手工分表的逻辑，找到所有需要更新的分表，然后依次更新，**在性能上**，与分区表并**没有实质的差别**\n2. 分区表由**Server层**决定使用哪个分区，手工分表由**应用代码**决定使用哪一个分表\n\n## 分区策略\n1. 每当**第一次**访问一个分区表的时候，MySQL需要把**所有的分区**都访问一遍\n    - 如果一个分区表的分区很多，比如超过了1000个\n    - 在MySQL启动时，如果需要打开的文件超过了`open_files_limit`，就会报错\n    - 实际只需要访问一个分区，但语句却无法执行（MyISAM才会如此，InnoDB采用本地分区策略）\n\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-partition-table-over-open-files-limit.png\" width=800/>\n\n\n### MyISAM\n1. MyISAM分区表使用的分区策略是**通用分区策略**（generic partitioning）\n    - 每次访问分区都由**Server层**控制\n2. 通用分区策略是MySQL一开始支持分区表时就存在的代码\n    - 在文件管理和表管理的实现上很**粗糙**\n    - 同时，还有比较严重的**性能问题**\n3. 从MySQL 5.7.17开始，将MyISAM分区表标记为`Deprecated`\n4. 从MySQL 8.0开始，不再允许创建MyISAM分区表了，只允许创建已经**实现了本地分区策略的引擎**\n    - 目前只有`InnoDB`引擎和`NDB`引擎支持本地分区策略\n\n### InnoDB\n1. 从MySQL 5.7.9开始，InnoDB引擎引入了**本地分区表**（native partitioning）\n    - 在**InnoDB内部**自己管理打开分区的行为\n\n## Server层行为\n从**Server层**来看，_**一个分区表就只是一个表**_\n\n### 操作序列\n| session A | session B | session C |\n| ---- | ---- | ---- |\n| BEGIN;<br/>SELECT * FROM t WHERE ftime='2018-04-01'; | | |\n| | ALTER TABLE t TRUNCATE PARTITION p_2017;<br/>(Blocked) | |\n| | | SHOW PROCESSLIST; |\n\n```sql\n-- session A持有整个表的MDL锁，导致session B被堵住\nmysql> SHOW PROCESSLIST;\n+----+-----------------+-----------+------+---------+--------+---------------------------------+-----------------------------------------+\n| Id | User            | Host      | db   | Command | Time   | State                           | Info                                    |\n+----+-----------------+-----------+------+---------+--------+---------------------------------+-----------------------------------------+\n|  4 | event_scheduler | localhost | NULL | Daemon  | 137019 | Waiting on empty queue          | NULL                                    |\n| 24 | root            | localhost | test | Sleep   |    126 |                                 | NULL                                    |\n| 25 | root            | localhost | test | Query   |      0 | starting                        | SHOW PROCESSLIST                        |\n| 26 | root            | localhost | test | Query   |      3 | Waiting for table metadata lock | ALTER TABLE t TRUNCATE PARTITION p_2017 |\n+----+-----------------+-----------+------+---------+--------+---------------------------------+-----------------------------------------+\n```\n\n### 小结\n1. MySQL在**第一次**打开分区表的时候，需要**访问所有的分区**\n2. 在**Server层**，认为是**同一张表**，因此**所有分区共用同一个MDL锁**\n3. 在**引擎层**，认为是**不同的表**，因此拿到**MDL锁**之后，根据分区规则，_**只访问必要的分区**_\n    - 必要的分区需要根据SQL语句中的**WHERE条件**和**分区规则**来实现\n    - `WHERE ftime='2018-4-1'`，必要分区是`p_2019`分区\n    - `WHERE ftime>='2018-4-1'`，必要分区是`p_2019`分区和`p_others`分区\n    - 如果查询语句的WHERE条件**没有分区Key**，就只能访问**所有分区**了\n\n## 优势\n1. _**对业务透明**_，_**方便清理历史数据**_\n2. `DROP TABLE t DROP PARTITION`，与`DELETE`语句删除数据相比，**速度更快**，**对系统影响小**\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 权限","url":"%2F2019%2F03%2F17%2Fmysql-grant-flush-privileges%2F","content":"\n## 创建用户\n```sql\nCREATE USER 'ua'@'%' IDENTIFIED BY 'pa';\n```\n1. 用户名+地址才表示一个用户，`ua@ip1`和`ua@ip2`代表的是两个不同的用户\n2. 在磁盘上，往`mysql.user`表里插入一行，由于没有指定权限，所有表示权限的字段都是N\n3. 在内存里，往数组`acl_users`里插入一个`acl_user`对象，该对象的`access`字段的值为0\n\n<!-- more -->\n\n```sql\nmysql> SELECT * FROM mysql.user WHERE user = 'ua'\\G;\n*************************** 1. row ***************************\n                  Host: %\n                  User: ua\n           Select_priv: N\n           Insert_priv: N\n           Update_priv: N\n           Delete_priv: N\n           Create_priv: N\n             Drop_priv: N\n           Reload_priv: N\n         Shutdown_priv: N\n          Process_priv: N\n             File_priv: N\n            Grant_priv: N\n       References_priv: N\n            Index_priv: N\n            Alter_priv: N\n          Show_db_priv: N\n            Super_priv: N\n Create_tmp_table_priv: N\n      Lock_tables_priv: N\n          Execute_priv: N\n       Repl_slave_priv: N\n      Repl_client_priv: N\n      Create_view_priv: N\n        Show_view_priv: N\n   Create_routine_priv: N\n    Alter_routine_priv: N\n      Create_user_priv: N\n            Event_priv: N\n          Trigger_priv: N\nCreate_tablespace_priv: N\n              ssl_type:\n            ssl_cipher:\n           x509_issuer:\n          x509_subject:\n         max_questions: 0\n           max_updates: 0\n       max_connections: 0\n  max_user_connections: 0\n                plugin: caching_sha2_password\n      password_expired: N\n password_last_changed: 2019-03-17 14:33:56\n     password_lifetime: NULL\n        account_locked: N\n      Create_role_priv: N\n        Drop_role_priv: N\nPassword_reuse_history: NULL\n   Password_reuse_time: NULL\n```\n\n## 权限范围\n\n### 全局权限\n作用于整个MySQL实例，权限信息保存在`mysql.user`，要给用户ua赋一个最高权限的语句如下\n```sql\nGRANT ALL PRIVILEGES ON *.* to 'ua'@'%' WITH GRANT OPTION;\n```\n1. 在磁盘上，将`mysql.user`表里的用户`'ua'@'%'`这一行中所有表示权限的字段都修改为Y\n2. 在内存里，从数组`acl_users`中找到这个用户对应的对象，将`access`值（**权限位**）修改为二进制的全1\n3. 这个`GRANT`命令执行完成后，如果有新的客户端使用用户ua登录成功\n    - MySQL会为**新连接**维护一个**线程对象**\n    - 然后从`acl_users`数组里查到用户ua的权限，并**将权限值拷贝到这个线程对象**中\n    - 之后在这个连接中执行的语句，所有关于全局权限的判断，都直接使用线程对象内部保存的权限位\n4. `GRANT`命令对于全局权限，同时更新了磁盘和内存，命令完成后**即时生效**\n    - 接下来新创建的连接会使用新的权限\n    - 对于一个**已经存在的连接**，它的**全局权限不受影响**（因为判断时采用的是线程对象内部的权限值）\n\n#### 回收权限\n```sql\nREVOKE ALL PRIVILEGES ON *.* FROM 'ua'@'%';\n```\n1. 在磁盘上，将`mysql.user`表里的用户`'ua'@'%'`这一行中所有表示权限的字段都修改为N\n2. 在内存里，从数组`acl_users`中找到这个用户对应的`acl_user`对象，将`access`的值修改为0\n\n### DB权限\n让用户`'ua'@'%'`拥有库db1的所有权限\n```sql\nGRANT ALL PRIVILEGES ON db1.* to 'ua'@'%' WITH GRANT OPTION;\n```\n1. 基于库的权限记录保存在`mysql.db`中，在内存里则保存在数组`acl_dbs`中\n2. 在磁盘上，往`mysql.db`表中插入一行记录，所有权限位的字段设置为Y\n3. 在内存中，增加一个对象到数组`acl_dbs`，该对象的权限位为全1\n4. 每次需要判断一个用户对一个数据库读写权限的时候，都需要遍历一遍`acl_dbs`数组（多线程共享）\n    - 根据`user`、`host`和`db`找到匹配的对象，然后根据对象的权限位来判断\n5. `GRANT`命令对于**已经存在的连接**的影响，全局权限和基于DB的权限是不一样的\n    - 全局权限：**线程私有**\n    - 基于DB的权限：**线程共享**\n\n```sql\nmysql> SELECT * FROM mysql.db WHERE user = 'ua'\\G;\n*************************** 1. row ***************************\n                 Host: %\n                   Db: db1\n                 User: ua\n          Select_priv: Y\n          Insert_priv: Y\n          Update_priv: Y\n          Delete_priv: Y\n          Create_priv: Y\n            Drop_priv: Y\n           Grant_priv: Y\n      References_priv: Y\n           Index_priv: Y\n           Alter_priv: Y\nCreate_tmp_table_priv: Y\n     Lock_tables_priv: Y\n     Create_view_priv: Y\n       Show_view_priv: Y\n  Create_routine_priv: Y\n   Alter_routine_priv: Y\n         Execute_priv: Y\n           Event_priv: Y\n         Trigger_priv: Y\n```\n\n#### 操作序列\n| 时刻 | session A | session B | session C |\n| ---- | ---- | ---- | ---- |\n| T1 | CONNECT(root,root);<br/>CREATE DATABASE db1;<br>CREATE USER 'ua'@'%' IDENTIFIED BY 'pa';<br/>GRANT SUPER ON \\*.\\* TO 'ua'@'%';<br/>GRANT ALL PRIVILEGES ON db1.\\* TO 'ua'@'%'; | | |\n| T2 | | CONNECT(ua,pa)<br/>SET GLOBAL sync_binlog=1;<br/>(Query OK)<br/>CREATE TABLE db1.t(c INT);<br>(Query OK) | CONNECT(ua,pa)<br/>USE db1; |\n| T3 | REVOKE SUPER ON \\*.\\* FROM 'ua'@'%'; | | |\n| T4 | | SET GLOBAL sync_binlog=1;<br/>(Query OK)<br/>ALTER TABLE db1.t ENGINE=InnoDB;<br>(Query OK) | ALTER TABLE t ENGINE=InnoDB;<br/>(Query OK) |\n| T5 | REVOKE ALL PRIVILEGES ON db1.\\* FROM 'ua'@'%'; | | |\n| T6 | | SET GLOBAL sync_binlog=1;<br/>(Query OK)<br/>ALTER TABLE db1.t ENGINE=InnoDB;<br/>(ALTER command denied) | ALTER TABLE t ENGINE=InnoDB;(Query OK) |\n\n1. `SET GLOBAL sync_binlog=1;`这个操作需要`SUPER`权限\n2. 虽然用户ua的`SUPER`权限在T3时刻被回收了，但在T4时刻执行`SET GLOBAL`的时候，权限验证还是通过了\n    - 这是因为`SUPER`是全局权限，这个信息在**线程对象**中，而`REVOKE`操作影响不了线程对象\n3. 在T4时刻去掉用户ua对db1库的所有权限后，session B在T6时刻再操作db1的表时，就会报**权限不足**\n    - 这是因为`acl_dbs`是一个**全局数组**，所有线程判断db权限都会用该数组\n    - 因此`REVOKE`操作会立马影响到session\n4. 特殊逻辑\n    - 如果当前会话已经在某个db里面，之前use这个db时拿到的库权限就会保存在**会话变量**中\n    - session C在T2执行了`USE db1`，拿到这个库的权限，在切换出db1之前，一直对db1有权限\n\n\n### 表权限和列权限\n```sql\nCREATE TABLE db1.t1(id INT, a INT);\nGRANT ALL PRIVILEGES ON db1.t1 TO 'ua'@'%' WITH GRANT OPTION;\nGRANT SELECT(id), INSERT(id,a) ON db1.t1 TO 'ua'@'%' WITH GRANT OPTION;\n```\n1. 表权限定义在表`mysql.tables_priv`，列权限定义在表`mysql.columns_priv`\n    - 这两类权限组合起来存放在**内存的hash结构**：`column_priv_hash`\n2. 跟DB权限类似，这两个权限在每次`GRANT`的时候都会修改数据表，也会同步修改内存的hash结构\n3. 因此这两类权限的操作，也会立马影响到**已经存在的连接**\n\n## FLUSH PRIVILEGES\n1. `FLUSH PRIVILEGES`命令会清空`acl_users`数组（_**全局权限**_）\n    - 然后从`mysql.user`表中读取数据重新加载，重新构造一个`acl_users`数组\n    - 以数据表中的数据为准，会将**全局权限**的内存数组重新加载一遍\n2. 同样的，对于**DB权限**、**表权限和列权限**，MySQL也做了同样的处理\n3. 如果**内存的权限数据**和**磁盘数据表的权限数据**相同的话，不需要执行`FLUSH PRIVILEGES`\n    - 如果都是用`GRANT/REVOKE`语句执行的话，内存和数据表的数据应该保持**同步更新**的\n    - 正常情况下，在执行`GRANT`命令之后，没有必要跟着执行`FLUSH PRIVILEGES`命令\n\n### 使用场景\n1. 当数据表的权限数据与内存中的权限数据**不一致**，通过`FLUSH PRIVILEGES`来**重建内存数据**，达到一致状态\n2. 这种不一致的状态往往由于**不规范的操作**导致的，例如直接用DML语句操作系统权限表\n\n### 不规范操作1\n| 时刻 | client A | client B |\n| ---- | ---- | ---- |\n| T1 | CONNECT(root,root)<br/>CREATE USER 'ua'@'%' IDENTIFIED BY 'pa'; | |\n| T2 | | CONNECT(ua,pa)<br/>(Connect OK)<br>DISCONNECT |\n| T3 | DELETE FROM mysql.user WHERE user='ua'; | |\n| T4 | | CONNECT(ua,pa)<br/>(Connect OK)<br>DISCONNECT |\n| T5 | FLUSH PRIVILEGES; | |\n| T6 | | CONNECT(ua,pa)<br/>(Access Denied) |\n\n1. T3时刻虽然使用了`DELETE`语句删除了用户ua，但在T4时刻，仍然可以用用户ua连接成功\n    - 因为内存中`acl_users`数组中还有这个用户，系统判断时认为用户还正常存在的\n2. T5时刻执行过`FLUSH PRIVILEGES`命令后，内存更新，T6时刻就会报`Access Denied`错误\n3. 直接操作系统权限表是很不规范的操作\n\n### 不规范操作2\n| 时刻 | client A |\n| ---- | ---- |\n| T1 | CONNECT(root,root)<br/>CREATE USER 'ua'@'%' IDENTIFIED BY 'pa'; |\n| T2 | DELETE FROM mysql.user WHERE user='ua'; |\n| T3 | GRANT SUPER ON \\*.\\* TO 'ua'@'%' WITH GRANT OPTION;<br/>(ERROR 1133 (42000): Can't find any matching row in the user table) |\n| T4 | CREATE USER 'ua'@'%' IDENTIFIED BY 'pa';<br/>(ERROR 1396 (HY000): Operation CREATE USER failed for 'ua'@'%') |\n\n1. 在T2时刻直接删除了数据表的记录，而内存的数据还存在\n2. T3时刻给用户ua赋权限失败，因为`mysql.user`表找不到这行记录\n3. T4时刻也无法重新创建用户ua，因为在内存判断的时候，会认为这个用户还存在\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 拷贝表","url":"%2F2019%2F03%2F16%2Fmysql-copy-table%2F","content":"\n## 初始化\n```sql\nCREATE DATABASE db1;\nUSE db1;\n\nCREATE TABLE t(id INT PRIMARY KEY, a INT, b INT, INDEX(a)) ENGINE=InnoDB;\nDELIMITER ;;\nCREATE PROCEDURE idata()\nBEGIN\n    DECLARE i INT;\n    SET i=1;\n    WHILE (i <= 1000) DO\n        INSERT INTO t VALUES (i,i,i);\n        SET i=i+1;\n    END WHILE;\nEND;;\nDELIMITER ;\nCALL idata();\n\nCREATE DATABASE db2;\nCREATE TABLE db2.t LIKE db1.t;\n\n-- 目标：把db1.t里面a>900的数据导出来，插入到db2.t\n```\n\n<!-- more -->\n\n## mysqldump\n```\n$ mysqldump -uroot --add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where=\"a>900\" --result-file=/tmp/t.sql\n\n# 部分结果\n$ cat /tmp/t.sql\nINSERT INTO `t` VALUES (901,901,901),(902,902,902),(903,903,903)...(999,999,999),(1000,1000,1000);\n```\n1. mysqldump命令将数据导出成一组`INSERT`语句，把结果输出到**客户端**的临时文件\n2. `--single-transaction`\n    - 导出数据时不需要对表db1.t加**表锁**\n    - 采用的是`START TRANSACTION WITH CONSISTENT SNAPSHOT`\n3. `--add-locks=0`\n    - 表示在输出到文件结果里，不增加`LOCK TABLES t WRITE`\n4. `--no-create-info`\n    - 不需要导出表结构\n5. `--set-gtid-purged=OFF`\n    - 不输出跟GTID相关的信息\n6. `--result-file`\n    - 执行**客户端**上输出文件的路径\n7. 输出结果中的`INSERT`语句会包含多个value对，为了后续如果使用这个文件写入数据，执行会更快\n    - 如果要一个`INSERT`语句只插入一行数据的话，增加参数`--skip-extended-insert`\n\n### 应用到db2\n```sql\n$ mysql -h$host -P$port -u$user db2 -e \"source /client_tmp/t.sql\"\n```\n1. `source`是一个客户端命令，打开文件，默认以**分号**结尾读取一条条的SQL语句\n2. 将SQL语句发送到服务端执行，`slowlog`和`binlog`都会记录这些语句\n\n## 导出CSV\n```sql\nmysql> SYSTEM cat cat /usr/local/etc/my.cnf\ncat: cat: No such file or directory\n# Default Homebrew MySQL server config\n[mysqld]\n# Only allow connections from localhost\nbind-address = 127.0.0.1\nslow_query_log = 1\nlong_query_time = 0\nsecure-file-priv = \"/tmp\"\n\nmysql> SELECT @@secure_file_priv;\n+--------------------+\n| @@secure_file_priv |\n+--------------------+\n| /tmp/              |\n+--------------------+\n\nmysql> SELECT * FROM db1.t WHERE a>900 INTO OUTFILE '/tmp/t.csv';\nQuery OK, 100 rows affected (0.01 sec)\n\nmysql> SYSTEM du -sh /tmp/t.csv\n4.0K\t/tmp/t.csv\n```\n1. secure-file-priv\n    - `secure-file-priv=\"\"`，表示不限制文件生成的位置，不安全\n    - `secure-file-priv=\"/XXX\"`，要求生成的文件只能存放在指定的目录或其子目录\n    - `secure-file-priv=NULL`，表示禁止在这个MySQL实例上执行`SELECT...INTO OUTFILE`\n2. `SELECT...INTO OUTFILE`语句\n    - 将结果保存在**服务端**\n    - **不会覆盖文件**\n    - 原则上一个数据行对应文本文件的一行\n    - **不会生成表结构文件**\n        - mysqldump提供`--tab`参数，可以同时导出**表结构定义文件**和**csv数据文件**\n\n### LOAD DATA\n```sql\nLOAD DATA INFILE '/tmp/t.csv' INTO TABLE db2.t;\n```\n1. 打开文件`/tmp/t.csv`\n    - 以制表符`\\t`作为**字段间的分隔符**，以换行符`\\n`作为**记录间的分隔符**，进行数据读取\n2. 启动事务\n3. 判断每一行的**字段数**和`db.t`是否相同\n    - 如果不相同，则直接报错，**回滚事务**\n    - 如果相同，则构造这一行，调用InnoDB引擎的接口，写入到表中\n4. 重复步骤3，直到`/tmp/t.csv`整个文件读入完成，**提交事务**\n\n#### 主备同步\n`binlog_format=STATEMENT`\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-load-data-replication.jpg\" width=800/>\n\n1. 主库执行完成后，将`/tmp/t.csv`文件的内容都**直接写到binlog文件**中\n2. 往binlog文件写入\n    - `LOAD DATA LOCAL INFILE '/tmp/SQL_LOAD_MB-1-0' INTO TABLE db2.t;`\n3. 把binlog传到备库\n4. 备库的应用日志线程在执行这个事务日志时\n    - 先把binlog中的t.csv文件的内容读出来，写到本地临时目录`/tmp/SQL_LOAD_MB-1-0`\n    - 再执行`LOAD DATA LOCAL`语句，往备库的db2.t插入跟主库相同的数据\n        - `LOCAL`，表示执行这条命令的**客户端**本地文件（这里的客户端即备库本身）\n\n#### LOCAL\n1. `LOAD DATA`\n    - 读取的是**服务端**文件，文件必须在`secure_file_priv`指定的目录或其子目录\n2. `LOAD DATA LOCAL`\n    - 读取的是**客户端**文件，只需要MySQL客户端有**访问这个文件的权限**即可\n    - 此时，MySQL客户端会**先把本地文件传给服务端**，然后再执行流程\n\n## 物理拷贝\n1. 直接把db1.t的frm文件和ibd文件拷贝到db2目录下，是不行的\n    - 因为一个InnoDB表，除了包含这两个物理文件外，还需要**在数据字典中注册**\n2. MySQL 5.6引入了**可传输表空间**，可以通过导出+导入表空间的方式，实现物理拷贝表\n\n### 执行步骤\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-table-physical-copy.jpg\" width=800/>\n\n1. 假设在db1库下，复制一个跟表t相同的表r\n2. 执行`CREATE TABLE r LIKE t;`，创建一个**相同表结构**的空表\n3. 执行`ALTER TABLE r DISCARD TABLESPACE;`，此时`r.ibd`文件会被删除\n4. 执行`FLUSH TABLE t FOR EXPORT;`\n    - 此时在db1目录下会生成`t.cfg`文件\n    - 整个`db1.t`处于**只读**状态，直到执行`UNLOCK TABLES`\n5. 在db1目录下执行`cp t.cfg r.cfg`和`cp t.ibd r.ibd`\n6. 执行`UNLOCK TABLES;`，此时`t.cfg`文件会被删除\n7. 执行`ALTER TABLE r IMPORT TABLESPACE;`\n    - 将这个`r.ibd`文件作为表r新的表空间\n    - 由于这个文件的内容与`t.ibd`是相同的，因此表r中数据与表t相同\n    - 为了让文件里的表空间id和数据字典中的一致，会修改`r.ibd`的表空间id\n        - 而**表空间id**存在于**每一个数据页**\n        - 如果是一个很大的文件，每个数据页都需要修改，`IMPORT`语句会需要点时间\n        - 但相对于逻辑拷贝的方法，`IMPORT`语句的耗时还是非常短的\n\n```sql\nmysql> CREATE TABLE r LIKE t;\nQuery OK, 0 rows affected (0.41 sec)\n\nmysql> SYSTEM ls /usr/local/var/mysql/db1\nr.ibd\tt.ibd\n\n-- 删除r.ibd\nmysql> ALTER TABLE r DISCARD TABLESPACE;\nmysql> SYSTEM ls /usr/local/var/mysql/db1\nt.ibd\n\n-- 生成t.cfg，t处于只读状态\nmysql> FLUSH TABLE t FOR EXPORT;\nmysql> SYSTEM ls /usr/local/var/mysql/db1\nt.cfg\tt.ibd\n\nmysql> UNLOCK TABLES;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> ALTER TABLE r IMPORT TABLESPACE;\nQuery OK, 0 rows affected (0.23 sec)\n\nmysql> SELECT COUNT(*) from r;\n+----------+\n| COUNT(*) |\n+----------+\n|     1000 |\n+----------+\n```\n\n## 小结\n1. **物理拷贝速度最快**，尤其对于大表来说\n    - 必须**全表拷贝**\n    - 需要**到服务器上拷贝数据**\n    - **不支持跨引擎使用**，源表和目标表都是使用InnoDB引擎\n2. mysqldump生成包含`INSERT`语句的方法，加上`where`过滤，可以只导出**部分数据**\n    - 不支持类似join等复杂的写法\n    - 逻辑拷贝，支持**跨引擎**使用\n3. `SELECT...INTO OUTFILE`最灵活，支持**所有的SQL语法**\n    - **每次只能导出一张表的数据，而且表结构需要另外的语句单独备份**\n    - 逻辑拷贝，支持**跨引擎**使用\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- INSERT语句的锁","url":"%2F2019%2F03%2F16%2Fmysql-insert-lock%2F","content":"\n## INSERT...SELECT\n\n### 表初始化\n```sql\nCREATE TABLE `t` (\n  `id` INT(11) NOT NULL AUTO_INCREMENT,\n  `c` INT(11) DEFAULT NULL,\n  `d` INT(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `c` (`c`)\n) ENGINE=InnoDB;\n\nINSERT INTO t VALUES (null,1,1);\nINSERT INTO t VALUES (null,2,2);\nINSERT INTO t VALUES (null,3,3);\nINSERT INTO t VALUES (null,4,4);\n\nCREATE TABLE t2 LIKE t;\n```\n\n<!-- more -->\n\n### 操作序列\n| 时刻 | session A | session B |\n| ---- | ---- | ---- |\n| T1 | | BEGIN; |\n| T2 | | INSERT INTO t2(c,d) SELECT c,d FROM t; |\n| T3 | INSERT INTO t VALUES (-1,-1,-1);<br/>(Blocked) | |\n\n```sql\n-- T3时刻\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X,GAP             | S                  |\n+--------------+-------------+-------------------+--------------------+\n```\n1. T2时刻，session B会在表t加上`PRIMARY:Next-Key Lock:(-∞,1]`\n2. 如果没有锁的话，就可能会出现session B的**INSERT语句先执行**，但对应的**binlog后写入**的情况\n    - `binlog_format=STATEMENT`，binlog里面的语句序列如下\n        - `INSERT INTO t VALUES (-1,-1,-1)`\n        - `INSERT INTO t2(c,d) SELECT c,d FROM t`\n    - 这个语句传到备库执行，就会把id=-1这一行也会写到t2，_**主备不一致**_\n\n## INSERT循环写入\n\n### 非循环写入\n```sql\nmysql> EXPLAIN INSERT INTO t2(c,d) (SELECT c+1,d FROM t FORCE INDEX(c) ORDER BY c DESC LIMIT 1);\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-------+\n| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-------+\n|  1 | INSERT      | t2    | NULL       | ALL   | NULL          | NULL | NULL    | NULL | NULL |     NULL | NULL  |\n|  1 | SIMPLE      | t     | NULL       | index | NULL          | c    | 5       | NULL |    1 |   100.00 | NULL  |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-------+\n\n# Time: 2019-03-15T04:55:55.315664Z\n# User@Host: root[root] @ localhost []  Id:     2\n# Query_time: 0.003300  Lock_time: 0.000424 Rows_sent: 0  Rows_examined: 1\nSET timestamp=1552625755;\nINSERT INTO t2(c,d) (SELECT c+1,d FROM t FORCE INDEX(c) ORDER BY c DESC LIMIT 1);\n```\n1. 加锁范围为在表t上`c:Next-Key Lock:(3,4]`+`c:Next-Key Lock:(4,+∞]`\n2. 执行流程比较简单，从表t中按索引c倒序扫描第一行，拿到结果后写入到表t2，整个语句的扫描行数为1\n\n### 循环写入\n```sql\n-- MySQL 5.7上执行\nmysql> EXPLAIN INSERT INTO t(c,d) (SELECT c+1,d FROM t FORCE INDEX(c) ORDER BY c DESC LIMIT 1);\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------+\n| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra           |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------+\n|  1 | INSERT      | t     | NULL       | ALL   | NULL          | NULL | NULL    | NULL | NULL |     NULL | NULL            |\n|  1 | SIMPLE      | t     | NULL       | index | NULL          | c    | 5       | NULL |    1 |   100.00 | Using temporary |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------+\n\nmysql> SHOW STATUS LIKE '%Innodb_rows_read%';\n+------------------+-------+\n| Variable_name    | Value |\n+------------------+-------+\n| Innodb_rows_read | 13    |\n+------------------+-------+\n\nmysql> INSERT INTO t(c,d) (SELECT c+1,d FROM t FORCE INDEX(c) ORDER BY c DESC LIMIT 1);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> SHOW STATUS LIKE '%Innodb_rows_read%';\n+------------------+-------+\n| Variable_name    | Value |\n+------------------+-------+\n| Innodb_rows_read | 17    |\n+------------------+-------+\n\n# Time: 2019-03-15T05:10:38.603323Z\n# User@Host: root[root] @ localhost []  Id:     2\n# Query_time: 0.004470  Lock_time: 0.000184 Rows_sent: 0  Rows_examined: 5\nSET timestamp=1552626638;\nINSERT INTO t(c,d) (SELECT c+1,d FROM t FORCE INDEX(c) ORDER BY c DESC LIMIT 1);\n```\n1. `Using temporary`表示用到了**临时表**，执行过程中，需要把表t的内容读出来，写入临时表\n2. 实际上，`EXPLAIN`结果里的`rows=1`是因为受到了`LIMIT 1`的影响\n3. 语句执行前后，`Innodb_rows_read`的值增加了4，因为临时表默认使用的是**Memory引擎**\n    - 这4行数据查的是表t，即对表t做了**全表扫描**\n4. 执行流程\n    - 创建临时表，表里有两个字段`c`和`d`\n    - 按照索引c扫描表t，依次取出c=4,3,2,1，然后**回表**，读到c和d的值写入临时表\n        - 此时，`Rows_examined=4`\n    - 由于有`LIMIT 1`，所以只会取临时表的第一行，再插入到表t\n        - 此时，`Rows_examined=5`\n5. 该语句会导致在表t上做**全表扫描**，并且会给索引c上的所有间隙都加上`Share Next-Key Lock`\n    - 在这个语句执行期间，其它事务不能在这个表上插入数据\n6. 需要临时表的原因\n    - 一边遍历数据，一边更新数据\n    - 如果读出来的数据直接写回原表，可能在遍历过程中，读到刚刚插入的记录\n    - 新插入的记录如果参与计算逻辑，就会与原语义不符\n\n#### 优化方案\n```sql\nCREATE TEMPORARY TABLE temp_t(c INT,d INT) ENGINE=Memory;\n-- Rows_examined=1\nINSERT INTO temp_t (SELECT c+1, d FROM t FORCE INDEX(c) ORDER BY c DESC LIMIT 1);\n-- Rows_examined=1\nINSERT INTO t(c,d) SELECT * FROM temp_t;\nDROP TABLE temp_t;\n```\n\n## INSERT唯一键冲突\n| 时刻 | session A | session B |\n| ---- | ---- | ---- |\n| T0 | SELECT * FROM t; | |\n| T1 | INSERT INTO t VALUES (10,10,10); | |\n| T2 | BEGIN; | |\n| T3 | INSERT INTO t VALUES (11,10,10);<br/>(Duplicate entry '10' for key 'c') | |\n| T4 | | INSERT INTO t VALUES (12,9,9);<br/>(Blocked) |\n\n```sql\n-- T0时刻\nmysql> SELECT * FROM t;\n+----+------+------+\n| id | c    | d    |\n+----+------+------+\n|  1 |    1 |    1 |\n|  2 |    2 |    2 |\n|  3 |    3 |    3 |\n|  4 |    4 |    4 |\n|  5 |    5 |    4 |\n+----+------+------+\n\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| c            | RECORD      | X,GAP             | S                  |\n+--------------+-------------+-------------------+--------------------+\n```\n1. session A要执行的INSERT语句，发生唯一键冲突，并不是简单地报错返回，还需要在**冲突的索引**上加锁\n2. 一个`Next-Key Lock`由它的**右边界**定义的，即是`c:Shared Next-Key Lock:(5,10]`\n\n## INSERT死锁\n| 时刻 | session A | session B | session C |\n| ---- | ---- | ---- | ---- |\n| T0 | TRUNCATE t; | | |\n| T1 | BEGIN;<br/>INSERT INTO t VALUES (null,5,5); | | |\n| T2 | | INSERT INTO t VALUES (null,5,5); | INSERT INTO t VALUES (null,5,5); |\n| T3 | ROLLBACK; | | Deadlock found |\n\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-insert-dead-lock.jpg\" width=800/>\n\n\n1. 在T1时刻，session A执行`INSERT`语句，在索引`c=5`上加上**行锁**（索引c是**唯一索引**，可以退化为**行锁**）\n2. 在T2时刻，session B和session C执行相同的`INSERT`语句，发现**唯一键冲突**，_等待加上**读锁**_\n3. 在T3时刻，session A执行`ROLLBACK`语句，session B和session C都试图继续插入执行操作，都要加上**写锁**\n    - 但两个session都要等待对方的**读锁**，所以就出现了死锁\n\n## INSERT INTO...ON DUPLICATE KEY\n```sql\nTRUNCATE T;\nINSERT INTO t VALUES (1,1,1),(2,2,2);\n\n-- 如果有多个列违反唯一性约束，按照索引的顺序，修改跟第一个索引冲突的行\n-- 2 rows affected，insert和update都认为自己成功了，update计数加1，insert计数也加1\nINSERT INTO t VALUES (2,1,100) ON DUPLICATE KEY UPDATE d=100;\nQuery OK, 2 rows affected (0.01 sec)\nRecords: 2  Duplicates: 0  Warnings: 0\n\nmysql> SELECT * FROM t;\n+----+------+------+\n| id | c    | d    |\n+----+------+------+\n|  1 |    1 |    1 |\n|  2 |    2 |  100 |\n+----+------+------+\n```\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 自增主键","url":"%2F2019%2F03%2F15%2Fmysql-auto-increment%2F","content":"\n## 自增不连续\n\n### 表初始化\n```sql\nCREATE TABLE `t` (\n  `id` INT(11) NOT NULL AUTO_INCREMENT,\n  `c` INT(11) DEFAULT NULL,\n  `d` INT(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `c` (`c`)\n) ENGINE=InnoDB;\n```\n\n<!-- more -->\n\n### 自增值\n```sql\nINSERT INTO t VALUES (null,1,1);\n\n-- AUTO_INCREMENT=2，表示下一次插入数据时，如果需要自动生成自增值，会生成id=2\nmysql> SHOW CREATE TABLE t;\n+-------+---------------------------------------------+\n| Table | Create Table                                |\n+-------+---------------------------------------------+\n| t     | CREATE TABLE `t` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `c` int(11) DEFAULT NULL,\n  `d` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `c` (`c`)\n) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8 |\n+-------+---------------------------------------------+\n```\n\n#### 保存策略\n1. MyISAM引擎的自增值是保存在**数据文件**\n2. InnoDB引擎的自增值，是保存在**内存**里，到了MySQL 8.0，才有**自增值持久化**的能力\n    - MySQL 5.7及之前的版本，自增值保存在内存里，并没有持久化\n        - 每次重启后，第一次打开表时，都会去找自增值的最大值`max(id)`\n        - 然后将`max(id)+1`作为这个表当前的自增值\n        - 假如一个表当前数据行的最大id为10，`AUTO_INCREMENT=11`\n        - 此时，删除id=10的行，`AUTO_INCREMENT`依然还是11\n        - 如果马上重启实例，重启后这个表的`AUTO_INCREMENT`就会变成10\n        - 即MySQL重启后可能会修改一个表的`AUTO_INCREMENT`值\n    - 从MySQL 8.0开始，将自增值的变更记录在`redolog`，重启时依靠`redolog`恢复重启之前的值\n\n#### 修改机制\n1. 如果插入数据时id字段指定为0、null或未指定值，就会把这个表当前的`AUTO_INCREMENT`值填到自增字段\n2. 如果插入数据时id字段指定了具体值，就直接使用语句里指定的值，但有可能会更新自增值\n3. 某次要插入的值为X，当前的自增值为Y\n    - 如果X<Y，那么这个表的自增值不变\n    - 如果X>=Y，就需要把当前自增值修改为**新的自增值**\n        - 从`auto_increment_offset`开始，以`auto_increment_increment`为步进\n        - 持续叠加，直到找到**第一个大于**X的值，作为新的自增值\n\n```sql\n-- 采用双M架构是，auto_increment_increment设置为2，避免两个库生成的主键冲突\nmysql> SELECT @@auto_increment_offset;\n+-------------------------+\n| @@auto_increment_offset |\n+-------------------------+\n|                       1 |\n+-------------------------+\n\nmysql> SELECT @@auto_increment_increment;\n+----------------------------+\n| @@auto_increment_increment |\n+----------------------------+\n|                          1 |\n+----------------------------+\n```\n\n### 场景\n\n#### 唯一键冲突\n```sql\nmysql> INSERT INTO t VALUES (null,1,1);\nERROR 1062 (23000): Duplicate entry '1' for key 'c'\n\n-- id没有回退\nmysql> SHOW CREATE TABLE t;\n+-------+---------------------------------------------+\n| Table | Create Table                                |\n+-------+---------------------------------------------+\n| t     | CREATE TABLE `t` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `c` int(11) DEFAULT NULL,\n  `d` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `c` (`c`)\n) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8 |\n+-------+---------------------------------------------+\n\nmysql> INSERT INTO t VALUES (null,2,2);\nQuery OK, 1 row affected (0.16 sec)\n\n-- id不连续\nmysql> SELECT * FROM t;\n+----+------+------+\n| id | c    | d    |\n+----+------+------+\n|  1 |    1 |    1 |\n|  3 |    2 |    2 |\n+----+------+------+\n```\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-auto-increment-duplicate-entry.jpg\" width=400/>\n\n1. 执行器调用InnoDB引擎接口写入一行，传入的这一行的值为`(0,1,1)`\n2. InnoDB发现用户没有指定自增id的值，获取表t当前的自增值为2\n3. 将传入的这一行的值改为`(2,1,1)`\n4. 将表的自增值改为3（_**在真正执行插入数据之前**_）\n5. 继续执行插入数据的操作，由于已经存在于c=1的记录，所以报`Duplicate entry`错误\n    - 表的自增值也**没有回退**\n\n#### 事务回滚\n```sql\nINSERT INTO t VALUES (null,1,1);\nBEGIN;\nINSERT INTO t VALUES (null,2,2);\nROLLBACK;\nINSERT INTO t VALUES (null,2,2);\n\n-- id不连续\nmysql> SELECT * FROM t;\n+----+------+------+\n| id | c    | d    |\n+----+------+------+\n|  1 |    1 |    1 |\n|  3 |    2 |    2 |\n+----+------+------+\n```\n\n## 不回退的原因\n1. 主要原因是为了**提高性能**\n2. 两个并行执行的事务，在申请自增值的时候，需要**加锁**，顺序申请\n3. 假设事务A申请了id=2，事务B申请了id=3，此时表t当前的自增值为4\n4. 事务B正确提交了，但事务A出现了唯一键冲突\n5. 假设允许事务A把自增值回退，即回退到2\n    - 此刻，**表里已经有id=3的行，但表t当前的自增值为2**\n6. 接下来，继续执行的其它事务会申请到id=2，再申请id=3，在插入过程中就会**主键冲突**\n\n### 解决思路\n1. 每次申请id之前，先判断表里是否已经有这个id，如果存在，则跳过这个id\n    - **成本太高**，因为需要到**主键索引**上查找\n2. 把自增id的锁范围扩大，必须等到一个事务执行完成并提交后，下一个事务才能再申请自增id\n    - **锁粒度太大，系统并发能力大大下降**\n3. 上述两个办法都会导致**性能问题**，根本原因是允许自增值回退\n    - **InnoDB放弃了自增值回退**，自增id**保证递增**的，但**不保证是连续**的\n\n## 自增锁\n1. 自增锁不是事务锁，每次申请完就马上释放，以便其它事务再申请\n2. MySQL 5.0，自增锁的范围是**语句级别**\n    - 一个语句申请了自增锁，需要等到语句结束后才会释放，_**影响并发度**_\n3. MySQL 5.1.22，引入了一个新策略，新增参数`innodb_autoinc_lock_mode`，默认值为1\n    - `innodb_autoinc_lock_mode=0`，表示采用之前MySQL 5.0的策略，**语句级别**\n    - `innodb_autoinc_lock_mode=1`\n        - 普通`INSERT`语句，自增锁在申请后**马上释放**，包括批量的`INSERT INTO...VALUES`\n        - 类似`INSERT...SELECT`这样的**批量插入**（无法明确数量）的语句，还是**语句级别**\n    - `innodb_autoinc_lock_mode=2`，所有的申请自增id的动作都是**申请后就释放锁**\n\n```sql\n-- MySQL 5.6\nmysql> SELECT @@innodb_autoinc_lock_mode;\n+----------------------------+\n| @@innodb_autoinc_lock_mode |\n+----------------------------+\n|                          1 |\n+----------------------------+\n```\n\n### INSERT...SELECT\n默认配置下，`INSERT...SELECT`的自增锁是语句级别的，这是为了**数据的一致性**\n\n#### 操作序列\n假设session B是申请了自增值以后马上释放自增锁，并且`binglog_format=STATEMENT`\n\n| session A | session B |\n| ---- | ---- |\n| INSERT INTO t VALUES (null,1,1); | |\n| INSERT INTO t VALUES (null,2,2); | |\n| INSERT INTO t VALUES (null,3,3); | |\n| INSERT INTO t VALUES (null,4,4); | |\n| | CREATE TABLE t2 LIKE t; |\n| INSERT INTO t2 VALUES (null,5,5); | INSERT INTO t2(c,d) SELECT c,d FROM t; |\n\n1. session B先插入两个记录`(1,1,1)`和`(2,2,2)`\n2. 然后，session A来申请自增id得到id=3，插入`(3,5,5)`\n3. 之后，session B继续执行，插入两条记录`(4,3,3)`和`(5,4,4)`\n4. 两个session是同时执行插入命令的，binlog里面对表t2的更新日志只有两种情况\n    - 要么先记session A的，要么先记session B的\n    - 不论哪一种，这个binlog拿到备库去执行或者拿来恢复临时实例\n    - 备库和临时实例里面，session B这个语句执行出来，生成的结果里面，id都是连续的，_**主备不一致**_\n\n#### 解决思路\n1. 让原库的批量插入语句，固定生成**连续的id值**，自增锁直到语句执行结束才释放\n    - `innodb_autoinc_lock_mode=1`\n2. binlog里面把插入数据的操作都**如实记录**下来，到备库执行的时候，不再依赖于自增主键去生成\n    - `innodb_autoinc_lock_mode=2` + `binlog_format=ROW`\n    - 从**并发插入的性能角度**考虑，**推荐使用**，既能提升并发度，又不会出现数据不一致\n\n### 批量插入\n1. 批量插入数据（**无法确定插入数量**），如果`innodb_autoinc_lock_mode=1`，自增锁为**语句级别**\n    - `INSERT...SELECT`\n    - `REPLACE...SELECT`\n    - `LOAD DATA`\n2. 普通批量插入：`INSERT INTO...VALUES`\n    - 即使采用`innodb_autoinc_lock_mode=1`，也不会等语句执行完成后才释放锁\n    - 因为这类语句在申请自增id时，可以**精确计算**出多少个id，然后一次性申请，申请完成后释放\n\n### 批量申请id策略\n1. 目的是为了减少申请次数，**提高并发插入的性能**\n2. 语句执行过程中，第一次申请自增id，会分配1个\n3. 1个用完以后，这个梗语句会第二次申请自增id，会分配2个\n4. 依次类推，同一个语句去申请自增id，每次申请到点自增id个数都是上一次的**2倍**\n\n```sql\nINSERT INTO t VALUES (null,1,1);\nINSERT INTO t VALUES (null,2,2);\nINSERT INTO t VALUES (null,3,3);\nINSERT INTO t VALUES (null,4,4);\nCREATE TABLE t2 LIKE t;\n-- 第一次申请id=1，第二次申请id=2~3，第三次申请id=4~7\nINSERT INTO t2(c,d) SELECT c,d FROM t;\n-- 实际插入为(8,5,5)\nINSERT INTO t2 VALUES (null,5,5);\n\nmysql> SELECT * FROM t2;\n+----+------+------+\n| id | c    | d    |\n+----+------+------+\n|  1 |    1 |    1 |\n|  2 |    2 |    2 |\n|  3 |    3 |    3 |\n|  4 |    4 |    4 |\n|  8 |    5 |    5 |\n+----+------+------+\n```\n\n## binlog\n自增ID的生成顺序，和binlog的写入顺序可能是不相同的\n```sql\nSET binlog_format=STATEMENT;\nCREATE TABLE t (id INT AUTO_INCREMENT PRIMARY KEY);\nINSERT INTO t VALUES (null);\n```\n\n```\nBEGIN\n$ mysqlbinlog -vv ./binlog.000027\n/*!*/;\n# at 15720\n# at 15752\n#190319 22:35:13 server id 1  end_log_pos 15752 CRC32 0xf118154f \tIntvar\nSET INSERT_ID=1/*!*/;\n#190319 22:35:13 server id 1  end_log_pos 15856 CRC32 0x40050594 \tQuery\tthread_id=28\texec_time=0\terror_code=0\nSET TIMESTAMP=1553006113/*!*/;\nINSERT INTO t VALUES (null)\n```\n1. `SET INSERT_ID=1`表示在同一个线程里下一次需要用到自增值的时候，固定用1\n2. `SET INSERT_ID`语句是固定跟在`INSERT`语句之前的\n3. 主库上语句A的id是1，语句B的id是2，写入binlog的顺序是先B后A，binlog如下\n    - SET INSERT_ID=2\n    - 语句B\n    - SET INSERT_ID=1\n    - 语句A\n4. 在备库上语句B用到的`INSERT_ID`依然为2，_**与主库一致**_\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- Memory引擎","url":"%2F2019%2F03%2F14%2Fmysql-memory-engine%2F","content":"\n## 数据组织\n\n### 表初始化\n```sql\nCREATE TABLE t1 (id INT PRIMARY KEY, c INT) ENGINE=Memory;\nCREATE TABLE t2 (id INT PRIMARY KEY, c INT) ENGINE=InnoDB;\nINSERT INTO t1 VALUES (1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);\nINSERT INTO t2 VALUES (1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);\n```\n\n<!-- more -->\n\n### 执行语句\n```sql\n-- 0在最后\nmysql> SELECT * FROM t1;\n+----+------+\n| id | c    |\n+----+------+\n|  1 |    1 |\n|  2 |    2 |\n|  3 |    3 |\n|  4 |    4 |\n|  5 |    5 |\n|  6 |    6 |\n|  7 |    7 |\n|  8 |    8 |\n|  9 |    9 |\n|  0 |    0 |\n+----+------+\n\n-- 0在最前\nmysql> SELECT * FROM t2;\n+----+------+\n| id | c    |\n+----+------+\n|  0 |    0 |\n|  1 |    1 |\n|  2 |    2 |\n|  3 |    3 |\n|  4 |    4 |\n|  5 |    5 |\n|  6 |    6 |\n|  7 |    7 |\n|  8 |    8 |\n|  9 |    9 |\n+----+------+\n```\n\n### 组织形式\n1. **索引组织表**（Index Organizied Table）：InnoDB引擎把数据放在主键索引上，其它索引上保存主键ID\n2. **堆组织表**（Heap Organizied Table）：Memory引擎把数据**单独存放**，索引上保存**数据位置**\n\n#### 索引组织表\nt2的数据组织方式，主键索引上的值是**有序存储**的，执行`SELECT *`时，按叶子节点从左到右扫描\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-memory-engine-index-organizied.jpg\" width=800/>\n\n\n#### 堆组织表\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-memory-engine-heap-organizied.jpg\" width=800/>\n\n1. Memory引擎的数据和索引是**分开存储**的\n    - 数据部分以**数组**的方式单独存放，主键索引（采用**哈希索引**）存的是**数据位置**\n2. 在t1上执行`SELECT *`时，走的也是**全表扫描**，即**顺序扫描整个数组**，因此0是最后一个被读到的\n3. t1的主键索引是**哈希索引**，如果是**范围查询**，需要走**全表扫描**，例如`SELECT * FROM t1 WHERE id<5`\n4. Memory表也支持B-Tree索引\n\n##### B-Tree索引\n```sql\nALTER TABLE t1 ADD INDEX a_btree_index USING BTREE (id);\n```\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-memory-engine-btree.jpg\" width=800/>\n\n```sql\n-- 优化器选择了a_btree_index索引\nmysql> EXPLAIN SELECT * FROM t1 WHERE id<5;\n+----+-------------+-------+------------+-------+-----------------------+---------------+---------+------+------+----------+-------------+\n| id | select_type | table | partitions | type  | possible_keys         | key           | key_len | ref  | rows | filtered | Extra       |\n+----+-------------+-------+------------+-------+-----------------------+---------------+---------+------+------+----------+-------------+\n|  1 | SIMPLE      | t1    | NULL       | range | PRIMARY,a_btree_index | a_btree_index | 4       | NULL |    6 |   100.00 | Using where |\n+----+-------------+-------+------------+-------+-----------------------+---------------+---------+------+------+----------+-------------+\n\n-- 0在最前面\nmysql> SELECT * FROM t1 WHERE id<5;\n+----+------+\n| id | c    |\n+----+------+\n|  0 |    0 |\n|  1 |    1 |\n|  2 |    2 |\n|  3 |    3 |\n|  4 |    4 |\n+----+------+\n\n-- 强制走主键索引，为哈希索引，走全表扫描\nmysql> SELECT * FROM t1 FORCE INDEX(PRIMARY) WHERE id<5;\n+----+------+\n| id | c    |\n+----+------+\n|  1 |    1 |\n|  2 |    2 |\n|  3 |    3 |\n|  4 |    4 |\n|  0 |    0 |\n+----+------+\n```\n\n#### 对比\n1. InnoDB的数据总是**有序存放**的，而内存表的数据是按照**写入顺序**存放的\n2. 当数据文件有空洞时\n    - InnoDB表在插入新数据时，为了保证数据的有序性，只能在**固定位置**写入新值\n    - 而Memory表**只要找到空位**就可以插入新值\n3. 数据位置发生变化时，InnoDB只需要修改**主键索引**，而Memory表需要修改**所有索引**\n4. 数据查找\n    - InnoDB表利用主键查找需要走一次索引查找，用辅助索引查找需要走两次索引查找\n    - Memory表中所有索引的地位都是相同的\n5. 变长数据类型\n    - InnoDB表支持变长数据类型\n    - Memory表不支持`BLOB`和`TEXT`类型\n        - 即使定义了`VARCHAR(N)`，实际也会当做`CHAR(N)`，**固定长度**\n        - 因此Memory表的**每行数据长度相同**\n        - 每个数据被删除后，空出的位置可以被接下来要插入的数据复用\n\n```sql\nDELETE FROM t1 WHERE id=5;\nINSERT INTO t1 VALUES (10,10);\n\nmysql> SELECT * FROM t1;\n+----+------+\n| id | c    |\n+----+------+\n|  1 |    1 |\n|  2 |    2 |\n|  3 |    3 |\n|  4 |    4 |\n| 10 |   10 |\n|  6 |    6 |\n|  7 |    7 |\n|  8 |    8 |\n|  9 |    9 |\n|  0 |    0 |\n+----+------+\n```\n\n## 缺点\n不推荐在**生产环境**使用Memory表\n\n### 锁粒度\nMemory表不支持行锁，**只支持表锁**（并不是MDL锁），**对并发访问的支持不够好**\n\n| session A | session B | session C |\n| ---- | ---- | ---- |\n| UPDATE t1 SET id=SLEEP(50) WHERE id=1; | | |\n| | SELECT * FROM t1 WHERE id=2;<br/>(Wait 50s) | |\n| | | SHOW PROCESSLIST; |\n\n```sql\nmysql> SHOW PROCESSLIST;\n+----+-----------------+-----------+------+---------+--------+------------------------------+---------------------------------------+\n| Id | User            | Host      | db   | Command | Time   | State                        | Info                                  |\n+----+-----------------+-----------+------+---------+--------+------------------------------+---------------------------------------+\n|  4 | event_scheduler | localhost | NULL | Daemon  | 206928 | Waiting on empty queue       | NULL                                  |\n| 21 | root            | localhost | test | Query   |     27 | User sleep                   | UPDATE t1 SET id=SLEEP(50) WHERE id=1 |\n| 22 | root            | localhost | test | Query   |     16 | Waiting for table level lock | SELECT * FROM t1 WHERE id=2           |\n| 23 | root            | localhost | test | Query   |      0 | starting                     | SHOW PROCESSLIST                      |\n+----+-----------------+-----------+------+---------+--------+------------------------------+---------------------------------------+\n```\n\n### 数据持久化\n数据库重启后，所有的Memory表都会被清空\n\n#### Master-Slave架构\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-memory-engine-master-slave.jpg\" width=600/>\n\n1. 业务正常访问主库\n2. 备库硬件升级，备库重启，内存表t1被清空\n3. 备库重启后，应用日志线程执行一条`UPDATE t1`的语句，备库会报错，导致**主备同步停止**\n4. 如果期间发生**主备切换**，客户端会看到t1的数据丢失了\n\n#### Master-Master架构\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-memory-engine-master-master.jpg\" width=600/>\n\n1. MySQL知道重启后，Memory表的数据会丢失，所以担心主库重启后，会出现主备不一致\n    - 在数据库重启之后，自动往binlog里面写一行`DELETE FROM t1`\n2. 在备库重启时，备库binlog的`DELETE`语句会传到主库，然后**主库Memory表的内容被莫名其妙地删除了**\n\n### 选择InnoDB\n1. 如果表的更新量很大，那么**并发度**是一个很重要的参考指标，**InnoDB支持行锁**\n2. 能放到Memory表的数据量都不大，InnoDB也有`Buffer Pool`，**读性能也不差**\n3. 建议将**普通Memory表**替换成**InnoDB表**\n4. 例外场景：在数据量可控，可以采用**内存临时表**，例如JOIN优化里面的临时表优化\n    - `CREATE TEMPORARY TABLE ... ENGINE=Memory`\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 内部临时表","url":"%2F2019%2F03%2F13%2Fmysql-internal-temporary-table%2F","content":"\n## UNION\nUNION语义：取两个子查询结果的**并集**，重复的行只保留一行\n\n### 表初始化\n```sql\nCREATE TABLE t1(id INT PRIMARY KEY, a INT, b INT, INDEX(a));\nDELIMITER ;;\nCREATE PROCEDURE idata()\nBEGIN\n    DECLARE i INT;\n\n    SET i=1;\n    WHILE (i<= 1000) DO\n        INSERT INTO t1 VALUES (i,i,i);\n        SET i=i+1;\n    END WHILE;\nEND;;\nDELIMITER ;\nCALL idata();\n```\n\n<!-- more -->\n\n### 执行语句\n```sql\n(SELECT 1000 AS f) UNION (SELECT id FROM t1 ORDER BY id DESC LIMIT 2);\n\nmysql> EXPLAIN (SELECT 1000 AS f) UNION (SELECT id FROM t1 ORDER BY id DESC LIMIT 2);\n+----+--------------+------------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------+\n| id | select_type  | table      | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra                            |\n+----+--------------+------------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------+\n|  1 | PRIMARY      | NULL       | NULL       | NULL  | NULL          | NULL    | NULL    | NULL | NULL |     NULL | No tables used                   |\n|  2 | UNION        | t1         | NULL       | index | NULL          | PRIMARY | 4       | NULL |    2 |   100.00 | Backward index scan; Using index |\n| NULL | UNION RESULT | <union1,2> | NULL       | ALL   | NULL          | NULL    | NULL    | NULL | NULL |     NULL | Using temporary                  |\n+----+--------------+------------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------+\n```\n1. 第二行的`Key=PRIMARY`，说明第二个子查询用到了索引id\n2. 第三行的Extra字段为`Using temporary`\n    - 表示在对子查询的结果做`UNION RESULT`的时候，使用了**临时表**\n\n### UNION RESULT\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-union-procedure.jpg\" width=800/>\n\n1. 创建一个**内存临时表**，这个内存临时表只有一个整型字段f，并且f为**主键**\n2. 执行第一个子查询，得到1000，并存入内存临时表中\n3. 执行第二个子查询\n    - 拿到第一行id=1000，试图插入到内存临时表，但由于1000这个值已经存在于内存临时表\n        - **违反唯一性约束**，插入失败，继续执行\n    - 拿到第二行id=999，插入内存临时表成功\n4. 从内存临时表中按行取出数据，返回结果，并**删除内存临时表**，结果中包含id=1000和id=999两行\n5. 内存临时表起到了**暂存数据**的作用，还用到了内存临时表主键id的**唯一性约束**，实现UNION的语义\n\n### UNION ALL\n`UNION ALL`没有**去重**的语义，一次执行子查询，得到的结果直接发给客户端，**不需要内存临时表**\n```sql\nmysql> EXPLAIN (SELECT 1000 AS f) UNION ALL (SELECT id FROM t1 ORDER BY id DESC LIMIT 2);\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------+\n| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra                            |\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------+\n|  1 | PRIMARY     | NULL  | NULL       | NULL  | NULL          | NULL    | NULL    | NULL | NULL |     NULL | No tables used                   |\n|  2 | UNION       | t1    | NULL       | index | NULL          | PRIMARY | 4       | NULL |    2 |   100.00 | Backward index scan; Using index |\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------+\n```\n\n## GROUP BY\n\n### 内存充足\n```sql\n-- 16777216 Bytes = 16 MB\nmysql> SHOW VARIABLES like '%tmp_table_size%';\n+----------------+----------+\n| Variable_name  | Value    |\n+----------------+----------+\n| tmp_table_size | 16777216 |\n+----------------+----------+\n```\n\n#### 执行语句\n```sql\n-- MySQL 5.6上执行\nmysql> EXPLAIN SELECT id%10 AS m, COUNT(*) AS c FROM t1 GROUP BY m;\n+----+-------------+-------+-------+---------------+------+---------+------+------+----------------------------------------------+\n| id | select_type | table | type  | possible_keys | key  | key_len | ref  | rows | Extra                                        |\n+----+-------------+-------+-------+---------------+------+---------+------+------+----------------------------------------------+\n|  1 | SIMPLE      | t1    | index | PRIMARY,a     | a    | 5       | NULL | 1000 | Using index; Using temporary; Using filesort |\n+----+-------------+-------+-------+---------------+------+---------+------+------+----------------------------------------------+\n\nmysql> SELECT id%10 AS m, COUNT(*) AS c FROM t1 GROUP BY m;\n+------+-----+\n| m    | c   |\n+------+-----+\n|    0 | 100 |\n|    1 | 100 |\n|    2 | 100 |\n|    3 | 100 |\n|    4 | 100 |\n|    5 | 100 |\n|    6 | 100 |\n|    7 | 100 |\n|    8 | 100 |\n|    9 | 100 |\n+------+-----+\n```\n1. `Using index`：表示使用了**覆盖索引**，选择了索引a，不需要回表\n2. `Using temporary`：表示使用了**临时表**\n3. `Using filesort`：表示需要**排序**\n\n#### 执行过程\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-group-by-temporary-table.jpg\" width=800/>\n\n1. 创建**内存临时表**，表里有两个字段m和c，m为主键\n2. 扫描t1的索引a，依次取出叶子节点上的id值，计算id%10，记为x\n    - 如果内存临时表中没有主键为x的行，插入一行记录`(x,1)`\n    - 如果内存临时表中有主键为x的行，将x这一行的c值加1\n3. 遍历完成后，再根据字段m做排序，得到结果集返回给客户端\n\n#### 排序过程\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-group-by-temporary-table-sort.jpg\" width=800/>\n\n\n#### ORDER BY NULL\n```sql\n-- 跳过最后的排序阶段，直接从临时表中取回数据\nmysql> EXPLAIN SELECT id%10 AS m, COUNT(*) AS c FROM t1 GROUP BY m ORDER BY NULL;\n+----+-------------+-------+-------+---------------+------+---------+------+------+------------------------------+\n| id | select_type | table | type  | possible_keys | key  | key_len | ref  | rows | Extra                        |\n+----+-------------+-------+-------+---------------+------+---------+------+------+------------------------------+\n|  1 | SIMPLE      | t1    | index | PRIMARY,a     | a    | 5       | NULL | 1000 | Using index; Using temporary |\n+----+-------------+-------+-------+---------------+------+---------+------+------+------------------------------+\n\n-- t1中的数据是从1开始的\nmysql> SELECT id%10 AS m, COUNT(*) AS c FROM t1 GROUP BY m ORDER BY NULL;\n+------+-----+\n| m    | c   |\n+------+-----+\n|    1 | 100 |\n|    2 | 100 |\n|    3 | 100 |\n|    4 | 100 |\n|    5 | 100 |\n|    6 | 100 |\n|    7 | 100 |\n|    8 | 100 |\n|    9 | 100 |\n|    0 | 100 |\n+------+-----+\n```\n\n### 内存不足\n```sql\nSET tmp_table_size=1024;\n```\n\n#### 执行语句\n```sql\n-- 内存临时表的上限为1024 Bytes，但内存临时表不能完全放下100行数据，内存临时表会转成磁盘临时表，默认采用InnoDB引擎\n-- 如果t1很大，这个查询需要的磁盘临时表就会占用大量的磁盘空间\nmysql> SELECT id%100 AS m, count(*) AS c FROM t1 GROUP BY m ORDER BY NULL LIMIT 10;\n+------+----+\n| m    | c  |\n+------+----+\n|    1 | 10 |\n|    2 | 10 |\n|    3 | 10 |\n|    4 | 10 |\n|    5 | 10 |\n|    6 | 10 |\n|    7 | 10 |\n|    8 | 10 |\n|    9 | 10 |\n|   10 | 10 |\n+------+----+\n```\n\n#### 优化方案\n\n##### 优化索引\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-group-by-opt-index.jpg\" width=800/>\n\n1. 不论使用内存临时表还是磁盘临时表，`GROUP BY`都需要构造一个带**唯一索引**的表，_**执行代价较高**_\n2. 需要临时表的原因：每一行的`id%100`是无序的，因此需要临时表，来记录并统计结果\n3. 如果可以确保输入的数据是有序的，那么计算`GROUP BY`时，只需要**从左到右顺序扫描**，依次累加即可\n    - 当碰到第一个1的时候，已经累积了X个0，结果集里的第一行为`(0,X)`\n    - 当碰到第一个2的时候，已经累积了Y个1，结果集里的第一行为`(1,Y)`\n    - 整个过程不需要**临时表**，也不需要**排序**\n\n```sql\n-- MySQL 5.7上执行\nALTER TABLE t1 ADD COLUMN z INT GENERATED ALWAYS AS(id % 100), ADD INDEX(z);\n\n-- 使用了覆盖索引，不需要临时表，也不需要排序\nmysql> EXPLAIN SELECT z, COUNT(*) AS c FROM t1 GROUP BY z;\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-------------+\n| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra       |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-------------+\n|  1 | SIMPLE      | t1    | NULL       | index | z             | z    | 5       | NULL | 1000 |   100.00 | Using index |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-------------+\n```\n\n##### 直接排序\n1. 一个`GROUP BY`语句需要放到临时表的数据量**特别大**，还是按照先放在内存临时表，再退化成磁盘临时表\n2. **可以直接用磁盘临时表的形式**，在`GROUP BY`语句中`SQL_BIG_RESULT`（告诉优化器涉及的数据量很大）\n3. 磁盘临时表原本采用B+树存储，**存储效率还不如数组**，优化器看到`SQL_BIG_RESULT`，**会直接用数组存储**\n    - 即放弃使用临时表，_**直接进入排序阶段**_\n\n###### 执行过程\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-group-by-opt-direct-sort.jpg\" width=800/>\n\n```sql\n-- 没有再使用临时表，而是直接使用了排序算法\nmysql> EXPLAIN SELECT SQL_BIG_RESULT id%100 AS m, COUNT(*) AS c FROM t1 GROUP BY m;\n+----+-------------+-------+-------+---------------+------+---------+------+------+-----------------------------+\n| id | select_type | table | type  | possible_keys | key  | key_len | ref  | rows | Extra                       |\n+----+-------------+-------+-------+---------------+------+---------+------+------+-----------------------------+\n|  1 | SIMPLE      | t1    | index | PRIMARY,a     | a    | 5       | NULL | 1000 | Using index; Using filesort |\n+----+-------------+-------+-------+---------------+------+---------+------+------+-----------------------------+\n```\n1. 初始化`sort_buffer`，确定放入一个整型字段，记为m\n2. 扫描t1的索引a，依次取出里面的id值，将id%100的值放入`sort_buffer`\n3. 扫描完成后，对`sort_buffer`的字段m做排序（sort_buffer内存不够时，会利用**磁盘临时文件**辅助排序）\n4. 排序完成后，得到一个有序数组，遍历有序数组，得到每个值出现的次数（类似上面优化索引的方式）\n\n### 对比DISTINCT\n```sql\n-- 标准SQL，SELECT部分添加一个聚合函数COUNT(*)\nSELECT a,COUNT(*) FROM t GROUP BY a ORDER BY NULL;\n-- 非标准SQL\nSELECT a FROM t GROUP BY a ORDER BY NULL;\n\nSELECT DISTINCT a FROM t;\n```\n1. 标准SQL：按照字段a分组，计算每组a出现的次数\n2. 非标准SQL：没有了`COUNT(*)`，不再需要执行计算总数的逻辑\n    - 按照字段a分组，相同的a的值只返回一行，与`DISTINCT`语义一致\n3. 如果不需要执行**聚合函数**，`DISTINCT`和`GROUP BY`的语义、执行流程和执行性能是相同的\n    - 创建一个**临时表**，临时表有一个字段a，并且在这个字段a上创建一个**唯一索引**\n    - 遍历表t，依次取出数据插入临时表中\n        - 如果发现唯一键冲突，就跳过\n        - 否则插入成功\n    - 遍历完成后，将临时表作为结果集返回给客户端\n\n## 小结\n1. 用到内部临时表的场景\n    - 如果语句执行过程中可以一边读数据，一边得到结果，是不需要额外内存的\n    - 否则需要额外内存来保存中间结果\n2. `join_buffer`是**无序数组**，`sort_buffer`是**有序数组**，临时表是**二维表结构**\n3. 如果执行逻辑需要用到**二维表特性**，就会优先考虑使用**临时表**\n4. 如果对`GROUP BY`语句的结果没有明确的排序要求，加上`ORDER BY NULL`（MySQL 5.6）\n5. 尽量让`GROUP BY`过程**用上索引**，**确认EXPLAIN结果没有`Using temporary`和`Using filesort`**\n6. 如果`GROUP BY`需要统计的数据量不大，尽量使用**内存临时表**（可以适当调大`tmp_table_size`）\n7. 如果数据量实在**太大**，使用`SQL_BIG_RESULT`来告诉优化器**直接使用排序算法**（跳过临时表）\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 用户临时表","url":"%2F2019%2F03%2F12%2Fmysql-user-temporary-table%2F","content":"\n## 临时表 VS 内存表\n1. 内存表，指的是使用`Memory`引擎的表，建表语法：`CREATE TABLE ... ENGINE=Memory`\n    - _**所有数据都保存在内存中，系统重启时被清空，但表结构还在**_\n2. 临时表，可以使用**各种引擎**\n    - 如果使用的是`InnoDB`或者`MyISAM`引擎，数据需要写到磁盘上\n    - 当然也可以使用`Memory`引擎\n\n<!-- more -->\n\n## 特征\n| session A | session B |\n| ---- | ---- |\n| CREATE TEMPORARY TABLE t(c int) ENGINE=MyISAM;<br/>（创建临时表） | |\n| | SHOW CREATE TABLE t;<br/>(Table 'test.t' doesn't exist) |\n| CREATE TABLE t(id INT PRIMARY KEY) ENGINE=InnoDB;<br/>（创建普通表） | |\n| SHOW CREATE TABLE t;<br/>（显示临时表） | |\n| SHOW TABLES;<br/>（显示普通表） | |\n| | INSERT INTO t VALUES (1); |\n| | SELECT * FROM t;<br>(返回1) |\n| SELECT * FROM t;<br/>(Empty set) | |\n\n1. 建表语法：`CREATE TEMPORARY TABLE`\n2. **临时表只能被创建它的session访问**，对其它线程是不可见的\n3. **临时表可以与普通表同名**\n4. 同一个session内有**同名**的临时表和普通表时，`SHOW CREATE`语句以及**增删改查**语句访问的是**临时表**\n5. `SHOW TABLES`命令**不显示临时表**\n6. 在**session结束**时，会**自动删除临时表**，临时表特别适用于**Join优化**的场景\n    - 不同session的临时表可以**重名**，可以支持多个session并发执行Join优化\n    - 无需担心数据的删除问题，临时表是**自动回收**的\n\n## 跨库查询\n将一个大表ht，按照字段f，拆分成1024个表，然后分布到32个数据库实例，每个实例32张表\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-sub-db-table.jpg\" width=800/>\n\n1. 选择分区Key的依据：**减少跨库查询和跨表查询**，如果大部分语句都会包含f的等值条件，就要用f做分区键\n2. 在Proxy这一层解析完SQL语句后，就能确定将这条语句路由到哪一个分区表做查询\n    - 例如`SELECT v FROM ht WHERE f=N;`，通过分表规则来确认需要的数据被放到哪一个分表上\n3. 假如表上还有另外一个索引k，\n    - 对于`SELECT v FROM ht WHERE k >= M ORDER BY t_modified DESC LIMIT 100;`\n    - 没有用到字段f，只能到所有分区中去查找所有满足条件的行，然后再统一做`ORDER BY`操作\n4. 两种实现思路\n    - 在Proxy层的进程代码中实现排序\n        - 优点：**处理速度快**\n        - 缺点：**开发工作量大**，**对Proxy端压力较大**（内存不足和CPU瓶颈）\n    - 从各个分库拿到数据，汇总到一个MySQL实例中的一个表，然后在**汇总表**上做逻辑操作\n\n### 汇总表方案\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-sub-db-table-temporary-table.jpg\" width=600/>\n\n1. 在汇总库上创建一个临时表temp_ht，表里包含三个字段v、k和t_modified\n2. 在各个分库上执行\n3. `SELECT v,k,t_modified FROM ht_x WHERE k >= M ORDER BY t_modified DESC LIMIT 100;`\n4. 把分库的执行结果插入到临时表temp_ht\n5. 在temp_ht上执行\n    - `SELECT v FROM temp_ht ORDER BY t_modified DESC LIMIT 100;`\n\n## 重名\n```sql\nCREATE TEMPORARY TABLE temp_t(id INT PRIMARY KEY) ENGINE=InnoDB;\n\nmysql> SELECT @@tmpdir;\n+----------+\n| @@tmpdir |\n+----------+\n| /tmp     |\n+----------+\n\nmysql> system ls -l /tmp\ntotal 108\n-rw-rw---- 1 mysql mysql  8556 Mar 12 05:00 #sql1_1_0.frm\n-rw-rw---- 1 mysql mysql 98304 Mar 12 05:00 #sql1_1_0.ibd\n```\n1. 创建一个frm文件，用于保存**表结构定义**，放在**临时文件目录**\n    - 前缀为`#sql{进程ID}_{线程ID}_{序号}`，后缀为`.frm`\n2. 表中数据的存放\n    - MySQL 5.6及之前，MySQL会在**临时文件目录**下创建一个**相同的前缀**，以`.ibd`为后缀\n    - 从MySQL 5.7开始，MySQL引入了一个**临时文件表空间**，用来存放临时文件的数据，不再需要ibd\n3. 从文件名的前缀规则可知，临时表和普通表的**存储是不一样**的，因此可以**重名**\n\n### 磁盘存储\n| session A | session B |\n| ---- | ---- |\n| CREATE TEMPORARY TABLE t1(id INT);<br/>// #sql1_2_0.frm | |\n| CREATE TEMPORARY TABLE t2(id INT);<br/>// #sql1_2_1.frm | |\n| | CREATE TEMPORARY TABLE t1(id INT);<br/>// #sql1_3_0.frm |\n\n```sql\n-- session A的线程ID为2，session B的线程ID为3\n-- session A和session B创建的临时表，在磁盘上的文件是不会重名的\nmysql> SHOW PROCESSLIST;\n+----+------+-----------+------+---------+------+-------+------------------+\n| Id | User | Host      | db   | Command | Time | State | Info             |\n+----+------+-----------+------+---------+------+-------+------------------+\n|  2 | root | localhost | test | Sleep   |  127 |       | NULL             |\n|  3 | root | localhost | test | Query   |    0 | init  | SHOW PROCESSLIST |\n+----+------+-----------+------+---------+------+-------+------------------+\n```\n\n### 内存区分\n1. 每个表都有一个对应的`table_def_key`\n2. 普通表的`table_def_key`：**库名 + 表名**\n3. 临时表的`table_def_key`：**库名 + 表名 + server_id + thread_id**\n    - session A和session B创建的临时表t1，**磁盘文件名不同**，**`table_def_key`也不同**，因此可以**并存**\n\n### 实现\n1. 每个线程都维护自己的**临时表链表**\n2. 每次session内操作表的时候，先遍历链表，检查是否有**同名的临时表**（**临时表优先**）\n3. 在session结束时，对链表里的每个临时表，执行删除表操作\n    - `DROP TEMPORARY TABLE t1`\n    - `binlog`中也记录了上面的删除命令\n\n## 主备复制\n写binlog，意味着备库需要\n\n### binlog_format\n```sql\nCREATE TABLE t_normal(id INT PRIMARY KEY, c INT) ENGINE=InnoDB; -- Q1\nCREATE TEMPORARY TABLE temp_t LIKE t_normal; -- Q2\nINSERT INTO temp_t VALUES(1,1); -- Q3\nINSERT INTO t_normal SELECT * FROM temp_t; -- Q4\n```\n1. `binlog_format=STATEMENT/MIXED`\n    - 如果关于临时表的操作都不记录，那么记录到binlog的语句就只有Q1和Q4\n    - 备库执行到Q4时会报错：表temp_t不存在\n    - Q2会传到备库执行，备库的同步线程就会创建这个临时表\n        - 主库在线程退出时，就会自动删除临时表\n        - 但备库同步线程时**持续运行**的，因此需要为主库的binlog自动加上`DROP TEMPORARY TABLE`\n2. `binlog_format=ROW`\n    - 与临时表相关的语句，都不会记录到binlog\n    - 记录Q4时，`write_row enent`里面记录的逻辑是：插入一行数据(1,1)\n    - `DROP TABLE t_normal，temp_t`，binlog只能重写成\n        - `DROP TABLE t_normal /* generated by server */`\n        - 这是因为备库上并没有temp_t，需要重写后再传到备库去执行，才不会导致备库同步线程停止\n\n### 同名临时表\n实例S是实例M的备库\n\n| 时刻 | M session A | M session B | S的应用日志线程 |\n| ---- | ---- | ---- | ---- |\n| T1 | CREATE TEMPORARY TABLE t1(id INT); | | |\n| T2 | | | CREATE TEMPORARY TABLE t1(id INT); |\n| T3 | | CREATE TEMPORARY TABLE t1(id INT); | |\n| T4 | | | CREATE TEMPORARY TABLE t1(id INT); |\n\n1. 主库上的两个session创建了同名的临时表t1，这两个语句都会被传到备库S上去执行\n2. 但备库的应用日志线程是共用的（哪怕是多线程复制，两个语句也有可能被分配给同一个workder）\n    - `CREATE TEMPORARY TABLE`可能会被先后执行两次\n3. MySQL在记录binlog的时候，会把主库执行这个语句的**thread_id**写到binlog\n    - 备库的应用线程就能知道每个语句的**主库thread_id**\n        - 利用这个**thread_id**来构造临时表的`table_def_key`\n    - session A的临时表t1，在备库上的`table_def_key`\n        - 库名 + t1 + M的server_id + **session A的thread_id**\n    - session B的临时表t2，在备库上的`table_def_key`\n        - 库名 + t1 + M的server_id + **session B的thread_id**\n    - 由于`table_def_key`是不同，所以两个表在备库的应用线程里面**不会冲突**\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- JOIN优化","url":"%2F2019%2F03%2F11%2Fmysql-join-opt%2F","content":"\n## 表初始化\n```sql\nCREATE TABLE t1(id INT PRIMARY KEY, a INT, b INT, INDEX(a));\nCREATE TABLE t2 LIKE t1;\n\nDROP PROCEDURE idata;\nDELIMITER ;;\nCREATE PROCEDURE idata()\nBEGIN\n    DECLARE i INT;\n    SET i=1;\n    WHILE (i <= 1000) DO\n        INSERT INTO t1 VALUES (i,1001-i,i);\n        SET i=i+1;\n    END WHILE;\n\n    SET i=1;\n    WHILE (i <= 1000000) DO\n        INSERT INTO t2 VALUES (i,i,i);\n        SET i=i+1;\n    END WHILE;\nEND;;\nDELIMITER ;\n\nCALL idata();\n```\n\n<!-- more -->\n\n## Multi-Range Read\nMRR的目的：尽量使用**顺序读盘**\n\n### 回表\n```sql\nSELECT * FROM t1 WHERE a>=1 AND a<=100;\n```\n如果随着a递增的顺序进行查询的话，id的值会变成随机的，就会出现**随机访问**，**性能相对较差**\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-join-opt-back-to-table.jpg\" width=600/>\n\n\n### MRR\n1. 根据索引a，定位到满足条件的记录，将id的值放入`read_rnd_buffer`中\n2. 将`read_rnd_buffer`中的id进行**递增排序**\n3. 排序后的id值，依次到主键索引中查找\n4. 如果`read_rnd_buffer`满，先执行完第2步和第3步，然后清空`read_rnd_buffer`，继续遍历索引a\n\n```sql\n-- 默认值为256KB\n-- 8388608 Bytes = 8 MB\nmysql> SHOW VARIABLES LIKE '%read_rnd_buffer_size%';\n+----------------------+---------+\n| Variable_name        | Value   |\n+----------------------+---------+\n| read_rnd_buffer_size | 8388608 |\n+----------------------+---------+\n\n-- mrr_cost_based=on：现在的优化器基于消耗的考虑，更倾向于不使用MRR\nmysql> SHOW VARIABLES LIKE '%optimizer_switch%'\\G;\n*************************** 1. row ***************************\nVariable_name: optimizer_switch\n        Value: index_merge=on,index_merge_union=on,index_merge_sort_union=on,index_merge_intersection=on,engine_condition_pushdown=on,index_condition_pushdown=on,mrr=on,mrr_cost_based=on,block_nested_loop=on,batched_key_access=off,materialization=on,semijoin=on,loosescan=on,firstmatch=on,duplicateweedout=on,subquery_materialization_cost_based=on,use_index_extensions=on,condition_fanout_filter=on,derived_merge=on,use_invisible_indexes=off\n\n-- 稳定启动MRR优化\nSET optimizer_switch='mrr_cost_based=off';\n```\n\n#### 执行流程\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-join-opt-back-to-table-mrr.jpg\" width=600/>\n\n\n#### EXPLAIN\n```sql\nmysql> SET optimizer_switch='mrr_cost_based=on';\nQuery OK, 0 rows affected (0.00 sec)\n\n-- 优化器没有选择MRR\nmysql> EXPLAIN SELECT * FROM t1 WHERE a>=1 AND a<=100;\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------+\n| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra                 |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------+\n|  1 | SIMPLE      | t1    | NULL       | range | a             | a    | 5       | NULL |  100 |   100.00 | Using index condition |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------+\n1 row in set, 1 warning (0.00 sec)\n\nmysql> SET optimizer_switch='mrr_cost_based=off';\nQuery OK, 0 rows affected (0.00 sec)\n\n-- 优化器选择了MRR\nmysql> EXPLAIN SELECT * FROM t1 WHERE a>=1 AND a<=100;\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+----------------------------------+\n| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra                            |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+----------------------------------+\n|  1 | SIMPLE      | t1    | NULL       | range | a             | a    | 5       | NULL |  100 |   100.00 | Using index condition; Using MRR |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+----------------------------------+\n```\n\n#### 小结\nMRR提升性能的核心：能够在索引a上做**范围查询**，得到**足够多的主键**，完成**排序**后再回表，体现出**顺序性**的优势\n\n## NLJ优化\n\n### NLJ算法\n从驱动表t1，一行行地取出a的值，再到被驱动表t2去join，此时**没有利用到MRR的优势**\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-join-nlj.jpg\" width=600/>\n\n\n### BKA优化\n`Batched Key Access`，是MySQL 5.6引入的对`Index Nested-Loop Join`（`NLJ`）的优化\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-join-opt-bka.jpg\" width=600/>\n\n1. `BKA`优化的思路：**复用`join_buffer`**\n2. 在`BNL`算法中，利用了`join_buffer`来暂存驱动表的数据，但在`NLJ`里面并没有利用到`join_buffer`\n3. 在`join_buffer`中放入的数据为P1~P100，表示只会取**查询所需要的字段**\n    - 如果`join_buffer`放不下P1~P100，就会将这100行数据**分成多段**执行\n\n### 启用\n```sql\n-- BKA算法依赖于MRR\nSET optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';\n```\n\n## BNL优化\n\n### 性能问题\n1. 使用`BNL`算法，可能会**对被驱动表做多次扫描**，如果被驱动表是一个**大的冷数据表**，首先**IO压力会增大**\n2. Buffer Pool的LRU算法\n    - 第一次从磁盘读入内存的数据页，会先放在`old`区\n    - 如果1s后这个数据页不再被访问，就不会被移动到LRU链表头部，对Buffer Pool的命中率影响不大\n3. 如果一个使用了BNL算法的Join语句，多次扫描一个冷表\n    - 如果**冷表不大**，能够**完全放入old区**\n        - 再次扫描冷表的时候，会把冷表的数据页移到LRU链表头部，**不属于期望的晋升**\n    - 如果**冷表很大**，_**业务正常访问的数据页，可能没有机会进入young区**_\n        - 一个正常访问的数据页，要进入young区，需要隔1S后再次被访问\n        - 由于Join语句在循环读磁盘和淘汰内存页，进入old区的数据页，很有可能在1S内被淘汰\n        - 正常业务访问的数据页也**一并被冲掉**，影响正常业务的内存命中率\n4. 大表Join虽然对IO有影响，但在语句执行结束后，对IO的影响也就结束了\n    - 但**对Buffer Pool的影响是持续性的**，需要依靠后续的查询请求慢慢恢复内存命中率\n    - 为了减少这种影响，可以考虑适当地增大`join_buffer_size`，减少对被驱动表的扫描次数\n5. 小结\n    - 可能会多次扫描**被驱动表**，占用磁盘**IO资源**\n    - 判断Join条件需要执行$M\\*N$次对比，如果是大表会占用非常多的**CPU资源**\n    - 可能会导致Buffer Pool的**热数据被淘汰**和**正常的业务数据无法成为热数据**，进而影响**内存命中率**\n6. 如果优化器选择了`BNL`算法，就需要做优化\n    - 给被驱动表**Join字段**加索引，把`BNL`算法转换成`BKA`算法\n    - 临时表\n\n### 不适合建索引\nt2中需要参与Join的只有2000行，并且为一个**低频语句**，为此在t2.b上建索引是比较浪费的\n```sql\nSELECT * FROM t1 JOIN t2 ON (t1.b=t2.b) WHERE t2.b>=1 AND t2.b<=2000;\n```\n\n#### 采用BNL\n1. 取出t1的所有字段，存入`join_buffer`（无序数组），完全放得下\n2. 扫描t2，取出每一行数据跟`join_buffer`中的数据进行对比\n    - 如果不满足`t1.b=t2.b`，则跳过\n    - 如果**满足**`t1.b=t2.b`，_**再判断是否满足其它条件**_，如果满足就作为结果集的一部分返回，否则跳过\n3. 等值判断的次数为1000*100W=**10亿**，计算量很大\n\n```sql\n-- 使用BNL算法\nmysql> EXPLAIN SELECT * FROM t1 JOIN t2 ON (t1.b=t2.b) WHERE t2.b>=1 AND t2.b<=2000;\n+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows   | filtered | Extra                                              |\n+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+\n|  1 | SIMPLE      | t1    | NULL       | ALL  | NULL          | NULL | NULL    | NULL |   1000 |   100.00 | Using where                                        |\n|  1 | SIMPLE      | t2    | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 998414 |     1.11 | Using where; Using join buffer (Block Nested Loop) |\n+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+\n\n-- 执行耗时为75S，非常久！\nmysql> SELECT * FROM t1 JOIN t2 ON (t1.b=t2.b) WHERE t2.b>=1 AND t2.b<=2000;\n...\n|  999 |    2 |  999 |  999 |  999 |  999 |\n| 1000 |    1 | 1000 | 1000 | 1000 | 1000 |\n+------+------+------+------+------+------+\n1000 rows in set (1 min 15.29 sec)\n\n# Time: 2019-03-11T12:04:49.066846Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 75.288703  Lock_time: 0.000174 Rows_sent: 1000  Rows_examined: 1001000\nSET timestamp=1552305889;\nSELECT * FROM t1 JOIN t2 ON (t1.b=t2.b) WHERE t2.b>=1 AND t2.b<=2000;\n```\n\n#### 临时表\n\n##### 思路\n1. 把t2中满足条件的数据先放到临时表tmp_t中\n2. 为了让join使用`BKA`算法，给临时表tmp_t的字段b加上索引\n3. 让表t1和tmp_t做join操作\n\n##### 执行过程\n```sql\nCREATE TEMPORARY TABLE temp_t (id INT PRIMARY KEY, a INT, b INT, INDEX(b)) ENGINE=InnoDB;\nINSERT INTO temp_t SELECT * FROM t2 WHERE b>=1 AND b<=2000;\n\n# Time: 2019-03-11T12:20:01.810030Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 0.624821  Lock_time: 0.002347 Rows_sent: 0  Rows_examined: 1000000\nSET timestamp=1552306801;\nINSERT INTO temp_t SELECT * FROM t2 WHERE b>=1 AND b<=2000;\n\n-- 采用NLJ算法，如果batched_key_access=on，将采用BKA优化\nmysql> EXPLAIN SELECT * FROM t1 JOIN temp_t ON (t1.b=temp_t.b);\n+----+-------------+--------+------------+------+---------------+------+---------+-----------+------+----------+-------------+\n| id | select_type | table  | partitions | type | possible_keys | key  | key_len | ref       | rows | filtered | Extra       |\n+----+-------------+--------+------------+------+---------------+------+---------+-----------+------+----------+-------------+\n|  1 | SIMPLE      | t1     | NULL       | ALL  | NULL          | NULL | NULL    | NULL      | 1000 |   100.00 | Using where |\n|  1 | SIMPLE      | temp_t | NULL       | ref  | b             | b    | 5       | test.t1.b |    1 |   100.00 | NULL        |\n+----+-------------+--------+------------+------+---------------+------+---------+-----------+------+----------+-------------+\n\n-- 执行耗时为20ms，提升很大\nmysql> SELECT * FROM t1 JOIN temp_t ON (t1.b=temp_t.b);\n...\n|  999 |    2 |  999 |  999 |  999 |  999 |\n| 1000 |    1 | 1000 | 1000 | 1000 | 1000 |\n+------+------+------+------+------+------+\n1000 rows in set (0.02 sec)\n\n# Time: 2019-03-11T12:20:11.041259Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 0.012139  Lock_time: 0.000187 Rows_sent: 1000  Rows_examined: 2000\nSET timestamp=1552306811;\nSELECT * FROM t1 JOIN temp_t ON (t1.b=temp_t.b);\n```\n1. 执行`INSERT`语句构造tmp_t表并插入数据的过程中，对t2做了**全表扫描**，扫描行数为100W\n2. JOIN语句先扫描t1，扫描行数为1000，在JOIN的比较过程中，做了1000次**带索引的查询**\n\n#### Hash Join\n1. 如果`join_buffer`维护的不是一个无序数组，而是一个**哈希表**，那只需要100W次哈希查找即可\n2. MySQL目前不支持`Hash Join`，业务端可以自己实现`Hash Join`\n    - `SELECT * FROM t1`\n        - 取t1的全部1000行数据，在业务端存入一个hash结构（如`java.util.HashMap`）\n    - `SELECT * FROM t2 WHERE b>=1 AND b<=2000`，获取t2中满足条件的2000行数据\n    - 把这2000行数据，一行行地到hash结构去匹配，将满足匹配条件的行数据，作为结果集的一行\n\n## 小结\n1. `BKA`是MySQL**内置支持**的，_**推荐使用**_\n2. `BNL`算法**效率低**，建议都尽量换成`BKA`算法，优化的方向是**给被驱动表的关联字段加上索引**\n3. 基于**临时表**的改进方案，对于能够**提前过滤出小数据的JOIN语句**来说，效果还是很明显的\n4. MySQL目前还不支持`Hash Join`\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- JOIN","url":"%2F2019%2F03%2F10%2Fmysql-join%2F","content":"\n## 表初始化\n```sql\nCREATE TABLE `t2` (\n    `id` INT(11) NOT NULL,\n    `a` INT(11) DEFAULT NULL,\n    `b` INT(11) DEFAULT NULL,\n    PRIMARY KEY (`id`),\n    KEY `a` (`a`)\n) ENGINE=InnoDB;\n\nDROP PROCEDURE IF EXISTS idata;\nDELIMITER ;;\nCREATE PROCEDURE idata()\nBEGIN\n  DECLARE i INT;\n  SET i=1;\n  WHILE (i <= 1000) DO\n    INSERT INTO t2 VALUES (i,i,i);\n    SET i=i+1;\n  END WHILE;\nEND;;\nDELIMITER ;\nCALL idata();\n\nCREATE TABLE t1 LIKE t2;\nINSERT INTO t1 (SELECT * FROM t2 WHERE id<=100);\n```\n\n<!-- more -->\n\n## Index Nested-Loop Join\n```sql\n-- 使用JOIN，优化器可能会选择t1或t2作为驱动表\n-- 使用STRAIGHT_JOIN，使用固定的连接关系，t1为驱动表，t2为被驱动表\nSELECT * FROM t1 STRAIGHT_JOIN t2 ON (t1.a=t2.a);\n\nmysql> EXPLAIN SELECT * FROM t1 STRAIGHT_JOIN t2 ON (t1.a=t2.a);\n+----+-------------+-------+------------+------+---------------+------+---------+-----------+------+----------+-------------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref       | rows | filtered | Extra       |\n+----+-------------+-------+------------+------+---------------+------+---------+-----------+------+----------+-------------+\n|  1 | SIMPLE      | t1    | NULL       | ALL  | a             | NULL | NULL    | NULL      |  100 |   100.00 | Using where |\n|  1 | SIMPLE      | t2    | NULL       | ref  | a             | a    | 5       | test.t1.a |    1 |   100.00 | NULL        |\n+----+-------------+-------+------------+------+---------------+------+---------+-----------+------+----------+-------------+\n```\n\n### 执行过程\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-join-nlj.jpg\" width=600/>\n\n1. 从t1读取一行数据R\n2. 从R中取出字段a，然后到t2去查找\n3. 取出t2中满足条件的行，与R组成一行，作为结果集的一部分\n4. 重复上面步骤，直至遍历t1完毕\n\n### 扫描行数\n1. 对驱动表t1做**全表扫描**，需要扫描100行\n2. 对每一行R，根据字段a去t2查找，走的是树**搜索过程**\n    - 构造的数据都是一一对应，总共扫描100行\n3. 因此，整个执行流程，总扫描行数为200行\n\n```sql\n# Time: 2019-03-10T11:06:13.271095Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 0.001391  Lock_time: 0.000135 Rows_sent: 100  Rows_examined: 200\nSET timestamp=1552215973;\nSELECT * FROM t1 STRAIGHT_JOIN t2 ON (t1.a=t2.a);\n```\n\n### 不使用Join\n1. 执行`SELECT * FROM t1`，扫描100行\n2. 循环遍历100行数据\n    - 从每一行R中取出字段a的值`$R.a`\n    - 执行`SELECT * FROM t2 WHERE a=$R.a`\n    - 把返回的结果和R构成结果集的一行\n3. 对比Join\n    - 同样扫描了200行，但总共**执行了101条语句**，客户端还需要**自己拼接**SQL语句和结果\n\n### 选择驱动表\n1. 上面的查询语句，**驱动表走全部扫描**，**被驱动表走树搜索**\n2. 假设被驱动表的行数为M\n    - 每次在被驱动表上查一行数据，需要先搜索**辅助索引a**，再搜索**主键索引**\n    - 因此，在被驱动表上查一行的时间复杂度是 $2\\*\\log_2 M$\n3. 假设驱动表的行数为N，需要扫描驱动表N行\n4. 整个执行过程，时间复杂度为 $N + N\\*2\\*\\log_2 M$\n    - N对扫描行数的影响更大，因此选择**小表做驱动表**\n\n## Simple Nested-Loop Join\n```sql\nSELECT * FROM t1 STRAIGHT_JOIN t2 ON (t1.a=t2.b);\n```\n1. 被驱动表t2的字段b上**没有索引**，因此每次到t2去做匹配的时候，都要做一次**全表扫描**\n2. 按照上面的算法，时间复杂度为 $N + N\\*M$，总扫描行数为100,100次（**10W**）\n    - 假如t1和t2都是10W行数据，那么总扫描次数为10,000,100,000次（**100\u0010亿**）\n    - 因此，MySQL本身没有使用`Simple Nested-Loop Join`算法\n\n## Block Nested-Loop Join\n针对场景：**被驱动表上没有可用的索引**\n\n### join_buffer充足\n\n#### 执行过程\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-join-blj.jpg\" width=600/>\n\n1. 把t1的数据读入线程内存`join_buffer`，执行的是`SELECT *`，因此会把整个t1读入`join_buffer`\n2. 扫描t2，把t2中的每一行取出来，与`join_buffer`中的数据做对比\n    - 如果满足join条件的行，作为结果集的一部分返回\n\n```sql\n-- 默认为256KB\n-- 4194304 Bytes == 4 MB\nmysql> SHOW VARIABLES LIKE '%join_buffer_size%';\n+------------------+---------+\n| Variable_name    | Value   |\n+------------------+---------+\n| join_buffer_size | 4194304 |\n+------------------+---------+\n```\n\n#### EXPLAIN\n```sql\nmysql> EXPLAIN SELECT * FROM t1 STRAIGHT_JOIN t2 ON (t1.a=t2.b);\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------------------------------------------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                                              |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------------------------------------------+\n|  1 | SIMPLE      | t1    | NULL       | ALL  | a             | NULL | NULL    | NULL |  100 |   100.00 | NULL                                               |\n|  1 | SIMPLE      | t2    | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 1000 |    10.00 | Using where; Using join buffer (Block Nested Loop) |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------------------------------------------+\n\n# Time: 2019-03-10T12:19:57.245356Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 0.010132  Lock_time: 0.000192 Rows_sent: 100  Rows_examined: 1100\nSET timestamp=1552220397;\nSELECT * FROM t1 STRAIGHT_JOIN t2 ON (t1.a=t2.b);\n```\n1. 整个过程中，对t1和t2都做了一次**全表扫描**，总扫描行数为**1100**\n2. 由于`join_buffer`是**以无序数组**的方式组织的，因此对t2的每一行数据，都需要做100次判断\n    - 因此，在内存中的总判断次数为100,000次\n3. `Simple Nested-Loop Join`的扫描行数也是100,000次，**时间复杂度是一样的**\n    - 但`Block Nested-Loop Join`的100,000次判断是**内存操作**，**速度会快很多**\n    - `Simple Nested-Loop Join`可能会涉及**磁盘操作**（全表扫描）\n\n#### 选择驱动表\n1. 假设小表的行数为N，大表的行数为M\n2. 两个表都要做一次**全表扫描**，总扫描行数为`M+N`\n3. 内存中的判断次数是`M*N`\n4. 此时，选择大表还是小表作为驱动表，_**没有任何差异**_\n\n### join_buffer不足\n```sql\n-- 放不下t1的所有数据，采取分段放的策略\nSET join_buffer_size=1200;\n\n# Time: 2019-03-10T12:30:32.194726Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 0.009459  Lock_time: 0.000559 Rows_sent: 100  Rows_examined: 2100\nSET timestamp=1552221032;\nSELECT * FROM t1 STRAIGHT_JOIN t2 ON (t1.a=t2.b);\n```\n\n#### 执行过程\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-join-blj-not-enough.jpg\" width=600/>\n\n1. 扫描t1，顺序读取数据行放入`join_buffer`，放完第88行后`join_buffer`满，继续第2步\n2. 扫描t2，把t2中的每一行取出来，跟`join_buffer`中的数据做对比\n    - 如果满足join条件的行，作为结果集的一部分返回\n3. 清空`join_buffer`（为了**复用**，体现**Block**的核心思想）\n4. 继续扫描t1，顺序取最后12行数据加入`join_buffer`，继续执行第2步\n\n#### 性能\n1. 由于t1被分成了两次加入`join_buffer`，导致t2会被扫描两次，因此总扫描行数为**2100**\n2. 但是内存的判断次数还是不变的，依然是100,000次\n\n#### 选择驱动表\n1. 假设驱动表的数据行数为N，需要分K段才能完成算法流程，被驱动表的数据行数为M\n    - K并非常数，N越大K越大，定义：$K=N\\*\\lambda, \\lambda \\in (0,1]$\n    - 在`join_buffer_size`固定且t1和2表类似的情况下，$\\lambda$是常量\n2. 扫描行数为 $N + \\lambda\\*N\\*M$\n    - 减少N比减少M，扫描的行数会更小\n    - 因此选择**小表当驱动表**\n3. 内存判断次数为 $N\\*M$（**无需考虑**）\n4. 如果要减少$\\lambda$的值，可以加大`join_buffer_size`的值，一次性放入的行越多，分段就越少\n\n### 对比Simple Nested-Loop Join\n1. `Simple Nested-Loop Join`需要对**被驱动表**做**全表扫描**\n2. 对被驱动表做全表扫描的时候，如果数据没有在Buffer Pool中，就需要等待这部分数据从磁盘读入\n    - 从磁盘读入数据到内存，会影响**正常业务的Buffer Pool命中率**\n        - `Simple Nested-Loop Join`算法天然会对被驱动表的数据做多次访问\n        - 因此，更容易将这些数据页放到Buffer Pool的头部\n3. 即使被驱动表的数据**都在内存中**，`BNL`算法的**遍历成本更低**\n    - `Simple Nested-Loop Join`遍历的是Buffer Pool，采用**链表**的形式\n    - `BNL`遍历的是`join_buffer`，采用**数组**的形式\n3. 因此`BNL`算法的性能会更好\n\n## 小表\n```sql\n-- 恢复为默认值256KB\nSET join_buffer_size=262144;\n```\n\n### 过滤行数\n\n#### t1为驱动表\n```sql\nmysql> EXPLAIN SELECT * FROM t1 STRAIGHT_JOIN t2 ON (t1.b=t2.b) WHERE t2.id<=50;\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra                                              |\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n|  1 | SIMPLE      | t1    | NULL       | ALL   | NULL          | NULL    | NULL    | NULL |  100 |   100.00 | NULL                                               |\n|  1 | SIMPLE      | t2    | NULL       | range | PRIMARY       | PRIMARY | 4       | NULL |   50 |    10.00 | Using where; Using join buffer (Block Nested Loop) |\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n\n# Time: 2019-03-10T13:15:50.346563Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 0.001006  Lock_time: 0.000162 Rows_sent: 50  Rows_examined: 150\nSET timestamp=1552223750;\nSELECT * FROM t1 STRAIGHT_JOIN t2 ON (t1.b=t2.b) WHERE t2.id<=50;\n```\n\n#### t2为驱动表\n`join_buffer`只需要放入t2的前50行，因此**t2的前50行**相对于**t1的所有行**来说是一个**更小的表**\n```sql\nmysql> EXPLAIN SELECT * FROM t2 STRAIGHT_JOIN t1 ON (t1.b=t2.b) WHERE t2.id<=50;\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra                                              |\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n|  1 | SIMPLE      | t2    | NULL       | range | PRIMARY       | PRIMARY | 4       | NULL |   50 |   100.00 | Using where                                        |\n|  1 | SIMPLE      | t1    | NULL       | ALL   | NULL          | NULL    | NULL    | NULL |  100 |    10.00 | Using where; Using join buffer (Block Nested Loop) |\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n\n# Time: 2019-03-10T13:18:26.656339Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 0.000965  Lock_time: 0.000150 Rows_sent: 50  Rows_examined: 150\nSET timestamp=1552223906;\nSELECT * FROM t2 STRAIGHT_JOIN t1 ON (t1.b=t2.b) WHERE t2.id<=50;\n```\n\n#### 优化器选择\n```sql\n-- 选择t2作为驱动表\nmysql> EXPLAIN SELECT * FROM t1 JOIN t2 ON (t1.b=t2.b) WHERE t2.id<=50;\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra                                              |\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n|  1 | SIMPLE      | t2    | NULL       | range | PRIMARY       | PRIMARY | 4       | NULL |   50 |   100.00 | Using where                                        |\n|  1 | SIMPLE      | t1    | NULL       | ALL   | NULL          | NULL    | NULL    | NULL |  100 |    10.00 | Using where; Using join buffer (Block Nested Loop) |\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n```\n\n### 列数量\n\n#### t1为驱动表\nt1只查字段b，如果将t1放入`join_buffer`，只需要放入字段b的值\n```sql\nmysql> EXPLAIN SELECT t1.b,t2.* FROM t1 STRAIGHT_JOIN t2 ON (t1.b=t2.b) WHERE t2.id<=100;\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra                                              |\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n|  1 | SIMPLE      | t1    | NULL       | ALL   | NULL          | NULL    | NULL    | NULL |  100 |   100.00 | NULL                                               |\n|  1 | SIMPLE      | t2    | NULL       | range | PRIMARY       | PRIMARY | 4       | NULL |  100 |    10.00 | Using where; Using join buffer (Block Nested Loop) |\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n\n# Time: 2019-03-10T13:23:55.558748Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 0.002742  Lock_time: 0.000123 Rows_sent: 100  Rows_examined: 200\nSET timestamp=1552224235;\nSELECT t1.b,t2.* FROM t1 STRAIGHT_JOIN t2 ON (t1.b=t2.b) WHERE t2.id<=100;\n```\n\n#### t2为驱动表\nt2要查所有的字段，如果将t2放入`join_buffer`，要放入三个字段`id`、`a`和`b`，因此t1是**更小的表**\n```sql\nmysql> EXPLAIN SELECT t1.b,t2.* FROM t2 STRAIGHT_JOIN t1 on (t1.b=t2.b) WHERE t2.id<=100;\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra                                              |\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n|  1 | SIMPLE      | t2    | NULL       | range | PRIMARY       | PRIMARY | 4       | NULL |  100 |   100.00 | Using where                                        |\n|  1 | SIMPLE      | t1    | NULL       | ALL   | NULL          | NULL    | NULL    | NULL |  100 |    10.00 | Using where; Using join buffer (Block Nested Loop) |\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n\n# Time: 2019-03-10T13:24:51.561116Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 0.002680  Lock_time: 0.000907 Rows_sent: 100  Rows_examined: 200\nSET timestamp=1552224291;\nSELECT t1.b,t2.* FROM t2 STRAIGHT_JOIN t1 on (t1.b=t2.b) WHERE t2.id<=100;\n```\n\n#### 优化器选择\n```sql\n-- 但优化器依然选择了t2作为驱动表\nmysql> EXPLAIN SELECT t1.b,t2.* FROM t2 JOIN t1 on (t1.b=t2.b) WHERE t2.id<=100;\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra                                              |\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n|  1 | SIMPLE      | t2    | NULL       | range | PRIMARY       | PRIMARY | 4       | NULL |  100 |   100.00 | Using where                                        |\n|  1 | SIMPLE      | t1    | NULL       | ALL   | NULL          | NULL    | NULL    | NULL |  100 |    10.00 | Using where; Using join buffer (Block Nested Loop) |\n+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+----------------------------------------------------+\n```\n\n### 小结\n选择驱动表时，应该是**按照各自的条件过滤**，然后**计算参与join的各个字段的总数据量**，数量量小的表，才是小表\n\n## 常见问题\n1. 能否可以使用Join\n    - 如果使用`Index Nested-Loop Join`，即**用上了被驱动表上的索引**，其实**问题不大**\n    - 如果使用`Block Nested-Loop Join`，**扫描行数可能会过多**，**尽量避免使用**，通过`EXPLAIN`确认\n2. 选择小表还是大表作为驱动表\n    - 如果使用`Index Nested-Loop Join`，选择**小表**作为驱动表\n    - 如果使用`Block Nested-Loop Join`\n        - `join_buffer`充足时，**没有区别**\n        - `join_buffer`不足时（更常见），选择**小表**作为驱动表\n    - 结论：**选择小表做驱动表**\n\n## LEFT JOIN\n\n### 表初始化\n```sql\nCREATE TABLE a(f1 INT, f2 INT, INDEX(f1)) ENGINE=InnoDB;\nCREATE TABLE b(f1 INT, f2 INT) ENGINE=InnoDB;\nINSERT INTO a VALUES (1,1),(2,2),(3,3),(4,4),(5,5),(6,6);\nINSERT INTO b VALUES (3,3),(4,4),(5,5),(6,6),(7,7),(8,8);\n\n-- Q1\nmysql> SELECT * FROM a LEFT JOIN b ON (a.f1=b.f1) AND (a.f2=b.f2);\n+------+------+------+------+\n| f1   | f2   | f1   | f2   |\n+------+------+------+------+\n|    3 |    3 |    3 |    3 |\n|    4 |    4 |    4 |    4 |\n|    5 |    5 |    5 |    5 |\n|    6 |    6 |    6 |    6 |\n|    1 |    1 | NULL | NULL |\n|    2 |    2 | NULL | NULL |\n+------+------+------+------+\n\n-- Q2\nmysql> SELECT * FROM a LEFT JOIN b ON (a.f1=b.f1) WHERE (a.f2=b.f2);\n+------+------+------+------+\n| f1   | f2   | f1   | f2   |\n+------+------+------+------+\n|    3 |    3 |    3 |    3 |\n|    4 |    4 |    4 |    4 |\n|    5 |    5 |    5 |    5 |\n|    6 |    6 |    6 |    6 |\n+------+------+------+------+\n```\n\n### Q1\n```sql\nmysql> EXPLAIN SELECT * FROM a LEFT JOIN b ON (a.f1=b.f1) AND (a.f2=b.f2);\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------------------------------------------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                                              |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------------------------------------------+\n|  1 | SIMPLE      | a     | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    6 |   100.00 | NULL                                               |\n|  1 | SIMPLE      | b     | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    6 |   100.00 | Using where; Using join buffer (Block Nested Loop) |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------------------------------------------+\n```\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-left-join-bnl.jpg\" width=600/>\n\n1. 驱动表是表a，被驱动表是表b，与使用`STRAIGHT_JOIN`的效果一致\n2. 由于表b的字段f1上没有索引，所以使用的是`BNL`算法\n    - 把表a的内容读入`join_buffer`中\n        - 因为是`SELECT *`，所以字段f1和字段f2都被放入到`join_buffer`中\n    - 顺序扫描表b，对于每一行数据，判断`JOIN`条件（a.f1=b.f1 and a.f2=b.f2）是否满足\n        - 如果满足条件，作为结果集的一行返回\n        - 如果语句中有`WHERE`字句，先判断WHERE部分满足条件后，再返回\n    - 表b扫描完成后，对于没有被匹配的表a的行，把剩余字段补上`NULL`，再放入到结果集\n\n### Q2\n```sql\nmysql> EXPLAIN SELECT * FROM a LEFT JOIN b ON (a.f1=b.f1) WHERE (a.f2=b.f2);\n+----+-------------+-------+------------+------+---------------+------+---------+-----------+------+----------+-------------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref       | rows | filtered | Extra       |\n+----+-------------+-------+------------+------+---------------+------+---------+-----------+------+----------+-------------+\n|  1 | SIMPLE      | b     | NULL       | ALL  | NULL          | NULL | NULL    | NULL      |    6 |   100.00 | Using where |\n|  1 | SIMPLE      | a     | NULL       | ref  | f1            | f1   | 5       | test.b.f1 |    1 |    16.67 | Using where |\n+----+-------------+-------+------------+------+---------------+------+---------+-----------+------+----------+-------------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> SHOW WARNINGS\\G;\n*************************** 1. row ***************************\n  Level: Note\n   Code: 1003\nMessage: /* select#1 */ select `test`.`a`.`f1` AS `f1`,`test`.`a`.`f2` AS `f2`,`test`.`b`.`f1` AS `f1`,`test`.`b`.`f2` AS `f2` from `test`.`a` join `test`.`b` where ((`test`.`a`.`f1` = `test`.`b`.`f1`) and (`test`.`a`.`f2` = `test`.`b`.`f2`))\n\n```\n1. 驱动表是表b\n2. 如果一条`JOIN`语句的`Extra`字段什么都没写，表示使用的是`NLJ`算法\n    - 顺序扫描表b，每一行用`b.f1`去表a查，匹配到记录后判断`a.f2=b.f2`是否满足\n    - 如果满足条件的话，作为结果集的一部分返回\n    - 在MySQL里，**NULL跟任何值执行等值判断和不等值判断的结果都是NULL**\n        - `SELECT NULL = NULL`，返回的也是NULL\n        - `WHERE (a.f2=b.f2)`表示查询结果里不会包含**`b.f2`为NULL**的行\n4. 虽然使用的是`LEFT JOIN`，但语义跟`JOIN`是一致的\n    - 优化器把这条语句的`LEFT JOIN`改写成了`JOIN`，参照`SHOW WARNINGS`的输出\n    - 因为表a的字段f1上有索引，就把表b作为驱动表，可以用上`NLJ`算法\n\n#### 小结\n1. 使用`LEFT JOIN`，_**左边的表不一定是驱动表**_\n2. 因此，如果要使用`LEFT JOIN`语义\n    - 就不能把**被驱动表的字段**放在WHERE条件里面的**等值判断**或**不等值判断**\n    - _**必须都写在ON里面**_\n\n### Q3 + Q4\n```sql\n-- Q3\nmysql> EXPLAIN SELECT * FROM a JOIN b ON (a.f1=b.f1) AND (a.f2=b.f2);\n+----+-------------+-------+------------+------+---------------+------+---------+-----------+------+----------+-------------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref       | rows | filtered | Extra       |\n+----+-------------+-------+------------+------+---------------+------+---------+-----------+------+----------+-------------+\n|  1 | SIMPLE      | b     | NULL       | ALL  | NULL          | NULL | NULL    | NULL      |    6 |   100.00 | Using where |\n|  1 | SIMPLE      | a     | NULL       | ref  | f1            | f1   | 5       | test.b.f1 |    1 |    16.67 | Using where |\n+----+-------------+-------+------------+------+---------------+------+---------+-----------+------+----------+-------------+\n\nmysql> SHOW WARNINGS\\G;\n*************************** 1. row ***************************\n  Level: Note\n   Code: 1003\nMessage: /* select#1 */ select `test`.`a`.`f1` AS `f1`,`test`.`a`.`f2` AS `f2`,`test`.`b`.`f1` AS `f1`,`test`.`b`.`f2` AS `f2` from `test`.`a` join `test`.`b` where ((`test`.`a`.`f2` = `test`.`b`.`f2`) and (`test`.`a`.`f1` = `test`.`b`.`f1`))\n\n-- Q4\nmysql> EXPLAIN SELECT * FROM a JOIN b ON (a.f1=b.f1) WHERE (a.f2=b.f2);\n+----+-------------+-------+------------+------+---------------+------+---------+-----------+------+----------+-------------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref       | rows | filtered | Extra       |\n+----+-------------+-------+------------+------+---------------+------+---------+-----------+------+----------+-------------+\n|  1 | SIMPLE      | b     | NULL       | ALL  | NULL          | NULL | NULL    | NULL      |    6 |   100.00 | Using where |\n|  1 | SIMPLE      | a     | NULL       | ref  | f1            | f1   | 5       | test.b.f1 |    1 |    16.67 | Using where |\n+----+-------------+-------+------------+------+---------------+------+---------+-----------+------+----------+-------------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> SHOW WARNINGS\\G;\n*************************** 1. row ***************************\n  Level: Note\n   Code: 1003\nMessage: /* select#1 */ select `test`.`a`.`f1` AS `f1`,`test`.`a`.`f2` AS `f2`,`test`.`b`.`f1` AS `f1`,`test`.`b`.`f2` AS `f2` from `test`.`a` join `test`.`b` where ((`test`.`a`.`f1` = `test`.`b`.`f1`) and (`test`.`a`.`f2` = `test`.`b`.`f2`))\n```\n1. Q3和Q4都被改写成\n    - `SELECT * FROM a JOIN b WHERE (a.f1=b.f1) AND (a.f2=b.f2)`\n2. `JOIN`语句：_**将判断条件是否全部放在ON部分是没有区别的**_\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 全表扫描","url":"%2F2019%2F03%2F08%2Fmysql-full-table-scan%2F","content":"\n## Server层\n```sql\n-- db1.t有200GB\nmysql -h$host -P$port -u$user -p$pwd -e \"select * from db1.t\" > $target_file\n```\n\n### 查询数据\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-query-send-data.jpg\" width=800/>\n\n\n<!-- more -->\n\n1. InnoDB的数据是保存在主键索引上，全表扫描实际上是直接扫描表t的主键索引\n2. 获取一行，写到`net_buffer`中，默认为**16K**，控制参数为`net_buffer_length`\n3. 重复获取行，直到**写满**`net_buffer`，然后调用网络接口发出去\n4. 如果发送成功，就**清空**`net_buffer`，然后继续取下一行并写入`net_buffer`\n5. 如果发送函数返回`EAGAIN`或者`WSAEWOULDBLOCK`，表示本地网络栈`socket send buffer`写满\n    - 此时，进入等待，直到网络栈重新可写，再继续发送\n6. 一个查询在发送数据的过程中，占用MySQL内部的内存最大为`net_buffer_length`，因此不会达到200G\n7. `socket send buffer`也不可能达到200G，如果`socket send buffer`被写满，就会暂停读取数据\n\n```sql\n-- 16384 Bytes = 16 KB\nmysql> SHOW VARIABLES LIKE '%net_buffer_length%';\n+-------------------+-------+\n| Variable_name     | Value |\n+-------------------+-------+\n| net_buffer_length | 16384 |\n+-------------------+-------+\n```\n\n### Sending to client\n1. MySQL是**边读边发**的，如果**客户端接收慢**，会导致MySQL服务端由于**结果发不出去**，**事务的执行时间变长**\n2. 下图为MySQL客户端不读取`socket receive buffer`中的内容的场景\n    - State为`Sending to client`，表示服务端的网络栈写满了\n3. `mysql --quick`，会使用`mysql_use_result`方法，该方法会**读取一行处理一行**\n    - 假设每读出一行数据后要处理的逻辑很慢，就会导致客户端要过很久才会去取下一行数据\n    - 这时也会出现State为`Sending to client`的情况\n    - 对于正常的线上业务，如果单个查询返回的结果不多，推荐使用`mysql_store_result`接口\n    - 适当地调大`net_buffer_length`可能是个更优的解决方案\n\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-client-do-not-receive.png\" width=800/>\n\n\n### Sending data\n\n#### State切换\n1. MySQL的**查询语句**在进入**执行阶段**后，首先把State设置为`Sending data`\n2. 然后，发送执行结果的**列相关的信息**（**meta data**）给客户端\n3. 再继续执行语句的流程，执行完成后，把State设置为**空字符串**\n4. 因此State为`Sending data`不等同于**正在发送数据**\n\n#### 样例\n```sql\nCREATE TABLE `t` (\n    `id` int(11) NOT NULL,\n    `c` int(11) NOT NULL,\n    PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\nINSERT INTO t VALUES (1,1);\n```\n\n| session A | session B |\n| ---- | ---- |\n| BEGIN; | |\n| SELECT * FROM t WHERE id=1 FOR UPDATE; | |\n| | SELECT * FROM t LOCK IN SHARE MODE;<br/>(Blocked) |\n\n```sql\nmysql> SHOW PROCESSLIST;\n+----+-----------------+-----------+------+---------+--------+------------------------+------------------------------------+\n| Id | User            | Host      | db   | Command | Time   | State                  | Info                               |\n+----+-----------------+-----------+------+---------+--------+------------------------+------------------------------------+\n|  4 | event_scheduler | localhost | NULL | Daemon  | 713722 | Waiting on empty queue | NULL                               |\n| 37 | root            | localhost | test | Sleep   |     35 |                        | NULL                               |\n| 38 | root            | localhost | test | Query   |     15 | Sending data           | SELECT * FROM t LOCK IN SHARE MODE |\n| 39 | root            | localhost | NULL | Query   |      0 | starting               | show processlist                   |\n+----+-----------------+-----------+------+---------+--------+------------------------+------------------------------------+\n```\n\n## InnoDB层\n1. 内存的数据页是在`Buffer Pool`中管理的\n2. 作用：**加速更新**（WAL机制）+**加速查询**\n\n### 内存命中率\n1. `SHOW ENGINE INNODB STATUS`中的`Buffer pool hit rate 990 / 1000`，表示命中率为99%\n2. `Buffer Pool`的大小由参数`innodb_buffer_pool_size`控制，一般设置为物理内存的`60%~80%`\n3. `Buffer Pool`一般都会小于磁盘的数据量，InnoDB将采用`LRU`算法来淘汰数据页\n\n```sql\n-- 134217728 Bytes = 128 MB\nmysql> SHOW VARIABLES LIKE '%innodb_buffer_pool_size%';\n+-------------------------+-----------+\n| Variable_name           | Value     |\n+-------------------------+-----------+\n| innodb_buffer_pool_size | 134217728 |\n+-------------------------+-----------+\n```\n\n### 基本LRU\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-innodb-eliminate-strategy-lru.jpg\" width=800/>\n\n1. InnoDB采用的LRU算法，是基于**链表**实现的\n2. State1，链表头部是P1，表示P1是最近**刚刚被访问过**的数据页\n3. State2，有一个读请求访问P3，P3被移动到链表的最前面\n4. State3，要访问的数据页不在链表中，所以需要在`Buffer Pool`中新申请一个数据页Px，加到链表头部\n    - 但由于`Buffer Pool`已满，不能再申请新的数据页\n    - 于是会清空链表末尾Pm这个数据页的内存，存入Px的内容，并且放到链表头部\n\n### 冷数据全表扫描\n1. 扫描一个200G的表，该表为历史数据表，平时没有什么业务访问它\n2. 按照基本LRU算法，就会把当前Buffer Pool里面的数据**全部淘汰**，存入扫描过程中访问到的数据页\n3. 此时，对外提供业务服务的库来说，**Buffer Pool的命中率会急剧下降**，**磁盘压力增加**，**SQL语句响应变慢**\n4. 因此InnoDB采用了改进的LRU算法\n\n### 改进LRU\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-innodb-eliminate-strategy-lru-opt.png\" width=800/>\n\n1. 在InnoDB的实现上，按照`5:3`的比例把整个LRU链表分成`young`区和`old`区\n2. `LRU_old`指向old区的第一个位置，即靠近链表头部的`5/8`是`young`区，靠近链表尾部的`3/8`是`old`区\n3. State1，要访问数据页P3，由于P3在young区，与基本的LRU算法一样，将其移动到链表头部，变为State2\n4. 然后要访问一个不在当前链表的数据页，此时依然要淘汰数据页Pm，但新插入的数据页Px放在`LRU_old`\n5. 处于old区的数据页，每次被访问的时候都需要做以下判断\n    - 如果这个数据页在LRU链表中**存在的时间**超过了1S，就把它移动到链表头部，否则，位置不变\n    - 存在时间的值由参数`innodb_old_blocks_time`控制\n6. 该策略是为了处理类似**全表扫描**的操作而定制的\n    - 扫描过程中，需要**新插入的数据页**，都被放到`old`区\n    - **一个数据页会有多条记录**，因此**一个数据页会被访问多次**\n        - 但由于是_**顺序扫描**_\n        - 数据页的**第一次被访问**和**最后一次被访问**的时间间隔不会超过1S，因此还是会留在`old`区\n    - 继续扫描，之前的数据页再也不会被访问到，因此也不会被移到`young`区，**最终很快被淘汰**\n7. 该策略最大的收益是在扫描大表的过程中，虽然**用到了Buffer Pool，但对young区完全没有影响**\n    - _**保证了Buffer Pool响应正常业务的查询命中率**_\n\n```sql\n-- 1000ms = 1s\nmysql> SHOW VARIABLES LIKE '%innodb_old_blocks_time%';\n+------------------------+-------+\n| Variable_name          | Value |\n+------------------------+-------+\n| innodb_old_blocks_time | 1000  |\n+------------------------+-------+\n```\n\n### INNODB STATUS\n```sql\nmysql> SHOW ENGINE INNODB STATUS\\G;\n----------------------\nBUFFER POOL AND MEMORY\n----------------------\n-- 137428992 Bytes = 131.0625 MB\nTotal large memory allocated 137428992\nDictionary memory allocated 432277\n-- innodb_buffer_pool_size = 134217728 / 16 / 1024 / 1024 = 8192\n-- 6957 + 1223 = 8180 ≈ Buffer pool size\nBuffer pool size   8191\nFree buffers       6957\nDatabase pages     1223\n-- 1223 * 3 / 8 = 458.625 ≈ Old database pages\nOld database pages 465\nModified db pages  0\nPending reads      0\nPending writes: LRU 0, flush list 0, single page 0\n-- made young : old -> young\n-- not young : young -> old\nPages made young 0, not young 0\n0.00 youngs/s, 0.00 non-youngs/s\nPages read 1060, created 163, written 666\n0.00 reads/s, 0.00 creates/s, 0.00 writes/s\nNo buffer pool page gets since the last printout\nPages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/s\nLRU len: 1223, unzip_LRU len: 0\nI/O sum[0]:cur[0], unzip sum[0]:cur[0]\n```\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- KILL + 客户端","url":"%2F2019%2F03%2F06%2Fmysql-kill-client%2F","content":"\n## KILL\n1. `KILL QUERY THREAD_ID`\n    - 终止这个线程中正在执行的语句\n2. `KILL [ CONNECTION ] THREAD_ID`\n    - 断开这个线程的连接，如果该线程有语句在执行，先停止正在执行的语句\n\n<!-- more -->\n\n## 锁等待\n\n### 表初始化\n```sql\nCREATE TABLE `t` (\n  `id` INT(11) NOT NULL,\n  `c` INT(11) NOT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\nINSERT INTO t VALUES (1,1);\n```\n\n### 操作次序\n| session A | session B | session C |\n| ---- | ---- | ---- |\n| BEGIN; | | |\n| UPDATE t SET c=c+1 WHERE id=1; | | |\n| | UPDATE t SET c=c+2 WHERE id=1;<br/>(Blocked) | |\n| | | SHOW PROCESSLIST; |\n| | | KILL QUERY 24; |\n| | ERROR 1317 (70100): Query execution was interrupted | |\n\n```sql\nmysql> SHOW PROCESSLIST;\n+----+-----------------+-----------+------+---------+--------+------------------------+-------------------------------+\n| Id | User            | Host      | db   | Command | Time   | State                  | Info                          |\n+----+-----------------+-----------+------+---------+--------+------------------------+-------------------------------+\n|  4 | event_scheduler | localhost | NULL | Daemon  | 472733 | Waiting on empty queue | NULL                          |\n| 21 | root            | localhost | test | Sleep   |    130 |                        | NULL                          |\n| 23 | root            | localhost | test | Query   |      0 | starting               | show processlist              |\n| 24 | root            | localhost | test | Query   |      5 | updating               | UPDATE t SET c=c+2 WHERE id=1 |\n+----+-----------------+-----------+------+---------+--------+------------------------+-------------------------------+\n```\n\n### KILL QUERY\n1. 对表进行**增删改查**操作时，会在表上加**MDL读锁**\n2. `KILL QUERY`并不是马上停止，而是告诉线程这条语句已经**不需要再继续执行**，可以开始执行停止的逻辑\n    - 类似于Linux的`kill -N pid`命令，并不是让进程直接停止\n    - 而是给进程发一个信号，然后让进程处理这个信号，进入终止逻辑\n3. MySQL的具体动作\n    - 把`session B`的线程状态改成`THD:KILL_QUERY`(将变量`killed`赋值为`THD:KILL_QUERY`)\n    - 给`session B`的执行线程发一个**信号**\n        - `session B`原本处于锁等待状态\n        - 如果只是修改线程状态，线程B是**不知道这个状态的变化**的，还会继续等待\n        - 发信号的目的：让`session B`退出等待，来处理`THD:KILL_QUERY`状态\n4. 隐含逻辑\n    - 一个语句在执行过程中会有多处**埋点**，在这些**埋点**的地方会判断线程状态\n        - 如果发现线程状态为`THD:KILL_QUERY`，才开始进入**语句终止**的逻辑\n    - 如果处于等待状态，必须是一个**可以被唤醒的等待**，否则根本不会执行到埋点处\n    - 语句从**开始进入**终止逻辑，到**完全完成**终止逻辑，是有个过程的\n\n## 并发线程数\n```sql\nSET GLOBAL innodb_thread_concurrency=2;\n```\n\n### 操作序列\n| session A | session B | session C | session D | session E |\n| ---- | ---- | ---- | ---- | ---- |\n| SELECT SLEEP(100) FROM t; | SELECT SLEEP(100) FROM t; | | | |\n| | | SELECT * FROM t;<br/>(Blocked) | | |\n| | | | SHOW PROCESSLIST;<br/>(1st) | |\n| | | | KILL QUERY 28;<br/>(无效) | |\n| | | | | KILL 28; |\n| | | | ERROR 2013 (HY000): Lost connection to MySQL server during query | |\n| | | | SHOW PROCESSLIST;<br/>(2nd) | |\n\n```sql\n-- 1st\nmysql> SHOW PROCESSLIST;\n+----+-----------------+-----------+------+---------+--------+------------------------+--------------------------+\n| Id | User            | Host      | db   | Command | Time   | State                  | Info                     |\n+----+-----------------+-----------+------+---------+--------+------------------------+--------------------------+\n|  4 | event_scheduler | localhost | NULL | Daemon  | 477650 | Waiting on empty queue | NULL                     |\n| 21 | root            | localhost | test | Query   |     12 | User sleep             | SELECT SLEEP(100) FROM t |\n| 24 | root            | localhost | test | Query   |      8 | User sleep             | SELECT SLEEP(100) FROM t |\n| 26 | root            | localhost | test | Sleep   |    291 |                        | NULL                     |\n| 27 | root            | localhost | test | Query   |      0 | starting               | SHOW PROCESSLIST         |\n| 28 | root            | localhost | test | Query   |      5 | Sending data           | SELECT * FROM t          |\n+----+-----------------+-----------+------+---------+--------+------------------------+--------------------------+\n\n-- 2nd\nmysql> SHOW PROCESSLIST;\n+----+-----------------+-----------+------+---------+--------+------------------------+--------------------------+\n| Id | User            | Host      | db   | Command | Time   | State                  | Info                     |\n+----+-----------------+-----------+------+---------+--------+------------------------+--------------------------+\n|  4 | event_scheduler | localhost | NULL | Daemon  | 477667 | Waiting on empty queue | NULL                     |\n| 21 | root            | localhost | test | Query   |     29 | User sleep             | SELECT SLEEP(100) FROM t |\n| 24 | root            | localhost | test | Query   |     25 | User sleep             | SELECT SLEEP(100) FROM t |\n| 26 | root            | localhost | test | Sleep   |      4 |                        | NULL                     |\n| 27 | root            | localhost | test | Query   |      0 | starting               | SHOW PROCESSLIST         |\n| 28 | root            | localhost | test | Killed  |     22 | Sending data           | SELECT * FROM t          |\n+----+-----------------+-----------+------+---------+--------+------------------------+--------------------------+\n```\n\n### KILL QUERY / CONNECTION\n1. `session C`执行的时候被堵住了，`session D`执行`KILL QUERY`没啥效果\n    - 等行锁时，使用的是`pthread_cond_timedwait`函数，这个等待状态是**可以被唤醒**的\n    - 本例中，28号线程的等待逻辑为\n        - 每**10ms**判断下能否进入InnoDB执行，如果不行，调用`nanosleep`函数进入`SLEEP`状态\n    - 虽然28号线程的状态被设置成了`THD:KILL_QUERY`，但在等待进入InnoDB的循环过程中\n        - 并**没有去判断线程的状态**，因此根本不会进入**终止逻辑**阶段\n2. `session E`执行`KILL CONNECTION`，断开`session C`的连接，`Command`列变成了`Killed`\n    - 表示**客户端**虽然**断开了连接**，但实际上**服务端**上这条语句还是在**执行中**\n    - 把28号线程的状态设置为`THD:KILL_CONNECTION`，然后**关闭**12号线程的**网络连接**\n        - `session C`会收到断开连接的提示\n3. SHOW PROCESSLIST\n    - 如果一个线程的状态为`THD:KILL_CONNECTION`，`Command`列会显示为`Killed`\n    - 28号线程只有满足进入InnoDB的条件后，`session C`的查询语句将继续执行\n        - 才有可能判断到线程状态是否已经变成了`KILL_QUERY`或者`KILL_CONNECTION`\n        - 再进入终止逻辑阶段\n\n## KILL无效的情况\n1. 线程没有执行到**判断线程状态**的逻辑\n    - innodb_thread_concurrency过小\n    - 例如IO压力过大，读写IO的函数一直没有返回，导致不能及时判断线程的状态\n2. **终止逻辑耗时较长**，`SHOW PROCESSLIST`显示为`Command=Killed`\n    - **超大事务执行期间被KILL**\n        - 回滚操作需要**对事务执行期间生成的所有新数据版本做回收操作**，耗时很长\n    - **大查询回滚**\n        - 查询过程中生成了**较大的临时文件**，恰好此时**文件系统压力较大**\n        - 删除临时文件需要等待IO资源，导致耗时较长\n    - **DDL执行到最后阶段被KILL**\n        - 需要删除中间过程的**临时文件**，可能受**IO资源**影响，耗时比较久\n\n## CTRL + C\n1. 在客户端的操作**只能影响到客户端的线程**\n2. 客户端与服务端只能通过**网络交互**，因此是**不可能直接操作服务端线程**的\n3. MySQL是**停等协议**，在这个线程执行的语句还没有返回的时候，再往该连接发命令是没有用的\n    - 实际上，执行`CTRL + C`，MySQL是**另起一个连接**，然后发送一个`KILL QUERY`命令\n\n## mysql -A\n```sql\n$ mysql -uroot -Dtest\nReading table information for completion of table and column names\nYou can turn off this feature to get a quicker startup with -A\n```\n1. MySQL客户端默认会提供一个本地库名和表名**补全**的功能，在客户端连接成功后，会多执行以下操作\n    - `SHOW DATABASES;` -> `USE test;` -> `SHOW TABLES;`\n    - 目的：用于构建一个**本地的哈希表**\n2. 当表很多的时候，会表现得慢，但这是**客户端慢**，而非**连接慢**或者**服务端慢**\n\n## mysql --quick\n1. MySQL客户端发送请求后，接收服务端返回结果的两种方式\n    - **使用本地缓存**，在本地开辟一片内存，先把结果存起来，对应API为`mysql_store_result`\n        - MySQL客户端默认行为，即不加参数`--quick`\n    - **不使用本地缓存**，读一个处理一个，对应API为`mysql_use_result`\n        - 如果**客户端本地处理得慢**，会导致**服务端发送结果被阻塞**，导致服务端变慢\n2. 使用`--quick`的效果\n    - `-A`参数，**跳过表名自动补全功能**\n    - `mysql_store_result`需要申请**本地内存**来缓存结果\n        - 如果查询结果太大，可能会**影响客户端本地机器的性能**\n    - 不会把执行命令记录到本地的**命令历史文件**\n3. `--quick`的目的是为了让**客户端更快**，但有可能会**降低服务端性能**\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 数据恢复","url":"%2F2019%2F03%2F04%2Fmysql-data-recovery%2F","content":"\n## DELETE\n1. 使用`DELETE`语句误删除了**数据行**，可以使用`Flashback`通过闪回把数据恢复\n2. `Flashback`恢复数据的原理：修改`binlog`的内容，然后拿到**原库重放**\n    - 前提：`binlog_format=ROW`和`binlog_row_image=FULL`\n3. 针对单个事务\n    - 对于`INSERT`语句，将`Write_rows event`改成`Delete_rows event`\n    - 对于`DELETE`语句，将`Delete_rows event`改成`Write_rows event`\n    - 对于`UPDATE`语句，`binlog`里面记录了数据行修改前和修改后的值，**对调两行的位置即可**\n4. 针对多个事务\n    - 误操作\n        - (A)DELETE\n        - (B)INSERT\n        - (C)UPDTAE\n    - Flashback\n        - (REVERSE C)UPDATE\n        - (REVERSE B)DELETE\n        - (REVERSE A)INSERT\n5. 不推荐直接在**主库**上执行上述操作，避免造成**二次破坏**\n    - 比较安全的做法是先恢复出一个备份或找一个从库作为**临时库**\n    - 在临时库上执行上述操作，然后再将**确认过**的临时库的数据，恢复到主库\n6. 预防措施\n    - `sql_safe_updates=ON`，下列情况会报错\n        - 没有`WHERE`条件的`DELETE`或`UPDATE`语句\n        - `WHERE`条件里面**没有包含索引字段的值**\n    - 上线前，必须进行**SQL审计**\n7. 删全表的性能\n    - `DELETE`全表**很慢**，因为需要生成`undolog`、写`redolog`和写`binlog`\n    - 优先考虑使用`DROP TABLE`或`TRUNCATE TABLE`\n\n<!-- more -->\n\n## DROP / TRUNCATE\n1. `DROP TABLE`、`TRUNCATE TABLE`和`DROP DATABASE`，是无法通过`Flashback`来恢复的\n    - 即使配置了`binlog_format=ROW`，执行上面3个命令，`binlog`里面记录的依然是`STATEMENT`格式\n    - `binlog`里面只有一个`TRUNCATE/DROP`语句，这些信息是无法恢复数据的\n2. 这种情况如果想要恢复数据，需要使用**全量备份**和**增量日志**的方式\n    - 要求线上**定期全量备份**，并且**实时备份`binlog`**\n\n### mysqlbinlog\n假设有人中午12点删除了一个库，恢复数据的流程\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-data-recovery-mysqlbinlog.png\" width=500/>\n\n1. 取最近一次全量备份，假设一天一备，即当天0点的全量备份\n2. 用全量备份恢复出一个临时库\n3. 从`binlog`备份里，取出凌晨0点以后的日志\n4. 把这些日志，**除误删数据的语句外**，全部应用到临时库\n5. 为了**加快数据恢复**，如果临时库上有多个数据库，可以加上`--database`参数，指定应用某个库的日志\n6. 跳过12点误操作语句的`binlog`\n    - 如果原实例没有使用`GTID`模式，只能在应用到包含12点的`binlog`文件的时候\n        - 先用`--stop-position`参数执行到**误操作之前**的日志\n        - 再用`--start-position`从**误操作之后**的日志继续执行\n    - 如果原实例使用`GTID`模式，假设误操作命令的`GTID`为`gtid1`\n        - 只需执行`SET gtid_next=gtid1;BEGIN;COMMIT;`\n        - 把`gtid1`加入到临时库的`GTID`集合，之后按顺序执行`binlog`时，会**自动跳过**误操作的语句\n7. 使用`mysqlbinlog`的方法恢复数据的速度**还是不够快**，主要原因\n    - 如果**误删表**，最好是**只重放这张表的操作**，但`mysqlbinlog`并不能指定只解析一个表的日志\n    - 用`mysqlbinlog`解析出日志来应用，应用日志的过程只能是**单线程**的\n8. 另外一个加速的方法：`Master-Slave`\n\n### Master-Slave\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-data-recovery-master-slave.png\" width=500/>\n\n1. 在`START SLAVE`之前，先通过执行`CHANGE REPLICATION FILTER REPLICATE_DO_TABLE=(tbl_name)`\n    - 让临时库**只同步误操作的表**，利用**并行复制**技术，来加速整个数据恢复过程\n2. `binlog`备份到线上备库之间是一条**虚线**\n    - 虚线指的是如果由于时间太久，线上备库有可能已经删除了临时实例所需要的`binlog`\n        - 可以从`binlog`备份系统中找到需要的`binlog`，再放到备库中\n    - 举例说明\n        - 例如当前临时实例需要的`binlog`是从`master.000005`开始\n        - 但在线上备库上执行`SHOW BINARY LOGS`显示最小的`binlog`文件是`master.000007`\n        - 意味着少了两个`binlog`文件\n        - 这时需要到`binlog`备份系统找到这两个文件，把之前删掉的`binlog`放回备库执行以下步骤\n        - 从备份系统下载`master.000005`和`master.000006`，放到备库的日志目录下\n        - 打开`master.index`，在文件头加入两行：`./master.000005`和`./master.000006`\n        - 重启备库，目的是为了让备库**重新识别**这两个日志文件\n        - 现在备库上就有了临时实例所需要的所有`binlog`，建立主备关系，就可以正常同步了\n\n### 延迟复制备库\n1. 上面`Master-Slave`的方案利用了**并行复制**来加速数据恢复的过程，但**恢复时间不可控**\n    - 如果一个库特别大，或者误操作的时间距离上一个全量备份的时间较长（一周一备）\n2. 针对核心业务，**不允许太长的恢复时间**，可以搭建**延迟复制的备库**（MySQL 5.6引入）\n3. 延迟复制的备库是一种特殊的备库\n    - 通过`CHANGE MASTER TO MASTER_DELAY=N`命令来指定备库持续与主库有N秒的延迟\n    - 假设N=3600，如果能在一小时内发现误删除命令，这个误删除的命令尚未在延迟复制的备库上执行\n    - 这时在这个备库上执行`STOP SLAVE`，再通过前面的方法，跳过误删除命令，就可以恢复数据\n    - 这样，可以得到一个恢复时间可控（最多1小时）的备库\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 故障诊断","url":"%2F2019%2F03%2F03%2Fmysql-trouble-shooting%2F","content":"\n## SELECT 1\n`SELECT 1`只能说明数据库**进程还在**，但不能说明数据库没有问题\n```sql\n-- innodb_thread_concurrency表示并发线程数量\nmysql> SHOW VARIABLES LIKE '%innodb_thread_concurrency%';\n+---------------------------+-------+\n| Variable_name             | Value |\n+---------------------------+-------+\n| innodb_thread_concurrency | 16    |\n+---------------------------+-------+\n```\n\n<!-- more -->\n\n### 表初始化\n```sql\n-- innodb_thread_concurrency默认为0，表示不限制并发线程数量，建议设置范围64~128\nSET GLOBAL innodb_thread_concurrency=3;\n\nCREATE TABLE `t` (\n    `id` INT(11) NOT NULL,\n    `c` INT(11) DEFAULT NULL,\n    PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\nINSERT INTO t VALUES (1,1);\n```\n\n### 操作序列\n| session A | session B | session C | session D |\n| ---- | ---- | ---- | ---- |\n| SELECT SLEEP(100) FROM t; | SELECT SLEEP(100) FROM t; | SELECT SLEEP(100) FROM t; | |\n| | | | SELECT 1;<br/>(Query OK)|\n| | | | SELECT * FROM t;<br/>(Blocked)|\n\n并发线程达到**上限**3后，InnoDB在接收新请求时，会进入**等待**状态\n\n### 并发连接 VS 并发查询\n1. `SHOW PROCESSLIST`可能会看到几千个连接，指的是**并发连接**；而**当前正在执行**的语句，才是**并发查询**\n2. 并发连接达到几千影响并不大，无非就是多占用一些内存，\n    - **并发查询**太大才是**CPU杀手**，因此才需要设置`innodb_thread_concurrency`\n3. _**在线程进入锁等待后，并发线程的计数将会减一**_\n    - 等待**行锁**或**间隙锁**的线程**不属于并发线程**，因为这些线程**不会再消耗CPU**\n4. `SELECT SLEEP(100) FROM t`是在真正地执行查询，所以还是要算并发线程\n\n## 查询判断\n1. 在系统库（`mysql`）里建一个表，命名为`health_check`，里面只放一行数据，然后**定期查询**\n    - `SELECT * FROM mysql.health_check`\n    - 可以检测出由于**并发线程过多**而导致数据库不可用的情况\n2. 但该方法无法检测**磁盘空间满**的情况\n    - 更新事务需要写`binlog`，而一旦`binlog`所在**磁盘的空间占用率**达到率100%\n    - 所有的**更新语句**和**事务的commit语句**都会被**阻塞**\n    - 但此时系统还是可以**正常地读取数据**的\n\n## 更新判断\n1. `UPDATE mysql.health_check SET t_modified=now()`\n2. 主库和从库都需要进行**节点的可用性检测**，从库的可用性检测也是需要写`binlog`的\n3. 一般会把A和B的主从关系设计为`Master-Master`结构，在从库B上执行的检测命令，也会发回主库A\n4. 如果主库A和从库B都使用**相同的更新命令**，可能会出现**行冲突**（无法区分谁更新的），导致**主从同步停止**\n    - 为了主从之间的更新不产生冲突，在`mysql.health_check`上存入**多行**数据，`server_id`为主键\n    - MySQL规定主库和从库的`server_id`必须**不同**，从而保证主从各自的检测命令不会发生冲突\n\n```sql\nCREATE TABLE `health_check` (\n    `id` INT(11) NOT NULL,\n    `t_modified` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\n-- 检测命令\nINSERT INTO mysql.health_check (id, t_modified) VALUES (@@server_id, now()) ON DUPLICATE KEY UPDATE t_modified=now();\n```\n\n### 判定慢\n1. 所有的检测都需要一个**超时时间N**，执行一个`UPDATE`语句，如果超过N秒后不返回，会认为系统不可用\n2. 假设一个日志盘的**IO利用率**已经是100%，整个系统响应非常慢，已经准备做主从切换了\n    - IO利用率为100%，表示系统的IO在正常工作，每个请求都是**有机会**得到IO资源的\n    - 而检测使用的`UPDATE`命令，需要的资源是很少的\n        - 可能在N秒内返回给检测系统，检测系统**误认为**系统是正常的\n3. 表现：业务系统上正常的SQL执行很慢，但DBA在HA系统上看到的却是系统处于可用状态\n4. 根本原因：都是基于**外部检测**（定时轮询），天然存在**随机性**的问题\n\n## 内部统计\n\n### redolog\n```sql\nmysql> SELECT * FROM performance_schema.file_summary_by_event_name WHERE EVENT_NAME='wait/io/file/innodb/innodb_log_file'\\G;\n*************************** 1. row ***************************\n               EVENT_NAME: wait/io/file/innodb/innodb_log_file\n               COUNT_STAR: 233\n           SUM_TIMER_WAIT: 132552328013\n           MIN_TIMER_WAIT: 1665048\n           AVG_TIMER_WAIT: 568893997\n           MAX_TIMER_WAIT: 86702766780\n               COUNT_READ: 8\n           SUM_TIMER_READ: 87079515796\n           MIN_TIMER_READ: 2300200\n           AVG_TIMER_READ: 10884939289\n           MAX_TIMER_READ: 86702766780\n SUM_NUMBER_OF_BYTES_READ: 70656\n              COUNT_WRITE: 114\n          SUM_TIMER_WRITE: 8780811305\n          MIN_TIMER_WRITE: 10705576\n          AVG_TIMER_WRITE: 77024423\n          MAX_TIMER_WRITE: 679922054\nSUM_NUMBER_OF_BYTES_WRITE: 92160\n               COUNT_MISC: 111\n           SUM_TIMER_MISC: 36692000912\n           MIN_TIMER_MISC: 1665048\n           AVG_TIMER_MISC: 330558403\n           MAX_TIMER_MISC: 18323439204\n```\n1. `EVENT_NAME`：统计的类型，这里为`redolog`\n2. 第1组：`COUNT_STAR`~`MAX_TIMER_WAIT`，所有IO类型的统计，单位为皮秒，`1 PS = 10^-12 S`\n3. 第2组：`COUNT_READ`~`SUM_NUMBER_OF_BYTES_READ`，读操作的统计\n    - `SUM_NUMBER_OF_BYTES_READ`：总共从`redolog`读取了多少**字节**\n4. 第3组：`COUNT_WRITE`~`SUM_NUMBER_OF_BYTES_WRITE`，写操作的统计\n5. 第4组：`COUNT_MISC`~`MAX_TIMER_MISC`，其它类型数据的统计\n    - 在`redolog`里，可以理解为对`fsync`的统计\n\n### binlog\n```sql\nmysql> SELECT * FROM performance_schema.file_summary_by_event_name WHERE EVENT_NAME='wait/io/file/sql/binlog'\\G;\n*************************** 1. row ***************************\n               EVENT_NAME: wait/io/file/sql/binlog\n               COUNT_STAR: 27\n           SUM_TIMER_WAIT: 3003083244\n           MIN_TIMER_WAIT: 0\n           AVG_TIMER_WAIT: 111225058\n           MAX_TIMER_WAIT: 1100158206\n               COUNT_READ: 4\n           SUM_TIMER_READ: 1283933427\n           MIN_TIMER_READ: 3404667\n           AVG_TIMER_READ: 320983264\n           MAX_TIMER_READ: 1100158206\n SUM_NUMBER_OF_BYTES_READ: 10248\n              COUNT_WRITE: 5\n          SUM_TIMER_WRITE: 597349326\n          MIN_TIMER_WRITE: 18148578\n          AVG_TIMER_WRITE: 119469791\n          MAX_TIMER_WRITE: 421662276\nSUM_NUMBER_OF_BYTES_WRITE: 896\n               COUNT_MISC: 18\n           SUM_TIMER_MISC: 1121800491\n           MIN_TIMER_MISC: 0\n           AVG_TIMER_MISC: 62322064\n           MAX_TIMER_MISC: 188882778\n```\n\n### 性能损耗\n如果打开所有的`performance_schema`，性能大概会下降`10%`左右，建议只打开所需要的项\n```sql\nUPDATE setup_instruments SET ENABLED='YES', TIMED='YES' WHERE NAME LIKE '%wait/io/file/innodb/innodb_log_file%';\n```\n\n### 故障诊断\n假设已经开启了`redolog`和`binlog`的统计信息功能，可以通过`MAX_TIMER`来判断数据库是否有问题\n```sql\n-- 单次IO超过200ms\nSELECT EVENT_NAME,MAX_TIMER_WAIT FROM performance_schema.file_summary_by_event_name WHERE EVENT_NAME IN ('wait/io/file/innodb/innodb_log_file','wait/io/file/sql/binlog') AND MAX_TIMER_WAIT>200*1000000000;\n```\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 读写分离","url":"%2F2019%2F03%2F02%2Fmysql-read-write-separation%2F","content":"\n## 读写分离架构\n\n### 客户端直连\n<img src=\"\thttps://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-read-write-separation-basic.png\" width=800/>\n\n\n<!-- more -->\n\n### Proxy\n<img src=\"\thttps://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-read-write-separation-proxy.png\" width=800/>\n\n\n### 对比\n1. 客户端直连\n    - 少了一层`Proxy`转发，查询性能稍微好一点\n    - 整体架构简单，排查问题方便\n    - 需要了解**后端部署细节**，在出现主从切换、库迁移时，客户端有感知，需要调整数据库连接信息\n        - 一般伴随着一个负责管理后端的组件，例如`ZooKeeper`\n2. Proxy -- **发展趋势**\n    - 对客户端友好，客户端不需要关注后端细节，但后端维护成本较高\n    - `Proxy`也需要**高可用**架构，带Proxy的整体架构相对复杂\n\n### 过期读\n由于**主从延迟**，主库上执行完一个更新事务后，立马在从库上执行查询，有可能读到刚刚的事务更新之前的状态\n\n## 解决方案\n\n### 强制走主库\n1. 将查询请求做**分类**\n    - 必须要拿到最新结果的请求，强制将其发送到主库上\n    - 可以读到旧数据的请求，将其发到从库上\n2. 如果完全不能接受过期读，例如金融类业务，相当于放弃读写分离，所有的读写压力都在主库上\n\n### SLEEP\n1. 主库更新后，读从库之前先`SLEEP`一下，类似于`SELECT SLEEP(1)`\n    - 基于的假设：大多数主从延时在1秒内\n2. 卖家发布商品后，用`Ajax`直接把客户端输入的内容作为“新的商品”显示在页面上，而非真正的做数据库查询\n    - 等卖家再次刷新页面，其实主从已经同步完成了，也达到了`SLEEP`的效果\n3. `SLEEP`方案解决了类似场景下的过期读问题，但存在**不精确**的问题\n    - 如果主从延时只有0.5秒，也会等到1秒\n    - 如果主从延迟超过了1秒，依然会出现**过期读**的问题\n\n### 判断主从无延迟\n1. `SLOW SLAVE STATUS`.`Seconds_Behind_Master`\n    - 每次在从库执行查询请求前，先判断`Seconds_Behind_Master`是否等于`0`\n    - `Seconds_Behind_Master=0`才能执行查询请求\n    - `Seconds_Behind_Master`的精度为**秒**，如果需要更高精度，可以考虑对比**位点**和`GTID`\n2. 位点\n    - `Master_Log_File`和`Read_Master_Log_Pos`，表示**读到的主库的最新位点**\n    - `Relay_Master_Log_File`和`Exec_Master_Log_Pos`，表示**从库执行的最新位点**\n    - `Master_Log_File=Relay_Master_Log_File`和`Read_Master_Log_Pos=Exec_Master_Log_Pos`\n        - 表示接收到的日志已经**同步完成**\n3. `GTID`\n    - `Auto_Position=1`，表示**主从关系**使用了`GTID`协议\n    - `Retrieved_Gtid_Set`，表示从库**收到**的所有日志的`GTID`集合\n    - `Executed_Gtid_Set`，表示从库所有**已经执行完成**的`GTID`集合\n\n```sql\nmysql> SHOW SLAVE STATUS\\G;\n*************************** 1. row ***************************\n               Slave_IO_State: Waiting for master to send event\n              Master_Log_File: master-bin.000003\n          Read_Master_Log_Pos: 484\n               Relay_Log_File: relay-bin.000003\n                Relay_Log_Pos: 699\n        Relay_Master_Log_File: master-bin.000003\n          Exec_Master_Log_Pos: 484\n        Seconds_Behind_Master: 0\n                  Master_UUID: b0bda503-3cf1-11e9-8c3a-0242ac110002\n      Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates\n           Retrieved_Gtid_Set: b0bda503-3cf1-11e9-8c3a-0242ac110002:1-6\n            Executed_Gtid_Set: b0bda503-3cf1-11e9-8c3a-0242ac110002:1-6,ba0b2f12-3cf1-11e9-9c40-0242ac110003:1-5\n                Auto_Position: 1\n```\n\n#### 不精确\n1. `binlog`在主从之间的状态\n    - 主库执行完成，写入`binlog`，反馈给客户端\n    - `binlog`被主库发送到从库，从库收到\n    - 从库执行`binlog`（应用`relaylog`）\n2. 上面判断的**主从无延迟**：_**从库收到的日志都执行完成了**_\n    - 并没有考虑这部分日志：客户端已经收到提交确认，但从库还未收到\n\n<img src=\"\thttps://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-read-write-separation-no-delay.png\" width=800/>\n\n1. 主库上执行完成了3个事务：`trx1`、`trx2`和`trx3`\n2. `trx1`和`trx2`已经传到从库，并且已经执行完成了\n3. `trx3`在主库执行完成后，并且已经回复给客户端，但还未传到从库中\n4. 如果此时在从库上执行查询请求，按上面的逻辑，从库已经**没有同步延迟**了，但还是查不到`trx3`的变更，出现了**过期读**\n\n### SEMI-SYNC\n\n#### SEMI-SYNC设计\n1. 事务提交到时候，主库把`binlog`发给从库\n2. 从库收到`binlog`后，发回给主库一个`ACK`，表示收到了\n3. 主库收到这个`ACK`以后，才能给客户端返回事务完成的确认\n\n#### 小结\n1. 启用了`SEMI-SYNC`\n    - 所有给客户端发送过确认的事务，都确保了**某一个从库**已经收到了这个日志\n2. `SEMI-SYNC`+位点的方案，只针对**一主一从**的场景是成立的\n    - 在**一主多从**的场景里，主库只要等到一个从库的`ACK`，就开始给客户端返回确认\n    - 如果对刚刚响应了`ACK`的从库执行查询请求（+判断**主从无延迟**），能够确保读到最新的数据，否则可能是**过期读**\n3. 如果在业务高峰期，主库的位点或者GTID集合更新很快，从库可能一直跟不上主库，导致从库迟迟无法响应查询请求\n    - 在出现**持续延迟**的情况下，可能会出现**过度等待**（判断**主从无延迟**）的情况\n\n### 等主库位点\n```sql\nSELECT MASTER_POS_WAIT(file, pos[, timeout]);\n```\n1. 在**从库**上执行\n2. 参数`file`和`pos`指的是**主库**上的文件名和位置\n3. `timeout`单位为秒\n4. 返回正整数，表示从**命令开始执行**，到应用完`file`和`pos`，总共**执行了多少事务**\n    - 如果在执行期间，从库的同步线程发生异常，返回NULL\n    - 如果等待超过`timeout`秒，返回`-1`\n    - 如果刚开始执行的时候，发现**已经执行**过这个位置，返回`0`\n\n#### 样例\n先在`MySQL A`执行`trx1`，然后在`MySQL B`执行查询请求\n<img src=\" https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-read-write-separation-wait-pos.png\" width=800/>\n\n1. 事务`trx1`更新完成后，马上执行`SHOW MASTER STATUS`，得到当前主库执行到的`File`和`Position`\n2. 选择一个从库执行查询语句\n3. 在该从库上先执行`SELECT MASTER_POS_WAIT(File, Position, 1)`\n4. 如果返回值`>=0`，则直接在这个从库上执行查询语句\n5. 否则，在主库上执行查询语句\n    - 一种退化机制，针对**主从延时不可控**的场景\n\n```sql\n-- MySQL A\nmysql> SHOW MASTER STATUS;\n+-------------------+----------+--------------+------------------+------------------------------------------+\n| File              | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set                        |\n+-------------------+----------+--------------+------------------+------------------------------------------+\n| master-bin.000003 |      643 |              |                  | b0bda503-3cf1-11e9-8c3a-0242ac110002:1-7 |\n+-------------------+----------+--------------+------------------+------------------------------------------+\n\n-- MySQL B\nmysql> SELECT MASTER_POS_WAIT('master-bin.000003',643,1);\n+--------------------------------------------+\n| MASTER_POS_WAIT('master-bin.000003',643,1) |\n+--------------------------------------------+\n|                                          0 |\n+--------------------------------------------+\n```\n\n### 等GTID\n```sql\n-- 等待，直到这个库执行的事务中包含传入的gtid_set，返回0\n-- 超时返回1\nSELECT WAIT_FOR_EXECUTED_GTID_SET(gtid_set, 1);\n```\n\n#### 样例\n<img src=\" https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-read-write-separation-wait-gtid.png\" width=800/>\n\n1. 从MySQL 5.7.6开始，允许在执行完**更新类事务**后，把这个事务的`GTID`返回给客户端\n2. 事务`trx1`更新完成后，从返回结果中直接获取`trx1`的`GTID`，记为`gtid1`\n3. 选择一个从库执行查询语句\n4. 在该从库上先执行`SELECT WAIT_FOR_EXECUTED_GTID_SET(gtid1, 1)`\n5. 如果返回`0`，则直接在这个从库上执行查询语句\n6. 否则，在主库上执行查询语句\n\n```sql\n-- MySQL A\nmysql> SHOW MASTER STATUS;\n+-------------------+----------+--------------+------------------+------------------------------------------+\n| File              | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set                        |\n+-------------------+----------+--------------+------------------+------------------------------------------+\n| master-bin.000003 |      643 |              |                  | b0bda503-3cf1-11e9-8c3a-0242ac110002:1-7 |\n+-------------------+----------+--------------+------------------+------------------------------------------+\n\n-- MySQL B\nmysql> SELECT WAIT_FOR_EXECUTED_GTID_SET('b0bda503-3cf1-11e9-8c3a-0242ac110002:1-7',1);\n+--------------------------------------------------------------------------+\n| WAIT_FOR_EXECUTED_GTID_SET('b0bda503-3cf1-11e9-8c3a-0242ac110002:1-7',1) |\n+--------------------------------------------------------------------------+\n|                                                                        0 |\n+--------------------------------------------------------------------------+\n```\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 主从切换","url":"%2F2019%2F02%2F26%2Fmysql-master-slave-switch%2F","content":"\n## 一主多从\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-master-multi-slave.png\" width=500/>\n\n\n<!-- more -->\n\n1. 虚线箭头为**主从关系**，`A`和`A'`互为主从，`B`、`C`、`D`指向主库`A`\n2. 一主多从的设置，一般用于**读写分离**，主库负责**所有的写入**和**一部分读**，其它读请求由从库分担\n\n## 主库故障切换\n`A'`成为新的主库，`B`、`C`、`D`指向主库`A'`\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-master-crash-switch.png\" width=500/>\n\n\n## 基于位点的切换\n`B`原先是`A`的从库，本地记录的也是`A`的位点，但**相同的日志**，`A`的位点与`A'`的位点是**不同**的\n```sql\n-- 节点B设置为节点A'的从库\nCHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nMASTER_LOG_FILE=$master_log_name\nMASTER_LOG_POS=$master_log_pos\n```\n\n### 寻找位点\n1. _**很难精确，只能大概获取一个位置**_\n2. 由于在切换过程中**不能丢数据**，在寻找位点的时候，总是找一个**稍微往前的位点**，跳过那些已经在`B`执行过的事务\n\n#### 常规步骤\n1. 等待新主库`A'`将所有`relaylog`全部执行完\n2. 在`A'`上执行`SHOW MASTER STATUS`，得到`A'`上最新的`File`和`Position`\n3. 获取原主库`A`发生故障的时刻`T`\n4. 使用`mysqlbinlog`解析`A'`的`File`，得到时刻`T`的位点\n\n```sql\n-- end_log_pos=123，表示在时刻T，A'写入新binlog的位置，作为B的CHANGE MASTER TO命令的MASTER_LOG_POS参数\n$ mysqlbinlog /var/lib/mysql/slave-bin.000009 --start-datetime='2019-02-26 17:44:00' --stop-datetime='2019-02-26 17:45:00' | grep end_log_pos\n#190226 17:42:01 server id 2  end_log_pos 123 CRC32 0x5b852e9b \tStart: binlog v 4, server v 5.7.25-log created 190226 17:42:01 at startup\n```\n\n#### 位点不精确\n1. 假设在时刻`T`，原主库`A`已经执行完成了一个`INSERT`语句，插入一行记录`R`\n    - 并且已经将`binlog`传给`A'`和B，然后原主库`A`掉电\n2. 在`B`上，由于已经同步了`binlog`，`R`这一行是已经存在的\n3. 在新主库`A'`上，`R`这一行也是存在的，日志写在了`123`这个位置之后\n4. 在`B`上执行`CHANGE MASTER TO`，执行`A'`的`File`文件的`123`位置\n    - 就会把插入`R`这一行数据的`binlog`又同步到`B`去执行\n    - `B`的同步线程会报**重复主键**错误，然后停止同步\n\n##### 跳过错误\n方式1：主动跳过一个事务，需要**持续观察**，每次碰到这些错误，就执行一次跳过命令\n```sql\nSET GLOBAL sql_slave_skip_counter=1;\nSTART SLAVE;\n```\n方式1：设置`slave_skip_errors=1032,1062`，`1032`错误是删除数据时**找不到行**，`1062`错误是插入数据时报**唯一键冲突**\n在**主从切换过程**中，直接跳过`1032`和`1062`是**无损**的，等主从间的同步关系建立完成后，需要将`slave_skip_errors`恢复为`OFF`\n\n```sql\nmysql> SHOW VARIABLES LIKE '%slave_skip_errors%';\n+-------------------+-------+\n| Variable_name     | Value |\n+-------------------+-------+\n| slave_skip_errors | OFF   |\n+-------------------+-------+\n```\n\n## 基于GTID的切换\n1. GTID: Global Transaction Identifier，**全局事务ID**\n2. 在事务**提交**时生成，是事务的唯一标识，组成`GTID = server_uuid:gno`\n    - `server_uuid`是实例第一次**启动**时自动生成的，是一个**全局唯一** 的值\n    - `gno`是一个整数，初始值为`1`，每次**提交事务**时分配，`+1`\n3. 官方定义：`GTID = source_id:transaction_id`\n    - `source_id`即`server_uuid`\n    - `transaction_id`容易造成误解\n        - `transaction_id`一般指事务ID，是在事务**执行过程**中分配的，即使事务**回滚**了，事务ID也会**递增**\n        - 而`gno`只有在事务**提交**时才会分配，因此`GTID`往往是**连续**的\n4. 开启`GTID`模式，添加启动参数`gtid_mode=ON`和`enforce_gtid_consistency=ON`\n5. 在`GTID`模式下，每个事务都会跟一个`GTID`一一对应，生成`GTID`的方式由参数`gtid_next`（Session）控制\n6. 每个MySQL实例都维护了一个`GTID`集合，用于表示：_**实例执行过的所有事务**_\n\n### gtid_next\n1. `gtid_next=AUTOMATIC`，MySQL会将`server_uuid:gno`分配给该事务\n    - 记录`binlog`时，会先记录一行`SET @@SESSION.GTID_NEXT=server_uuid:gno`，将该`GTID`加入到本实例的`GTID`集合\n2. `gtid_next=UUID:NUMBER`，通过`SET @@SESSION.GTID_NEXT=current_gtid`执行\n    - 如果`current_gtid`已经**存在**于实例的`GTID`集合中，那么接下来执行的这个事务会直接被系统**忽略**\n    - 如果`current_gtid`并**没有存在**于实例的`GTID`集合中，那么接下来执行的这个事务会被分配为`current_gtid`\n    - `current_gtid`只能给**一个事务**使用，如果执行下一个事务，需要把`gtid_next`设置成另一个`GTID`或者`AUTOMATIC`\n\n```sql\n-- gtid_next=AUTOMATIC\nmysql> SHOW BINLOG EVENTS IN 'master-bin.000003';\n+-------------------+-----+----------------+-----------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n| Log_name          | Pos | Event_type     | Server_id | End_log_pos | Info                                                                                                                                       |\n+-------------------+-----+----------------+-----------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n| master-bin.000003 |   4 | Format_desc    |         1 |         123 | Server ver: 5.7.25-log, Binlog ver: 4                                                                                                      |\n| master-bin.000003 | 123 | Previous_gtids |         1 |         194 | b8502fe3-3b4a-11e9-9562-0242ac110002:1-5                                                                                                   |\n| master-bin.000003 | 194 | Gtid           |         1 |         259 | SET @@SESSION.GTID_NEXT= 'b8502fe3-3b4a-11e9-9562-0242ac110002:6'                                                                          |\n| master-bin.000003 | 259 | Query          |         1 |         484 | GRANT REPLICATION SLAVE ON *.* TO 'replication'@'%' IDENTIFIED WITH 'mysql_native_password' AS '*6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9' |\n| master-bin.000003 | 484 | Gtid           |         1 |         549 | SET @@SESSION.GTID_NEXT= 'b8502fe3-3b4a-11e9-9562-0242ac110002:7'                                                                          |\n| master-bin.000003 | 549 | Query          |         1 |         643 | CREATE DATABASE test                                                                                                                       |\n+-------------------+-----+----------------+-----------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n```\n\n### 表初始化\n```sql\nCREATE TABLE `t` (\n  `id` INT(11) NOT NULL,\n  `c` INT(11) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\nINSERT INTO t VALUES (1,1);\n```\n\n#### 对应的binlog\n```sql\nmysql> SHOW MASTER STATUS;\n+-------------------+----------+--------------+------------------+-------------------------------------------+\n| File              | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set                         |\n+-------------------+----------+--------------+------------------+-------------------------------------------+\n| master-bin.000004 |      877 |              |                  | b8502fe3-3b4a-11e9-9562-0242ac110002:1-12 |\n+-------------------+----------+--------------+------------------+-------------------------------------------+\n\nmysql> SHOW BINLOG EVENTS IN 'master-bin.000004';\n+-------------------+-----+----------------+-----------+-------------+--------------------------------------------------------------------+\n| Log_name          | Pos | Event_type     | Server_id | End_log_pos | Info                                                               |\n+-------------------+-----+----------------+-----------+-------------+--------------------------------------------------------------------+\n| master-bin.000004 |   4 | Format_desc    |         1 |         123 | Server ver: 5.7.25-log, Binlog ver: 4                              |\n| master-bin.000004 | 123 | Previous_gtids |         1 |         194 | b8502fe3-3b4a-11e9-9562-0242ac110002:1-9                           |\n| master-bin.000004 | 194 | Gtid           |         1 |         259 | SET @@SESSION.GTID_NEXT= 'b8502fe3-3b4a-11e9-9562-0242ac110002:10' |\n| master-bin.000004 | 259 | Query          |         1 |         373 | use `test`; DROP TABLE `t` /* generated by server */               |\n| master-bin.000004 | 373 | Gtid           |         1 |         438 | SET @@SESSION.GTID_NEXT= 'b8502fe3-3b4a-11e9-9562-0242ac110002:11' |\n| master-bin.000004 | 438 | Query          |         1 |         620 | use `test`; CREATE TABLE `t` (\n  `id` INT(11) NOT NULL,\n  `c` INT(11) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB |\n| master-bin.000004 | 620 | Gtid           |         1 |         685 | SET @@SESSION.GTID_NEXT= 'b8502fe3-3b4a-11e9-9562-0242ac110002:12' |\n| master-bin.000004 | 685 | Query          |         1 |         757 | BEGIN                                                              |\n| master-bin.000004 | 757 | Table_map      |         1 |         802 | table_id: 109 (test.t)                                             |\n| master-bin.000004 | 802 | Write_rows     |         1 |         846 | table_id: 109 flags: STMT_END_F                                    |\n| master-bin.000004 | 846 | Xid            |         1 |         877 | COMMIT /* xid=27 */                                                |\n+-------------------+-----+----------------+-----------+-------------+--------------------------------------------------------------------+\n```\n1. 事务`BEGIN`之前有一条`SET @@SESSION.GTID_NEXT`\n2. 如果实例X有从库Z，那么将`CREATE TABLE`和`INSERT`语句的`binlog`同步到从库Z执行\n    - 执行事务之前，会先执行两个`SET`命令，这样两个`GTID`就会被加入到从库Z的`GTID`集合\n\n#### 主键冲突\n1. 如果实例X是实例Y的从库，之前实例Y上执行`INSERT INTO t VALUES (1,1)`\n    - 对应的`GTID`为`aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee:12`\n    - 实例X需要同步该事务过来执行，会报**主键冲突**的错误，实例X的同步线程停止，处理方法如下\n\n```sql\n-- 实例X提交一个空事务，将该GTID加到实例X的GTID集合中\nSET gtid_next='aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee:12';\nBEGIN;\nCOMMIT;\n-- 实例X的Executed_Gtid_Set已经包含了aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee:12\nmysql> SHOW MASTER STATUS;\n+-------------------+----------+--------------+------------------+------------------------------------------------------------------------------------+\n| File              | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set                                                                  |\n+-------------------+----------+--------------+------------------+------------------------------------------------------------------------------------+\n| master-bin.000004 |     1087 |              |                  | aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee:12,b8502fe3-3b4a-11e9-9562-0242ac110002:1-12  |\n+-------------------+----------+--------------+------------------+------------------------------------------------------------------------------------+\n\n-- 恢复GTID的默认分配行为\nSET gtid_next=AUTOMATIC;\n\n-- 实例X还是会继续执行实例Y传过来的事务\n-- 但由于实例X的GTID集合已经包含了aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeeeee:12，因此实例X会直接跳过该事务\nSTART SLAVE;\n```\n\n### 主从切换\n```\nCHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nmaster_auto_position=1\n```\n1. `master_auto_position=1`：主从关系使用的是`GTID`协议，不再需要指定`MASTER_LOG_FILE`和`MASTER_LOG_POS`\n2. 实例`A'`的`GTID`集合记为`set_a`，实例`B`的`GTID`集合记为`set_b`\n3. 实例`B`执行`START SLAVE`，取`binlog`的逻辑如下\n\n#### START SLAVE\n1. 实例`B`指定新主库`A'`，基于**主从协议**建立连接\n2. 实例`B`把`set_b`发送给`A'`\n3. 实例`A'`计算出`seb_a`和`set_b`的`GTID`差集（存在于`set_a`，但不存在于`set_b`的`GTID`集合）\n    - 判断实例`A'`本地是否包含了**差集需要的所有`binlog`事务**\n    - 如果**没有全部包含**，说明实例`A'`已经把实例`B`所需要的`binlog`删除掉了，直接返回错误\n    - 如果**全部包含**，实例`A'`从自己的`binlog`文件里面，找到第1个不在`set_b`的事务，发送给实例`B`\n        - 然后从该事务开始，往后读文件，按顺序读取`binlog`，发给实例`B`去执行\n\n#### 位点 VS GTID\n1. 基于`GTID`的主从关系里面，系统认为只要**建立了主从关系**，就必须保证**主库发给从库的日志是完整**的\n2. 如果实例`B`需要的日志已经不存在了，那么实例`A'`就拒绝将日志发送给实例`B`\n3. 基于**位点**的协议，是由**从库决定**的，从库指定哪个位点，主库就发送什么位点，不做**日志完整性**的判断\n4. 基于`GTID`的协议，主从切换**不再需要找位点**，而找位点的工作在实例`A'`内部**自动完成**\n\n#### 日志格式\n1. 切换前\n    - 实例`B`的`GTID`集合：`server_uuid_of_A:1-N`\n2. 新主库`A'`自己生成的`binlog`对应的`GTID`集合：`server_uuid_of_A':1-M`\n3. 切换后\n    - 实例`B`的`GTID`集合：`server_uuid_of_A:1-N,server_uuid_of_A':1-M`\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 从库并行复制","url":"%2F2019%2F02%2F25%2Fmysql-slave-parallel-replication%2F","content":"\n## 主从复制\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-master-slave-replication-parallel.png\" width=500/>\n\n\n<!-- more -->\n\n1. 第一个黑色箭头：客户端写入主库，第二个黑色箭头：从库上`sql_thread`执行`relaylog`，前者的并发度大于后者\n2. 在主库上，影响并发度的原因是**锁**，InnoDB支持**行锁**，对业务并发度的支持还算比较友好\n3. 如果在从库上采用**单线程**（MySQL 5.6之前）更新`DATA`的话，有可能导致从库应用`relaylog`不够快，造成主从延迟\n\n## 多线程模型\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-slave-replication-multi-thread.png\" width=500/>\n\n1. `coordinator`就是原来的`sql_thread`，但不会再直接应用`relaylog`后更新`DATA`，只负责**读取`relaylog`**和**分发事务**\n2. 真正更新日志的是`worker`线程，数量由参数`slave_parallel_workers`控制\n\n```sql\nmysql> SHOW VARIABLES LIKE '%slave_parallel_workers%';\n+------------------------+-------+\n| Variable_name          | Value |\n+------------------------+-------+\n| slave_parallel_workers | 4     |\n+------------------------+-------+\n```\n\n### 分发原则\n1. **不能造成更新覆盖**，更新同一行的两个事务，必须被分到同一个`worker`中\n2. **同一个事务不能被拆开**，必须放到同一个`worker`中\n\n## 并行复制策略\n\n### MySQL 5.5\n\n#### 按表分发策略\n1. 基本思路：如果两个事务更新的是不同的表，那么就可以并行\n2. 如果有**跨表的事务**，还是需要将两张表放在一起考虑\n\n##### 具体逻辑\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-slave-parallel-replication-by-table.png\" width=500/>\n\n1. 每个`worker`线程对应一个`hash`表，用于保存当前正在这个`worker`的执行队列里的事务所涉及的表\n    - `key`为**库名.表名**，`value`是一个数字，表示队列中有多少事务修改这个表\n2. 在有事务分配给`worker`时，事务里面涉及到的表会被加到对应的`hash`表中\n3. `worker`执行完成后，这个表会从`hash`表中去掉\n4. `hash_table_1`表示：现在`worker_1`的**待执行事务队列**中，有4个事务涉及到`db1.t1`，有1个事务涉及到`db2.t2`\n5. `hash_table_2`表示：现在`worker_2`的**待执行事务队列**中，有1个事务涉及到`db1.t3`\n6. 现在`coordinator`从`relaylog`中读入一个事务`T`，该事务修改的行涉及到`db1.t1`和`db1.t3`\n7. 分配流程\n    - 事务`T`涉及到修改`db1.t1`，而`worker_1`的队列中有事务在修改`db1.t1`，事务`T`与`worker_1`是冲突的\n    - 按照上面的逻辑，事务`T`与`worker_2`也是冲突的\n    - 事务`T`与**多于1**个`worker`冲突，`coordinator`线程进入**等待**\n    - 每个`worker`继续执行，同时会修改`hash_table`\n        - 假设`hash_table_2`里涉及到修改`db1.t3`先执行完，`hash_table_2`会把`db1.t3`去掉\n    - `coordinator`发现跟事务`T`冲突的只有`worker_1`，因此直接将事务`T`分配给`worker_1`\n    - `coordinator`继续读取下一个`relaylog`，继续分发事务\n\n##### 冲突关系\n1. 如果事务与所有`worker`**都不冲突**，`coordinator`线程就会把该事务分发给**最空闲**的`worker`\n2. 如果事务跟**多于1个**`worker`冲突，`coordinator`线程就会进入**等待**状态，直到和该事务存在冲突关系的`worker`**只剩下一个**\n3. 如果事务只跟**1个**`worker`冲突，`coordinator`线程就会把该事务分发给该`worker`\n\n##### 小结\n1. 适用于在**多个表负载均匀**的场景\n2. 如果碰到**热点表**，有可能**退化为单线程复制**\n\n#### 按行分发策略\n1. 核心思路：如果两个事务没有更新**相同的行**，它们是可以在从库上**并行执行**的\n2. 要求：`binlog`必须采用`ROW`格式\n3. 事务`T`与`worker`是否**冲突**的判断依据：修改**同一行**\n4. 为每个`worker`分配一个`hash`表，`key`为**库名+表名+唯一键的值**\n\n##### 唯一键\n```sql\nCREATE TABLE `t1` (\n  `id` INT(11) NOT NULL,\n  `a` INT(11) DEFAULT NULL,\n  `b` INT(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `a` (`a`)\n) ENGINE=InnoDB;\n\nINSERT INTO t1 VALUES (1,1,1),(2,2,2),(3,3,3),(4,4,4),(5,5,5);\n```\n\n| session A | session B |\n| ---- | ---- |\n| UPDATE t1 SET a=6 WHERE id=1; | |\n| | UPDATE t1 SET a=1 WHERE id=2; |\n\n1. 如果两个事务被分发到不同的`worker`，`session B`的事务有可能先执行，报唯一键冲突错误\n2. 因此基于按行分发的策略，事务`hash`还需要考虑唯一键，`key`为**库名+表名+索引a的名字+a的值**\n3. `coordinator`在执行`UPDATE t SET a=1 WHERE id=2`的`binlog`时，hash表的内容\n    - `key=hash_func(db1+t1+\"PRIMARY\"+2), value=2`\n        - `value=2`：修改前后的行id值不变，出现了2次\n    - `key=hash_func(db1+t1+\"a\"+2), value=1`\n        - 影响到`a=2`的行\n    - `key=hash_func(db1+t1+\"a\"+1), value=1`\n        - 影响到`a=1`的行\n4. 相对于按表分发的策略，按行分发的策略在决定线程分发的时候，需要**消耗更多的计算资源**\n\n#### 对比\n1. 按表分发或按行分发的约束\n    - 能够从`binlog`解析出表名，主键值和唯一索引的值，因此必须采用`ROW`格式的`binlog`\n    - 表**必须有主键**，因为**隐含主键**是不会在`binlog`中体现\n    - **不能有外键**，因为**级联更新的行**是不会记录在`binlog`中，这样冲突检测是不准确的\n2. 按行分发策略的并发度更高\n3. 如果操作很多行的大事务，按行分发策略的问题\n    - **耗费内存**：如果要删除100W行数据，hash表就要记录100W个记录\n    - **耗费CPU**：解析`binlog`，然后计算`hash`值\n    - 优化：设置**行数阈值**，当单个事务超过设置的行数阈值，就退化为**单线程**模式，退化过程\n        - `coordinator`暂时先`hold`住这个事务\n        - 等待**所有**`worker`都**执行完成**，变成了空队列\n        - `coordinator`直接执行这个事务\n        - 恢复并行模式\n\n### MySQL 5.6\n1. MySQL 5.6版本，支持粒度为**按库分发**的并行复制\n2. 在决定分发策略的`hash`表里，`key`为**数据库名**\n3. 该策略的并行效果，取决于压力模型，如果各个DB的压力均匀，效果会很好\n4. 相比于**按表分发**和**按行分发**，该策略的两个优势\n    - 构造`hash`值很快，只需要**数据库名**，并且一个实例上DB数不会很多\n    - 不要求`binlog`的格式，因为`STATEMENT`格式的`binlog`也很容易拿到**数据库名**\n5. 如果主库上只有一个DB或者不同DB的热点不同，也起不到并行的效果\n\n### MariaDB\n1. MariaDB的并行复制策略利用了`redolog`的**组提交**（group commit）\n    - 能够在**同一组里提交的事务**，一定**不会修改同一行**\n    - 在**主库**上可以**并行执行**的事务，在**从库**上也一定可以**并行执行**的\n2. 具体做法\n    - 在一组里面提交的事务，有一个相同的`commit_id`，下一组就是`commit_id+1`\n    - `commit_id`直接写到`binlog`里面\n    - 传到**从库**应用的时候，相同`commit_id`的事务可以分发到多个`worker`上执行\n    - 这一组全部执行完成后，`coordinator`再去取下一批\n3. MariaDB目标：**模拟主库的并发行为**\n    - 问题：并没有真正的模拟主库并发度，在主库上，一组事务在`commit`的时候，下一组事务可以同时处于**执行中**的状态\n\n#### 主库并发事务\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-mariadb-master-trx.png\" width=500/>\n\n1. 在主库上，在`trx1`、`trx2`和`trx3`提交的时候，`trx4`、`trx5`和`trx6`是在执行\n2. 在第一组事务提交完成后，下一组事务很快就会进入`commit`状态\n\n#### 从库并发复制\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-mariadb-slave-trx.png\" width=500/>\n\n1. 在从库上，必须等第一组事务**完全执行**完成后，第二组事务才能开始执行，与主库相比，**吞吐量是下降的**\n2. 并且很容易**被大事务拖后腿**\n    - 假设`trx2`是一个**超大事务**，`trx1`和`trx3`执行完成后，只能等`trx2`完全执行完成，下一组才能开始执行\n    - 这段期间，只有一个`worker`线程在工作，是对资源的浪费\n\n### MySQL 5.7\n1. `slave_parallel_type=DATABASE`，使用MySQL 5.6的**按库分发**的并行复制策略\n2. `slave_parallel_type=LOGICAL_CLOCK`，使用类似MariaDB的策略，但针对**并行度**做了优化\n\n```sql\nmysql> SHOW VARIABLES LIKE '%slave_parallel_type%';\n+---------------------+----------+\n| Variable_name       | Value    |\n+---------------------+----------+\n| slave_parallel_type | DATABASE |\n+---------------------+----------+\n```\n\n#### LOGICAL_CLOCK\n1. 并不是所有处于**执行状态**的事务都可以并行的\n    - 因为里面可能包括由于**锁冲突**而处于**锁等待状态**的事务\n    - 如果这些事务在从库上被分配到不同的`worker`，会出现**主从不一致**的情况\n2. MariaDB的并行复制策略：所有处于`redolog commit`状态都事务是可以并行的\n    - 事务处于`redolog commit`状态，表示已经**通过了锁冲突的检验**了\n3. MySQL 5.7的并行复制策略\n    - 同时处于`redolog prepare fsync`状态的事务，在从库执行时是可以并行的\n    - 处于`redolog prepare fsync`状态和`redolog commit`状态之间的事务，在从库上执行时也是可以并行的\n4. `binlog_group_commit_sync_delay`和`binlog_group_commit_sync_no_delay_count`\n    - 故意拉长`binlog`从`write`到`fsync`的时间，以此来减少`binlog`的写盘次数\n    - 在MySQL 5.7，可以制造更多同时处于`redolog prepare fsync`阶段的事务，增加从库复制的并行度\n    - 故意**让主库提交慢些**，**让从库执行快些**\n\n只要达到`redolog prepare fsync`阶段，就已经表示事务已经通过了**锁冲突的检验**了\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-2-phase-commit-opt.png\" width=400/>\n\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"Java核心 -- final + finally + finalize","url":"%2F2019%2F02%2F25%2Fjava-core-final-finally-finalize%2F","content":"\n## final\n1. 修饰**类**，代表不可以**继承扩展**\n2. 修饰**变量**，代表变量不可以**修改**\n3. 修饰**方法**，代表方法不可以**重写**\n\n<!-- more -->\n\n### 实践\n1. 推荐使用`final`关键字来**明确表示**代码的语义和逻辑意图\n2. 将方法或类声明为`final`，明确表示不允许重写或继承\n3. 使用`final`修饰参数或变量，能够避免意外赋值而导致的编程错误\n4. `final`变量产生了某种程度的**不可变**（immutable）的效果，可以用于保护只读数据\n5. 现在`JVM`足够智能，_**`final`对性能的影响，在大部分情况下，都没有必要考虑**_，应用程序更应该关注的是**语义**\n\n### final != immutable\nJava目前没有**原生的immutable支持**\n```java\n// final只能约束strList这个引用不可以被赋值，但strList对象本身的行为是不受影响的\nfinal List<String> strList = new ArrayList<>();\nstrList.add(\"Hello\");\nstrList.add(\"World\");\n// since 9\nList<String> unmodifiableStrList = List.of(\"Hello\", \"world\");\n// throw java.lang.UnsupportedOperationException\nunmodifiableStrList.add(\"again\");\n```\n\n### immutable类\n1. `final class`\n2. 所以成员变量定义为`private final`，并且不要实现`setter`方法\n3. 构造对象时，成员变量使用**深度拷贝**来初始化\n    - 防御编程：因为无法确保输入对象不会被其它线程修改\n4. 如果需要实现`getter`，使用`copy-on-write`原则\n\n## finally\n1. 保证重点代码**一定要被执行**的一种机制\n2. `try-finally`和`try-catch-finally`\n3. `try-with-resources`（JDK 7引入）\n\n```java\ntry {\n    System.exit(-1);\n} finally {\n    // 不会执行\n    System.out.println(\"Print from finally\");\n}\n```\n\n## finalize\n1. `java.lang.Object`中的一个`protected`方法\n2. 设计目标：_**保证对象在被GC前完成特定资源的回收**_\n3. 不推荐使用，在`JDK 9`中已经被标记为`@Deprecated(since=\"9\")`\n4. **无法保证`finalize()`何时会执行，执行的结果是否符合预期**\n    - 如果使用不当会影响性能，导致程序死锁、挂起等问题\n5. 一旦实现类非空的`finalize`方法，会导致对象回收呈现**数量级**上的变慢（40~50倍）\n6. 实现了`finalize`方法的对象是**特殊公民**，JVM需要对它们进行额外的处理\n    - `finalize`本质上成为了**快速回收的阻碍者**\n    - 可能导致对象经过多个**GC周期**才能被回收\n7. `System.runFinalization()`同样是不可预测的\n8. 实践中，`finalize`会拖慢GC，导致**大量对象堆积**，有可能导致`OOM`\n9. 对于消耗非常高频的资源，不要指望`finalize`去承担释放资源的主要职责\n    - 推荐做法：**资源用完即显式释放**，或者利用**资源池**来复用\n10. 另外，`finalize`会**掩盖资源回收时的出错信息**\n\n```java java.lang.ref.Finalizer\n// Throwable被生吞\nprivate void runFinalizer(JavaLangAccess jla) {\n    ...\n    try {\n        Object finalizee = this.get();\n        if (finalizee != null && !(finalizee instanceof java.lang.Enum)) {\n            jla.invokeFinalize(finalizee);\n            // Clear stack slot containing this variable, to decrease\n            // the chances of false retention with a conservative GC\n            finalizee = null;\n        }\n    } catch (Throwable x) { }\n    super.clear();\n}\n```\n\n### 替代方案 -- Cleaner\n1. Java平台逐渐使用`java.lang.ref.Cleaner`替换掉原有的`finalize`实现\n2. `Cleaner`的实现利用了**幻象引用**（Phantom Reference）\n    - 利用**幻象引用**和**引用队列**，保证对象被**销毁之前**做一些类似资源回收的工作\n3. `Cleaner`比`finalize`更加**轻量**，更加**可靠**\n4. 每个`Cleaner`的操作都是**独立**的，都有**自己的运行线程**，可以**避免意外死锁**等问题\n5. 从**可预测**的角度来判断，`Cleaner`或者**幻象引用**改善的程度依然是有限的\n    - 由于种种原因导致**幻象引用堆积**，同样会出现问题\n    - `Cleaner`适合作为**最后的保证手段**，而**不能完全依赖**`Cleaner`进行资源回收\n\n```java\npublic class CleaningExample implements AutoCloseable {\n    // A cleaner, preferably one shared within a library\n    private static final Cleaner cleaner = Cleaner.create();\n\n    // State定义为static，为了避免由于普通的内部类隐含对外部对象的强引用，而导致外部对象无法进入幻象可达的状态\n    static class State implements Runnable {\n        State() {\n            // initialize State needed for cleaning action\n        }\n\n        @Override\n        public void run() {\n            // cleanup action accessing State, executed at most once\n        }\n    }\n\n    private final State state;\n    private final Cleaner.Cleanable cleanable;\n\n    public CleaningExample() {\n        this.state = new State();\n        this.cleanable = cleaner.register(this, state);\n    }\n\n    @Override\n    public void close() {\n        cleanable.clean();\n    }\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["Java Core"],"categories":["Core"]},{"title":"MySQL -- 主从复制的可靠性与可用性","url":"%2F2019%2F02%2F24%2Fmysql-reliability-availability%2F","content":"\n## Master-Master 主从切换\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-master-master-switch.png\" width=500/>\n\n\n<!-- more -->\n\n## 同步延时\n1. 主库A执行完成一个事务，**写入binlog**，记为`T1`\n2. 然后传给从库B，从库B**接收该binlog**，记为`T2`\n3. 从库B执行完成这个事务，记为`T3`\n4. 同步延时：`T3-T1`\n    - 同一个事务，在**从库执行完成的时间**和**主库执行完成的时间**之间的差值\n    - `SHOW SLAVE STATUS`中的`Seconds_Behind_Master`\n\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-ha-sbm.png\" width=1000/>\n\n\n### Seconds_Behind_Master\n1. 计算方法\n    - 每个事务的`binlog`里面都有一个**时间字段**，用于记录该`binlog`在**主库**上的写入时间\n    - 从库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间点差值，得到`Seconds_Behind_Master`\n    - 即`T3-T1`\n2. 如果主库与从库的时间不一致，`Seconds_Behind_Master`会不会有误差？\n    - **一般不会**\n    - 在**从库连接到主库**时，会通过`SELECT UNIX_TIMESTAMP()`获取**当前主库的系统时间**\n    - 如果**从库**发现**当前主库的系统时间**与自己的不一致，在计算`Seconds_Behind_Master`会**自动扣除**这部分差值\n    - 但建立连接后，主库或从库又修改了系统时间，依然会不准确\n3. 在**网络正常**的情况下，`T2-T1`通常会非常小，此时同步延时的主要来源是**`T3-T2`**\n    - _**从库消费`relaylog`的速度跟不上主库生成`binlog`的速度**_\n\n### 延时来源\n1. 从库所在**机器的性能**要弱于主库所在的机器\n    - **更新请求对于IPOS的压力**，在**主库**和**从库**上是**无差别**的\n2. **非对称部署**：20个主库放在4个机器上，但所有从库放在一个机器上\n    - 主从之间可能会**随时切换**，现在一般都会采用**相同规格的机器**+**对称部署**\n3. **从库压力大**\n    - 常见场景：管理后台的查询语句\n    - 从库上的查询耗费大量的**CPU资源**和**IO资源**，影响了同步速度，造成了**同步延时**\n    - 解决方案\n        - **一主多从**，分担读压力，一般都会采用\n        - 通过`binlog`输出到**外部系统**，例如Hadoop\n4. **大事务**\n    - 主库上必须等待**事务执行完成**后才会写入`binlog`，再传给从库\n    - 常见场景1：**一次性删除太多数据**（如归档的历史数据）\n        - 解决方案：控制每个事务删除的数据量，分多次删除\n    - 常见场景2：**大表DDL**\n        - 解决方案：`gh-ost`\n5. 从库的**并行复制能力**（后续展开）\n\n## 切换策略\n\n### 可靠性优先\n切换过程一般由专门的`HA`系统完成，存在**不可用时间**（主库A和从库B都处于**只读**状态）\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-ha-reliability-first.png\" width=500/>\n\n1. 判断**从库B**的`Seconds_Behind_Master`值，当**小于**某个值（例如5）才继续下一步\n2. 把**主库A**改为**只读**状态（`readonly=true`）\n3. 等待**从库B**的`Seconds_Behind_Master`值降为`0`\n4. 把**从库B**改为**可读写**状态（`readonly=false`）\n5. 把**业务请求**切换至**从库B**\n\n### 可用性优先\n不等主从同步完成，**直接把业务请求切换至从库B**，并且让**从库B可读写**，这样几乎不存在不可用时间，但可能会**数据不一致**\n\n#### 表初始化\n```sql\nCREATE TABLE `t` (\n  `id` INT(11) UNSIGNED NOT NULL AUTO_INCREMENT,\n  `c` INT(11) UNSIGNED DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\nINSERT INTO t (c) VALUES (1),(2),(3);\n```\n\n#### 插入数据\n```sql\nINSERT INTO t (c) VALUES (4);\n-- 主库上的其它表有大量的更新，导致同步延时为5S，插入c=4后发起了主从切换\nINSERT INTO t (c) VALUES (5);\n```\n\n#### MIXED\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-ha-availability-first-mixed.png\" width=800/>\n\n1. 主库A执行完`INSERT c=4`，得到`(4,4)`，然后开始执行**主从切换**\n2. 主从之间有5S的同步延迟，从库B会先执行`INSERT c=5`，得到`(4,5)`，并且会把这个`binlog`发给主库A\n3. 从库B执行主库A传过来的`INSERT c=4`，得到`(5,4)`\n4. 主库A执行从库B传过来的`INSERT c=5`，得到`(5,5)`\n5. 此时主库A和从库B会有**两行**不一致的数据\n\n#### ROW\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-ha-availability-first-row.png\" width=800/>\n\n1. 采用`ROW`格式的`binlog`时，会记录新插入行的**所有字段的值**，所以最后只会有**一行**数据不一致\n2. 主库A和从库B的同步线程都会**报错并停止**：`duplicate key error`\n\n### 小结\n1. 使用`ROW`格式的`binlog`，数据不一致的问题**更容易发现**，采用`MIXED`或`STATEMENT`格式的`binlog`，数据可能悄悄地不一致\n2. 主从切换采用**可用性优先**策略，可能会导致**数据不一致**，大多数情况下，优先选择**可靠性优先**策略\n3. 在满足**数据可靠性**的前提下，MySQL的**可用性**依赖于**同步延时**的大小（**同步延时越小**，**可用性越高**）\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 基于Docker搭建主从集群","url":"%2F2019%2F02%2F23%2Fmysql-docker-master-slave%2F","content":"\n## 目录结构\n```\n$ tree\n.\n├── master\n│   ├── data\n│   └── master.cnf\n└── slave\n    ├── data\n    └── slave.cnf\n```\n\n<!-- more -->\n\n### master.cnf\n```\n[mysqld]\npid-file    = /var/run/mysqld/mysqld.pid\nsocket      = /var/run/mysqld/mysqld.sock\ndatadir     = /var/lib/mysql\nserver-id=1\nlog-bin=master-bin\ngtid_mode=on\nenforce_gtid_consistency=on\n```\n\n### slave.cnf\n```\n[mysqld]\npid-file    = /var/run/mysqld/mysqld.pid\nsocket      = /var/run/mysqld/mysqld.sock\ndatadir     = /var/lib/mysql\nserver-id=2\nlog-bin=slave-bin\nread-only=1\nrelay_log=relay-bin\nlog-slave-updates=1\ngtid_mode=on\nenforce_gtid_consistency=on\n```\n\n## 启动容器\n```\n$ docker run --name mysql_master -d -e MYSQL_ROOT_PASSWORD=123456 -v ~/mysql/master/data:/var/lib/mysql -v ~/mysql/master/master.cnf:/etc/mysql/mysql.conf.d/master.cnf mysql:5.7\n519a9c6d2d6bb03916fb7659d3a5be86a179e6569d6545215517720665da23f0\n\n$ docker run --name mysql_slave -d -e MYSQL_ROOT_PASSWORD=123456 -v ~/mysql/slave/data:/var/lib/mysql -v ~/mysql/slave/slave.cnf:/etc/mysql/mysql.conf.d/slave.cnf mysql:5.7\nd087a00e01a93a816b023c4f2d87a15cc475446e8822031ae70e59d654cf651e\n\n$ docker ps -a\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                 NAMES\nd087a00e01a9        mysql:5.7           \"docker-entrypoint.s…\"   9 seconds ago       Up 8 seconds        3306/tcp, 33060/tcp   mysql_slave\n519a9c6d2d6b        mysql:5.7           \"docker-entrypoint.s…\"   24 seconds ago      Up 23 seconds       3306/tcp, 33060/tcp   mysql_master\n\n$ docker inspect --format='{{.NetworkSettings.IPAddress}}' mysql_master mysql_slave\n172.17.0.2\n172.17.0.3\n```\n\n## 主库\n\n### 添加复制账号\n```sql\n$ docker exec -it mysql_master bash\nroot@519a9c6d2d6b:/# mysql -uroot -p123456\n\nmysql> GRANT REPLICATION SLAVE ON *.* to 'replication'@'%' IDENTIFIED BY '123456';\nQuery OK, 0 rows affected, 1 warning (0.03 sec)\n\nmysql> SHOW WARNINGS;\n+---------+------+------------------------------------------------------------------------------------------------------------------------------------+\n| Level   | Code | Message                                                                                                                            |\n+---------+------+------------------------------------------------------------------------------------------------------------------------------------+\n| Warning | 1287 | Using GRANT for creating new user is deprecated and will be removed in future release. Create new user with CREATE USER statement. |\n+---------+------+------------------------------------------------------------------------------------------------------------------------------------+\n```\n\n### 查看binlog位置\n```sql\nmysql> SHOW MASTER STATUS;\n+-------------------+----------+--------------+------------------+------------------------------------------+\n| File              | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set                        |\n+-------------------+----------+--------------+------------------+------------------------------------------+\n| master-bin.000003 |      484 |              |                  | b0bda503-3cf1-11e9-8c3a-0242ac110002:1-6 |\n+-------------------+----------+--------------+------------------+------------------------------------------+\n```\n\n## 从库\n\n### 配置同步信息\n```sql\n$ docker exec -it mysql_slave bash\nroot@d087a00e01a9:/# mysql -uroot -p123456\n\n-- 基于位点\n-- mysql> CHANGE MASTER TO master_host='172.17.0.2',master_user='replication',master_password='123456',master_log_file='master-bin.000003',master_log_pos=484,master_port=3306;\n\n-- 基于GTID\nmysql> CHANGE MASTER TO master_host='172.17.0.2',master_user='replication',master_password='123456',master_auto_position=1,master_port=3306;\nQuery OK, 0 rows affected, 2 warnings (0.06 sec)\n\n-- Slave_IO_Running=No, Slave_SQL_Running=No\nmysql> SHOW SLAVE STATUS\\G;\n*************************** 1. row ***************************\n               Slave_IO_State:\n                  Master_Host: 172.17.0.2\n                  Master_User: replication\n                  Master_Port: 3306\n                Connect_Retry: 60\n              Master_Log_File:\n          Read_Master_Log_Pos: 4\n               Relay_Log_File: relay-bin.000001\n                Relay_Log_Pos: 4\n        Relay_Master_Log_File:\n             Slave_IO_Running: No\n            Slave_SQL_Running: No\n              Replicate_Do_DB:\n          Replicate_Ignore_DB:\n           Replicate_Do_Table:\n       Replicate_Ignore_Table:\n      Replicate_Wild_Do_Table:\n  Replicate_Wild_Ignore_Table:\n                   Last_Errno: 0\n                   Last_Error:\n                 Skip_Counter: 0\n          Exec_Master_Log_Pos: 0\n              Relay_Log_Space: 154\n              Until_Condition: None\n               Until_Log_File:\n                Until_Log_Pos: 0\n           Master_SSL_Allowed: No\n           Master_SSL_CA_File:\n           Master_SSL_CA_Path:\n              Master_SSL_Cert:\n            Master_SSL_Cipher:\n               Master_SSL_Key:\n        Seconds_Behind_Master: NULL\nMaster_SSL_Verify_Server_Cert: No\n                Last_IO_Errno: 0\n                Last_IO_Error:\n               Last_SQL_Errno: 0\n               Last_SQL_Error:\n  Replicate_Ignore_Server_Ids:\n             Master_Server_Id: 0\n                  Master_UUID:\n             Master_Info_File: /var/lib/mysql/master.info\n                    SQL_Delay: 0\n          SQL_Remaining_Delay: NULL\n      Slave_SQL_Running_State:\n           Master_Retry_Count: 86400\n                  Master_Bind:\n      Last_IO_Error_Timestamp:\n     Last_SQL_Error_Timestamp:\n               Master_SSL_Crl:\n           Master_SSL_Crlpath:\n           Retrieved_Gtid_Set:\n            Executed_Gtid_Set: ba0b2f12-3cf1-11e9-9c40-0242ac110003:1-5\n                Auto_Position: 1\n         Replicate_Rewrite_DB:\n                 Channel_Name:\n           Master_TLS_Version:\n```\n\n### 开启同步\n```sql\nmysql> START SLAVE;\nQuery OK, 0 rows affected (0.01 sec)\n\n-- Slave_IO_Running=Yes, Slave_SQL_Running=Yes, Seconds_Behind_Master=0\nmysql> SHOW SLAVE STATUS\\G;\n*************************** 1. row ***************************\n               Slave_IO_State: Waiting for master to send event\n                  Master_Host: 172.17.0.2\n                  Master_User: replication\n                  Master_Port: 3306\n                Connect_Retry: 60\n              Master_Log_File: master-bin.000003\n          Read_Master_Log_Pos: 484\n               Relay_Log_File: relay-bin.000003\n                Relay_Log_Pos: 699\n        Relay_Master_Log_File: master-bin.000003\n             Slave_IO_Running: Yes\n            Slave_SQL_Running: Yes\n              Replicate_Do_DB:\n          Replicate_Ignore_DB:\n           Replicate_Do_Table:\n       Replicate_Ignore_Table:\n      Replicate_Wild_Do_Table:\n  Replicate_Wild_Ignore_Table:\n                   Last_Errno: 0\n                   Last_Error:\n                 Skip_Counter: 0\n          Exec_Master_Log_Pos: 484\n              Relay_Log_Space: 3058612\n              Until_Condition: None\n               Until_Log_File:\n                Until_Log_Pos: 0\n           Master_SSL_Allowed: No\n           Master_SSL_CA_File:\n           Master_SSL_CA_Path:\n              Master_SSL_Cert:\n            Master_SSL_Cipher:\n               Master_SSL_Key:\n        Seconds_Behind_Master: 0\nMaster_SSL_Verify_Server_Cert: No\n                Last_IO_Errno: 0\n                Last_IO_Error:\n               Last_SQL_Errno: 0\n               Last_SQL_Error:\n  Replicate_Ignore_Server_Ids:\n             Master_Server_Id: 1\n                  Master_UUID: b0bda503-3cf1-11e9-8c3a-0242ac110002\n             Master_Info_File: /var/lib/mysql/master.info\n                    SQL_Delay: 0\n          SQL_Remaining_Delay: NULL\n      Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates\n           Master_Retry_Count: 86400\n                  Master_Bind:\n      Last_IO_Error_Timestamp:\n     Last_SQL_Error_Timestamp:\n               Master_SSL_Crl:\n           Master_SSL_Crlpath:\n           Retrieved_Gtid_Set: b0bda503-3cf1-11e9-8c3a-0242ac110002:1-6\n            Executed_Gtid_Set: b0bda503-3cf1-11e9-8c3a-0242ac110002:1-6,\nba0b2f12-3cf1-11e9-9c40-0242ac110003:1-5\n                Auto_Position: 1\n         Replicate_Rewrite_DB:\n                 Channel_Name:\n           Master_TLS_Version:\n```\n\n## 验证\n```\n$ docker exec mysql_slave mysql -uroot -p123456 -e \"SHOW DATABASES\"\nDatabase\ninformation_schema\nmysql\nperformance_schema\nsys\n\n$ docker exec mysql_master mysql -uroot -p123456 -e \"CREATE DATABASE test\"\n\n$ docker exec mysql_slave mysql -uroot -p123456 -e \"SHOW DATABASES\"\nDatabase\ninformation_schema\nmysql\nperformance_schema\nsys\ntest\n```\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 主从复制的基本原理","url":"%2F2019%2F02%2F22%2Fmysql-master-slave-replication%2F","content":"\n## 主从切换\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-master-slave-switch.png\" width=500/>\n\n\n<!-- more -->\n\n1. 在状态1，客户端的读写都是直接访问节点A，节点B是节点A的从库\n    - 只是将节点A的更新都同步过来，在节点B本地执行，保持一致\n2. 在状态1，虽然节点B没有被直接访问，但依然建议设置成`readonly`模式\n    - 运营类的查询语句会在从库上执行，设置成`readonly`模式能够防止一些误操作\n    - 防止切换逻辑有Bug，例如出现**双写**，造成主**从不一致**\n    - 可以通过`readonly`状态来判断节点的**角色**\n3. 在状态1，节点B设置为`readonly`模式，同样能与节点A保持同步更新\n    - `readonly`设置对**超级权限用户**是无效的，而节点B中用于**同步更新**的线程，就拥有超级权限\n\n## 主从同步\n在节点A执行update语句，然后同步到节点B\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-master-slave-replication.png\" width=600/>\n\n1. 从库B与主库A之间维持一个**长连接**，主库A内部有一个专门用于服务于从库B长连接的线程\n2. 在从库B上执行`CHANGE MASTER`命令，设置主库A的信息\n    - `IP`、`PORT`、`USER`、`PASSWORD`\n    - 从**哪个位置**（**文件名** + **日志偏移量**）开始请求`binlog`\n3. 在从库B上执行`START SLAVE`命令，这时从库B会启动两个线程：`io_thread` + `sql_thread`\n    - `io_thread`：负责与主库A**建立连接**\n4. 主库A校验完`USER`和`PASSWORD`后，按照从库B传过来的**位置信息**，从本地读取`binlog`，发送给从库B\n5. 从库B拿到`binlog`后，写到本地文件，即**中转日志**（`relaylog`）\n6. `sql_thread`读取`relaylog`，解析出日志里的命令，然后执行\n\n## binlog\n\n### 格式\n1. STATEMENT\n2. ROW\n3. MIXED = STATEMENT + ROW\n\n### 表初始化\n```sql\nCREATE TABLE `t` (\n  `id` INT(11) NOT NULL,\n  `a` INT(11) DEFAULT NULL,\n  `t_modified` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  PRIMARY KEY (`id`),\n  KEY `a` (`a`),\n  KEY `t_modified`(`t_modified`)\n) ENGINE=InnoDB;\n\nINSERT INTO t VALUES (1,1,'2018-11-13');\nINSERT INTO t VALUES (2,2,'2018-11-12');\nINSERT INTO t VALUES (3,3,'2018-11-11');\nINSERT INTO t VALUES (4,4,'2018-11-10');\nINSERT INTO t VALUES (5,5,'2018-11-09');\n```\n\n### STATEMENT\n```sql\nSET binlog_format='STATEMENT';\n-- mysql -c启动\nDELETE FROM t /*comment*/  WHERE a>=4 AND T_MODIFIED<='2018-11-10' LIMIT 1;\n```\n```sql\nmysql > SHOW BINLOG EVENTS IN 'binlog.000014';\n| binlog.000014 | 6814 | Anonymous_Gtid |         1 |        6889 | SET @@SESSION.GTID_NEXT= 'ANONYMOUS'\n| binlog.000014 | 6889 | Query          |         1 |        6979 | BEGIN\n| binlog.000014 | 6979 | Query          |         1 |        7138 | use `test`; DELETE FROM t /*comment*/  WHERE a>=4 AND T_MODIFIED<='2018-11-10' LIMIT 1\n| binlog.000014 | 7138 | Xid            |         1 |        7169 | COMMIT /* xid=73 */\n```\n1. `BEGIN`与`COMMIT`对应，包装成一个事务，`xid=73`是**事务ID**\n2. `use test;`是**自动添加**的，保证日志在从库上执行时，能找到正确的库\n3. `STATEMENT`格式的`binlog`记录的是**SQL原文**\n\n#### SHOW WARNINGS\n```sql\nmysql> SHOW WARNINGS;\n+-------+------+--------------------------------------------------------------------------------------------------------------------------------+\n| Level | Code | Message                                                                                                                        |\n+-------+------+--------------------------------------------------------------------------------------------------------------------------------+\n| Note  | 1592 | Unsafe statement written to the binary log using statement format since BINLOG_FORMAT = STATEMENT.                             |\n|       |      | The statement is unsafe because it uses a LIMIT clause. This is unsafe because the set of rows included cannot be predicted.   |\n+-------+------+--------------------------------------------------------------------------------------------------------------------------------+\n\nmysql> EXPLAIN DELETE FROM t /*comment*/  WHERE a>=4 AND T_MODIFIED<='2018-11-10' LIMIT 1;\n+----+-------------+-------+------------+-------+---------------+------+---------+-------+------+----------+-------------+\n| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref   | rows | filtered | Extra       |\n+----+-------------+-------+------------+-------+---------------+------+---------+-------+------+----------+-------------+\n|  1 | DELETE      | t     | NULL       | range | a,t_modified  | a    | 5       | const |    1 |   100.00 | Using where |\n+----+-------------+-------+------------+-------+---------------+------+---------+-------+------+----------+-------------+\n```\n1. `Unsafe`的原因：`DELETE` + `LIMIT`，可能会导致**主从不一致**\n2. 如果`DELETE`语句使用的是索引`a`，那么删除的是`a=4`这一行\n3. 如果`DELETE`语句使用的是索引`t_modified`，那么删除的是`t_modified='2018-11-09'`这一行，即`a=5`这一行\n4. 当`binlog_format=STATEMENT`，`binlog`记录的只是**SQL原文**，可能会导致**主从不一致**\n\n### ROW\n```sql\nSET binlog_format='ROW';\n-- mysql -c启动\nDELETE FROM t /*comment*/  WHERE a>=4 AND T_MODIFIED<='2018-11-10' LIMIT 1;\n```\n```sql\nmysql > SHOW BINLOG EVENTS IN 'binlog.000014';\n| binlog.000014 | 12010 | Anonymous_Gtid |         1 |       12085 | SET @@SESSION.GTID_NEXT= 'ANONYMOUS'\n| binlog.000014 | 12085 | Query          |         1 |       12168 | BEGIN\n| binlog.000014 | 12168 | Table_map      |         1 |       12218 | table_id: 72 (test.t)\n| binlog.000014 | 12218 | Delete_rows    |         1 |       12266 | table_id: 72 flags: STMT_END_F\n| binlog.000014 | 12266 | Xid            |         1 |       12297 | COMMIT /* xid=102 */\n```\n1. `ROW`格式的`binlog`并没有记录**SQL原文**，而是替换成了两个`Event`：`Table_map` + `Delete_rows`\n    - `Table_map Event`：说明要操作的是`test.t`\n    - `Delete_rows Event`：定义**删除**行为\n2. 查看更详细的信息需要借助`mysqlbinlog`命令，从`12010`开始解析日志\n\n#### mysqlbinlog\n```\n$ mysqlbinlog -vv ./binlog.000014 --start-position=12010;\n/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;\n/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;\nDELIMITER /*!*/;\n# at 4\n#190221 13:29:32 server id 1  end_log_pos 124 CRC32 0xe3d095e4 \tStart: binlog v 4, server v 8.0.12 created 190221 13:29:32 at startup\n# Warning: this binlog is either in use or was not closed properly.\nROLLBACK/*!*/;\nBINLOG '\nPDduXA8BAAAAeAAAAHwAAAABAAQAOC4wLjEyAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAA8N25cEwANAAgAAAAABAAEAAAAYAAEGggAAAAICAgCAAAACgoKKioAEjQA\nCgHkldDj\n'/*!*/;\n# at 12010\n#190222 16:35:19 server id 1  end_log_pos 12085 CRC32 0xfab19774 \tAnonymous_GTID\tlast_committed=39\tsequence_number=40\trbr_only=yes\toriginal_committed_timestamp=1550824519718005\timmediate_commit_timestamp=1550824519718005\ttransaction_length=287\n/*!50718 SET TRANSACTION ISOLATION LEVEL READ COMMITTED*//*!*/;\n# original_commit_timestamp=1550824519718005 (2019-02-22 16:35:19.718005 CST)\n# immediate_commit_timestamp=1550824519718005 (2019-02-22 16:35:19.718005 CST)\n/*!80001 SET @@session.original_commit_timestamp=1550824519718005*//*!*/;\nSET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;\n# at 12085\n#190222 16:35:19 server id 1  end_log_pos 12168 CRC32 0x322f1087 \tQuery\tthread_id=12\texec_time=0\terror_code=0\nSET TIMESTAMP=1550824519/*!*/;\nSET @@session.pseudo_thread_id=12/*!*/;\nSET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;\nSET @@session.sql_mode=1168113696/*!*/;\nSET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;\n/*!\\C utf8mb4 *//*!*/;\nSET @@session.character_set_client=255,@@session.collation_connection=255,@@session.collation_server=33/*!*/;\nSET @@session.time_zone='SYSTEM'/*!*/;\nSET @@session.lc_time_names=0/*!*/;\nSET @@session.collation_database=DEFAULT/*!*/;\n/*!80005 SET @@session.default_collation_for_utf8mb4=255*//*!*/;\nBEGIN\n/*!*/;\n# at 12168\n#190222 16:35:19 server id 1  end_log_pos 12218 CRC32 0x7cb9c355 \tTable_map: `test`.`t` mapped to number 72\n# at 12218\n#190222 16:35:19 server id 1  end_log_pos 12266 CRC32 0x155fe45e \tDelete_rows: table id 72 flags: STMT_END_F\n\nBINLOG '\nR7RvXBMBAAAAMgAAALovAAAAAEgAAAAAAAEABHRlc3QAAXQAAwMDEQEAAgEBAFXDuXw=\nR7RvXCABAAAAMAAAAOovAAAAAEgAAAAAAAEAAgAD/wAEAAAABAAAAFvlrwBe5F8V\n'/*!*/;\n### DELETE FROM `test`.`t`\n### WHERE\n###   @1=4 /* INT meta=0 nullable=0 is_null=0 */\n###   @2=4 /* INT meta=0 nullable=1 is_null=0 */\n###   @3=1541779200 /* TIMESTAMP(0) meta=0 nullable=0 is_null=0 */\n# at 12266\n#190222 16:35:19 server id 1  end_log_pos 12297 CRC32 0x4d1336cc \tXid = 102\nCOMMIT/*!*/;\nSET @@SESSION.GTID_NEXT= 'AUTOMATIC' /* added by mysqlbinlog */ /*!*/;\nDELIMITER ;\n# End of log file\n/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;\n/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;\n```\n1. `server id 1`：事务在`server_id=1`的库上执行\n2. 每个`Event`都有`CRC32`值，控制参数`binlog_checksum`\n3. `Table_map Event`会map到一个数字，代表一张要打开的表\n    - 如果要操作多张表，会有多个`Table_map Event`\n4. `@1=4,@2=4,@3=1541779200`：详细记录**各个字段的值**\n5. `binlog_row_image`\n    - `FULL`：记录**所有字段**的值\n    - `MINIMAL`：记录**必要**的信息，这里只会记录`id=4`\n6. 当`binlog_format=ROW`，传到从库的执行时会删除`id=4`的行，不会主从不一致\n\n```sql\nmysql> SHOW VARIABLES LIKE '%binlog_checksum%';\n+-----------------+-------+\n| Variable_name   | Value |\n+-----------------+-------+\n| binlog_checksum | CRC32 |\n+-----------------+-------+\n\nmysql> SHOW VARIABLES LIKE '%binlog_row_image%';\n+------------------+-------+\n| Variable_name    | Value |\n+------------------+-------+\n| binlog_row_image | FULL  |\n+------------------+-------+\n```\n\n### MIXED\n1. `STATEMENT`：可能导致**主从不一致**\n2. `ROW`：非常**占用空间**和**耗费IO资源**\n3. `MIXED`是一个折中方案\n    - MySQL自行判断SQL语句是否有可能导致**主从不一致**\n    - 如果有可能则采用`ROW`格式，否则采用`STATEMENT`格式\n4. 线上配置最少是`MIXED`，更严格是`ROW`（**推荐**，可用于**恢复数据**）\n\n#### now\n```sql\nSET binlog_format='MIXED';\nINSERT INTO t VALUES (10,10, NOW());\n```\n```sql\n-- 采用的是STATEMENT格式\nmysql > SHOW BINLOG EVENTS IN 'binlog.000014';\n| binlog.000014 | 14314 | Anonymous_Gtid |         1 |       14389 | SET @@SESSION.GTID_NEXT= 'ANONYMOUS'\n| binlog.000014 | 14389 | Query          |         1 |       14479 | BEGIN\n| binlog.000014 | 14479 | Query          |         1 |       14599 | use `test`; INSERT INTO t VALUES (10,10, NOW())\n| binlog.000014 | 14599 | Xid            |         1 |       14630 | COMMIT /* xid=116 */\n```\n```sql\n$ mysqlbinlog -vv ./binlog.000014 --start-position=14479 --stop-position=14599;\n/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;\n/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;\nDELIMITER /*!*/;\n# at 4\n#190221 13:29:32 server id 1  end_log_pos 124 CRC32 0xe3d095e4 \tStart: binlog v 4, server v 8.0.12 created 190221 13:29:32 at startup\n# Warning: this binlog is either in use or was not closed properly.\nROLLBACK/*!*/;\nBINLOG '\nPDduXA8BAAAAeAAAAHwAAAABAAQAOC4wLjEyAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAA8N25cEwANAAgAAAAABAAEAAAAYAAEGggAAAAICAgCAAAACgoKKioAEjQA\nCgHkldDj\n'/*!*/;\n# at 14479\n#190222 17:39:17 server id 1  end_log_pos 14599 CRC32 0xcbe6d9c4 \tQuery\tthread_id=12\texec_time=0\terror_code=0\nuse `test`/*!*/;\nSET TIMESTAMP=1550828357/*!*/;\nSET @@session.pseudo_thread_id=12/*!*/;\nSET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;\nSET @@session.sql_mode=1168113696/*!*/;\nSET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;\n/*!\\C utf8mb4 *//*!*/;\nSET @@session.character_set_client=255,@@session.collation_connection=255,@@session.collation_server=33/*!*/;\nSET @@session.time_zone='SYSTEM'/*!*/;\nSET @@session.lc_time_names=0/*!*/;\nSET @@session.collation_database=DEFAULT/*!*/;\n/*!80005 SET @@session.default_collation_for_utf8mb4=255*//*!*/;\nINSERT INTO t VALUES (10,10, NOW())\n/*!*/;\nSET @@SESSION.GTID_NEXT= 'AUTOMATIC' /* added by mysqlbinlog */ /*!*/;\nDELIMITER ;\n# End of log file\n/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;\n/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;\n```\n记录`binlog`时，执行了`SET TIMESTAMP`命令，约定了后续`now()`函数的返回值，因此确保了**主从一致**\n\n## 恢复数据\n\n### DELETE\n1. 即便执行的是`DELETE`语句，`ROW`格式（`binlog_row_image=FULL`）的`binlog`也会保存被删除的**整行数据**\n2. 当发现误删数据后，可以直接将`binlog`中的`DELETE`换成`INSERT`即可\n\n### INSERT\n1. 与`DELETE`类似，能**精确定位**到误插入的数据\n2. 将`INSERT`换成`DELETE`即可\n\n### UPDATE\n1. 针对`UPDATE`语句，`ROW`格式的`binlog`记录的是**修改前后的整行数据**\n2. 如果是误更新，只需要将这个`EVENT`前后的两行信息**对调**一下，再到数据库执行即可\n\n### 标准做法\n用`mysqlbinlog`先**解析**出来，然后把**整个解析结果**发个MySQL执行\n```\n$ mysqlbinlog binlog.000014 --start-position=14314 --stop-position=14599 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;\n```\n\n## 循环复制\n线上常用为`Master-Master`结构，节点A与节点B为**互为主从**关系（在切换过程中无需修改主从关系）\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-master-master-switch.png\" width=500/>\n\n1. `log_slave_updates=ON`，从库执行完`relaylog`后也会生成`binlog`\n2. 从节点A更新的事务，`binlog`记录的都是节点A的`server id`\n3. 传到节点B执行以后，节点B生成的`binlog`的`server id`依然是节点A的`server id`\n4. 再传回到节点A，节点A判断到这个`server id`与自己相同，就不会再处理该日志，解决**循环复制**的问题\n\n```sql\nmysql> SHOW VARIABLES LIKE '%log_slave%';\n+-------------------+-------+\n| Variable_name     | Value |\n+-------------------+-------+\n| log_slave_updates | ON    |\n+-------------------+-------+\n```\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 数据可靠性","url":"%2F2019%2F02%2F21%2Fmysql-reliability%2F","content":"\n## binlog的写入机制\n1. 事务在执行过程中，先把日志写到`binlog cache`，事务**提交**时，再把`binlog cache`写到`binlog file`\n2. 一个事务的binlog是**不能被拆开**的，不论事务多大，也要确保**一次性写入**\n3. 系统会给**每个线程**分配一块内存`binlog cache`，由参数`binlog_cache_size`控制\n    - 如果超过了`binlog_cache_size`，需要**暂存到磁盘**\n4. 事务提交时，执行器把`binlog cache`里面的**完整事务**写入到`binlog file`，并**清空**`binlog cache`\n\n```sql\n-- 2097152 Bytes = 2 MB\nmysql> SHOW VARIABLES LIKE '%binlog_cache_size%';\n+-----------------------+----------------------+\n| Variable_name         | Value                |\n+-----------------------+----------------------+\n| binlog_cache_size     | 2097152              |\n| max_binlog_cache_size | 18446744073709547520 |\n+-----------------------+----------------------+\n```\n\n<!-- more -->\n\n### 写入过程\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-binlog-write.png\" width=800/>\n\n1. 每个线程都有自己的`binlog cache`，但共用一份`binlog file`\n2. `write`：把日志写入到**文件系统的page cache**，但并没有将数据持久化到磁盘，**速度比较快**\n3. `fsync`：将数据持久化到磁盘，`fsync`才会占用磁盘的**IOPS**\n\n### sync_binlog\n```sql\nmysql> SHOW VARIABLES LIKE '%sync_binlog%';\n+---------------+-------+\n| Variable_name | Value |\n+---------------+-------+\n| sync_binlog   | 0     |\n+---------------+-------+\n```\n1. `sync_binlog=0`，每次提交事务都只`write`，不`fsync`\n2. `sync_binlog=1`，每次提交事务都会执行`fsync`\n3. `sync_binlog=N`，每次提交事务都会`write`，但累计N个事务后才`fsync`\n    - 一般为`(100 ~ 1,000)`，可以**提高性能**\n    - 如果主机**断电**，会**丢失最近的N个事务的binlog**\n\n## redolog的写入机制\n1. 事务在执行过程中，生成的`redolog`需要先写到`redolog buffer`\n2. `redolog buffer`里面的内容，并不需要**每次**生成后都直接持久化到磁盘\n    - 如果事务执行期间，MySQL异常重启，那么这部分日志丢失了\n    - 由于事务**没有提交**，所以这时的日志丢失不会有什么影响\n3. 在事务还未提交时，`redolog buffer`中的**部分日志**也是有可能**持久化到磁盘**的\n\n### redolog的状态\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-redolog-status.png\" width=500/>\n\n1. 红色部分：存在于`redolog buffer`中，物理上存在于**MySQL进程的内存**\n2. 黄色部分：写到磁盘（`write`），但没有持久化（`fsync`），物理上存在于**文件系统的page cache**\n3. 绿色部分：持久化到磁盘，物理上存在于`hard disk`\n4. 日志写到`redolog buffer`是很快的，`write`到`FS page cache`也比较快，但`fsync`到磁盘的速度就会慢很多\n\n### redolog的写入策略\n\n#### 事务提交\n```sql\nmysql> show variables like '%innodb_flush_log_at_trx_commit%';\n+--------------------------------+-------+\n| Variable_name                  | Value |\n+--------------------------------+-------+\n| innodb_flush_log_at_trx_commit | 2     |\n+--------------------------------+-------+\n```\n1. `innodb_flush_log_at_trx_commit=0`\n    - 每次事务提交时都只是将`redolog`写入到`redolog buffer`（**红色部分**）\n    - `redolog`只存在内存中，MySQL本身异常重启也会丢失数据，**风险太大**\n2. `innodb_flush_log_at_trx_commit=1`\n    - 每次事务提交时都将`redolog`持久化到磁盘（**绿色部分**）\n    - 两阶段提交：`redolog prepare` -> `写binlog` -> `redolog commit`\n    - `redolog prepare`需要持久化一次，因为崩溃恢复依赖于**prepare**的`redolog`和`binlog`\n    - `redolog commit`就不需要持久化（`fsync`）了，只需要`write`到`FS page cache`即可\n    - **双1配置**：一个事务完整提交前，需要**2次刷盘**：`redolog prepare` + `binlog`\n        - 优化：**组提交**\n3. `innodb_flush_log_at_trx_commit=2`\n    - 每次事务提交时都将`redolog`写入到`FS page cache`（**黄色部分**）\n\n#### 后台刷新\n1. 后台线程：每隔**1秒**，就会将`redolog buffer`中的日志，调用`write`写入到`FS page cache`，再调用`fsync`持久化到磁盘\n2. 事务执行期间的`redolog`是直接写到`redolog buffer`，这些`redolog`也会被后台线程一起持久化到磁盘\n    - 即一个**未提交**的事务的`redolog`也是有可能已经持久化到磁盘的\n\n#### 事务未提交\n```sql\n-- 16777216 Bytes = 16 MB\nmysql> SHOW VARIABLES LIKE '%innodb_log_buffer_size%';\n+------------------------+----------+\n| Variable_name          | Value    |\n+------------------------+----------+\n| innodb_log_buffer_size | 16777216 |\n+------------------------+----------+\n```\n1. 当`redolog buffer`占用的空间即将达到`innodb_log_buffer_size`的**一半**时，后台线程会**主动写盘**\n    - 由于事务尚未提交，因此这个写盘动作是在`write`，不会调用`fsync`，停留在`FS page cache`\n2. 在**并行事务提交**时，顺带将**未提交事务**的`redolog buffer`持久化到磁盘\n    - 事务A执行到一半，有部分`redolog`在`redolog buffer`\n    - 事务B提交，且`innodb_flush_log_at_trx_commit=1`，事务B要把`redolog buffer`里面的日志**全部**持久化到磁盘\n    - 这时会带上事务A在`redolog buffer`里的日志一起持久化到磁盘\n\n### 组提交\n\n#### LSN\n1. `LSN`：log sequence number\n2. `LSN`是**单调递增**的，对应`redolog`的**写入点**\n    - 每次写入长度为length的`redolog`，`LSN`就会加上length\n3. `LSN`也会写入到**数据页**中，用来**确保数据页不会被多次执行重复的`redolog`**\n\n#### 样例\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-redolog-group-commit.png\" width=500/>\n\n1. 三个**并发事务**处于`prepare`阶段：`tx1`、`tx2`、`tx3`\n    - 都完成写入`redolog buffer`和**持久化到磁盘**的过程\n    - 对应的`LSN`为`50`、`120`、`160`\n2. `tx1`第一个到达，被选为组`leader`\n3. 等`trx1`要开始**写盘**的时候，组内已经有3个事务，`LSN`变成了`160`\n4. `trx1`带着`LSN=160`去写盘，等`trx1`返回时，所有`LSN<160`的`redolog`都已经持久化到磁盘\n    - `trx2`和`trx3`可以**直接返回**\n\n#### 小结\n1. 一次组提交里面，组员越多，节省磁盘的IOPS的效果越好\n2. 在**并发更新**场景下，第1个事务写完`redolog buffer`后，接下来的`fsync`越晚调用，节省磁盘的IOPS的效果越好\n\n#### binlog组提交\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-2-phase-commit.png\" width=500/>\n\n`写binlog`其实分两步：`binlog cache -> (write) -> binlog file` + `binlog file -> (fsync) -> disk`\nMySQL为了让组提交效果更好，延后了`fsync`执行时机，两阶段提交细化如下\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-2-phase-commit-opt.png\" width=500/>\n\n`binlog`也可以支持**组提交**了，但第3步执行很快，导致了`binlog`的组提交效果不如`redolog`的组提交效果\n\n**参数**\n```sql\nmysql> SHOW VARIABLES LIKE '%binlog_group_commit_sync%';\n+-----------------------------------------+-------+\n| Variable_name                           | Value |\n+-----------------------------------------+-------+\n| binlog_group_commit_sync_delay          | 0     |\n| binlog_group_commit_sync_no_delay_count | 0     |\n+-----------------------------------------+-------+\n```\n1. `binlog_group_commit_sync_delay`：延迟多少**微秒**才调用`fsync`\n2. `binlog_group_commit_sync_no_delay_count`：累计多少次之后才调用`fsync`\n3. 两者关系：**或**，但当`binlog_group_commit_sync_delay=0`时，`binlog_group_commit_sync_no_delay_count`无效\n\n## WAL性能\n1. `redolog`和`binlog`都是**顺序写**\n2. **组提交机制**：可以大幅降低磁盘的**IOPS消耗**\n\n## MySQL的IO瓶颈\n1. 设置`binlog_group_commit_sync_delay`和`binlog_group_commit_sync_no_delay_count`\n    - **故意等待**，利用**组提交**减少**IOPS**消耗，同时可能会**增加语句的响应时间**，但**没有丢数据风险**\n2. `sync_binlog=N(100~1,000)`\n    - 主机**断电**会丢失`binlog`日志\n3. `innodb_flush_log_at_trx_commit=2`\n    - 主机**断电**会丢失数据\n    - `2`和`0`的**性能接近**，但设置为`0`（数据仅在`redolog buffer`），在MySQL**异常重启**时也会丢失数据\n\n## crash-safe的保证\n1. 如果客户端收到**事务成功**的消息，事务就一定持久化了的\n2. 如果客户端收到**事务失败**（主键冲突、回滚等）的消息，事务一定是失败的\n3. 如果客户端收到**执行异常**的消息，应用需要**重连**后通过**查询**当前状态来继续后续的逻辑\n    - 数据库只需要保证内部（**数据与日志之间**，**主从之间**）一致即可\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"Java核心 -- Exception + Error","url":"%2F2019%2F02%2F20%2Fjava-core-exception-error%2F","content":"\n## 继承关系\n<img src=\"https://java-core-1253868755.cos.ap-guangzhou.myqcloud.com/java-core-exception.png\" />\n\n<!-- more -->\n\n## 概念\n1. Exception：程序正常运行中，可以**预料**的意外情况，可能并且应该被捕获，进行相关处理\n    - Checked Exception：源代码显式捕获处理，**编译期检查**，设计初衷为**从异常情况中恢复**\n    - Unchecked Exception（RuntimeException）：**可以编码避免的逻辑错误**，不会在编译期强制要求\n2. Error：在正常情况下，不太可能出现，绝大部分的Error都会导致程序处于**不可恢复**的状态\n\n## ClassNotFoundException\n```\nThrown when an application tries to load in a class through its string name using:\n    The forName method in class Class.\n    The findSystemClass method in class ClassLoader.\n    The loadClass method in class ClassLoader.\nbut no definition for the class with the specified name could be found.\n```\n找不到`.class`文件\n\n## NoClassDefFoundError\n```\nThrown if the Java Virtual Machine or a ClassLoader instance tries to load in the definition of a class\n(as part of a normal method call or as part of creating a new instance using the new expression) and no definition of the class could be found.\nThe searched-for class definition existed when the currently executing class was compiled, but the definition can no longer be found.\n```\n能找到`.class`文件，但`ClassLoader`尝试加载类的定义时却找不到该类的定义\n\n## 最佳实践\n\n### 反例1\n```java\ntry {\n    // 业务代码\n    Thread.sleep(1000L);\n} catch (Exception e) {\n    // 忽略\n}\n```\n1. 不要捕获通用异常`Exception`，应该捕获**特定异常**`InterruptedException`\n    - 不要捕获`Throwable`或`Error`，否则很难保证能够正常处理`OutOfMemoryError`\n2. 不要**生吞异常**，出现故障后**难以诊断**\n\n### 反例2\n```java\ntry {\n    // 业务代码\n} catch (IOException e) {\n    // Prints this throwable and its backtrace to the standard error stream.\n    e.printStackTrace();\n}\n```\n1. 在复杂的生产环境中，`stderr`不是一个合适的输出选项，很难判断输出到哪里去了\n2. 最佳实践：使用产品日志，输出到**日志系统**\n\n### Throw early, catch late\n\n#### Throw early\n```java\npublic static void main(String[] args) throws FileNotFoundException {\n    readFile(null);\n}\n\nprivate static void readFile(String fileName) throws FileNotFoundException {\n    InputStream in = new FileInputStream(fileName);\n}\n\n// 异常信息不直观\nException in thread \"main\" java.lang.NullPointerException\n\tat java.io.FileInputStream.<init>(FileInputStream.java:130)\n\tat java.io.FileInputStream.<init>(FileInputStream.java:93)\n\tat me.zhongmingmao.Main.readFile(Main.java:14)\n\tat me.zhongmingmao.Main.main(Main.java:9)\n```\n```java\npublic static void main(String[] args) throws FileNotFoundException {\n    readFile(null);\n}\n\nprivate static void readFile(String fileName) throws FileNotFoundException {\n    Objects.requireNonNull(fileName);\n    InputStream in = new FileInputStream(fileName);\n}\n\n// 使用Throw early，异常信息比较直观\nException in thread \"main\" java.lang.NullPointerException\n\tat java.util.Objects.requireNonNull(Objects.java:203)\n\tat me.zhongmingmao.Main.readFile(Main.java:14)\n\tat me.zhongmingmao.Main.main(Main.java:10)\n```\n\n#### Catch late\n捕获异常后，如果实在不知道如何处理，可以保留**原有异常的cause信息**，直接**再抛出**或者**构建新的异常**抛出\n\n### 自定义异常\n1. 是否定义成`Checked Exception`，`Checked Exception`的设计初衷是为了**从异常情况中恢复**\n    - 我们作为异常的设计者，是有充足的信息对异常进行分类的，是否满足`Checked Exception`的设计初衷\n2. 在保证**诊断信息**足够的同时，也需要避免包含**敏感信息**（例如用户信息），可能会导致潜在的**安全问题**\n\n## 性能开销\n1. `try-catch`会产生额外的性能开销，往往会影响JVM对代码进行优化\n    - 尽量**仅捕获有必要的代码块**，尽量不要使用大`try-catch`块\n    - 不要使用`try-catch`来**控制代码流程**，比常规的条件语句（if/else，switch）要低效\n2. 每实例化一个`Exception`，都需要对当时的**栈**进行**快照**，这是一个**比较重的操作**\n    - 当服务吞吐量下降时，可以考虑检查发生最频繁的`Exception`\n\n<!-- indicate-the-source -->\n","tags":["Java Core"],"categories":["Core"]},{"title":"MySQL -- 短连接 + 慢查询","url":"%2F2019%2F02%2F20%2Fmysql-short-conn-slow-query%2F","content":"\n## 短连接\n1. 短连接模式：连接到数据库后，执行**很少的SQL**后就断开，下次需要的时候再重连\n2. 在**业务高峰**期，会出现连接数突然暴涨的情况\n    - MySQL建立连接的**成本非常昂贵**\n    - 成本：TCP/IP三次握手 + 登录权限判断 + 获取连接的数据读写权限\n\n<!-- more -->\n\n### max_connections\n1. `max_connections`：MySQL实例同时存在的连接数上限\n2. 当连接数超过`max_connections`，系统会**拒绝**接下来的连接请求，返回：`Too many connections`\n    - 当连接被拒绝，从业务角度来看是**数据库不可用**\n3. 如果机器**负载较高**，处理现有请求的时间会变长，每个连接**保持的时间**也会变长\n    - 如果再有新建连接的话，很容易触发`max_connections`的限制\n4. `max_connections`的目的是**保护MySQL**的\n    - 如果把`max_connections`设置得过大，更多的连接就会进来，导致系统负载会进一步加大\n    - 大量的资源会耗费在**权限验证**等逻辑上，而已经**拿到连接的线程**会抢不到CPU资源去执行业务SQL\n\n```sql\nmysql> SHOW VARIABLES LIKE '%max_connections%';\n+-----------------+-------+\n| Variable_name   | Value |\n+-----------------+-------+\n| max_connections | 2000  |\n+-----------------+-------+\n```\n\n### 清理Sleep状态的连接\n`KILL CONNECTION`：主动踢除**不需要保持**的连接（与`wait_timeout`的效果一样）\n\n| 时刻 | sission A | session B | session C |\n| ---- | ---- | ---- | ---- |\n| T | BEGIN;<br/>INSERT INTO t VALUES (1,1); | SELECT * FROM t WHERE id=1; | |\n| T+30s | | | SHOW PROCESSLIST;<br/>KILL CONNECTION |\n\n1. 踢除`Sleep`状态的连接是**有损**的\n2. 如果断开sission A的连接，会**回滚事务**\n3. 如果断开sission B的连接，没有任何影响\n    - 优先断开**事务外空闲**的连接\n    - 再考虑断开**事务内空闲**的连接\n\n#### 事务外空闲\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-short-conn-trx-idle-1.png\" width=500/>\n\n`trx_mysql_thread_id`：`id=4`的线程还处在事务中\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-short-conn-trx-idle-2.png\" width=500/>\n\n\n#### KILL CONNECTION\n1. 服务端执行`KILL CONNECTION id`，如果连接在此前处于`Sleep`状态，客户端是**不会立马知道**\n2. 客户端如果发起**下一个请求**，报错`ERROR 2006 (HY000): MySQL server has gone away`\n    - 因此，客户端（应用层）需要有**重连机制**\n\n### 减少连接过程的消耗\n1. 数据库**跳过权限验证阶段** -- _**风险极高**_\n    - 重启数据库，启动参数`--skip-grant-tables`\n    - 跳过**所有**的权限验证阶段（**连接过程**+**语句执行过程**）\n2. 从MySQL 8.0开始，启用`--skip-grant-tables`参数，默认会启用`--skip-networking`（**本地客户端**）\n\n## 慢查询\n\n### 索引没有设计好\n\n#### 古老方案\n1. `Online DDL` -- `ALTER TABLE`\n2. 主库A，备库B\n3. 在备库B上执行`SET sql_log_bin=OFF`（**不写binlog**），`ALTER TABLE`加上索引\n4. 执行**主备切换**，变成主库B，备库A\n5. 在备库A上执行`SET sql_log_bin=OFF`（**不写binlog**），`ALTER TABLE`加上索引\n\n#### 工具\ngh-ost\n\n### 语句没写好\n```sql\n-- Since MySQL 5.7\nINSERT INTO query_rewrite.rewrite_rules (pattern, replacement, pattern_database)\n    VALUES (\"SELECT * FROM t WHERE id + 1 = ?\", \"SELECT * FROM t WHERE id = ? - 1\", \"test\");\n\nCALL query_rewrite.flush_rewrite_rules();\n```\n\n### MySQL选错索引\n1. `FORCE INDEX`\n2. `query_rewrite` + `FORCE INDEX`\n\n### 预先发现问题\n1. 测试环境配置：`slow_query_log=ON`+`long_query_time=0`\n2. SQL Review，留意`Rows_examined`是否与预期的一致\n3. 工具：`pt-query-digest`\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- RR的行锁","url":"%2F2019%2F02%2F14%2Fmysql-rr-row-lock%2F","content":"\n## 本文环境\n```sql\nmysql> SELECT VERSION();\n+-----------+\n| version() |\n+-----------+\n| 8.0.12    |\n+-----------+\n\nmysql> SHOW VARIABLES LIKE '%transaction_isolation%';\n+-----------------------+-----------------+\n| Variable_name         | Value           |\n+-----------------------+-----------------+\n| transaction_isolation | REPEATABLE-READ |\n+-----------------------+-----------------+\n```\n\n<!-- more -->\n\n## 加锁规则\n1. 基本原则\n    - 加锁的**基本单位**是`Next-Key Lock`\n    - 遍历过程中**被访问到的对象**才有可能被加锁\n2. 等值查询的优化\n    - 如果遍历的是**唯一索引**（聚簇索引）且能**等值命中**，`Next-Key Lock`会降级为`Row Lock`\n    - 向**右**遍历到**第一个不满足等值条件**的时候，`Next-Key Lock`会降级为`Gap Lock`\n3. bug\n    - 在**唯一索引**（聚簇索引）上的**范围查询**，会访问到**不满足条件的第一个值**为止\n\n## 表初始化\n```sql\nCREATE TABLE `t` (\n  `id` INT(11) NOT NULL,\n  `c` INT(11) DEFAULT NULL,\n  `d` INT(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `c` (`c`)\n) ENGINE=InnoDB;\n\nINSERT INTO t VALUES (0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n```\n\n## 唯一索引\n\n### 等值查询 -- 不命中降级\n`Next-Key Lock`降级为`Gap Lock`\n\n| session A | session B | session C |\n| ---- | ---- | ---- |\n| BEGIN;<br/>UPDATE t SET d=d+1 WHERE id=7; | | |\n| | INSERT INTO t VALUES(1,1,1);<br/>(Query OK) | |\n| | INSERT INTO t VALUES(8,8,8);<br/>(Blocked) | |\n| | | UPDATE t SET d=d+1 WHERE id=5;<br/>(Query OK) |\n| | | UPDATE t SET d=d+1 WHERE id=10;<br/>(Query OK) |\n\n```sql\n-- sission B Blocked\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X,GAP             | X,GAP              |\n+--------------+-------------+-------------------+--------------------+\n```\nsession A持有的锁：`PRIMARY:Gap Lock:(5,10)`\n\n### 范围查询 -- 起点降级\n`Next-Key Lock`降级为`Row Lock`\n\n| session A | session B | session C |\n| ---- | ---- | ---- |\n| BEGIN;<br/>SELECT * FROM t WHERE id>=10 AND id<11 FOR UPDATE; | | |\n| | INSERT INTO t VALUES (8,8,8);<br/>(Query OK) | |\n| | INSERT INTO t VALUES (13,13,13);<br/>(Blocked) | |\n| | | UPDATE t SET d=d+1 WHERE id=10;<br/>(Blocked) |\n| | | UPDATE t SET d=d+1 WHERE id=15;<br/>(Blocked) |\n\n```sql\n-- sission B Blocked\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X,GAP             | X                  |\n+--------------+-------------+-------------------+--------------------+\n\n-- sission C Blocked 1\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X                 | X                  |\n+--------------+-------------+-------------------+--------------------+\n\n-- sission C Blocked 2\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X                 | X                  |\n+--------------+-------------+-------------------+--------------------+\n```\n条件会拆分成`=10`（`Row Lock`）和`>10 & <11`，session A持有的锁：：`PRIMARY:X Lock:10`+`PRIMARY:Next-Key Lock:(10,15]`\n\n### 范围查询 -- 尾点延伸\n直到遍历到**第一个不满足的值**为止\n\n| session A | session B | session C |\n| ---- | ---- | ---- |\n| BEGIN;<br/>SELECT * FROM t WHERE id>10 AND id<=15 FOR UPDATE; | | |\n| | INSERT INTO t VALUES (16,16,16);<br/>(Blocked) | |\n| | | UPDATE t SET d=d+1 WHERE id=20;<br/>(Blocked) |\n\n```sql\n-- sission B Blocked\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X,GAP             | X                  |\n+--------------+-------------+-------------------+--------------------+\n\n-- sission C Blocked\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X                 | X                  |\n+--------------+-------------+-------------------+--------------------+\n```\nsession A持有的锁：`PRIMARY:Next-Key Lock:(10,15]`+`PRIMARY:Next-Key Lock:(15,20]`\n\n## 非唯一索引\n\n### 等值查询 -- LOCK IN SHARE MODE\n| session A | session B | session C |\n| ---- | ---- | ---- |\n| BEGIN;<br/>SELECT id FROM t WHERE c=5 LOCK IN SHARE MODE; | | |\n| | INSERT INTO t VALUES (7,7,7);<br/>(Blocked) | |\n| | | UPDATE t SET d=d+1 WHERE id=5;<br/>(Query OK) |\n| | | UPDATE t SET d=d+1 WHERE c=10;<br/>(Query OK) |\n\n```sql\n-- Using index：覆盖索引\nmysql> EXPLAIN SELECT id FROM t WHERE c=5 LOCK IN SHARE MODE;\n+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref   | rows | filtered | Extra       |\n+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------------+\n|  1 | SIMPLE      | t     | NULL       | ref  | c             | c    | 5       | const |    1 |   100.00 | Using index |\n+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------------+\n\n-- sission B Blocked\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| c            | RECORD      | X,GAP             | S,GAP              |\n+--------------+-------------+-------------------+--------------------+\n```\nsession A持有的锁：`c:Next-Key Lock:(0,5]`+`c:Gap Lock:(5,10)`\n\n### 等值查询 -- FOR UPDATE\n`LOCK IN SHARE MODE`只会锁住**覆盖索引**，而`FOR UPDATE`会同时给**聚簇索引**上**满足条件的行**加上**X Lock**\n\n| session A | session B |\n| ---- | ---- |\n| BEGIN;<br/>SELECT id FROM t WHERE c=5 FOR UPDATE; | |\n| | UPDATE t SET d=d+1 WHERE id=5;<br/>(Blocked) |\n\n```sql\n-- sission B Blocked\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X                 | X                  |\n+--------------+-------------+-------------------+--------------------+\n```\nsession A持有的锁：`c:Next-Key Lock:(0,5]`+`c:Gap Lock:(5,10)`+`PRIMARY:X Lock:5`\n\n### 等值查询 -- 绕过覆盖索引\n无法利用覆盖索引，就必须**回表**，与上面`FOR UPDATE`的情况一致\n\n| session A | session B |\n| ---- | ---- |\n| BEGIN;<br/>SELECT d FROM t WHERE c=5 LOCK IN SHARE MODE | |\n| | UPDATE t SET d=d+1 WHERE id=5;<br/>(Blocked) |\n\n```sql\n-- Extra=NULL：绕过覆盖索引，需要回表\nmysql> EXPLAIN SELECT d FROM t WHERE c=5 LOCK IN SHARE MODE;\n+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref   | rows | filtered | Extra |\n+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+\n|  1 | SIMPLE      | t     | NULL       | ref  | c             | c    | 5       | const |    1 |   100.00 | NULL  |\n+----+-------------+-------+------------+------+---------------+------+---------+-------+------+----------+-------+\n\n-- sission B Blocked\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X                 | S                  |\n+--------------+-------------+-------------------+--------------------+\n```\nsession A持有的锁：`c:Next-Key Lock:(0,5]`+`c:Gap Lock:(5,10)`+`PRIMARY:S Lock:5`\n\n### 等值查询 -- 相同的值\n```sql\n-- c=10有两行，两行之间也存在Gap\nINSERT INTO t VALUES (30,10,30);\n```\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-locking-rule-index-c.png\" width=500/>\n\n`DELETE`语句的加锁逻辑与`SELECT...FOR UPDTAE`是类似的\n\n| session A | session B | session C |\n| ---- | ---- | ---- |\n| BEGIN;<br/>DELETE FROM t WHERE c=10; | | |\n| | INSERT INTO t VALUES (12,12,12);<br/>(Blocked) | |\n| | | UPDATE t SET d=d+1 WHERE c=5;<br/>(Query OK) |\n| | | UPDATE t SET d=d+1 WHERE c=15;<br/>(Query OK) |\n| | | UPDATE t SET d=d+1 WHERE id=5;<br/>(Query OK) |\n| | | UPDATE t SET d=d+1 WHERE id=15;<br/>(Query OK) |\n| | | UPDATE t SET d=d+1 WHERE id=10;<br/>(Blocked) |\n| | | UPDATE t SET d=d+1 WHERE id=30;<br/>(Blocked) |\n\n```sql\n-- session B Blocked\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| c            | RECORD      | X,GAP             | X,GAP              |\n+--------------+-------------+-------------------+--------------------+\n\n-- session C Blocked 1\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X                 | X                  |\n+--------------+-------------+-------------------+--------------------+\n\n-- session C Blocked 2\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X                 | X                  |\n+--------------+-------------+-------------------+--------------------+\n```\nsession A在二级索引c上的加锁效果如下所示\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-locking-rule-secondary-index-eq.png\" width=500/>\n\nsession A持有的锁\n- `c:Next-Key Lock:((c=5,id=5),(c=10,id=10)]`+`c:Gap Lock:((c=10,id=10),(c=15,id=15))`\n- `PRIMARY:X Lock:10`+`PRIMARY:X Lock:30`\n\n### 等值查询 -- LIMIT\n```sql\n-- 与上面“相同的值”一样\nINSERT INTO t VALUES (30,10,30);\n```\n\n| session A | session B | session C |\n| ---- | ---- | ---- |\n| BEGIN;<br/>DELETE FROM t WHERE c=10 LIMIT 2; | | |\n| | INSERT INTO t VALUES (12,12,12);<br/>(Query OK) | |\n| | | UPDATE t SET d=d+1 WHERE id=10;<br/>(Blocked) |\n| | | UPDATE t SET d=d+1 WHERE id=30;<br/>(Blocked) |\n\n```sql\n-- session C Blocked 1\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X                 | X                  |\n+--------------+-------------+-------------------+--------------------+\n\n-- session C Blocked 2\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X                 | X                  |\n+--------------+-------------+-------------------+--------------------+\n```\n\n在遍历到`(c=10,id=30)`这一行记录后，已经有两行记录满足条件，**循环结束**，session A在二级索引c上的加锁效果如下所示\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-locking-rule-limit.png\" width=500/>\n\nsession A持有的锁\n- `c:Next-Key Lock:((c=5,id=5),(c=10,id=10)]`+`c:Next-Key Lock:((c=10,id=10),(c=10,id=30)]`\n- `PRIMARY:X Lock:10`+`PRIMARY:X Lock:30`\n\n因此在删除数据时，尽量加上`LIMIT`，可以**控制删除数据的条数**，也可以**减少加锁的范围**\n\n### 等值查询 -- Gap Lock死锁\n| session A | session B |\n| ---- | ---- |\n| BEGIN;<br/>SELECT id FROM t WHERE c=10 LOCK IN SHARE MODE; | |\n| | UPDATE t SET d=d+1 WHERE c=10;<br/>(Blocked) |\n| INSERT INTO t values (8,8,8); | |\n| | ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction |\n\n由于二级索引`c`是**非唯一索引**，因此没法降级为**行锁**\nsession A持有的锁\n- `c:Next-Key Lock:(5,10]`+`c:Next-Key Lock:(10,15]`\n- `PRIMARY:S Lock:10`\n\nsession B首先尝试持有`c:Next-Key Lock:(5,10]`，分**两阶段**\n- `c:Gap Lock:(5,10)`，加锁成功\n- `c:X Lock:10`，加锁失败，被阻塞，session B被session A阻塞\n\nsession A尝试插入`(8,8,8)`，被session B的`c:Gap Lock:(5,10)`阻塞，系统检测到死锁并回滚session B\n\n```sql\n-- session B Blocked\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| c            | RECORD      | X                 | S                  |\n+--------------+-------------+-------------------+--------------------+\n```\n\n### 范围查询\n| session A | session B | session C |\n| ---- | ---- | ---- |\n| BEGIN;<br/>SELECT * FROM t WHERE c>=10 AND c<11 FOR UPDATE; | | |\n| | INSERT INTO t VALUES (8,8,8);<br/>(Blocked) | |\n| | | UPDATE t SET d=d+1 WHERE id=10;<br/>(Blocked)|\n| | | UPDATE t SET d=d+1 WHERE c=15;<br/>(Blocked)|\n\n```sql\n-- session B Blocked\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| c            | RECORD      | X,GAP             | X                  |\n+--------------+-------------+-------------------+--------------------+\n\n-- session C Blocked 1\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X                 | X                  |\n+--------------+-------------+-------------------+--------------------+\n\n-- session C Blocked 2\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| c            | RECORD      | X                 | X                  |\n+--------------+-------------+-------------------+--------------------+\n```\n由于二级索引`c`是**非唯一索引**，因此没法降级为**行锁**\nsession A持有的锁\n- `c:Next-Key Lock:(5,10]`+`c:Next-Key Lock:(10,15]`\n- `PRIMARY:X Lock:10`\n\n## ORDE BY DESC\n| session A | session B |\n| ---- | ---- |\n| BEGIN;<br/>SELECT * FROM t WHERE c>=15 AND c <=20 ORDER BY c DESC LOCK IN SHARE MODE; | |\n| | INSERT INTO t VALUES (6,6,6);<br/>(Blocked) |\n| | INSERT INTO t VALUES (21,21,21);<br/>(Blocked) |\n| | UPDATE t SET d=d+1 WHERE id=10;<br/>(Query OK) |\n| | UPDATE t SET d=d+1 WHERE id=25;<br/>(Query OK) |\n| | UPDATE t SET d=d+1 WHERE id=15;<br/>(Blocked) |\n| | UPDATE t SET d=d+1 WHERE id=20;<br/>(Blocked) |\n\n```sql\n-- session B Blocked 1\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| c            | RECORD      | X,GAP             | S                  |\n+--------------+-------------+-------------------+--------------------+\n\n-- session B Blocked 2\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| c            | RECORD      | X,GAP             | S,GAP              |\n+--------------+-------------+-------------------+--------------------+\n\n-- session B Blocked 3\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X                 | S                  |\n+--------------+-------------+-------------------+--------------------+\n\n-- session B Blocked 4\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X                 | S                  |\n+--------------+-------------+-------------------+--------------------+\n```\n1. `ORDE BY DESC`，首先找到第一个满足`c=20`的行，session A持有锁：`c:Next-Key Lock:(15,20]`\n2. 由于二级索引`c`是**非唯一索引**，继续向**右**遍历，session A持有锁：`c:Gap Key Lock:(20,25)`\n3. 向**左**遍历，`c=15`，session A持有锁：`c:Next-Key Lock:(10,15]`\n4. 继续向**左**遍历，`c=10`，session A持有锁：`c:Next-Key Lock:(5,10]`\n5. 上述过程中，满足条件的主键为`id=15`和`id=20`，session A持有**聚簇索引**上对应行的`S Lock`\n6. 总结，session A持有的锁\n    - `c:Next-Key Lock:(5,10]`+`c:Next-Key Lock:(10,15]`+`c:Next-Key Lock:(15,20]`+`c:Gap Key Lock:(20,25)`\n    - `PRIMARY:S Lock:15`+`PRIMARY:S Lock:20`\n\n## 等值 VS 遍历\n```sql\nBEGIN;\nSELECT * FROM t WHERE id>9 AND id<12 ORDER BY id DESC FOR UPDATE;\n```\n1. 利用上面的加锁规则，加锁范围如下\n    - `PRIMARY:Next-Key Lock:(0,5]`\n    - `PRIMARY:Next-Key Lock:(5,10]`\n    - `PRIMARY:Gap Lock:(10,15)`\n2. 加锁动作是发生在语句执行过程中\n    - `ORDER BY DESC`，优化器必须先找到**第一个id<12的值**\n    - 这个过程是通过**索引树的搜索过程**得到的，其实是在引擎内部查找`id=12`\n    - 只是最终没找到，而找到了`(10,15)`这个间隙\n    - 然后**向左遍历**，在这个遍历过程，就不是等值查询了\n3. 在执行过程中，通过**树搜索**的方式定位记录的过程，用的是**等值查询**\n\n## IN\n```sql\nBEGIN;\nSELECT id FROM t WHERE c IN (5,20,10) LOCK IN SHARE MODE;\n\n-- Using index：使用了覆盖索引\n-- key=c：使用了索引c\n-- rows=3：三个值都是通过树搜索定位的\nmysql> EXPLAIN SELECT id FROM t WHERE c IN (5,20,10) LOCK IN SHARE MODE;\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+\n| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra                    |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+\n|  1 | SIMPLE      | t     | NULL       | range | c             | c    | 5       | NULL |    3 |   100.00 | Using where; Using index |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+\n```\n1. 查找`c=5`\n    - `c:Next-Key Lock:(0,5]`+`c:Gap Lock:(5,10)`\n2. 查找`c=10`\n    - `c:Next-Key Lock:(5,10]`+`c:Gap Lock:(10,15)`\n3. 查找`c=20`\n    - `c:Next-Key Lock:(15,20]`+`c:Gap Lock:(20,25)`\n4. 锁是在执行过程中是**一个一个**加的\n\n### ORDER BY DESC\n```sql\nBEGIN;\nSELECT id FROM t WHERE c IN (5,20,10) ORDER BY c DESC FOR UPDATE;\n\nmysql> EXPLAIN SELECT id FROM t WHERE c IN (5,20,10) ORDER BY c DESC FOR UPDATE;\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------------------------------+\n| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra                                         |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------------------------------+\n|  1 | SIMPLE      | t     | NULL       | range | c             | c    | 5       | NULL |    3 |   100.00 | Using where; Backward index scan; Using index |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-----------------------------------------------+\n```\n1. `ORDER BY DESC`：先锁`c=20`，再锁`c=10`，最后锁`c=5`\n2. **加锁资源相同**，但**加锁顺序相反**，如果语句是并发执行的，可能会出现**死锁**\n\n## 死锁\n| session A | session B |\n| ---- | ---- |\n| BEGIN; | |\n| SELECT id FROM t WHERE c=5 LOCK IN SHARE MODE; | |\n| | BEGIN; |\n| | SELECT id FROM t WHERE c=20 FOR UPDATE; |\n| SELECT id FROM t WHERE c=20 LOCK IN SHARE MODE; | |\n| | SELECT id FROM t WHERE c=5 FOR UPDATE; |\n| Deadlock found when trying to get lock; try restarting transaction | |\n\nMySQL只保留**最后一个死锁的现场**，并且这个现场还不完备\n```sql\nmysql> SHOW ENGINE INNODB STATUS\\G;\n------------------------\nLATEST DETECTED DEADLOCK\n------------------------\n2019-03-03 20:49:40 0x700006a43000\n*** (1) TRANSACTION:\nTRANSACTION 281479811602240, ACTIVE 35 sec starting index read\nmysql tables in use 1, locked 1\nLOCK WAIT 4 lock struct(s), heap size 1136, 3 row lock(s)\nMySQL thread id 15, OS thread handle 123145414946816, query id 283 localhost root Sending data\nSELECT id FROM t WHERE c=20 LOCK IN SHARE MODE\n*** (1) WAITING FOR THIS LOCK TO BE GRANTED:\nRECORD LOCKS space id 77 page no 5 n bits 80 index c of table `test`.`t` trx id 281479811602240 lock mode S waiting\nRecord lock, heap no 6 PHYSICAL RECORD: n_fields 2; compact format; info bits 0\n 0: len 4; hex 80000014; asc     ;;\n 1: len 4; hex 80000014; asc     ;;\n\n*** (2) TRANSACTION:\nTRANSACTION 6407220, ACTIVE 25 sec starting index read, thread declared inside InnoDB 5000\nmysql tables in use 1, locked 1\n5 lock struct(s), heap size 1136, 4 row lock(s)\nMySQL thread id 16, OS thread handle 123145413734400, query id 284 localhost root Sending data\nSELECT id FROM t WHERE c=5 FOR UPDATE\n*** (2) HOLDS THE LOCK(S):\nRECORD LOCKS space id 77 page no 5 n bits 80 index c of table `test`.`t` trx id 6407220 lock_mode X\nRecord lock, heap no 6 PHYSICAL RECORD: n_fields 2; compact format; info bits 0\n 0: len 4; hex 80000014; asc     ;;\n 1: len 4; hex 80000014; asc     ;;\n\n*** (2) WAITING FOR THIS LOCK TO BE GRANTED:\nRECORD LOCKS space id 77 page no 5 n bits 80 index c of table `test`.`t` trx id 6407220 lock_mode X waiting\nRecord lock, heap no 3 PHYSICAL RECORD: n_fields 2; compact format; info bits 0\n 0: len 4; hex 80000005; asc     ;;\n 1: len 4; hex 80000005; asc     ;;\n\n*** WE ROLL BACK TRANSACTION (1)\n```\n1. `(1) TRANSACTION`：第一个事务的信息\n2. `(2) TRANSACTION`：第二个事务的信息\n3. `WE ROLL BACK TRANSACTION (1)`：最终的处理结果是回滚第一个事务\n\n### 第一个事务\n```sql\nSELECT id FROM t WHERE c=20 LOCK IN SHARE MODE\n*** (1) WAITING FOR THIS LOCK TO BE GRANTED:\nRECORD LOCKS space id 77 page no 5 n bits 80 index c of table `test`.`t` trx id 281479811602240 lock mode S waiting\nRecord lock, heap no 6 PHYSICAL RECORD: n_fields 2; compact format; info bits 0\n 0: len 4; hex 80000014; asc     ;;\n 1: len 4; hex 80000014; asc     ;;\n```\n1. `(1) WAITING FOR THIS LOCK TO BE GRANTED`：表示第一个事务在等待的锁的信息\n2. `index c of table test.t`：表示等待表`t`的索引`c`上的锁\n3. `lock mode S waiting`：表示正在执行的语句要加一个`S Lock`，当前状态为**等待中**\n4. `Record lock`：表示这是一个**记录锁**（行数）\n5. `n_fields 2`：表示这个记录有2列（二级索引），即字段`c`和主键字段`id`\n6. `0: len 4; hex 80000014; asc     ;;`：第一个字段`c`\n    - `asc`：表示接下来要打印值里面的**可打印字符**，20不是可打印字符，因此显示**空格**\n7. `1: len 4; hex 80000014; asc     ;;`：第二个字段`id`\n8. 第一个事务在等待`(c=20,id=20)`这一行的行锁\n9. 但并没有打印出第一个事务本身所占有的锁，可以通过第二个事务反向推导出来\n\n### 第二个事务\n```sql\nSELECT id FROM t WHERE c=5 FOR UPDATE\n*** (2) HOLDS THE LOCK(S):\nRECORD LOCKS space id 77 page no 5 n bits 80 index c of table `test`.`t` trx id 6407220 lock_mode X\nRecord lock, heap no 6 PHYSICAL RECORD: n_fields 2; compact format; info bits 0\n 0: len 4; hex 80000014; asc     ;;\n 1: len 4; hex 80000014; asc     ;;\n\n *** (2) WAITING FOR THIS LOCK TO BE GRANTED:\n RECORD LOCKS space id 77 page no 5 n bits 80 index c of table `test`.`t` trx id 6407220 lock_mode X waiting\n Record lock, heap no 3 PHYSICAL RECORD: n_fields 2; compact format; info bits 0\n  0: len 4; hex 80000005; asc     ;;\n  1: len 4; hex 80000005; asc     ;;\n```\n1. `(2) HOLDS THE LOCK(S)`：表示第二个事务持有的锁的信息\n2. `index c of table test.t`：表示锁是加在表`t`的索引`c`上\n3. `0: len 4; hex 80000014; asc     ;;`+`1: len 4; hex 80000014; asc     ;;`\n    - 第二个事务持有`(c=20,id=20)`这一行的行锁（`X Lock`）\n4. `(2) WAITING FOR THIS LOCK TO BE GRANTED`\n    - 第二个事务等待`(c=5,id=5)`只一行的行锁\n\n### 小结\n1. 锁是**一个一个**加的，为了避免死锁，对**同一组资源**，尽量按照**相同的顺序**访问\n2. 在发生死锁的时候，`FOR UPDATE`占用的资源更多，**回滚成本更大**，因此选择回滚`LOCK IN SHARE MODE`\n\n## 锁等待\n| 时刻 | session A | session B |\n| ---- | ---- | ---- |\n| T1 | BEGIN; | |\n| T2 | SELECT * FROM t WHERE id>10 AND id<=15 FOR UPDATE; | |\n| T3 | | DELETE FROM t WHERE id=10;<br/>(Query OK) |\n| T4 | | INSERT INTO t VALUES (10,10,10);<br/>(Blocked) |\n\n```sql\n-- session B Blocked\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| PRIMARY      | RECORD      | X,GAP             | X                  |\n+--------------+-------------+-------------------+--------------------+\n\nmysql> SHOW ENGINE INNODB STATUS\\G;\n------------\nTRANSACTIONS\n------------\n---TRANSACTION 6407254, ACTIVE 3 sec inserting\nmysql tables in use 1, locked 1\nLOCK WAIT 2 lock struct(s), heap size 1136, 1 row lock(s)\nMySQL thread id 16, OS thread handle 123145413734400, query id 319 localhost root update\nINSERT INTO t VALUES (10,10,10)\n------- TRX HAS BEEN WAITING 3 SEC FOR THIS LOCK TO BE GRANTED:\nRECORD LOCKS space id 78 page no 4 n bits 80 index PRIMARY of table `test`.`t` trx id 6407254 lock_mode X locks gap before rec insert intention waiting\nRecord lock, heap no 5 PHYSICAL RECORD: n_fields 5; compact format; info bits 0\n 0: len 4; hex 8000000f; asc     ;;\n 1: len 6; hex 00000061c44a; asc    a J;;\n 2: len 7; hex 810000008f0137; asc       7;;\n 3: len 4; hex 8000000f; asc     ;;\n 4: len 4; hex 8000000f; asc     ;;\n```\n1. 时刻`T2`，session A持有的锁如下\n    - `PRIMARY:Next-Key Lock:(10,15]`+`PRIMARY:Next-Key Lock:(15,20]`\n2. 因此在时刻`T3`，session B能直接删除`id=10`这一行\n3. `index PRIMARY of table test.t`：语句被锁住是因为表`t`的主键上的某一个锁\n4. `lock_mode X locks gap before rec insert intention waiting`\n    - `insert intention`：表示当前线程准备插入一个记录，是一个**插入意向锁**\n    - `gap before rec`：表示这是一个`Gap Lock`，而不是`Record Lock`\n5. `n_fields 5`：表示这一记录有5列（聚簇索引）\n    - `0: len 4; hex 8000000f; asc     ;;`：表示主键`id`字段，即`id=15`\n        - 因此`gap before rec`里面的`rec`指的就是`id=15`这一行\n        - 又因为`id=10`这一行已经不存在了，因此这个`gap`就是`(5,15)`\n    - `1: len 6; hex 00000061c44a; asc    a J;;`：表示6字节的**事务ID**\n    - `2: len 7; hex 810000008f0137; asc       7;;`：表示7字节的**回滚段信息**\n    - `3: len 4; hex 8000000f; asc     ;;`：表示字段`c`\n    - `4: len 4; hex 8000000f; asc     ;;`：表示字段`d`\n6. 原来session A持有的`PRIMARY:Next-Key Lock:(10,15]`膨胀成了`PRIMARY:Next-Key Lock:(5,15]`\n    - **间隙的本质**：由间隙**右边的记录**来定义的\n\n## Gap Lock\n| session A | session B |\n| ---- | ---- |\n| BEGIN; | |\n| SELECT c FROM t WHERE c>5 LOCK IN SHARE MODE; | |\n| | UPDATE t SET c=1 WHERE c=5;<br/>(Query OK) |\n| | UPDATE t SET c=5 WHERE c=1;<br/>(Blocked) |\n\n```sql\n-- session B Blocked\nmysql> SELECT locked_index,locked_type,waiting_lock_mode,blocking_lock_mode FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`';\n+--------------+-------------+-------------------+--------------------+\n| locked_index | locked_type | waiting_lock_mode | blocking_lock_mode |\n+--------------+-------------+-------------------+--------------------+\n| c            | RECORD      | X,GAP             | S                  |\n| c            | RECORD      | X,GAP             | S                  |\n+--------------+-------------+-------------------+--------------------+\n\nmysql> show engine innodb status\\G;\n------------\nTRANSACTIONS\n------------\n---TRANSACTION 6407282, ACTIVE 5 sec updating or deleting\nmysql tables in use 1, locked 1\nLOCK WAIT 5 lock struct(s), heap size 1136, 4 row lock(s), undo log entries 1\nMySQL thread id 16, OS thread handle 123145413734400, query id 337 localhost root updating\nUPDATE t SET c=5 WHERE c=1\n------- TRX HAS BEEN WAITING 5 SEC FOR THIS LOCK TO BE GRANTED:\nRECORD LOCKS space id 79 page no 5 n bits 80 index c of table `test`.`t` trx id 6407282 lock_mode X locks gap before rec insert intention waiting\nRecord lock, heap no 4 PHYSICAL RECORD: n_fields 2; compact format; info bits 0\n 0: len 4; hex 8000000a; asc     ;;\n 1: len 4; hex 8000000a; asc     ;;\n```\n1. session A持有的锁如下\n    - `c:Next-Key Lock:(5,10]`\n    - `c:Next-Key Lock:(10,15]`\n    - `c:Next-Key Lock:(15,20]`\n    - `c:Next-Key Lock:(20,25]`\n    - `c:Next-Key Lock:(25,supremum]`\n2. 依据`c>5`查找到的第一个记录是`c=10`，因此不包含`c:Next-Key Lock:(0,5]`\n3. `UPDATE t SET c=1 WHERE c=5`等价于两步\n    - 插入`(c=1,id=5)`这个记录\n    - 删除`(c=5,id=5)`这个记录\n4. 执行完上面两步，session A持有的`c:Next-Key Lock:(5,10]`会膨胀为`c:Next-Key Lock:(1,10]`\n5. `UPDATE t SET c=5 WHERE c=1`等价于两步\n    - 插入`(c=5,id=5)`这个记录\n    - 删除`(c=1,id=5)`这个记录\n6. 在试图执行第一步的时候，会被session A持有的`c:Next-Key Lock:(1,10]`所阻塞\n\n## RR与RC\n1. RR隔离级别\n    - 遵守**两阶段**协议，所有**加锁的资源**都是在事务**提交**或**回滚**时才释放\n2. RC隔离级别\n    - 执行过程加上的**行锁**，在**语句执行完成后**，就要把**“不满足条件的行”上的行锁直接释放**，无需等待事务提交或回滚\n    - **锁范围更小**，**锁定时间更短**，这是很多业务选择RC的一个原因\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 幻读","url":"%2F2019%2F02%2F14%2Fmysql-phantom%2F","content":"\n## 表初始化\n```sql\nCREATE TABLE `t` (\n    `id` INT(11) NOT NULL,\n    `c` INT(11) DEFAULT NULL,\n    `d` INT(11) DEFAULT NULL,\n    PRIMARY KEY (`id`),\n    KEY `c` (`c`)\n) ENGINE=InnoDB;\n\nINSERT INTO t VALUES (0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n```\n\n<!-- more -->\n\n## 定义与问题\n\n### 定义\n1. 幻读：在同一个事务内，前后两次查询**同一范围**的时候，后一次查询看到了前一次查询没有看到的行\n    - 幻读专指_**新插入的行**_\n2. 在**RR**隔离级别下，**普通查询是快照读**，是看不到其他事务插入的数据的\n    - _幻读仅在**当前读**时才会出现_\n\n### 解决思路\n\n#### 只有行锁\n假设`SELECT * FROM t WHERE d=5 FOR UPDATE;`只会在`id=5`这一行上加`X Lock`，执行时序如下：\n\n| 时刻 | session A | session B | session C |\n| ---- | ---- | ---- | ---- |\n| T1 | BEGIN;<br/>SELECT * FROM t WHERE d=5 FOR UPDATE;<br/>result:(5,5,5) | | |\n| T2 | | UPDATE t SET d=5 WHERE id=0;<br/>UPDATE t SET c=5 WHERE id=0; | |\n| T3 | SELECT * FROM t WHERE d=5 FOR UPDATE;<br/>result:(0,5,5),(5,5,5) | | |\n| T4 | | | INSERT INTO t VALUES (1,1,5);<br/>UPDATE t SET c=5 WHERE id=1; |\n| T5 | SELECT * FROM t WHERE d=5 FOR UPDATE;<br/>result:(0,5,5),(1,1,5),(5,5,5) | | |\n| T6 | COMMIT; | | |\n\n1. `T1`返回`id=5`这1行\n2. `T3`返回`id=0`和`id=5`这2行\n    - `id=0`不是幻读，因为不是新插入的行\n3. `T5`返回`id=0`、`id=1`和`id=5`的这三行\n    - `id=1`是**幻读**，因为这是**新插入的行**\n    - 显然只有行锁（**RC**）是无法解决幻读问题的\n\n#### 幻读的问题\n\n##### 破坏语义\n1. session A在`T1`时刻声明：锁住所有`d=5`的行，不允许其他事务进行读写操作\n2. session B在`T2`时刻修改了`id=0,d=5`这一行\n3. session C在`T4`时刻修改了`id=1,d=5`这一行\n\n##### 破坏数据一致性\n\n###### 数据\n\n| 时刻 | session A | session B | session C |\n| ---- | ---- | ---- | ---- |\n| T1 | BEGIN;<br/>SELECT * FROM t WHERE d=5 FOR UPDATE;<br/>UPDATE t SET d=100 WHERE d=5; | | |\n| T2 | | UPDATE t SET d=5 WHERE id=0;<br/>UPDATE t SET c=5 WHERE id=0; | |\n| T3 | SELECT * FROM t WHERE d=5 FOR UPDATE; | | |\n| T4 | | | INSERT INTO t VALUES (1,1,5);<br/>UPDATE t SET c=5 WHERE id=1; |\n| T5 | SELECT * FROM t WHERE d=5 FOR UPDATE; | | |\n| T6 | COMMIT; | | |\n\n1. `UPDATE`与`SELECT...FOR UPDATE`的加锁语义一致（`X Lock`）\n2. `T1`时刻，`id=5`这一行变成了`(5,5,100)`，在`T6`时刻才正式提交\n3. `T2`时刻，`id=0`这一行变成了`(0,5,5)`\n4. `T4`时刻，新插入了一行`(1,5,5)`\n\n###### binlog\n1. T2时刻，session B事务提交，写入两条语句\n2. T4时刻，session C事务提交，写入两条语句\n3. T6时刻，session A事务提交，写入`UPDATE t SET d=100 WHERE d=5;`\n\n```sql\nUPDATE t SET d=5 WHERE id=0; -- (0,0,5)\nUPDATE t SET c=5 WHERE id=0; -- (0,5,5)\n\nINSERT INTO t VALUES (1,1,5); -- (1,1,5)\nUPDATE t SET c=5 WHERE id=1; -- (1,5,5)\n\nUPDATE t SET d=100 WHERE d=5; -- 所有d=5的行，d改成100\n```\n1. 该binlog如果在备库上执行，最终结果为`(0,5,100)`，`(1,5,100)`，`(5,5,100)`，`id=0`和`id=1`这两行数据会与主库不一致\n2. 原因：`SELECT * FROM t WHERE d=5 FOR UPDATE;`只给`id=5`这一行`X Lock `\n\n#### 加强行锁\n增强为：扫描过程中**所有**碰到的行，都加上`X Lock`，执行序列如下\n\n| 时刻 | session A | session B | session C |\n| ---- | ---- | ---- | ---- |\n| T1 | BEGIN;<br/>SELECT * FROM t WHERE d=5 FOR UPDATE;<br/>UPDATE t SET d=100 WHERE d=5; | | |\n| T2 | | UPDATE t SET d=5 WHERE id=0;(blocked)<br/>UPDATE t SET c=5 WHERE id=0; | |\n| T3 | SELECT * FROM t WHERE d=5 FOR UPDATE; | | |\n| T4 | | | INSERT INTO t VALUES (1,1,5);<br/>UPDATE t SET c=5 WHERE id=1; |\n| T5 | SELECT * FROM t WHERE d=5 FOR UPDATE; | | |\n| T6 | COMMIT; | | |\n\n1. session A把**所有的行**都加了`X Lock`，因此session B在执行第一个update语句时被锁住了\n    - 需要等到`T6`时刻，session A提交之后，session B才能继续执行\n2. 对于`id=0`这一行，在数据库中的最终结果还是`(0,5,5)`\n\n**binlog**\n```sql\nINSERT INTO t VALUES (1,1,5); -- (1,1,5)\nUPDATE t SET c=5 WHERE id=1; -- (1,5,5)\n\nUPDATE t SET d=100 WHERE d=5; -- 所有d=5的行，d改成100\n\nUPDATE t SET d=5 WHERE id=0; -- (0,0,5)\nUPDATE t SET c=5 WHERE id=0; -- (0,5,5)\n```\n1. `id=0`这一行的最终结果也是`(0,5,5)`，因此`id=0`这一行的数据是一致的\n2. 对于`id=1`这一行数据而言，在数据库端的结果为`(1,5,5)`，而根据binlog的执行结果是`(1,5,100)`，数据不一致\n    - 并且依然存在**幻读**\n3. 原因：只能给加锁时存在的行加`X Lock`\n    - 在`T3`时刻，在给所有的行加`X Lock`时，此时`id=1`这一行还不存在，因此也就加不上`X Lock`了\n    - 即使在**所有的记录**都加上了`X Lock`，依旧**阻止不了插入新纪录**\n\n## 解决方案\n\n### Gap Lock\n1. 产生幻读的原因：行锁只能锁住行，新插入记录这个动作，要更新的是记录之间的**间隙**\n2. 为了解决幻读，InnoDB引入了新的锁：**间隙锁**（**Gap Lock**）\n\n表初始化，插入了6个记录，产生了7个间隙\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-phantom-gap.png\" width=500/>\n\n1. `SELECT * FROM t WHERE d=5 FOR UPDATE;`\n    - 给已有的6个记录加上`X Lock`，同时还会加上7个`Gap Lock`，这样就确保**无法再插入新纪录**\n2. 上锁实体\n    - **数据行**\n    - **数据行之间的间隙**\n\n### 冲突关系\n\n#### 行锁\n行锁的冲突关系（跟行锁有冲突关系的是**另一个行锁**）\n\n| | S Lock | X Lock |\n| ---- | ---- | ---- |\n| S Lock | 兼容 | 冲突 |\n| X Lock | 冲突 | 冲突 |\n\n#### 间隙锁\n跟**间隙锁**存在冲突关系的是_**往这个间隙插入一个记录的操作**_，_**间隙锁之间不会相互冲突**_\n\n| session A | session B |\n| ---- | ---- |\n| BEGIN;<br/>SELECT * FROM t WHERE c=7 LOCK IN SHARE MODE; | |\n| | BEGIN;<br/>SELECT * FROM t WHERE c=7 FOR UPDATE; |\n\n1. **session B并不会被阻塞**，因为表t里面并没有`c=7`的记录\n    - 因此session A加的是**间隙锁**`(5,10)`，而session B也是在这个间隙加间隙锁\n    - 两个session有共同的目标： 保护这个间隙，不允许插入值，但两者之间不冲突\n\n### Next-Key Lock\n1. 间隙锁和行锁合称`Next-Key Lock`，每个`Next-Key Lock`都是**左开右闭**区间\n2. `SELECT * FROM t WHERE d=5 FOR UPDATE;`形成了7个`Next-Key Lock`，分别是\n    - `(-∞,0],(0,5],(5,10],(10,15],(15,20],(20,25],(25,+supremum]`\n    - `+supremum`：InnoDB给每一个索引加的一个**不存在的最大值supremum**\n3. 约定：`Gap Lock`为**左开右开**区间，`Next-Key Lock`为**左开右闭**区间\n\n#### 可能死锁\n```sql\n-- 并发执行\n-- 死锁并不是大问题，回滚重试即可\nBEGIN;\nSELECT * FROM t WHERE id=N FOR UPDATE;\n\n-- 如果行不存在\nINSERT INTO t VALUES (N,N,N);\n-- 如果行存在\nUPDATE t SET d=N SET id=N;\n\nCOMMIT;\n```\n\n| session A | session B |\n| --- | ---- |\n| BEGIN;<br/>SELECT * FROM t WHERE id=9 FOR UPDATE; | |\n| | BEGIN;<br/>SELECT * FROM t WHERE id=9 FOR UPDATE; |\n| | INSERT INTO t VALUES (9,9,9);(blocked) |\n| INSERT INTO t VALUES (9,9,9);(Deadlock fund) | |\n\n1. session A执行`SELECT * FROM t WHERE id=9 FOR UPDATE;`，`id=9`这一行不存在，会加上**间隙锁**`(5,10)`\n2. session B执行`SELECT * FROM t WHERE id=9 FOR UPDATE;`，间隙锁之间不冲突，同样会加上**间隙锁**`(5,10)`\n3. session B试图插入一行`(9,9,9)`，被session A的间隙锁阻塞\n4. session A试图插入一行`(9,9,9)`，被session B的间隙锁阻塞，两个session相互等待，形成**死锁**\n    - InnoDB的**死锁检测**很快就会发现死锁，并让session A的insert语句**报错返回**\n5. 解决方案：假如**只有一个唯一索引**，可以用`INSERT ... ON DUPLICATE KEY UPDATE`来替代\n\n### 小结\n1. 引入`Gap Lock`，会导致同样的语句**锁住更大的范围**，_**影响并发度**_\n2. `Gap Lock`是在**RR**隔离级别下才生效的（在**RC**隔离级别是没有`Gap Lock`的）\n3. 解决**数据与日志不一致**的另一个方案：RC + binlog_format=row\n    - 如果**RC**（没有`Gap Lock`，锁范围更小）隔离级别够用，业务并不需要可重复读的保证，可以选择RC\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 问题排查","url":"%2F2019%2F02%2F13%2Fmysql-troubleshoot%2F","content":"\n## 表初始化\n```sql\nCREATE TABLE `t` (\n    `id` INT(11) NOT NULL,\n    `c` INT(11) DEFAULT NULL,\n    PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\nDELIMITER ;;\nCREATE PROCEDURE idata()\nBEGIN\n    DECLARE i INT;\n    SET i=1;\n    WHILE (i<=100000) DO\n        INSERT INTO t VALUES (i,i);\n        SET i=i+1;\n    END WHILE;\nEND;;\nDELIMITER ;\n\nCALL idata();\n```\n\n<!-- more -->\n\n## 查询长时间等待\n大概率是表`t`被锁住了，通过`SHOW PROCESSLIST;`查看语句处于什么状态\n```sql\nSELECT * FROM t WHERE id=1;\n```\n\n### 等MDL\n\n#### 执行时序\n| session A | session B |\n| ---- | ---- |\n| LOCK TABLE t WRITE; | |\n| | SELECT * FROM t WHERE id=1; |\n\n1. session A通过`LOCK TABLE`命令持有表`t`的**MDL写锁**\n2. session B执行DML，需要先持有表`t`的**MDL读锁**，从而进入阻塞状态\n\n#### 语句状态\nsession B的线程ID为33，状态为等待MDL：`Waiting for table metadata lock`\n```sql\nmysql> SHOW PROCESSLIST;\n+----+-----------------+-----------+------+---------+-------+---------------------------------+----------------------------+\n| Id | User            | Host      | db   | Command | Time  | State                           | Info                       |\n+----+-----------------+-----------+------+---------+-------+---------------------------------+----------------------------+\n|  4 | event_scheduler | localhost | NULL | Daemon  | 21668 | Waiting on empty queue          | NULL                       |\n| 30 | root            | localhost | test | Query   |    33 | Waiting for table metadata lock | SELECT * FROM t WHERE id=1 |\n| 31 | root            | localhost | test | Sleep   |    41 |                                 | NULL                       |\n| 33 | root            | localhost | NULL | Query   |     0 | starting                        | SHOW PROCESSLIST           |\n+----+-----------------+-----------+------+---------+-------+---------------------------------+----------------------------+\n\n-- 设置成`ON`，会有10%左右的性能损失\nmysql> SHOW VARIABLES LIKE 'performance_schema';\n+--------------------+-------+\n| Variable_name      | Value |\n+--------------------+-------+\n| performance_schema | ON    |\n+--------------------+-------+\n```\n\n#### 锁信息\n`blocking_pid=31`阻塞`waiting_pid=30`，应该采用`KILL 31`\n```sql\nmysql> SELECT * FROM sys.schema_table_lock_waits\\G;\n*************************** 1. row ***************************\n               object_schema: test\n                 object_name: t\n           waiting_thread_id: 69\n                 waiting_pid: 30\n             waiting_account: root@localhost\n           waiting_lock_type: SHARED_READ\n       waiting_lock_duration: TRANSACTION\n               waiting_query: SELECT * FROM t WHERE id=1\n          waiting_query_secs: 404\n waiting_query_rows_affected: 0\n waiting_query_rows_examined: 0\n          blocking_thread_id: 70\n                blocking_pid: 31\n            blocking_account: root@localhost\n          blocking_lock_type: SHARED_NO_READ_WRITE\n      blocking_lock_duration: TRANSACTION\n     sql_kill_blocking_query: KILL QUERY 31\nsql_kill_blocking_connection: KILL 31\n```\n\n### 等flush\n\n#### flush tables\n```sql\n-- Closes all open tables, forces all tables in use to be closed, and flushes the prepared statement cache.\nFLUSH TABLES t WITH READ LOCK;\nFLUSH TABLES WITH READ LOCK;\n```\n\n#### 执行时序\n| 时刻 | session A | session B | session C | session D |\n| ---- | ---- | ---- | ---- |\n| T1 | SELECT SLEEP(1) FROM t; | | | |\n| T2 | | | | SHOW PROCESSLIST; |\n| T3 | | FLUSH TABLES t; | | |\n| T4 | | | | SHOW PROCESSLIST; |\n| T5 | | | SELECT * FROM t WEHERE id=1; | |\n| T6 | | | | SHOW PROCESSLIST; |\n\n1. session A：执行10W秒，在这期间表`t`会被session A**一直打开**\n2. session B：需要等待session A的查询结束后才能执行flush命令，被阻塞\n3. session C：在session B中的flush命令还未执行完成时发起查询操作，会**被flush命令阻塞**\n\n#### 语句状态\n```sql\n-- T2时刻\nmysql> SHOW PROCESSLIST;\n+----+-----------------+-----------+------+---------+-------+------------------------+------------------------+\n| Id | User            | Host      | db   | Command | Time  | State                  | Info                   |\n+----+-----------------+-----------+------+---------+-------+------------------------+------------------------+\n|  4 | event_scheduler | localhost | NULL | Daemon  | 26199 | Waiting on empty queue | NULL                   |\n| 30 | root            | localhost | test | Sleep   |   434 |                        | NULL                   |\n| 33 | root            | localhost | test | Sleep   |   430 |                        | NULL                   |\n| 34 | root            | localhost | test | Query   |     6 | User sleep             | SELECT SLEEP(1) FROM t |\n| 35 | root            | localhost | test | Query   |     0 | starting               | SHOW PROCESSLIST       |\n+----+-----------------+-----------+------+---------+-------+------------------------+------------------------+\n\n-- T4时刻\nmysql> SHOW PROCESSLIST;\n+----+-----------------+-----------+------+---------+-------+-------------------------+------------------------+\n| Id | User            | Host      | db   | Command | Time  | State                   | Info                   |\n+----+-----------------+-----------+------+---------+-------+-------------------------+------------------------+\n|  4 | event_scheduler | localhost | NULL | Daemon  | 26210 | Waiting on empty queue  | NULL                   |\n| 30 | root            | localhost | test | Query   |     3 | Waiting for table flush | FLUSH TABLES t         |\n| 33 | root            | localhost | test | Sleep   |   441 |                         | NULL                   |\n| 34 | root            | localhost | test | Query   |    17 | User sleep              | SELECT SLEEP(1) FROM t |\n| 35 | root            | localhost | test | Query   |     0 | starting                | SHOW PROCESSLIST       |\n+----+-----------------+-----------+------+---------+-------+-------------------------+------------------------+\n\n-- T6时刻\nmysql> SHOW PROCESSLIST;\n+----+-----------------+-----------+------+---------+-------+-------------------------+----------------------------+\n| Id | User            | Host      | db   | Command | Time  | State                   | Info                       |\n+----+-----------------+-----------+------+---------+-------+-------------------------+----------------------------+\n|  4 | event_scheduler | localhost | NULL | Daemon  | 26232 | Waiting on empty queue  | NULL                       |\n| 30 | root            | localhost | test | Query   |    25 | Waiting for table flush | FLUSH TABLES t             |\n| 33 | root            | localhost | test | Query   |     3 | Waiting for table flush | SELECT * FROM t WHERE id=1 |\n| 34 | root            | localhost | test | Query   |    39 | User sleep              | SELECT SLEEP(1) FROM t     |\n| 35 | root            | localhost | test | Query   |     0 | starting                | SHOW PROCESSLIST           |\n+----+-----------------+-----------+------+---------+-------+-------------------------+----------------------------+\n```\n\n### 等行锁\n\n#### 执行时序\nsession A持有`id=1`这行记录的**X Lock**，session B尝试获取`id=1`这行记录的**S Lock**，被**阻塞**\n\n| session A | session B |\n| ---- | ---- |\n| BEGIN; | |\n| UPDATE t SET c=c+1 WHERE id=1; | |\n| | SELECT * FROM t WHERE id=1 LOCK IN SHARE MODE; |\n\n#### 语句状态\n```sql\nmysql> SHOW PROCESSLIST;\n+----+-----------------+-----------+------+---------+-------+------------------------+-----------------------------------------------+\n| Id | User            | Host      | db   | Command | Time  | State                  | Info                                          |\n+----+-----------------+-----------+------+---------+-------+------------------------+-----------------------------------------------+\n|  4 | event_scheduler | localhost | NULL | Daemon  | 26456 | Waiting on empty queue | NULL                                          |\n| 30 | root            | localhost | test | Query   |     7 | statistics             | SELECT * FROM t WHERE id=1 LOCK IN SHARE MODE |\n| 33 | root            | localhost | test | Sleep   |   227 |                        | NULL                                          |\n| 34 | root            | localhost | test | Sleep   |    14 |                        | NULL                                          |\n| 35 | root            | localhost | test | Query   |     0 | starting               | SHOW PROCESSLIST                              |\n+----+-----------------+-----------+------+---------+-------+------------------------+-----------------------------------------------+\n```\n\n#### 锁信息\n```sql\nmysql> SELECT * FROM sys.innodb_lock_waits WHERE locked_table='`test`.`t`'\\G;\n*************************** 1. row ***************************\n                wait_started: 2019-02-13 20:52:55\n                    wait_age: 00:00:18\n               wait_age_secs: 18\n                locked_table: `test`.`t`\n         locked_table_schema: test\n           locked_table_name: t\n      locked_table_partition: NULL\n   locked_table_subpartition: NULL\n                locked_index: PRIMARY\n                 locked_type: RECORD\n              waiting_trx_id: 281479630179024\n         waiting_trx_started: 2019-02-13 20:52:55\n             waiting_trx_age: 00:00:18\n     waiting_trx_rows_locked: 1\n   waiting_trx_rows_modified: 0\n                 waiting_pid: 30\n               waiting_query: SELECT * FROM t WHERE id=1 LOCK IN SHARE MODE\n             waiting_lock_id: 281479630179024:22:5:2\n           waiting_lock_mode: S\n             blocking_trx_id: 4401915\n                blocking_pid: 34\n              blocking_query: NULL\n            blocking_lock_id: 4401915:22:5:2\n          blocking_lock_mode: X\n        blocking_trx_started: 2019-02-13 20:52:48\n            blocking_trx_age: 00:00:25\n    blocking_trx_rows_locked: 1\n  blocking_trx_rows_modified: 1\n     sql_kill_blocking_query: KILL QUERY 34\nsql_kill_blocking_connection: KILL 34\n```\n1. `locked_index`：**PRIMARY**，加锁的对象是**聚簇索引**\n2. `locked_type`：**RECORD**，锁类型是**行锁**\n3. `waiting_lock_mode`：**S**，预期的加锁模式是**S Lock**\n4. `blocking_pid=16`阻塞`waiting_pid=30`\n5. `blocking_lock_mode`：**X**，目前持有**X Lock**\n6. `KILL QUERY 34`：停止正在执行的语句，但不会释放锁\n7. `KILL 34`：断开连接，会**释放锁**\n\n## 查询慢\n\n### 无索引\n字段`c`没有索引，因此只能走聚簇索引扫描，即**全部扫描**\n```sql\nSELECT * FROM t WHERE c=50000 LIMIT 1;\n```\n\n#### explain\n`type=ALL`+`rows=100,464`：**全表扫描**\n```sql\nmysql> EXPLAIN SELECT * FROM t WHERE c=50000 LIMIT 1;\n+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+-------------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows   | filtered | Extra       |\n+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+-------------+\n|  1 | SIMPLE      | t     | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 100464 |    10.00 | Using where |\n+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+-------------+\n```\n\n#### slowlog\n```sql\n# Time: 2019-02-13T17:29:39.646343+08:00\n# User@Host: root[root] @ localhost []  Id:    29\n# Query_time: 0.013134  Lock_time: 0.000239 Rows_sent: 1  Rows_examined: 50000\nSET timestamp=1550050179;\nSELECT * FROM t WHERE c=50000 LIMIT 1;\n```\n1. `Rows_examined=50,000`，扫描**聚簇索引**，直到找到第1个满足条件的行\n2. `Query_time`为13ms，不算慢，但这是`O(N)`的查询\n    - _**坏查询不一定是慢查询**_\n\n### undolog过多\n\n#### 存储过程\n```sql\nDELIMITER ;;\nCREATE PROCEDURE udata()\nBEGIN\n    DECLARE i INT;\n    SET i=1;\n    WHILE (i<=1000000) DO\n        UPDATE t SET c=c+1 WHERE id=1;\n        SET i=i+1;\n    END WHILE;\nEND;;\nDELIMITER ;\n```\n\n#### 执行时序\n| 时刻 | session A | session B |\n| ---- | ---- | ---- |\n| T1 | START TRANSACTION WITH CONSISTENT SNAPSHOT; | |\n| T2 | SELECT * FROM t WHERE id=1;（返回1，很慢） | |\n| T3 | | CALL udata(); |\n| T4 | SELECT * FROM t WHERE id=1;（返回1，较慢） | |\n| T5 | SELECT * FROM t WHERE id=1 LOCK IN SHARE MODE;（返回1,000,001，很快） | |\n\n#### 执行结果\n```sql\n-- T4时刻，快照读（一致性读）\nmysql> SELECT * FROM t WHERE id=1;\n+----+------+\n| id | c    |\n+----+------+\n|  1 |    1 |\n+----+------+\n1 row in set (0.99 sec)\n\n-- T5时刻，当前读\nmysql> SELECT * FROM t WHERE id=1 LOCK IN SHARE MODE;\n+----+---------+\n| id | c       |\n+----+---------+\n|  1 | 1000001 |\n+----+---------+\n1 row in set (0.00 sec)\n```\n\n#### undolog\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-troubleshoot-undolog.png\" width=500/>\n\n1. session B执行完100W次更新操作后，会生成100W个undolog\n2. `T4`时刻采用的是**快照读**（一致性读），需要从行的当前版本往回依次应用100W个undolog，返回1\n2. `T5`时刻采用的是**当前读**，直接返回当前版本，速度很快，返回1,000,001\n\n#### slowlog\n`T4`时刻的`Query_time`为`T5`时刻的4024倍\n```sql\n-- T3时刻\n# Time: 2019-02-13T21:17:33.758542+08:00\n# User@Host: root[root] @ localhost []  Id:    34\n# Query_time: 0.998028  Lock_time: 0.000093 Rows_sent: 1  Rows_examined: 1\nSET timestamp=1550063853;\nSELECT * FROM t WHERE id=1;\n\n-- T5时刻\n# Time: 2019-02-13T21:18:07.613083+08:00\n# User@Host: root[root] @ localhost []  Id:    34\n# Query_time: 0.000248  Lock_time: 0.000100 Rows_sent: 1  Rows_examined: 1\nSET timestamp=1550063887;\nSELECT * FROM t WHERE id=1 LOCK IN SHARE MODE;\n```\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 索引上的函数","url":"%2F2019%2F02%2F12%2Fmysql-index-function%2F","content":"\n## 结论先行\n如果对**索引字段**做**函数**操作，可能会**破坏索引值的有序性**，因此**优化器**会决定**放弃**走**树搜索**功能\n\n## 条件字段函数操作\n\n### 交易日志表\n```sql\nCREATE TABLE `tradelog` (\n    `id` INT(11) NOT NULL,\n    `tradeid` VARCHAR(32) DEFAULT NULL,\n    `operator` INT(11) DEFAULT NULL,\n    `t_modified` DATETIME DEFAULT CURRENT_TIMESTAMP,\n    PRIMARY KEY (`id`),\n    KEY `tradeid` (`tradeid`),\n    KEY `t_modified` (`t_modified`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n```\n\n<!-- more -->\n\n```sql\n-- 94608000 = 3 * 365 * 24 * 3600\n-- t_modified : 2016-01-01 00:00:00 ~ 2019-01-01 00:00:00\nDELIMITER ;;\nCREATE PROCEDURE tdata()\nBEGIN\n    DECLARE i INT;\n    SET i=0;\n    WHILE i<1000000 DO\n        INSERT INTO tradelog VALUES (i,i,i,FROM_UNIXTIME(UNIX_TIMESTAMP('2016-01-01 00:00:00')+FLOOR(0+(RAND()*94608000))));\n        SET i=i+1;\n    END WHILE;\nEND;;\nDELIMITER ;\n\nCALL tdata();\n```\n\n### month函数\n```sql\nSELECT COUNT(*) FROM tradelog WHERE MONTH(t_modified)=7;\n```\n\n#### explain\n```sql\nmysql> EXPLAIN SELECT COUNT(*) FROM tradelog WHERE MONTH(t_modified)=7\\G;\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: tradelog\n   partitions: NULL\n         type: index\npossible_keys: NULL\n          key: t_modified\n      key_len: 6\n          ref: NULL\n         rows: 998838\n     filtered: 100.00\n        Extra: Using where; Using index\n```\n1. `key=t_modified`：优化器选择了遍历二级索引`t_modified`\n2. `type=index`：表示**全索引扫描**（二级索引）\n3. `rows=998,838≈1,000,000`：说明这条语句基本**扫描**了整个二级索引`t_modified`\n4. `Using index`：表示使用了**覆盖索引**（**无需回表**）\n5. 在索引字段`t_modified`上加上`MONTH`函数，导致了**全索引扫描**，无法使用**树搜索**功能\n\n#### slowlog\n`Rows_examined=1,000,000`，佐证了**全索引扫描**\n```sql\n# Time: 2019-02-12T14:25:07.158350+08:00\n# User@Host: root[root] @ localhost []  Id:    13\n# Query_time: 0.208787  Lock_time: 0.000162 Rows_sent: 1  Rows_examined: 1000000\nSET timestamp=1549952707;\nSELECT COUNT(*) FROM tradelog WHERE MONTH(t_modified)=7;\n```\n\n#### 分析\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-index-function-month.png\" width=600/>\n\n1. `WHERE t_modified='2018-07-01'`，InnoDB会按照绿色箭头的路线找到结果（树搜索）\n    - 这源于B+树的特性：**同一层兄弟节点的有序性**\n2. `WHERE MONTH(t_modified)=7`，在树的第一层就不知道如何操作，因此**优化器放弃了树搜索功能**\n    - 优化器可以选择遍历**聚簇索引**，或者遍历**二级索引**`t_modified`\n    - 优化器在对比索引大小后发现，二级索引`t_modified`更小，最终选择了遍历二级索引`t_modified`\n\n### 优化方案\n```sql\nmysql> SELECT COUNT(*) FROM tradelog WHERE\n    -> (t_modified >= '2016-7-1' AND t_modified<'2016-8-1') OR\n    -> (t_modified >= '2017-7-1' AND t_modified<'2017-8-1') OR\n    -> (t_modified >= '2018-7-1' AND t_modified<'2018-8-1');\n```\n\n#### explain\n```sql\nmysql> EXPLAIN SELECT COUNT(*) FROM tradelog WHERE\n    -> (t_modified >= '2016-7-1' AND t_modified<'2016-8-1') OR\n    -> (t_modified >= '2017-7-1' AND t_modified<'2017-8-1') OR\n    -> (t_modified >= '2018-7-1' AND t_modified<'2018-8-1')\\G;\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: tradelog\n   partitions: NULL\n         type: range\npossible_keys: t_modified\n          key: t_modified\n      key_len: 6\n          ref: NULL\n         rows: 180940\n     filtered: 100.00\n        Extra: Using where; Using index\n```\n1. `type=range`：表示**索引范围扫描**（二级索引）\n2. `rows=180,940 < 998,838`，扫描行数**远小于**上面使用`MONTH`函数的情况\n\n#### slowlog\n`Rows_examined=84,704 < 1,000,000`，`Query_time`也仅为使用`MONTH`函数情况的**25%**\n```sql\n# Time: 2019-02-12T14:56:51.727672+08:00\n# User@Host: root[root] @ localhost []  Id:    13\n# Query_time: 0.051701  Lock_time: 0.000239 Rows_sent: 1  Rows_examined: 84704\nSET timestamp=1549954611;\nSELECT COUNT(*) FROM tradelog WHERE (t_modified >= '2016-7-1' AND t_modified<'2016-8-1') OR (t_modified >= '2017-7-1' AND t_modified<'2017-8-1') OR (t_modified >= '2018-7-1' AND t_modified<'2018-8-1');\n```\n\n### id+1\n```sql\nmysql> explain select * from tradelog where id+1 = 1000000\\G;\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: tradelog\n   partitions: NULL\n         type: ALL\npossible_keys: NULL\n          key: NULL\n      key_len: NULL\n          ref: NULL\n         rows: 998838\n     filtered: 100.00\n        Extra: Using where\n\nmysql> EXPLAIN SELECT * FROM tradelog WHERE id = 999999\\G;\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: tradelog\n   partitions: NULL\n         type: const\npossible_keys: PRIMARY\n          key: PRIMARY\n      key_len: 4\n          ref: const\n         rows: 1\n     filtered: 100.00\n        Extra: NULL\n```\n1. 优化器会偷懒，依然认为`id+1=1,000,000`是应用在索引字段上的函数，因此采用的是**全表扫描**\n2. 而`id=999,999`会走**聚簇索引**的**树搜索**，`const`表示这是**常量**操作（最多只会有一行记录匹配）\n\n## 隐式类型转换\n\n### 字符串 -> 数字\n在MySQL中，如果字符串和数字做比较，会先**将字符串转换为数字**\n```sql\nmysql> SELECT '10' > 9;\n+----------+\n| '10' > 9 |\n+----------+\n|        1 |\n+----------+\n```\n\n### tradeid\n\n#### explain\n```sql\nmysql> EXPLAIN SELECT * FROM tradelog WHERE tradeid=625912\\G;\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: tradelog\n   partitions: NULL\n         type: ALL\npossible_keys: tradeid\n          key: NULL\n      key_len: NULL\n          ref: NULL\n         rows: 998838\n     filtered: 10.00\n        Extra: Using where\n```\n1. `type=ALL`：表示**全表扫描**\n2. `rows=998,838≈1,000,000`\n3. 等价于`SELECT * FROM tradelog WHERE CAST(tradid AS SIGNED INT)=625912;`\n    - 隐式的类型转换，导致会在索引字段上做函数操作，优化器会放弃走树搜索的功能\n\n#### slowlog\n`Rows_examined`依然为`1,000,000`\n```sql\n# Time: 2019-02-12T15:30:09.033772+08:00\n# User@Host: root[root] @ localhost []  Id:    13\n# Query_time: 0.312170  Lock_time: 0.000114 Rows_sent: 1  Rows_examined: 1000000\nSET timestamp=1549956609;\nSELECT * FROM tradelog WHERE tradeid=625912;\n```\n\n### id\n\n#### explain\n```sql\nmysql> EXPLAIN SELECT * FROM tradelog WHERE id='625912'\\G;\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: tradelog\n   partitions: NULL\n         type: const\npossible_keys: PRIMARY\n          key: PRIMARY\n      key_len: 4\n          ref: const\n         rows: 1\n     filtered: 100.00\n        Extra: NULL\n```\n1. `type=const`：表示**常量操作**\n2. `key=PRIMARY`：走**聚簇索引**的树搜索功能\n3. `rows=1`：只需要扫描一行\n4. 等价于`SELECT * FROM tradelog WHERE id=CAST('625912' AS SIGNED INT);`\n    - 只是在**输入参数**上做隐式类型转换，在索引字段上并没有做函数操作，依然可以走**聚簇索引**的树搜索功能\n\n#### slowlog\n`Rows_examined=1`，只需要扫描一行\n```sql\n# Time: 2019-02-12T15:45:38.222760+08:00\n# User@Host: root[root] @ localhost []  Id:    13\n# Query_time: 0.000476  Lock_time: 0.000210 Rows_sent: 1  Rows_examined: 1\nSET timestamp=1549957538;\nSELECT * FROM tradelog WHERE id='625912';\n```\n\n## 隐式字符编码转换\n\n### 交易详情表\n```sql\n-- tradelog的编码为utf8mb4，trade_detail的编码为utf8\nCREATE TABLE `trade_detail` (\n    `id` INT(11) NOT NULL,\n    `tradeid` VARCHAR(32) DEFAULT NULL,\n    `trade_step` INT(11) DEFAULT NULL,\n    `step_info` VARCHAR(32) DEFAULT NULL,\n    PRIMARY KEY (`id`),\n    KEY `tradeid` (`tradeid`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n```\n```sql\nINSERT INTO tradelog VALUES (1, 'aaaaaaaa', 1000, NOW());\nINSERT INTO tradelog VALUES (2, 'aaaaaaab', 1000, NOW());\ninsert into tradelog VALUES (3, 'aaaaaaac', 1000, NOW());\n\nINSERT INTO trade_detail VALUES (1, 'aaaaaaaa', 1, 'add');\nINSERT INTO trade_detail VALUES (2, 'aaaaaaaa', 2, 'update');\nINSERT INTO trade_detail VALUES (3, 'aaaaaaaa', 3, 'commit');\nINSERT INTO trade_detail VALUES (4, 'aaaaaaab', 1, 'add');\nINSERT INTO trade_detail VALUES (5, 'aaaaaaab', 2, 'update');\nINSERT INTO trade_detail VALUES (6, 'aaaaaaab', 3, 'update again');\nINSERT INTO trade_detail VALUES (7, 'aaaaaaab', 4, 'commit');\nINSERT INTO trade_detail VALUES (8, 'aaaaaaac', 1, 'add');\nINSERT INTO trade_detail VALUES (9, 'aaaaaaac', 2, 'update');\nINSERT INTO trade_detail VALUES (10, 'aaaaaaac', 3, 'update again');\nINSERT INTO trade_detail VALUES (11, 'aaaaaaac', 4, 'commit');\n```\n\n### 函数作用于二级索引\n\n#### explain\n```sql\nmysql> EXPLAIN SELECT d.* FROM tradelog l, trade_detail d WHERE d.tradeid=l.tradeid AND l.id=2;\n+----+-------------+-------+------------+-------+-----------------+---------+---------+-------+------+----------+-------------+\n| id | select_type | table | partitions | type  | possible_keys   | key     | key_len | ref   | rows | filtered | Extra       |\n+----+-------------+-------+------------+-------+-----------------+---------+---------+-------+------+----------+-------------+\n|  1 | SIMPLE      | l     | NULL       | const | PRIMARY,tradeid | PRIMARY | 4       | const |    1 |   100.00 | NULL        |\n|  1 | SIMPLE      | d     | NULL       | ALL   | NULL            | NULL    | NULL    | NULL  |   11 |   100.00 | Using where |\n+----+-------------+-------+------------+-------+-----------------+---------+---------+-------+------+----------+-------------+\n```\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-index-function-char-encode.png\" width=500/>\n\n1. `tradelog`称为**驱动表**，`trade_detail`称为**被驱动表**，`tradeid`为**关联字段**。驱动原则：_**小表驱动大表**_\n2. 优化器会先在`tradelog`表上查找`id=2`的行，使用了`tradelog`的聚簇索引，只扫描了一行，取出`tradeid='aaaaaaab'`\n3. 然后到`trade_detail`表上查找`tradeid='aaaaaaab'`的行，但没有选择**二级索引**`tradeid`，而选择了**全表扫描**\n    - `type=ALL`，不符合预期，本希望走二级索引`tradeid`的树搜索功能\n    - 原因：两个表的**字符集不相同**\n        - `tradelog`的编码为`utf8mb4`，`trade_detail`的编码为`utf8`，\n        - `utf8mb4`是`utf8`的超集，详见[mysql中utf8和utf8mb4区别](https://www.cnblogs.com/beyang/p/7580814.html)\n        -  `d.tradeid=l.tradeid`时，需要先**将`utf8`字符串转换成`utf8mb4`字符串**\n        - 因此，被驱动表`trade_detail`里面的`tradeid`字段需要先转换成`utf8mb4`类型，再跟L2进行比较\n    - 等价于`SELECT * FROM trade_detail WHERE CONVERT(traideid USING utf8mb4)=$L2.tradeid.value;`\n        - 隐式的**字符编码转换**，导致会在二级索引`tradeid`上做函数操作，优化器会放弃走**树搜索**的功能\n\n#### slowlog\n```sql\n# Time: 2019-02-12T16:45:14.841502+08:00\n# User@Host: root[root] @ localhost []  Id:    13\n# Query_time: 0.000470  Lock_time: 0.000202 Rows_sent: 4  Rows_examined: 11\nSET timestamp=1549961114;\nSELECT d.* FROM tradelog l, trade_detail d WHERE d.tradeid=l.tradeid AND l.id=2;\n```\n\n### 函数作用于输入参数\n\n#### explain\n```sql\nmysql> EXPLAIN SELECT l.* FROM tradelog l, trade_detail d WHERE d.tradeid=l.tradeid AND d.id=4;\n+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+\n| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref   | rows | filtered | Extra |\n+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+\n|  1 | SIMPLE      | d     | NULL       | const | PRIMARY       | PRIMARY | 4       | const |    1 |   100.00 | NULL  |\n|  1 | SIMPLE      | l     | NULL       | ref   | tradeid       | tradeid | 131     | const |    1 |   100.00 | NULL  |\n+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+\n```\n1. `trade_detail`称为**驱动表**，`tradelog`称为**被驱动表**，`tradeid`为**关联字段**\n2. 被驱动表`tradelog`的编码为`utf8mb4`，驱动表`trade_detail`的编码为`utf8`\n    - 等价于`SELECT * FROM tradelog WHERE traideid = CONVERT($R4.tradeid.value USING utf8mb4);`\n    - 函数是用在**输入参数**上的，并非二级索引`tradeid`上，因此可以用**树搜索**功能（`key=tradeid`和`rows=1`）\n    - `type=ref`：**Join语句中被驱动表索引引用的查询**\n\n#### slowlog\n```sql\n# Time: 2019-02-12T17:31:50.553151+08:00\n# User@Host: root[root] @ localhost []  Id:    13\n# Query_time: 0.004090  Lock_time: 0.001874 Rows_sent: 1  Rows_examined: 1\nSET timestamp=1549963910;\nSELECT l.* FROM tradelog l, trade_detail d WHERE d.tradeid=l.tradeid AND d.id=4;\n```\n\n### 优化方案\n1. 常用：将`trade_detail.tradeid`的字符串编码修改为`utf8mb4`\n    - `ALTER TABLE trade_detail MODIFY tradeid VARCHAR(32) CHARACTER SET utf8mb4 DEFAULT NULL;`\n2. 修改SQL（场景：数据量较大或暂不支持该DDL）\n    - 主动把`l.tradeid`转换为`utf8`，避免了**被驱动表上的隐式字符编码转换**\n    - `SELECT d.* FROM tradelog l, trade_detail d WHERE d.tradeid=CONVERT(l.tradeid USING utf8) AND l.id=2;`\n\n```sql\nmysql> EXPLAIN SELECT d.* FROM tradelog l, trade_detail d WHERE d.tradeid=CONVERT(l.tradeid USING utf8) AND l.id=2;\n+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+\n| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref   | rows | filtered | Extra |\n+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+\n|  1 | SIMPLE      | l     | NULL       | const | PRIMARY       | PRIMARY | 4       | const |    1 |   100.00 | NULL  |\n|  1 | SIMPLE      | d     | NULL       | ref   | tradeid       | tradeid | 99      | const |    4 |   100.00 | NULL  |\n+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+\n```\n```sql\n# Time: 2019-02-12T17:50:29.844772+08:00\n# User@Host: root[root] @ localhost []  Id:    13\n# Query_time: 0.000504  Lock_time: 0.000206 Rows_sent: 4  Rows_examined: 4\nSET timestamp=1549965029;\nSELECT d.* FROM tradelog l, trade_detail d WHERE d.tradeid=CONVERT(l.tradeid USING utf8) AND l.id=2;\n```\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- order by rand","url":"%2F2019%2F02%2F10%2Fmysql-order-by-rand%2F","content":"\n## 单词表\n目的：随机选择3个单词\n```sql\nCREATE TABLE `words` (\n  `id` INT(11) NOT NULL AUTO_INCREMENT,\n  `word` VARCHAR(64) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\nDELIMITER ;;\nCREATE PROCEDURE wdata()\nBEGIN\n    DECLARE i INT;\n    SET i=0;\n    WHILE i<10000 DO\n        INSERT INTO words(word) VALUES (CONCAT(CHAR(97+(i DIV 1000)), CHAR(97+(i % 1000 DIV 100)), CHAR(97+(i % 100 DIV 10)), CHAR(97+(i % 10))));\n        SET i=i+1;\n    END WHILE;\nEND;;\nDELIMITER ;\n\nCALL wdata();\n```\n\n### 查询语句\n```sql\nSELECT word FROM words ORDER BY RAND() LIMIT 3;\n```\n\n<!-- more -->\n\n## 内存临时表\n\n### explain\n```sql\nmysql> EXPLAIN SELECT word FROM words ORDER BY RAND() LIMIT 3\\G;\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: words\n   partitions: NULL\n         type: ALL\npossible_keys: NULL\n          key: NULL\n      key_len: NULL\n          ref: NULL\n         rows: 9980\n     filtered: 100.00\n        Extra: Using temporary; Using filesort\n```\n1. `Using temporary;`：表示需要使用到**临时表**\n    - 如果采用的是**内存临时表**，存储引擎可以选择**TempTable**（默认）或**MEMORY**\n    - 如果采用的是**磁盘临时表**，存储引擎可以选择**InnoDB**（默认）或**MyISAM**\n2. `Using filesort`：表示需要执行**排序**操作\n3. 综合起来：需要**在临时表上排序**，该操作往往**执行代价比较大**，尽量避免\n\n```sql\n-- internal_tmp_mem_storage_engine introduced 8.0.2\nmysql> SHOW VARIABLES LIKE '%storage_engine%';\n+----------------------------------+--------+\n| Variable_name                    | Value  |\n+----------------------------------+--------+\n| default_storage_engine           | InnoDB |\n| default_tmp_storage_engine       | InnoDB |\n| disabled_storage_engines         |        |\n| internal_tmp_disk_storage_engine | InnoDB |\n| internal_tmp_mem_storage_engine  | MEMORY |\n+----------------------------------+--------+\n```\n\n#### 排序算法\n1. 对于**磁盘临时表**而言，会优先选择**全字段排序**，因为可以**减少磁盘访问**\n2. 对于**内存临时表**而言，会优先选择**rowid排序**，因为不需要磁盘操作，**回表的开销很低**\n\n### rowid\n1. 每个存储引擎用来**唯一标识一行数据的字段**\n2. InnoDB\n    - InnoDB采用的是索引组织表，必然有“主键”（显式声明或隐式自动生成）\n    - 如有**有显式**声明**主键**或**唯一主键**，rowid就是**主键**（主键优先）或**唯一主键**\n    - 如果**没有显式**声明**主键**和**唯一主键**，rowid是由**系统自动生成**（6 Bytes）的\n3. MEMORY\n    - MEMORY采用的不是**索引组织表**，可以简单理解为一个**数组**，rowid就是**数组的下标**\n    - 下面执行过程中讲到的**位置信息**（**pos**），其实就是**MEMORY引擎的rowid**（**数组下标**），即`rowid = pos`\n\n### tmp_table_size\n1. 当临时表需要的空间**小于**`tmp_table_size`（默认16MB），临时表将采用内存临时表\n2. 内存临时表存放两个字段：R（**8** Bytes）和W（**64*3** Bytes，按UTF8最大占用空间计算）\n3. 最大占用空间：`(8+64*3)*10000=2,000,000 < 16,777,216`，因此可以采用**内存临时表**\n\n```sql\n-- 16777216 Bytes = 16 MB\n-- 线上配置为128 MB\nmysql> SHOW VARIABLES LIKE '%tmp_table_size%';\n+----------------+----------+\n| Variable_name  | Value    |\n+----------------+----------+\n| tmp_table_size | 16777216 |\n+----------------+----------+\n```\n\n### sort_buffer_size\n```sql\n-- 262144 Bytes = 256 KB\nmysql> SHOW VARIABLES LIKE 'sort_buffer_size';\n+------------------+--------+\n| Variable_name    | Value  |\n+------------------+--------+\n| sort_buffer_size | 262144 |\n+------------------+--------+\n```\n1. 对于使用**内存临时表**而言，由于**回表开销很低**（都在**内存**中），优先选择**rowid排序**\n2. 而对`sort buffer`按R进行排序时，在空间充足的情况下，会优先现在**优先级队列排序**（MySQL 5.6引入）\n3. `262144 / size(R)+size(pos) = 262144/14 = 18724 > 3`，因此会选择**优先级队列排序**\n\n### 执行过程\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-order-by-rand-process.png\" width=600/>\n\n1. 创建一个采用**MEMORY**引擎的**内存临时表**（_**数组**_，_**没有索引**_），表内有两个字段：**R**和**W**\n    - R：**double类型**，用于存放**随机小数**\n    - W：**VARCHAR(64)类型**，用于存放**原表的word字段**\n2. 从**原表**中，按**主键顺序**依次取出**所有的word值**\n    - 对于每一个word值，调用`rand()`函数生成一个`(0,1)`之间的**随机小数**\n    - 将生成的随机小数和word值分别存入内存临时表的R和W字段\n    - 此时，行扫描行数为10000\n3. 内存临时表已经有10000行数据，下面需要在**没有索引的内存临时表**上，**按照字段R排序**\n    - 后续操作就没有原表什么事情了，_内存临时表相当于下一阶段的原表_\n4. 初始化`sort buffer`，确定放入两个字段：一个是**double**类型的R字段，一个是**整型类型**的pos\n    - R：用于存放**内存临时表的R字段**\n    - pos：用于存放**内存临时表的rowid字段**\n    - 类似于**rowid排序**，但实际可能会优化为**优先级队列排序**\n5. 从**内存临时表**中一行一行地取出**R**和**pos**，分别存入`sort buffer`的两个字段\n    - 此时，行扫描行数为20000\n6. 在`sort buffer`中根据字段**R排序**（如果优化为**优先级队列排序**，跳过）\n    - 该过程**不涉及表操作**，**不会增加扫描行数**\n7. 排序完成后，取出前3个结果的**pos**，依据pos依次到**内存临时表**中取出word值，返回客户端\n    - 此时，行扫描行数为**20003**\n\n### 观察指标\n\n#### 慢查询日志\n`Rows_examined`为20003，与上面分析结论一致\n```sql\n# Time: 2019-02-11T09:27:42.472723Z\n# User@Host: root[root] @ localhost []  Id:    13\n# Query_time: 0.007515  Lock_time: 0.000179 Rows_sent: 3  Rows_examined: 20003\nSET timestamp=1549877262;\nSELECT word FROM words ORDER BY RAND() LIMIT 3;\n```\n\n#### OPTIMIZER_TRACE\n```json\n\"filesort_information\": [\n    {\n        \"direction\": \"asc\",\n        \"table\": \"intermediate_tmp_table\",\n        \"field\": \"tmp_field_0\"\n    }\n],\n\"filesort_priority_queue_optimization\": {\n    \"limit\": 3,\n    \"chosen\": true\n},\n...\n\"filesort_summary\": {\n    \"memory_available\": 262144,\n    \"key_size\": 24,\n    \"row_size\": 24,\n    \"max_rows_per_buffer\": 4,\n    \"num_rows_estimate\": 10010,\n    \"num_rows_found\": 4,\n    \"num_examined_rows\": 10000,\n    \"num_initial_chunks_spilled_to_disk\": 0,\n    \"peak_memory_used\": 128,\n    \"sort_algorithm\": \"std::sort\",\n    \"unpacked_addon_fields\": \"using_priority_queue\",\n    \"sort_mode\": \"<fixed_sort_key, rowid>\"\n}\n```\n1. `filesort_priority_queue_optimization.chosen=true`和`unpacked_addon_fields=using_priority_queue`\n    - 表示使用了**优先级队列排序**\n2. `peak_memory_used < memory_available`和`num_initial_chunks_spilled_to_disk=0`\n    - 表示排序过程中没有使用**磁盘临时文件**，完全在`sort buffer`中进行，峰值内存才为**128 Bytes**\n3. `num_examined_rows`：参与排序的有10000行，这些行需要从**内存临时表**中读取，扫描行数+10000\n4. `sort_mode`中有`rowid`关键字：表示采用的是**rowid排序**\n\n### 优先级队列排序\n1. 需要取回R值**最小**的3个rowid，如果使用**归并排序**，结束后，10000行数据都是有序的，这样会**浪费**很多计算量\n2. 而采用优先级队列排序，可以**精确**地只得到3个最小的值\n\n#### 构建最大堆\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-order-by-rand-build-heap.png\" width=500/>\n\n1. 在内存临时表中，有10000个准备参与排序的行，一行为`(R,rowid)`，先取前3行放入`sort buffer`，构造成一个**堆**\n2. 取下一行`(R',rowid')`，与当前堆中最大的`R`比较\n    - 如果`R'`小于`R`，则把这个`(R,rowid)`从堆中去掉，替换成`(R',rowid')`\n3. 重复上述步骤，直到第10000行比较完成\n\n#### 回表返回\n1. 构造**最大堆**（在`sort buffer`中）完成后，堆里面存放的是10000行中R值**最小**的3行\n2. 依次取出对应的rowid，然后**回表**（内存临时表）取出word字段，返回给客户端\n\n## 磁盘临时表\n当临时表需要的空间**大于**`tmp_table_size`（默认16MB），内存临时表就会转成**磁盘临时表**（默认InnoDB存储引擎）\n\n### 优先级队列排序\n\n#### 执行过程\n```sql\n-- 构造使用磁盘临时表的场景，最小为1024\nSET tmp_table_size=1024;\n\n-- 构造使用磁盘临时文件的场景，最小为32768\n-- 如果内存空间不能满足优先级队列排序，会降级为归并排序（需要使用磁盘临时文件）\nSET sort_buffer_size=32768;\n\n-- 打开optimizer_trace，只对本线程有效\nSET optimizer_trace='enabled=on';\n\n-- 执行语句\nSELECT word FROM words ORDER BY RAND() LIMIT 3;\n\n-- 查看OPTIMIZER_TRACE输出\nSELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\\G\n```\n\n#### 观察指标\n\n##### 慢查询日志\n```sql\n# Time: 2019-02-11T10:32:49.301884Z\n# User@Host: root[root] @ localhost []  Id:    13\n# Query_time: 0.013087  Lock_time: 0.000124 Rows_sent: 3  Rows_examined: 20003\nSET timestamp=1549881169;\nSELECT word FROM words ORDER BY RAND() LIMIT 3;\n```\n\n##### OPTIMIZER_TRACE\n```json\n\"filesort_information\": [\n    {\n        \"direction\": \"asc\",\n        \"table\": \"intermediate_tmp_table\",\n        \"field\": \"tmp_field_0\"\n    }\n],\n\"filesort_priority_queue_optimization\": {\n    \"limit\": 3,\n    \"chosen\": true\n},\n...\n\"filesort_summary\": {\n    \"memory_available\": 32768,\n    \"key_size\": 8,\n    \"row_size\": 210,\n    \"max_rows_per_buffer\": 4,\n    \"num_rows_estimate\": 1170,\n    \"num_rows_found\": 4,\n    \"num_examined_rows\": 10000,\n    \"num_initial_chunks_spilled_to_disk\": 0,\n    \"peak_memory_used\": 872,\n    \"sort_algorithm\": \"std::sort\",\n    \"unpacked_addon_fields\": \"using_priority_queue\",\n    \"sort_mode\": \"<fixed_sort_key, additional_fields>\"\n}\n```\n1. 临时表需要占用的最小空间：`(8+4*1)*10000=120,000 > 32,768=tmp_table_size`，因此采用的是**磁盘临时表**\n2. 采用**磁盘临时表**，那就必须考虑**回表开销**了，优先选择**全字段排序**\n3. 磁盘临时表包含三个字段：**rowid（6 Bytes）**、**R（8 Bytes）**、**word（4\\*1~64\\*3 Bytes）**\n    - 单行最大长度为`6+8+64*3=206 < 4096=max_length_for_sort_data`，依然采用**全字段排序**\n4. `sort_mode`中有`additional_fields`关键字：表示采用的是**全字段排序**\n5. `sort_buffer_size / row_max_size = 32768/206 = 159 > 3`，因此可以选择**优先级队列排序**，佐证如下：\n    - `peak_memory_used=872 < memory_available`\n    - `filesort_priority_queue_optimization.chosen=true`\n    - `unpacked_addon_fields=using_priority_queue`\n    - `num_initial_chunks_spilled_to_disk=0`\n\n### 归并排序\n\n#### 执行过程\n```sql\nSELECT word FROM words ORDER BY RAND() LIMIT 3000;\n```\n\n#### 慢查询日志\n```sql\n# Time: 2019-02-11T11:07:01.812796Z\n# User@Host: root[root] @ localhost []  Id:    13\n# Query_time: 0.018456  Lock_time: 0.000113 Rows_sent: 3000  Rows_examined: 23000\nSET timestamp=1549883221;\nSELECT word FROM words ORDER BY RAND() LIMIT 3000;\n```\n\n#### OPTIMIZER_TRACE\n```json\n\"filesort_information\": [\n    {\n        \"direction\": \"asc\",\n        \"table\": \"intermediate_tmp_table\",\n        \"field\": \"tmp_field_0\"\n    }\n],\n\"filesort_priority_queue_optimization\": {\n    \"limit\": 3000,\n    \"strip_additional_fields\": {\n        \"row_size\": 22,\n        \"chosen\": false,\n        \"cause\": \"not_enough_space\"\n    }\n},\n...\n\"filesort_summary\": {\n    \"memory_available\": 32768,\n    \"key_size\": 8,\n    \"row_size\": 212,\n    \"max_rows_per_buffer\": 154,\n    \"num_rows_estimate\": 1170,\n    \"num_rows_found\": 10000,\n    \"num_examined_rows\": 10000,\n    \"num_initial_chunks_spilled_to_disk\": 8,\n    \"peak_memory_used\": 47968,\n    \"sort_algorithm\": \"std::stable_sort\",\n    \"sort_mode\": \"<fixed_sort_key, packed_additional_fields>\"\n}\n```\n1. `sort_mode`中含有`packed_additional_fields`关键字\n    - 采用**全字段排序**，并且对字段有做**紧凑**处理（word为VARCHAR类型）\n    - 佐证：`filesort_priority_queue_optimization.strip_additional_fields`\n2. `filesort_priority_queue_optimization..chosen=false`\n    - `row_size=22`，而`sort_buffer_size / row_size = 32768/22 = 1489 < 3000`\n    - 因此`sort buffer`不足以满足采用**优先级队列排序**，降级为**归并排序**（外部排序）\n    - 佐证：`cause=not_enough_space`和`num_initial_chunks_spilled_to_disk=8`\n\n## 随机排序\n1. 无论采用**内存临时表**还是**磁盘临时表**，`order by rand`都会让**计算过程很复杂**，需要**扫描大量行**，**资源消耗严重**\n2. 解决思路：**数据库只负责读写数据**（**职责尽量单一**），随机排序的逻辑交由**业务层**实现\n\n### 随机算法1\n简化问题：随机选择1个word\n```sql\nSELECT MAX(id),MIN(id) INTO @M,@N FROM words;\nSET @X=FLOOR(@N+(@M-@N+1)*RAND());\nSELECT * FROM words WHERE id >= @X LIMIT 1;\n```\n1. MAX和MIN都**不需要将索引遍历一遍**，**效率很高**\n2. 第3步可以利用**索引**快速定位\n3. 但算法本身并**非严格随机**，因为ID中间可能存在**空洞**，因此选择不同行的概率是不一样的\n\n### 随机算法2\n```sql\nSELECT COUNT(*) INTO @C FROM words;\nSET @Y = FLOOR(@C*RAND());\nSET @sql = CONCAT(\"SELECT * FROM words LIMIT \", @Y, \",1\");\nPREPARE stmt from @sql;\nEXECUTE stmt;\nDEALLOCATE PREPARE stmt;\n```\n1. 优点：**严格随机**\n2. `LIMIT Y,1`：按顺序一个个读出，丢掉前面Y个，然后把第**Y+1**个记录返回，因此该过程需要扫描Y+1行\n3. 整个过程的扫描行数：**C+Y+1**\n    - 执行代价比随机算法1要高\n    - 但相对于`order by rand`，执行代价还是很小的\n        - 因为随机算法2是**直接根据主键**排序获取的\n        - 而`order by rand`很繁琐：**生成临时表**，**按R字段排序**，**获取rowid后回查临时表**（如果是rowid排序）\n\n### 随机算法3\n恢复到取3个word，整个过程的扫描行数：**C+(Y1+1)+(Y2+1)+(Y3+1)**\n```sql\nSELECT COUNT(*) INTO @C FROM words;\nSET @Y1 = FLOOR(@C * RAND());\nSET @Y2 = FLOOR(@C * RAND());\nSET @Y3 = FLOOR(@C * RAND());\n-- 在应用代码里面取Y1、Y2、Y3，拼出SQL后执行\nSELECT * FROM words LIMIT @Y1,1;\nSELECT * FROM words LIMIT @Y2,1;\nSELECT * FROM words LIMIT @Y3,1;\n```\n\n### 随机算法4\n整个过程的扫描行数：**C+MAX(Y1,Y2,Y3)+1+3**\n```sql\nSELECT COUNT(*) INTO @C FROM words;\nSET @Y1 = FLOOR(@C * RAND());\nSET @Y2 = FLOOR(@C * RAND());\nSET @Y3 = FLOOR(@C * RAND());\nSET @M = MAX(@Y1,@Y2,@Y3);\nSET @N = MIN(@Y1,@Y2,@Y3);\nSELECT id FROM words LIMIT N,M-N+1;\n-- 业务代码随机选择ID1、ID2、ID3\nSELECT * FROM words WHERE id IN (ID1,ID2,ID3);\n```\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- order by","url":"%2F2019%2F02%2F09%2Fmysql-order-by%2F","content":"\n## 市民信息\n```sql\nCREATE TABLE `t` (\n  `id` INT(11) NOT NULL,\n  `city` VARCHAR(16) NOT NULL,\n  `name` VARCHAR(16) NOT NULL,\n  `age` INT(11) NOT NULL,\n  `addr` VARCHAR(128) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `city` (`city`)\n) ENGINE=InnoDB;\n```\n\n### 查询语句\n```sql\nSELECT city,name,age FROM t WHERE city='杭州' ORDER BY name LIMIT 1000;\n```\n\n<!-- more -->\n\n### 存储过程\n```sql\nDELIMITER ;;\nCREATE PROCEDURE idata()\nBEGIN\n    DECLARE i INT;\n    SET i=0;\n    WHILE i<4000 DO\n        INSERT INTO t VALUES (i,'杭州',concat('zhongmingmao',i),'20','XXX');\n        SET i=i+1;\n    END WHILE;\nEND;;\nDELIMITER ;\n\nCALL idata();\n```\n\n## 全字段排序\n\n### city索引树\n满足city='杭州'的行，主键为`ID_X ~ ID_(X+N)`\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-order-by-index-city.png\" width=500/>\n\n\n### sort buffer\n```sql\nmysql> EXPLAIN SELECT city,name,age FROM t FORCE INDEX(city) WHERE city='杭州' ORDER BY name LIMIT 1000\\G;\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: t\n   partitions: NULL\n         type: ref\npossible_keys: city\n          key: city\n      key_len: 50\n          ref: const\n         rows: 4000\n     filtered: 100.00\n        Extra: Using index condition; Using filesort\n```\n1. `rows=4000`：EXPLAIN是**不考虑LIMIT的**，代表**匹配条件的总行数**\n2. `Using index condition`：表示使用了**索引下推**\n3. `Using filesort`：表示需要**排序**，MySQL会为每个**线程**分配一块内存用于排序，即`sort buffer`\n\n```sql\n-- 1048576 Bytes = 1 MB\nmysql> SHOW VARIABLES LIKE '%sort_buffer%';\n+-------------------------+----------+\n| Variable_name           | Value    |\n+-------------------------+----------+\n| innodb_sort_buffer_size | 67108864 |\n| myisam_sort_buffer_size | 8388608  |\n| sort_buffer_size        | 1048576  |\n+-------------------------+----------+\n```\n\n### 执行过程\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-order-by-all-field-sort.jpg\" width=500/>\n\n1. 初始化`sort buffer`，确定放入三个字段：**`city`、`name`、`age`**\n2. 从**city索引树**找到第一个满足city='杭州'的主键ID，即ID_X\n3. 然后拿着ID_X**回表**取出整行，将`city`、`name`、`age`这三个字段的值都存入`sort buffer`\n4. 回到**city索引树**取下一条记录，重复上述动作，直至city的值不满足条件为止，即ID_Y\n5. 对`sort buffer`中的数据按照`name`字段进行排序\n    - 排序过程可能使用**内部排序**（**内存**，**首选**，**快速排序/堆排序**），也可能使用**外部排序**（**磁盘**，**次选**，**归并排序**）\n    - 这取决于**排序所需要的内存**是否小于`sort_buffer_size`（默认**1 MB**）\n6. 按照排序结果取前1000行返回给客户端\n\n### 观察指标\n```sql\n-- 打开慢查询日志\nSET GLOBAL slow_query_log=ON;\nSET long_query_time=0;\n\n-- 查询optimizer_trace时需要用到临时表，internal_tmp_disk_storage_engine默认值为InnoDB\n-- 采用默认值时，把数据从临时表取出来的时候，会将Innodb_rows_read+1，因此修改为MyISAM，减少干扰信息\nSET GLOBAL internal_tmp_disk_storage_engine=MyISAM;\n\n-- 将sort buffer设置为最小值，这是为了构造外部排序的场景，如果是内部排序则无需执行该语句\nSET sort_buffer_size=32768;\n\n-- 打开optimizer_trace，只对本线程有效\nSET optimizer_trace='enabled=on';\n\n-- @a 保存Innodb_rows_read的初始值\nSELECT VARIABLE_VALUE INTO @a FROM  performance_schema.session_status WHERE variable_name = 'Innodb_rows_read';\n\n-- 执行语句\nSELECT city,name,age FROM t FORCE INDEX(city) WHERE city='杭州' ORDER BY name LIMIT 1000;\n\n-- 查看optimizer_trace输出\nSELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\\G;\n\n-- @b 保存Innodb_rows_read的当前值\nSELECT VARIABLE_VALUE INTO @b FROM performance_schema.session_status WHERE variable_name = 'Innodb_rows_read';\n\n-- 计算Innodb_rows_read差值\n-- MyISAM为4000，InnoDB为4001\nSELECT @b-@a;\n```\n\n#### 外部排序\n\n##### 慢查询日志\n```sql\n# Time: 2019-02-10T07:19:38.347053Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 0.012832  Lock_time: 0.000308 Rows_sent: 1000  Rows_examined: 5000\nSET timestamp=1549783178;\nSELECT city,name,age FROM t FORCE INDEX(city) WHERE city='杭州' ORDER BY name LIMIT 1000;\n```\n\n##### OPTIMIZER_TRACE\n```json\n\"filesort_summary\": {\n    \"memory_available\": 32768,\n    \"key_size\": 32,\n    \"row_size\": 140,\n    \"max_rows_per_buffer\": 234,\n    \"num_rows_estimate\": 16912,\n    \"num_rows_found\": 4000,\n    \"num_examined_rows\": 4000,\n    \"num_initial_chunks_spilled_to_disk\": 9,\n    \"peak_memory_used\": 35096,\n    \"sort_algorithm\": \"std::stable_sort\",\n    \"sort_mode\": \"<fixed_sort_key, packed_additional_fields>\"\n}\n```\n> In optimizer trace output, `num_tmp_files` did not actually indicate number of files.\nIt has been **renamed** to `num_initial_chunks_spilled_to_disk` and indicates the **number of chunks before any merging has occurred**.\n\n1. `num_initial_chunks_spilled_to_disk=9`，说明采用了**外部排序**，使用了**磁盘临时文件**\n2. `peak_memory_used > memory_available`：**sort buffer空间不足**\n3. 如果`sort_buffer_size`越小，`num_initial_chunks_spilled_to_disk`的值就越大\n4. 如果`sort_buffer_size`足够大，那么`num_initial_chunks_spilled_to_disk=0`，采用**内部排序**\n5. `num_examined_rows=4000`：**参与排序的行数**\n6. `sort_mode`含有的`packed_additional_fields`：排序过程中对**字符串**做了**紧凑**处理\n    - 字段name为`VARCHAR(16)`，在排序过程中还是按照**实际长度**来分配空间\n\n##### 扫描行数\n整个执行过程中总共**扫描**了4000行（如果`internal_tmp_disk_storage_engine=InnoDB`，返回4001）\n```sql\nmysql> SELECT @b-@a;\n+-------+\n| @b-@a |\n+-------+\n|  4000 |\n+-------+\n```\n\n#### 内部排序\n\n##### 慢查询日志\n`Query_time`为0.007517，为采用外部排序的**59%**\n```sql\n# Time: 2019-02-10T07:36:36.442679Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 0.007517  Lock_time: 0.000242 Rows_sent: 1000  Rows_examined: 5000\nSET timestamp=1549784196;\nSELECT city,name,age FROM t FORCE INDEX(city) WHERE city='杭州' ORDER BY name LIMIT 1000;\n```\n\n##### OPTIMIZER_TRACE\n```json\n\"filesort_information\": [\n    {\n        \"direction\": \"asc\",\n        \"table\": \"`t` FORCE INDEX (`city`)\",\n        \"field\": \"name\"\n    }\n],\n\"filesort_priority_queue_optimization\": {\n    \"limit\": 1000,\n    \"chosen\": true\n},\n...\n\"filesort_summary\": {\n    \"memory_available\": 1048576,\n    \"key_size\": 32,\n    \"row_size\": 138,\n    \"max_rows_per_buffer\": 1001,\n    \"num_rows_estimate\": 16912,\n    \"num_rows_found\": 1001,\n    \"num_examined_rows\": 4000,\n    \"num_initial_chunks_spilled_to_disk\": 0,\n    \"peak_memory_used\": 146146,\n    \"sort_algorithm\": \"std::stable_sort\",\n    \"unpacked_addon_fields\": \"using_priority_queue\",\n    \"sort_mode\": \"<fixed_sort_key, additional_fields>\"\n}\n```\n1. `num_initial_chunks_spilled_to_disk=0`，说明采用了内部排序（**堆排序**），排序直接在`sort buffer`中完成\n2. `peak_memory_used < memory_available`：**sort buffer空间充足**\n3. `num_examined_rows=4000`：**参与排序的行数**\n4. `filesort_priority_queue_optimization`：采用**优先级队列优化**（**堆排序**）\n\n##### 扫描行数\n```sql\nmysql> SELECT @b-@a;\n+-------+\n| @b-@a |\n+-------+\n|  4000 |\n+-------+\n```\n\n### 性能\n1. 全字段排序：对**原表**数据读一遍（覆盖索引的情况除外），其余操作都在`sort buffer`和**临时文件**中进行\n2. 如果查询要**返回的字段很多**，那么`sort buffer`中能同时放下的行就会变得很少\n3. 这时会分成**很多个临时文件**，**排序性能就会很差**\n4. 解决方案：采用_**rowid排序**_\n    - 单行的长度**不超过**`max_length_for_sort_data`：**全字段排序**\n    - 单行的长度**超过**`max_length_for_sort_data`：**rowid排序**\n\n```sql\nmysql> SHOW VARIABLES LIKE '%max_length_for_sort_data%';\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| max_length_for_sort_data | 4096  |\n+--------------------------+-------+\n```\n\n## rowid排序\n`city`、`name`和`age`三个字段的总长度最少为36，执行`SET max_length_for_sort_data=16;`\n\n### 执行过程\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-order-by-rowid-sort.jpg\" width=500/>\n\n1. 初始化`sort buffer`，确定放入两个字段：**`name`（需要排序的字段）、`id`（索引组织表，主键）**\n2. 从**city索引树**找到第一个满足city='杭州'的主键ID，即ID_X\n3. 然后拿着ID_X**回表**取出整行，将`name`和`ID`这两个字段的值存入`sort buffer`\n4. 回到**city索引树**取下一条记录，重复上述动作，直至city的值不满足条件为止，即ID_Y\n5. 对`sort buffer`中的数据按照`name`字段进行排序（当然也有可能仍然是**外部排序**）\n6. 遍历排序结果，取出前1000行，并按照主键id的值**回表**取出`city`，`name`和`age`三个字段返回给客户端\n    - 其实，结果集只是一个**逻辑概念**，MySQL服务端在sort buffer排序完成后，不会再耗费内存来存储回表取回的内容\n    - 实际上，MySQL服务端从排序后的`sort buffer`中依次取出id，回表取回内容后，**直接返回给客户端**\n\n### 观察指标\n```sql\n-- 采用外部排序 + rowid排序\nSET sort_buffer_size=32768;\nSET max_length_for_sort_data=16;\n```\n\n#### 慢查询日志\n```sql\n# Time: 2019-02-10T08:23:59.068672Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 0.012047  Lock_time: 0.000479 Rows_sent: 1000  Rows_examined: 5000\nSET timestamp=1549787039;\nSELECT city,name,age FROM t FORCE INDEX(city) WHERE city='杭州' ORDER BY name LIMIT 1000;\n```\n\n#### OPTIMIZER_TRACE\n```json\n\"filesort_information\": [\n    {\n        \"direction\": \"asc\",\n        \"table\": \"`t` FORCE INDEX (`city`)\",\n        \"field\": \"name\"\n    }\n],\n\"filesort_priority_queue_optimization\": {\n    \"limit\": 1000\n},\n...\n\"filesort_summary\": {\n    \"memory_available\": 32768,\n    \"key_size\": 36,\n    \"row_size\": 36,\n    \"max_rows_per_buffer\": 910,\n    \"num_rows_estimate\": 16912,\n    \"num_rows_found\": 4000,\n    \"num_examined_rows\": 4000,\n    \"num_initial_chunks_spilled_to_disk\": 6,\n    \"peak_memory_used\": 35008,\n    \"sort_algorithm\": \"std::stable_sort\",\n    \"unpacked_addon_fields\": \"max_length_for_sort_data\",\n    \"sort_mode\": \"<fixed_sort_key, rowid>\"\n}\n```\n1. `num_initial_chunks_spilled_to_disk`，9->6，说明外部排序所需要的**临时文件变少**了\n2. `sort_mode`含有的`rowid`：采用**rowid排序**\n3. `num_examined_rows=4000`：**参与排序的行数**\n\n#### 扫描行数\n扫描的行数变成了5000行（多出了1000行是**回表**操作）\n```sql\nmysql> SELECT @b-@a;\n+-------+\n| @b-@a |\n+-------+\n|  5000 |\n+-------+\n```\n\n## 全字段排序 vs rowid排序\n1. MySQL只有在担心由于**sort buffer太小而影响排序效率**的时候，才会考虑使用rowid排序，rowid排序的优缺点如下\n    - 优点：排序过程中，**一次排序可以排序更多的行**\n    - 缺点：增加**回表**次数，**与LIMIT N成正相关**\n2. MySQL如果认为`sort buffer`足够大，会**优先选择全字段排序**\n    - 把需要的所有字段都放到`sort buffer`，排序完成后**直接从内存返回查询结果**，**无需回表**\n    - 体现了MySQL的一个设**计思路**\n        - _**尽量使用内存，减少磁盘访问**_\n4. MySQL排序是一个比较**成本较高**的操作，进一步的优化方案：**联合索引**、**覆盖索引**\n    - 目的：**移除`Using filesort`**\n\n## 优化方案\n\n### 联合索引\n```sql\nALTER TABLE t ADD INDEX city_user(city, name);\n```\n\n#### city_user索引树\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-order-by-combine-index.png\" width=500/>\n\n\n#### explain\n```sql\nmysql> EXPLAIN SELECT city,name,age FROM t FORCE INDEX(city_user) WHERE city='杭州' ORDER BY name LIMIT 1000\\G;\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: t\n   partitions: NULL\n         type: ref\npossible_keys: city_user\n          key: city_user\n      key_len: 50\n          ref: const\n         rows: 4000\n     filtered: 100.00\n        Extra: Using index condition\n```\n1. `Extra`里面已经移除了`Using filesort`，说明MySQL**不需要排序**操作了\n2. 联合索引`city_user`本身就是**有序**的，因此无需将4000行都扫描一遍，只需要扫描满足条件的前**1000**条记录即可\n3. `Using index condition`：表示使用了**索引下推**\n\n#### 执行过程\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-order-by-combine-index-process.jpg\" width=500/>\n\n1. 从**city_user索引树**找到第一个满足city='杭州'的主键ID，即ID_X\n2. 然后拿着ID_X**回表**取出整行，取`city`、`name`和`age`三个字段的值，作为结果集的一部分**直接返回给客户端**\n3. 继续取**city_user索引树**的下一条记录，重复上述步骤，直到查到1000条记录或者不满足city='杭州'时结束循环\n4. 这个过程**不需要排序**（当然也不需要外部排序用到的**临时文件**）\n\n#### 观察指标\n\n##### 慢查询日志\n`Rows_examined`为1000，`Query_time`为上面全字段排序（内部排序）的情况耗时的**49%**\n```sql\n278 # Time: 2019-02-10T09:00:28.956622Z\n279 # User@Host: root[root] @ localhost []  Id:     8\n280 # Query_time: 0.003652  Lock_time: 0.000569 Rows_sent: 1000  Rows_examined: 1000\n281 SET timestamp=1549789228;\n282 SELECT city,name,age FROM t FORCE INDEX(city_user) WHERE city='杭州' ORDER BY name LIMIT 1000;\n```\n\n##### 扫描行数\n```sql\nmysql> SELECT @b-@a;\n+-------+\n| @b-@a |\n+-------+\n|  1000 |\n+-------+\n```\n\n### 覆盖索引\n覆盖索引：索引上的信息**足够满足查询需求**，**无需再回表**，但维护索引是有代价的，需要权衡\n```sql\nALTER TABLE t ADD INDEX city_user_age(city, name, age);\n```\n\n#### explain\n`Using index`：表示使用**覆盖索引**\n```sql\nmysql> EXPLAIN SELECT city,name,age FROM t FORCE INDEX(city_user_age) WHERE city='杭州' ORDER BY name LIMIT 1000\\G;\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: t\n   partitions: NULL\n         type: ref\npossible_keys: city_user_age\n          key: city_user_age\n      key_len: 50\n          ref: const\n         rows: 4000\n     filtered: 100.00\n        Extra: Using where; Using index\n```\n\n#### 执行过程\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-order-by-coverage-index-process.jpg\" width=500/>\n\n1. 从**city_user_age索引树**找到第一个满足city='杭州'的记录\n    - 直接取出`city`、`name`和`age`这三个字段的值，作为结果集的一部分**直接返回给客户端**\n2. 继续取**city_user_age索引树**的下一条记录，重复上述步骤，直到查到1000条记录或者不满足city='杭州'时结束循环\n\n#### 观察指标\n\n##### 慢查询日志\n`Rows_examined`同样为1000，`Query_time`为上面使用联合索引`city_user`耗时的**49%**\n```sql\n# Time: 2019-02-10T09:16:20.911513Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 0.001800  Lock_time: 0.000366 Rows_sent: 1000  Rows_examined: 1000\nSET timestamp=1549790180;\nSELECT city,name,age FROM t FORCE INDEX(city_user_age) WHERE city='杭州' ORDER BY name LIMIT 1000;\n```\n\n##### 扫描行数\n```sql\nmysql> SELECT @b-@a;\n+-------+\n| @b-@a |\n+-------+\n|  1000 |\n+-------+\n```\n\n## in语句优化\n假设已有联合索引city_user(city,name)，查询语句如下\n```sql\nSELECT * FROM t WHERE city IN ('杭州','苏州') ORDER BY name LIMIT 100;\n```\n单个city内部，name是递增的，但在匹配多个city时，name就不能保证是递增的，因此这个SQL语句**需要排序**\n\n### explain\n依然有`Using filesort`\n```sql\nmysql> EXPLAIN SELECT * FROM t FORCE INDEX(city_user) WHERE city IN ('杭州','苏州') ORDER BY name LIMIT 100\\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: t\n   partitions: NULL\n         type: range\npossible_keys: city_user\n          key: city_user\n      key_len: 50\n          ref: NULL\n         rows: 4001\n     filtered: 100.00\n        Extra: Using index condition; Using filesort\n\nmysql> EXPLAIN SELECT * FROM t FORCE INDEX(city_user) WHERE city IN ('杭州') ORDER BY name LIMIT 100\\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: t\n   partitions: NULL\n         type: ref\npossible_keys: city_user\n          key: city_user\n      key_len: 50\n          ref: const\n         rows: 4000\n     filtered: 100.00\n        Extra: Using index condition\n```\n\n### 解决方案\n1. _**拆分语句，包装在同一个事务**_\n2. `SELECT * FROM t WHERE city='杭州' ORDER BY name LIMIT 100;`：不需要排序，客户端用一个**内存数组A**保存结果\n3. `SELECT * FROM t WHERE city='苏州' ORDER BY name LIMIT 100;`：不需要排序，客户端用一个**内存数组B**保存结果\n4. 内存数组A和内存数组B**均为有序数组**，可以采用**内存中的归并排序**\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 无过滤条件的count","url":"%2F2019%2F02%2F07%2Fmysql-innodb-pure-count%2F","content":"\n## count(\\*)\n\n### 实现\n1. **MyISAM**：将**表的总行数**存放在**磁盘**上，针对**无过滤条件**的查询可以**直接返回**\n    - 如果有过滤条件的count(\\*)，MyISAM也不能很快返回\n2. **InnoDB**：从存储引擎**一行行**地读出数据，然后**累加计数**\n    - 由于**MVCC**，在同一时刻，InnoDB应该返回多少行是**不确定**\n\n<!-- more -->\n\n#### 样例\n假设表t有10000条记录\n\n| session A | session B | session C |\n| ---- | ---- | ---- |\n| BEGIN; | | |\n| SELECT COUNT(*) FROM t;（返回10000） | | |\n| | | INSERT INTO t;（插入一行） |\n| | BEGIN; | |\n| | INSERT INTO t（插入一行）; | |\n| SELECT COUNT(*) FROM t;（返回10000） | SELECT COUNT(*) FROM t;（返回10002）| SELECT COUNT(*) FROM T;（返回10001） |\n\n1. 最后时刻三个会话同时查询t的总行数，拿到的结果却是不同的\n2. InnoDB默认事务隔离级别是**RR**，通过**MVCC**实现\n    - 每个事务都需要判断**每一行记录**是否**对自己可见**\n\n### 优化\n1. InnoDB是**索引组织表**\n    - **聚簇索引树**：叶子节点是**数据**\n    - **二级索引树**：叶子节点是**主键值**\n2. 二级索引树**占用的空间**比聚簇索引树**小很多**\n3. 优化器会在保证**逻辑正确**的前提下，遍历**最小**的索引树，尽量减少扫描的数据量\n    - 针对无过滤条件的count操作，无论遍历哪一颗索引树，效果都是一样的\n    - 优化器会为count(\\*)选择**最优**的索引树\n\n### show table status\n```sql\nmysql> SHOW TABLE STATUS\\G;\n*************************** 1. row ***************************\n           Name: t\n         Engine: InnoDB\n        Version: 10\n     Row_format: Dynamic\n           Rows: 100256\n Avg_row_length: 47\n    Data_length: 4734976\nMax_data_length: 0\n   Index_length: 5275648\n      Data_free: 0\n Auto_increment: NULL\n    Create_time: 2019-02-01 17:49:07\n    Update_time: NULL\n     Check_time: NULL\n      Collation: utf8_general_ci\n       Checksum: NULL\n Create_options:\n        Comment:\n```\n`SHOW TABLE STATUS`同样通过**采样**来估算（非常不精确），误差能到`40%~50%`\n\n## 维护计数\n\n### 缓存\n\n#### 方案\n1. 用**Redis**来保存表的总行数（无过滤条件）\n2. 这个表每插入一行，Redis计数+1，每删除一行，Redis计数-1\n\n#### 缺点\n\n##### 丢失更新\n1. Redis可能会丢失更新\n2. 解决方案：Redis异常重启后，到数据库执行一次count(\\*)\n    - 异常重启并不常见，这时全表扫描的成本是可以接受的\n\n##### 逻辑不精确 -- 致命\n1. 场景：显示**操作记录的总数**和**最近操作的100条记录**\n2. Redis和MySQL是两个不同的存储系统，_**不支持分布式事务**_，因此无法拿到精确的**一致性视图**\n\n**时序A**\nsession B在T3时刻，查到的100行结果里面有最新插入的记录，但Redis还没有+1，_**逻辑不一致**_\n\n| 时刻 | session A | session B |\n| ---- | ---- | ---- |\n| T1 | | |\n| T2 | 插入一行数据R; | |\n| T3 | | 读取Redis计数;<br/>查询最近100条记录; |\n| T4 | Redis计数+1; | |\n\n**时序B**\nsession B在T3时刻，查到的100行结果里面没有最新插入的记录，但Redis已经+1，_**逻辑不一致**_\n\n| 时刻 | session A | session B |\n| ---- | ---- | ---- |\n| T1 | | |\n| T2 | Redis计数+1; | |\n| T3 | | 读取Redis计数;<br/>查询最近100条记录; |\n| T4 | 插入一行数据R; | |\n\n\n### 数据库\n1. 把计数值放到数据库单独的一张计数表C中\n2. 利用InnoDB的**crash-safe**的特性，解决了**崩溃丢失**的问题\n3. 利用InnoDB的**支持事务**的特性，解决了**一致性视图**的问题\n4. session B在T3时刻，session A的事务还未提交，表C的计数值+1对自己不可见，_**逻辑一致**_\n\n| 时刻 | session A | session B |\n| ---- | ---- | ---- |\n| T1 | | |\n| T2 | BEGIN;<br/>表C中的计数值+1; | |\n| T3 | | BEGIN;<br/>读表C计数值;<br/>查询最新100条记录;<br/>COMMIT; |\n| T4 | 插入一行数据R;<br/>COMMIT; | |\n\n## count的性能\n\n### 语义\n1. count()是一个**聚合**函数，对于返回的结果集，一行一行地进行判断\n    - 如果count函数的参数值不是**NULL**，累计值+1，否则不加，最后返回累计值\n2. **count(字段F)**\n    - 字段F**有可能为NULL**\n    - 表示返回满足条件的结果集里字段F**不为NULL**的总数\n3. **count(主键ID)**、**count(1)**、**count(\\*)**\n    - _**不可能为NULL**_\n    - 表示返回满足条件的结果集的总数\n4. Server层要什么字段，InnoDB引擎就返回什么字段\n    - count(\\*)例外，_**不返回整行**_，只返回**空行**\n\n### 性能对比\n\n#### count(字段F)\n1. 如果字段F定义为**不允许为NULL**，一行行地从记录里读出这个字段，判断通过后按行累加\n    - 通过表结构判断该字段是**不可能为NULL**\n2. 如果字段F定义为**允许NULL**，一行行地从记录里读出这个字段，判断通过后按行累加\n    - 通过表结构判断该字段是**有可能为NULL**\n    - 判断该字段值是否实际为NULL\n3. 如果字段F上**没有二级索引**，只能**遍历整张表**（聚簇索引）\n4. _**由于InnoDB必须返回字段F，因此优化器能做出的优化决策将减少**_\n    - 例如不能选择**最优**的索引来遍历\n\n#### count(主键ID)\n1. InnoDB会**遍历整张表**（聚簇索引），把每一行的id值取出来，返回给Server层\n2. Server层拿到id后，判断为不可能为NULL，然后按行累加\n3. 优化器可能会选择**最优**的索引来遍历\n\n#### count(1)\n1. InnoDB引擎会**遍历整张表**（聚簇索引），但**不取值**\n2. Server层对于返回的每一行，放一个数字1进去，判断是不可能为NULL，按行累加\n3. count(1)比count(主键ID)快，因为count(主键ID)会涉及到两部分操作\n    - _**解析数据行**_\n    - _**拷贝字段值**_\n\n#### count(\\*)\n1. count(\\*)不会把所有值都取出来，而是专门做了优化，**不取值**，因为『\\*』肯定不为NULL，按行累加\n2. 不取值：InnoDB返回一个**空行**，告诉Server层**不是NULL，可以计数**\n\n#### 效率排序\n1. **count(字段F) < count(主键ID) < count(1) ≈ count(\\*)**\n2. **尽量使用count(\\*)**\n\n### 样例\n```sql\nmysql> SHOW CREATE TABLE prop_action_batch_reward\\G;\n*************************** 1. row ***************************\n       Table: prop_action_batch_reward\nCreate Table: CREATE TABLE `prop_action_batch_reward` (\n  `id` bigint(20) NOT NULL,\n  `source` int(11) DEFAULT NULL,\n  `serial_id` bigint(20) NOT NULL,\n  `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  `user_ids` mediumtext,\n  `serial_index` tinyint(4) DEFAULT '0',\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `uniq_serial_id_source_index` (`serial_id`,`source`,`serial_index`),\n  KEY `idx_create_time` (`create_time`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8\n```\n\n#### count(字段F)\n\n##### 无索引\nuser_ids上无索引，而InnoDB又必须返回user_ids字段，只能**遍历聚簇索引**\n```sql\nmysql> EXPLAIN SELECT COUNT(user_ids) FROM prop_action_batch_reward;\n+----+-------------+--------------------------+------+---------------+------+---------+------+----------+-------+\n| id | select_type | table                    | type | possible_keys | key  | key_len | ref  | rows     | Extra |\n+----+-------------+--------------------------+------+---------------+------+---------+------+----------+-------+\n|  1 | SIMPLE      | prop_action_batch_reward | ALL  | NULL          | NULL | NULL    | NULL | 16435876 | NULL  |\n+----+-------------+--------------------------+------+---------------+------+---------+------+----------+-------+\n\nmysql> SELECT COUNT(user_ids) FROM prop_action_batch_reward;\n+-----------------+\n| count(user_ids) |\n+-----------------+\n|        17689788 |\n+-----------------+\n1 row in set (10.93 sec)\n```\n\n##### 有索引\n1. serial_id上有索引，可以遍历`uniq_serial_id_source_index`\n2. 但由于InnoDB必须返回serial_id字段，因此不会遍历**逻辑结果等价**的更优选择`idx_create_time`\n    - 如果选择`idx_create_time`，并且返回serial_id字段，这意味着必须**回表**\n\n```sql\nmysql> EXPLAIN SELECT COUNT(serial_id) FROM prop_action_batch_reward;\n+----+-------------+--------------------------+-------+---------------+-----------------------------+---------+------+----------+-------------+\n| id | select_type | table                    | type  | possible_keys | key                         | key_len | ref  | rows     | Extra       |\n+----+-------------+--------------------------+-------+---------------+-----------------------------+---------+------+----------+-------------+\n|  1 | SIMPLE      | prop_action_batch_reward | index | NULL          | uniq_serial_id_source_index | 15      | NULL | 16434890 | Using index |\n+----+-------------+--------------------------+-------+---------------+-----------------------------+---------+------+----------+-------------+\n\nmysql> SELECT COUNT(serial_id) FROM prop_action_batch_reward;\n+------------------+\n| count(serial_id) |\n+------------------+\n|         17705069 |\n+------------------+\n1 row in set (5.04 sec)\n```\n\n#### count(主键ID)\n优化器选择了**最优**的索引`idx_create_time`来遍历，而非聚簇索引\n```sql\nmysql> EXPLAIN SELECT COUNT(id) FROM prop_action_batch_reward;\n+----+-------------+--------------------------+-------+---------------+-----------------+---------+------+----------+-------------+\n| id | select_type | table                    | type  | possible_keys | key             | key_len | ref  | rows     | Extra       |\n+----+-------------+--------------------------+-------+---------------+-----------------+---------+------+----------+-------------+\n|  1 | SIMPLE      | prop_action_batch_reward | index | NULL          | idx_create_time | 5       | NULL | 16436797 | Using index |\n+----+-------------+--------------------------+-------+---------------+-----------------+---------+------+----------+-------------+\n\nmysql> SELECT COUNT(id) FROM prop_action_batch_reward;\n+-----------+\n| count(id) |\n+-----------+\n|  17705383 |\n+-----------+\n1 row in set (4.54 sec)\n```\n\n#### count(1)\n```sql\nmysql> EXPLAIN SELECT COUNT(1) FROM prop_action_batch_reward;\n+----+-------------+--------------------------+-------+---------------+-----------------+---------+------+----------+-------------+\n| id | select_type | table                    | type  | possible_keys | key             | key_len | ref  | rows     | Extra       |\n+----+-------------+--------------------------+-------+---------------+-----------------+---------+------+----------+-------------+\n|  1 | SIMPLE      | prop_action_batch_reward | index | NULL          | idx_create_time | 5       | NULL | 16437220 | Using index |\n+----+-------------+--------------------------+-------+---------------+-----------------+---------+------+----------+-------------+\n\nmysql> SELECT COUNT(1) FROM prop_action_batch_reward;\n+----------+\n| count(1) |\n+----------+\n| 17705808 |\n+----------+\n1 row in set (4.12 sec)\n```\n\n#### count(\\*)\n```sql\nmysql> EXPLAIN SELECT COUNT(*) FROM prop_action_batch_reward;\n+----+-------------+--------------------------+-------+---------------+-----------------+---------+------+----------+-------------+\n| id | select_type | table                    | type  | possible_keys | key             | key_len | ref  | rows     | Extra       |\n+----+-------------+--------------------------+-------+---------------+-----------------+---------+------+----------+-------------+\n|  1 | SIMPLE      | prop_action_batch_reward | index | NULL          | idx_create_time | 5       | NULL | 16437518 | Using index |\n+----+-------------+--------------------------+-------+---------------+-----------------+---------+------+----------+-------------+\n\nmysql> SELECT COUNT(*) FROM prop_action_batch_reward;\n+----------+\n| count(*) |\n+----------+\n| 17706074 |\n+----------+\n1 row in set (4.06 sec)\n```\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 空间回收","url":"%2F2019%2F02%2F01%2Fmysql-reclaim-space%2F","content":"\n## InnoDB的物理存储\n1. InnoDB表的组成：**表结构（frm）**+**数据（ibd）**\n    - MySQL 8.0开始，允许将**表结构定义**（**占用空间很小**）放在**系统数据表**中\n2. 控制参数`innodb_file_per_table`\n    - ON：每个InnoDB表数据存储在一个以**.ibd**为后缀的文件中，**推荐**\n        - 更容易管理，`DROP TABLE`会直接删除这个文件\n    - OFF：InnoDB表数据存储在**共享表空间**\n        - `DROP TABLE`，空间也是不会回收的\n\n<!-- more -->\n\n```sql\nmysql> SHOW VARIABLES LIKE '%innodb_file_per_table%';\n+-----------------------+-------+\n| Variable_name         | Value |\n+-----------------------+-------+\n| innodb_file_per_table | ON    |\n+-----------------------+-------+\n```\n\n## 文件空洞\n空洞：**可以被复用但没有被使用的空间**，经过大量**增删改**的表，都会存在空洞\n\n### 删除\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-reclaim-index.png\" width=500/>\n\n1. 如果删掉`R4`，InnoDB只会将`R4`**标记为删除**，如果再插入**300~600**的记录时，可能会**复用**这个位置，但磁盘文件不会缩小\n    - **记录的复用**，仅限于**符合范围**条件的数据\n2. 如果删除了**一个数据页上的所有记录**，那么**整个数据页**都可以被**复用**的\n    - 当**整个页**从B+树里摘除后，可以被复用到**任何位置**\n    - 如果将`page A`上的所有记录删除后，`page A`会被**标记为可复用**\n        - 当插入ID=50的记录时，需要**申请新页**时`page A`可以被复用\n3. 如果**相邻**的两个数据页**利用率**都很小\n    - 系统会把这两个数据页上的数据**合并**到其中一个页上，另一个数据页就会被标记为**可复用**\n4. 如果通过`DELETE`命令**删除整个表**，那么**所有的数据页**都会被**标记为可复用**，但磁盘上的文件同样不会变小\n5. **`TRUNCATE` = `DROP` + `CREATE`**\n\n### 插入\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-reclaim-insert.png\" width=500/>\n\n1. 如果数据是**随机插入**的，就有可能造成**索引的数据页分裂**\n2. `page A`已满，如果再插入ID=550的数据，就必须申请一个新的页面`page B`来保存数据，导致**页分裂**，留下了空洞\n\n### 更新\n更新**索引**上的值，等同于**先逻辑删除旧值后再插入新值**，同样也会造成**空洞**\n\n## 重建表\n\n### 逻辑过程\n1. 新建一个与表A**结构相同**的表B\n2. 按照**主键递增**的顺序，把表A中的数据一行一行读出，然后再插入表B\n    - 表B的主键索引更**紧凑**，数据页的**利用率**也更高\n3. 表B作为**临时表**，数据从表A导入到表B，然后用表B替换A\n\n### 重建命令\n```sql\nALTER TABLE A ENGINE=InnoDB;\n```\n`ALTER TABLE`默认会**提交前面的事务**\n\n#### Before MySQL 5.5\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-reclaim-alter-before-5_5.png\" width=500/>\n\n1. 与上述的逻辑过程类似，MySQL**自动完成**转存数据，交换表名和删除旧表等操作\n2. 时间消耗最多的是往**临时表**（**Server层**）插入数据的过程，在这个过程中，如果**新数据**要写入表A，就会造成**数据丢失**\n3. 因此整个DDL过程中，表A是不能执行DML的，即不是**Online**的\n4. MySQL 5.6引入**Online DDL**\n\n#### Since MySQL 5.6\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-reclaim-alter-online-ddl.png\" width=500/>\n\n1. 建立一个**临时文件**（**InnoDB内部**），扫描表A主键的所有数据页\n2. 用数据页中表A的记录生成B+树，存储到临时文件\n3. state 2（**日志**）：生成临时文件的过程中，将所有对A的**操作**记录在一个**日志文件**（**row log**）中\n4. state 3（**重放**）：临时文件生成后，将日志文件的操作**应用到临时文件**，得到一个**逻辑数据**上与表A相同的数据文件\n5. 用最新的临时文件替换表A的数据文件\n\n##### MDL锁\n1. `ALTER`语句在**启动**时需要获取**MDL写锁**，但会在**真正拷贝数据之前退化为MDL读锁**\n    - MDL读锁**不会阻塞**其他线程对这个表的**DML**，同时又能**阻塞**其他线程对这个表的**DDL**\n2. 对一个大表来说，`Online DDL`最耗时的过程是**拷贝数据到临时表**的过程，期间是可以接受DML\n    - 相对于整个DDL过程来说，**锁的时间非常短**，对**业务**来说，可以认为是`Online`\n\n### 性能消耗\n1. 重建表会**扫描原表数据**和**构建临时文件（或临时表）**\n2. 对于大表来说，重建表会**非常消耗IO和CPU资源**\n3. 推荐工具：`gh-ost`\n\n## Online + Inplace\n1. `tmp_table`是一个**临时表**，在**Server**层创建的\n2. `tmp_file`是**临时文件**，在**InnoDB**内部创建的，**整个DDL过程都在InnoDB内部完成**\n    - 对于**Server**层来说，并没有把数据挪动到**临时表**，是个原地操作（**Inplace**）\n3. **DDL过程如果是Online的，那一定是Inplace的，反之不成立**\n    - `ALTER TABLE t ADD FULLTEXT(field_name);`是**Inplace**的，但会阻塞DML（**非Online**）\n\n```sql\nALTER TABLE A ENGINE=InnoDB;\n等同于\nmysql> ALTER TABLE t ENGINE=InnoDB, ALGORITHM=INPLACE;\nQuery OK, 0 rows affected (0.68 sec)\nRecords: 0  Duplicates: 0  Warnings: 0\n```\n与**Inplace**对应的是**Copy**，强制拷贝表到**Server**层\n```sql\nmysql> ALTER TABLE t ENGINE=InnoDB, ALGORITHM=COPY;\nQuery OK, 100000 rows affected (1.46 sec)\nRecords: 100000  Duplicates: 0  Warnings: 0\n```\n\n## ALTER + ANALYZE + OPTIMIZE\n1. `ALTER TABLE t ENGINE=InnoDB`：**重建表**\n2. `ANALYZE TABLE t`：触发**表索引信息的重新采样统计**\n3. `OPTIMIZE TABLE t`：`ALTER` + `ANALYZE`\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 字符串索引","url":"%2F2019%2F01%2F31%2Fmysql-index-string%2F","content":"\n## 场景\n\n### 建表\n```sql\nCREATE TABLE SUser(\n    id BIGINT UNSIGNED PRIMARY KEY,\n    name VARCHAR(64),\n    email VARCHAR(64)\n) ENGINE=InnoDB;\n```\n\n<!-- more -->\n\n### 查询\n```sql\nSELECT id,name,email FROM SUser WHERE email='zhangssxyz@xxx.com';\n```\n\n## 创建索引\n```sql\nALTER TABLE SUser ADD INDEX index1(email);\nALTER TABLE SUser ADD INDEX index2(email(6));\n```\n\n### index1\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-index-string-all.jpg\" width=500/>\n\n1. 索引长度：**整个字符串**\n2. 从index1索引树找到第一个满足索引值为zhangssxyz@xxx.com的记录，取得主键为ID2\n    - 到**聚簇索引**上查找值为ID2的行，判断email的值是否正确（**Server层行为**），将该行记录加入结果集\n3. 获取index1上的下一条记录，发现不满足email=zhangssxyz@xxx.com，循环结束\n4. 整个过程，只需要**回表**1次，系统认为只扫描了1行\n\n### index2\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-index-string-prefix.jpg\" width=500/>\n\n1. 索引长度：_**前6个字节**_\n2. 索引占用的**空间更小**，增加额外的记录**扫描次数**，（且不支持**覆盖索引**，见后面）\n3. 从index2索引树找到第一个满足索引值为`zhangs`的记录，取得主键为ID1\n    - 到聚簇索引上查找值为ID1的行，email!=zhangssxyz@xxx.com（**Server层行为**），记录**丢弃**\n4. 获取index2上的下一条记录，发现仍然是`zhangs`，取得主键为ID2\n    - 到聚簇索引上查找值为ID2的行，email==zhangssxyz@xxx.com，加入结果集\n5. 重复上面的步骤，直到index2上取得的值不为`zhangs`为止\n6. 整个过程，需要**回表**4次，系统认为扫描了4行\n7. 假设index2为`email(7)`，满足前缀`zhangss`只有一个，只需要回表一次\n    - 使用前缀索引，如果能**定义好长度**，即能**节省空间**，又**不会增加太多的查询成本**\n\n## 前缀索引的长度\n原则：**区分度**。使用前缀索引一般都会**损失区分度**，预设一个**可接受的损失比例**，在该损失比例内，寻找**最短**前缀长度\n```\nSELECT\n    COUNT(DISTINCT email) AS L,\n    COUNT(DISTINCT LEFT(email,4)）AS L4,\n    COUNT(DISTINCT LEFT(email,5)）AS L5,\n    COUNT(DISTINCT LEFT(email,6)）AS L6,\n    COUNT(DISTINCT LEFT(email,7)）AS L7\nFROM SUser;\n```\n\n## 前缀索引与覆盖索引\n```sql\nSELECT id,email FROM SUser WHERE email='zhangssxyz@xxx.com';\n```\n1. 如果使用**index1**，可以利用**覆盖索引**，**不需要回表**\n2. 如果使用**index2**，就**必须回表**，获得整行记录后再去判断email字段的值\n    - 即使index2为`email(18)`（包含了所有信息），还是需要回表\n    - 因为系统**不确定前缀索引的定义是否截断了完整信息**\n    - 因此，**前缀索引是用不上覆盖索引对查询性能的优化**\n\n## 其他手段\n场景：前缀的区分度非常差，例如居民身份证（前6位是地址码）\n\n### 倒序存储\n```sql\nSELECT field_list FROM t WHERE id_card = REVERSE('input_id_card_string');\n```\n\n### 增加hash字段\n```sql\nALTER TABLE t ADD id_card_crc INT UNSIGNED, ADD INDEX(id_card_crc);\nSELECT field_list FROM t WHERE id_card_crc=CRC32('input_id_card_string') AND id_card='input_id_card_string';\n```\n1. 每次插入新纪录的时候，都需要使用`CRC32()`函数得到校验码\n2. 由于校验码可能会**冲突**，因此查询语句的条件需要加上id_card（**精确匹配**）\n3. 索引的长度变为了**4个字节**，比直接用身份证作为索引所占用的空间小很多\n\n### 异同点\n1. 都**不支持范围查询**，只支持**等值查询**\n2. 空间占用\n    - 倒序存储：N个字节的索引\n    - 增加hash字段：字段+索引\n3. CPU\n    - 倒序存储：每次读写都需要额外调用一次`REVERSE`函数，开销比`CRC32`函数略小\n    - 增加hash字段：每次读写都需要额外调用一次`CRC32`函数\n4. 查询效率\n    - 增加**hash**字段方式的查询性能会**更加稳定**一些\n        - CRC32虽然会有一定的冲突概率，但概率非常低，可以认为**平均扫描行数接近1**\n    - 倒序存储一般会用到**前缀索引**，这会增加**扫描行数**（**无法利用覆盖索引，必须回表**）\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- flush","url":"%2F2019%2F01%2F31%2Fmysql-flush%2F","content":"\n## 脏页 + 干净页\n1. 脏页：内存数据页与磁盘数据页内容**不一致**\n2. 干净页：内存数据页与磁盘数据页内容**一致**\n3. flush：**将内存中的脏页写入磁盘**\n4. _**flush -- 刷脏页；purge -- 清undolog；merge -- 应用change buffer**_\n\n<!-- more -->\n\n## flush过程\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-flush-procedure.jpeg\" width=400/>\n\n\n## 触发flush\n\n### redolog写满\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-flush-redolog.jpeg\" width=400/>\n\n1. 当InnoDB的redolog写满，系统会**停止所有的更新操作**，推进`checkpoint`\n2. 把`checkpoint`从CP推进到CP'，需要将两点之间的日志（绿色），所**对应的所有脏页**都flush到磁盘上\n3. 然后`write pos`到CP'之间（红色+绿色）可以再写入redolog\n\n#### 性能影响\nInnoDB应该**尽量避免**，此时所有更新都会被**堵住**，更新数（**写性能**）跌为0\n\n### 内存不足\n1. 当需要新的内存页，而内存不够用时，就需要**淘汰**一些内存数据页（**LRU**）\n2. 如果淘汰的是**脏页**，就需要**先将脏页flush到磁盘**\n    - 该过程不会动redolog，因为redolog在重放的时候\n    - 如果一个数据页已经flush过，会识别出来并跳过\n\n#### 性能影响\n1. 这种情况是**常态**，InnoDB使用`buffer pool`管理内存\n2. `buffer pool`中内存页有3种状态\n    - 没有被使用\n    - 已被使用且为**干净页**\n    - 已被使用且为**脏页**\n3. InnoDB的策略是**尽量使用内存**，对于一个**长期运行**的库来说，未被使用的内存页很少\n4. 当要读入的数据页没有在内存中，必须到`buffer pool`中申请一个内存页，采用**LRU**策略淘汰内存页\n    - 如果淘汰的是**干净页**，**直接释放并复用**\n    - 如果淘汰的是**脏页**，必须先将脏页**flush**到磁盘上，变成干净页后才能复用\n4. 如果一个查询**要淘汰的脏页太多**，会导致查询的**响应时间明显变长**\n\n### 其他情况\n1. **系统空闲**\n2. **正常关闭**\n\n## 脏页控制策略\n\n### 主机IO能力\n1. 需要配置主机的**IO能力**，InnoDB才知道**全力刷脏页**时，可以刷多快\n2. 控制参数`innodb_io_capacity`，建议设置为磁盘的`IOPS`（可以通过`fio`测试）\n3. 如果该值设置**过小**，InnoDB会认为主机的IO能力很差，从而**控制刷脏页的速度**，甚至低于脏页的生成速度\n    - 造成**脏页累积**，**影响查询和更新性能**\n\n```sql\nmysql> SHOW VARIABLES LIKE '%innodb_io_capacity%';\n+------------------------+-------+\n| Variable_name          | Value |\n+------------------------+-------+\n| innodb_io_capacity     | 2000  |\n| innodb_io_capacity_max | 4000  |\n+------------------------+-------+\n```\n```\n$ fio -filename=fio.txt -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=2048M -numjobs=10 -runtime=10 -group_reporting -name=mytest\n...\nJobs: 10 (f=10): [m(10)][90.9%][r=155MiB/s,w=155MiB/s][r=9907,w=9896 IOPS][eta 00m:01s]\nmytest: (groupid=0, jobs=10): err= 0: pid=4867: Thu Jan 31 11:26:20 2019\n   read: IOPS=11.2k, BW=175MiB/s (184MB/s)(1754MiB/10002msec)\n   ...\n   bw (  KiB/s): min=14285, max=24256, per=10.01%, avg=17978.35, stdev=2020.97, samples=190\n   iops        : min=  892, max= 1516, avg=1123.32, stdev=126.33, samples=190\n  write: IOPS=11.2k, BW=176MiB/s (184MB/s)(1756MiB/10002msec)\n    ...\n   bw (  KiB/s): min=14211, max=24480, per=10.01%, avg=17990.18, stdev=2278.29, samples=190\n   iops        : min=  888, max= 1530, avg=1124.08, stdev=142.44, samples=190\n\nRun status group 0 (all jobs):\n   READ: bw=175MiB/s (184MB/s), 175MiB/s-175MiB/s (184MB/s-184MB/s), io=1754MiB (1839MB), run=10002-10002msec\n  WRITE: bw=176MiB/s (184MB/s), 176MiB/s-176MiB/s (184MB/s-184MB/s), io=1756MiB (1841MB), run=10002-10002msec\n```\n\n### flush speed\n1. 刷脏页速度**慢**的后果\n    - **内存脏页太多**\n    - **redolog写满**\n2. 因素：_**脏页比例**_ + _**redolog写盘速度**_\n3. 控制参数`innodb_max_dirty_pages_pct`：脏页比例上限\n4. `F1(M)`：InnoDB会根据**当前的脏页比例M**，计算出一个`[0,100]`的值，伪代码如下所示\n5. `F2(N)`：**N越大，F2越大**\n    - InnoDB每次写入的日志都有一个序号\n    - N：`write pos`对应的序号与`checkpoint`对应的序号之间的**差值**\n6. 算法\n    - **`R = max(F1(M) , F2(N))`**\n    - **`flush speed = innodb_io_capacity * R%`**\n\n```sql\nmysql> SHOW VARIABLES LIKE '%innodb_max_dirty_pages_pct%';\n+--------------------------------+-------+\n| Variable_name                  | Value |\n+--------------------------------+-------+\n| innodb_max_dirty_pages_pct     | 75    |\n| innodb_max_dirty_pages_pct_lwm | 0     |\n+--------------------------------+-------+\n```\n```c\nF1(M){\n    if M>=innodb_max_dirty_pages_pct then\n        return 100;\n    return M/innodb_max_dirty_pages_pct * 100;\n}\n```\n\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-flush-speed.png\" width=400/>\n\n\n### 脏页比例\n1. 平时要多关注**脏页比例**：`Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total`\n2. 不要经常接近`innodb_max_dirty_pages_pct`\n\n```sql\nmysql> SHOW GLOBAL STATUS LIKE '%Innodb_buffer_pool_pages_%';\n+----------------------------------+------------+\n| Variable_name                    | Value      |\n+----------------------------------+------------+\n| Innodb_buffer_pool_pages_data    | 633395     |\n| Innodb_buffer_pool_pages_dirty   | 99         |\n| Innodb_buffer_pool_pages_flushed | 1286891803 |\n| Innodb_buffer_pool_pages_free    | 8191       |\n| Innodb_buffer_pool_pages_misc    | 13774      |\n| Innodb_buffer_pool_pages_total   | 655360     |\n+----------------------------------+------------+\n\n# 1. Innodb_buffer_pool_pages_data\n#   The number of pages in the InnoDB buffer pool containing data. The number includes both dirty and clean pages.\n# 2. Innodb_buffer_pool_pages_dirty\n#   The current number of dirty pages in the InnoDB buffer pool.\n# 3. Innodb_buffer_pool_pages_flushed\n#   The number of requests to flush pages from the InnoDB buffer pool.\n# 4. Innodb_buffer_pool_pages_free\n#   The number of free pages in the InnoDB buffer pool.\n# 5. Innodb_buffer_pool_pages_misc\n#   The number of pages in the InnoDB buffer pool that are busy because they have been allocated for administrative overhead, such as row locks or the adaptive hash index.\n#   Innodb_buffer_pool_pages_misc = Innodb_buffer_pool_pages_total − Innodb_buffer_pool_pages_free − Innodb_buffer_pool_pages_data.\n#   13774 = 655360 - 8191 - 633395\n# 6. Innodb_buffer_pool_pages_total\n#   The total size of the InnoDB buffer pool.\n\n# Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total = 0.015%\n```\n\n### flush neighbor\n\n```sql\nmysql> SHOW VARIABLES LIKE '%innodb_flush_neighbors%';\n+------------------------+-------+\n| Variable_name          | Value |\n+------------------------+-------+\n| innodb_flush_neighbors | 0     |\n+------------------------+-------+\n```\n1. 在准备刷一个脏页的时候，如果这个数据页的**邻居**恰好也是脏页，也会一起flush，可能会**蔓延**\n2. 在**HDD**（**IOPS为几百**）时代，能**减少很多随机IO**\n3. 对于**SDD**，IOPS不再是瓶颈，可以将`innodb_flush_neighbors`设置为0，只刷新自己，MySQL 8.0默认\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 索引选择","url":"%2F2019%2F01%2F30%2Fmysql-index-select%2F","content":"\n## 优化器\n1. 优化器的重要职责：_**选择索引**_\n    - 目的是寻找**最优**的执行方案\n    - 大多数时候，优化器都能找到正确的索引\n2. 在数据库里面，决定**执行代价**的因素\n    - _**扫描行数**_ -- 本文关注点\n    - 是否使用**临时表**\n    - 是否**排序**\n3. MySQL在真正开始执行语句之前，并不能精确地知道满足条件的记录有多少\n    - 只能根据**统计信息**（**索引的区分度**）来**估算**记录数\n    - **基数越大（不同的值越多），索引的区分度越好**\n4. 统计信息中索引的基数是**不准确**的\n\n<!-- more -->\n\n```sql\nmysql> SHOW INDEX FROM t;\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+\n| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible |\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+\n| t     |          0 | PRIMARY  |            1 | id          | A         |      100256 |     NULL |   NULL |      | BTREE      |         |               | YES     |\n| t     |          1 | a        |            1 | a           | A         |      100512 |     NULL |   NULL | YES  | BTREE      |         |               | YES     |\n| t     |          1 | b        |            1 | b           | A         |      100512 |     NULL |   NULL | YES  | BTREE      |         |               | YES     |\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+\n```\n\n### 基数统计\n1. 方法：_**采样统计**_\n2. 基数：InnoDB默认选择**N**个数据页，统计这些页上的不同值，得到一个**平均值**，然后再乘以**索引的页面数**\n3. 当数据表**变更的数据行**超过**1/M**时，会**自动触发**索引的采样统计\n4. 索引统计信息的存储，参数控制`innodb_stats_persistent`\n    - ON：持久化存储统计信息，N=20，M=10\n    - OFF：统计信息只会存储在内存中，N=8，M=16\n5. 手动触发索引的采样统计：_**`ANALYZE TABLE t;`**_\n    - 使用场景：当explain预估的rows与实际情况差距较大时\n\n```sql\nmysql> SHOW VARIABLES LIKE '%innodb_stats_persistent%';\n+--------------------------------------+-------+\n| Variable_name                        | Value |\n+--------------------------------------+-------+\n| innodb_stats_persistent              | ON    |\n| innodb_stats_persistent_sample_pages | 20    |\n+--------------------------------------+-------+\n```\n\n## 表初始化\n\n### 建表\n```sql\nCREATE TABLE `t` (\n    `id` INT(11) NOT NULL,\n    `a` INT(11) DEFAULT NULL,\n    `b` INT(11) DEFAULT NULL,\n    PRIMARY KEY (`id`),\n    KEY `a` (`a`),\n    KEY `b` (`b`)\n) ENGINE=InnoDB;\n```\n\n### 表初始化\n```sql\n# 存储过程\nDELIMITER //\nCREATE PROCEDURE idata()\nBEGIN\n    DECLARE i INT;\n    SET i=1;\n    WHILE (i <= 100000) DO\n        INSERT INTO t VALUES (i, i, i);\n    SET i=i+1;\n    END WHILE;\nEND//\nDELIMITER ;\n\n# 调用存储过程\nCALL idata();\n```\n\n### 索引树\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-index-select.png\" width=600/>\n\n\n## 查询\n\n### 常规查询\n选择索引`a`，预估的扫描行数为`10001`\n```sql\nmysql> EXPLAIN SELECT * FROM t WHERE a BETWEEN 10000 AND 20000;\n+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+-----------------------+\n| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows  | filtered | Extra                 |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+-----------------------+\n|  1 | SIMPLE      | t     | NULL       | range | a             | a    | 5       | NULL | 10001 |   100.00 | Using index condition |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+-----------------------+\n```\n\n### 索引选择异常\n```sql\n# 返回空集合\nmysql> EXPLAIN SELECT * FROM t WHERE (a BETWEEN 1 AND 1000) AND (b BETWEEN 50000 AND 100000) ORDER BY b LIMIT 1;\n+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+------------------------------------+\n| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows  | filtered | Extra                              |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+------------------------------------+\n|  1 | SIMPLE      | t     | NULL       | range | a,b           | b    | 5       | NULL | 50128 |     1.00 | Using index condition; Using where |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+-------+----------+------------------------------------+\n\nmysql> SELECT * FROM t WHERE (a BETWEEN 1 AND 1000) AND (b BETWEEN 50000 AND 100000) ORDER BY b LIMIT 1;\nEmpty set (0.07 sec)\n\n# Time: 2019-01-30T11:32:31.335272Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 0.046896  Lock_time: 0.000141 Rows_sent: 0  Rows_examined: 50001\nSET timestamp=1548847951;\nSELECT * FROM t WHERE (a BETWEEN 1 AND 1000) AND (b BETWEEN 50000 AND 100000) ORDER BY b LIMIT 1;\n```\n1. 如果使用索引`a`进行查询\n    - 扫描索引`a`的前1000个值，取得对应的id，再到**聚簇索引**上查出每一行，然后根据字段b来过滤，需要扫描1000行\n2. 如果使用索引`b`进行查询\n    - 扫描索引`b`的最后50001个值，与上面的过程类似，需要扫描50001行\n    - 优化器的异常选择，预估的扫描行数依然**不准确**\n    - 之前优化器选择索引`b`，是认为使用索引b能够**避免排序**，所以即使扫描行数多，也认为代价较小\n        - `Extra`没有`Using filesort`\n\n### force index\n代码不优雅\n```sql\nmysql> EXPLAIN SELECT * FROM t FORCE INDEX(a) WHERE (a BETWEEN 1 AND 1000) AND (b BETWEEN 50000 AND 100000) ORDER BY b LIMIT 1;\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+----------------------------------------------------+\n| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra                                              |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+----------------------------------------------------+\n|  1 | SIMPLE      | t     | NULL       | range | a             | a    | 5       | NULL | 1000 |    11.11 | Using index condition; Using where; Using filesort |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+----------------------------------------------------+\n\nmysql> SELECT * FROM t FORCE INDEX(a) WHERE (a BETWEEN 1 AND 1000) AND (b BETWEEN 50000 AND 100000) ORDER BY b LIMIT 1;\nEmpty set (0.00 sec)\n\n# Time: 2019-01-30T11:32:45.938128Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 0.001304  Lock_time: 0.000148 Rows_sent: 0  Rows_examined: 1000\nSET timestamp=1548847965;\nSELECT * FROM t FORCE INDEX(a) WHERE (a BETWEEN 1 AND 1000) AND (b BETWEEN 50000 AND 100000) ORDER BY b LIMIT 1;\n```\n\n### order by b,a\n不通用\n```sql\nmysql> EXPLAIN SELECT * FROM t WHERE (a BETWEEN 1 AND 1000) AND (b BETWEEN 50000 AND 100000) ORDER BY b,a LIMIT 1;\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+----------------------------------------------------+\n| id | select_type | table | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra                                              |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+----------------------------------------------------+\n|  1 | SIMPLE      | t     | NULL       | range | a,b           | a    | 5       | NULL | 1000 |    50.00 | Using index condition; Using where; Using filesort |\n+----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+----------------------------------------------------+\n\nmysql> SELECT * FROM t WHERE (a BETWEEN 1 AND 1000) AND (b BETWEEN 50000 AND 100000) ORDER BY b,a LIMIT 1;\nEmpty set (0.01 sec)\n\n# Time: 2019-01-30T13:53:18.233163Z\n# User@Host: root[root] @ localhost []  Id:     8\n# Query_time: 0.000609  Lock_time: 0.000191 Rows_sent: 1  Rows_examined: 0\nSET timestamp=1548856398;\nEXPLAIN SELECT * FROM t WHERE (a BETWEEN 1 AND 1000) AND (b BETWEEN 50000 AND 100000) ORDER BY b,a LIMIT 1;\n```\n1. `order by b,a`要求按照b,a排序，那**扫描行数**成为了影响优化器**决策的主要条件**，此时会选择只需扫描1000行的索引`a`\n2. 但这并非通用优化手段，只是恰好`order by b limit 1`和`order by b,a limit 1`都是返回b中最小的一行，语义一致而已\n\n### limit 100\n不通用\n```sql\nmysql> EXPLAIN SELECT * FROM (SELECT * FROM t WHERE (a BETWEEN 1 AND 1000) AND (b BETWEEN 50000 AND 100000) ORDER BY b LIMIT 100) alias LIMIT 1;\n+----+-------------+------------+------------+-------+---------------+------+---------+------+------+----------+----------------------------------------------------+\n| id | select_type | table      | partitions | type  | possible_keys | key  | key_len | ref  | rows | filtered | Extra                                              |\n+----+-------------+------------+------------+-------+---------------+------+---------+------+------+----------+----------------------------------------------------+\n|  1 | PRIMARY     | <derived2> | NULL       | ALL   | NULL          | NULL | NULL    | NULL |  100 |   100.00 | NULL                                               |\n|  2 | DERIVED     | t          | NULL       | range | a,b           | a    | 5       | NULL | 1000 |    50.00 | Using index condition; Using where; Using filesort |\n+----+-------------+------------+------------+-------+---------------+------+---------+------+------+----------+----------------------------------------------------+\n```\n`limit 100`：根据数据特征来**诱导**优化器，让优化器意识到使用索引`b`的**代价很高**，同样不具有通用性\n\n### 其他办法\n1. **新建一个更合适的索引**\n2. **删除误用的索引**\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 普通索引与唯一索引","url":"%2F2019%2F01%2F29%2Fmysql-index-unique-common%2F","content":"\n## 场景\n1. 维护一个市民系统，有一个字段为身份证号\n2. 业务代码能保证不会写入两个重复的身份证号（如果业务无法保证，可以依赖数据库的唯一索引来进行约束）\n3. 常用SQL查询语句：`SELECT name FROM CUser WHERE id_card = 'XXX'`\n4. 建立索引\n    - 身份证号比较大，不建议设置为主键\n    - 从**性能**角度出发，选择**普通索引**还是**唯一索引**？\n\n<!-- more -->\n\n假设字段k上的值都不重复\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-index-bplustree.png\" width=400/>\n\n\n## 查询过程\n1. 查询语句：`SELECT id FROM T WHERE k=5`\n2. 查询过程\n    - 通过B+树从**树根**开始，**按层搜索到叶子节点**，即上图中右下角的数据页\n    - 在**数据页内部**通过**二分法**来定位具体的记录\n3. 针对**普通索引**\n    - 查找满足条件的第一个记录`(5,500)`，然后查找下一个记录，直到找到第一个不满足`k=5`的记录\n4. 针对**唯一索引**\n    - 由于索引定义了**唯一性**，查找到第一个满足条件的记录后，就会停止继续查找\n\n### 性能差异\n1. 性能差异：**微乎其微**\n2. InnoDB的数据是按照**数据页**为单位进行读写的，默认为16KB\n3. 当需要读取一条记录时，并不是将这个记录本身从磁盘读出来，而是以数据页为单位进行读取的\n4. 当找到k=5的记录时，它所在的数据页都已经在**内存**里了\n5. 对于**普通索引**而言，只需要多一次**指针寻找**和多一次**计算** -- CPU消耗很低\n    - 如果k=5这个记录恰好是所在数据页的最后一个记录，那么如果要取下一个记录，就需要读取**下一个数据页**\n    - **概率很低**：对于**整型字段**索引，一个数据页（16KB，compact格式）可以存放大概745个值\n\n## change buffer\n1. 当需要**更新一个数据页**时，如果数据页**在内存中**就**直接更新**\n2. 如果这个数据页**不在内存中**，在不影响**数据一致性**的前提下\n    - InnoDB会将这些**更新操作**缓存在change buffer\n    - **不需要从磁盘读入这个数据页**（**随机读**）\n    - 在**下次查询**需要访问这个数据页的时候，**将数据页读入内存**\n        - 然后执行change buffer中与这个数据页有关的操作（merge）\n3. change buffer是可以**持久化**的数据，在内存中有拷贝，也会被写入到磁盘上\n4. 将更新操作先记录在channge buffer，**减少随机读磁盘**，提升语句的执行速度\n5. 另外数据页读入内存需要占用buffer pool，使用channge buffer能避免占用内存，**提高内存利用率**\n6. change buffer用到是buffer pool里的内存，不能无限增大，控制参数`innodb_change_buffer_max_size`\n\n```sql\n# 默认25，最大50\nmysql> SHOW VARIABLES LIKE '%innodb_change_buffer_max_size%';\n+-------------------------------+-------+\n| Variable_name                 | Value |\n+-------------------------------+-------+\n| innodb_change_buffer_max_size | 25    |\n+-------------------------------+-------+\n```\n\n### merge\n1. merge：将change buffer中的操作**应用**到原数据页\n2. merge的执行过程\n    - 从磁盘读入数据页到内存（老版本的数据页）\n    - 从change buffer里找出这个数据页的change buffer记录（可能多个）\n        - 然后**依次执行**，得到**新版本的数据页**\n    - 写入redolog，包含内容：**数据页的表更**+**change buffer的变更**\n3. merge执行完后，内存中的数据页和change buffer所对应的磁盘页都还没修改，属于**脏页**\n    - 通过其他机制，脏页会被刷新到对应的物理磁盘页\n4. 触发时机\n    - **访问这个数据页**\n    - 系统后台线程**定期merge**\n    - 数据库**正常关闭**\n\n### 使用条件\n1. 对于**唯一索引**来说，所有的更新操作需要先判断这个操作**是否违反唯一性约束**\n2. _**唯一索引的更新无法使用change buffer，只有普通索引可以使用change buffer**_\n    - **主键也是无法使用change buffer的**\n    - 例如要插入`(4,400)`，必须先判断表中是否存在k=4的记录，这个判断的前提是**将数据页读入内存**\n    - 既然数据页已经读入到了内存，直接更新内存中的数据页就好，无需再写change buffer\n\n### 使用场景\n1. 一个数据页在**merge之前**，change buffer**记录关于这个数据页的变更越多**，**收益越大**\n2. 对于**写多读少**的业务，页面在写完后马上被访问的概率极低，此时**change buffer的使用效果最好**\n    - 例如账单类、日志类的系统\n3. 如果一个业务的更新模式为：**写入之后马上会做查询**\n    - 虽然更新操作被记录到change buffer，但之后马上查询，又会**从磁盘读取**数据页，触发merge过程\n    - **没有减少随机读，反而增加了维护change buffer的代价**\n\n## 更新过程\n\n### 插入(4,400)\n\n#### 目标页在内存中\n1. 对于**唯一索引**来说，找到3~5之间的位置，**判断没有冲突**，插入这个值\n2. 对于**普通索引**来说，找到3~5之间的位置，插入这个值\n3. 性能差异：**微乎其微**\n\n#### 目标页不在内存中\n1. 对于**唯一索引**来说，需要**将数据页读入内存**，**判断没有冲突**，插入这个值\n    - **磁盘随机读**，成本很高\n2. 对于**普通索引**来说，**将更新操作记录在change buffer**即可\n    - **减少了磁盘随机读**，性能提升明显\n\n## 索引选择\n1. 普通索引与唯一索引，在查询性能上并没有太大差异，主要考虑的是**更新性能**，**推荐选择普通索引**\n2. 建议**关闭change buffer**的场景\n    - _**如果所有的更新后面，都伴随着对这个记录的查询**_\n    - 控制参数`innodb_change_buffering`\n\n```sql\nmysql> SHOW VARIABLES LIKE '%innodb_change_buffering%';\n+-------------------------+-------+\n| Variable_name           | Value |\n+-------------------------+-------+\n| innodb_change_buffering | all   |\n+-------------------------+-------+\n\n# Valid Values (>= 5.5.4)\nnone / inserts / deletes / changes / purges / all\n\n# Valid Values (<= 5.5.3)\nnone / inserts\n\n# change buffer的前身是insert buffer，只能对insert操作进行优化\n```\n\n## change buffer + redolog\n\n### 更新过程\n当前k树的状态：找到对应的位置后，k1所在的数据页**Page 1在内存中**，k2所在的数据页**Page 2不在内存中**\n```sql\nINSERT INTO t(id,k) VALUES (id1,k1),(id2,k2);\n```\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-innodb-change-buffer-update.png\" width=500/>\n\n\n```\n# 内存：buffer pool\n# redolog：ib_logfileX\n# 数据表空间：t.ibd\n# 系统表空间：ibdata1\n```\n1. Page 1在内存中，直接更新内存\n2. Page 2不在内存中，在changer buffer中记录：`add (id2,k2) to Page 2`\n3. 上述两个动作计入redolog（**磁盘顺序写**）\n4. 至此事务完成，执行更新语句的成本很低\n    - 写两次内存+一次磁盘\n5. 由于在事务提交时，会把change buffer的操作记录也记录到redolog\n    - 因此可以在**崩溃恢复**时，恢复change buffer\n6. 虚线为**后台操作**，不影响更新操作的响应时间\n\n### 读过程\n假设：读语句发生在更新语句后不久，**内存中的数据都还在**，与系统表空间（ibdata1）和redolog（ib_logfileX）无关\n```sql\nSELECT * FROM t WHERE k IN (k1,k2);\n```\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-innodb-change-buffer-read.png\" width=500/>\n\n1. 读Page 1，**直接从内存返回**（此时Page 1有可能还是**脏页**，并未真正落盘）\n2. 读Page 2，通过**磁盘随机读**将数据页读入内存，然后应用change buffer里面的操作日志（**merge**）\n    - 生成一个正确的版本并返回\n\n### 提升更新性能\n1. **redolog**：节省**随机写**磁盘的IO消耗（顺序写）\n2. **change buffer**：节省**随机读**磁盘的IO消耗\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- RR隔离与RC隔离","url":"%2F2019%2F01%2F28%2Fmysql-transaction-isolation-rr-rc%2F","content":"\n## 视图\n1. **虚拟表** -- 本文不关心\n    - 在调用的时候执行**查询语句**并生成执行结果\n    - SQL语句：`CREATE VIEW`\n2. InnoDB在实现**MVCC**时用到的**一致性读视图**（consistent read view）\n    - 用于支持**RC**和**RR**隔离级别的实现\n    - **没有对应的物理结构**\n    - 主要作用：在事务执行期间，事务能看到怎样的数据\n\n<!-- more -->\n\n## 快照\n1. 在**RR**隔离级别下，事务在启动的时候保存了一个**快照**，快照是基于**整库**的\n2. 在InnoDB，每个事务都有一个**唯一的事务ID**（**transaction id**）\n    - 在**事务开始**的时候向InnoDB的**事务系统**申请的，**按申请的顺序严格递增**\n3. 每行数据都有**多个版本**，每次事务**更新数据**的时候，都会生成一个**新的数据版本**\n    - 事务会把自己的**transaction id**赋值给这个数据版本的事务ID，记为`row trx_id`\n        - **每个数据版本都有对应的row trx_id**\n    - 同时也要**逻辑保留**旧的数据版本，通过新的数据版本和`undolog`可以**计算**出旧的数据版本\n\n### 多版本\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-innodb-row-multi-version.png\" width=500/>\n\n1. 虚线框是同一行记录的4个版本\n2. 当前最新版本为V4，k=22，是被`transaction id`为25的事务所更新的，因此它的`row trx_id`为25\n3. 虚线箭头就是`undolog`，而V1、V2和V3并**不是物理真实存在**的\n    - 每次需要的时候根据**当前最新版本**与`undolog`计算出来的\n    - 例如当需要V2时，就通过V4依次执行U3和U2算出来的\n\n### 创建快照\n1. RR的定义：在事务启动时，能够看到**所有已经提交的事务结果**\n    - 在该事务后续的执行过程中，其他事务的更新对该事务是不可见的\n    - 在事务启动时，事务**只认可在该事务启动之前提交的数据版本**\n2. 在实现上，InnoDB会为每个事务构造一个**视图数组**，用来保存在这个事务启动的瞬间，所有处于**活跃状态**的事务ID\n    - 活跃的定义：**启动了但尚未提交**\n3. 低水位与高水位\n    - **低水位**：视图数组里面**最小的事务ID**\n    - **高水位**：当前系统中**已经创建过最大事务ID+1**，一般就是当前事务的`transaction id`\n4. 当前事务的**一致性读视图**的组成部分：**视图数组**和**高水位**\n5. 获取事务的视图数组和高水位在**事务系统的锁保护**下进行，可以认为是**原子**操作，期间**不能创建事务**\n6. InnoDB利用了数据的**Multi-Version**的特性，实现**快照的秒级创建**\n    - **快照 = 一致性读视图 = 视图数组+高水位**\n\n## 事务启动\n1. `BEGIN/START TRANSACTION`：事务**并未立马启动**，在执行到后续的第一个**一致性读**语句，事务才真正开始\n2. `START TRANSACTION WITH CONSISTENT SNAPSHOT;`：事务**立马启动**\n\n## 样例分析\n\n### 表初始化\n```sql\n# 建表\nCREATE TABLE `t` (\n    `id` INT(11) NOT NULL,\n    `k` INT(11) DEFAULT NULL,\n    PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\n# 表初始化\nINSERT INTO t (id, k) VALUES (1,1), (2,2);\n```\n\n### 样例1\n\n#### 事务执行流程\n事务ABC的执行流程（**autocommit=1**）\n\n| 事务A | 事务B | 事务C |\n| ---- | ---- | ---- |\n| START TRANSACTION WITH CONSISTENT SNAPSHOT; | | |\n| | START TRANSACTION WITH CONSISTENT SNAPSHOT; | |\n| | | UPDATE t SET k=k+1 WHERE id=1; |\n| | UPDATE t SET k=k+1 WHERE id=1; | |\n| | SELECT k FROM t WHERE id=1; | |\n| SELECT k FROM t WHERE id=1; | | |\n| COMMIT; | | |\n| | COMMIT; | |\n\n#### 事务A的查询\n\n##### 假设\n1. 事务A开始前，系统里只有一个活跃事务ID是99\n2. 事务ABC的事务ID分别是100，101和102，且当前系统只有这4个事务\n3. 事务ABC开始前，`(1,1)`这一行数据的`row trx_id`是90\n4. 视图数组\n    - 事务A：`[99,100]`\n    - 事务B：`[99,100,101]`\n    - 事务C：`[99,100,101,102]`\n5. 低水位与高水位\n    - 事务A：`99`和`100`\n    - 事务B：`99`和`101`\n    - 事务C：`99`和`102`\n\n##### 查询逻辑\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-innodb-trx-session-a.png\" width=500/>\n\n1. 第一个有效更新是事务C，采用**当前读**，读取当前最新版本`(1,1)`，改成`(1,2)`\n    - 此时最新版本的`row trx_id`为102，90那个版本成为历史版本\n    - 由于**autocommit=1**，事务C在执行完更新后会立马**释放**id=1的**行锁**\n2. 第二个有效更新是事务B，采用**当前读**，读取当前最新版本`(1,2)`，改成`(1,3)`\n    - 此时最新版本的`row trx_id`为101，102那个版本成为历史版本\n3. 事务A查询时，由于事务B还未提交，当前最新版本为`(1,3)`，对事务A是不可见的，否则就了**脏读**了，读取过程如下\n    - 事务A的视图数组为`[99,100]`，读数据都是从**当前最新版本**开始读\n    - 首先找到当前最新版本`(1,3)`，判断`row trx_id`为101，比事务A的视图数组的高水位（100）大，**不可见**\n    - 接着寻找**上一历史版本**，判断`row trx_id`为102，同样比事务A的视图数组的高水位（100）大，**不可见**\n    - 再往前寻找，找到版本`(1,1)`，判断`row trx_id`为90，比事务A的视图数组的低水位（99）小，**可见**\n    - 所以事务A的查询结果为1\n4. **一致性读**：事务A不论在什么时候查询，看到的数据都是**一致**的，哪怕同一行数据同时会被其他事务更新\n\n##### 时间视角\n1. 一个**数据版本**，对于一个**事务视图**来说，除了该事务本身的更新总是可见以外，还有下面3种情况\n    - 如果版本对应的事务未提交，不可见\n    - 如果版本对应的事务已提交，但是是在视图创建之后提交的，不可见\n    - **如果版本对应的事务已提交，并且是在视图创建之前提交的，可见**\n2. 归纳：_**一个事务只承认自身更新的数据版本以及视图创建之前已经提交的数据版本**_\n3. 应用规则进行分析\n    - 事务A的**一致性读视图**是在事务A启动时生成的，在事务A查询时\n    - 此时`(1,3)`的数据版本尚未提交，不可见\n    - 此时`(1,2)`的数据版本虽然提交了，但是是在事务A的**一致性读视图**创建之后提交的，不可见\n    - 此时`(1,1)`的数据版本是在事务A的**一致性读视图**创建之前提交的，可见\n\n#### 更新逻辑\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-innodb-trx-session-b.png\" width=500/>\n\n1. 如果在事务B执行更新之前查询一次，采用的是**一致性读**，查询结果也为1\n2. 如果事务B要执行更新操作，是**不能在历史版本上更新**\n    - 否则事务C的更新就会**丢失**，或者需要采取分支策略来兼容（增加复杂度）\n3. 因此更新数据需要先进行**当前读**（current read），再写入数据\n    - _**当前读：总是读取已经提交的最新版本**_\n    - **当前读伴随着加锁**（更新操作为**X Lock模式的当前读**）\n    - 如果当前事务在执行当前读时，其他事务在这之前已经执行了更新操作，但尚未提交（**持有行锁**），当前事务被阻塞\n4. 事务B的`SET k=k+1`操作是在最新版`(1,2)`上进行的，更新后生成新的数据版本`(1,3)`，对应的`row trx_id`为101\n5. 事务B在进行后续的查询时，发现最新的数据版本为`101`，与自己的版本号**一致**，认可该数据版本，查询结果为3\n\n#### 当前读\n```sql\n# 查询语句\n## 读锁（S锁，共享锁）\nSELECT k FROM t WHERE id=1 LOCK IN SHARE MODE;\n## 写锁（X锁，排他锁）\nSELECT k FROM t WHERE id=1 FOR UPDATE;\n\n# 更新语句，首先采用（X锁的）当前读\n```\n\n### 样例2\n\n#### 事务执行流程\n事务ABC'的执行流程\n\n| 事务A | 事务B | 事务C' |\n| ---- | ---- | ---- |\n| START TRANSACTION WITH CONSISTENT SNAPSHOT; | | |\n| | START TRANSACTION WITH CONSISTENT SNAPSHOT; | |\n| | | START TRANSACTION WITH CONSISTENT SNAPSHOT; |\n| | | UPDATE t SET k=k+1 WHERE id=1; |\n| | UPDATE t SET k=k+1 WHERE id=1; | |\n| | SELECT k FROM t WHERE id=1; | |\n| | | COMMIT; |\n| SELECT k FROM t WHERE id=1; | | |\n| COMMIT; | | |\n| | COMMIT; | |\n\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-innodb-trx-session-b-lock-wait.png\" width=500/>\n\n\n1. 事务C'没有自动提交，依然持有当前最新版本版本`(1,2)`上的**写锁**（X Lock）\n2. 事务B执行更新语句，采用的是**当前读**（X Lock模式），会被阻塞，必须等事务C'释放这把写锁后，才能继续执行\n\n### 样例3\n```sql\n# 建表\nCREATE TABLE `t` (\n    `id` INT(11) NOT NULL,\n    `c` INT(11) DEFAULT NULL,\n    PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\n# 表初始化\nINSERT INTO t (id, c) VALUES (1,1),(2,2),(3,3),(4,4);\n```\n\n#### 事务执行顺序1\n| session A | session B |\n| ---- | ---- |\n| BEGIN; | |\n| SELECT * FROM T; | |\n| | UPDATE t SET c=c+1 |\n| UPDATE t SET c=0 WHERE id=c; | |\n| SELECT * FROM T; | |\n\n#### 事务执行顺序2\n| session A | session B' |\n| ---- | ---- |\n| | BEGIN; |\n| | SELECT * FROM T; |\n| BEGIN; | |\n| SELECT * FROM T; | |\n| | UPDATE t SET c=c+1; |\n| | COMMIT; |\n| UPDATE t SET c=0 WHERE id=c; | |\n| SELECT * FROM T; | |\n\n#### session A视角\n```sql\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t;\n+----+------+\n| id | c    |\n+----+------+\n|  1 |    1 |\n|  2 |    2 |\n|  3 |    3 |\n|  4 |    4 |\n+----+------+\n4 rows in set (0.00 sec)\n\nmysql> UPDATE t SET c=0 WHERE id=c;\nQuery OK, 0 rows affected (0.01 sec)\nRows matched: 0  Changed: 0  Warnings: 0\n\n# 没有修改成功，因为update时采用当前读，基于最新的数据版本（已被其他事务修改并提交）\nmysql> SELECT * FROM t;\n+----+------+\n| id | c    |\n+----+------+\n|  1 |    1 |\n|  2 |    2 |\n|  3 |    3 |\n|  4 |    4 |\n+----+------+\n4 rows in set (0.00 sec)\n```\n\n## RR与RC\n\n### RR\n1. RR的实现核心为**一致性读**（consistent read）\n2. 事务更新数据的时候，只能用**当前读**（current read）\n3. 如果当前的记录的行锁被其他事务占用的话，就需要进入**锁等待**\n4. 在RR隔离级别下，只需要在事务**启动**时创建一致性读视图，之后事务里的其他查询都共用这个一致性读视图\n5. 对于RR，查询只承认**事务启动前**就已经提交的数据\n6. **表结构不支持RR，只支持当前读**\n    - 因为表结构没有对应的行数据，也没有row trx_id\n\n### RC\n1. 在RC隔离级别下，每个**语句执行前**都会**重新计算**出一个新的一致性读视图\n2. 在RC隔离级别下，再来考虑样例1，事务A与事务B的查询语句的结果\n3. `START TRANSACTION WITH CONSISTENT SNAPSHOT`的原意：创建一个**持续整个事务**的**一致性视图**\n    - 在RC隔离级别下，一致性读视图会被**重新计算**，等同于普通的`START TRANSACTION`\n4. 事务A的查询语句的一致性读视图是在执行这个语句时才创建的\n    - 数据版本`(1,3)`未提交，不可见\n    - 数据版本`(1,2)`提交了，并且在事务A**当前的一致性读视图**创建之前提交的，**可见**\n    - 因此事务A的查询结果为2\n5. 事务B的查询结果为3\n6. 对于RC，查询只承认**语句启动前**就已经提交的数据\n\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-innodb-trx-rc.png\" width=500/>\n\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 锁","url":"%2F2019%2F01%2F25%2Fmysql-lock%2F","content":"\n## 全局锁\n1. 全局锁：对整个**数据库实例**加锁\n2. 加**全局读锁**：`FLUSH TABLES WITH READ LOCK`，阻塞其他线程的下列语句\n    - **数据更新语句**（增删改）\n    - **数据定义语句**（建表、修改表结构）\n    - **更新类事务的提交语句**\n3. 主动解锁：`UNLOCK TABLES`\n3. 典型使用场景：**全库逻辑备份**\n    - 把整库每个表都**SELECT**出来，然后存成**文本**\n4. 缺点\n    - 如果在**主库**上执行**逻辑备份**，备份期间**不能执行更新操作**，导致**业务停摆**\n    - 如果在**备库**上执行**逻辑备份**，备份期间从库**不能执行由主库同步过来的binlog**，导致**主从延时**\n5. 备份加全局锁的必要性\n    - 保证**全局视图**是**逻辑一致**的\n\n<!-- more -->\n\n### mysqldump\n1. `--single-transaction`\n    - 导数据之前**启动一个事务**，确保拿到_**一致性视图**_\n    - 由于**MVCC**的支持，在这个过程中是可以**正常更新数据**的\n2. 需要**存储引擎**支持_**RR的事务隔离级别**_\n    - MyISAM不支持事务，如果备份过程中有更新，总是能取到最新的数据，破坏了备份的一致性\n    - 因此MyISAM只能依赖于`FLUSH TABLES WITH READ LOCK`，不能使用`--single-transaction`\n3. 针对**全库逻辑备份**的场景，`--single-transaction`只适用于**所有的表都使用了事务引擎的库**\n    - 如果有的表使用了不支持事务的存储引擎，那么只能依赖于`FLUSH TABLES WITH READ LOCK`\n    - 这是MyISAM被InnoDB替代的一个重要原因\n4. 在逻辑备份时，如果全部库**都使用InnoDB**，建议使用`--single-transaction`参数，对应用更加友好\n\n#### 逻辑备份 + DDL\n在**备库**用`--single-transaction`做**逻辑备份**的过程中，由**主库的binlog**传来了一个针对小表`t1`的**DDL**语句\n\n##### 备份关键语句\n```\n# 备份过程中的关键语句\nQ1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;\nQ2:START TRANSACTION WITH CONSISTENT SNAPSHOT;\n/* other tables */\nQ3:SAVEPOINT sp;\n/* 时刻 1 */\nQ4:SHOW CREATE TABLE `t1`;\n/* 时刻 2 */\nQ5:SELECT * FROM `t1`;\n/* 时刻 3 */\nQ6:ROLLBACK TO SAVEPOINT sp;\n/* 时刻 4 */\n/* other tables */\n```\n1. 备份开始时，为了确保**RR**的隔离级别，再设置一次（Q1）\n2. 启动事务，用`WITH CONSISTENT SNAPSHOT`确保可以得到一个**一致性视图**（Q2）\n3. 设置一个保存点（Q3）\n4. `SHOW CREATE TABLE`是为了拿到**表结构**（Q4）\n5. `SELECT * FROM`是正式**导数据**（Q5）\n6. `ROLLBACK TO SAVEPOINT`的作用是**释放t1的MDL锁**（Q6）\n\n##### DDL到达时刻\n1. 时刻1：备份拿到的是**DDL后**的表结构\n    - 现象为**无影响**\n2. 时刻2：Q5执行时，报异常：`Table definition has changed, please retry transaction`\n    - 现象为**mysqldump终止**\n3. 在时刻2~时刻3之间（**导数据期间**）：mysqldump占据着t1的**MDL读锁**，因此**binlog会被阻塞**，直到Q6结束\n    - 现象为**主从延时**\n4. 时刻4：mysqldump释放**MDL读锁**，备份拿到的是**DDL前**的表结构\n    - 现象为**无影响**\n\n### readonly\n1. `SET GLOBAL READONLY=true`也能让全库进入只读状态，推荐使用`FLUSH TABLES WITH READ LOCK`\n2. 在有些系统中，`readonly`的值会被用来做其他逻辑，因此修改`global`变量的方式**影响面会比较大**\n3. 异常处理机制不同\n    - 执行`FLUSH TABLES WITH READ LOCK`命令后，客户端发生异常，MySQL会**自动释放全局锁**\n    - 执行`SET GLOBAL READONLY=true`命令后，客户端发生异常，MySQL会**一直保持readonly状态**\n\n## 表级锁\n\n### 表锁\n1. 表锁：`LOCK TABLES ... READ/WRITE`\n2. 解锁\n    - 主动解锁：`UNLOCK TABLES`\n    - 自动解锁：客户端发生异常，断开连接\n3. `LOCK TABLES`除了会限制**其他线程**的读写外，也会限制**本线程**接下来的操作\n    - 线程A执行`LOCK TABLES t1 READ, t2 WRITE`，在线程A执行`UNLOCK TABLES`之前\n    - 其他线程允许的操作：**读t1**\n    - 线程A允许的操作：**读t1**，**读写t2**，同样_**不允许写t1**_\n4. InnoDB支持**行锁**，所以一般不使用`LOCK TABLES`来进行并发控制\n\n### 元数据锁（MDL）\n1. MDL是**隐式使用**的，在**访问一个表**的时候会被**自动加上**\n2. MDL的作用：**保证读写的正确性**，从**MySQL 5.5**引入\n    - _**防止DDL与DML的并发冲突**_\n3. MDL读锁 + MDL写锁\n    - 对一个表做**增删改查**操作（**DML**）的时候，加**MDL读锁**\n    - 对**表结构**做**变更**操作（**DDL**）的时候，加**MDL写锁**\n    - 关系\n        - **读锁之间不互斥**：多线程可以并发对同一张表进行增删改查\n        - **读写锁之间，写锁之间互斥**：用于保证变更表结构操作的安全性\n\n#### 加字段的问题\n<img src='https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-lock-add-column.jpg' width=450/>\n\n1. session A先启动，对表t加上一个**MDL读锁**\n2. session B需要的也是**MDL读锁**，不互斥，可以正常执行\n3. session C需要的是**MDL写锁**，session A的事务**还未提交**，**持有的MDL读锁还未释放**，session C会被阻塞\n4. session D只需要申请**MDL读锁**，但同样会**被session C阻塞**\n    - 所有对表的增删改查都需要先**申请MDL读锁**，此时表现为**完全不可读写**\n    - 如果该表上的**查询比较频繁**，而且**客户端**恰好有**重试机制**（超时后再起一个session去请求）\n        - 那么**数据库的线程**很快就会被**占满**\n5. 事务中的**MDL锁**，在**语句开始执行时申请**，但会等到**整个事务提交后再释放**\n\n#### 解决办法\n1. 首先要解决**长事务**的影响，因为只要事务不提交，就会一直占用相关的MDL锁\n    - `INFORMATION_SCHEMA.INNODB_TRX`中的`trx_started`字段\n    - 在做**DDL**变更之前，首先**确认是否长事务在执行**，如果有则先**kill**掉这个长事务\n2. 如果需要执行DDL的表是**热点表**，**请求很频繁**，kill长事务未必管用，因为很快就会有新的请求\n    - `ALTER TALE`语句设定**等待时间**，就算拿不到**MDL写锁**也不至于**长时间阻塞后面的业务语句**\n    - 目前`MariaDB`和`AliSQL`支持该功能\n\n```sql\nALTER TABLE T [WAIT [n]|NO_WAIT] ADD f INT\n```\n\n### 关系\n1. 线程A在MyISAM表上更新一行数据，那么会加**MDL读锁**和**表的写锁**\n2. 线程B在同一个MyISAM表上更新另外一行数据，那么也会加**MDL读锁**和**表的写锁**\n    - 线程B加**MDL读锁**成功，但加**表的写锁**失败\n    - 表现：线程B被线程A阻塞\n3. 引申：如果有多种锁，必须**全部锁不互斥**才能**并行**，只要有一个锁互斥，就得等\n\n## 行锁\n1. MySQL的行锁是在**存储引擎层**实现的\n2. MyISAM不支持行锁，而InnoDB支持行锁，这是InnoDB替代MyISAM的一个重要原因\n\n### 两阶段锁\nid为表t的主键，事务B的update语句会被阻塞，直到事务A执行commit之后，事务B才能继续执行\n<img src='https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-innodb-two-phase-commit.jpg' width=450/>\n\n1. 两阶段锁\n    - 在InnoDB事务中，行锁是在**需要的时候**加上\n    - 但并不是在不需要了就立刻释放，而是要等待**事务结束**后才释放\n2. 如果事务需要**锁定多行**，要就把最可能**造成锁冲突**和**影响并发度**的锁尽可能**往后放**\n\n#### 电影票业务\n1. 顾客A在电影院B购买电影票，涉及以下操作（同一事务）\n    - update：从顾客A的账户余额中扣除电影票价\n    - update：给电影院B的账户余额增加电影\u0010票价\n    - insert：记录一条交易日志\n2. 假设此时顾客C也要在电影院B买票的，两个事务冲突的部分就是第2个语句（同一个电影院账户）\n    - 所有操作所需要的行锁都是在事务结束的时候才会释放\n    - 将第2个语句放在最后，能最大程度地**减少事务之间的锁等待**，**提升并发度**\n\n### 死锁\n假设电影院做活动，在活动开始的时候，CPU消耗接近100%，但整个库每秒执行不到100个事务\n<img src='https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-innodb-dead-lock.jpg' width=450/>\n\n1. 事务A在等待事务B释放id=2的行锁，事务B在等待事务A释放id=1的行锁，导致**死锁**\n2. 当出现死锁后，有2种处理策略\n    - **等待**，直至超时（不推荐）\n        - **业务有损**：业务会出现大量超时\n    - **死锁检测**（推荐）\n        - **业务无损**：业务设计不会将死锁当成严重错误，当出现死锁时可采取：_**事务回滚+业务重试**_\n\n#### 等待\n1. 由参数`innodb_lock_wait_timeout`控制（MySQL 5.7.15引入）\n2. 默认是50s，对于**在线服务**来说是无法接受的\n3. 但也**不能设置成很小的值**，因为如果实际上并不是死锁，只是简单的锁等待，会出现很多**误伤**\n\n#### 死锁检测（推荐）    \n1. 发现死锁后，**主动回滚锁链条中的某一事务**，让其他事务继续执行\n    - 需要设置参数`innodb_deadlock_detect`\n2. 触发死锁检测：**要加锁访问的行上有锁**\n    - **一致性读不会加锁**\n3. 死锁检测并**不需要扫描所有事务**\n    - 某个时刻，事务等待状态为：事务B等待事务A，事务D等待事务C\n    - 新来事务E，事务E需要等待D，那么只会判断事务CDE是否会形成死锁\n4. CPU消耗高\n    - 每个新来的线程发现自己**要加锁访问的行上有锁**\n        - 会去判断会不会**由于自己的加入而导致死锁**，总体时间复杂度为**`O(N^2)`**\n    - 假设有1000个并发线程，最坏情况下死锁检测的操作量级为100W（1000^2）\n5. 解决方法\n    - 如果业务能确保一定不会出现死锁，可以**临时关闭死锁检测**，但存在一定的风险（超时）\n    - 控制并发度，如果并发下降，那么死锁检测的成本就会降低，这需要在**数据库服务端**实现\n        - 如果有**中间件**，可以在中间件实现\n        - 如果能修改**MySQL源码**，可以在MySQL内部实现\n    - 设计上的优化\n        - 将一行改成**逻辑上的多行**来**减少锁冲突**\n\n```sql\nmysql> SHOW VARIABLES LIKE '%innodb_deadlock_detect%';\n+------------------------+-------+\n| Variable_name          | Value |\n+------------------------+-------+\n| innodb_deadlock_detect | ON    |\n+------------------------+-------+\n\nmysql> SHOW VARIABLES LIKE '%innodb_lock_wait_timeout%';\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| innodb_lock_wait_timeout | 30    |\n+--------------------------+-------+\n```\n\n### 更新无锁引字段\n```sql\n# name字段没有索引\nUPDATE t SET t.name='abc' WHERE t.name='cde'\n```\nInnoDB内部会根据**聚簇索引**，_**逐行扫描，逐行加锁，事务提交后统一释放锁**_\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 索引","url":"%2F2019%2F01%2F21%2Fmysql-index%2F","content":"\n## 索引模型\n\n### 哈希表\n实现上类似于`java.util.HashMap`，哈希表适合只有**等值查询**的场景\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-index-hashtable.png\" width=400/>\n\n\n<!-- more -->\n\n### 有序数组\n有序数组只适用于**静态存储引擎**（针对不会再修改的数据）\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-index-sortedarray.png\" width=400/>\n\n\n#### 查找\n1. 等值查询：可以采用**二分法**，时间复杂度为`O(log(N))`\n2. 范围查询：查找`[ID_card_X,ID_card_Y]`\n    - 首先通过**二分法**找到第一个大于等于`ID_card_X`的记录\n    - 然后向**右**遍历，直到找到第一个大于`ID_card_Y`的记录\n\n#### 更新\n在中间**插入或删除**一个纪录就得**挪动后面的所有的记录**\n\n### 搜索树\n\n#### 平衡二叉树\n查询的时间复杂度：`O(log(N))`，更新的时间复杂度：`O(log(N))`（维持树的**平衡**）\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-index-binarytree.png\" width=400/>\n\n\n#### N叉树\n1. 大多数的数据库存储并没有采用二叉树，原因：**索引不仅仅存在于内存中，还要写到磁盘上**\n    - 对于有**100W**节点的平衡二叉树，树高为**20**，即一次查询可能需要访问20个数据块\n    - 假设HDD，随机读取一个数据块需要**10ms**左右的**寻址时间**\n    - 即一次查询可能需要**200ms** -- 慢成狗\n2. 为了让一个查询**尽量少的读取磁盘**，就必须让查询过程访问**尽量少的数据块**，因此采用N叉树\n    - N的大小取决于**数据页的大小**和**索引大小**\n    - 在InnoDB中，以**INT**（4 Bytes）字段为索引，假设页大小为16KB，并采用Compact行记录格式，N大概是745\n    - 假设树高还是4（**树根的数据块总是在内存中**），数据量可以达到`745^3 = 4.1亿`\n    - 访问这4亿行的表上的INT字段索引，查找一个值最多只需要读取3次磁盘（很大概率，树的第2层也在内存中）\n3. N叉树由于在**读写上的性能优点**以及**适配HDD的访问模式**，被广泛应用于数据库引擎中\n\n## InnoDB的索引\n索引是在**存储引擎层**实现的，**没有统一的索引标准**，不同存储引擎的索引的工作方式是不一样的，哪怕多个存储引擎支持同一类型的索引，其底层的实现也可能不同的\n\n### 索引组织表\n表都是根据**主键顺序**以**索引的形式**存放的，这种存储方式称为**索引组织表**，每一个**索引**在InnoDB里面都对应一棵**B+树**\n```sql\n# 建表\nCREATE TABLE T(\n    id INT PRIMARY KEY,\n    k INT NOT NULL,\n    INDEX (k)\n) ENGINE=INNODB;\n\n# 初始化数据\nR1 : (100,1)\nR2 : (200,2)\nR3 : (300,3)\nR4 : (500,5)\nR5 : (600,6)\n```\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-index-bplustree.png\" width=400/>\n\n1. 根据**叶子节点的内容**，索引类型分为**聚簇索引**（clustered index）和**二级索引**（secondary index）\n    - 聚簇索引的叶子节点存储的是**整行数据**\n    - 二级索引的叶子节点存储的是**主键的值**\n2. `select * from T where ID=500`：只需要搜索ID树\n3. `select * from T where k=5`：先搜索k树，得到ID的值为500，再到ID树搜索，该过程称为_**回表**_\n4. 基于二级索引的查询需要多扫描一棵索引树，因此**尽量使用主键查询**\n\n### 维护索引\n1. B+树为了维护**索引的有序性**，在插入新值时，需要做必要的维护\n2. 如果新插入的行ID为700，只需要在R5的记录后插入一个新纪录\n3. 如果新插入的行ID为400，需要**逻辑上**（实际采用**链表**的形式，直接追加）挪动R3后面的数据，空出位置\n    - 如果R5所在的数据页已经满了，根据B+树的算法，需要申请一个新的数据页，然后将部分数据挪过去，称为_**页分裂**_\n    - 页分裂的影响：**性能**、**数据页的利用率**\n4. **页合并**：页分裂的逆过程\n    - 当**相邻**两个页由于**删除**了数据，利用率很低之后，会将数据页合并\n\n#### 自增主键\n1. 逻辑：如果主键为自增，并且在插入新纪录时不指定主键的值，系统会获取当前主键的**最大值+1**作为新纪录的主键\n    - 适用于**递增插入**的场景，每次插入一条新纪录都是**追加操作**，既不会涉及其他记录的挪动操作，也不会触发页分裂\n2. 如果采用**业务字段**作为主键，**很难保证有序插入**，写数据的成本相对较高\n3. 主键长度越小，二级索引占用的空间也就越小\n    - 在一般情况下，创建一个自增主键，这样二级索引占用的空间最小\n4. 针对实际中一般采用分布式ID生成器的情况\n    - 满足**有序插入**\n    - 分布式ID**全局唯一**\n4. 适合直接采用**业务字段**做主键的场景：**KV场景**（**只有一个唯一索引**）\n    - 无须考虑**二级索引的占用空间问题**\n    - 无须考虑**二级索引的回表问题**\n\n#### 重建索引\n```sql\n# 重建二级索引\nALTER TABLE T DROP INDEX k;\nALTER TABLE T ADD INDEX(k);\n\n# 重建聚簇索引\nALTER TABLE T DROP PRIMARY KEY;\nALTER TABLE T ADD PRIMARY KEY(id);\n```\n1. 重建索引的原因\n    - 索引可能因为**删除和页分裂**等原因，导致**数据页有空洞**\n    - 重建索引的过程会**创建一个新的索引**，**把数据按顺序插入**\n    - 这样**页面的利用率最高**，使得索引更紧凑，更省空间\n2. 重建二级索引k是合理的，可以达到省空间的目的\n3. **重建聚簇索引是不合理的**\n    - 不论是**删除聚簇索引**还是**创建聚簇索引**，都会**将整个表重建**\n    - 替代语句：`ALTER TABLE T ENGINE=INNODB`\n\n### 索引优化\n\n#### 覆盖索引\n```sql\n# 建表\nCREATE TABLE T (\n    ID INT PRIMARY KEY,\n    k INT NOT NULL DEFAULT 0,\n    s VARCHAR(16) NOT NULL DEFAULT '',\n    INDEX k(k)\n) ENGINE=INNODB;\n\n# 初始化数据\nINSERT INTO T VALUES (100,1,'aa'),(200,2,'bb'),(300,3,'cc'),(500,5,'ee'),(600,6,'ff'),(700,7,'gg');\n```\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-index-scan-row.png\" width=400/>\n\n\n##### 需要回表的查询\n```sql\nSELECT * FROM T WHERE k BETWEEN 3 AND 5\n```\n\n1. 在k树上找到k=3的记录，取得ID=300\n2. 再到ID树上查找ID=300的记录，对应为R3\n3. 在k树上取**下一个**值k=5，取得ID=500\n4. 再到ID树上查找ID=500的记录，对应为R4\n5. 在k树上取**下一个**值k=6，不满足条件，循环结束\n\n整个查询过程读了k树3条记录，回表了2次\n\n##### 不需要回表的查询\n```sql\nSELECT ID FROM T WHERE k BETWEEN 3 AND 5\n```\n1. 只需要查ID的值，而ID的值已经在k树上，可以直接提供查询结果，**不需要回表**\n    - 因为k树已经覆盖了我们的查询需求，因此称为**覆盖索引**\n2. 覆盖索引可以**减少树的搜索次数**，显著**提升查询性能**，因此使用覆盖索引是一个常用的性能优化手段\n3. 扫描行数\n    - 在存储引擎内部使用覆盖索引在索引k上其实是读取了3个记录，\n    - 但对于MySQL的**Server层**来说，存储引擎返回的只有2条记录，因此MySQL认为扫描行数为2\n\n##### 联合索引\n```sql\nCREATE TABLE `tuser` (\n    `id` INT(11) NOT NULL,\n    `id_card` VARCHAR(32) DEFAULT NULL,\n    `name` VARCHAR(32) DEFAULT NULL,\n    `age` INT(11) DEFAULT NULL,\n    `ismale` TINYINT(1) DEFAULT NULL,\n    PRIMARY KEY (`id`),\n    KEY `id_card` (`id_card`),\n    KEY `name_age` (`name`,`age`)\n) ENGINE=InnoDB\n```\n高频请求：根据id_card查询name。可以建立联合索引`(id_card,name)`，达到**覆盖索引**的效果\n\n#### 最左前缀原则\nB+树的索引结构，可以利用索引的**最左前缀**来定位记录\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-index-leftmost-prefix.jpg\" width=400/>\n\n1. 索引项是按照**索引定义**里**字段出现的顺序**来排序的\n    - 如果查找所有名字为**张三**的人时，可以快速定位到ID4，然后**向后遍历**，直到不满足条件为止\n    - 如果查找所有名字的第一个字是**张**的人，找到第一个符合条件的记录ID3，然后**向后遍历**，直到不满足条件为止\n2. 只要满足**最左前缀**，就可以利用索引来加速检索，最左前缀有2种情况\n    - **联合索引的最左N个字段**\n    - **字符串索引的最左M个字符**\n3. 建立联合索引时，定义**索引内字段顺序**的原则\n    - **复用**：如果通过调整顺序，可以**少维护一个索引**，往往优先考虑这样的顺序\n    - **空间**：维护`(name,age)`+`age`比维护`(age,name)`+`name`所占用的空间更少\n\n#### 索引下推\n```sql\nSELECT * FROM tuser WHERE name LIKE '张%' AND age=10 AND ismale=1;\n```\n1. 依据**最左前缀**原则，上面的查询语句只能用**张**，找到第一个满足条件的记录ID3（优于全表扫描）\n2. 然后判断其他条件是否满足\n    - 在**MySQL 5.6**之前，只能从ID3开始**一个个回表**，到聚簇索引上找出对应的数据行，再对比字段值\n        - 这里暂时忽略**MRR**：在不影响排序结果的情况下，在取出主键后，回表之前，会对所有获取到的主键进行排序\n    - 在**MySQL 5.6**引入了**下推优化**（index condition pushdown）\n        - 可以在**索引遍历**过程中，**对索引所包含的字段先做判断**，**直接过滤掉不满足条件的记录**，**减少回表次数**\n\n无索引下推，回表4次\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-index-pushdown.jpg\" width=400/>\n\n\n采用索引下推，回表2次\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-index-no-pushdown.jpg\" width=400/>\n\n\n#### 删除冗余索引\n```sql\nCREATE TABLE `geek` (\n    `a` int(11) NOT NULL,\n    `b` int(11) NOT NULL,\n    `c` int(11) NOT NULL,\n    `d` int(11) NOT NULL,\n    PRIMARY KEY (`a`,`b`),\n    KEY `c` (`c`),\n    KEY `ca` (`c`,`a`),\n    KEY `cb` (`c`,`b`)\n) ENGINE=InnoDB;\n\n# 索引(`a`,`b`)是业务属性\n# 常规查询，应该如何优化索引？\nselect * from geek where c=N order by a limit 1;\nselect * from geek where c=N order by b limit 1;\n```\n\n##### 结论\n索引`ca`是不需要的，因为满足**最左前缀**原则，`ca(b) = c(ab)`\n\n##### 样例\n假设表记录\n\n| a | b | c | d |\n| -- | -- | -- | -- |\n| 1 | 2 | 3 | d |\n| 1 | 3 | 2 | d |\n| 1 | 4 | 3 | d |\n| 2 | 1 | 3 | d |\n| 2 | 2 | 2 | d |\n| 2 | 3 | 4 | d |\n\n索引`ca`：先按c排序，再按a排序，同时记录主键\n\n| c | a | 部分主键b(只有b) |\n| -- | -- | -- |\n| 2 | 1 | 3 |\n| 2 | 2 | 2 |\n| 3 | 1 | 2 |\n| 3 | 1 | 4 |\n| 3 | 2 | 1 |\n| 4 | 2 | 3 |\n\n这与索引`c`是一样的，索引`ca`是多余的\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 事务隔离","url":"%2F2019%2F01%2F16%2Fmysql-transaction-isolation%2F","content":"\n## 概念\n1. 事务：保证一组数据库操作，要么**全部成功**，要么**全部失败**\n2. 在MySQL中，事务支持是在**存储引擎**层实现的\n    - MyISAM不支持事务\n    - InnoDB支持事务\n\n## 隔离性与隔离级别\n\n<!-- more -->\n\n1. 事务特性：**ACID**（Atomicity、Consistency、Isolation、Durability）\n2. 如果多个**事务并发执行**时，就可能会出现**脏读**、**不可重复读**、**幻读**（phantom read）等问题\n    - 解决方案：**隔离级别**\n    - 隔离级别越高，效率就会越低\n3. SQL标准的事务隔离级别\n    - **READ-UNCOMMITTED**\n        - 一个事务还未提交时，它所做的变更能被别的事务看到\n    - **READ-COMMITTED**\n        - 一个事务提交之后，它所做的变更才会被其他事务看到\n    - **REPEATABLE-READ**\n        - 一个事务在执行过程中所看到的数据，总是跟这个事务在启动时看到的数据是一致的\n        - 同样，在RR隔离级别下，未提交的变更对其他事务也是不可见的\n    - **SERIALIZABLE**\n        - 对同一行记录，写会加写锁，读会加读锁，锁级别是**行锁**\n        - 当出现读写锁冲突时，后访问的事务必须等前一个事务执行完成，才能继续执行\n3. 默认隔离级别\n    - Oracle：READ-COMMITTED\n    - MySQL：REPEATABLE-READ\n\n```sql\nmysql> SHOW VARIABLES LIKE '%isolation%';\n+---------------+-----------------+\n| Variable_name | Value           |\n+---------------+-----------------+\n| tx_isolation  | REPEATABLE-READ |\n+---------------+-----------------+\n```\n\n### 样例\n```sql\nmysql> create table T(c int) engine=InnoDB;\ninsert into T(c) values(1);\n```\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-isolation-level-example.png\" width=350/>\n\n\n| 隔离级别 | V1 | V2 | V3 | 备注 |\n| ---- | ---- | ---- | ---- | ---- |\n| READ-UNCOMMITTED | 2 | 2 | 2 | |\n| READ-COMMITTED | 1 | 2 | 2 | |\n| REPEATABLE-READ | 1 | 1 | 2 | |\n| SERIALIZABLE | 1 | 1 | 2 | 事务B在执行『1->2』时被锁住，等事务A提交后才能继续执行 |\n\n### 实现\n1. 在实现上，数据库里面会创建一个**视图**（read-view），访问的时候会以视图的逻辑结果为准\n2. REPEATABLE-READ的视图是在**事务启动时**创建的，整个事务存在期间都用这个视图\n    - 事务启动：begin后的第一个**DML**语句，**begin语句本身不会开启事务**\n3. READ-COMMITTED的视图在**每个SQL语句开始执行时**创建的\n4. READ-UNCOMMITTED**没有视图概念**，直接返回**记录上的最新值**（**内存**，InnoDB Buffer Pool）\n5. SERIALIZABLE则直接用**加锁**（行锁）的方式来避免并行访问\n\n## RR隔离的实现\n实际上，每条记录在**更新**的时候都会同时（**在redolog和binlog提交之前**）记录一条**回滚操作**\n记录上的最新值，通过回滚操作，都可以得到前一个状态的值\n\n### 多版本\n变更记录：1->2->3->4\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-read-view.png\" width=500/>\n\n1. 当前值为4，但在查询这条记录的时候，**不同时刻启动的事务会有不同的视图**\n2. 在视图A、B和C，这一个记录的值分别是1、2和4\n3. 同一条记录在系统中可以存在多个版本，这就是**MVCC**（**多版本并发控制**）\n4. 对于视图A，要得到1，必须**将当前值依次执行图中的所有回滚操作**\n    - 这会存在一定的**性能开销**\n    - 这里的视图是**逻辑视图**，**并不是快照**\n    - 这里的视图是InnoDB（**存储引擎层**）的read-view，也不是Server层都VIEW（虚表）\n5. 即使此时有另外一个事务正在将4改成5，这个事务跟视图A、B和C所对应的事务并不冲突\n\n### 删除回滚段\n1. **当没有事务需要用到这些回滚段时**，回滚段就会被删除\n2. 不被事务所需要的回滚段：**比系统中最早视图还要早的回滚段**\n\n### 长事务\n1. 长事务意味着系统里面存在**很老的事务视图**\n2. 长事务随时可能访问数据库里面的任何数据，在这个事务提交之前，它**可能用到的回滚段都必须保留**\n    - 因此这会导致**占用大量的存储空间**\n    - <= MySQL5.5，回滚段跟数据字典一起放在**ibdata**文件里，即使长事务最终提交，回滚段被清理，**文件也不会变小**\n3. RC隔离级别一般不会导致回滚段过长的问题\n\n```sql\n# 查询持续时间超过60s的事务\nmysql> select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60;\n```\n\n## 事务的启动方式\n1. 启动方式\n    - 显式启动事务，**begin(start transaction) + commit/rollback**\n    - **set autocommit=0 + commit/rollback**\n        - set autocommit=0：关闭自动提交\n        - 一些客户端框架会在默认连接成功后执行set autocommit=0，导致**接下来的查询都在事务中**\n        - 如果是**长连接**，就会导致**意外的长事务**\n2. 推荐方式\n    - _**set autocommit=1 + begin(start transaction) + commit/rollback**_\n    - set autocommit=1 + begin(start transaction) + (commit and chain)/(rollback and chain)\n        - 适用于频繁使用事务的业务\n        - 省去再次执行begin语句的开销\n        - 从程序开发的角度能够明确地知道每个语句是否处于事务中\n\n## 避免长事务的方案\n\n### 应用开发端\n1. 确保**set autocommit=1**，可以通过**general_log**来确认\n2. 确认程序中是否有**不必要的只读事务**\n3. 业务连接数据库的时候，预估**每个语句执行的最长时间**（**max_execution_time**）\n\n```sql\nmysql> SHOW VARIABLES LIKE '%general_log%';\n+------------------+-----------------------------------------------+\n| Variable_name    | Value                                         |\n+------------------+-----------------------------------------------+\n| general_log      | OFF                                           |\n| general_log_file | /data_db3/mysql/3323/data/ym_DB_12_100071.log |\n+------------------+-----------------------------------------------+\n```\n```sql\n# Introduced 5.7.8\n# 0 -> disable\nmysql> SHOW VARIABLES LIKE '%max_execution_time%';\n+--------------------+-------+\n| Variable_name      | Value |\n+--------------------+-------+\n| max_execution_time | 0     |\n+--------------------+-------+\n```\n\n### 数据库端\n1. 监控**information_schema.innodb_trx**，设置长事务阈值，告警或者Kill（工具：pt-kill）\n2. 在业务功能的测试阶段要求输出所有的general_log，分析日志行为并提前发现问题\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- redolog + binlog","url":"%2F2019%2F01%2F15%2Fmysql-redolog-binlog%2F","content":"\n## 更新语句\n```sql\nmysql> CREATE TABLE T (id INT PRIMARY KEY, c INT);\n\nmysql> UPDATE T SET c=c+1 WHERE id=2;\n```\n\n## 执行过程\n\n<!-- more -->\n\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-architecture.png\" width=500/>\n\n\n1. 通过连接器，客户端与MySQL建立连接\n2. update语句会把**T表上的所有查询缓存清空**\n3. 分析器会通过词法分析和语法分析识别这是一条更新语句\n4. 优化器会决定使用id这个索引（聚簇索引）\n5. 执行器负责具体执行，找到匹配的一行，然后更新\n6. 更新过程中还会涉及**redolog**（重做日志）和**binlog**（归档日志）的操作\n\n## redolog -- InnoDB\n1. 如果每次更新操作都需要**直接写入磁盘**（在磁盘中找到相关的记录并更新），整个过程的**IO成本**和**查找成本**都很高\n2. 针对这种情况，MySQL采用的是**WAL**技术（**Write-Ahead Logging**）：_**先写日志，再写磁盘**_\n3. 当有一条记录需要更新的时候，InnoDB会先把记录写到**redolog**（redolog buffer），并**更新内存**（buffer pool）\n    - InnoDB会在适当的时候（例如系统空闲），将这个操作记录到磁盘里面（**刷脏页**）\n4. InnoDB的redolog是**固定大小**的，如果每个日志文件大小为1GB，4个日志文件为一组\n    - redolog的总大小为4GB，_**循环写**_\n    - write pos是**当前记录的位置**，一边写一边后移，写到3号文件末尾后就回到0号文件开头\n        - redolog是**顺序写**，数据文件是**随机写**\n    - checkpoint是**当前要擦除的位置**，**擦除记录前需要先把对应的数据落盘**（更新内存页，等待刷脏页）\n    - write pos到checkpoint之间的部分可以用来**记录新的操作**\n        - 如果write pos赶上了checkpoint，说明redolog已**满**，不能再执行新的更新操作，需要先推进checkpoint\n        - **只要write pos未赶上checkpoint，就可以执行新的更新操作**\n    - checkpoint到write pos之间的部分**等待落盘**（先更新内存页，然后等待刷脏页）\n        - 如果checkpoint赶上了write pos，说明redolog已**空**\n5. 有了redolog之后，InnoDB能保证数据库即使发生**异常重启**，**之前提交的记录都不会丢失**，达到**crash-safe**\n6. 如果redolog太小，会导致很快被写满，然后就不得不强行刷redolog，这样**WAL**机制的能力就无法发挥出来\n    - 如果磁盘能达到几TB，那么可以将redolog设置4个一组，每个日志文件大小为1GB\n\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-innodb-redo-log.jpg\" width=400/>\n\n\n```sql\n# innodb_log_file_size -> 单个redolog文件的大小\n# 268435456 Bytes = 256 MB\nmysql> SHOW VARIABLES LIKE '%innodb_log_file%';\n+---------------------------+-----------+\n| Variable_name             | Value     |\n+---------------------------+-----------+\n| innodb_log_file_size      | 268435456 |\n| innodb_log_files_in_group | 3         |\n+---------------------------+-----------+\n```\n```sql\n# 这里的written是指写到磁盘缓存\n# 0 -> Logs are written and flushed to disk once per second\n# 1 -> Logs are written and flushed to disk at each transaction commit\n# 2 -> Logs are written after each transaction commit and flushed to disk once per second\nmysql> SHOW VARIABLES LIKE '%innodb_flush_log_at_trx_commit%';\n+--------------------------------+-------+\n| Variable_name                  | Value |\n+--------------------------------+-------+\n| innodb_flush_log_at_trx_commit | 2     |\n+--------------------------------+-------+\n```\n[innodb_flush_log_at_trx_commit](https://dev.mysql.com/doc/refman/5.6/en/innodb-parameters.html#sysvar_innodb_flush_log_at_trx_commit)\n\n### 数据落盘\n1. redolog并**没有记录数据页的完整记录**，只是记录**数据页的变更**，因此redolog本身并**没有直接更新磁盘页的能力**\n2. MySQL实例正常运行，在**内存中的数据页**被修改后，跟**磁盘上的数据页**不一致，称为**脏页**\n    - 最终的**数据落盘**，指的是**把内存中的数据页覆盖磁盘上的数据页**，这个过程**与redolog无关**\n3. 在崩溃恢复的场景，InnoDB如果判断是下面的`2.a`场景\n    - 就会**读取磁盘上对应的数据页到内存**中，然后**应用redolog**，更新内存页\n    - 更新完成后，这个内存页就变成了脏页，等待被刷到磁盘上\n\n### redolog buffer\n```sql\nBEGIN;\nINSERT INTO t1;\nINSERT INTO t2;\nCOMMIT;\n```\n1. redolog buffer用于存放redolog\n2. 执行完第一个`INSERT`后，内存中（**buffer pool**）的数据页被修改了，另外**redolog buffer**也写入了日志\n3. `COMMIT`：真正把日志写到redolog（ib_logfileX）\n4. 自动开启事务的SQL语句**隐式**包含上述过程\n\n## binlog -- Server\n1. **redolog是InnoDB特有的日志，binlog属于Server层日志**\n2. 有两份日志的历史原因\n    - 一开始并没有InnoDB，采用的是MyISAM，但**MyISAM没有crash-safe的能力**，**binlog日志只能用于归档**\n    - InnoDB是以插件的形式引入MySQL的，**为了实现crash-safe**，InnoDB采用了**redolog**的方案\n3. binlog一开始的设计就是**不支持崩溃恢复**（原库）的，如果不考虑搭建从库等操作，**binlog是可以关闭的**（sql_log_bin）\n4. redolog vs binlog\n    - redolog是InnoDB特有的，binlog是MySQL的Server层实现的，所有层都可以使用\n    - redolog是**物理日志**，记录某个**数据页**上做了什么**修改**\n        - binlog是**逻辑日志**，记录某个**语句的原始逻辑**\n        - 逻辑日志：**提供给别的引擎用**，是大家都能理解的逻辑，例如**搭建从库**\n        - 物理日志：**只能内部使用**，其他引擎无法共享内部的物理格式\n    - redolog是**循环写**，**空间固定**，**不能持久保存**，没有**归档**功能\n        - binlog是**追加写**，**空间不受限制**，有**归档**功能\n    - redolog主要用于**crash-safe**，原库恢复\n        - binlog主要用于恢复成**临时库**（从库）\n    - 崩溃恢复的过程**不写binlog**（可能需要**读binlog**，如果binlog有打开，一般都会打开）\n        - 用binlog恢复实例（从库），需要**写redolog**\n5. _**redolog支持事务的持久性，undolog支持事务的隔离性**_\n6. redolog对应用开发来说是**透明**的\n7. binlog有两种模式\n    - **statement格式**：SQL语句\n    - **row格式**：行内容（记两条，更新前和更新后），**推荐**\n        - 日志一样的可以用于**重放**\n\n```sql\nmysql> SHOW VARIABLES LIKE '%sql_log_bin%';\n+---------------+-------+\n| Variable_name | Value |\n+---------------+-------+\n| sql_log_bin   | ON    |\n+---------------+-------+\n```\n\n## update 内部流程\n浅色框在**InnoDB内部**执行，深色框在**执行器中**执行\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-innodb-update-procedure-1.jpg\" width=500/>\n\n\n1. 执行器先通过InnoDB获取id=2这一行，id是主键，InnoDB可以通过**聚簇索引**找到这一行\n    - 如果**id=2这一行所在的数据页**本来就在内存（**InnoDB Buffer Pool**）中，直接返回给执行器\n    - 否则先从磁盘读入内存，然后再返回\n2. 执行器拿到InnoDB返回的行数据，进行**+1**操作，得到新的一行数据，再调用InnoDB的引擎接口写入这行数据\n3. InnoDB首先将这行新数据**更新到内存**（**InnoDB Buffer Pool**）中，同时将这个更新操作**记录到redolog**（物理记录）\n    - 更新到内存中，在**事务提交后，后续的查询就可以直接在内存中读取该数据页**，但此时的数据可能**还没有真正落盘**\n        - 但在**事务提交前，其他事务是无法看到这个内存修改的**\n        - 而在**事务提交后，说明已经成功写入了redolog，可崩溃恢复，不会丢数据，因此可以直接读内存的数据**\n    - 刚更新的内存是不会删除的，除非内存不够用，在数据从内存删除之前，系统会保证它们已经落盘\n    - 此时redolog处于**prepare**状态（**prepare标签**），然后告诉执行器执行完成，**随时可以提交事务**\n        - 对其他事务来说，刚刚修改的内存是**不可见**的\n4. 执行器生成这个操作的**binlog**（**逻辑记录**）并写入磁盘\n    - **binlog写成功事务就算成功**，可以提交事务\n        - 哪怕崩溃恢复，也会恢复binlog写成功的事务（此时对应的redolog处于prepare状态）\n    - **binlog如果没写成功就回滚**，回滚会**写redolog**，打上**rollback标签**，binlog则会直接丢弃\n        - 如果binlog不丢弃，则会传播到从库\n5. 执行器调用InnoDB的**提交事务**接口，InnoDB把刚刚写入的redolog改成**commit**状态，更新完成\n    - redolog打上了**commit标签**\n    - commit表示两个日志都生效了\n    - commit完成后才会返回客户端\n\n[sync_binlog](https://dev.mysql.com/doc/refman/5.6/en/replication-options-binary-log.html#sysvar_sync_binlog)\n\n```sql\n# 0 -> Disables synchronization of the binary log to disk by the MySQL server\n#       Instead, the MySQL server relies on the operating system to flush the binary log to disk from time to time as it does for any other file\n#       This setting provides the best performance    \n# 1 -> Enables synchronization of the binary log to disk before transactions are committed\n#       This is the safest setting but can have a negative impact on performance due to the increased number of disk writes\n# N -> The binary log is synchronized to disk after N binary log commit groups have been collected\n#       A higher value improves performance, but with an increased risk of data loss\nmysql> SHOW VARIABLES LIKE '%sync_binlog%';\n+---------------+-------+\n| Variable_name | Value |\n+---------------+-------+\n| sync_binlog   | 0     |\n+---------------+-------+\n\n# 如果系统IO能扛得住，采用双1\nFor the greatest possible durability and consistency in a replication setup that uses InnoDB with transactions, use these settings:\nsync_binlog=1.\ninnodb_flush_log_at_trx_commit=1.\n\n# 实际中的线上环境可能会做一定的权衡，innodb_flush_log_at_trx_commit=2，sync_binlog=0\n# 最多丢失1s的redolog，丢失部分binlog\n```\n```\n# 归纳\ninnodb_flush_log_at_trx_commit\n    0 -> write+flush by second\n    1 -> write+flush by commit\n    2 -> write by commit, flush by second\n\nsync_binlog\n    0 -> rely on os\n    1 -> 1 commit\n    N -> N commit\n```\n\n### redolog的两阶段提交\n1. 目的：为了让redolog和binlog的**逻辑一致**\n2. 脑洞：假设不采用两阶段提交\n    - 有两种顺序：redolog->binlog，或者binlog->redolog\n    - 此时可以认为redolog和binlog**完全独立**\n        - _**崩溃恢复完全依赖于redolog（原库），恢复临时库完全依赖于binlog**_\n    - 按照上面的两种顺序，都会导致redolog和binlog逻辑上的不一致\n        - 假设原库crash后执行**原库恢复**+执行**临时库恢复**，恢复出来的数据是不一致的（主从不一致）\n3. 恢复清醒：两阶段提交（假设是**双1**的配置）\n    - redolog prepare + binlog成功，**提交事务**，崩溃恢复后也会继续提交事务（redolog commit），逻辑一致\n    - redolog prepare + binlog失败，**回滚事务**，崩溃恢复后也会继续回滚事务（redolog rollback），逻辑一致\n        - 一个事务的binlog是有**固定格式**的\n        - redolog与binlog是通过**事务id**（**XID**）进行**关联**的\n        - 此时binglog中没有对应的记录，事务记录是不完整的\n    - 崩溃恢复后是会从**checkpoint**开始往后主动刷数据\n4. 采用非双1的配置，在极端环境下会出现redolog与binlog**不一致**的情况\n    - **优先保证redolog**，先原库崩溃恢复，再处理从库（原库可以在崩溃恢复后，重新做一次**全量备份**，重建从库）\n\n#### redolog->binlog\n1. 反证：事务的**持久性**问题\n2. 对InnoDB而言，redolog有commit标签，代表这个事务不能再回滚\n3. 假若后续的binlog写失败了，此时**数据**与**binlog**是不一致的，**主从也不一致**\n\n#### 只有binlog\nbinlog是**逻辑日志**，没有记录数据页的更新细节，_**没有能力恢复数据页**_\n\n#### 只有redolog\n1. 如果仅从**崩溃恢复**的角度来说，**binlog是可以关掉的**\n    - 因为**崩溃恢复是redolog的功能**\n    - 此时没有两阶段提交，但系统依然是**crash-safe**的\n2. 但线上一般都会打开binlog，binlog有着redolog无法替代的功能\n    - 首先是**归档**功能，redolog是循环写，起不到归档的作用\n    - _**binlog复制：MySQL高可用的基础**_\n        - **主从复制**\n        - 异构系统（如数据分析系统）会**消费MySQL的binlog**来更新自己的数据\n\n## 崩溃恢复\n\n### 判断逻辑\n1. 如果redolog里面的事务是**完整**的，即已经有了**commit标签**，那么**直接提交**\n2. 如果redolog里面的事务只有**prepare**标签，则需要判断**事务对应的binlog是否存在并完整**\n    - a. 如果**是**，则**提交事务**\n    - b. 如果**否**，则**回滚事务**\n\n### redolog与binlog关联\n1. redolog和binlog有一个**共同的数据字段**：**XID**\n2. 崩溃恢复时，会按顺序扫描redolog\n    - 如果碰到既有prepare标签又有commit标签的redolog，就直接提交\n    - 如果碰到只有prepare标签但没有commit标签的redolog，就拿着对应的XID去binlog找对应的事务\n        - 后续需要校验事务对应的binlog的完整性\n\n### binlog的完整性\n1. binlog格式\n    - statement格式，最后会有`COMMMIT;`\n    - row格式，最后会有一个`XID Event`\n2. 从MySQL 5.6.2开始，引入了**binlog-checksum**，用于验证binlog内容的正确性\n    - binlog可能由于**磁盘原因**，在**日志中间**出错，MySQL可以通过校验checksum来发现\n\n## 异常重启\n\n### 时刻A\n1. 对应上面`2.b`的情况\n1. **redolog还未提交，binlog还未写**，在崩溃恢复时，事务会**回滚**\n2. 由于binlog还没写，也**不会传到备库**\n\n### 时刻B\n1. 对应上面的`2.a`的情况，崩溃恢复过程中事务会被提交\n2. 此时binlog已经写入了，之后会被**从库**或**临时库**使用\n    - 因此**主库**也需要提交这个事务，保证**主从一致**\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"MySQL -- 基础架构","url":"%2F2019%2F01%2F14%2Fmysql-architecture%2F","content":"\n## 查询语句\n```sql\nmysql> select * from T where ID=10;\n```\n\n## 基本架构\n<img src=\"https://mysql-1253868755.cos.ap-guangzhou.myqcloud.com/mysql-architecture.png\" width=400/>\n\n\n<!-- more -->\n\n1. 大体上，MySQL可以分为**Server层**和**存储引擎层**\n2. Server层包括**连接器、查询缓存、分析器、优化器和执行器**等\n    - 涵盖MySQL的**大多数核心服务功能**，以及**所有的内置函数**\n    - 所有的**跨存储引擎的功能**都在这一层实现，例如存储过程、触发器和视图等\n3. 存储引擎层负责**数据的存储和提取**，架构模式为**插件式**\n    - 支持InnoDB、MyISAM和Memory等存储引擎\n    - 最常用为**InnoDB**（Since 5.5.5，默认）\n\n## 连接器\n连接器负责跟客户端**建立连接、获取权限、维持和管理连接**，命令如下\n```\n$ mysql -h$host -P$port -u$user -p\n```\n\n### 权限\n- mysql是客户端工具，用来与服务端建立连接\n- 在完成TCP三次握手之后，连接器就要开始认证身份，即`-u`和`-p`\n    - 如果账号密码不对，客户端会收到`Access denied for user`的错误\n    - 如果账号密码认证通过，连接器会到**权限表**里查询拥有的权限\n        - 之后在**这个连接里**的权限判断，都**依赖于此时读取的权限**\n        - 因此即使用管理员账号对权限进行修改，也**不会影响到已经存在连接的权限**\n\n### 连接\n- 连接完成后，如果没有后续的动作，这个连接就会处于空闲状态\n    - 可以通过`show processlist`命令查看，`Command=Sleep`表示是一个**空闲连接**\n- 如果客户端太长时间没有动静，连接器会**自动将其断开**，有参数`wait_timeout`控制，默认为8小时\n- 如果在连接被断开之后，客户端再次发送请求后，会收到错误\n    - `Lost connection to MySQL server during query`\n    - 如果需要继续，就需要**重新连接**，然后再执行请求\n- 数据库层面的**长连接**和**短连接**\n    - 长连接：在连接成功后，如果客户端持续有请求，则一直使用同一连接\n        - 建立连接的过程比较复杂，推荐使用\n    - 短连接：每次执行完很少的**几次查询**后就会断开连接，下次查询再重新建立连接\n- 全部使用长连接后，MySQL的**占用内存**可能会**涨的很快**\n    - 原因：MySQL在执行过程中**临时使用的内存**是在**连接对象**里面管理的，而这些资源在**连接断开**时才会**释放**\n    - 如果长连接累计下来，可能会导致占用内存太大，因为**OOM**被系统强行Kill掉，表现为**MySQL异常重启**\n    - 解决方案\n        - 定期断开长连接。可以减少`wait_timeout`，或者在程序中判断是否执行过占用大内存的查询，然后断开连接\n        - 从MySQL 5.7开始，可以在每次执行较大的操作后，执行`mysql_reset_connection`来**初始化**连接资源\n            - 该过程不需要**重新建立连接**和**重新做权限校验**\n            - 只是会将连接**恢复**到**刚刚创建完**时的状态\n\n```\nmysql> show processlist;\n+---------+-------------+----------------------+-----------+---------+------+-------+------------------+\n| Id      | User        | Host                 | db        | Command | Time | State | Info             |\n+---------+-------------+----------------------+-----------+---------+------+-------+------------------+\n| 5649500 | live_prop_r | 192.168.30.55:38764  | live_prop | Sleep   |  327 |       | NULL             |\n| 5784362 | live_prop_r | 192.168.80.58:35068  | live_prop | Sleep   |  326 |       | NULL             |\n| 5785680 | live_prop_r | 192.168.80.58:41968  | live_prop | Sleep   |  326 |       | NULL             |\n| 5789440 | live_prop_r | 192.168.80.88:35896  | live_prop | Sleep   | 1030 |       | NULL             |\n| 5790469 | live_prop_r | 192.168.85.200:56204 | live_prop | Query   |    0 | init  | show processlist |\n+---------+-------------+----------------------+-----------+---------+------+-------+------------------+\n```\n```\n# 连接过程中的等待时间\nmysql> SHOW VARIABLES LIKE '%connect_timeout%';\n+-----------------+-------+\n| Variable_name   | Value |\n+-----------------+-------+\n| connect_timeout | 10    |\n+-----------------+-------+\n\n# 非交互式，连接完成后，使用过程中的等待时间\nmysql> show variables like 'wait_timeout';\n+---------------+-------+\n| Variable_name | Value |\n+---------------+-------+\n| wait_timeout  | 3600  |\n+---------------+-------+\n\n# 交互式，连接完成后，使用过程中的等待时间\nmysql> SHOW VARIABLES LIKE '%interactive_timeout%';\n+---------------------+-------+\n| Variable_name       | Value |\n+---------------------+-------+\n| interactive_timeout | 3600  |\n+---------------------+-------+\n```\n\n## 查询缓存\n- MySQL收到一个查询语句后，首先会查询缓存\n- 之前执行过的语句及其结果可能会以`Key-Value`的形式，被直接缓存在内存中\n    - Key：查询语句\n    - Value：查询结果\n- 如果能在缓存中找到这个Key，直接返回对应的Value\n- 否则，就会继续执行后续的执行阶段，执行完成后，执行结果会被存入查询缓存中\n- **查询缓存往往弊大于利**\n    - 查询缓存的**失效非常频繁**，只要有一个对表的**更新**操作，这个表上的**所有查询缓存**都会被**清空**\n    - 因此对**更新频繁**的场景来说，查询缓存的**命中率很低**\n    - 查询缓存比较适合**读多写极少**的场景，例如系统配置表\n- query_cache_type\n    - A value of 0 or **OFF** prevents caching or retrieval of cached results\n    - A value of 1 or **ON** enables caching except of those statements that begin with **SELECT SQL_NO_CACHE**\n    - A value of 2 or **DEMAND** causes caching of only those statements that begin with **SELECT SQL_CACHE**\n- MySQL 8.0删除掉了查询缓存这个功能\n\n[Query Cache Configuration](https://dev.mysql.com/doc/refman/5.6/en/query-cache-configuration.html)\n```\nmysql> SHOW VARIABLES LIKE '%query_cache%';\n+------------------------------+---------+\n| Variable_name                | Value   |\n+------------------------------+---------+\n| have_query_cache             | YES     |\n| query_cache_limit            | 1048576 |\n| query_cache_min_res_unit     | 4096    |\n| query_cache_size             | 0       |\n| query_cache_type             | OFF     |\n| query_cache_wlock_invalidate | OFF     |\n+------------------------------+---------+\n```\n\n## 分析器\n- 如果没有命中查询缓存，就要开始真正地执行语句\n- 分析器首先会做**词法分析**\n    - MySQL需要识别SQL语句里面的字符串是什么\n    - 通过`select`关键字识别出这是一个查询语句\n    - 将`T`识别成表名，将字符串`ID`识别成列名\n- 分析器会接着做**语法分析**\n    - 根据词法分析的结果，语法分析会根据**语法规则**，判断SQL是否满足MySQL语法\n    - 如果不满足，将会收到错误`You have an error in your SQL syntax`错误\n\n## 优化器\n- 经过**分析器**，MySQL已经能理解要**做什么**，在开始执行之前，需要经过**优化器**的处理，达到**怎么做**\n- 优化器会在表里存在多个索引的时候，选择使用哪个索引\n- 优化器也会在多表关联的时候，决定各个表的连接顺序\n- 优化器阶段完成后，语句的**执行方案**就已经能确定下来了，然后进入执行器阶段\n\n## 执行器\n- MySQL通过**分析器**能明白**做什么**，再通过**优化器**能明白**怎么做**，而**执行器**是负责语句的**具体执行**\n- 首先会判断是否有**执行权限**，如果没有就会返回权限错误，`SELECT command denied to user`\n    - 如果命中查询缓存，也会在查询缓存**返回**结果的时候，做权限验证\n    - 优化器之前也会调用**precheck**做验证权限\n- 如果有权限，那么将打开表继续执行\n    - 打开表的时候，执行器会根据表的引擎定义，去**调用引擎提供的接口**\n- 假设表T中，ID字段没有索引，执行器的执行流程如下\n    - 调用InnoDB的引擎接口，获取表的第一行，判断ID是否为10\n        - 如果不是则跳过，如果是则将这行存放在结果集中\n    - 调用引擎接口获取下一行，重复上面的判断逻辑，直到获取到表的最后一行\n    - 执行器将上面遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端\n- **rows_examined**\n    - 数据库的慢查询日志会有`rows_examined`字段\n    - 在执行器每次调用引擎获取数据行的时候**累加**的（+1）\n    - 有些场景，执行器调用一次，但在引擎内部则是扫描了很多行\n        - 例如在InnoDB中，**一页有很多行数据**\n    - 因此，**引擎扫描行数（引擎内部真正扫描的次数）跟rows_examined并不完全相同**\n\n[The Slow Query Log](https://dev.mysql.com/doc/refman/5.6/en/slow-query-log.html)\n```\nmysql> SHOW VARIABLES LIKE '%slow_query%';\n+---------------------+-----------------------------------------------------+\n| Variable_name       | Value                                               |\n+---------------------+-----------------------------------------------------+\n| slow_query_log      | ON                                                  |\n| slow_query_log_file | /data_db3/mysql/3323/slowlog/slowlog_2019011423.log |\n+---------------------+-----------------------------------------------------+\n\nSET GLOBAL log_timestamps = SYSTEM;\n```\n\n## 参考资料\n《MySQL实战45讲》\n\n<!-- indicate-the-source -->\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"JVM进阶 -- 浅谈Java Agent","url":"%2F2019%2F01%2F12%2Fjvm-advanced-agent%2F","content":"\n## Java Agent的运行方式\n1. JVM并**不会限制Java Agent的数量**\n    - 可以在JVM参数中包含多个-javaagent参数\n    - 也可以远程attach多个Java Agent\n2. JVM会按照参数的顺序或者attach的顺序，逐个执行Java Agent\n3. JRebal/Btrace/arthas等工具都是基于Java Agent实现的\n\n### premain\n以**JVM参数**（-javaagent）的方式启动，在Java程序的main方法执行之前执行\n\n<!-- more -->\n\n#### MyAgent\n```java\npackage me.zhongmingmao;\n\npublic class MyAgent {\n    // JVM能识别的premain方法接收的是字符串类型的参数，并非类似main方法的字符串数组\n    public static void premain(String args) {\n        System.out.println(\"premain\");\n    }\n}\n```\n\n#### manifest.txt\n```\n# 写入两行数据，最后一行为空行\n$ echo 'Premain-Class: me.zhongmingmao.MyAgent\n' > manifest.txt\n\n$ tree\n.\n├── manifest.txt\n└── me\n    └── zhongmingmao\n        └── MyAgent.java\n```\n\n#### 编译打包\n```\n$ javac me/zhongmingmao/MyAgent.java\n\n$ jar cvmf manifest.txt myagent.jar me/\n已添加清单\n正在添加: me/(输入 = 0) (输出 = 0)(存储了 0%)\n正在添加: me/zhongmingmao/(输入 = 0) (输出 = 0)(存储了 0%)\n正在添加: me/zhongmingmao/MyAgent.class(输入 = 399) (输出 = 285)(压缩了 28%)\n正在添加: me/zhongmingmao/MyAgent.java(输入 = 142) (输出 = 114)(压缩了 19%)\n```\n\n#### HelloWorld\n```java\npackage helloworld;\n\nimport java.util.concurrent.TimeUnit;\n\npublic class HelloWorld {\n    public static void main(String[] args) throws InterruptedException {\n        System.out.println(\"Hello World\");\n        TimeUnit.MINUTES.sleep(1);\n    }\n}\n```\n\n#### 编译运行\n```\n$ javac helloworld/HelloWorld.java\n\n$ java -javaagent:myagent.jar helloworld.HelloWorld\npremain\nHello World\n```\n\n### agentmain\n1. 以**Attach**的方式启动，在Java程序启动后运行，利用VirtualMachine的**Attach API**\n2. Attach API其实是**Java进程之间**的沟通桥梁，底层通过**Socket**进行通信\n3. jps/jmap/jinfo/jstack/jcmd均依赖于Attach API\n\n#### MyAgent\n```java\npackage me.zhongmingmao;\n\npublic class MyAgent {\n    public static void agentmain(String args) {\n        System.out.println(\"agentmain\");\n    }\n}\n```\n\n#### manifest.txt\n```\n# 改为Agent-Class\n$ echo 'Agent-Class: me.zhongmingmao.MyAgent\n' > manifest.txt\n\n$ tree\n.\n├── manifest.txt\n└── me\n    └── zhongmingmao\n        └── MyAgent.java\n```\n\n#### 编译打包\n```\n$ javac me/zhongmingmao/MyAgent.java\n\n$ jar cvmf manifest.txt myagent.jar me/\n已添加清单\n正在添加: me/(输入 = 0) (输出 = 0)(存储了 0%)\n正在添加: me/zhongmingmao/(输入 = 0) (输出 = 0)(存储了 0%)\n正在添加: me/zhongmingmao/MyAgent.class(输入 = 401) (输出 = 285)(压缩了 28%)\n正在添加: me/zhongmingmao/MyAgent.java(输入 = 146) (输出 = 115)(压缩了 21%)\n```\n\n#### AttachTest\n```java\nimport com.sun.tools.attach.VirtualMachine;\n\npublic class AttachTest {\n    public static void main(String[] args) throws Exception {\n        if (args.length <= 1) {\n            System.out.println(\"Usage: java AttachTest <PID> /PATH/TO/AGENT.jar\");\n            return;\n        }\n        String pid = args[0];\n        String agent = args[1];\n        // Attach API\n        VirtualMachine vm = VirtualMachine.attach(pid);\n        vm.loadAgent(agent);\n    }\n}\n```\n编译AttachTest\n```\n# 指定classpath\n$ javac -cp ~/.sdkman/candidates/java/current/lib/tools.jar AttachTest.java\n```\n\n#### 运行HelloWorld\n```\n$ java helloworld.HelloWorld\n\n$ jps\n23386 HelloWorld\n23387 Jps\n```\n\n#### 运行AttachTest\n```\n$ java -cp ~/.sdkman/candidates/java/current/lib/tools.jar:. AttachTest 23386 PATH_TO_AGENT/myagent.jar\n```\n```\n# HelloWorld进程继续输出agentmain\nHello World\nagentmain\n```\n\n## Java Agent的功能\n1. ClassFileTransformer用于拦截**类加载**事件，需要注册到Instrumentation\n2. Instrumentation.**redefineClasses**\n    - 针对**已加载**的类，**舍弃原本的字节码**，替换为由用户提供的byte数组\n    - 功能比较**危险**，一般用于修复出错的字节码\n3. Instrumentation.**retransformClasses**\n    - 针对**已加载**的类，重新调用**所有已注册**的ClassFileTransformer的transform方法，两个场景\n    - 在执行premain和agentmain方法前，JVM**已经加载了不少类**\n        - 而这些类的加载事件并没有被拦截并执行相关的注入逻辑\n    - 定义了多个Java Agent，多个注入的情况，可能需要**移除其中的部分注入**\n        - 调用**Instrumentation.removeTransformer**去除某个注入类后，可以调用retransformClasses\n        - 重新从**原始byte**数组开始进行注入\n4. Java Agent的功能是通过**JVMTI** Agent（C Agent），JVMTI是一个**事件驱动**的工具实现接口\n    - 通常会在C Agent加载后的方法入口Agent_OnLoad处注册各种事件的钩子方法\n    - 当JVM触发这些事件时，便会调用对应的钩子方法\n    - 例如可以为JVMTI中的**ClassFileLoadHook**事件设置钩子，从而在C层面**拦截所有的类加载事件**\n\n### 获取魔数\n\n#### MyAgent\n```java\npackage me.zhongmingmao;\n\nimport java.lang.instrument.ClassFileTransformer;\nimport java.lang.instrument.IllegalClassFormatException;\nimport java.lang.instrument.Instrumentation;\nimport java.security.ProtectionDomain;\n\npublic class MyAgent {\n    public static void premain(String args, Instrumentation instrumentation) {\n        // 通过instrumentation来注册类加载事件的拦截器（实现ClassFileTransformer.transform）\n        instrumentation.addTransformer(new MyTransformer());\n    }\n\n    static class MyTransformer implements ClassFileTransformer {\n        @Override\n        public byte[] transform(ClassLoader loader, String className, Class<?> classBeingRedefined,\n                                ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException {\n            // 返回的byte数组，代表更新后的字节码\n            // 当transform方法返回时，JVM会使用返回的byte数组来完成接下来的类加载工作\n            // 如果transform方法返回null或者抛出异常，JVM将使用原来的byte数组来完成类加载工作\n            // 基于类加载事件的拦截功能，可以实现字节码注入（Bytecode instrumentation），往正在被加载的类插入额外的字节码\n            System.out.printf(\"Loaded %s: 0x%X%X%X%X\\n\", className,\n                    classfileBuffer[0], classfileBuffer[1], classfileBuffer[2], classfileBuffer[3]);\n            return null;\n        }\n    }\n}\n```\n\n#### 编译运行\n```\n$ java -javaagent:myagent.jar helloworld.HelloWorld\n...\nLoaded helloworld/HelloWorld: 0xCAFEBABE\nHello World\n...\nLoaded java/lang/Shutdown: 0xCAFEBABE\nLoaded java/lang/Shutdown$Lock: 0xCAFEBABE\n```\n\n### ASM注入字节码\n通过ASM注入字节码可参考[Instrumenting Java Bytecode with ASM](http://web.cs.ucla.edu/~msb/cs239-tutorial/)\n\n#### MyAgent\n```java\npackage me.zhongmingmao;\n\nimport org.objectweb.asm.ClassReader;\nimport org.objectweb.asm.ClassWriter;\nimport org.objectweb.asm.Opcodes;\nimport org.objectweb.asm.tree.*;\n\nimport java.lang.instrument.ClassFileTransformer;\nimport java.lang.instrument.IllegalClassFormatException;\nimport java.lang.instrument.Instrumentation;\nimport java.security.ProtectionDomain;\n\npublic class MyAgent {\n    public static void premain(String args, Instrumentation instrumentation) {\n        instrumentation.addTransformer(new MyTransformer());\n    }\n\n    static class MyTransformer implements ClassFileTransformer, Opcodes {\n        @Override\n        public byte[] transform(ClassLoader loader, String className, Class<?> classBeingRedefined,\n                                ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException {\n            // 将classfileBuffer转换为ClassNode\n            ClassReader classReader = new ClassReader(classfileBuffer);\n            ClassNode classNode = new ClassNode(ASM7);\n            classReader.accept(classNode, ClassReader.SKIP_FRAMES);\n\n            // 遍历ClassNode的MethodNode节点，即构造器和方法\n            for (MethodNode methodNode : classNode.methods) {\n                // 在main方法入口处注入System.out.println(\"Hello Instrumentation\");\n                if (\"main\".equals(methodNode.name)) {\n                    InsnList instrumentation = new InsnList();\n                    instrumentation.add(new FieldInsnNode(GETSTATIC, \"java/lang/System\", \"out\", \"Ljava/io/PrintStream;\"));\n                    instrumentation.add(new LdcInsnNode(\"Hello, Instrumentation!\"));\n                    instrumentation.add(new MethodInsnNode(INVOKEVIRTUAL, \"java/io/PrintStream\", \"println\", \"(Ljava/lang/String;)V\", false));\n                    methodNode.instructions.insert(instrumentation);\n                }\n            }\n\n            ClassWriter classWriter = new ClassWriter(ClassWriter.COMPUTE_FRAMES | ClassWriter.COMPUTE_MAXS);\n            classNode.accept(classWriter);\n            return classWriter.toByteArray();\n        }\n    }\n}\n```\n编译MyAgent\n```\n$ javac -cp PATH_TO_ASM/asm-7.0.jar:PATH_TO_ASM_TREE/asm-tree-7.0.jar me/zhongmingmao/MyAgent.java\n```\n\n#### 运行\n```\n$ java -javaagent:myagent.jar -cp PATH_TO_ASM/asm-7.0.jar:PATH_TO_ASM_TREE/asm-tree-7.0.jar:. helloworld.HelloWorld\nHello, Instrumentation!\nHello World\n```\n\n## 基于字节码注入的profiler\n\n### 统计新建实例数量\n\n#### MyProfiler\n```java\npackage me.zhongmingmao;\n\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.atomic.AtomicInteger;\n\npublic class MyProfiler {\n    // 统计每个类所新建实例的数目\n    public static ConcurrentHashMap<Class<?>, AtomicInteger> data = new ConcurrentHashMap<>();\n\n    public static void fireAllocationEvent(Class<?> klass) {\n        data.computeIfAbsent(klass, kls -> new AtomicInteger()).incrementAndGet();\n    }\n\n    public static void dump() {\n        data.forEach((kls, counter) -> System.err.printf(\"%s: %d\\n\", kls.getName(), counter.get()));\n    }\n\n    static {\n        Runtime.getRuntime().addShutdownHook(new Thread(MyProfiler::dump));\n    }\n}\n```\n\n#### MyAgent\n```java\npackage me.zhongmingmao;\n\nimport org.objectweb.asm.ClassReader;\nimport org.objectweb.asm.ClassWriter;\nimport org.objectweb.asm.Opcodes;\nimport org.objectweb.asm.Type;\nimport org.objectweb.asm.tree.*;\n\nimport java.lang.instrument.ClassFileTransformer;\nimport java.lang.instrument.IllegalClassFormatException;\nimport java.lang.instrument.Instrumentation;\nimport java.security.ProtectionDomain;\n\npublic class MyAgent {\n    public static void premain(String args, Instrumentation instrumentation) {\n        instrumentation.addTransformer(new MyTransformer());\n    }\n\n    static class MyTransformer implements ClassFileTransformer, Opcodes {\n        @Override\n        public byte[] transform(ClassLoader loader, String className, Class<?> classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException {\n            if (className.startsWith(\"java\") ||\n                    className.startsWith(\"javax\") ||\n                    className.startsWith(\"jdk\") ||\n                    className.startsWith(\"sun\") ||\n                    className.startsWith(\"com/sun\") ||\n                    className.startsWith(\"me/zhongmingmao\")) {\n                // Skip JDK classes and profiler classes\n                // 避免循环引用，从而导致StackOverflowException\n                return null;\n            }\n\n            ClassReader classReader = new ClassReader(classfileBuffer);\n            ClassNode classNode = new ClassNode(ASM7);\n            classReader.accept(classNode, ClassReader.SKIP_FRAMES);\n\n            for (MethodNode methodNode : classNode.methods) {\n                // 遍历方法内的指令\n                for (AbstractInsnNode node : methodNode.instructions.toArray()) {\n                    if (node.getOpcode() == NEW) {\n                        // 在每条new指令后插入对fireAllocationEvent方法的调用\n                        TypeInsnNode typeInsnNode = (TypeInsnNode) node;\n                        InsnList instrumentation = new InsnList();\n                        instrumentation.add(new LdcInsnNode(Type.getObjectType(typeInsnNode.desc)));\n                        instrumentation.add(new MethodInsnNode(INVOKESTATIC, \"me/zhongmingmao/MyProfiler\", \"fireAllocationEvent\", \"(Ljava/lang/Class;)V\", false));\n                        methodNode.instructions.insert(node, instrumentation);\n                    }\n                }\n            }\n\n            ClassWriter classWriter = new ClassWriter(ClassWriter.COMPUTE_FRAMES | ClassWriter.COMPUTE_MAXS);\n            classNode.accept(classWriter);\n            return classWriter.toByteArray();\n        }\n    }\n}\n```\n\n#### ProfilerMain\n```java\npublic class ProfilerMain {\n    public static void main(String[] args) {\n        String s = \"\";\n        for (int i = 0; i < 10; i++) {\n            s = new String(\"\" + i);\n        }\n        Integer i = 0;\n        for (int j = 0; j < 20; j++) {\n            i = new Integer(j);\n        }\n    }\n}\n```\n\n#### 运行\n```\n$ java -javaagent:myagent.jar -cp PATH_TO_ASM/asm-7.0.jar:PATH_TO_ASM_TREE/asm-tree-7.0.jar:. ProfilerMain\njava.lang.StringBuilder: 10\njava.lang.String: 10\njava.lang.Integer: 20\n```\n\n### 命名空间\n1. 不少应用程序都依赖于ASM工程，当注入逻辑依赖于ASM时\n    - 可能会出现注入使用最新版的ASM，而应用程序本身使用的是较低版本的ASM\n2. JDK本身也使用了ASM库，例如用来生成Lambda表达式的适配器，JDK的做法是**重命名**整个ASM库\n    - 为所有类的包名添加**jdk.internal**前缀\n3. 还有另外一个方法是借助**自定义类加载器**来隔离命名空间\n\n### 观察者效应\n1. 例如字节码注入收集每个方法的运行时间\n    - 假设某个方法调用了另一个方法，而这个两个方法都被注入了\n    - 那么统计被调用者运行时间点注入代码所耗费的时间，将不可避免地被计入至调用者方法的运行时间之中\n2. 统计新建对象数量\n    - 即时编译器的逃逸分析可能会优化掉新建对象操作，但它并不会消除相关的统计操作\n    - 因此会统计到**实际没有发生**的新建对象操作\n3. 因此当使用字节码注入开发profiler，**仅能表示在被注入的情况下程序的执行状态**\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Advanced"]},{"title":"JVM进阶 -- 浅谈JNI","url":"%2F2019%2F01%2F12%2Fjvm-advanced-jni%2F","content":"\n## native方法\n```java\npublic class Object {\n    public native int hashCode();\n}\n```\n当Java代码调用native方法时，JVM将通过**JNI**，调用至对应的C函数\nObject.hashCode()就是一个native方法，对应的C函数将计算对象的哈希值，并缓存在**对象头**、**栈上锁记录**（轻量级锁）或者**对象监视锁**（重量级锁，monitor）中，以确保该值在**对象的生命周期之内不会变更**\n\n<!-- more -->\n\n## 链接方式\n在调用native方法之前，JVM需要将该native方法链接至对应的C函数上\n\n### 自动链接\nJVM自动查找符合**默认命名规范**的C函数，并且链接起来\n\n#### Java代码\n```java\npackage me.zhongmingmao.advanced.jni;\n\npublic class Foo {\n    int i = 0xDEADBEEF;\n    public static native void foo();\n    public native void bar(int i, long j);\n    public native void bar(String s, Object o);\n}\n```\n\n#### 生成C头文件\n```c\n$ javac -h . me/zhongmingmao/advanced/jni/Foo.java\n\n$ cat me_zhongmingmao_advanced_jni_Foo.h\n/* DO NOT EDIT THIS FILE - it is machine generated */\n#include <jni.h>\n/* Header for class me_zhongmingmao_advanced_jni_Foo */\n\n#ifndef _Included_me_zhongmingmao_advanced_jni_Foo\n#define _Included_me_zhongmingmao_advanced_jni_Foo\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n/*\n * Class:     me_zhongmingmao_advanced_jni_Foo\n * Method:    foo\n * Signature: ()V\n */\nJNIEXPORT void JNICALL Java_me_zhongmingmao_advanced_jni_Foo_foo\n  (JNIEnv *, jclass);\n\n/*\n * Class:     me_zhongmingmao_advanced_jni_Foo\n * Method:    bar\n * Signature: (IJ)V\n */\nJNIEXPORT void JNICALL Java_me_zhongmingmao_advanced_jni_Foo_bar__IJ\n  (JNIEnv *, jobject, jint, jlong);\n\n/*\n * Class:     me_zhongmingmao_advanced_jni_Foo\n * Method:    bar\n * Signature: (Ljava/lang/String;Ljava/lang/Object;)V\n */\nJNIEXPORT void JNICALL Java_me_zhongmingmao_advanced_jni_Foo_bar__Ljava_lang_String_2Ljava_lang_Object_2\n  (JNIEnv *, jobject, jstring, jobject);\n\n#ifdef __cplusplus\n}\n#endif\n#endif\n```\n1. native方法对应的C函数都需要以**Java_**为前缀，之后跟着完整的**包名**、**方法名**（和**方法描述符**）\n2. C函数名不支持/字符，/字符会被转换为_，原本方法名中的 _ 字符，转换为_1\n3. 当某个类出现**重载的native方法**时，JVM会将**参数类型**纳入自动链接对象的考虑范围之中\n    - 在前面C函数名的基础上，追加__以及**方法描述符**作为后缀\n    - 方法描述符中的**特殊符**号同样会被替换：\n        - 分隔符/被替换为_\n        - 引用类型所使用的;被替换为\\_2\n        - 数组类型所使用的[被替换为_3\n\n### 主动链接\n这种链接方式对C函数名没有要求，通常会使用一个名为`registerNatives`的native方法，该方法还是会按照**自动链接**的方式链接到对应的C函数，然后在`registerNatives`对应的C函数中，**手动链接该类的其他native方法**\n```java\npublic class Object {\n    // 自动链接\n    private static native void registerNatives();\n    static {\n        registerNatives();\n    }\n    public final native Class<?> getClass();\n\n    // 主动链接\n    public native int hashCode();\n    public final native void wait(long timeout) throws InterruptedException;\n    public final native void notify();\n    public final native void notifyAll();\n    protected native Object clone() throws CloneNotSupportedException;\n}\n```\n```c\nstatic JNINativeMethod methods[] = {\n    {\"hashCode\",    \"()I\",                    (void *)&JVM_IHashCode},\n    {\"wait\",        \"(J)V\",                   (void *)&JVM_MonitorWait},\n    {\"notify\",      \"()V\",                    (void *)&JVM_MonitorNotify},\n    {\"notifyAll\",   \"()V\",                    (void *)&JVM_MonitorNotifyAll},\n    {\"clone\",       \"()Ljava/lang/Object;\",   (void *)&JVM_Clone},\n};\n\nJNIEXPORT void JNICALL\nJava_java_lang_Object_registerNatives(JNIEnv *env, jclass cls)\n{\n    (*env)->RegisterNatives(env, cls,\n                            methods, sizeof(methods)/sizeof(methods[0]));\n}\n\nJNIEXPORT jclass JNICALL\nJava_java_lang_Object_getClass(JNIEnv *env, jobject this)\n{\n    if (this == NULL) {\n        JNU_ThrowNullPointerException(env, NULL);\n        return 0;\n    } else {\n        return (*env)->GetObjectClass(env, this);\n    }\n}\n```\nC函数将调用**RegisterNatives API**，注册Object类中其他native方法（不包括getClass）所要链接的C函数，这些C函数的函数名并**不符合默认的命名规则**，详细的C代码请查阅[Object.c](http://hg.openjdk.java.net/jdk8u/jdk8u60/jdk/file/afbc08ea922b/src/share/native/java/lang/Object.c)\n\n## 实现native方法\n\n### C实现\n```c\n// foo.c\n#include <stdio.h>\n#include \"me_zhongmingmao_advanced_jni_Foo.h\"\n\nJNIEXPORT void JNICALL Java_me_zhongmingmao_advanced_jni_Foo_bar__Ljava_lang_String_2Ljava_lang_Object_2\n  (JNIEnv *env, jobject thisObject, jstring str, jobject obj) {\n    printf(\"Hello, World\\n\");\n    return;\n}\n```\n\n### 动态链接库\n通过**gcc**命令将其编译成**动态链接库**，动态链接库的名字必须以**lib**为前缀，以**.dylib**（Linux上为**.so**）为扩展名\n```\n$ gcc -I$JAVA_HOME/include -I$JAVA_HOME/include/darwin -o libfoo.dylib -shared foo.c\n```\n\n### 调用\n```java\n// -Djava.library.path=$PATH_TO_DYLIB\npublic static void main(String[] args) {\n    try {\n        System.loadLibrary(\"foo\");\n    } catch (UnsatisfiedLinkError e) {\n        e.printStackTrace();\n        System.exit(1);\n    }\n    new Foo().bar(\"\", \"\");\n}\n```\n```\n$ java -Djava.library.path=$PATH_TO_DYLIB me.zhongmingmao.advanced.jni.Foo\nHello, World\n```\n\n## JNI API\n1. JVM会将**所有JNI函数的函数指针**聚合到一个名为**JNIEnv**的数据结构中\n2. JNIEnv是一个**线程私有**的数据结构，JVM会为每个线程创建一个JNIEnv\n    - 并且规定C代码不能将当前线程的JNIEnv共享给其他线程，否则**无法保证JNI函数的正确性**\n3. JNIEnv采用线程私有的设计原因\n    - 给**JNI函数**提供一个**单独的命名空间**\n    - 允许JVM通过**更改函数指针**来的方式来**替换**JNI函数的**具体实现**\n\n### 类型映射关系\nJNI会将Java层面的**基本类型**以及**引用类型**映射为另一套可供C代码使用的**数据结构**\n\n#### 基本类型\n```\nJava类型     C数据结构\n--------------------\nboolean     jboolean\nbyte        jbyte\nchar        jchar\nshort       jshort\nint         jint\nlong        jlong\nfloat       jfloat\ndouble      jdouble\nvoid        jvoid\n```\n\n#### 引用类型\n引用类型对应的数据结构之间也存在**继承**关系\n```\njobject\n|- jclass (java.lang.Class objects)\n|- jstring (java.lang.String objects)\n|- jthrowable (java.lang.Throwable objects)\n|- jarray (arrays)\n   |- jobjectArray (object arrays)\n   |- jbooleanArray (boolean arrays)\n   |- jbyteArray (byte arrays)\n   |- jcharArray (char arrays)\n   |- jshortArray (short arrays)\n   |- jintArray (int arrays)\n   |- jlongArray (long arrays)\n   |- jfloatArray (float arrays)\n   |- jdoubleArray (double arrays)\n```\n\n### 头文件解析\n```c\n/*\n * Class:     me_zhongmingmao_advanced_jni_Foo\n * Method:    foo\n * Signature: ()V\n */\nJNIEXPORT void JNICALL Java_me_zhongmingmao_advanced_jni_Foo_foo\n  (JNIEnv *, jclass);\n\n/*\n * Class:     me_zhongmingmao_advanced_jni_Foo\n * Method:    bar\n * Signature: (IJ)V\n */\nJNIEXPORT void JNICALL Java_me_zhongmingmao_advanced_jni_Foo_bar__IJ\n  (JNIEnv *, jobject, jint, jlong);\n\n/*\n * Class:     me_zhongmingmao_advanced_jni_Foo\n * Method:    bar\n * Signature: (Ljava/lang/String;Ljava/lang/Object;)V\n */\nJNIEXPORT void JNICALL Java_me_zhongmingmao_advanced_jni_Foo_bar__Ljava_lang_String_2Ljava_lang_Object_2\n  (JNIEnv *, jobject, jstring, jobject);\n```\n1. 静态native方法foo接收两个参数\n    - 一个为**JNIEnv**指针（聚合JNI函数的函数指针）\n    - 另一个是**jclass**参数（用来指代**定义该native方法的类**）\n2. 实例native方法bar的第二个参数为**jobject**类型，**用来指代该native方法的调用者**\n3. 如果native方法声明了参数，那么对应的C函数也将会接收这些参数（映射为对应的C数据结构）\n\n### 获取实例字段\n修改C代码，获取Foo类实例的i字段\n```java\nJNIEXPORT void JNICALL Java_me_zhongmingmao_advanced_jni_Foo_bar__Ljava_lang_String_2Ljava_lang_Object_2\n  (JNIEnv *env, jobject thisObject, jstring str, jobject obj) {\n    // JNI中访问实例字段的方式类似于JAVA的反射API\n    jclass cls = (*env)->GetObjectClass(env, thisObject);\n    jfieldID fieldID = (*env)->GetFieldID(env, cls, \"i\", \"I\");\n    jint value = (*env)->GetIntField(env, thisObject, fieldID);\n    printf(\"Hello, World 0x%x\\n\", value);\n    return;\n}\n```\n```\n$ java -Djava.library.path=$PATH_TO_DYLIB me.zhongmingmao.advanced.jni.Foo\nHello, World 0xdeadbeef\n```\n如果尝试获取**不存在**的实例字段j，会抛出异常\n```\n$ java -Djava.library.path=$PATH_TO_DYLIB me.zhongmingmao.advanced.jni.Foo\nHello, World 0x1\nException in thread \"main\" java.lang.NoSuchFieldError: j\n        at me.zhongmingmao.advanced.jni.Foo.bar(Native Method)\n        at me.zhongmingmao.advanced.jni.Foo.main(Foo.java:19)\n```\n1. 当调用JNI函数的过程中，**JVM会生成相关的异常实例**，并**缓存**在内存的某一个位置\n2. 但与Java编程不一样的是，它不会显式地跳转至异常处理器或者调用者，而是**继续执行**接下来的C代码\n3. 因此，当从**可能触发异常**的JNI函数返回时，需要通过JNI函数**ExceptionOccurred**来检查是否发生了异常\n4. 如果无须抛出该异常，需要通过JNI函数**ExceptionClear**显式地**清空已缓存的异常实例**\n\n```c\nJNIEXPORT void JNICALL Java_me_zhongmingmao_advanced_jni_Foo_bar__Ljava_lang_String_2Ljava_lang_Object_2\n  (JNIEnv *env, jobject thisObject, jstring str, jobject obj) {\n    // JNI中访问实例字段的方式类似于JAVA的反射API\n    jclass cls = (*env)->GetObjectClass(env, thisObject);\n    jfieldID fieldID = (*env)->GetFieldID(env, cls, \"j\", \"I\");\n    if((*env)->ExceptionOccurred(env)) {\n        printf(\"Exception!\\n\");\n        (*env)->ExceptionClear(env);\n    }\n    fieldID = (*env)->GetFieldID(env, cls, \"i\", \"I\");\n    jint value = (*env)->GetIntField(env, thisObject, fieldID);\n    // we should put an exception guard here as well.\n    printf(\"Hello, World 0x%x\\n\", value);\n    return;\n}\n```\n```\n$ java -Djava.library.path=$PATH_TO_DYLIB me.zhongmingmao.advanced.jni.Foo\nException!\nHello, World 0xdeadbeef\n```\n\n## 句柄与性能\n\n### 背景\n1. 在**C代码**中，既可以**访问所传入的引用类型参数**，也可以**通过JNI函数创建新的Java对象**\n2. 这些**Java对象**也会**受到GC的影响**，因此JVM需要一种机制，来告知GC算法：**不要回收这些C代码中可能引用到的Java对象**\n3. 该机制就是**局部引用**和**全局引用**，GC算法会将这两种引用指向的对象标记为**不可回收**\n\n### 局部引用与全局引用\n1. 局部引用\n    - **传入的引用类型参数**，\n    - 通过**JNI函数返回的引用类型参数**（除NewGlobalRef和NewWeakGlobalRef）\n2. 一旦**从C函数返回至Java方法**之中，那么**局部引用将失效**\n    - 因此**不能缓存局部引用**，以供**另一个C线程**或**下一次native方法调用**时使用\n    - 因此，可以借助JNI函数**NewGlobalRef**，将局部引用转换为**全局引用**，以确保其指向的Java对象不会被垃圾回收\n    - 相应的，可以通过JNI函数**DeleteGlobalRef**来消除**全局引用**，以便回收被全局引用指向的Java对象\n3. 如果C函数**运行时间极长**，可以通过JNI函数**DeleteLocalRef**来消除**不再使用的局部引用**，以便回收被引用的Java对象\n\n### 句柄\n1. 由于**垃圾回收器**可能会**移动对象在内存中的位置**，因此JVM需要另一种机制\n    - 保证**局部引用**或**全局引用**将**正确地指向移动后的对象**，HotSpot通过**句柄**的方式来实现\n    - 句柄：**Java对象指针的指针**\n    - 当发生GC时，如果Java对象被移动了，那么句柄指向的指针也将发生变动，但**句柄本身保持不变**\n2. 无论**局部引用**还是**全局引用**，都是**句柄**\n3. 局部引用所对应的句柄有两种**存储方式**\n    - 一种是在**本地方法栈帧**中，主要用于存储**C函数所接收的来自Java层面的引用类型参数**\n    - 另一种是**线程私有的句柄块**，主要用于存储**C函数运行过程中创建的局部引用**\n4. 当**从C函数返回至Java方法**时\n    - 本地方法栈帧中的句柄将被**自动清除**\n    - 线程私有句柄块则需要由**JVM显式清除**\n5. JNI调用的**额外性能开销**\n    - 进入C函数时对引用类型参数的**句柄化**\n    - **调整参数位置**（C调用和Java调用传参的方式不一样）\n    - 从C函数返回时**清理线程私有句柄块**\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Advanced"]},{"title":"JVM进阶 -- MAT","url":"%2F2019%2F01%2F10%2Fjvm-advanced-gui-mat%2F","content":"\n## 概念\n\n### Shallow Heap + Retained Heap\n\n#### Shallow Heap\nShallow heap is the **memory consumed by one object**. An object needs 32 or 64 bits (depending on the OS architecture) per reference, 4 bytes per Integer, 8 bytes per Long, etc. Depending on the heap dump format the size may be adjusted (e.g. aligned to 8, etc...) to model better the real consumption of the VM.\n\n#### Retained Set\nRetained set of X is the set of objects which would be removed by GC when X is garbage collected.\n\n#### Retained Heap\nRetained heap of X is the **sum of shallow sizes of all objects in the retained set of X**, i.e. memory kept alive by X.\nGenerally speaking, shallow heap of an object is its size in the heap and retained size of the same object is the **amount of heap memory that will be freed when the object is garbage collected**.\n\n<!-- more -->\n\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-mat-shallow-retained.png\" />\nThe **Minimum Retained Size** gives a good (under)estimation of the retained size which is calculated ways **faster** than the exact retained size of a set of objects. It only depends on the number of objects in the **inspected set**, not the number of objects in the heap dump.\n\n### Dominator Tree\nMemory Analyzer provides a dominator tree of the object graph. The transformation of the object reference graph into a dominator tree allows you to easily identify the **biggest chunks of retained memory** and the **keep-alive dependencies among objects**.\n\n#### Dominate\nAn object x dominates an object y if **every path** in the **object graph** from the start (or the root) node to y **must** go through x.\n\n#### Immediate Dominator\nThe immediate dominator x of some object y is the dominator **closest** to the object y.\n\n#### Properties\n1. The objects belonging to the **sub-tree** of x (i.e. the objects dominated by x) represent the **retained set** of x.\n2. If x is the immediate dominator of y , then the immediate dominator of x also dominates y , and so on.\n3. The edges in the dominator tree **do not directly** correspond to object references from the object graph.\n\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-mat-dominator-tree.png\" />\nA dominator tree is built out of the object graph. In the dominator tree each object is the **immediate dominator** of its **children**, so dependencies between the objects are easily identified.\n\n## Overview\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-mat-overview.png\" />\n\n## Dominator Tree\n\n### No Grouping(Objects)\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-mat-dominator-tree-object.png\" />\n\n### Group By Class\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-mat-dominator-tree-class.png\" />\n\n### Group By Class Loader\n纬度：组件\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-mat-dominator-tree-classloader.png\" />\n\n### Group By Package\n纬度：自身编写的代码\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-mat-dominator-tree-package.png\" />\n\n### Path To GC Roots\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-mat-dominator-tree-path-to-root.png\" />\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-mat-dominator-tree-path-to-root-1.png\" />\n\n\n## Histogram\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-mat-histogram.png\" />\nMAT默认按**Shallow Heap**倒排，手动选择按**Retained Heap**倒排，排第一的是**Ehcache**的**OnHeapStore**类\n\n### List objects\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-mat-histogram-object-incoming-ref.png\" />\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-mat-histogram-object-incoming-ref-1.png\" />\n\n### Immediate Dominator\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-mat-histogram-immediate-dominator.png\" />\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-mat-histogram-immediate-dominator-1.png\" />\n\n### Merge Shortest Path To GC Roots\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-mat-histogram-path-to-root.png\" />\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-mat-histogram-path-to-root-1.png\" />\n\n\n## 参考资料\n1. [Shallow vs. Retained Heap](https://help.eclipse.org/neon/index.jsp?topic=%2Forg.eclipse.mat.ui.help%2Fconcepts%2Fshallowretainedheap.html)\n2. [Dominator Tree](https://help.eclipse.org/neon/index.jsp?topic=%2Forg.eclipse.mat.ui.help%2Fconcepts%2Fdominatortree.html)\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Advanced"]},{"title":"JVM进阶 -- JDK命令","url":"%2F2019%2F01%2F08%2Fjvm-advanced-command%2F","content":"\n## jps\nLists the instrumented Java Virtual Machines (JVMs) on the target system.\n如果Java进程关闭了默认开启的UsePerfData参数（**-XX:-UsePerfData**），那么**jps/jstat**将**无法探知**到该Java进程\n```\n$ jps\n1408 Jps\n19 LiveCoverMain\n```\n| 参数 | 备注 |\n| ---- | ---- |\n| m | Displays the arguments passed to the **main method**. The output may be null for embedded JVMs. |\n| l | Displays the **full package name** for the application's main class or the **full path name** to the application's JAR file. |\n| v | Displays the arguments passed to the **JVM**. |\n\n<!-- more -->\n\n## jstat\nMonitors Java Virtual Machine (JVM) statistics.\n```\n➜  ~ jstat -options\n-class\n-compiler\n-gc\n-gccapacity\n-gccause\n-gcmetacapacity\n-gcnew\n-gcnewcapacity\n-gcold\n-gcoldcapacity\n-gcutil\n-printcompilation\n```\n\n### class\nDisplays statistics about the behavior of the **class loader**.\n```\n$ jstat -class 19\nLoaded  Bytes  Unloaded  Bytes     Time   \n 15375 27526.8       54    74.3      68.95\n```\n| 参数 | 备注 |\n| ---- | ---- |\n| Loaded | Number of classes loaded. |\n| Bytes | Number of **kBs** loaded. |\n| Unloaded | Number of classes unloaded. |\n| Bytes | Number of **Kbytes** unloaded. |\n| Time | Time spent performing class loading and unloading operations. |\n\n### compiler\nDisplays statistics about the behavior of the Java HotSpot VM **Just-in-Time** compiler.\n```\n$ jstat -compiler 19\nCompiled Failed Invalid   Time   FailedType FailedMethod\n   17421      1       0   122.19          1 org/apache/skywalking/apm/dependencies/net/bytebuddy/pool/TypePool$Default$WithLazyResolution doResolve\n```\n| 参数 | 备注 |\n| ---- | ---- |\n| Compiled | Number of compilation tasks performed. |\n| Failed | Number of compilations tasks failed. |\n| Invalid | Number of compilation tasks that were invalidated. |\n| Time | Time spent performing compilation tasks. |\n| FailedType | Compile type of the **last** failed compilation. |\n| FailedMethod | Class name and method of the **last** failed compilation. |\n\n### printcompilation\nDisplays Java HotSpot VM **compilation method** statistics.\n```\n$ jstat -printcompilation 19\nCompiled  Size  Type Method\n   17423    204    1 io/netty/util/internal/MpscLinkedQueue offer\n```\n| 参数 | 备注 |\n| ---- | ---- |\n| Compiled | Number of compilation tasks performed by the **most recently** compiled method. |\n| Size | Number of **bytes of byte code** of the **most recently** compiled method. |\n| Type | Compilation type of the **most recently** compiled method. |\n| Method | Class name and method name identifying the **most recently** compiled method. |\n\n### gc\nDisplays statistics about the behavior of the garbage collected heap.\n```\njstat -gc 19\n S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT   \n43648.0 43648.0  0.0   356.5  43776.0  17636.4  1835008.0   407774.3  91668.0 82097.8 12108.0 10130.4  33313  553.212   6      0.128  553.340\n```\n| 参数 | 备注 |\n| ---- | ---- |\n| S0C | Current survivor space 0 capacity (kB). |\n| S1C | Current survivor space 1 capacity (kB). |\n| S0U | Survivor space 0 utilization (kB). |\n| S1U | Survivor space 1 utilization (kB). |\n| EC | Current eden space capacity (kB). |\n| EU | Eden space utilization (kB). |\n| OC | Current old space capacity (kB). |\n| OU | Old space utilization (kB). |\n| MC | 1. Metaspace capacity (kB).<br/>2. Klass Metaspace以及NoKlass Metaspace两者总共**committed**的内存大小 |\n| MU | 1. Metacspace utilization (kB).<br/>2. Klass Metaspace以及NoKlass Metaspace两者已经使用了的内存大小 |\n| CCSC | 1. Compressed class space capacity (kB).<br/>2. Klass Metaspace的已经committed的内存大小 |\n| CCSU | 1. Compressed class space used (kB).<br/>2. Klass Metaspace的已经被使用的内存大小 |\n| YGC | Number of young generation garbage collection events. |\n| YGCT | Young generation garbage collection time. |\n| FGC | Number of full GC events. |\n| FGCT | Full garbage collection time. |\n| GCT | Total garbage collection time. |\n\nMetaspace相关内容可参考：[JVM源码分析之Metaspace解密](https://www.jianshu.com/p/92a5fbb33764)\n\n#### G1\n```\n$ jstat -gc -t 13903\nTimestamp        S0C    S1C    S0U    S1U      EC       EU        OC         OU       PC     PU    YGC     YGCT    FGC    FGCT     GCT\n       554652.2  0.0   8192.0  0.0   8192.0 5275648.0 4276224.0 3104768.0   755520.9  131072.0 61178.3   8219  169.021   0      0.000  169.021\n```\n1. S0C和S0U始终为0，这是因为使用G1 GC时，JVM不再设置Eden区、Survivor区和Old区的**内存边界**，而是将堆划分为若干个**等长**内存区域\n2. 每个内存区域都可以作为Eden区、Survivor区和Old区，并且可以在不同区域类型之间来回切换\n3. 因此，**逻辑上只有一个Survivor区**，当需要迁移Survivor区中的数据（Copying），只需要申请一个或多个内存区域，作为新的Survivor区\n4. 当发生垃圾回收时，JVM可能出现Survivor内存区域内的对象**全被回收**或者**全被晋升**的现象\n    - 此时，JVM会将这块内存区域回收，并标记为**可分配**\n    - 结果堆中可能**完全没有Survivor内存区域**，S1C和S1U均为0\n5. 554652s = 6.4day\n\n### gcnew\nDisplays statistics of the behavior of the **new generation**.\n```\n$ jstat -gcnew 19\n S0C    S1C    S0U    S1U   TT MTT  DSS      EC       EU     YGC     YGCT  \n43648.0 43648.0  315.7    0.0 15  15 21824.0  43776.0  16609.9  34072  566.323\n```\n| 参数 | 备注 | 样例 |\n| ---- | ---- | ---- |\n| S0C | Current survivor space 0 capacity (kB). | |\n| S1C | Current survivor space 1 capacity (kB). | |\n| S0U | Survivor space 0 utilization (kB). | |\n| S1U | Survivor space 1 utilization (kB). | |\n| TT | **Tenuring threshold**. | 15 |\n| MTT | **Maximum tenuring threshold**. | 15 |\n| DSS | Desired survivor size (kB). | 1. -XX:TargetSurvivorRatio=50<br/>2. Desired percentage of survivor space used after scavenge.<br/>3. 21824KB == 0.5 * S0C |\n| EC | Current eden space capacity (kB). | |\n| EU | Eden space utilization (kB). | |\n| YGC | Number of young generation GC events. | |\n| YGCT | Young generation garbage collection time. | |\n\n### gcold\nDisplays statistics about the behavior of the **old generation** and **metaspace** statistics.\n```\n$ jstat -gcold 19\n   MC       MU      CCSC     CCSU       OC          OU       YGC    FGC    FGCT     GCT   \n 92564.0  82773.0  12236.0  10223.6   1835008.0    423476.6  34693     6    0.128  575.369\n```\n| 参数 | 备注 |\n| ---- | ---- |\n| MC | Metaspace capacity (kB). |\n| MU | Metaspace utilization (kB). |\n| CCSC | Compressed class space capacity (kB). |\n| CCSU | Compressed class space used (kB). |\n| OC | Current old space capacity (kB). |\n| OU | Old space utilization (kB). |\n| YGC | Number of young generation GC events. |\n| FGC | Number of full GC events. |\n| FGCT | Full garbage collection time. |\n| GCT | Total garbage collection time. |\n\n### gccapacity\nDisplays statistics about the capacities of the generations and their corresponding spaces.\n```\n$ jstat -gccapacity 19\n NGCMN    NGCMX     NGC     S0C   S1C       EC      OGCMN      OGCMX       OGC         OC       MCMN     MCMX      MC     CCSMN    CCSMX     CCSC    YGC    FGC\n131072.0 131072.0 131072.0 43648.0 43648.0  43776.0  1835008.0  1835008.0  1835008.0  1835008.0      0.0 1128448.0  91668.0      0.0 1048576.0  12108.0  33477     6\n```\n| 参数 | 备注 | 样例 |\n| ---- | ---- | ---- |\n| NGCMN | Minimum new generation capacity (kB). | |\n| NGCMX | Maximum new generation capacity (kB). | |\n| NGC | Current new generation capacity (kB). | |\n| S0C | Current survivor space 0 capacity (kB). | |\n| S1C | Current survivor space 1 capacity (kB). | |\n| EC | Current eden space capacity (kB). | |\n| OGCMN | Minimum old generation capacity (kB). | |\n| OGCMX | Maximum old generation capacity (kB). | |\n| OGC | Current old generation capacity (kB). | |\n| OC | Current old space capacity (kB). | |\n| MCMN | Minimum metaspace capacity (kB). | 0 |\n| MCMX | Maximum metaspace capacity (kB). | 1. Klass Metaspace以及NoKlass Metaspace两者总共的**reserved**的内存大小<br/>2. 默认情况下Klass Metaspace是通过**CompressedClassSpaceSize**这个参数来reserved 1G的内存<br/>3. NoKlass Metaspace默认reserved的内存大小是**2*InitialBootClassLoaderMetaspaceSize**<br/>4. 1128448KB == 1.076GB |\n| MC | Metaspace capacity (kB). | 1. Klass Metaspace以及NoKlass Metaspace两者总共**committed**的内存大小<br/>2. 91668KB == 89.5MB |\n| CCSMN | Compressed class space minimum capacity (kB). | 0 |\n| CCSMX | Compressed class space maximum capacity (kB). | 1. Klass Metaspace reserved的内存大小<br/>2. 1048576KB == 1GB |\n| CCSC | Compressed class space capacity (kB). | 1. Klass Metaspace的已committed的内存大小<br/>2. 12108KB == 11.8MB |\n| YGC | Number of young generation GC events. | |\n| FGC | Number of full GC events. | |\n\n### gcnewcapacity\nDisplays statistics about the sizes of the new generations and its corresponding spaces.\n```\n$ jstat -gcnewcapacity 19\n  NGCMN      NGCMX       NGC      S0CMX     S0C     S1CMX     S1C       ECMX        EC      YGC   FGC\n  131072.0   131072.0   131072.0  43648.0  43648.0  43648.0  43648.0    43776.0    43776.0 34383     6\n```\n| 参数 | 备注 |\n| ---- | ---- |\n| NGCMN | Minimum new generation capacity (kB). |\n| NGCMX | Maximum new generation capacity (kB). |\n| NGC | Current new generation capacity (kB). |\n| S0CMX | Maximum survivor space 0 capacity (kB). |\n| S0C | Current survivor space 0 capacity (kB). |\n| S1CMX | Maximum survivor space 1 capacity (kB). |\n| S1C | Current survivor space 1 capacity (kB). |\n| ECMX | Maximum eden space capacity (kB). |\n| EC | Current eden space capacity (kB). |\n| YGC | Number of young generation GC events. |\n| FGC | Number of full GC events. |\n\n### gcoldcapacity\nDisplays statistics about the sizes of the old generation.\n```\n$ jstat -gcoldcapacity 19\n   OGCMN       OGCMX        OGC         OC       YGC   FGC    FGCT     GCT   \n  1835008.0   1835008.0   1835008.0   1835008.0 34478     6    0.128  572.454\n```\n| 参数 | 备注 |\n| ---- | ---- |\n| OGCMN | Minimum old generation capacity (kB). |\n| OGCMX | Maximum old generation capacity (kB). |\n| OGC | Current old generation capacity (kB). |\n| OC | Current old space capacity (kB). |\n| YGC | Number of young generation GC events. |\n| FGC | Number of full GC events. |\n| FGCT | Full garbage collection time. |\n| GCT | Total garbage collection time. |\n\n### gcmetacapacity\nDisplays statistics about the sizes of the metaspace.\n```\n$ jstat -gcmetacapacity 19\n   MCMN       MCMX        MC       CCSMN      CCSMX       CCSC     YGC   FGC    FGCT     GCT   \n       0.0  1130496.0    92564.0        0.0  1048576.0    12236.0 34593     6    0.128  574.271\n```\n| 参数 | 备注 |\n| ---- | ---- |\n| MCMN | Minimum metaspace capacity (kB). |\n| MCMX | Maximum metaspace capacity (kB). |\n| MC | Metaspace capacity (kB). |\n| CCSMN | Compressed class space minimum capacity (kB). |\n| CCSMX | Compressed class space maximum capacity (kB). |\n| YGC | Number of young generation GC events. |\n| FGC | Number of full GC events. |\n| FGCT | Full garbage collection time. |\n| GCT | Total garbage collection time. |\n\n### gcutil\nDisplays a summary about garbage collection statistics.\n```\n$ jstat -gcutil 19\n  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT   \n  0.16   0.00  14.11  23.02  89.37  83.50  34596  574.184     6    0.128  574.312\n```\n| 参数 | 备注 | 样例 |\n| ---- | ---- | ---- |\n| S0 | Survivor space 0 utilization as a percentage of the space's current capacity. | |\n| S1 | Survivor space 1 utilization as a percentage of the space's current capacity. | |\n| E | Eden space utilization as a percentage of the space's current capacity. | |\n| O | Old space utilization as a percentage of the space's current capacity. | |\n| M | Metaspace utilization as a percentage of the space's current capacity. | 1. Klass Metaspace以及NoKlass Metaspace两者总共的使用率<br/>2. MC=92564.0, MU=82773.0, CCSC=12236.0, CCSU=10223.6<br/>3. M = MU/MC = 89.4<br/>4. 有时候M达到90%以上，不一定说明metaspace使用了很多，因为内存是慢慢commit的 |\n| CCS | Compressed class space utilization as a percentage. | 1. NoKlass Metaspace的使用率<br/>2. MC=92564.0, MU=82773.0, CCSC=12236.0, CCSU=10223.6<br/>3. CCS = CCSU/CCSC = 83.5 |\n| YGC | Number of young generation GC events. | |\n| YGCT | Young generation garbage collection time. | |\n| FGC | Number of full GC events. | |\n| FGCT | Full garbage collection time. | |\n| GCT | Total garbage collection time. | |\n\n### gccause\nDisplays a summary about garbage collection statistics (same as -gcutil), with the cause of the **last** and **current** (when\napplicable) garbage collection events.\n```\n$ jstat -gccause 19\n  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT    LGCC                 GCC                 \n  0.00   0.83   2.23  22.60  89.67  84.02  33919  563.393     6    0.128  563.521 Allocation Failure   No GC\n```\n| 参数 | 备注 | 样例 |\n| ---- | ---- | ---- |\n| LGCC | Cause of **last** garbage collection | Allocation Failure |\n| GCC | Cause of **current** garbage collection | No GC |\n\n## jmap\n1. Prints shared object memory maps or heap memory details for a process, core file, or remote debug server.\n2. 由于jmap将访问**堆中的所有对象**，为了保证次此过程不被应用线程干扰\n    - jmap需要借助**安全点机制**，让所有线程停留在不改变堆中数据的状态\n3. 因此，**jmap导出的堆快照必定是安全点位置的**，可能导致基于该堆快照的分析结果存在**偏差**\n    - 例如编译生成的机器码中，某些对象的生命周期在两个安全点之间，那么:live选项将无法探知到这些对象\n4. 如果某个线程长时间无法跑到安全点，jmap将一直等待下去\n    - 垃圾回收器会主动将jstat所需要的摘要数据保存至**固定位置**\n    - 因此jstat只需要直接读取即可\n5. **jps/jmap/jinfo/jstack/jcmd**，均依赖于JVM的**Attach API**，因此**只能监控本地Java进程**\n6. 如果开启`-XX:+DisableAttachMechanism`，那么基于**Attach API**的命令也将无法执行\n\n### clstats\nPrints class loader wise statistics of Java heap. For each class loader, its name, how active it is, address, parent class loader, and the number and size of classes it has loaded are printed.\n```\n$ jmap -clstats 19\nAttaching to process ID 19, please wait...\nDebugger attached successfully.\nServer compiler detected.\nJVM version is 25.131-b11\nfinding class loader instances ..done.\ncomputing per loader stat ..done.\nplease wait.. computing liveness.liveness analysis may be inaccurate ...\nclass_loader    classes bytes   parent_loader   alive?  type\n\n<bootstrap>     2508    4508619   null          live    <internal>\n0x000000009388bb88      1       1473      null          dead    sun/reflect/DelegatingClassLoader@0x0000000100009df8\n0x0000000090bcccb8      1       1472    0x0000000090024a50      dead    sun/reflect/DelegatingClassLoader@0x0000000100009df8\n...\ntotal = 634     12693   20378456            N/A         alive=1, dead=633           N/A\n```\n\n### finalizerinfo\nPrints information about objects that are awaiting finalization.\n```\n$ jmap -finalizerinfo 19\nAttaching to process ID 19, please wait...\nDebugger attached successfully.\nServer compiler detected.\nJVM version is 25.131-b11\nNumber of objects pending for finalization: 0\n```\n\n### heap\nPrints a heap summary of the garbage collection used, the head configuration, and generation-wise heap usage. In addition, the number and size of interned Strings are printed.\n```\n$ jmap -heap 19\nAttaching to process ID 19, please wait...\nDebugger attached successfully.\nServer compiler detected.\nJVM version is 25.131-b11\n\nusing parallel threads in the new generation.\nusing thread-local object allocation.\nConcurrent Mark-Sweep GC\n\nHeap Configuration:\n   MinHeapFreeRatio         = 40\n   MaxHeapFreeRatio         = 70\n   MaxHeapSize              = 2013265920 (1920.0MB)\n   NewSize                  = 134217728 (128.0MB)\n   MaxNewSize               = 134217728 (128.0MB)\n   OldSize                  = 1879048192 (1792.0MB)\n   NewRatio                 = 2\n   SurvivorRatio            = 1\n   MetaspaceSize            = 21807104 (20.796875MB)\n   CompressedClassSpaceSize = 1073741824 (1024.0MB)\n   MaxMetaspaceSize         = 17592186044415 MB\n   G1HeapRegionSize         = 0 (0.0MB)\n\nHeap Usage:\nNew Generation (Eden + 1 Survivor Space):\n   capacity = 89522176 (85.375MB)\n   used     = 32297224 (30.80103302001953MB)\n   free     = 57224952 (54.57396697998047MB)\n   36.07734467937866% used\nEden Space:\n   capacity = 44826624 (42.75MB)\n   used     = 31529392 (30.068771362304688MB)\n   free     = 13297232 (12.681228637695312MB)\n   70.33630728024488% used\nFrom Space:\n   capacity = 44695552 (42.625MB)\n   used     = 767832 (0.7322616577148438MB)\n   free     = 43927720 (41.892738342285156MB)\n   1.7179159125274928% used\nTo Space:\n   capacity = 44695552 (42.625MB)\n   used     = 0 (0.0MB)\n   free     = 44695552 (42.625MB)\n   0.0% used\nconcurrent mark-sweep generation:\n   capacity = 1879048192 (1792.0MB)\n   used     = 33776136 (32.21143341064453MB)\n   free     = 1845272056 (1759.7885665893555MB)\n   1.7975130251475744% used\n\n21703 interned Strings occupying 2142592 bytes.\n```\n\n### histo[:live]\nPrints a histogram of the heap. For each Java class, the number of objects, memory size in bytes, and the fully qualified class names are printed. The JVM internal class names are printed with an asterisk (\\*) prefix. If the live suboption is specified, then only active objects are counted.\n```\n$ jmap -histo:live 19\nnum     #instances         #bytes  class name\n----------------------------------------------\n   1:         72102        6440744  [C\n   2:          5996        4159456  [B\n   3:         19079        1783760  [Ljava.lang.Object;\n   4:         71213        1709112  java.lang.String\n...\nTotal        529634       28005336\n```\n### dump:[live,] format=b, file=filename\nDumps the Java heap in **hprof** binary format to filename. The live suboption is optional, but when specified, only the active objects in the heap are dumped.\n相关的JVM参数：`-XX:+HeapDumpAfterFullGC`，`-XX:+HeapDumpOnOutOfMemoryError`\n```\n$ jmap -dump:live,format=b,file=/tmp/cover.hprof 19\nDumping heap to /tmp/cover.hprof ...\nHeap dump file created\n```\n\n## jinfo\nGenerates configuration information\n```\n$ jinfo 19\nAttaching to process ID 19, please wait...\nDebugger attached successfully.\nServer compiler detected.\nJVM version is 25.131-b11\nJava System Properties:\n\njava.runtime.name = Java(TM) SE Runtime Environment\njava.vm.version = 25.131-b11\n...\nconf.key = lz_live_cover\n...\nVM Flags:\nNon-default VM flags: -XX:CICompilerCount=2 -XX:+CMSClassUnloadingEnabled\n....\nCommand line:  -Dconf.key=lz_live_cover -Dconf.env=pre\n```\n\n### sysprops\nPrints Java system properties as name-value pairs.\n```\n$ jinfo -sysprops 19\nAttaching to process ID 19, please wait...\nDebugger attached successfully.\nServer compiler detected.\nJVM version is 25.131-b11\njava.runtime.name = Java(TM) SE Runtime Environment\njava.vm.version = 25.131-b11\n...\njava.vm.vendor = Oracle Corporation\nconf.key = lz_live_cover\n...\njava.vm.name = Java HotSpot(TM) 64-Bit Server VM\nsun.java.launcher = SUN_STANDARD\n...\n```\n\n### flags\n```\n$ jinfo -flags 19\nAttaching to process ID 19, please wait...\nDebugger attached successfully.\nServer compiler detected.\nJVM version is 25.131-b11\nNon-default VM flags: -XX:CICompilerCount=2 -XX:+CMSClassUnloadingEnabled\n...\nCommand line:  -Dconf.key=lz_live_cover -Dconf.env=pre\n...\n```\n\n### manageable参数\n```\n$ java -XX:+PrintFlagsFinal -version | grep manageable\n     intx CMSAbortablePrecleanWaitMillis            = 100                                 {manageable}\n     intx CMSTriggerInterval                        = -1                                  {manageable}\n     intx CMSWaitDuration                           = 2000                                {manageable}\n     bool HeapDumpAfterFullGC                       = false                               {manageable}\n     bool HeapDumpBeforeFullGC                      = false                               {manageable}\n     bool HeapDumpOnOutOfMemoryError                = false                               {manageable}\n    ccstr HeapDumpPath                              =                                     {manageable}\n    uintx MaxHeapFreeRatio                          = 100                                 {manageable}\n    uintx MinHeapFreeRatio                          = 0                                   {manageable}\n     bool PrintClassHistogram                       = false                               {manageable}\n     bool PrintClassHistogramAfterFullGC            = false                               {manageable}\n     bool PrintClassHistogramBeforeFullGC           = false                               {manageable}\n     bool PrintConcurrentLocks                      = false                               {manageable}\n     bool PrintGC                                   = false                               {manageable}\n     bool PrintGCDateStamps                         = false                               {manageable}\n     bool PrintGCDetails                            = false                               {manageable}\n     bool PrintGCID                                 = false                               {manageable}\n     bool PrintGCTimeStamps                         = false                               {manageable}\njava version \"1.8.0_131\"\nJava(TM) SE Runtime Environment (build 1.8.0_131-b11)\nJava HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)\n```\n\n### flag\nPrints the name and value of the specified command-line flag.\n```\n$ jinfo -flag HeapDumpAfterFullGC 19\n-XX:-HeapDumpAfterFullGC\n```\n\n### flag [+|-]name\nEnables or disables the specified Boolean command-line flag.\n```\n$ jinfo -flag +HeapDumpAfterFullGC 19\n\n$ jinfo -flag HeapDumpAfterFullGC 19\n-XX:+HeapDumpAfterFullGC\n```\n\n### flag name=value\nSets the specified command-line flag to the specified value.\n```\n$ jinfo -flag CMSWaitDuration=1999 19\n\n$ jinfo -flag CMSWaitDuration 19\n-XX:CMSWaitDuration=1999\n```\n\n## jstack\nPrints Java thread stack traces for a Java process, core file, or remote debug server.\njstack的一个常用应用场景为**死锁检测**\n```\n$ jstack 19120\n2019-01-10 09:53:21\nFull thread dump Java HotSpot(TM) 64-Bit Server VM (25.181-b13 mixed mode):\n\n...\n\n\"t3\" #12 prio=5 os_prio=31 tid=0x00007faa948b4800 nid=0xf07 waiting for monitor entry [0x00007000043c8000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n\tat me.zhongmingmao.advanced.command.SyncThread.run(ThreadDeadlock.java:39)\n\t- waiting to lock <0x0000000795700530> (a java.lang.Object)\n\t- locked <0x0000000795700550> (a java.lang.Object)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\"t2\" #11 prio=5 os_prio=31 tid=0x00007faa948b4000 nid=0x3c03 waiting for monitor entry [0x0000700005581000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n\tat me.zhongmingmao.advanced.command.SyncThread.run(ThreadDeadlock.java:39)\n\t- waiting to lock <0x0000000795700550> (a java.lang.Object)\n\t- locked <0x0000000795700540> (a java.lang.Object)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\"t1\" #10 prio=5 os_prio=31 tid=0x00007faa948b3000 nid=0x4203 waiting for monitor entry [0x000070000547e000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n\tat me.zhongmingmao.advanced.command.SyncThread.run(ThreadDeadlock.java:39)\n\t- waiting to lock <0x0000000795700540> (a java.lang.Object)\n\t- locked <0x0000000795700530> (a java.lang.Object)\n\tat java.lang.Thread.run(Thread.java:748)\n\n...\n\nFound one Java-level deadlock:\n=============================\n\"t3\":\n  waiting to lock monitor 0x00007faa94811b58 (object 0x0000000795700530, a java.lang.Object),\n  which is held by \"t1\"\n\"t1\":\n  waiting to lock monitor 0x00007faa9480da08 (object 0x0000000795700540, a java.lang.Object),\n  which is held by \"t2\"\n\"t2\":\n  waiting to lock monitor 0x00007faa94811aa8 (object 0x0000000795700550, a java.lang.Object),\n  which is held by \"t3\"\n\n...\n\nFound 1 deadlock.\n```\n\n## jcmd\nSends diagnostic command requests to a running Java Virtual Machine (JVM).\n**jcmd可以替代上面除了jstat之外的所有命令，并没有保留jstat的输出格式**\n\n### 查看进程\n```\n$ jcmd -l\n19 fm.lizhi.live.cover.LiveCoverMain lz-live-cover-pre-deployment-5f45b6955d-f4xjj\n3241 sun.tools.jcmd.JCmd -l\n```\n\n### 查看性能统计\n```\n$ jcmd 19 PerfCounter.print\njava.ci.totalTime=445938928367\njava.cls.loadedClasses=20317\n...\njava.threads.daemon=121\njava.threads.live=124\njava.threads.livePeak=125\njava.threads.started=2458\n...\n```\n\n### 可执行的操作\n```\n$ jcmd 19 help\n19:\nThe following commands are available:\nJFR.stop\nJFR.start\nJFR.dump\nJFR.check\nVM.native_memory\nVM.check_commercial_features\nVM.unlock_commercial_features\nManagementAgent.stop\nManagementAgent.start_local\nManagementAgent.start\nGC.rotate_log\nThread.print\nGC.class_stats\nGC.class_histogram\nGC.heap_dump\nGC.run_finalization\nGC.run\nVM.uptime\nVM.flags\nVM.system_properties\nVM.command_line\nVM.version\nhelp\n```\n\n#### VM.uptime\n```\n$ jcmd 19 VM.uptime\n19:\n87089.850 s\n```\n\n#### GC.run\n```\n$ jcmd 19 GC.run\n19:\nCommand executed successfully\n```\n\n#### Thread.print\n```\n$ jcmd 3721 Thread.print\nFound one Java-level deadlock:\n=============================\n\"t3\":\n  waiting to lock monitor 0x00007fd53105ff58 (object 0x0000000795700530, a java.lang.Object),\n  which is held by \"t1\"\n\"t1\":\n  waiting to lock monitor 0x00007fd53105be08 (object 0x0000000795700540, a java.lang.Object),\n  which is held by \"t2\"\n\"t2\":\n  waiting to lock monitor 0x00007fd53105fea8 (object 0x0000000795700550, a java.lang.Object),\n  which is held by \"t3\"\n```\n\n#### JFR\n```\n$ jcmd 3721 JFR.check\n3721:\nJava Flight Recorder not enabled.\nUse VM.unlock_commercial_features to enable.\n\n$ jcmd 3721 VM.unlock_commercial_features\n3721:\nCommercial Features now unlocked.\n\n$ jcmd 3721 JFR.check\n3721:\nNo available recordings.\nUse JFR.start to start a recording.\n```\n```\n$ jcmd 3721 JFR.start name=abc,duration=120s\n3721:\nStarted recording 1. No limit (duration/maxsize/maxage) in use.\nUse JFR.dump name=abc,duration=120s filename=FILEPATH to copy recording data to file.\n\n$ jcmd 3721 JFR.check\n3721:\nRecording: recording=1 name=\"abc,duration=120s\" (running)\n```\n```\n$ cmd 3721 JFR.dump name=abc,duration=120s filename=abc.jfr\n3721:\nDumped recording \"abc,duration=120s\", 391.4 kB written to:\n/Users/zhongmingmao/Documents/source_code/github/jvm_demo/abc.jfr\n```\n```\n$ jcmd 3721 JFR.stop name=abc,duration=120s\n3721:\nStopped recording \"abc,duration=120s\".\n```\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Advanced"]},{"title":"JVM进阶 -- 浅谈注解处理器","url":"%2F2019%2F01%2F07%2Fjvm-advanced-annotation-processor%2F","content":"\n## 注解与注解处理器\n1. 注解是Java 5引入，用来为类、方法、字段和参数等Java结构**提供额外信息**的机制\n2. `@Override`仅对**Java编译器**有用，为Java编译器**引用一条新的编译规则**，编译完成后，它的使命也结束了\n3. Java的注解机制允许开发人员**自定义注解**，这些自定义注解同样可以为Java编译器**添加编译规则**\n    - 这种功能需要由开发人员提供，并且以**插件的形式**接入Java编译器中，这些插件被称之为**注解处理器**\n4. 除了**引入新的编译规则**外，注解处理器还可以用于**修改已有的Java源文件**（不推荐）和**生成新的Java源文件**\n\n```java\n@Target(ElementType.METHOD)\n@Retention(RetentionPolicy.SOURCE)\npublic @interface Override {\n}\n// 元注解@Target：用来限定目标注解所能标注的Java结构\n// 元注解@Retention：用来限定目标注解的生命周期\n//      SOURCE：源代码，一旦源代码被编译为字节码，注解便会被擦除\n//      CLASS：源代码+字节码\n//      RUNTIME：源代码+字节码+运行时\n```\n\n<!-- more -->\n\n## 原理 + 用途\n\n### 编译过程\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-annotation-processor.png\" />\n1. 将源文件解析为**抽象语法树**\n2. 调用已注册的**注解处理器**\n    - 如果该过程**生成了新的源文件**，编译器将重复第1、2步\n    - 每次重复成为**一轮**\n    - 第一轮解析处理的是输入至编译器中的已有源文件\n    - 当注解处理器不再生成新的源文件，将进入最后一轮\n3. 生成**字节码**\n\n### 主要用途\n1. 定义编译规则，并检查被编译的源文件\n2. 修改已有源代码，涉及Java编译器的内部API，不推荐\n3. 生成新的源代码\n\n## 定义编译规则\n```java\nimport java.lang.annotation.*;\n\n@Target({ElementType.TYPE, ElementType.FIELD})\n@Retention(RetentionPolicy.SOURCE)\npublic @interface CheckGetter {\n}\n```\nCheckGetter的目的：遍历被标注的类中的实例字段，并检查有没有对应的getter方法\n\n### 实现注解处理器\n\n#### Processor接口\n```java\npublic interface Processor {\n    void init(ProcessingEnvironment processingEnv);\n    Set<String> getSupportedAnnotationTypes();\n    SourceVersion getSupportedSourceVersion();\n    boolean process(Set<? extends TypeElement> annotations, RoundEnvironment roundEnv);\n    ...\n}\n```\n1. init：注解处理器的初始化代码\n    - 不采用**构造器**的原因是在Java编译器中，**注解处理器实例是通过反射生成的**\n    - 因此每个注解处理器类都需要定义一个**无参构造器**\n    - 通常来说不需要声明任何构造器，而是**依赖于Java编译器自动插入一个无参构造器**\n    - 具体的初始化代码，放入`init`方法中\n2. getSupportedAnnotationTypes：返回该注解处理器**所支持的注解类型**\n3. getSupportedSourceVersion：返回该注解处理器**所支持的Java版本**，通常需要**与Java编译器的版本一致**\n4. process：最为**关键**的注解处理方法\n\n#### AbstractProcessor抽象类\n`AbstractProcessor`实现了`init`，`getSupportedAnnotationTypes`和`getSupportedSourceVersion`方法\n它的子类可以通过`@SupportedAnnotationTypes`和`@SupportedSourceVersion`注解来声明所支持的**注解类型**以及**Java版本**\n```java\nimport javax.annotation.processing.*;\nimport javax.lang.model.SourceVersion;\nimport javax.lang.model.element.*;\nimport javax.lang.model.util.ElementFilter;\nimport javax.tools.Diagnostic;\nimport java.util.Set;\n\n@SupportedAnnotationTypes(\"CheckGetter\")\n@SupportedSourceVersion(SourceVersion.RELEASE_8)\npublic class CheckGetterProcessor extends AbstractProcessor {\n    @Override\n    public boolean process(Set<? extends TypeElement> annotations, RoundEnvironment roundEnv) {\n        // annotations：该注解处理器所能处理的注解类型\n        // roundEnv：囊括当前轮生成的抽象语法树RoundEnvironment\n        // roundEnv.getElementsAnnotatedWith(CheckGetter.class) -> 获取所有被@CheckGetter注解的类\n        for (TypeElement annotatedClass : ElementFilter.typesIn(roundEnv.getElementsAnnotatedWith(CheckGetter.class))) {\n            for (VariableElement field : ElementFilter.fieldsIn(annotatedClass.getEnclosedElements())) {\n                if (!containsGetter(annotatedClass, field.getSimpleName().toString())) {\n                    processingEnv.getMessager().printMessage(Diagnostic.Kind.ERROR,\n                            String.format(\"getter not fund for '%s.%s'.\", annotatedClass.getSimpleName(),\n                                    field.getSimpleName()));\n                }\n            }\n        }\n        return false;\n    }\n\n    private static boolean containsGetter(TypeElement typeElement, String name) {\n        // 拼接getter名称\n        String getter = \"get\" + name.substring(0, 1).toUpperCase() + name.substring(1).toLowerCase();\n        for (ExecutableElement executableElement : ElementFilter.methodsIn(typeElement.getEnclosedElements())) {\n            if (!executableElement.getModifiers().contains(Modifier.STATIC)\n                    && executableElement.getSimpleName().toString().equals(getter)\n                    && executableElement.getParameters().isEmpty()) {\n                return true;\n            }\n        }\n        return false;\n    }\n}\n```\nprocess方法涉及处理各种不同类型的Element，分别指代Java程序的各个**结构**\n```java\n// package me.zhongmingmao.advanced.annotation; // PackageElement\n\n@CheckGetter\npublic class Foo { // TypeElement\n    int a; // VariableElement\n    static int b; // VariableElement\n\n    Foo() { // ExecutableElement\n    }\n\n    void setA( // ExecutableElement\n               int newA // VariableElement\n    ) {\n    }\n}\n```\nJava结构之间也存在从属关系，`TypeElement.getEnclosedElements()`将获取**字段，构造器和方法**\n\n#### 注册\n在将注解处理器编译成class文件后，就可以将其**注册为Java编译器的插件**，并用来**处理其他源代码**\n```shell\n$ ll\ntotal 24\n-rw-r--r--  1 zhongmingmao  staff   147B  1  7 22:53 CheckGetter.java\n-rw-r--r--  1 zhongmingmao  staff   2.0K  1  7 22:54 CheckGetterProcessor.java\n-rw-r--r--  1 zhongmingmao  staff   316B  1  7 22:55 Foo.java\n\n$ javac CheckGetter.java CheckGetterProcessor.java\n\n$ javac -cp . -processor CheckGetterProcessor Foo.java\n错误: getter not fund for 'Foo.a'.\n错误: getter not fund for 'Foo.b'.\n2 个错误\n\n$ ll\ntotal 40\n-rw-r--r--  1 zhongmingmao  staff   385B  1  7 22:57 CheckGetter.class\n-rw-r--r--  1 zhongmingmao  staff   147B  1  7 22:53 CheckGetter.java\n-rw-r--r--  1 zhongmingmao  staff   3.1K  1  7 22:57 CheckGetterProcessor.class\n-rw-r--r--  1 zhongmingmao  staff   2.0K  1  7 22:54 CheckGetterProcessor.java\n-rw-r--r--  1 zhongmingmao  staff   316B  1  7 22:55 Foo.java\n```\n\n## 修改与生成源代码\n1. 注解处理器并**不能真正地修改源代码**\n2. 实际修改的是**由Java源代码生成的抽象语法树**\n    - 在其中修改已有的树节点或者插入新的树节点，从而使生成的字节码发生变化\n    - 对抽象语法树的修改涉及了**Java编译器的内部API**，很可能**随版本变更而失效**，不推荐\n    - 样例：lombok\n3. 相对于修改源代码，用注解处理器**生成源代码更为常用**\n\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-annotation-processor-lombok.png\" width=250/>\n\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Advanced"]},{"title":"JVM进阶 -- 浅谈循环优化","url":"%2F2019%2F01%2F06%2Fjvm-advanced-optimization-loop%2F","content":"\n## 循环无关代码外提\n\n### 外提无关代码\n1. 循环无关代码：**循环中值不变的表达式**\n2. 在不改变程序语义的情况下，将循环无关代码提出循环外\n    - 那么程序将避免重复执行这些表达式，从而达到性能提升的效果\n\n```java\nint foo(int x, int y, int[] a) {\n    int sum = 0;\n    for (int i = 0; i < a.length; i++) {\n        sum += x * y + a[i];\n    }\n    return sum;\n}\n```\n\n<!-- more -->\n\n```\n// 对应的字节码\nint foo(int, int, int[]);\n  Code:\n     0: iconst_0\n     1: istore 4\n     3: iconst_0\n     4: istore 5\n     6: goto 25\n// 循环体开始\n     9: iload 4        // load sum\n    11: iload_1        // load x\n    12: iload_2        // load y\n    13: imul           // x*y\n    14: aload_3        // load a\n    15: iload 5        // load i\n    17: iaload         // a[i]\n    18: iadd           // x*y + a[i]\n    19: iadd           // sum + (x*y + a[i])\n    20: istore 4       // sum = sum + (x*y + a[i])\n    22: iinc 5, 1      // i++\n    25: iload 5        // load i\n    27: aload_3        // load a\n    28: arraylength    // a.length\n    29: if_icmplt 9    // i < a.length\n// 循环体结束\n    32: iload 4\n    34: ireturn\n```\n\n1. 循环体中的表达式`x*y`和循环判断条件中的`a.length`均属于循环不变代码\n2. `x*y`是整数乘法运算，`a.length`是内存访问操作，读取数组对象a的长度\n    - 数组的长度存放在数组对象的**对象头**中，通过`arraylength`指令来访问\n\n理想情况下，经过循环无关代码外提后，等同于下面的手工优化版本\n```java\nint fooManualOpt(int x, int y, int[] a) {\n    int sum = 0;\n    int t0 = x * y;\n    int t1 = a.length;\n    for (int i = 0; i < t1; i++) {\n        sum += t0 + a[i];\n    }\n    return sum;\n}\n```\n即时编译器除了将`x*y`和`a.length`外提，还提供int数组加载指令`iaload`所暗含的`null check`和`range check`，伪代码如下\n```java\nint iaload(int[] arrayRef, int index) {\n    if (arrayRef == null) { // null check\n        throw new NullPointerException();\n    }\n    if (index < 0 || index >= arrayRef.length) { // range check\n        throw new ArrayIndexOutOfBoundsException();\n    }\n    return arrayRef[index];\n}\n```\n\n### 外提null check\nfoo方法中的`null check`属于**循环无关**代码，即与第几次循环无关，将iaload伪代码展开，得到\n```java\nint foo(int[] a) {\n    int sum = 0;\n    for (int i = 0; i < a.length; i++) {\n        if (a == null) { // null check\n            throw new NullPointerException();\n        }\n        if (i < 0 || i >= a.length) { // range check\n            throw new ArrayIndexOutOfBoundsException();\n        }\n        sum += a[i];\n    }\n    return sum;\n}\n```\n在C2中，`null check`的外提是通过**额外的编译优化**（_即**循环预测**_，-XX:+UseLoopPredicate）来实现的\n该优化的实际做法就是在**循环之前**插入**同样**的检测代码，并在命中的时候进行**去优化**\n```java\nint foo(int[] a) {\n    int sum = 0;\n    if (a == null) {\n        deoptimize(); // never returns\n    }\n    for (int i = 0; i < a.length; i++) {\n        if (a == null) { // now evluate to false\n            throw new NullPointerException();\n        }\n        if (i < 0 || i >= a.length) { // range check\n            throw new ArrayIndexOutOfBoundsException();\n        }\n        sum += a[i];\n    }\n    return sum;\n}\n```\n\n### 外提range check\n由于如果外提`range check`之后，将无法再引用到循环变量，因此即时编译器需要**转换检测条件**\n```java\nfor (int i = INIT; i < LIMIT; i += STRIDE) {\n    if (i < 0 || i >= a.length) { // range check\n        throw new ArrayIndexOutOfBoundsException();\n    }\n    sum += a[i];\n}\n----------\n// 经过range check外提之后\nif (INIT < 0 || IMAX >= a.length) {\n    // IMAX是i所能达到的最大值，不一定是LIMIT-1\n    detopimize(); // never returns\n}\nfor (int i = INIT; i < LIMIT; i += STRIDE) {\n    sum += a[i]; // 不再包含range check\n}\n```\n\n## 循环展开\n循环展开：**在循环体中重复多次循环迭代**，并**减少循环次数**的编译优化，是一种以**空间换时间**的优化方式\n```java\nint foo(int[] a) {\n    int sum = 0;\n    for (int i = 0; i < 64; i++) {\n        sum += (i % 2 == 0) ? a[i] : -a[i];\n    }\n    return sum;\n}\n```\n经过一次**循环展开**后\n```java\nint foo(int[] a) {\n    int sum = 0;\n    for (int i = 0; i < 64; i += 2) { // 步长为2\n        sum += (i % 2 == 0) ? a[i] : -a[i];\n        sum += ((i + 1) % 2 == 0) ? a[i + 1] : -a[i + 1];\n    }\n    return sum;\n}\n```\n\n### 计数循环\n在**C2**中，只有**计数循环**才能被展开，计数循环需要满足以下条件\n1. 维护一个循环计数器，并且**基于计数器的循环出口只有一个**\n    - 但可以有基于其他判断条件的出口\n2. 循环计数器的**类型**只能为**int/short/char**\n3. 每个迭代循环计数器的**增量为常数**\n4. 循环计数器的**上限和下限是与循环无关的数值**\n\n```java\nfor (int i = START; i < LIMIT; i += STRIDE) { .. }\n// 等价于\nint i = START;\nwhile (i < LIMIT) {\n    ..\n    i += STRIDE;\n}\n// 只要LIMIT是与循环无关的数值，STRIDE是常数，而且循环中除了i < LIMIT之外没有其他基于循环变量i的循环出口\n// 那么C2便会将该循环标识为计数循环\n```\n\n### 优缺点\n循环展开的缺点：**增加了代码的冗余度**，导致所**生成机器码的长度大幅上涨**\n但随着循环体的增大，优化机会也会不断地增加，一旦循环展开能触发**进一步的优化**，总体的代码复杂度也将降低\n```java\nint foo(int[] a) {\n    int sum = 0;\n    for (int i = 0; i < 64; i += 2) {\n        sum += a[i];\n        sum += -a[i + 1];\n    }\n    return sum;\n}\n```\n\n### 完全展开\n完全展开：当循环的数量是**固定**值而且**非常小**，即时编译器将循环完全展开\n原本循环中的循环判断语句将不复存在，变成了若干**顺序执行**的循环体\n```java\nint foo(int[] a) {\n    int sum = 0;\n    for (int i = 0; i < 4; i++) {\n    sum += a[i];\n    }\n    return sum;\n}\n```\n完全展开\n```java\nint foo(int[] a) {\n    int sum = 0;\n    sum += a[0];\n    sum += a[1];\n    sum += a[2];\n    sum += a[3];\n    return sum;\n}\n```\n即时编译器会在**循环体的大小**与**循环展开次数**之间作出**权衡**\n\n## 循环判断外提\n循环判断外提：**将循环中的if语句外提到循环之前，并且在该if语句的两个分支中分别放置一份循环代码**\n```java\nint foo(int[] a) {\n    int sum = 0;\n    for (int i = 0; i < a.length; i++) {\n        if (a.length > 4) {\n            sum += a[i];\n        }\n    }\n    return sum;\n}\n```\n```java\n// 循环判断外提\nint foo(int[] a) {\n    int sum = 0;\n    if (a.length > 4) {\n        for (int i = 0; i < a.length; i++) {\n            sum += a[i];\n        }\n    } else {\n        for (int i = 0; i < a.length; i++) {\n        }\n    }\n    return sum;\n}\n// 进一步优化\nint foo(int[] a) {\n    int sum = 0;\n    if (a.length > 4) {\n        for (int i = 0; i < a.length; i++) {\n            sum += a[i];\n        }\n    }\n    return sum;\n}\n```\n循环**判断外提**与循环**无关检测外提**所针对的代码模式比较类似，都是循环中的**if语句**\n循环**无关检测外提**在检查失败时会**抛出异常**，**中止当前的正常执行路径**\n循环**判断外提**针对更**常见的情况**，即通过if语句的不同分支执行不同的代码逻辑\n\n## 循环剥离\n循环剥离：将循环的**前几个迭代**或者**后几个迭代**剥离出循环的优化方式\n通过将这几个特殊的迭代剥离出去，使得原本的循环体的**规律性更加明显**，从而**触发进一步优化**\n```java\nint foo(int[] a) {\n    int j = 0;\n    int sum = 0;\n    for (int i = 0; i < a.length; i++) {\n        sum += a[j];\n        j = i;\n    }\n    return sum;\n}\n```\n剥离第一个迭代\n```java\nint foo(int[] a) {\n    int sum = 0;\n    if (0 < a.length) {\n        sum += a[0];\n        for (int i = 1; i < a.length; i++) {\n            sum += a[i - 1];\n        }\n    }\n    return sum;\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Advanced"]},{"title":"JVM进阶 -- 浅谈字段访问优化","url":"%2F2019%2F01%2F06%2Fjvm-advanced-optimization-filed-access%2F","content":"\n## 概念\n在实际中，Java程序中的对象或许**本身就是逃逸**的，或许因为**方法内联不够彻底**而被即时编译器**当成是逃逸**的，这两种情况都将\n导致即时编译器**无法进行标量替换**，这时，针对对象字段访问的优化显得更为重要。\n\n```java\nstatic int bar(Foo o, int x) {\n    o.a = x;\n    return o.a;\n}\n```\n\n<!-- more -->\n\n1. 对象o是传入参数，**不属于逃逸分析的范围**（JVM中的逃逸分析针对的是**新建对象**）\n2. 该方法会将所传入的int型参数x的值存储至实例字段Foo.a中，然后再读取并返回同一字段的值\n3. 这段代码涉及**两次**内存访问操作：存储和读取实例字段Foo.a\n4. 代码可以手工优化成如下\n\n```java\nstatic int bar(Foo o, int x) {\n    o.a = x;\n    return x;\n}\n```\n即时编译器也能作出类似的**自动优化**\n\n## 字段读取优化\n1. 即时编译器会优化**实例字段**和**静态字段**的访问，以**减少总的内存访问次数**\n2. 即时编译器将**沿着控制流**，缓存各个字段**存储节点**将要存储的值，或者字段**读取节点**所得到的值\n    - 当即时编译器**遇到对同一字段的读取节点**时，如果缓存值还没有失效，那么将读取节点**替换**为该缓存值\n    - 当即时编译器**遇到对同一字段的存储节点**时，会**更新**所缓存的值\n        - 当即时编译器遇到**可能更新**字段的节点时，它会采取**保守**的策略，**舍弃所有的缓存值**\n        - **方法调用节点**：在即时编译器看来，方法调用会执行**未知代码**\n        - **内存屏障节点**：其他线程可能异步更新了字段\n\n### 样例1\n```java\nstatic int bar(Foo o, int x) {\n    int y = o.a + x;\n    return o.a + y;\n}\n```\n实例字段Foo.a被读取两次，即时编译器会将第一次读取的值缓存起来，并且**替换**第二次的字段读取操作，以**节省**一次内存访问\n```java\nstatic int bar(Foo o, int x) {\n    int t = o.a;\n    int y = t + x;\n    return t + y;\n}\n```\n\n### 样例2\n```java\nstatic int bar(Foo o, int x) {\n    o.a = 1;\n    if (o.a >= 0)\n        return x;\n    else\n        return -x;\n}\n```\n字段读取节点被替换成一个**常量**，进一步触发更多的优化\n```java\nstatic int bar(Foo o, int x) {\n    o.a = 1;\n    return x;\n}\n```\n\n### 样例3\n```java\nclass Foo {\n    boolean a;\n    void bar() {\n        a = true;\n        while (a) {}\n    }\n    void whatever() { a = false; }\n}\n```\n即时编译器会将while循环中读取实例字段a的操作**直接替换为常量true**\n```java\nvoid bar() {\n    a = true;\n    while (true) {}\n}\n// 生成的机器码将陷入这一死循环中\n0x066b: mov    r11,QWORD PTR [r15+0x70] // 安全点测试\n0x066f: test   DWORD PTR [r11],eax      // 安全点测试\n0x0672: jmp    0x066b                   // while (true)\n```\n1. 可以通过**volatile**关键字标记实例字段a，以**强制**对a的读取\n2. 实际上，即时编译器将**在volatile字段访问前后插入内存屏障节点**\n    - 这些**内存屏障节点**将**阻止**即时编译器**将屏障之前所缓存的值用于屏障之后的读取节点之上**\n    - 在X86_64平台上，volatile字段读取前后的内存屏障都是no-op\n        - 在**即时编译过程中的屏障节点**，还是会**阻止即时编译器的字段读取优化**\n        - 强制在循环中使用**内存读取指令**访问实例字段Foo.a的最新值\n3. 同理，**加解锁操作同样也会阻止即时编译器的字段读取优化**\n\n## 字段存储优化\n如果一个字段先后被存储了两次，而且这**两次存储之间没有对第一次存储内容读取**，那么即时编译器将**消除**第一个字段存储\n\n### 样例1\n```java\nclass Foo {\n    int a = 0;\n    void bar() {\n        a = 1;\n        a = 2;\n    }\n}\n```\n即时编译器将消除bar方法的冗余存储\n```java\nvoid bar() {\n    a = 2;\n}\n```\n\n### 样例2\n即便在某个字段的两个存储操作之间读取该字段，即时编译器也可能在**字段读取优化**的帮助下，将第一个存储操作当作**冗余存储**\n场景：例如两个存储操作之间隔着许多代码，又或者因为**方法内联**的原因，将两个存储操作纳入到同一编译单元里（如构造器中字段的初始化以及随后的更新）\n```java\nclass Foo {\n    int a = 0;\n    void bar() {\n        a = 1;\n        int t = a;\n        a = t + 2;\n    }\n}\n// 优化为\nclass Foo {\n    int a = 0;\n    void bar() {\n        a = 1;\n        int t = 1;\n        a = t + 2;\n    }\n}\n// 进一步优化为\nclass Foo {\n    int a = 0;\n    void bar() {\n        a = 3;\n    }\n}\n```\n如果所存储的字段被标记为**volatile**，那么即时编译器也_**不能消除冗余存储**_\n\n## 死代码消除\n\n### 样例1\n```java\nint bar(int x, int y) {\n    int t = x*y;\n    t = x+y;\n    return t;\n}\n```\n没有节点依赖于t的第一个值`x*y`，因此该乘法运算将被消除\n```java\nint bar(int x, int y) {\n    return x+y;\n}\n```\n\n### 样例2\n```java\nint bar(boolean f, int x, int y) {\n    int t = x*y;\n    if (f)\n        t = x+y;\n    return t;\n}\n```\n部分程序路径上有冗余存储（f=true），该路径上的乘法运算将会被消除\n```java\nint bar(boolean f, int x, int y) {\n    int t;\n    if (f)\n        t = x+y;\n    else\n        t = x*y;\n    return t;\n}\n```\n\n### 样例3\n```java\nint bar(int x) {\n    if (false)\n        return x;\n    else\n        return -x;\n}\n```\n不可达分支指的是任何程序路径都不可达到的分支，即时编译器将**消除不可达分支**\n```java\nint bar(int x) {\n    return -x;\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Advanced"]},{"title":"JVM进阶 -- 浅谈逃逸分析","url":"%2F2019%2F01%2F05%2Fjvm-advanced-escape%2F","content":"\n## 概念\n1. 在JVM**即时编译**语境下，逃逸分析将判断**新建的对象是否逃逸**\n2. 即时编译器判断对象是否逃逸的依据\n    - 对象是否被存入**堆**中（**静态字段**或者**堆中对象的实例字段**）\n        - 堆是**线程共享**的，其他线程可以获得该对象的引用\n    - 对象是否被传入**未知代码**\n        - JVM即时编译是**以方法为单位**的\n        - 对于方法中**未被内联的方法调用**，即时编译器会将其当做未知代码\n        - _**方法调用的调用者以及参数是逃逸的**_\n3. 注：方法内联可以简单理解，在即时编译过程中遇到方法调用时\n    - **将目标方法的方法体纳入到编译范围之中，并取代原方法调用的优化手段**\n\n<!-- more -->\n\n## foreach\n语法糖\n```java\npublic void forEach(ArrayList<Object> list, Consumer<Object> f) {\n    for (Object obj : list) {\n        f.accept(obj);\n    }\n}\n```\n\n等价代码\n```java\npublic void forEach(ArrayList<Object> list, Consumer<Object> f) {\n    Iterator<Object> iter = list.iterator();\n    while (iter.hasNext()) {\n        Object obj = iter.next();\n        f.accept(obj);\n    }\n}\n```\n\n迭代器：ArrayList$Itr\n```java\npublic class ArrayList ... {\n    public Iterator<E> iterator() {\n        return new Itr();\n    }\n    private class Itr implements Iterator<E> {\n        int cursor;       // index of next element to return\n        int lastRet = -1; // index of last element returned; -1 if no such\n        int expectedModCount = modCount;\n        ...\n        public boolean hasNext() {\n            return cursor != size;\n        }\n        @SuppressWarnings(\"unchecked\")\n        public E next() {\n            checkForComodification();\n            int i = cursor;\n            if (i >= size)\n                throw new NoSuchElementException();\n            Object[] elementData = ArrayList.this.elementData;\n            if (i >= elementData.length)\n                throw new ConcurrentModificationException();\n            cursor = i + 1;\n            return (E) elementData[lastRet = i];\n        }\n        ...\n        final void checkForComodification() {\n            if (modCount != expectedModCount)\n                throw new ConcurrentModificationException();\n        }\n    }\n}\n```\n\n假设即时编译器能够对上面这些方法都能**内联**：ArrayList$Itr()，hasNext()，next()，checkForComodification()，<br/>可以得到类似的伪代码\n```java\npublic void forEach(ArrayList<Object> list, Consumer<Object> f) {\n    Itr iter = new Itr; // new指令，分配内存空间，但未初始化，这里不是Java中的构造器调用\n    iter.cursor = 0;\n    iter.lastRet = -1;\n    iter.expectedModCount = list.modCount;\n    while (iter.cursor < list.size) {\n        if (list.modCount != iter.expectedModCount)\n            throw new ConcurrentModificationException();\n        int i = iter.cursor;\n        if (i >= list.size)\n            throw new NoSuchElementException();\n        Object[] elementData = list.elementData;\n        if (i >= elementData.length)\n            throw new ConcurrentModificationException();\n        iter.cursor = i + 1;\n        iter.lastRet = i;\n        Object obj = elementData[i];\n        f.accept(obj);\n    }\n}\n```\n伪代码中的ArrayList$Itr实例**既没有被存入任何字段之中**，**也没有作为任何方法调用的调用者或参数**，可以断定该实例**不逃逸**\n\n## 基于逃逸分析的优化\n即时编译器可以根据**逃逸分析的结果**进行如锁消除、栈上分配以及标量替换等优化\n\n### 锁消除\n1. 如果即时编译器能够**证明锁对象不逃逸**，那么对该锁对象的加锁、解锁操作时没有意义的\n    - 其他线程并不能获得该锁对象，也就不可能对该锁对象加锁\n    - 这种情况下，即时编译器可以消除对该不逃逸锁对象的加锁、解锁操作\n2. 传统编译器仅需证明锁对象不逃逸出线程，即可以进行锁消除\n    - 由于JVM**即时编译的限制**（**方法为单位**），上述条件被强化为**证明锁对象不逃逸出该编译的方法**\n3. 锁消除的例子：`synchronized(new Object()){}`\n4. 对于`synchronized(escapedObject){}`，由于其他线程可能对该逃逸了的对象escapedObject进行加锁操作\n    - 从而构造了两个线程之间的happens-before关系\n    - 因此即时编译器至少需要为这段代码生成一条刷新缓存的内存屏障指令\n5. 实际上，**基于逃逸分析的锁消除并不多见**\n    - 开发人员不会对方法中的新建对象进行加锁操作\n\n### 栈上分配\n1. JVM的对象都在堆上分配，而堆上的内容对任何线程都是可见的\n    - 同时，JVM需要对所分配的堆内存进行管理，并且在对象不再被引用时回收其占据的内存\n2. 如果逃逸分析能够证明某些**新建的对象不逃逸**，那么JVM完全可以将其分配在栈上\n    - 在new语句所在的**方法退出**时，通过**弹出当前方法的栈帧**来**自动回收**所分配的内存空间\n    - 这样便无须借助垃圾回收器来处理不再被引用的对象\n    - 但由于之前大部分代码的假设是：对象只能堆分配\n        - 因此**HotSpot没有采用栈上分配，而是使用了标量替换**\n\n### 标量替换\n1. 标量：**仅能存储一个值的变量**，例如Java代码中的局部变量\n2. 聚合量：可以同时存储多个值，例如Java对象\n3. 标量替换：**将原本对对象字段的访问，替换成对一个个局部变量的访问**\n    - 如下所示，原本需要在内存中**连续分布的对象**，被**拆分成一个个单独的字段**\n        - 这些字段即可以存储在**栈**上，也可以存储在**寄存器**中（不占用内存）\n    - 该对象的**对象头信息直接消失**，不再被保存至内存中\n4. 由于**对象没有被实际分配**，因此和栈上分配一样，同样可以**减轻垃圾回收的压力**\n5. 与栈上分配相比\n    - 标量替换**对字段的内存连续性没有要求**\n    - 字段可以**直接维护在寄存器**中，无需浪费任何内存空间\n\n```java\npublic void forEach(ArrayList<Object> list, Consumer<Object> f) {\n    // Itr iter = new Itr; // 经过标量替换后该分配无意义，可以被优化掉\n    int cursor = 0;     // 标量替换\n    int lastRet = -1;   // 标量替换\n    int expectedModCount = list.modCount; // 标量替换\n    while (cursor < list.size) {\n    if (list.modCount != expectedModCount)\n        throw new ConcurrentModificationException();\n    int i = cursor;\n    if (i >= list.size)\n        throw new NoSuchElementException();\n    Object[] elementData = list.elementData;\n    if (i >= elementData.length)\n        throw new ConcurrentModificationException();\n    cursor = i + 1;\n    lastRet = i;\n    Object obj = elementData[i];\n        f.accept(obj);\n    }\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Advanced"]},{"title":"JVM基础 -- 字节码","url":"%2F2019%2F01%2F03%2Fjvm-basic-bytecode%2F","content":"\n## 操作数栈\n1. JVM是**基于栈的计算模型**\n2. 在**解析过程**中，每当为**Java方法**分配**栈帧**时\n    - 执行每条执行之前，JVM要求该指令的操作数已被压入操作数栈中\n    - 在执行指令时，JVM会将该指令所需要的操作数**弹出**，并将该指令的结果重新**压入**栈中\n\n<!-- more -->\n\n### iadd\n1. 执行iadd之前，栈顶的元素为int值1和int值2\n2. 执行iadd指令会将弹出这两个int，并将求得的和int值3压入栈中\n3. iadd只消耗栈顶的两个元素，iadd并不关心更远的元素，也不会对它们进行修改\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-bytecode-iadd-0.png\" width=400/>\n\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-bytecode-iadd-1.png\" width=400/>\n\n\n### dup + pop\n1. dup和pop只能处理非long和非double类型的值\n2. long类型和double类型需要占据两个栈单元，对应使用dup2和pop2\n\n#### dup\n1. dup：**复制栈顶元素**\n2. dup指令常用于复制new指令生成的**未经初始化**的引用\n\n```\npublic void dup() {\n    Object o = new Object();\n}\n\n// 对应的字节码\npublic void dup();\n  descriptor: ()V\n  flags: ACC_PUBLIC\n  Code:\n    stack=2, locals=2, args_size=1\n       0: new               // class java/lang/Object\n       3: dup\n       4: invokespecial     // Method java/lang/Object.\"<init>\":()V\n       7: astore_1\n       8: return\n```\n\n1. 执行new指令时，JVM将指向一块**已分配的但未初始化**的内存引用压入操作数栈\n2. invokespecial指令将要以这个引用为调用者，调用其构造器\n    - 该指令将**消耗**操作数栈上的元素，作为它的调用者和参数\n3. 因此，在这之前利用dup**指令**复制一份new指令的结果，并用来调用构造器\n\n#### pop\n1. pop：**舍弃栈顶元素**\n2. pop指令常用于**舍弃调用指令的返回结果**\n\n```\npublic static boolean judge() {\n    return false;\n}\n\npublic void pop() {\n    judge();\n}\n\n// 对应的字节码\npublic void pop();\n  descriptor: ()V\n  flags: ACC_PUBLIC\n  Code:\n    stack=1, locals=1, args_size=1\n       0: invokestatic      // Method judge:()Z\n       3: pop\n       4: return\n```\n\n1. invokestatic指令依然会将返回值压入pop方法的操作数栈\n2. 因此JVM需要执行额外的pop指令，将返回值舍弃\n\n\n### 加载常量\n1. iconst指令加载-1和5之间的int值\n2. bipush（sipush）指令加载一个字节（两个字节）所能代表的int值\n3. ldc指令加载常量池中的常量值\n\n| 类型 | 常数指令 | 范围 |\n| ---- | ---- | ---- |\n| int/short/char/byte/boolean   | iconst  |  [-1,5]  |\n|   | bipush  | [-128,127]  |\n|   | sipush  | [-32768,32767]  |\n|   | ldc  | any int value  |\n| long  | lconst  | 0,1  |\n|   | ldc  | any long value  |\n| float   | fconst  | 0,1,2  |\n|   | ldc  | any float value |\n| double  | dconst  | 0,1  |\n|   | ldc  | any double value |\n| reference   | aconst  | null  |\n|   | ldc  | String literal,Class literal |\n\n### 异常\n1. 正常情况下，操作数栈的压入弹出都是**一条条**指令完成的\n2. 在抛出异常时，JVM会**清空**操作数栈上到所有内容，而后将异常实例的引用压入操作数栈\n\n## 局部变量表\n1. Java方法**栈帧**的组成：**操作数栈+局部变量表**\n2. 字节码程序将计算的结果**缓存**在局部变量表\n3. 局部变量表类似于一个**数组**，依次存放\n    - **this指针（针对实例方法）**\n    - **所传入的参数**\n    - **字节码中的局部变量**\n4. 与操作数栈一样，long类型和double类型将占据两个存储单元\n\n```\npublic void locals(long l, float f) {\n    {\n        int i = 0;\n    }\n    {\n        String s = \"Hello Word\";\n    }\n}\n\n// 对应的字节码\npublic void locals(long, float);\n  descriptor: (JF)V\n  flags: ACC_PUBLIC\n  Code:\n    stack=1, locals=5, args_size=3\n       0: iconst_0\n       1: istore        4\n       3: ldc               // String Hello Word\n       5: astore        4\n       7: return\n```\n\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-bytecode-locals.png\" width=400/>\n\n1. locals是一个实例方法，局部变量表的第0个单元存放this指针\n2. 第一个参数为long类型，占用局部变量表的第1、2个单元\n3. 第二个参数为int类型，占用局部变量表的第3个单元\n4. 方法体内的两个代码块中，分别定义了局部变量i和s，两者的生命周期没有重合\n    - Java编译器将它们编排至同一单元，即局部变量表的第4个单元\n    - `istore 4`和`astore 4`\n5. Java编译器在编译时就已经能确定操作数栈、局部变量表的大小以及参数个数\n    - `stack=1, locals=5, args_size=3`\n\n### 加载 + 存储\n1. 存储在局部变量表中的值，通常需要加载至操作数栈中，才能进行计算\n2. 得到的计算结果后再存储至局部变量表中\n3. 局部变量表的**加载**和**存储**指令都需要指明所加载单元的**下标**\n4. 唯一直接作用于局部变量表的指令：iinc M N\n    - 将局部变量表的第M个单元中的int值增加N\n    - 常用于for循环中的自增量的更新\n\n| 类型 | 加载指令 | 存储指令 |\n| ---- | ---- | ---- |\n| int/short/char/byte/boolean | iload | istore |\n| long | lload | lstore |\n| float | fload | fstore |\n| double | dload | dstore |\n| reference | aload | astore |\n\n```\npublic void innc() {\n    for (int i = 0; i < 100; i++) {\n    }\n}\n\n// 对应的字节码\npublic void innc();\n  descriptor: ()V\n  flags: ACC_PUBLIC\n  Code:\n    stack=2, locals=2, args_size=1\n       0: iconst_0\n       1: istore_1\n       2: iload_1\n       3: bipush        100\n       5: if_icmpge     14\n       8: iinc          1, 1 // i++\n      11: goto          2\n      14: return\n```\n\n## 其他字节码\n\n### Java相关\n1. new：后跟目标类，生成该类**未初始化**的对象引用\n2. instanceof：后跟目标类，判断**栈顶元素**是否为目标类（接口）的实例，**是则压入1，否则压入0**\n3. checkcast：后跟目标类，判断**栈顶元素**是否为目标类（接口）的实例，如果不是则**抛出异常**\n4. athrow：将**栈顶异常**抛出\n5. monitorenter：为**栈顶对象**加锁\n6. monitorexit：为**栈顶对象**解锁\n7. getstatic/putstatic/getfield/putfield\n    - **附带用于定位目标字段的信息，但消耗的操作数栈元素个各不相同**\n    - 如下图，将值v存储至对象obj的目标字段中\n8. invokestatic/invokespecial/invokevirtual/invokeinterface\n    - 这四个方法调用指令所消耗的操作数栈元素是根据**调用类型**以及**目标方法描述符**来确定的\n    - **在进行方法调用之前，需要依次压入调用者（invokestatic不需要）以及各个参数**\n\n#### putfiled\n```\npublic class PutField {\n    private Object obj;\n\n    public void putFiled() {\n        obj = new Object();\n    }\n}\n\n// 对应的字节码\npublic void putFiled();\n  descriptor: ()V\n  flags: ACC_PUBLIC\n  Code:\n    stack=3, locals=1, args_size=1\n       0: aload_0\n       1: new               // class java/lang/Object\n       4: dup\n       5: invokespecial     // Method java/lang/Object.\"<init>\":()V\n       8: putfield          // Field obj:Ljava/lang/Object;\n      11: return\n```\n\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-bytecode-putfield.png\" width=400/>\n\n\n#### invokevirtual\n```\npublic int neg(int i) {\n    return -i;\n}\n\npublic int foo(int i) {\n    return neg(neg(i));\n}\n\n// 对应的字节码\npublic int foo(int);\n  descriptor: (I)I\n  flags: ACC_PUBLIC\n  Code:\n    stack=3, locals=2, args_size=2\n       0: aload_0\n       1: aload_0\n       2: iload_1\n       3: invokevirtual     // Method neg:(I)I\n       6: invokevirtual     // Method neg:(I)I\n       9: ireturn\n```\n\nfoo(2)的执行过程\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-bytecode-invoke.png\" width=300/>\n\n\n### 数组相关\n1. newarray：新建**基本类型**的数组\n2. anewarray：新建**引用类型**的数组\n3. multianewarray：生成**多维数组**\n4. arraylegth：求**数组长度**\n5. 数组的**加载**和**存储**指令（区分类型）\n\n```\npublic void array() {\n    int[] a = new int[10];\n    Object[] b = new Object[10];\n    int[][] c = new int[10][10];\n    int l = a.length;\n}\n\n// 对应的字节码\npublic void array();\n  descriptor: ()V\n  flags: ACC_PUBLIC\n  Code:\n    stack=2, locals=5, args_size=1\n       0: bipush        10\n       2: newarray       int\n       4: astore_1\n       5: bipush        10\n       7: anewarray     #2      // class java/lang/Object\n      10: astore_2\n      11: bipush        10\n      13: bipush        10\n      15: multianewarray #3,  2 // class \"[[I\"\n      19: astore_3\n      20: aload_1\n      21: arraylength\n      22: istore        4\n      24: return\n```\n\n| 数组类型 | 加载指令 | 存储指令 |\n| ----- | ---- | ---- |\n| byte/boolean | baload | bastore |\n| char | caload | castore |\n| short | saload | sastore |\n| int | iaload | iastore |\n| long | laload | lastore |\n| float | faload | fastore |\n| double | daload | dastore |\n| reference | aaload | aastore |\n\n### 控制流\n1. goto：无条件跳转\n2. tableswitch/lookupswitch：密集case/稀疏case\n3. 返回指令\n4. 除了返回指令外，其他控制流指令均附带一个或多个字节码偏移量，代表需要跳转到的位置\n\n| 返回类型 | 返回指令 |\n| ---- | ---- |\n| void | return |\n| int/short/char/byte/boolean | ireturn |\n| long | lreturn |\n| float | freturn |\n| double | dreturn |\n| reference | areturn |\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM进阶 -- 浅谈即时编译","url":"%2F2019%2F01%2F02%2Fjvm-advanced-jit%2F","content":"\n## 概念\n1. 即时编译是用来**提升应用运行效率**的技术\n2. 代码会先在JVM上**解释执行**，之后反复执行的**热点代码**会被**即时翻译成为机器码**，直接运行在**底层硬件**上\n\n<!-- more -->\n\n## 分层编译\n1. HotSpot包含多个即时编译器：C1、C2和Graal（Java 10，实验性）\n2. 在Java 7之前，需要根据程序的特性选择对应的**即时编译器**\n    - 对于**执行时间较短**或**对启动性能有要求**的程序，采用**编译效率较快的C1**，对应参数：`-client`\n    - 对于**执行时间较长**或**对峰值性能有要求**的程序，采用**生成代码执行效率较快的C2**，对应参数：`-server`\n3. Java 7引入了**分层编译**（-XX:+TieredCompilation），综合了**C1的启动性能优势**和**C2的峰值性能优势**\n4. 分层编译将**JVM的执行状态**分了5个层次\n    - 0：解释执行（也会profiling）\n    - 1：执行**不带profiling**的C1代码\n    - 2：执行仅带**方法调用次数**和**循环回边执行次数**profiling的C1代码\n    - 3：执行带**所有profiling**的C1代码\n    - 4：执行C2代码\n5. 通常情况下，**C2代码的执行效率比C1代码高出30%以上**\n6. 对于C1代码的三种状态，按执行效率从高至低：1层 > 2层 > 3层\n    - **1层的性能略高于2层，2层的性能比3层高出30%**\n    - **profiling越多，额外的性能开销越大**\n7. profiling：在程序执行过程中，收集能够反映程序执行状态的数据\n    - profile：收集的数据\n    - JDK附带的**hprof**（CPU+Heap）\n    - JVM**内置profiling**\n8. Java 8默认开启了分层编译，无论开启还是关闭分层编译，原本的`-client`和`-client`都是无效的\n    - 如果**关闭分层编译**，JVM将直接采用**C2**\n    - 如果只想用C1，在打开分层编译的同时，使用参数：-XX:TieredStopAtLevel=1\n\n### 编译路径\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-jit-path.png\" width=600/>\n\n\n1. 1层和4层是**终止状态**\n    - 当一个**方法**被**终止状态**编译后，如果**编译后的代码没有失效**，那么JVM**不会再次发出该方法的编译请求**\n2. 通常情况下，热点方法会被3层的C1编译，然后再被4层的C2编译\n3. 如果方法的**字节码数目较少**（如getter/setter），并且**3层的profiling没有可收集的数据**\n    - JVM会断定**该方法对于C1和C2的执行效率相同**\n    - JVM会在3层的C1编译后，**直接选用1层的C1编译**\n    - 由于1层是**终止状态**，JVM不会继续用4层的C2编译\n4. 在C1忙碌的情况下，JVM在**解释执行过程**中对程序进行**profiling**，而后直接由4层的C2编译\n5. 在C2忙碌的情况下，方法会被2层的C1编译，然后再被3层的C1编译，以减少方法在3层的执行时间\n\n### 触发JIT的条件\n1. JVM是依据**方法的调用次数**以及**循环回边的执行次数**来触发JIT的\n2. JVM将在0层、2层和3层执行状态时进行profiling，其中包括方法的调用次数和循环回边的执行次数\n    - 循环回边是一个控制流程图中的概念，在字节码中，可以简单理解为**往回跳**的指令\n    - 在即时编译过程中，JVM会识别循环的头部和尾部，**循环尾部到循环头部的控制流就是真正意义上的循环回边**\n    - C1将在**循环回边**插入**循环回边计数器**的代码\n    - 解释执行和C1代码中增加循环回边计数的**位置**并不相同，但这不会对程序造成影响\n    - JVM不会对这些**计数器**进行**同步**操作，因此收集到的执行次数也**不是精确值**\n    - 只要该数值**足够大**，就能表示对应的方法包含热点代码\n3. 在**不启动**分层编译时，当**方法的调用次数和循环回边的次数的和**超过-XX:CompileThreshold，便会触发JIT\n    - 使用**C1**时，该值为**1500**\n    - 使用**C2**时，该值为**10000**\n4. 当**启用**分层编译时，阈值大小是**动态调整**的\n    - **阈值 * 系数**\n\n\n#### 系数\n```\n系数的计算方法：\ns = queue_size_X / (TierXLoadFeedback * compiler_count_X) + 1\n\n其中X是执行层次，可取3或者4\nqueue_size_X：执行层次为X的待编译方法的数目\nTierXLoadFeedback：预设好的参数，其中Tier3LoadFeedback为5，Tier4LoadFeedback为3\ncompiler_count_X：层次X的编译线程数目。\n```\n\n#### 编译线程数\n1. 在64位JVM中，默认情况下，编译线程的总数目是根据**处理器数量**来调整的\n    - -XX:+CICompilerCountPerCPU=true，**编译线程数依赖于处理器数量**\n    - -XX:+CICompilerCountPerCPU=false -XX:+CICompilerCount=N，**强制设定总编译线程数**\n2. JVM会将这些编译线程按照1:2的比例分配给C1和C2（至少1个），对于4核CPU，总编译线程数为3\n\n```\n// -XX:+CICompilerCountPerCPU=true\nn = log2(N) * log2(log2(N)) * 3 / 2\n其中 N 为 CPU 核心数目，N >= 4\n```\n\n#### 触发条件\n当启用分层编译时，触发JIT的条件\n```\ni > TierXInvocationThreshold * s || (i > TierXMinInvocationThreshold * s  && i + b > TierXCompileThreshold * s)\n其中i为方法调用次数，b为循环回边执行次数\n```\n\n## Profiling\n1. 在分层编译中的0层、2层和3层，都会进行profiling，最为基础的是**方法的调用次数**以及**循环回边的执行次数**\n    - 主要拥有触发JIT\n2. 此外，0层和3层还会收集用于4层C2编译的数据，例如\n    - **branch profiling**\n        - 分支跳转字节码，包括跳转次数和不跳转次数\n    - **type profiling**\n        - 非私有实例方法调用指令：**invokevirtual**\n        - 强制类型转换指令：**checkcast**\n        - 类型测试指令：**instanceof**\n        - 引用类型数组存储指令：**aastore**\n3. branch profiling和type profiling将给应用带来不少的**性能开销**\n    - 3层C1的性能比2层C1的性能低30%\n    - 通常情况下，我们不会在**解析执行**过程中进行branch profiling和type profiling\n        - 只有在方法**触发C1编译后**，JVM认为该方法**有可能被C2编译**，才会在该方法的C1代码中收集这些profile\n    - 只有在**极端**情况下（如等待C1编译的方法数目太多），才会开始在**解释**执行过程中收集这些profile\n    - C2可以根据收集得到的数据进行**猜测和假设**，从而作出比较**激进的优化**\n\n### branch profiling\n\n#### Java代码\n```java\npublic static int foo(boolean f, int in) {\n    int v;\n    if (f) {\n        v = in;\n    } else {\n        v = (int) Math.sin(in);\n    }\n    if (v == in) {\n        return 0;\n    } else {\n        return (int) Math.cos(v);\n    }\n}\n```\n\n#### 字节码\n```\npublic static int foo(boolean, int);\n  descriptor: (ZI)I\n  flags: ACC_PUBLIC, ACC_STATIC\n  Code:\n    stack=2, locals=3, args_size=2\n       0: iload_0\n       1: ifeq          9       // false，跳转到偏移量为9的字节码\n       4: iload_1\n       5: istore_2\n       6: goto          16\n       9: iload_1\n      10: i2d\n      11: invokestatic          // Method java/lang/Math.sin:(D)D\n      14: d2i\n      15: istore_2\n      16: iload_2\n      17: iload_1\n      18: if_icmpne     23      // 如果v!=in，跳转到偏移量为23的字节码\n      21: iconst_0\n      22: ireturn\n      23: iload_2\n      24: i2d\n      25: invokestatic          // Method java/lang/Math.cos:(D)D\n      28: d2i\n      29: ireturn\n```\n\n#### 优化过程\n\n##### 正常分支\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-jit-branch-profiling-0.png\" width=500/>\n\n\n##### profiling\n假设应用程序调用该方法，所传入的都是true，那么偏移量为1和偏移量为18的条件跳转指令所对应的分支profile中，其跳转的次数都是0。实际执行的分支如下：\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-jit-branch-profiling-1.png\" width=500/>\n\n\n##### 剪枝\nC2根据这两个分支profile作出假设，在后续的执行过程中，这两个条件跳转指令仍旧不会执行，基于这个假设，C2不会在编译这两个条件跳转语句所对应的false分支（剪枝）。最终的结果是在第一个条件跳转之后，C2代码直接返回0\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-jit-branch-profiling-2.png\" width=500/>\n\n\n#### 小结\n1. 根据条件跳转指令的分支profile，即时编译器可以将**从未执行过**的分支减掉\n    - 避免编译这些不会用到的代码\n    - 节省**编译时间**以及部署代码所要消耗的**内存空间**\n3. 剪枝同时也能精简数据流，从而触发更多的优化\n4. 现实中，分支profile出现仅跳转或者不跳转的情况并不常见\n4. 即时编译器对分支profile的利用也不仅仅限于剪枝\n    - 还可以依据分支profile，**计算每一条执行路径的概率**\n    - 以便于某些编译器优化优先处理概率较高的路径\n\n### type profiling\n\n#### Java代码\n```java\npublic static int hash(Object in) {\n    if (in instanceof Exception) {\n        return System.identityHashCode(in);\n    } else {\n        return in.hashCode();\n    }\n}\n```\n\n#### 字节码\n```\npublic static int hash(java.lang.Object);\n  descriptor: (Ljava/lang/Object;)I\n  flags: ACC_PUBLIC, ACC_STATIC\n  Code:\n    stack=1, locals=1, args_size=1\n       0: aload_0\n       1: instanceof        // class java/lang/Exception\n       4: ifeq          12  // 不是Exception，跳转到偏移量为12的字节码\n       7: aload_0\n       8: invokestatic      // Method java/lang/System.identityHashCode:(Ljava/lang/Object;)I\n      11: ireturn\n      12: aload_0\n      13: invokevirtual     // Method java/lang/Object.hashCode:()I\n      16: ireturn\n```\n\n#### 优化过程\n\n##### 正常分支\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-jit-type-profiling-0.png\" width=500/>\n\n\n##### profiling+优化\n1. 假设应用调用该方法时，所传入的Object皆为Integer实例\n    - 偏移量为1的**instanceof**指令的**类型profile**仅包含Integer\n    - 偏移量为4的分支跳转语句的**分支profile**不跳转次数为0\n    - 偏移量为13的方法调用指令的**类型profile**仅包含Integer\n2. 测试instanceof\n    - 如果instanceof的**目标类型是final类型**，那么JVM仅需比较测试**对象的动态类型**是否为该final类型\n    - 如果**目标类型不是final类型**，JVM需要依次按下列顺序测试是否与目标类型一致\n        - 该类本身\n        - 该类的父类、祖先类\n        - 该类所直接实现或间接实现的接口\n3. instanceof指令的类型profile仅包含Integer\n    - JVM会假设在接下来的执行过程中，所输入的Object对象仍为Integer对象\n    - 生成的代码将**直接测试所输入的动态类型是否为Integer**，如果是继续执行接下来的代码\n4. 然后，即时编译器会采用**针对分支profile的优化**以及**对方法调用的条件去虚化内联**\n    - 内联结果：生成的代码将测试所输入对象的动态类型是否为Integer，如果是，执行`Integer.hashCode()`方法的代码\n\n```java\npublic final class Integer ... {\n    @Override\n    public int hashCode() {\n        return Integer.hashCode(value);\n    }\n\n    public static int hashCode(int value) {\n        return value;\n    }\n}\n```\n\n针对上面三个profile的分支图\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-jit-type-profiling-1.png\" width=500/>\n\n\n进一步优化（剪枝）\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/advanced/jvm-advanced-jit-type-profiling-2.png\" width=500/>\n\n\n#### 小结\n1. 和基于分支profile的优化一样，基于类型profile的优化同样也是作出假设，从而精简控制流以及数据流，两者的**核心是假设**\n2. 对于**分支profile**，即时编译器假设**仅执行某一分支**\n3. 对于**类型profile**，即时编译器假设的是**对象的动态类型仅为类型profile中的那几个**\n4. 如果**假设失败**，将进入**去优化**\n\n### 去优化\n1. 去优化：从执行即时编译生成的机器码**切回解释执行**\n2. 在生成的机器码中，即时编译器将在**假设失败**的位置插入一个**陷阱**（trap）\n    - 陷阱实际上是一条**call指令**，调用至JVM**专门负责去优化的方法**\n    - 上图红色方框的问号，便代表陷阱\n3. 去优化的过程很复杂，由于即时编译器采用了许多优化方式，其生成的代码和原本字节码的差异非常大\n4. 在去优化的过程中，**需要将当前机器码的执行状态切换至某一字节码之前的执行状态，并从该字节码开始执行**\n    - 要求即时编译器在编译过程中记录好这两种执行状态的**映射**\n5. 在调用JVM的去优化方法时，即时编译器生成的机器码可以根据**产生去优化的原因**决定**是否保留这份机器码**，以及**何时重新编译对应的Java代码**\n    - 如果去优化的原因**与优化无关**\n        - 即使重新编译也不会改变生成的机器码，那么生成的机器码可以在调用去优化代码时传入**Action_None**\n        - **表示保留这一份机器码，在下次调用该方法时重新进入这一份机器码**\n    - 如果去优化的原因**与静态分析的结果有关**，例如类层次分析\n        - 那么生成的机器码可以在调用去优化方法时传入**Action_Recompile**\n        - **表示不保留这一份机器码，但是可以不经过重新收集profile，直接重新编译**\n    - 如果去优化的原因**与基于profile的激进优化有关**\n        - 那么生成的机器码需要在调用去优化方法时传入**Action_Reinterpret**\n        - **表示不保留这一份机器码，并且需要重新收集profile，再重新编译**\n        - 因为之前收集到的profile已经**不能准确**反映程序的运行情况，需要重新收集\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Advanced"]},{"title":"JVM基础 -- Java语法糖","url":"%2F2019%2F01%2F01%2Fjvm-basic-sugar%2F","content":"\n## 自动装拆箱\n\n### Java代码\n```java\npublic int foo() {\n    List<Integer> list = new ArrayList<>();\n    list.add(0);\n    return list.get(0);\n}\n```\n\n<!-- more -->\n\n### 字节码\n```\npublic int foo();\n  descriptor: ()I\n  flags: ACC_PUBLIC\n  Code:\n    stack=2, locals=2, args_size=1\n       0: new               // class java/util/ArrayList\n       3: dup\n       4: invokespecial     // Method java/util/ArrayList.\"<init>\":()V\n       7: astore_1\n       8: aload_1\n       9: iconst_0\n       // 自动装箱\n      10: invokestatic      // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer;\n       // 伪泛型\n      13: invokeinterface   // InterfaceMethod java/util/List.add:(Ljava/lang/Object;)Z\n      18: pop\n      19: aload_1\n      20: iconst_0\n       // 伪泛型\n      21: invokeinterface   // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;\n       // 类型转换\n      26: checkcast         // class java/lang/Integer\n       // 自动拆箱\n      29: invokevirtual     // Method java/lang/Integer.intValue:()I\n      32: ireturn\n```\n\n#### 自动装箱\n```java\n// 字节码中的方法描述符：java/lang/Integer.valueOf:(I)Ljava/lang/Integer\n// -Djava.lang.Integer.IntegerCache.high=128\n// -XX:+AggressiveOpts会让AutoBoxCacheMax到达20_000\n// Java暂不支持IntegerCache.low的更改\npublic static Integer valueOf(int i) {\n    if (i >= IntegerCache.low && i <= IntegerCache.high)\n        return IntegerCache.cache[i + (-IntegerCache.low)];\n    return new Integer(i);\n}\n```\n\n#### 自动拆箱\n```java\n// 字节码中的方法描述符：java/lang/Integer.intValue:()I\npublic int intValue() {\n    return value;\n}\n```\n\n## 泛型与类型擦除\n截取上面关键的字节码\n```\n// 伪泛型，add(Object):Z\n13: invokeinterface   // InterfaceMethod java/util/List.add:(Ljava/lang/Object;)Z\n// 伪泛型，get(I):Object\n21: invokeinterface   // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object;\n// 类型转换，方便后续的自动拆箱\n26: checkcast         // class java/lang/Integer\n```\n\n1. **Java程序里面的泛型信息，在JVM里面全部丢失**\n    - 主要是为了**兼容**引入泛型之前的代码\n2. Java编译器会选取该泛型能指代的所有类中**层次最高**的那个，作为替换泛型的类\n    - 对于**限定了继承类**的泛型参数，类型擦除后，所有的类型参数都会变成所限定的继承类\n    - 否则，将**默认限定了继承自Object**\n\n### Java代码\n```java\npublic class Generic<T extends Number> {\n    T func(T t) {\n        return t;\n    }\n}\n```\n\n### 字节码\n```\nT func(T);\n  descriptor: (Ljava/lang/Number;)Ljava/lang/Number;\n  flags:\n  Code:\n    stack=1, locals=2, args_size=2\n       0: aload_1\n       1: areturn\n    LineNumberTable:\n      line 5: 0\n    LocalVariableTable:\n      Start  Length  Slot  Name   Signature\n          0       2     0  this   Lme/zhongmingmao/basic/sugar/Generic;\n          0       2     1     t   Ljava/lang/Number;\n    LocalVariableTypeTable:\n      Start  Length  Slot  Name   Signature\n          0       2     0  this   Lme/zhongmingmao/basic/sugar/Generic<TT;>;\n          0       2     1     t   TT;\n  Signature: #19                          // (TT;)TT;\n```\n\n1. 方法描述符的接收参数类型以及返回参数类型都是Number\n2. 字节码仍然存在泛型参数的信息，例如`T func(T);`和方法签名`(TT;)TT;`\n    - 这类信息主要在Java编译器**编译其他类**时使用\n\n## foreach\n\n### 数组\n```java\npublic void funa(int[] array) {\n    for (int item : array) {\n    }\n}\n\n// 等同于\npublic void funb(int[] array) {\n    int[] tmpArray = array;\n    int length = tmpArray.length;\n    for (int i = 0; i < length; i++) {\n        int item = tmpArray[i];\n    }\n}\n```\n\n### Iterable对象\n```java\npublic void func(List<Iterable> list) {\n    for (Iterable item : list) {\n    }\n}\n\n// 等同于\npublic void fund(List<Iterable> list) {\n    Iterator<Iterable> iterator = list.iterator();\n    while (iterator.hasNext()) {\n        Iterable item = iterator.next();\n    }\n}\n```\n\n## switch\n\n### Java代码\n```java\npublic void func(String s) {\n    switch (s) {\n        case \"A\":\n            break;\n        case \"B\":\n            break;\n        default:\n            break;\n    }\n}\n```\n\n### 字节码\n```\npublic void func(java.lang.String);\n  descriptor: (Ljava/lang/String;)V\n  flags: ACC_PUBLIC\n  Code:\n    stack=2, locals=4, args_size=2\n       0: aload_1\n       1: astore_2\n       2: iconst_m1\n       3: istore_3\n       4: aload_2\n       // 取字符串的hashCode\n       5: invokevirtual         // Method java/lang/String.hashCode:()I\n       8: lookupswitch  {\n                    65: 36      // 65 -> \"A\"\n                    66: 50      // 66 -> \"B\"\n               default: 61\n          }\n      36: aload_2\n      37: ldc                   // String A\n      39: invokevirtual         // Method java/lang/String.equals:(Ljava/lang/Object;)Z\n      42: ifeq          61\n      45: iconst_0\n      46: istore_3\n      47: goto          61\n      50: aload_2\n      51: ldc                   // String B\n      53: invokevirtual         // Method java/lang/String.equals:(Ljava/lang/Object;)Z\n      56: ifeq          61\n      59: iconst_1\n      60: istore_3\n      61: iload_3\n      62: lookupswitch  {\n                     0: 88\n                     1: 91\n               default: 94\n          }\n      88: goto          94\n      91: goto          94\n      94: return\n```\n\n1. 每个case截获的字符串都是一个**常量值**，取其**hashCode**，当成**int值的switch**\n2. 由于hashCode有可能发生**碰撞**，因此还需要借助`String.equals`逐个比较发生了碰撞的字符串\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- 浅谈synchronized","url":"%2F2018%2F12%2F30%2Fjvm-basic-synchronized%2F","content":"\n## 抽象算法\n\n### synchronized代码块\n```java\npublic void foo(Object lock) {\n    synchronized (lock) {\n        lock.hashCode();\n    }\n}\n```\n\n<!-- more -->\n\n```\npublic void foo(java.lang.Object);\n  descriptor: (Ljava/lang/Object;)V\n  flags: ACC_PUBLIC\n  Code:\n    stack=2, locals=4, args_size=2\n       0: aload_1\n       1: dup\n       2: astore_2\n       3: monitorenter\n       4: aload_1\n       5: invokevirtual #2                  // Method java/lang/Object.hashCode:()I\n       8: pop\n       9: aload_2\n      10: monitorexit\n      11: goto          19\n      14: astore_3\n      15: aload_2\n      16: monitorexit\n      17: aload_3\n      18: athrow\n      19: return\n    Exception table:\n       from    to  target type\n           4    11    14   any\n          14    17    14   any\n```\n1. monitorenter指令和monitorexit指令均会消耗操作数栈上的一个**引用类型**元素，作为所要加锁解锁的**锁对象**\n2. 上面的字节码包含一个monitorenter指令和多个monitorexit指令\n    - JVM需要保证所获得的锁在**正常执行路径**以及**异常执行路径**上都能够被**解锁**\n    - 具体的执行路径请参照**Exception table**\n\n### 实例方法 + 静态方法\n```java\npublic synchronized void eoo(Object lock) {\n    lock.hashCode();\n}\n```\n\n```\npublic synchronized void eoo(java.lang.Object);\n  descriptor: (Ljava/lang/Object;)V\n  flags: ACC_PUBLIC, ACC_SYNCHRONIZED\n  Code:\n    stack=1, locals=2, args_size=2\n       0: aload_1\n       1: invokevirtual #2                  // Method java/lang/Object.hashCode:()I\n       4: pop\n       5: return\n```\n1. 字节码中方法的访问标记（flags）包括**ACC_SYNCHRONIZED**\n2. 进入该方法时，JVM需要执行monitorenter操作\n3. 不管正常返回还是向调用者抛出异常，JVM均需要执行monitorexit操作\n4. 这里的monitorenter操作和monitorexit操作**所对应的锁对象是隐式**的\n    - 对于**实例方法**来说，锁对象为**this**\n    - 对于**静态方法**来说，锁对象为**所在类的Class实例**\n\n### monitorenter + monitorexit\n1. 抽象理解：每个**锁对象**拥有一个**锁计数器**和**指向持有该锁的线程的指针**\n2. 当执行monitorenter时，如果锁对象的计数器为0\n    - 那么说明锁对象还没有被其他线程所持有\n    - JVM会将锁对象的持有线程设置为当前线程，并将计数器+1\n3. 当执行monitorenter时，如果锁对象的计数器不为0\n    - 如果锁对象的持有线程是当前线程，那么JVM会将其计数器+1\n    - 否则需要等待，直到持有该锁对象的线程释放该锁\n4. 当执行monitorexit时，JVM则需要将该锁对象的计数器-1\n    - 当计数器减为0时，那么代表该锁已经被释放掉了\n5. 采用计数器的方式，是为了允许同一个线程重复获取同一把锁，**可重入**\n\n\n## 锁优化\n\n### 对象状态图\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-synchronized.gif\" width=800/>\n\n\n针对**一个对象的整个生命周期**，锁升级是**单向不可逆**：偏向锁 -> 轻量级锁 -> 重量级锁\n\n### 重量级锁\n1. 重量级锁是JVM中最为基础的锁实现\n    - JVM会阻塞加锁失败的线程，并在目标锁被释放掉的时候，唤醒这些线程\n    - Java线程的**阻塞**和**唤醒**，都依赖于**操作系统**完成\n    - 涉及系统调用，需要从操作系统的**用户态切换至内核态**，**开销很大**\n    - 每个**Java对象**都存在一个与之关联的**monitor对象**\n2. 为了尽量避免昂贵的线程阻塞和唤醒操作，采用**自旋**\n    - 自旋：在处理器上**空跑**并且**轮询锁是否被释放**\n    - 线程会进入自旋的两种情况（**睡前醒后**）\n        - 线程即将**进入阻塞状态之前**\n        - 线程**被唤醒后竞争不到锁**\n    - 与线程阻塞相比，自旋可能会**浪费大量的处理器资源**\n        - JVM采取的是**自适应自旋**\n        - 根据以往**自旋等待时间**是否能够获得锁来动态调整自旋的时间（循环次数）\n    - 自旋还会带来**不公平锁**\n        - 处于阻塞状态的线程，没有办法立即竞争被释放的锁\n        - 而处于自旋状态的线程，则很有可能优先获得这把锁\n\n### 轻量级锁\n1. 场景：**多个线程在不同的时间段请求同一把锁，没有锁竞争**\n2. JVM采用轻量级锁，可以避免**避免重量级锁的阻塞和唤醒**\n\n#### 加锁\n1. 如果锁对象标记字段的最后两位为**01**（**无锁或偏向锁**）\n2. JVM会在**当前栈帧**中建立一个名为**锁记录**（Lock Record）的内存空间\n    - 用于存储锁对象当前的标记字段（Mark Word）的拷贝，叫作**Displaced Mark Word**\n3. 拷贝锁对象的标记字段到锁记录中，见下图：轻量级锁CAS操作之前\n4. JVM使用**CAS操作**\n    - 将**锁对象的标记字段更新为指向锁记录的指针**\n    - 将**锁记录里面的owner指针指向锁对象**\n5. 如果CAS更新成功，那么当前线程**拥有**了该锁对象的**锁**，并将锁对象标记字段的锁标志位设置为**00**\n    - 此时该锁对象处于轻量级锁的状态，见下图：轻量级锁CAS操作之后\n6. 如果CAS更新失败，检查**锁对象的标记字段**是否指向**当前线程的栈帧**\n    - 如果是，说明**锁重入**，继续执行同步代码\n    - 如果不是，说明出现多线程竞争，膨胀为**重量级锁**\n        - 锁标记位变为**10**，锁对象的标记字段存储的是**指向monitor对象的指针**\n        - **后面等待锁的线程进入阻塞状态，当前线程则尝试使用自旋来获取锁**\n\n轻量级锁CAS操作之前\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-synchronized-lightweight-before-cas.png\" width=400/>\n\n\n轻量级锁CAS操作之后\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-synchronized-lightweight-after-cas.png\" width=300/>\n\n\n#### 解锁\n1. JVM通过**CAS操作**，**把线程中的Displaced Mark Word复制回锁对象的标记字段**\n2. 如果CAS更新成功，同步过程结束\n3. 如果CAS更新失败，说明其他线程尝试获取过该锁（**现已膨胀**），在释放锁的同时，**唤醒被挂起的线程**\n\n### 偏向锁\n1. 在**无多线程竞争**的情况下，仍然需要**尽量减少不必要的轻量级锁的执行路径**\n    - 轻量级锁的获取和释放**依赖多次CAS原子指令**\n    - 由此引入了偏向锁\n2. 偏向锁乐观地认为：**从始至终只有一个线程请求某一把锁**\n    - 只需要在置换ThreadID时需要依赖一次CAS操作\n    - 一旦出现多线程**竞争**，必须**撤销**偏向锁\n    - 轻量级锁是为了在**线程交替执行**同步块时提高性能\n    - 偏向锁是为了在**只有一个线程执行**同步块时进一步提高性能\n\n#### 加锁\n1. 偏向锁只会在**第1次**加锁时采用CAS操作\n2. 如果锁对象的标记字段最后三位为**101**，即**可偏向状态**\n3. 锁对象处于**未偏向**状态（Thread ID == 0）\n    - 那么JVM会通过**CAS操作**，将**当前线程的ID**记录在该**锁对象的标记字段**中\n    - 如果CAS成功，则认为当前线程获得该锁对象的偏向锁\n    - 如果CAS失败，说明另外一个线程抢先获取了偏向锁\n        - 此时需要**撤销偏向锁**，使得锁对象进入**轻量级锁**状态\n4. 锁对象处于**已偏向**状态（Thread ID != 0）\n    - 检测：**标记字段中的线程ID == 当前线程的ID？**\n    - 如果是，说明**锁重入**，直接返回\n    - 如果不是，说明该锁对象目前偏向于其他线程，需要**撤销偏向锁**\n    - 一个线程执行完同步代码后，**不会将标记字段的线程ID清空**，最小化开销\n\n#### 撤销\n1. 偏向锁只有遇到**其他线程尝试竞争偏向锁**时，持有偏向锁的线程才会释放锁，**线程本身不会主动释放偏向锁**\n2. 偏向锁的撤销，需要等待**全局安全点**，暂停拥有偏向锁的线程，判断**锁对象当前是否处于被锁定的状态**\n    - 如果是，撤销偏向锁后升级为**轻量级锁**的状态\n    - 如果不是，撤销偏向锁后恢复为**无锁**状态\n3. 如果某个类的总撤销数超过-XX:BiasedLockingBulkRevokeThreshold=40\n    - Threshold of number of revocations per type to **permanently** revoke biases of all objects in the heap of that type\n    - JVM会**撤销该类实例的偏向锁**，并且在之后的加锁过程中直接为该类实例设置为**轻量级锁**\n\n## 参考资料\n1. https://wiki.openjdk.java.net/display/HotSpot/Synchronization\n2. http://stas-blogspot.blogspot.com/2011/07/most-complete-list-of-xx-options-for.html\n3. https://www.cnblogs.com/paddix/p/5405678.html\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- Java内存模型","url":"%2F2018%2F12%2F30%2Fjvm-basic-jmm%2F","content":"\n## JIT的重排序\n\n### Java代码\n```java\npublic class JMM {\n    private int a = 0;\n    private int b = 0;\n\n    public void method1() {\n        int r2 = a; // A1\n        b = 1; // A2\n    }\n\n    public void method2() {\n        int r1 = b; // B1\n        a = 2; // B2\n    }\n}\n```\n\n- 单线程，method1->method2，**(r1,r2)=(1,0)**\n- 单线程，method2->method1，**(r1,r2)=(0,2)**\n- 多线程，没有重排序，A1->B1->A2->B2，**(r1,r2)=(0,0)**\n- 多线程，重排序，A2->B1->B2->A1，**(r1,r2)=(1,2)**\n\n<!-- more -->\n\n### As-If-Serial\n1. 在**单线程**情况下，要给程序造成一个**顺序执行**的假象\n    - 即经过**重排序的执行结果**要与**顺序执行的结果**保持一致\n2. 如果两个操作之间存在**数据依赖**，那么即时编译器（和处理器）**不能调整它们之间的顺序**\n\n## happens-before\n1. Java 5引入了明确定义的**Java内存模型**，其中最为重要的是**happens-before**关系\n    - happens-before关系用来描述**两个操作的内存可见性**\n    - **如果操作X happens-before 操作Y，那么X的结果对于Y可见**\n2. 线程**内**的happens-before\n    - 在**同一个线程**中，**字节码的先后顺序（program order）也暗含了happens-before关系**\n    - 在程序控制流路径中**靠前的字节码happens-before靠后的字节码**\n    - 但**不意味着前者一定在后者之前执行**，实际上，如果**后者没有数据依赖于前者**，它们可能会被**重排序**\n3. 线程**间**的happens-before\n    - 解锁操作happens-before之后（**时钟顺序**）对**同一把锁**的加锁操作\n    - volatile字段的写操作happens-before之后（**时钟顺序**）对同一字段的读操作\n    - 线程的启动操作（Thread.start()）happens-before该线程的第一个操作\n    - 线程的最后一个操作happens-before它的终止事件\n        - 其他线程通过Thread.isAlive()或者Thread.join()判断该线程是否终止\n    - 线程对其他线程的中断操作happens-before被中断线程所收到的中断事件\n        - 被中断线程的InterruptedException，\n        - 第三个线程针对被中断线程的Thread.interrupted()或者thread.isInterrupted()调用\n    - 构造器中的最后一个操作happens-before析构器的第一个操作\n4. happens-before具有**传递性**\n5. 上面的代码除了默认的线程内happens-before关系外，没有定义任何其他的happens-before关系\n    - 拥有happens-before关系的两对赋值操作之间**没有任何数据依赖**\n    - 因此，即时编译器、处理器都可以对其进行重排序\n    - 可以在程序中加入happens-before关系来解决，例如将a或b设置为volatile字段\n\n```java\npublic class JMMVolatile {\n    private int a = 0;\n    private volatile int b = 0;\n\n    public void method1() {\n        int r2 = a; // A1\n        b = 1; // A2\n    }\n\n    public void method2() {\n        int r1 = b; // B1\n        a = 2; // B2\n    }\n}\n```\n1. A1 happens-before A2，B1 happens-before B2\n2. A2 happens-before B1\n3. 依据传递性，A1 happens-before B2\n    - 因此r2不可能为2\n4. **没有标记为volatile，在同一线程中，A1和A2存在happens-before关系，但没有数据依赖，因此可以重排序**\n5. 一旦**标记了volatile**，即时编译器和CPU需要考虑多线程happens-before关系，因此就**不能自由重排序**了\n6. 解决类似问题的关键：**构造一个跨线程的happens-before关系**\n    - **操作X happens-before 操作Y，使得操作X之前的字节码结果对操作Y之后的字节码可见**\n\n## JMM的底层实现\n1. JMM是通过**内存屏障**（memory barrier）来**禁止即时编译器的重排序**的\n2. 对于**即时编译器**来说，会**针对每个happens-before关系**，向正在编译的目标方法中插入相应的内存屏障\n    - 内存屏障类型：读读、读写、写读和写写\n    - 这些内存屏障会**限制即时编译器的重排序操作**\n3. 对于volatile字段，即时编译器将在**volatile字段的读写操作前后**各插入一些内存屏障，这些内存屏障\n    - 既**不允许**volatile字段**写操作之前的内存访问被重排序至其之后**\n    - 也**不允许**volatile字段**读操作之后的内存访问被重排序至其之前**\n4. 即时编译器将根据具体的底层体系架构，将这些**内存屏障都替换成具体的cpu指令**\n    - 在X86_64架构上，其他内存屏障都是空操作，只有**写读**内存屏障需要被替换成具体指令\n    - 在**X86_64**架构上，只有volatile字段**写操作之后的写读内存屏障**需要用具体的指令来替代\n        - 具体指令的效果：**强制刷新处理器的写缓存，使得当前线程写入的volatile字段的值，同步至主内存中**\n        - 写缓存：在碰到内存写操作的时，处理器并不会等待该指令结束，而是直接开始下一指令，并且依赖写缓存将更改的数据同步到主内存中\n        - **内存写操作同时会无效化其他处理器所持有的、指向同一内存地址的缓存行，因此其他处理器能够立即见到该volatile字段的最新值**\n5. 对于**即时编译器**来说，内存屏障将**限制**它所能做的**重排序优化**\n6. 对于**处理器**来说，内存屏障会导致**刷新缓存**操作\n\n## 锁与volatile字段\n\n### 锁\n1. 在**解锁**时，JVM同样需要**强制刷新缓存**，使得当前线程所修改的内存对其他线程可见\n2. 锁操作的happens-before规则针对的同一把锁，如果编译器能够证明锁仅被同一线程持有，那么久可以移除相应的加锁解锁操作\n    - 因此也不会再强制刷新缓存，例如即时编译后的`synchronized(new Object()){}`等同于空操作\n\n### volatile字段\n1. volatile字段是一种**轻量级的，不保证原子性的同步，性能往往优于锁操作**\n2. 频繁地访问volatile字段也会因为不断地**强制刷新缓存而严重影响程序的性能**\n3. 在X86_64平台上，只有volatile字段的写操作会强制刷新缓存\n4. 理想情况下，对volatile字段的使用应当是**读多写少**，并且应当**只有一个线程进行写操作**\n5. volatile字段的**每次访问**均需要**直接从内存中读写**\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- 垃圾回收基础","url":"%2F2018%2F12%2F26%2Fjvm-basic-gc%2F","content":"\n## 判定对象存亡\n\n垃圾回收标记的是**非垃圾**\n\n### 引用计数法\n1. 为每个对象添加一个**引用计数器**，用来统计**指向该对象的引用个数**\n    - 如果有一个引用，被赋值为某一对象，那么将该对象的引用计数器+1\n    - 如果指向某一对象的引用，被赋值为其他值，那么该对象的引用计数器-1\n2. 一旦某个对象的引用计数器为**0**，说明对象已经**死亡**\n3. 缺点\n    - 额外的空间来存储计数器 + 繁琐的更新操作\n    - 无法处理**循环引用**的场景，造成**内存泄露**\n\n<!-- more -->\n\n### 可达性分析\n1. 将一系列**GC Roots**作为**初识存活对象合集**\n    - 标记：从该集合出发，探索所有能够被该集合引用到的对象，并将其加入到该集合中\n    - 最终未被探索到的对象便是死亡，可以被回收\n2. GC Roots：**堆外指向堆内的引用**，一般包括\n    - Java方法栈帧中的局部变量\n    - 已加载类的静态变量\n    - 已启动且未停止的Java线程\n    - JNI MethodHandles\n\n## STW + 安全点\n1. JVM中的**STW**是通过**安全点机制**来实现的\n2. 当JVM收到**STW请求**时，会等待**所有的线程都到达安全点**，才允许请求STW的线程进行**独占地工作**\n3. 安全点的初衷并不是让其他线程停下，而是找到一个**稳定的执行状态**\n    - 在这个执行状态下，JVM的**堆栈不会发生变化**\n    - 垃圾回收器能够**安全地执行可达性分析**\n4. JNI：\n    - Java程序通过JNI执行本地代码时，如果本地代码不**访问Java对象**、**调用Java方法**或者**返回至Java方法**\n    - 那么JVM的堆栈是不会发生改变的，这段本地代码可以作为一个**安全点**\n    - 主要不离开这个安全点，JVM便能够在垃圾回收的**同时**，继续运行这段本地代码\n    - JVM仅需要在上述3个操作对应的**JNI API入口处**进行**安全点检测**\n        - 测试是否有其他线程请求停留在安全点，就可以在必要的时候挂起当前线程\n5. Java线程状态\n    - 运行状态\n        - 解释执行字节码\n        - 执行即时编译生成的机器码\n        - JVM需要**在可预见的时间内进入安全点**，否则**垃圾回收线程可能长期处于等待所有线程进入安全点的状态**，反而提高了垃圾回收的暂停时间\n    - 线程阻塞\n        - 阻塞的线程处于**JVM线程调度器的掌控之下**，属于**安全点**\n6. 解析执行\n    - **字节码与字节码之间皆可作为安全点**\n    - 当有**安全点请求**时，**执行一条字节码便进行一次安全点检测**\n7. 执行即时编译生成的机器码\n    - 代码直接运行在底层硬件上，**不受JVM掌控**\n    - 在即时编译时，需要**插入安全点检测**，**避免机器码长时间没有安全点检测的情况**\n    - 为什么不在**每一条机器码**或者**每一个机器码基本块**处插入安全点检测\n        - 性能开销：安全点检测本身也有一定的**开销**\n        - 内存开销：即时编译器生成的机器码打乱了原本栈帧上的对象分布状况，为了方便垃圾回收器能够枚举GC Roots，需要不少的**额外空间**来存储额外信息\n\n## 垃圾回收的方式\n\n### 清除（Sweep）\n1. 把死亡对象所占据的内存标记为空闲内存，并记录在一个**空闲列表**中\n2. 当需要新建对象时，内存管理模块便会从该空闲列表中寻找空闲内存，并划分给新建的对象\n3. 缺点\n    - **内存碎片：JVM堆中的对象必须是连续分布的**\n    - **分配效率低下：逐个访问列表中的项，来查找能够放入新建对象的空闲内存**\n\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-gc-sweep.png\" width=600/>\n\n\n### 压缩（Compact）\n1. 把**存活对象**聚集到内存区域的**起始位置**，从而留下一段**连续的内存空间**\n2. 能**解决内存碎片**的问题，代价为**压缩算法的性能开销**\n\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-gc-compact.png\" width=600/>\n\n### 复制（Copy）\n1. 把内存区域划分为**两等分**，分别用from和to指针来维护，**from指针**指向的内存区域用来**分配内存**\n2. 当发生垃圾回收时，便**把存活的对象复制到to指针指向的内存区域**，并且**交换from指针和to指针的内容**\n3. 同样能**解决内存碎片**的问题，代价为**堆空间的使用效率极其低下**\n4. 压缩也需要复制数据\n    - 压缩：需要**复杂的算法**保证引用能够正确更新\n    - 复制：可以在**复制完成后统一更新**引用\n\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-gc-copy.png\" width=600/>\n\n## 分代回收\n1. 分代回收的背景：大部分Java对象只存活一小段时间，而存活下来的小部分Java对象会存活很长时间\n2. 将堆空间划分为新生代和老年代，新生代用于存储新建对象，如果对象存活时间足够长，则会被移动到老年代\n3. 对应新生代，Java对象只存活很短时间，因此可以**频繁**地采用**耗时较短**的垃圾回收算法\n4. 对于老年代，由于在一般情况下大部分垃圾已经在新生代被回收，而在老年代的对象很大概率会继续存活，如果触发老年代回收，说明\n    - 新生代并没有回收大部分本该回收的垃圾\n    - 堆空间已经耗尽\n5. 对于老年代回收，JVM将做一次**全堆扫描**，**耗时可能将不计成本**\n\n## Minor GC\n\n### 堆划分\n1. 新生代将分为Eden区和两个大小相同的Survivor区\n2. 默认情况下，JVM采取**动态分配**的策略（**-XX:+UsePSAdaptiveSurvivorSizePolicy**）\n    - 依据**生成对象的速率**，以及**Survivor区的使用情况**动态调整Eden区和Survivor区的比例\n    - 也可以通过**-XX:SurvivorRatio=8**来固定这个比例\n    - 其中一个Survivor区会**一直为空**，比例越低堆空间浪费越严重\n3. 调用**new**指令时，会在**Eden**区划出一块作为存储对象的内存\n    - 由于**堆空间**是**内存共享**的，因此需要**同步**\n    - JVM采用的技术为**TLAB**（Thread Local Allocation Buffer），-XX:+UseTLAB，**默认开启**\n\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-gc-heap.png\" width=600/>\n\n#### TLAB\n1. 每个**线程**可以向JVM申请一段**连续的内存**，作为**线程私有的TLAB**\n    - 这个操作需要**加锁**，线程需要维护两个指针，一个指向**TLAB中空余内存的起始位置**，一个指向**TLAB的末尾**\n2. new指令，直接通过**指针加法**来实现，即把指向空余内存位置的指针加上所请求的字节数\n    - 如果加法后空余内存指针的值仍然小于等于指向末尾的指针，代表分配成功\n    - 否则TLAB已经没有足够的空间来满足本次新建操作，这个时候需要当前线程**重新申请新的TLAB**\n\n### Minor GC\n1. 当**Eden区的空间被耗尽**，JVM会触发一个**Minor GC**，来**回收新生代的垃圾**\n2. 当发生Minor GC时，**Eden区和from指向的Survivor区中的存活对象会被复制到to指向的Survivor区**，然后交换from和to指针\n3. JVM会记录Survivor区中的对象一共被来回复制了几次\n    - 当一个对象被复制的次数为-XX:+MaxTenuringThreshold=15时，那么该对象将被晋升到老年代\n    - 15的原因是**对象年龄**（在对象头中）使用**4bit**记录\n4. 如果Survivor区已经被占用-XX:TargetSurvivorRatio=50%的时候，那么**较高复制次数的对象**也会被晋升到老年代\n5. 发生Minor GC时，采用**标记-复制**算法\n    - 理想情况下，Eden区中的对象都**基本死亡**了，那么需要**复制的数据是非常少**的，效果将很好\n6. Minor GC**无需对整个堆进行回收**\n    - **老年代的对象可能引用新生代的对象**\n    - 在之前，在标记存活对象的时候，需要扫描整个老年代中的对象\n    - **如果老年代的对象拥有对新生代对象的引用，那么这个引用也会被作为GC Roots**\n    - 借助**卡表**，**无需全堆扫描**\n\n### 卡表（HotSpot）\n1. 将**整个堆**划分为大小为**512Bytes**的卡，并且维护一个卡表，用来存储**每张卡的标识位**\n    - 标识位：**对应的卡是否可能存在有指向新生代对象的引用**\n    - 如果**可能存在**，即认为这张卡是**脏**的\n2. 在进行**Minor GC**的时候，便可以**不用扫描整个老年代**，而是**在卡表中寻找脏卡**，并将**脏卡中的对象加入到Minor GC的GC Roots**里\n    - **当完成所有脏卡的扫描后，JVM会将所有的脏卡的标识位清零**\n3. Minor GC伴随着**存活对象的复制**，而在复制的同时**需要更新指向被复制对象的引用**\n    - 在更新引用的同时，又可以**设置引用所在卡的标识位**\n    - 在这个时候，可以**确保脏卡中必定包含指向新生代对象的引用**\n4. **在（下一次）Minor GC之前，并不能确保脏卡中包含指向新生代对象的引用**\n    - 如果想要保证每个可能有指向新生代对象引用的卡都被标记为脏卡，JVM需要**截获每个引用类型实例变量的写操作**，并作出对应的写标识位操作\n    - 在解释执行器中比较容易实现，在即时编译器生成的字节码中，需要插入额外的逻辑，即**写屏障**\n    - 写屏障需要**尽可能保持简洁**，因为不能在每条引用型实例变量的写指令后注入大量的指令\n        - **写屏障并不会判断更新后的引用是否真的指向新生代中的对象，而是一律当成可能指向新生代对象的引用**\n        - 原则：**宁杀错，勿放过**\n        - 伪代码：`CARD_TABLE [this address >> 9] = DIRTY;`\n    - 虽然写屏障存在一定开销，但能够**加大Minor GC的吞吐量** -- AppTime/(AppTime+GcTime)\n    - 在**高并发**环境下，写屏障会出现**伪共享**的问题\n        - **卡表中不同卡的标识位之间的伪共享**\n        - 在HotSpot中，使用-XX:+UseCondCardMark来尽量减少写卡表的操作\n\n\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- Java对象的内存布局","url":"%2F2018%2F12%2F22%2Fjvm-baisc-jol%2F","content":"\n## 创建对象\n1. new + 反射\n    - 通过调用**构造器**来初始化实例字段\n2. Object.clone + 反序列化\n    - 通过直接**复制已有的数据**，来初始化新建对象的实例字段\n3. Unsafe.allocateInstance\n    - 不会初始化实例字段\n\n```\n// Foo foo = new Foo();对应的字节码\n// new指令：请求内存\n0: new              // class me/zhongmingmao/basic/jol/Foo\n3: dup\n// invokespecial指令：调用构造器\n4: invokespecial    // Method \"<init>\":()V\n```\n\n<!-- more -->\n\n## Java构造器\n\n### 默认构造器\n如果一个类**没有定义任何构造器**，那么Java编译器会自**动添加一个无参数的构造器**\n\n#### Java代码\n```java\n// 未定义任何构造器\npublic class Foo {\n    public static void main(String[] args) {\n        Foo foo = new Foo();\n    }\n}\n```\n\n#### 字节码\n```\n// Foo类的构造器会调用父类Object的构造器\npublic me.zhongmingmao.basic.jol.Foo();\n  descriptor: ()V\n  flags: ACC_PUBLIC\n  Code:\n    stack=1, locals=1, args_size=1\n       0: aload_0           // [this]\n       1: invokespecial     // Method java/lang/Object.\"<init>\":()V\n       4: return\n```\n\n### 父类构造器\n1. **子类的构造器需要调用父类的构造器**\n2. 如果**父类存在无参数的构造器**，可以**隐式调用**，即Java编译器会自动添加对父类构造器的调用\n3. 如果**父类没有无参数的构造器**，子类的构造器需要**显式调用**父类带参数的构造器，分两种\n    - 直接的显式调用：super关键字调用父类构造器\n    - 间接的显式调用：this关键字调用同一个类中的其他构造器\n    - 不管直接的显式调用，还是间接的显式调用，都需要作为构造器的**第一个语句**，以便**优先初始化继承而来的父类字段**\n4. 当我们调用一个构造器时，将**优先调用父类的构造器**，**直至Object类**\n    - **这些构造器的调用者皆为同一对象，即通过new指令新建而来的对象**\n5. 通过new指令新建出来的对象，它的内存其实**涵盖了所有父类中的实例字段**\n    - 虽然子类无法访问**父类的私有实例字段**，或者子类的实例字段隐藏了**父类的同名实例字段**\n    - 但**子类的实例依然会为父类的实例字段分配内存**\n\n#### 隐式调用\n\n##### Java代码\n```java\npublic class A {\n}\n\nclass B extends A {\n}\n```\n\n##### 字节码\n```\n$ javap -v -p -c B\nme.zhongmingmao.basic.jol.B();\n  descriptor: ()V\n  flags:\n  Code:\n    stack=1, locals=1, args_size=1\n       0: aload_0           // [this]\n       1: invokespecial     // Method me/zhongmingmao/basic/jol/A.\"<init>\":()V\n       4: return\n\n$ javap -v -p -c A\npublic me.zhongmingmao.basic.jol.A();\n  descriptor: ()V\n  flags: ACC_PUBLIC\n  Code:\n    stack=1, locals=1, args_size=1\n       0: aload_0           // [this]\n       1: invokespecial     // Method java/lang/Object.\"<init>\":()V\n       4: return\n```\n\n#### 显式调用\n\n##### Java代码\n```java\npublic class C {\n    public C(String name) {\n    }\n}\n\nclass D extends C {\n    public D() {\n        // 直接显式调用\n        super(\"Hello\");\n    }\n\n    public D(String name) {\n        // 间接显式调用\n        this();\n    }\n}\n```\n\n##### 字节码\n```\n$ javap -v -p -c D\npublic me.zhongmingmao.basic.jol.D();\n  descriptor: ()V\n  flags: ACC_PUBLIC\n  Code:\n    stack=2, locals=1, args_size=1\n       0: aload_0\n       1: ldc                   // String Hello\n       // 直接显式调用\n       3: invokespecial         // Method me/zhongmingmao/basic/jol/C.\"<init>\":(Ljava/lang/String;)V\n       6: return\n\npublic me.zhongmingmao.basic.jol.D(java.lang.String);\n  descriptor: (Ljava/lang/String;)V\n  flags: ACC_PUBLIC\n  Code:\n    stack=1, locals=2, args_size=2\n       0: aload_0\n       // 间接显式调用\n       1: invokespecial         // Method \"<init>\":()V\n       4: return\n```\n\n```\n$ javap -v -p -c C\npublic me.zhongmingmao.basic.jol.C(java.lang.String);\n  descriptor: (Ljava/lang/String;)V\n  flags: ACC_PUBLIC\n  Code:\n    stack=1, locals=2, args_size=2\n       0: aload_0\n       1: invokespecial         // Method java/lang/Object.\"<init>\":()V\n       4: return\n```\n\n## 压缩指针+字节对齐\n\n### 概念\n1. Java对象头：**标记字段** + **类型指针**\n    - 标记字段：用于存储JVM有关该**对象的运行数据**（_哈希码、GC信息和锁信息_）\n    - 类型指针：指向该对象的类\n2. Java引入基本类型的原因之一\n    - 在64位JVM中，标记字段占用8Bytes，类型指针占用8Bytes，因此对象头占用16Bytes\n    - 而Integer仅有一个int类型的私有字段，占用4Bytes，额外开销为400%\n3. 为了尽量减少对象内存的使用量，在**64位**的JVM中引入**压缩指针**（-XX:+UseCompressedOops），作用于\n    - 对象头中的类型指针\n    - 引用类型的字段\n    - 引用类型的数组\n\n### 原理\n1. 关闭指针压缩的时候，JVM按照**1字节寻址**；当开启指针压缩的时候，JVM按照**8字节寻址**\n2. Java对象默认按**8字节对齐**（-XX:ObjectAlignmentInBytes），浪费掉的空间称为为**对象间的填充**\n3. JVM中的**32位压缩指针**能寻址**2^35**个字节（即**32GB**）的地址空间，**超过32GB则会关闭压缩指针**\n4. 在对**32位压缩指针**解引用时，将其**左移3位**，再加上一个**固定的偏移量**，便可以得到能够**寻址32GB地址空间的伪64位指针**\n5. 可以通过配置-XX:ObjectAlignmentInBytes来进一步**提升寻址范围**\n    - 但可能**增加对象间填充**，**导致压缩指针没有达到原本节省空间的效果**\n6. 当**关闭了指针压缩**，JVM还是会进行**内存对齐**\n7. 内存对齐不仅仅存在于**对象与对象之间**，也存在于**对象的字段之间**\n    - 字段内存对齐的一个原因：让一个字段只会出现在同一个CPU缓存行，避免出现**伪共享**\n\n## 字段重排序\n1. JVM重新分配字段的先后顺序，以达到**内存对齐**的目的\n2. JVM有三种排列方式（-XX:FieldsAllocationStyle，默认为1）\n3. 规则\n    - 如果**一个字段占据C个字节**，那么该字段的偏移量需要对齐**NC**（偏移量：字段地址与对象起始地址的差值）\n    - **子类继承字段的偏移量，需要与父类对齐字段的偏移量保持一致**\n    - JVM对齐子类字段的起始位置\n        - 对于**开启了压缩指针64位虚拟机**来说，子类的第一个字段需要对齐至**4N**\n        - 对于**关闭了压缩指针64位虚拟机**来说，子类的第一个字段需要对齐至**8N**\n4. Java 8引入一个新的注解**@Contended**，用来解决对象字段之间的**伪共享**问题\n    - JVM会让不同的@Contended字段处于独立的缓存行中，但同时也会导致**大量的空间被浪费**\n\n## JOL\n1. [对象内存布局 - JOL使用教程 1](http://zhongmingmao.me/2016/07/02/jvm-jol-tutorial-1/)\n2. [对象内存布局 - JOL使用教程 2](http://zhongmingmao.me/2016/07/03/jvm-jol-tutorial-2/)\n3. [对象内存布局 - JOL使用教程 3](http://zhongmingmao.me/2016/07/04/jvm-jol-tutorial-3/)\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- 浅谈反射","url":"%2F2018%2F12%2F20%2Fjvm-basic-reflection%2F","content":"\n## 反射API\n\n### 获取Class对象\n1. Class.forName()\n2. object.getClass()\n3. 类名.class\n    - Integer.TYPE指向int.class\n4. 数组类型：**类名[].class**\n\n```java\npublic static final Class<Integer>  TYPE = (Class<Integer>) Class.getPrimitiveClass(\"int\");\n```\n\n<!-- more -->\n\n### 常规用法\n1. newInstance()\n    - 生成该类实例\n    - 需要**无参构造器**\n2. isInstance(Object)\n    - 判断一个对象是否为该类的实例\n    - **语法上等同于instanceOf，在JIT优化时会有所差别**\n3. Array.newInstance(Class<?>, int)\n    - 构造该类型的数组\n4. getFields()/getConstructors()/ getMethods()\n    - 访问类成员\n    - 带**Declared**的方法**不会返回父类成员，但会返回私有成员**；不带**Declared**的方法恰好相反\n\n### 获取类成员后\n1. Field/Constructor/Method setAccessible(true)\n    - 绕开Java语言的限制\n2. Field.get/set(Object)\n    - 访问字段的值\n3. Constructor.newInstance(Object[])\n    - 生成该类实例\n4. Method.invoke(Object, Object[])\n    - 调用方法\n\n## 方法的反射调用\n\n```java\npublic final class Method extends Executable {\n    public Object invoke(Object obj, Object... args) throws ... {\n        ... // 权限检查\n        MethodAccessor ma = methodAccessor;\n        if (ma == null) {\n            ma = acquireMethodAccessor();\n        }\n        // 委派给MethodAccessor来处理\n        return ma.invoke(obj, args);\n    }\n}\n\npublic interface MethodAccessor {\n    Object invoke(Object var1, Object[] var2) throws IllegalArgumentException, InvocationTargetException;\n}\n```\n\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-reflect-method-accessor.png\" />\n\n每个Method实例的**第一次反射调用**都会生成一个**委派实现**，它**所委派的具体实现**便是一个**本地实现**\n- **本地实现**：进入JVM内部后，便拥有了Method实例所指向方法的**具体地址**\n- 此时，反射调用无非就是准备好入参，然后调用进入目标方法\n\n### 本地实现\n\n```java\npublic class V0 {\n    public static void target(int i) {\n        new Exception(\"#\" + i).printStackTrace();\n    }\n\n    public static void main(String[] args) throws Exception {\n        Class<?> klass = Class.forName(V0.class.getName());\n        Method method = klass.getMethod(\"target\", int.class);\n        method.invoke(null, 0);\n    }\n}\n```\n\n```\n// 本地实现\n// Method.invoke -> DelegatingMethodAccessorImpl.invoke\n// -> NativeMethodAccessorImpl.invoke -> NativeMethodAccessorImpl.invoke0\njava.lang.Exception: #0\n\tat me.zhongmingmao.basic.reflect.V0.target(V0.java:7) -- Java\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) -- C++\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498) -- Java\n\tat me.zhongmingmao.basic.reflect.V0.main(V0.java:13)\n```\n\n1. 反射调用的顺序\n    - Method.invoke（反射调用）\n    - DelegatingMethodAccessorImpl.invoke（委派实现）\n    - NativeMethodAccessorImpl.invoke（本地实现）\n    - NativeMethodAccessorImpl.invoke0（目标方法）\n2. 采用**委派实现**作为**中间层**的原因\n    - 因为Java的反射调用机制还设立了另一种**动态生成字节码**的实现（**动态实现**），直接使用invoke指令来调用目标方法\n    - **Method.invoke -> DelegatingMethodAccessorImpl.invoke -> GeneratedMethodAccessor1.invoke**\n    - 因此采用委派实现，是为了能够在**本地实现**以及**动态实现**之间切换\n3. **动态实现与本地实现相比，动态实现的运行效率能快上20倍**\n    - 这是因为动态实现无需经过Java到C++再到Java的切换\n4. **但生成字节码十分耗时，仅调用一次的话，反而本地实现要快上3~4倍**\n    - 许多反射调用仅会执行一次，阈值：**sun.reflect.inflationThreshold=15**\n    - < 15，采用本地实现\n    - \\>= 15，采用动态实现，将委派实现的委派对象切换至动态实现，该过程称之为**Inflation**\n    - **-Dsun.reflect.noInflation=true**，关闭**Inflation**机制，反射调用在**一开始便会直接使用动态实现**，而不会使用委派实现或者本地实现\n\n```java\n// 动态实现的伪代码\npackage jdk.internal.reflect;\n\npublic class GeneratedMethodAccessor1 extends ... {\n    @Overrides    \n    public Object invoke(Object obj, Object[] args) throws ... {\n        V0.target((int) args[0]);\n        return null;\n    }\n}\n```\n\n### 动态实现\n```java\n// -verbose:class\npublic class V1 {\n    public static void target(int i) {\n        new Exception(\"#\" + i).printStackTrace();\n    }\n\n    public static void main(String[] args) throws Exception {\n        Class<?> klass = Class.forName(V1.class.getName());\n        Method method = klass.getMethod(\"target\", int.class);\n        for (int i = 0; i < 20; i++) {\n            method.invoke(null, i);\n        }\n    }\n}\n```\n\n```\n// 第15次反射调用时，触发了动态实现的生成，JVM额外加载其他类\njava.lang.Exception: #14\n\tat me.zhongmingmao.basic.reflect.V1.target(V1.java:7)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat me.zhongmingmao.basic.reflect.V1.main(V1.java:14)\n...\n// 加载自动生成的字节码\n[Loaded sun.reflect.GeneratedMethodAccessor1 from __JVM_DefineClass__]\njava.lang.Exception: #15\n\tat me.zhongmingmao.basic.reflect.V1.target(V1.java:7)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat me.zhongmingmao.basic.reflect.V1.main(V1.java:14)\n// 切换至刚刚生成的动态实现\njava.lang.Exception: #16\n\tat me.zhongmingmao.basic.reflect.V1.target(V1.java:7)\n\tat sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat me.zhongmingmao.basic.reflect.V1.main(V1.java:14)\n```\n\n## 反射调用的开销\n\n### Class.forName + Class.getMethod\n1. Class.forName会调用本地方法\n2. Class.getMethod则会遍历**该类的公有方法**，如果没有匹配到，还将匹配**父类的公有方法**\n    - 返回查找得到结果的一份**拷贝**\n    - 避免在热点代码中使用返回**Method数组**的Class.getMethods()方法和Class.getDeclaredMethods()方法，减少不必要的堆空间消耗\n3. 尽量在应用程序中缓存Class.forName和Class.getMethod的结果\n\n### Method.invoke\n\n#### 直接调用\n\n##### Java代码\n```java\npublic class V2 {\n    public static void target(int i) {\n    }\n\n    private static void directCall() {\n        long current = System.currentTimeMillis();\n        for (int i = 1; i <= 2_000_000_000; i++) {\n            if (i % 100_000_000 == 0) {\n                long temp = System.currentTimeMillis();\n                System.out.println(temp - current);\n                current = temp;\n            }\n\n            V2.target(128);\n        }\n    }\n\n    public static void main(String[] args) {\n        directCall();\n    }\n}\n```\n\n1. 取最后5个值，作为预热后的峰值性能，大约为111.6ms；**与不调用的时间基本一致**\n    - 因为这是**热循环**，触发**JIT**，将V2.target的调用**内联**进来，从而**消除了调用的开销**\n2. **性能基准：111.6ms**\n\n#### 反射调用\n\n##### Java代码\n```java\n// -XX:+PrintGC\npublic class V3 {\n    public static void target(int i) {\n    }\n\n    private static void reflectCall() throws Exception {\n        Class<?> klass = Class.forName(\"me.zhongmingmao.basic.reflect.V3\");\n        Method method = klass.getMethod(\"target\", int.class);\n\n        long current = System.currentTimeMillis();\n        for (int i = 1; i <= 2_000_000_000; i++) {\n            if (i % 100_000_000 == 0) {\n                long temp = System.currentTimeMillis();\n                System.out.println(temp - current);\n                current = temp;\n            }\n\n            method.invoke(null, 128);\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        reflectCall();\n    }\n}\n```\n\n峰值性能：457.4ms，为基准耗时的4.1倍\n\n##### 字节码\n```\n63: aload_1                         // 加载Method对象\n64: aconst_null                     // 静态方法，反射调用的第一个参数为null\n65: iconst_1\n66: anewarray                       // 生成一个长度为1的Object数组\n69: dup\n70: iconst_0\n71: sipush        128\n74: invokestatic Integer.valueOf    // 将128自动装箱成Integer\n77: aastore                         // 存入Object数组\n78: invokevirtual Method.invoke     // 反射调用\n```\n反射调用前的两个动作\n- Method.invoke是一个**变长参数**方法，**最后一个参数**在**字节码层面**会是**Object数组**\n    - Java编译器会在方法调用处生成一个**长度为入参数量的Object数组**，并将入参一一存储进该数组\n- Object数组不能存储基本类型，Java编译器会对传入的基本类型进行**自动装箱**\n- 上述两个步骤会带来**性能开销**和**GC**\n\n#### 减少装箱\n1. V3的代码增加启动JVM参数：**-Djava.lang.Integer.IntegerCache.high=128**\n2. 峰值性能：280.4ms，为基准耗时的2.5倍\n\n#### 减少自动生成Object数组\n\n##### Java代码\n```java\n// -XX:+PrintGC\npublic class V4 {\n    public static void target(int i) {\n    }\n\n    public static void main(String[] args) throws Exception {\n        Class<?> klass = Class.forName(\"me.zhongmingmao.basic.reflect.V4\");\n        Method method = klass.getMethod(\"target\", int.class);\n\n        // 在循环外构造参数数组\n        Object[] arg = new Object[1];\n        arg[0] = 128;\n\n        long current = System.currentTimeMillis();\n        for (int i = 1; i <= 2_000_000_000; i++) {\n            if (i % 100_000_000 == 0) {\n                long temp = System.currentTimeMillis();\n                System.out.println(temp - current);\n                current = temp;\n            }\n\n            method.invoke(null, arg);\n        }\n    }\n}\n```\n\n```\n80: aload_2                         // 加载Method对象\n81: aconst_null                     // 静态方法，反射调用的第一个参数为null\n82: aload_3\n83: invokevirtual Method.invoke     // 反射调用，无anewarray指令\n```\n\n1. 峰值性能：312.4ms，为基准耗时的2.8倍\n2. V4**不会触发GC**，因为**反射调用被内联**了\n    - 即时编译器中的**逃逸分析**会**将原本新建的Object数组判定为不逃逸的对象**\n    - 如果一个对象被判定为**不逃逸**，那么即时编译器会选择**栈分配**或者**虚拟分配**，**不占用堆空间**\n    - 在循环外新建数组，即时编译器无法确定这个数组会不会被中途修改，从而无法优化掉访问数组的操作\n\n#### 关闭Inflation机制\n1. 关闭Inflation机制，取消委派实现，并且**直接使用动态实现**\n2. 关闭权限校验：每次反射调用都会**检查目标方法的权限**\n\n##### Java代码\n```java\n// -Djava.lang.Integer.IntegerCache.high=128\n// -Dsun.reflect.noInflation=true\npublic class V5 {\n    public static void target(int i) {\n    }\n\n    public static void main(String[] args) throws Exception {\n        Class<?> klass = Class.forName(\"me.zhongmingmao.basic.reflect.V5\");\n        Method method = klass.getMethod(\"target\", int.class);\n        // 关闭权限检查\n        method.setAccessible(true);\n\n        long current = System.currentTimeMillis();\n        for (int i = 1; i <= 2_000_000_000; i++) {\n            if (i % 100_000_000 == 0) {\n                long temp = System.currentTimeMillis();\n                System.out.println(temp - current);\n                current = temp;\n            }\n\n            method.invoke(null, 128);\n        }\n    }\n}\n```\n\n峰值性能：186.2ms，为基准耗时的1.7倍\n\n\n#### 方法内联的瓶颈\n1. V5的反射调用能如此快，主要是**即时编译器中的方法内联**\n2. 在关闭了Inflation机制后，方法内联的瓶颈在于Method.invoke方法中对MethodAccessor.invoke方法的调用\n3. 在生成环境中，通常有多个不同的反射调用，对应多个GeneratedMethodAccessor，也就是动态实现\n4. JVM关于上述调用点的类型profile无法同时记录多个类，造成所测试的**反射调用没有被内联**的情况\n    - 类型profile：对于invokevirtual或invokeinterface，JVM会记录下**调用者的具体类型**\n\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-reflect-method-invoke.png\" />\n\n##### Java代码\n```java\npublic class V6 {\n    public static void target(int i) {\n    }\n\n    public static void target1(int i) {\n    }\n\n    public static void target2(int i) {\n    }\n\n    public static void polluteProfile() throws Exception {\n        // 误扰Method.invoke()的类型profile\n        Method method1 = V6.class.getMethod(\"target1\", int.class);\n        Method method2 = V6.class.getMethod(\"target2\", int.class);\n        for (int i = 0; i < 2000; i++) {\n            method1.invoke(null, 0);\n            method2.invoke(null, 0);\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        Class<?> klass = Class.forName(\"me.zhongmingmao.basic.reflect.V6\");\n        Method method = klass.getMethod(\"target\", int.class);\n        // 关闭权限检查\n        method.setAccessible(true);\n        polluteProfile();\n\n        long current = System.currentTimeMillis();\n        for (int i = 1; i <= 2_000_000_000; i++) {\n            if (i % 100_000_000 == 0) {\n                long temp = System.currentTimeMillis();\n                System.out.println(temp - current);\n                current = temp;\n            }\n\n            method.invoke(null, 128);\n        }\n    }\n}\n```\n\n1. 峰值性能：1565.6ms，为基准耗时的14倍\n2. 原因\n    - 方法没有内联\n    - 逃逸分析不再起效（解决方案：循环外构造数组，峰值性能：892.4ms，为基准耗时的8倍）\n    - 每个调用能够记录的类型数目太少，默认2（-XX:TypeProfileWidth=5，峰值性能：1456.2ms，为基准耗时的13倍）\n\n\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- 异常处理","url":"%2F2018%2F12%2F19%2Fjvm-basic-exception%2F","content":"\n## 抛出异常 + 捕获异常\n\n### 抛出异常\n1. **显式**抛异常的主体是**应用程序**，使用**throw**关键字\n2. **隐式**抛异常的主体是**JVM**，在JVM执行过程中，碰到无法继续执行的异常状态时，自动抛出异常\n    - 例如ArrayIndexOutOfBoundsException\n\n### 捕获异常\n1. try代码块\n    - 标记需要**异常监控**的代码\n2. catch代码块\n    - 定义了**针对指定类型的异常处理器**\n    - 多个catch代码块，JVM会**从上至下**匹配异常处理器\n    - 前面catch代码块所捕获的异常类型不能覆盖后边的，否则编译器会报错\n3. finally代码块\n    - 声明一段**必定运行**的代码\n    - 程序正常执行，未抛出异常，try -> finally\n    - 程序抛出异常未被捕获，try(throw A) -> finally -> throw A\n    - 程序抛出异常并被捕获，try(throw A) -> catch(A) -> finally\n    - 程序抛出异常并被捕获，并且catch代码块也抛出异常，try(throw A) -> catch(A, throw B) -> finally -> throw B\n    - finally代码块抛出异常，中断finally代码块的执行，往外抛出异常\n\n<!-- more -->\n\n## 基本概念\n\n### 继承关系\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-exception.png\" />\n\n1. 所有异常都是Throwable的子类\n2. Error\n    - 应用程序不应该捕获的异常\n    - 当程序触发Error时，已经无法恢复，需要**终止线程**甚至**终止JVM**\n3. Exception\n    - 应用程序需要捕获的异常（RuntimeException除外）\n4. **RuntimeException和Error属于Java的unchecked exception**，其他异常属于checked exception\n    - 所有checked exception都需要显式捕获或在方法声明中用throws关键词标注\n    - 通常情况下，**程序自定义的异常应该为checked exception**，以便于最大化利用Java编译器的**编译时检查**\n5. **异常实例的构造是非常昂贵的**\n    - 在构造异常实例时，JVM需要生成该异常的**栈轨迹（stack trace）**\n    - 该操作会**逐一访问当前线程的Java栈帧，并且记录下各种调试信息**\n        - 栈帧所指向方法的名字，方法所在的类名、文件名，以及在代码中的第几行触发该异常\n    - 在生成stack trace的时候，JVM会忽略掉异常构造器以及填充栈帧的Java方法（Throwable.fillInStackTrace），直接从新建异常位置开始算起\n    - JVM还会忽略标记为不可见的方法栈帧\n    - 即使代价昂贵，依旧不推荐缓存异常实例，容易误导开发人员\n\n## 捕获异常的机制\n\n### Java代码\n```java\ntry {\n    int a = 1;\n} catch (RuntimeException e) {\n    int b = 2;\n} catch (Exception e) {\n    int c = 3;\n}\n```\n\n### 字节码\n```\nstack=1, locals=3, args_size=1\n     0: iconst_1\n     1: istore_1\n     2: goto          14\n     5: astore_1\n     6: iconst_2\n     7: istore_2\n     8: goto          14\n    11: astore_1\n    12: iconst_3\n    13: istore_2\n    14: return\n  Exception table:\n     from    to  target type\n         0     2     5   Class java/lang/RuntimeException\n         0     2    11   Class java/lang/Exception\n```\n\n1. 编译生成的字节码中，**每个方法都附带一个异常表**，异常表中的每一个条目代表一个**异常处理器**\n    - 条目组成：from指针、to指针、target指针和所捕获的异常类型\n    - 这里的指针的值指的是**字节码索引**，用于定位字节码\n    - from指针和to指针（不含）标示了该异常处理器所监控的范围\n    - target指针指向异常处理器的起始位置\n2. 当程序触发异常时，JVM虚拟机会从上而下遍历异常表中的所有条目\n    - 当触发异常的字节码的索引值在某个异常表条目的监控范围内，JVM会判断所抛出的异常与该条目**想要捕获的异常**是否匹配\n    - 如果匹配，JVM会将控制流转移到该条目的target指针指向的字节码\n    - 如果遍历完所有异常条目，JVM仍未匹配到异常处理器，那么会**弹出当前方法所对应的栈帧**，并且在**调用者**中重复上述操作\n    - **最坏情况：JVM需要遍历当前线程Java栈上所有方法的异常表**\n\n### finally代码块\n1. 复制finally代码块的内容，分别放在try-catch代码块的**正常执行路径出口**以及**异常执行路径出口**\n2. 针对异常执行路径，Java编译器会生成一个或多个异常表条目，**监控整个try-catch代码块**，并且捕获所有种类的异常（any）\n    - 这些异常表条目的target指针将指向另一份复制的finally代码块\n    - **在这个代码块最后，Java编译器会重新抛出所捕获的异常**\n\n#### Java代码\n```java\npublic class Foo {\n    private int tryBlock;\n    private int catchBlock;\n    private int finallyBlock;\n    private int methodExit;\n\n    public void test() {\n        try {\n            tryBlock = 0;\n        } catch (RuntimeException e) {\n            catchBlock = 1;\n        } finally {\n            finallyBlock = 2;\n        }\n        methodExit = 3;\n    }\n}\n```\n\n#### 字节码\n```\nstack=2, locals=3, args_size=1\n   0: aload_0\n   1: iconst_0\n   2: putfield      #2                  // Field tryBlock:I\n   5: aload_0\n   6: iconst_2\n   7: putfield      #3                  // Field finallyBlock:I\n  10: goto          35\n  13: astore_1\n  14: aload_0\n  15: iconst_1\n  16: putfield      #5                  // Field catchBlock:I\n  19: aload_0\n  20: iconst_2\n  21: putfield      #3                  // Field finallyBlock:I\n  24: goto          35\n  27: astore_2\n  28: aload_0\n  29: iconst_2\n  30: putfield      #3                  // Field finallyBlock:I\n  33: aload_2\n  34: athrow\n  35: aload_0\n  36: iconst_3\n  37: putfield      #6                  // Field methodExit:I\n  40: return\nException table:\n   from    to  target type\n       0     5    13   Class java/lang/RuntimeException # 监控try代码块\n       0     5    27   any # 监控try代码块\n      13    19    27   any # 监控catch代码块\n```\n1. 编译结果包含三份finallyBlock代码块\n    - 前两份分别位于try代码块和catch代码块的正常执行路径出口\n    - 最后一份作为异常处理器，监控try代码块和catch代码块，用于捕获两类异常\n        - try代码块触发的，未被catch代码块捕获的异常\n        - catch代码块触发的异常\n2. 如果catch代码块捕获了异常A，并且触发异常B，那么finally捕获并重新抛出的是异常B\n    - **原本的异常会被忽略掉**，对于代码调试非常不方便\n\n## Supressed异常+语法糖\n1. Java 7引入**Supressed异常**来解决上述问题，允许**将一个异常附于另一个异常之上**\n    - 抛出的异常可以附带多个异常的信息\n2. 语法糖：**try-with-resources**\n    - **在字节码层面自动使用Supressed异常**\n\n### Java代码\n```java\n@Data\n@AllArgsConstructor\npublic class R implements AutoCloseable {\n    private String name;\n\n    @Override\n    public void close() throws Exception {\n        throw new RuntimeException(name);\n    }\n\n    public static void main(String[] args) throws Exception {\n        try (R r1 = new R(\"R1\");\n             R r2 = new R(\"R2\")) {\n            throw new RuntimeException(\"Init\");\n        }\n    }\n}\n```\n\n### 输出\n```\nException in thread \"main\" java.lang.RuntimeException: Init\n\tat me.zhongmingmao.basic.exception.R.main(R.java:19)\n\tSuppressed: java.lang.RuntimeException: R2\n\t\tat me.zhongmingmao.basic.exception.R.close(R.java:13)\n\t\tat me.zhongmingmao.basic.exception.R.main(R.java:20)\n\tSuppressed: java.lang.RuntimeException: R1\n\t\tat me.zhongmingmao.basic.exception.R.close(R.java:13)\n\t\tat me.zhongmingmao.basic.exception.R.main(R.java:20)\n```\n\n### 字节码\n```\n103: astore        9\n105: aload_2\n106: aload         9\n// 自动使用Supressed异常\n108: invokevirtual #11                 // Method java/lang/Throwable.addSuppressed:(Ljava/lang/Throwable;)V\n111: goto          118\n114: aload_1\n115: invokevirtual #10                 // Method close:()V\n118: aload         8\n120: athrow\n```\n\n## 同时捕获多个异常\n\n### Java代码\n```java\npublic class T {\n    public void test() {\n        try {\n            int a = 1;\n        } catch (E2 | E1 e) {\n            int b = 2;\n        }\n    }\n}\n\nclass E1 extends RuntimeException {\n}\nclass E2 extends RuntimeException {\n}\n```\n\n### 字节码\n```\nstack=1, locals=3, args_size=1\n   0: iconst_1\n   1: istore_1\n   2: goto          8\n   5: astore_1\n   6: iconst_2\n   7: istore_2\n   8: return\nException table:\n   // 按顺序生成多个异常表条目\n   from    to  target type\n       0     2     5   Class me/zhongmingmao/basic/exception/E2\n       0     2     5   Class me/zhongmingmao/basic/exception/E1\n```\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- 桥接方法","url":"%2F2018%2F12%2F18%2Fjvm-basic-bridge-method%2F","content":"\n## 背景\nJava语言的重写与JVM的重写并不一致，当在Java语言中为重写而在JVM中为非重写，编译器会通过生成**桥接方法**来实现Java中的重写语义\n\n## 桥接方法 -- 返回类型\n\n### Java代码\n```java\n@Slf4j\npublic class Father {\n    public Number work() {\n        return 1.0;\n    }\n\n    public static void main(String[] args) {\n        Father father = new Son();\n        // 实际调用的是桥接方法\n        Number work = father.work();\n        log.info(\"{}\", work);\n    }\n}\n\nclass Son extends Father {\n    @Override\n    public Double work() {\n        return 2.0;\n    }\n}\n```\n\n<!-- more -->\n\n### 字节码\n```\n$ javap -v -c Son\npublic java.lang.Double work();\n  descriptor: ()Ljava/lang/Double;\n  flags: ACC_PUBLIC\n  Code:\n    stack=2, locals=1, args_size=1\n       0: ldc2_w        #2                  // double 2.0d\n       3: invokestatic  #4                  // Method java/lang/Double.valueOf:(D)Ljava/lang/Double;\n       6: areturn\n    LineNumberTable:\n      line 21: 0\n    LocalVariableTable:\n      Start  Length  Slot  Name   Signature\n          0       7     0  this   Lme/zhongmingmao/basic/bridge/return_type/Son;\n\n// 桥接办法\npublic java.lang.Number work();\n  descriptor: ()Ljava/lang/Number;\n  // ACC_BRIDGE：桥接方法\n  // ACC_SYNTHETIC：编译器自动生成，对Java源码来说是不可见的，但可以通过反射调用\n  flags: ACC_PUBLIC, ACC_BRIDGE, ACC_SYNTHETIC\n  Code:\n    stack=1, locals=1, args_size=1\n       0: aload_0\n       // 调用Son本身重写的方法\n       1: invokevirtual #5                  // Method work:()Ljava/lang/Double;\n       4: areturn\n    LineNumberTable:\n      line 18: 0\n    LocalVariableTable:\n      Start  Length  Slot  Name   Signature\n          0       5     0  this   Lme/zhongmingmao/basic/bridge/return_type/Son;\n```\n\n1. 如果没有桥接办法，对于Java语言是重写的，但对于JVM来说却不是重写的\n    - 只有当两个方法的**参数类型**和**返回类型**一致，JVM才会判定为重写\n    - Java编译器会在Son的字节码中**自动生成一个桥接方法**来保证重写语义\n\n#### 翻译桥接方法\n```java\npublic Number work() {\n    return this.work();\n}\n```\n\n### 调用桥接办法\n1. 编译器通过插入**桥接办法**来保证重写的语义\n2. JVM通过**方法描述符**（参数类型+返回类型）定位到具体的方法\n\n```java\nFather father = new Son();\n// 实际调用的是桥接方法\nNumber work = father.work();\nlog.info(\"{}\", work);\n```\n\n## 桥接方法 -- 泛型\n\n### Java代码\n```java\npublic interface Father {\n    void work();\n\n    static void main(String[] args) {\n        Job job = new Doctor();\n        // 调用实际的方法\n        job.work(new Son());\n        // 调用桥接方法，有checkcast指令，抛出ClassCastException\n        job.work(new Daughter());\n    }\n}\n\nclass Son implements Father {\n    @Override\n    public void work() {\n    }\n}\n\nclass Daughter implements Father {\n    @Override\n    public void work() {\n    }\n}\n\nabstract class Job<T extends Father> {\n    protected void work(T father) {\n        father.work();\n    }\n}\n\nclass Doctor extends Job<Son> {\n    @Override\n    public void work(Son son) {\n        super.work(son);\n    }\n}\n\nclass Nurse extends Job<Daughter> {\n    @Override\n    public void work(Daughter daughter) {\n        super.work(daughter);\n    }\n}\n```\n\n### 字节码\n```\n$ javap -v -c Job\nprotected void work(T);\n  // Java是伪泛型，会进行类型擦除\n  // 因此泛型T被换成Father，方法签名为protected void work(Father father)\n  descriptor: (Lme/zhongmingmao/basic/bridge/generic/Father;)V\n  flags: ACC_PROTECTED\n  Code:\n    stack=1, locals=2, args_size=2\n       0: aload_1\n       // 调用接口方法\n       1: invokeinterface #2,  1            // InterfaceMethod me/zhongmingmao/basic/bridge/generic/Father.work:()V\n       6: return\n    LineNumberTable:\n      line 27: 0\n      line 28: 6\n    LocalVariableTable:\n      Start  Length  Slot  Name   Signature\n          0       7     0  this   Lme/zhongmingmao/basic/bridge/generic/Job;\n          0       7     1 father   Lme/zhongmingmao/basic/bridge/generic/Father;\n    LocalVariableTypeTable:\n      Start  Length  Slot  Name   Signature\n          0       7     0  this   Lme/zhongmingmao/basic/bridge/generic/Job<TT;>;\n          0       7     1 father   TT;\n  Signature: #20                          // (TT;)V\n```\n\n\n```\n$ javap -v -c Doctor\npublic void work(me.zhongmingmao.basic.bridge.generic.Son);\n  descriptor: (Lme/zhongmingmao/basic/bridge/generic/Son;)V\n  flags: ACC_PUBLIC\n  Code:\n    stack=2, locals=2, args_size=2\n       0: aload_0\n       1: aload_1\n       2: invokespecial #2                  // Method me/zhongmingmao/basic/bridge/generic/Job.work:(Lme/zhongmingmao/basic/bridge/generic/Father;)V\n       5: return\n    LineNumberTable:\n      line 34: 0\n      line 35: 5\n    LocalVariableTable:\n      Start  Length  Slot  Name   Signature\n          0       6     0  this   Lme/zhongmingmao/basic/bridge/generic/Doctor;\n          0       6     1   son   Lme/zhongmingmao/basic/bridge/generic/Son;\n\n// 桥接方法\npublic void work(me.zhongmingmao.basic.bridge.generic.Father);\n  descriptor: (Lme/zhongmingmao/basic/bridge/generic/Father;)V\n  flags: ACC_PUBLIC, ACC_BRIDGE, ACC_SYNTHETIC\n  Code:\n    stack=2, locals=2, args_size=2\n       0: aload_0\n       1: aload_1\n       // 类型校验，必须为Son类型\n       2: checkcast     #3                  // class me/zhongmingmao/basic/bridge/generic/Son\n       // 调用Doctor本身重写的方法（非私有实例方法）\n       5: invokevirtual #4                  // Method work:(Lme/zhongmingmao/basic/bridge/generic/Son;)V\n       8: return\n    LineNumberTable:\n      line 31: 0\n    LocalVariableTable:\n      Start  Length  Slot  Name   Signature\n          0       9     0  this   Lme/zhongmingmao/basic/bridge/generic/Doctor;\n```\n\n#### 翻译桥接办法\n```java\npublic void work(Father father){\n    // 强制类型转换\n    super.work((Son) father);\n}\n```\n\n### 调用桥接办法\n```java\nJob job = new Doctor();\n// 调用实际的方法\njob.work(new Son());\n// 调用桥接方法，有checkcast指令，抛出ClassCastException\njob.work(new Daughter());\n```\n\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- 方法调用","url":"%2F2018%2F12%2F17%2Fjvm-basic-invoke%2F","content":"\n## 重载+重写\n1. 重载：方法名相同，但方法描述符不相同的方法之间的关系\n2. 重写：方法名相同，并且方法描述符也相同的方法之间的关系\n3. 方法描述符\n    1. **Java：参数类型**\n    2. **JVM：参数类型+返回类型**\n\n### 重载\n1. 重载的方法在**编译过程**即可完成识别\n    - 具体到在每个方法调用时，Java编译器会根据**传入参数的声明类型**（不是实际类型）来选取重载方法\n2. 三阶段\n    - 在不允许**自动装拆箱**和**可变长参数**的情况下，选取重载方法\n    - 允许**自动装拆箱**，但不允许**可变长参数**的情况下，选取重载方法\n    - 在允许**自动装拆箱**和**可变长参数**的情况下，选取重载方法\n3. Java编译器在**同一阶段**找到多个适配的方法，依据**形式参数的继承关系**，选择最贴切的方法，原则：**子类优先**\n4. 重载来源\n    - **同一个类中定义**\n    - **继承父类非私有同名方法**\n\n<!-- more -->\n\n### 重写\n1. 子类中定义了与父类中**非私有的同名实例方法**，且**参数类型相同**\n    - 如果是**静态方法**，那么子类中的方法会**隐藏**父类中方法\n2. 方法**重写**是Java**多态**最重要的一种体现形式\n\n## 静态绑定与+动态绑定\n1. JVM识别**重载方法**的关键在于**类名**，**方法名**和**方法描述符**\n    - 方法描述符：**参数类型 + 返回类型**\n    - 如果在同一个类中出现多个**方法名**和**方法描述符**也相同的方法，那么JVM会在类的**验证阶段报错**\n    - JVM的限制比Java语言的**限制更少**，Java语言：**方法描述符 = 方法的参数类型**\n3. JVM中关于**重写方法**的判定同样基于**方法描述符**\n    - 如果子类定义了与父类中**非私有实例方法同名的方法**，那么只有当这两个方法的**参数类型**以及**返回类型**一致，JVM才会判定为重写\n4. **Java语言中的重写**而**JVM中的非重写**，编译器会通过生成**桥接方法**来实现Java中的重写语义，保证Java语言和JVM表现出来的重写语义一致\n5. 对重载方法的区分在**编译阶段**已经完成，可以认为**JVM不存在重载这一概念**\n6. **静态绑定**：在**解析阶段**时能够**直接识别**目标方法\n7. **动态绑定**：在**运行过程**中**根据调用者的动态类型**来识别目标方法\n8. 重载 == 静态绑定，重写 == 动态绑定？\n    - 反例：**重载不一定是静态绑定**（某个类的重载方法可能被它的子类所重写）\n    - 反例：**重写不一定是动态绑定**（final修饰目标方法）\n    - Java编译器会将**对非私有实例方法的调用**都编译为需要**动态绑定**的类型（可能进一步优化）\n    - **重载/重写** 和 **静态绑定/动态绑定** 是**两个不同纬度的描述**\n\n### 重载不一定是静态绑定\n\n#### Java代码\n```java\n// 重载\npublic class Overload {\n    public static void main(String[] args) {\n        A a = new B();\n        // invokevirtual指令：A.func(int)和A.func(long)形成重载，但需要动态绑定\n        a.func(1);\n    }\n}\n\nclass A {\n    void func(int i) {\n    }\n\n    void func(long i) {\n    }\n}\n\nclass B extends A {\n    @Override\n    void func(int i) {\n    }\n}\n```\n\n#### 字节码\n```\npublic static void main(java.lang.String[]);\n    descriptor: ([Ljava/lang/String;)V\n    flags: ACC_PUBLIC, ACC_STATIC\n    Code:\n      stack=2, locals=2, args_size=1\n         0: new           #2                  // class me/zhongmingmao/basic/invoke/bind/B\n         3: dup\n         4: invokespecial #3                  // Method me/zhongmingmao/basic/invoke/bind/B.\"<init>\":()V\n         7: astore_1\n         8: aload_1\n         9: iconst_1\n         // 虚方法调用\n        10: invokevirtual #4                  // Method me/zhongmingmao/basic/invoke/bind/A.func:(I)V\n        13: return\n      LineNumberTable:\n        line 6: 0\n        line 7: 8\n        line 8: 13\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0      14     0  args   [Ljava/lang/String;\n            8       6     1     a   Lme/zhongmingmao/basic/invoke/bind/A;\n}\n```\n\n### 重写不一定是动态绑定\n\n#### Java代码\n```java\n// 重写\npublic class Override {\n    public static void main(String[] args) {\n        C c = new C();\n        // C.func()的flags为：ACC_FINAL\n        // JVM能确定目标方法只有一个，invokevirtual指令将采用静态绑定\n        c.func();\n    }\n}\n\nclass C {\n    final void func() {\n    }\n}\n```\n\n#### 字节码\nC\n```\nfinal void func();\n    descriptor: ()V\n    flags: ACC_FINAL\n    Code:\n      stack=0, locals=1, args_size=1\n         0: return\n      LineNumberTable:\n        line 13: 0\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0       1     0  this   Lme/zhongmingmao/basic/invoke/bind/C;\n```\nOverride\n```\npublic static void main(java.lang.String[]);\n  descriptor: ([Ljava/lang/String;)V\n  flags: ACC_PUBLIC, ACC_STATIC\n  Code:\n    stack=2, locals=2, args_size=1\n       0: new           #2                  // class me/zhongmingmao/basic/invoke/bind/C\n       3: dup\n       4: invokespecial #3                  // Method me/zhongmingmao/basic/invoke/bind/C.\"<init>\":()V\n       7: astore_1\n       8: aload_1\n       9: invokevirtual #4                  // Method me/zhongmingmao/basic/invoke/bind/C.func:()V\n      12: return\n    LineNumberTable:\n      line 6: 0\n      line 7: 8\n      line 8: 12\n    LocalVariableTable:\n      Start  Length  Slot  Name   Signature\n          0      13     0  args   [Ljava/lang/String;\n          8       5     1     d   Lme/zhongmingmao/basic/invoke/bind/C;\n}\n```\n\n## 调用相关的指令\n\n### 具体指令\n1. invokestatic：调用静态方法\n2. invokespecial\n    - 调用**私有实例方法**、构造器\n    - 使用**super**关键词调用父类的实例方法、构造器\n    - 调用所实现接口的**default方法**\n3. invokevirtual：调用**非私有实例方法**\n4. invokeinterface：调用接口方法\n5. invokedynamic：调用动态方法（比较复杂）\n\n```java\ninterface Customer {\n    boolean isVip();\n}\n\nclass Merchant {\n    static final double ORIGINAL_DISCOUNT = 0.8d;\n\n    public double discount(double originalPrice, Customer customer) {\n        return originalPrice * ORIGINAL_DISCOUNT;\n    }\n}\n\nclass Profiteer extends Merchant {\n    @Override\n    public double discount(double originalPrice, Customer customer) {\n        if (customer.isVip()) { // invokeinterface\n            return originalPrice * priceDiscrimination(); // invokestatic\n        }\n        return super.discount(originalPrice, customer); // invokespecial\n    }\n\n    private static double priceDiscrimination() {\n        return new Random() // invokespecial\n                .nextDouble() // invokevirtual\n                + ORIGINAL_DISCOUNT;\n    }\n}\n```\n\n### 定位目标方法\n1. 对于**invokestatic**和**invokespecial**，JVM在**解析阶段**能够**直接识别**具体的目标方法\n2. 对于**invokevirtual**和**invokeinterface**，在绝大部分情况下，JVM需要在**执行过程**中，根据**调用者的动态类型**，来确定具体的目标方法\n    - 唯一例外：如果JVM能确定目标方法**有且只有一个**，例如目标方法被标记为final\n\n### 调用指令的符号引用\n1. 在编译过程中，并不知道目标方法的具体内存地址，因此，Java编译器会暂时用**符号引用**来表示该目标方法\n    - 符号引用包括：**目标方法所在的类或接口的名字，以及目标方法的方法名和方法描述符**\n2. **符号引用**存储在**class文件的常量池之中**，根据**目标方法是否为接口方法**，这些引用可分为**接口符号引用**和**非接口符号引用**\n\n```\n$ javap -v Profiteer\nConstant pool:\n   #1 = Methodref          #8.#30         // me/zhongmingmao/basic/Merchant.\"<init>\":()V\n   #2 = InterfaceMethodref #31.#32        // me/zhongmingmao/basic/Customer.isVip:()Z\n   #3 = Methodref          #11.#33        // me/zhongmingmao/basic/Profiteer.priceDiscrimination:()D\n   #4 = Methodref          #8.#34         // me/zhongmingmao/basic/Merchant.discount:(DLme/zhongmingmao/basic/Customer;)D\n...\n   #6 = Methodref          #5.#30         // java/util/Random.\"<init>\":()V\n   #7 = Methodref          #5.#36         // java/util/Random.nextDouble:()D\n```\n\n#### 目标方法的查找步骤\n1. 对于**非接口符号引用**，假设该符号引用所指向的类为C，查找步骤\n    - 在C中查找符合名字和描述符的方法\n    - 如果没有找到，在C的**父类**中继续搜索，直至Object类\n    - 如果没有找到，在C所**直接实现或间接实现的接口**中搜索，这一步搜索得到的目标方法必须是**非私有、非静态**的\n        - 如果目标方法在**间接接口**中，则需要满足**C与该接口之间没有其他符合条件的目标方法** -- 越近，优先级越高\n        - 如果有**多个符合条件的目标方法**，则**任意返回**其中一个\n    - **静态方法** 也可以通过**子类**来调用，子类的静态方法会**隐藏**父类中同名同描述符的静态方法\n2. 对于**接口符号引用**，假设该符号引用所指向的接口为I，查找步骤\n    - 在I中查找符合名字和描述符的方法\n    - 如果没有找到，在**Object类中的公有实例方法**中搜索\n    - 如果没有找到，则在I的**超接口**中搜索，这一步的搜索结果的要求**与非接口符号引用的要求一致**\n3. 经过上述的**解析**步骤之后，**符号引用会被解析成实际引用**\n    - 对于可以**静态绑定**的方法调用而言，实际引用的是**一个指向方法的指针**\n    - 对于需要**动态绑定**的方法调用而言，实际引用则是**一个虚方法表的索引**\n\n## 虚方法调用\n1. JVM的虚方法调用指令\n    - Java里所有**非私有实例方法的调用**都会编译成**invokevirtual**指令（**绝大数情况下动态绑定**）\n    - 而**接口方法调用**都会被编译成**invokeinterface**指令\n2. 在绝大数情况下，JVM需要根据**调用者的动态类型**，来**确定虚方法调用的目标方法**，这个过程称之为**动态绑定**\n    - 相对于静态绑定的非虚方法调用来说，**虚方法调用更加耗时**\n3. 静态绑定\n    - 调用静态方法的**invokestatic**指令\n    - 调用构造器、私有实例方法和父类非私有实例方法（可继承）的**invokespecial**指令\n        - 父类非私有实例方法：本意是要调用父类的特定方法，而非根据具体类型决定目标方法\n    - 如果**虚方法调用**指向一个**标记为final**的方法，那么JVM也可以**静态绑定**该虚方法调用的目标方法\n\n## 虚方法表（链接-准备阶段）\n1. 虚方法表：JVM采取了一种用**空间换时间**的策略来实现**动态绑定**\n2. invokevirtual的虚方法表与invokeinterface的虚方法表类似\n3. 虚方法表本质上是一个**数组**，每个数组元素指向**当前类及其父类中非私有、非final的实例方法**\n4. 虚方法表的特性\n    - **子类虚方法表中包含父类虚方法表中的所有方法**\n    - 子类方法在虚方法表中的**索引值**，与它**所重写的父类方法的索引值相同**\n5. 方法调用指令中的**符号引用**会在**执行之前**解析成**实际引用**\n    - 对于**静态绑定**的方法调用而言，实际引用将指向**具体的目标方法**\n    - 对于**动态绑定**的方法调用而言，实际引用则是**虚方法表的索引**（不仅仅是索引值）\n6. 动态绑定：JVM将**获取调用者的实际类型**，并在**实际类型的虚方法表**中，根据**索引值**获得**目标方法**\n7. 使用虚方法表的动态绑定与静态绑定相比，**仅仅多出几个内存解引用操作**（相对于创建和初始化栈帧来说，开销很小）\n    - 访问**栈**上的调用者\n    - 读取调用者的**动态类型**\n    - 读取该类型的**虚方法表**\n    - 读取虚方法表某个**索引值**所对应的**目标方法**\n\n```java\n// -XX:CompileCommand=dontinline,*.outBound\n@Slf4j\npublic class InvokeVirtual {\n    public static void main(String[] args) {\n        Passenger a = new Foreigner();\n        Passenger b = new Chinese();\n        long start = System.currentTimeMillis();\n        int count = 2_000_000_000;\n        int half_count = count / 2;\n        for (int i = 1; i <= count; i++) {\n            Passenger c = (i < half_count) ? a : b;\n            c.outBound();\n        }\n        long end = System.currentTimeMillis();\n        // 超多态内存缓存（方法表）：6700ms\n        // 单态内联缓存：2315ms\n        log.info(\"{}ms\", end - start);\n    }\n}\n\nabstract class Passenger {\n    public abstract void outBound();\n\n    @Override\n    public String toString() {\n        return super.toString();\n    }\n}\n\n@Slf4j\nclass Foreigner extends Passenger {\n    @Override\n    public void outBound() {\n    }\n}\n\n@Slf4j\nclass Chinese extends Passenger {\n    @Override\n    public void outBound() {\n    }\n\n    public void shopping() {\n    }\n}\n```\n\nPassenger的方法表\n\n| 索引 | 方法 | 备注 |\n| -- | -- | -- |\n| 0 | Passenger.toString() | 重写Object.toString() |\n| 1 | Passenger.outBound() | 抽象方法，不可执行 |\n\nForeigner的方法表\n\n| 索引 | 方法 | 备注 |\n| -- | -- | -- |\n| 0 | Passenger.toString() | 重写Object.toString() |\n| 1 | Foreigner.outBound() | 重写Passenger.outBound() |\n\nChinese的方法表\n\n| 索引 | 方法 | 备注 |\n| -- | -- | -- |\n| 0 | Passenger.toString() | 重写Object.toString() |\n| 1 | Chinese.outBound() | 重写Passenger.outBound() |\n| 2 | Chinese.shopping() | 购物 |\n\n## 即时编译优化\n\n### 内联缓存\n1. **加快动态绑定**的优化技术：**缓存虚方法调用中调用者的动态类型，以及该类型所对应的目标方法**\n2. 在之后的执行过程中，如果碰到已缓存的类型，内联缓存便会直接调用该类型所对应的目标方法\n    - 如果没有碰到已缓存的类型，内联缓存则会退化至使用**基于虚方法表的动态绑定**\n3. 内联缓存实际上并**没有内联目标方法**\n    - **任何方法调用除非被内联，否则都会有固定开销**\n    - 开销\n        - 保存程序在该方法中的**执行位置**\n        - 新建、压入和弹出新方法所使用的**栈帧**\n    - getter/setter方法的固定开销所占据的CPU时间甚至超过了方法本身\n    - 在**即时编译**中，**方法内联可以消除方法调用的固定开销**\n\n#### 针对多态的优化\n1. 术语\n    - 单态：仅有一种状态的情况\n    - 多态：有限数量状态的情况\n    - 超多态：在某个具体数值之下，称之为多态，否则，称之为超多态\n2. 对于内联缓存，我们也有对应的单态内联缓存、多态内联缓存和超多态内联缓存\n    - 单态内联缓存\n        - 只缓存了一种动态类型以及它所对应的目标方法；比较所缓存的动态类型，如果命中，则调用对应的目标方法\n        - 大部分的虚方法调用均是单态的（只有一种动态类型），为了节省内存空间，**JVM只采用单态内联缓存**\n    - 多态内联缓存（HotSpot中不存在）\n        - 缓存了多个动态类型以及目标方法；逐个将所缓存的动态类型与当前动态类型进行比较，如果命中，则调用相应的目标方法\n        - 一般来说，我们会将更热门的动态类型放在前面\n3. 当内联缓存没有命中的情况下，JVM需要重新使用**虚方法表**进行动态绑定，有两种选择\n    - 替换单态内联缓存中的记录（**数据局部性原理**）\n        - 最坏情况：每次进行方法调用都轮流替换内联缓存，导致**只有写缓存的额外开销，但没有读缓存对性能提升**\n        - 可以劣化为超多态内联缓存\n    - **超多态内联缓存（JVM的具体实现方式）**\n        - 实际上已经**放弃了优化的机会，直接访问虚方法表来动态绑定目标方法**\n4. 单态内联缓存 -> (无法命中，劣化) -> 超多态内联缓存（直接使用虚方法表来进行动态绑定）\n    - **HotSpot只存在单态内联缓存和超多态内联缓存**，不存在多态内联缓存\n\n#### 性能对比\n```java\n// -XX:CompileCommand=dontinline,*.outBound\nPassenger a = new Foreigner();\nPassenger b = new Chinese();\nlong start = System.currentTimeMillis();\nint count = 2_000_000_000;\nint half_count = count / 2;\nfor (int i = 1; i <= count; i++) {\n    Passenger c = (i < half_count) ? a : b;\n    c.outBound();\n}\nlong end = System.currentTimeMillis();\n// 超多态内存缓存（方法表）：6700ms\n// 单态内联缓存：2315ms\nlog.info(\"{}ms\", end - start);\n```\n\n### 方法内联（跳过，后续介绍）\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- 类加载","url":"%2F2018%2F12%2F16%2Fjvm-basic-load-class%2F","content":"\n## 引用类型\n1. 类（字节流）\n2. 接口（字节流）\n3. 数组类（由JVM直接生成）\n4. 泛型参数（类型擦除，伪泛型）\n\n## 类加载过程\n\n### 加载\n1. 加载：**查找字节流，并且据此创建类的过程**\n2. 对于**数组类**，没有对应的字节流，而是由JVM直接生成的\n    - 对于其他类而言，JVM需要借助**类加载器**来完成查找字节流的过程\n\n<!-- more -->\n\n#### 类加载器\n1. 启动类加载器（boot class loader）：由C++实现，没有对应的Java对象，在Java中只能用null来指代\n2. 除了启动类加载器外，其他的类加载器都是**java.lang.ClassLoader**的子类，有对应的Java对象\n    - 这些类加载器需要先由另一个类加载器（如启动类加载器），加载至Java虚拟机中，方能执行类加载\n3. **双亲委派模型**\n    - 每当一个类加载器接收到加载请求时，会先将请求转发给父类加载器\n    - 在父类加载器没有找到所请求的类的情况下，该类加载器才会尝试自己加载\n4. Before Java9\n    - 启动类加载器（boot class loader）：负责加载**最基础、最重要**的类（-Xbootclasspath）\n    - 扩展类加载器（extension class loader）：父类加载器为**启动类加载器**，负责加载**相对次要、但又通用**的类（java.ext.dirs）\n    - 应用类加载器（application class loader）：父类加载器为**扩展类加载器**，负责加载应用程序路径下的类\n        - -cp\n        - -classpath\n        - 系统变量java.class.path\n        - 环境变量CLASSPATH\n5. Since Java9\n    - 引入模块系统\n    - 扩展类加载器改名为**平台类加载器**(platform class loader)\n    - Java SE中除了少数几个关键模块（java.base）是由启动类加载器加载之外，其他的模块均由平台类加载器所加载\n6. 自定义类加载\n    - 例如对class文件进行加密，加载时再利用自定义的类加载器对其解密\n\n#### 命名空间+唯一性\n类的唯一性：**类加载实例 + 类的全名**\n\n### 链接\n1. 链接：将创建的类**合并**至JVM，使之**能够执行**的过程\n2. 链接过程：**验证**、**准备**和**解析**\n\n#### 验证\n1. 确保被加载到类能够**满足JVM的约束条件**\n2. Java编译器生成的类文件必然满足JVM的约束条件\n\n#### 准备\n1. **为被加载类的静态字段分配内存**\n2. Java代码中对静态字段的**具体初始化**，会在**初始化阶段**进行\n3. 构造其他与类层次相关的数据结构，例如用来**实现虚方法的动态绑定的方法表**\n\n#### 解析（可选）\n1. 解析：将**符号引用**解析成为**实际引用**\n2. 在class文件被加载至JVM之前，这个类是无法知道其他类及其方法、字段所对应的具体地址，甚至不知道自己方法、字段的地址\n    - 因此每当需要引用这些成员时，**Java编译器**都会生成一个**符号引用**\n    - 在**运行阶段**，这个符号引用一般都能够无歧义地定位到**具体目标**上\n3. 如果**符号引用**指向一个**未被加载的类**或者**未被加载到类的字段或方法**，那么解析将会**触发这个类的加载**（未必触发这个类的链接和初始化）\n4. Java虚拟机规范**并没有要求在链接过程中要完成解析**\n    - **如果某些字节码使用了符号引用，那么在执行这些字节码之前，需要完成对这些符号引用的解析**\n\n### 初始化\n1. 初始化：**为标记为常量值的字段赋值** + **执行<clinit>方法**\n2. 如果要初始化一个静态字段，可以在声明时直接赋值，也可以在静态代码块中对其赋值\n3. 如果**直接赋值**的静态字段被**final**所修饰，并且它的类型是**基本类型**或**字符串**时，那么该字段便会被**Java编译器**标记为**常量值**（ConstantValue）,**其初始化直接由JVM完成**\n4. 除此之外的直接赋值操作以及所有静态代码块中的代码，则会被Java编译器置于同一方法中，既**<clinit\\>**\n5. JVM会通过**加锁**来保证类的**<clinit\\>** 仅被执行一次\n6. 只有当初始化完成后，类才正式开始成为可执行的状态\n\n#### 触发时机\n1. new指令\n2. putstatic/getstatic指令\n3. invokestatic指令\n4. 反射\n    - Class.forName\n    - Class.newInstance\n5. 子类的初始化会触发父类的初始化\n6. 执行主类\n7. 如果接口定义了default方法，那么直接实现或者间接实现该接口的类进行初始化，会触发该接口初始化\n\n详情请访问[类加载 - 类初始化](http://zhongmingmao.me/2016/07/15/jvm-class-initialization/)\n\n```java\n// JVM参数：-verbose:class\npublic class Singleton {\n    private Singleton() {\n    }\n\n    private static class LazyHolder {\n        static final Singleton INSTANCE = new Singleton();\n\n        static {\n            System.out.println(\"LazyHolder.<clinit>\");\n        }\n    }\n\n    private static Object getInstance(boolean flag) {\n        if (flag) {\n            // Loaded xxx.Singleton$LazyHolder from file:XXX\n            // 新建数组知会导致加载，但不会导致初始化\n            return new LazyHolder[2];\n        }\n        // LazyHolder.<clinit>\n        // getstatic指令触发类的初始化\n        return LazyHolder.INSTANCE;\n    }\n\n    public static void main(String[] args) {\n        getInstance(true);\n        System.out.println(\"----\");\n        getInstance(false);\n    }\n}\n```\n\n## 新建数组\n新建数组**只会触发加载阶段**，而**不会触发链接和初始化阶段**\n```\n$ java -cp ./asmtools.jar org.openjdk.asmtools.jdis.Main Singleton\\$LazyHolder.class > Singleton\\$LazyHolder.jasm.bak\n\n# 将字节码修改为不符合JVM规范，在类加载-链接阶段会报错（从而验证有没有执行到链接阶段）\n$ awk 'NR==1,/stack 1/{sub(/stack 1/, \"stack 0\")} 1' Singleton\\$LazyHolder.jasm.bak > Singleton\\$LazyHolder.jasm\n\n$ java -cp ./asmtools.jar org.openjdk.asmtools.jasm.Main Singleton\\$LazyHolder.jasm\n\n$ java -verbose:class Singleton\n[Loaded Singleton$LazyHolder from file:/Users/zhongmingmao/Downloads/asmtools-7.0-build/dist/asmtools-7.0/lib/]\n----\n[Loaded java.lang.VerifyError from /Users/zhongmingmao/.sdkman/candidates/java/8.0.181-oracle/jre/lib/rt.jar]\nException in thread \"main\" [Loaded java.lang.Throwable$PrintStreamOrWriter from /Users/zhongmingmao/.sdkman/candidates/java/8.0.181-oracle/jre/lib/rt.jar]\n[Loaded java.lang.Throwable$WrappedPrintStream from /Users/zhongmingmao/.sdkman/candidates/java/8.0.181-oracle/jre/lib/rt.jar]\n[Loaded java.util.IdentityHashMap from /Users/zhongmingmao/.sdkman/candidates/java/8.0.181-oracle/jre/lib/rt.jar]\n[Loaded java.util.IdentityHashMap$KeySet from /Users/zhongmingmao/.sdkman/candidates/java/8.0.181-oracle/jre/lib/rt.jar]\njava.lang.VerifyError: Operand stack overflow\nException Details:\n  Location:\n    Singleton$LazyHolder.<init>()V @0: aload_0\n  Reason:\n    Exceeded max stack size.\n  Current Frame:\n    bci: @0\n    flags: { flagThisUninit }\n    locals: { uninitializedThis }\n    stack: { }\n  Bytecode:\n    0x0000000: 2ab7 0007 b1\n\n\tat Singleton.getInstance(Singleton.java:22)\n\tat Singleton.main(Singleton.java:28)\n```\n\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- 基本类型","url":"%2F2018%2F12%2F15%2Fjvm-basic-native-type%2F","content":"\n## boolean类型\n\n### Java代码\n```java\npublic class Foo {\n    public static void main(String[] args) {\n        boolean flag = true;\n        if (flag) System.out.println(\"Hello, Java!\");\n        if (flag == true) System.out.println(\"Hello, JVM!\");\n    }\n}\n```\n\n### 编译运行\n```bash\n$ javac Foo.java\n\n$ java Foo\nHello, Java!\nHello, JVM!\n```\n\n### 修改字节码运行\n```\n# jasm与javap的输出比较类似\n$ java -cp ./asmtools.jar org.openjdk.asmtools.jdis.Main Foo.class > Foo.jasm.bak\n```\n\n<!-- more -->\n\n```\n$ tail -n 23 Foo.jasm.bak | head -n 21\npublic static Method main:\"([Ljava/lang/String;)V\"\n\tstack 2 locals 2\n{\n\t\ticonst_1;\n\t\tistore_1;\n\t\tiload_1;\n\t\tifeq\tL14; # 出栈int，如果等于0时跳转；实际为1，无需跳转\n\t\tgetstatic\tField java/lang/System.out:\"Ljava/io/PrintStream;\";\n\t\tldc\tString \"Hello, Java!\";\n\t\tinvokevirtual\tMethod java/io/PrintStream.println:\"(Ljava/lang/String;)V\";\n\tL14:\tstack_frame_type append;\n\t\tlocals_map int;\n\t\tiload_1;\n\t\ticonst_1;\n\t\tif_icmpne\tL27; # 出栈2个int，如果不相等时跳转；实际为1和1，无需跳转\n\t\tgetstatic\tField java/lang/System.out:\"Ljava/io/PrintStream;\";\n\t\tldc\tString \"Hello, JVM!\";\n\t\tinvokevirtual\tMethod java/io/PrintStream.println:\"(Ljava/lang/String;)V\";\n\tL27:\tstack_frame_type same;\n\t\treturn;\n}\n```\n使用awk命令修改字节码\n```\n$ awk 'NR==1,/iconst_1/{sub(/iconst_1/, \"iconst_2\")} 1' Foo.jasm.bak > Foo.jasm\n\n$ tail -n 23 Foo.jasm.bak | head -n 21\npublic static Method main:\"([Ljava/lang/String;)V\"\n\tstack 2 locals 2\n{\n\t\ticonst_2; # iconst_1 -> iconst_2\n\t\tistore_1;\n\t\tiload_1;\n\t\tifeq\tL14; # 出栈int，如果等于0时跳转；实际为1，无需跳转\n\t\tgetstatic\tField java/lang/System.out:\"Ljava/io/PrintStream;\";\n\t\tldc\tString \"Hello, Java!\";\n\t\tinvokevirtual\tMethod java/io/PrintStream.println:\"(Ljava/lang/String;)V\";\n\tL14:\tstack_frame_type append;\n\t\tlocals_map int;\n\t\tiload_1;\n\t\ticonst_1;\n\t\tif_icmpne\tL27; # 出栈2个int，如果不相等时跳转；实际为1和2，需跳转\n\t\tgetstatic\tField java/lang/System.out:\"Ljava/io/PrintStream;\";\n\t\tldc\tString \"Hello, JVM!\";\n\t\tinvokevirtual\tMethod java/io/PrintStream.println:\"(Ljava/lang/String;)V\";\n\tL27:\tstack_frame_type same;\n\t\treturn;\n}\n```\n\n```\n$ java -cp ./asmtools.jar org.openjdk.asmtools.jasm.Main Foo.jasm\n\n$ java Foo\nHello, Java!\n```\n\n### Java语言规范+Java虚拟机规范\n1. Java语言规范：boolean类型只有两个取值：**true**和**false**，显然这两个符号是不能被虚拟机直接使用的\n2. Java虚拟机规范：**boolean类型被映射成int类型**，true被映射成1，false被映射成0\n    - 这个编码规则约束了**Java字节码的具体实现**\n        - 例如对于存储boolean数组的字节码，JVM需要保证实际存入的值为整数1或0\n    - 要求**Java编译器**也遵守这个编码规则，并且用**整数相关的字节码**来实现**逻辑运算**，以及boolean类型的**条件跳转**\n        - 因此，编译而成的class文件中，除了**字段**和**入参**外，基本看不出boolean类型的痕迹\n\n## 基本类型\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-native-type.png\" />\n\n1. 默认值看起来不一样，但在内存中都是**0**\n2. boolean和char是**无符号类型**，通常我们可以认定char类型是非负数，可以作为数组索引\n\n### 浮点数\n\n### 两个0\n```java\nprivate static String floatToHexIntBits(float f) {\n    return Integer.toHexString(Float.floatToIntBits(f));\n}\n```\n```java\nfloat z1 = +0.0F; // +0.0F\nfloat z2 = -0.0F; // -0.0F\nlog.info(\"{}\", floatToHexIntBits(z1)); // 0\nlog.info(\"{}\", floatToHexIntBits(z2)); // 0x80000000\nlog.info(\"{}\", z1 == z2); // 两个0对应的内存数值不同，但+0.0F == -0.0F\n```\n\n### 两个Infinity\n1. 正无穷：**任意正浮点数**（不含+0.0F）除以**+0.0F**得到的值\n2. 负无穷：**任意正浮点数**（不含+0.0F）除以**-0.0F**得到的值\n3. 正无穷和负无穷都是有**确切**的值的，分别是**0x7F800000**和**0xFF800000**\n\n```java\npublic static final float POSITIVE_INFINITY = 1.0f / 0.0f;\npublic static final float NEGATIVE_INFINITY = -1.0f / 0.0f;\nlog.info(\"{}\", floatToHexIntBits(Float.POSITIVE_INFINITY)); // 0x7F800000\nlog.info(\"{}\", floatToHexIntBits(Float.NEGATIVE_INFINITY)); // 0XFF800000\n```\n\n### NaN(Not-a-Number)\n1. NaN：**[0x7F800001, 0x7FFFFFFF] U [0xFF800001, 0xFFFFFFFF]**\n2. 标准NaN：**+0.0f/+0.0f，0x7FC00000**\n3. 除了**!=** 始终返回**true**之外，其他所有的比较结果都会返回false\n\n```java\nfloat f = 1.0F;\nlog.info(\"{}\", floatToHexIntBits(NaN)); // 0x7FC00000\nlog.info(\"{}\", NaN < f);    // false\nlog.info(\"{}\", NaN >= f);   // false\nlog.info(\"{}\", NaN != f);   // true\nlog.info(\"{}\", NaN == f);   // false\nlog.info(\"{}\", NaN == NaN); // false\n```\n\n### 存储\n1. JVM每调用一个**Java方法**，都会创建一个**栈帧**\n2. 栈帧组成：**局部变量表**+**操作数栈**\n    - 局部变量表示广义的，包含实例方法的\"this\"指针和入参\n3. 局部变量表等价于一个**数组**，**long**和**double** 需要用**2个**数组单元来存储，其他基本类型和引用类型均占用1个数组单元\n    - boolean、byte、char、short、int、float和reference\n        - 32位HotSpot：在栈上占用**4Bytes**\n        - 64位HotSpot：在栈上占用**8Bytes**\n    - 这种情况**仅存在于局部变量表**中，并不会出现在存储在堆中的字段或者数组元素上\n4. 将一个**int类型**的值，存储到**堆中的char**类型字段时，相当于做了一次**隐式的掩码操作**（0xFFFFFFFF -> '\\uFFFF'）\n5. **boolean数组直接用byte数组来实现**\n    - 为了保证堆中的boolean值是合法的，HotSpot在存储时进行**显式的掩码操作**，只取最后一位的值存入boolean字段或数组\n\n```java\n@Slf4j\n@Data\npublic class User {\n    private boolean sex;\n\n    public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException {\n        Field field = Unsafe.class.getDeclaredField(\"theUnsafe\");\n        field.setAccessible(true);\n        Unsafe unsafe = (Unsafe) field.get(null);\n\n        User user = new User();\n        Field sexField = User.class.getDeclaredField(\"sex\");\n\n        unsafe.putByte(user, unsafe.objectFieldOffset(sexField), (byte) 2);\n        log.info(\"{}\", user.isSex()); // 10 -> 0 , false\n\n        unsafe.putByte(user, unsafe.objectFieldOffset(sexField), (byte) 3);\n        log.info(\"{}\", user.isSex()); // 11 -> 1 , true\n    }\n}\n```\n### 加载\n1. JVM的算数运算依赖于操作数栈，将堆中的boolean、byte、char以及short加载到操作数栈上，而后将栈上到值**当做int类型**来运算\n2. 对于**boolean**和**char**这两个**无符号**类型来说，加载伴随着**零扩展**\n3. 对于**byte**和**short**这两个**有符号**类型来说，加载伴随着**符号扩展**\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- 运行过程+运行效率","url":"%2F2018%2F12%2F14%2Fjvm-basic-run%2F","content":"\n## 虚拟机视角\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-jvm-vision.png\" />\n\n1. 将class文件加载到JVM中，加载后的Java类会被存放在**方法区**，实际运行时，虚拟机会执行方法区内的代码\n2. JVM同样会将内存划分出**堆**和**栈**来存储运行时数据，栈会细分**本地方法栈**和**Java方法栈**\n3. PC寄存器：用于记录**各个线程的执行位置**\n4. 在运行过程中，每当调用进入一个**Java方法**，JVM会在**当前线程的Java方法栈**中生成一个**栈帧**\n    - 栈帧用于存放**局部变量表**和**操作数**\n    - 栈帧的大小是**提前计算**好的，并且JVM**不要求**栈帧在内存空间里**连续分布**\n5. 当退出当前执行的方法时，不管是**正常返回**还是**异常返回**，JVM都会**弹出并舍弃当前线程的当前栈帧**\n\n<!-- more -->\n\n## 硬件视角\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/basic/jvm-basic-hardware-vision.png\" />\n\n1. Java字节码无法直接执行，需要JVM将字节码翻译成机器码，有两种形式：**解析执行**+**即时编译**\n    - 解释执行：逐条将字节码翻译成机器码并执行，**无需等待编译**\n    - 即时编译（JIT）：将**一个方法中包含的所有字节码**编译成机器码后再执行，**实际运行速度更快**\n2. HotSpot默认采用**混合模式**，**先解析执行** 字节码，然后将其反复执行的热点代码，**以方法为单位** 进行**即时编译**\n    - 即时编译建立在**2-8定律**的假设之上\n    - 对于占据大部分的不常用代码，无需耗费时间将其编译成机器码，而是采用解释执行的方式\n    - 对于仅占小部分的热点代码，我们可以将其编译成机器码，以达到理想的运行速度\n\n## JVM的运行效率\n1. 理论上讲，即时编译后的Java程序的执行效率，是有可能超过C++程序的，这是因为与静态编译相比，即时编译拥有程序的**运行时信息**，并且能够根据这个信息作出**相应的优化**\n2. 为了满足不同用户场景的需要，HotSpot内置了多个即时编译器：**C1**、**C2**和**Graal**（Java 10引入，实验性）\n    - 引入多个即时编译器，是为了在**编译时间**和**生成代码的执行效率**之间进行取舍\n    - C1又叫做**Client编译器**，面向对**启动性能**有要求的GUI程序，采用的优化手段相对简单，因此编译时间较短\n    - C2又叫做**Server编译器**，面向对是对**峰值性能**有要求的服务端程序，采用的优化手段相对复杂，因此编译时间较长，但生成代码执行效率较高\n3. 从Java 7开始，HotSpot默认采用**分层编译**的方式，**热点方法首先会被C1编译，而后热点方法中的热点会进一步被C2编译**\n4. 为了不干扰应用的正常运行，HotSpot的即时编译是放在**额外的编译线程**中进行的，HotSpot会根据CPU的数量设置编译线程的数目，默认按**1:2**的比例配置给C1和C2编译器\n5. 在计算资源充足的情况下，字节码的**解释执行和即时编译可同时进行**。解析完成后的机器码会在**下一次调用**该方法时启用，以替换原本的解释执行\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"Kafka -- 消费者","url":"%2F2018%2F10%2F18%2Fkafka-consume%2F","content":"\n## 基本概念\n\n### 消费者 + 消费者群组\n1. _**消费者从属于消费者群组**_\n2. 一个消费者群组里的消费者订阅的是**同一个主题**，每个消费者接收主题的**部分分区**的消息\n\n#### 消费者横向扩展\n\n##### 1个消费者\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/consumer_topic_1.png\" width=\"400\">\n1. 主题T1有4个分区，然后创建消费者C1，C1是消费者群组G1里唯一的消费者，C1订阅T1\n2. 消费者C1将接收主题T1的**全部**4个分区的消息\n\n<!-- more -->\n\n##### 2个消费者\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/consumer_topic_2.png\" width=\"400\">\n1. 如果群组G1新增一个消费者C2，那么每个消费者将**分别从两个分区接收消息**\n2. 假设C1接收分区0和分区2的消息，C2接收分区1和分区3的消息\n\n##### 4个消费者\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/consumer_topic_3.png\" width=\"400\">\n如果群组G1有4个消费者，那么每个消费者可以分配到一个分区\n\n##### 5个消费者\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/consumer_topic_4.png\" width=\"400\">\n如果群组G1有5个消费者，_**消费者数量超过主题的分区数量**_，那么有1个消费者就会被**闲置**，不会接收到任何消息\n\n##### 总结\n1. 往群组里增加消费者是**横向伸缩消费能力**的主要方式\n2. 消费者经常会做一些**高延迟**的操作，比如把数据写到数据库或HDFS，或者使用数据进行比较耗时的计算\n3. 有必要**为主题创建大量的分区**，在负载增长时可以加入更多的消费者，**减少消息堆积**\n    - 不要让**消费者的数量超过主题分区的数量**，多余的消费者只会被**闲置**\n\n#### 消费者群组横向扩展\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/consumer_topic_5.png\" width=\"400\">\n1. Kafka设计的主要目标之一，就是要让Kafka主题里的数据能够满足企业各种应用场景（**不同的消费者群组**）的需求\n2. 在这些场景里，每个应用程序可以获取到**所有的消息**，而不只是其中的一部分\n3. 只要保证每个应用程序有自己的消费者群组，就可以让它们获取到主题所有的消息\n4. 不同于传统的消息系统，_**横向伸缩Kafka消费者和消费者群组并不会对性能造成负面影响**_\n\n### 消费者群组 + 分区再均衡\n\n#### 分区再均衡\n1. 分区再均衡：_**分区的所有权从一个消费者转移到另一个消费者**_\n2. 分区再均衡非常重要，它为消费者群组带来了**高可用性**和**伸缩性**（可以放心地添加或移除消费者）\n3. 在分区再均衡期间，_**消费者无法读取消息**_，造成整个群组在一小段时间内**不可用**\n4. 当分区被**重新分配**给另一个消费者时，消费者**当前的读取状态**会**丢失**\n    - 它有可能需要去**刷新缓存**，在它重新恢复状态之前会**拖慢应用程序**\n\n#### 心跳\n1. 消费者通过向被指派为**群组协调器**的Broker发送**心跳**\n    - 目的\n        - 维持它们_**和群组的从属关系**_\n        - 维持它们_**对分区的所有权关系**_\n    - **不同的群组可以有不同的协调器**\n2. 只要消费者以**正常的时间间隔**发送心跳，就被认为是**活跃**的，说明它还在读取分区里的消息\n3. 消费者发送心跳的时机\n    - **轮询消息**（为了获取消息）\n    - **提交偏移量**\n4. 如果消费者停止发送心跳的时间**足够长**，会话就会过期，群组协调器认为它已经**死亡**，就会触发一次**再均衡**\n5. 如果一个消费者发生崩溃，并停止读取消息，群组协调器会等待几秒钟，确认它死亡了才会触发再均衡\n    - 在这几秒的时间内，死掉的消费者不会读取分区里的消息\n6. 在清理消费者时，消费者会**通知**群组协调器它**将要离开群组**，群组协调器会**立即**触发一次**再均衡**，尽量**降低处理停顿**\n\n#### 分配分区\n1. 当消费者要加入消费者群组时，它会向**群组协调器**发送一个`JoinGroup`的请求，**第一个**加入群组的消费者将成为**群主**\n2. **群主**（消费者）从**群组协调器**（Broker）那里获得**成员列表**（消费者）\n    - 列表中包含了**最近发送过心跳的消费者**，它们被认为是**活跃**的\n    - _**群主负责给每个成员（消费者）分配分区**_\n    - 实现`PartitionAssignor`接口的类来决定哪些分区应该被分配给哪个消费者\n3. **群主**（消费者）分配分区完毕后，把**分区的分配情况**发送给**群组协调器**（Broker）\n    - **群组协调器**（Broker）再把这些信息发送给**所有的消费者**\n    - _**每个消费者只能看到自己的分配信息，只有群主知道消费者群组里所有消费者的分配信息**_\n4. 这个过程会在每次**再均衡**时重复发生\n\n## 创建消费者\n```java\nProperties properties = new Properties();\nproperties.put(\"bootstrap.servers\", \"localhost:9092\");\nproperties.put(\"group.id\", GROUP_ID);\nproperties.put(\"key.deserializer\", StringDeserializer.class.getName());\nproperties.put(\"value.deserializer\", StringDeserializer.class.getName());\nConsumer<String, String> consumer = new KafkaConsumer<>(properties);\n```\n\n## 订阅主题\n```java\n// 订阅主题\n// 支持正则表达式：如果创建新主题，并且主题的名字与正则表达式匹配，\n//              就会触发一次再均衡，消费者就能读取新添加的主题\n// consumer.subscribe(\"test.*\");\nconsumer.subscribe(Collections.singletonList(TOPIC));\n```\n\n## 轮询\n1. 消息轮询是消费者API的核心，通过一个简单的轮询向服务器请求数据\n2. 一旦消费者订阅了主题，轮询就会处理**所有的细节**\n    - **群组协调**、**分区再均衡**、**发送心跳**、**获取数据**\n3. 线程安全\n    - 在同一个群组里，无法让一个线程运行多个消费者，也无法让多个线程安全地共享一个消费者\n    - 按照规则，_**一个消费者使用一个线程**_\n\n```java\ntry {\n    while (true) {\n        // 消费者必须持续对Kafka进行轮询，否则会被认为已经死亡，它的分区就会被移交给群组里的其它消费者\n        // 在消费者的缓冲区里没有可用数据时会发生阻塞\n        // 返回一个记录列表，每条记录包含\n        //  1. 记录所属主题的信息\n        //  2. 记录所在分区的信息\n        //  3. 记录在分区里的偏移量\n        //  4. 记录的键值对\n        // timeout参数指定多久之后可以返回，不管有没有可用的数据，0会立即返回\n        ConsumerRecords<String, String> records = consumer.poll(100);\n        records.forEach(record -> log.info(\"topic={}, partition={}, offset={}, key={}, value={}\",\n                record.topic(), record.partition(), record.offset(), record.key(), record.value()));\n    }\n} finally {\n    // 网络连接和Socket也会随之关闭\n    // 并且立即触发一次再均衡，而不是等待群组协调器发现它不再发送心跳并认定它已死亡\n    //  因为那样需要更长的时间，导致整个群组在一段时间内无法读取消息\n    consumer.close();\n}\n```\n\n## 消费者的配置\n\n### fetch.min.bytes\n1. 该参数指定了消费者**单个数据请求**的最小字节数，默认值为`1`\n2. Broker在收到消费者的数据请求时\n    - 如果可用的数据量小于`fetch.min.bytes`指定的大小，那么它会等到有足够的可用数据时才会返回给消费者\n    - 这样可以降低消费者和Broker的工作负载，因为在主题不是很活跃的时候，就不需要来回处理消息\n\n### fetch.max.wait.ms\n1. 如果`fetch.max.wait.ms`（默认值为500）被设为100ms，并且`fetch.min.bytes`被设为1MB\n2. 那么Kafka在收到消费者的请求后，要么返回1MB数据，要么在100ms后返回所有可用的数据，**看哪个条件先得到满足**\n\n### max.partition.fetch.bytes\n1. 该参数指定了服务器从**每个分区**里返回给消费者的最大字节数，默认1MB\n    - `Consumer.poll()`方法从**每个分区**里返回的数据不能超过`max.partition.fetch.bytes`\n    - 如果单次`poll()`返回的数据太多，消费者需要更多时间来处理\n        - 可能无法及时地进行下一次**轮询**（发送**心跳**）来避免**会话过期**，**触发再平衡**\n        - 减少`max.partition.fetch.bytes`的值\n        - 或者**延长会话过期时间**\n2. 如果主题有20个分区和5个消费者，那么每个消费者需要至少4MB的可用内存来接收记录\n    - 在为消费者分配内存时，可以适当地多分配些\n    - 因为如果消费者群组里有消费者发生崩溃，剩下的消费者需要处理更多的分区\n3. `max.partition.fetch.bytes`必须比`message.max.bytes`（Broker能够接收到最大消息的字节数）大\n    - 否着消费者可能**无法读取**这些**大消息**，导致**消费者一直挂起重试**\n\n### session.timeout.ms + heartbeat.interval.ms\n1. `session.timeout.ms`指定了**消费者在被认为死亡之前可以与服务器断开连接的时间**，默认值为10000\n    - 如果消费者没有在`session.timeout.ms`指定的时间内发送**心跳**给在**群组协调器**（Broker）\n    - 就会被认为已经死亡，群组协调器就会触发**再均衡**\n2. `heartbeat.interval.ms`指定了`poll()`方法向群组协调器**发送心跳的频率**，默认值为3000\n    - 而`session.timeout.ms`指定了消费者**可以多久不发心跳**\n3. `heartbeat.interval.ms`必须比`session.timeout.ms`小，一般是`session.timeout.ms`的**1/3**\n4. 如果把`session.timeout.ms`值设置得**比默认值小**，可以**更快地检测和恢复崩溃的节点**\n    - 不过长时间的轮询或者GC可能会导致**非预期的再均衡**\n5. 如果把`session.timeout.ms`值设置得比默认值大，**可以减少意外的再均衡**\n    - 不过检测节点崩溃需要更长的时间\n\n### auto.offset.reset\n1. 该参数指定了消费者在下列情况下该如何处理\n    - 读取一个**没有偏移量**的分区（新加入消费者，还没有该消费者的消费记录）\n    - **偏移量无效**（消费者长时间失效，包含偏移量的记录已经过时并被删除）\n2. 默认值是**latest**：消费者从**最新**的记录开始读取数据\n3. **earliest**：消费者从**起始位置**读取分区的记录\n\n### enable.auto.commit + auto.commit.interval.ms\n1. `enable.auto.commit`指定了消费者是否**自动提交偏移量**，默认值是true\n    - 可能出现**重复数据**和**数据丢失**\n2. `auto.commit.interval.ms`指定提交的**频率**，默认值为5000\n\n### partition.assignment.strategy\n1. 分区会被分配给消费群组里的消费者的策略\n2. `Range`：把主题的若干**连续**的分区分配给消费者，默认值\n3. `RoundRobin`：把主题的所有分区**逐个**分配给消费者\n\n### client.id\n1. 任意字符串，Broker用它来标识从客户端发过来的消息\n2. 通常被用在日志、度量指标和配额里\n\n### max.poll.records\n1. 该参数用于控制单次调用`poll()`方法能够返回的消息数量，默认值为500\n\n### receive.buffer.bytes + send.buffer.bytes\n1. 设置socket在**读写数据**时用到的**TCP缓冲区**\n    - 如果为**-1**，就使用**操作系统的默认值**\n    - `receive.buffer.bytes`的默认值为`32KB`\n    - `send.buffer.bytes`的默认值为`128KB`\n2. 如果生产者或消费者与Broker处于不同的数据中心内，可以适当增大这些值\n\n## 提交 + 偏移量\n1. 每次调用`poll()`方法，总是返回由生产者写入Kafka但还没有被消费者读取过的记录\n2. Kakfa不像其它JMS队列那样，_**Kafka不需要得到消费者的确认**_\n3. 消费者可以使用Kafka来追踪消息在分区里的位置（偏移量）\n4. 把**更新分区当前位置**的操作叫作**提交**\n    - 消费者往一个叫作`__consumer_offsets`的特殊主题发送消息，消息里包含_**每个分区的偏移量**_\n    - 如果**消费者发生崩溃**或者有**新的消费者加入群组**，就会触发**再均衡**\n    - 完成再均衡之后，每个消费者可能**分配到新的分区**\n        - 为了能继续之前的工作，消费者需要读取**每个分区最后一次提交的偏移量**，然后从偏移量指定的位置继续处理\n5. 偏移量不相同\n    - 如果提交的偏移量 **小于** 客户端处理的最后一个消息的偏移量\n        - 那么处于**两个偏移量之间的消息**就会被_**重复处理**_\n    - 如果提交的偏移量 **大于** 客户端处理的最后一个消息的偏移量\n        - 那么处于**两个偏移量之间的消息**就会_**丢失**_\n\n### 自动提交\n1. 自动提交是基于**时间间隔**\n2. 如果`enable.auto.commit`为true，那么每过`auto.commit.interval.ms`（默认5s）\n    - 消费者就会自动把从`poll()`方法接收到的**最大偏移量**提交上去，_**不论客户端是否真的处理完**_\n3. 自动提交也是在**轮询**里进行，消费者**每次轮询**时会**检查是否该提交偏移量**\n    - 如果是，那就会提交`poll()`返回的**最大偏移量**\n\n#### 问题\n1. _**消息重复处理**_\n    - 假设时刻`T`自动提交，在时刻`T+3`发生了再均衡，还没到时刻`T+5`\n        - _客户端已经处理的部分消息没有被提交_\n    - 再均衡之后，消费者还是会从最后一次提交的偏移量位置（时刻`T`）开始读取消息，消息会被重复处理\n2. _**消息丢失**_\n    - 假设时刻`T`自动提交，执行`poll()`拉回100条消息，在时刻`T+5`会再次提交\n    - 但在时刻`T+5`，客户端只处理完了90条消息，在自动提交完成之后的那一刻该客户端崩溃，消息丢失\n3. 每次调用轮询方法都会把上一次调用`poll()`返回的**最大偏移量**提交上去，_**并不关心哪些消息已经被处理过了**_\n    - 所以在再次调用轮询之前最好确保**所有应该处理的消息**都已经处理完毕\n\n### 同步提交\n1. `enable.auto.commit=false`，让应用程序决定何时提交偏移量\n2. 使用`commitAsync()`提交偏移量**最简单也最可靠**\n    - 提交由`poll()`方法返回的**最大偏移量**，提交成功后立马返回，如果提交失败就会抛出异常\n3. 如果发生**再均衡**，消息会被_**重复处理**_\n\n```java\nconsumer.subscribe(Collections.singletonList(TOPIC));\ntry {\n    while (true) {\n        // 获取最新偏移量\n        ConsumerRecords<String, String> records = consumer.poll(100);\n        records.forEach(record -> {\n            log.info(\"topic={}, partition={}, offset={}, key={}, value={}\",\n                    record.topic(), record.partition(), record.offset(), record.key(), record.value());\n        });\n        // 同步提交当前偏移量\n        consumer.commitAsync();\n    }\n} finally {\n    consumer.close();\n}\n```\n\n### 异步提交\n1. **同步提交**，在Broker对提交请求作出响应之前，应用程序会一直**阻塞**，_**限制应用程序的吞吐量**_\n    - 可以通过**降低提交频率**来**提升吞吐量**，但如果发生再均衡，会增加重复消息的数量\n2. 在**成功提交**或碰到**无法恢复的错误**之前，`commitSync()`会**一直重试**，但是`commitAsync()`不会\n    - 不进行重试的原因：_**在它收到服务器响应的时候，可能有一个更大的偏移量已经提交成功**_\n3. `commitAsync()`支持**回调**，在Broker作出响应时会执行回调（通常用于记录提交错误或生成度量指标）\n    - 如果用**回调**来进行**重试**，一定要注意_**提交的顺序**_\n    - 使用一个**单调递增的序列号**来维护**异步提交的顺序**\n    - 在每次**提交偏移量之后**或者在**回调里提交偏移量时**递增序列号\n    - 在进行重试前，先检查**回调的序列号**和**即将提交的偏移量**是否相等\n        - 如果**相等**，说明没有新的提交，那么可以安全地进行**重试**\n        - 如果**回调序列号比较大**，说明有一个新的提交已经发送出去了，应该**停止重试**\n\n```java\nconsumer.subscribe(Collections.singletonList(TOPIC));\nwhile (true) {\n    ConsumerRecords<String, String> records = consumer.poll(100);\n    for (ConsumerRecord<String, String> record : records) {\n        log.info(\"topic={}, partition={}, offset={}, key={}, value={}\",\n                record.topic(), record.partition(), record.offset(),\n                record.key(), record.value());\n    }\n    // 异步提交\n    consumer.commitAsync((offsets, exception) -> {\n        if (exception != null) {\n            log.error(\"Commit failed for offsets \" + offsets, exception);\n        }\n    });\n}\n```\n\n### 组合提交（同步+异步）\n1. 一般情况下，偶尔出现的提交失败，不进行重试不会有太大问题\n2. 如果这是发生在**关闭消费者**或者**再均衡前**的**最后一次提交**，那么就要_**确保能够提交成功**_\n\n```java\nconsumer.subscribe(Collections.singletonList(TOPIC));\ntry {\n    while (true) {\n        ConsumerRecords<String, String> records = consumer.poll(100);\n        for (ConsumerRecord<String, String> record : records) {\n            log.info(\"topic={}, partition={}, offset={}, key={}, value={}\",\n                    record.topic(), record.partition(), record.offset(),\n                    record.key(), record.value());\n        }\n        // 异步提交，速度更快，如果这次提交失败，下一次提交很有可能会成功\n        consumer.commitAsync((offsets, exception) -> {\n            if (exception != null) {\n                log.error(\"Commit failed for offsets \" + offsets, exception);\n            }\n        });\n    }\n} catch (Exception e) {\n    log.error(\"Unexpected error\", e);\n} finally {\n    try {\n        // 一直重试，直到提交成功或者发生无法恢复的错误\n        consumer.commitSync();\n    } finally {\n        // 如果直接关闭消费者，就没有所谓的下一次提交了\n        consumer.close();\n    }\n}\n```\n\n### 提交特定的偏移量\n1. 提交偏移量的频率和处理消息批次的频率是一样的\n2. `commitSync()`和`commitAsync()`，只会提交**最后一个偏移**，而此时该批次里的部分消息可能还没处理\n3. 如果需要提交特定的偏移量，需要**跟踪所有分区的偏移量**\n\n```java\nconsumer.subscribe(Collections.singletonList(TOPIC));\n// 用于追踪偏移量的Map\nMap<TopicPartition, OffsetAndMetadata> currentOffsets = Maps.newHashMap();\nint count = 0;\nwhile (true) {\n    ConsumerRecords<String, String> records = consumer.poll(100);\n    for (ConsumerRecord<String, String> record : records) {\n        log.info(\"topic={}, partition={}, offset={}, key={}, value={}\",\n                record.topic(), record.partition(), record.offset(), record.key(), record.value());\n        // 在读取每条记录后，使用期望处理的下一条记录的偏移量更新map里的偏移量\n        // 下一次就从这里开始读取消息\n        TopicPartition topicPartition = new TopicPartition(record.topic(), record.partition());\n        OffsetAndMetadata offsetAndMetadata = new OffsetAndMetadata(record.offset() + 1, \"no metadata\");\n        currentOffsets.put(topicPartition, offsetAndMetadata);\n        if (count++ % 1000 == 0) {\n            // 每处理1000条记录就提交一次偏移量\n            // 提交特定偏移量时，仍然要处理可能发生的错误（虽然这里的OffsetCommitCallback虽然为null）\n            consumer.commitAsync(currentOffsets, null);\n        }\n    }\n}\n```\n\n## 再均衡监听器\n1. 消费者在**退出消费者群组**和进行**分区再均衡**之前，会做一些清理工作\n    - 在消费者**失去对一个分区的所有权之前**提交**最后一个已处理**记录的**偏移量**\n    - 如果消费者准备了一个缓冲区用于处理偶发的事件，那么在失去分区所有权之前，需要处理在缓冲区累积下来的记录\n    - 关闭文件句柄，数据库连接\n2. 在为消费者**分配新分区**或者**移除旧分区**时，可以通过消费者API执行一些动作\n    - 在调用`subscribe()`方法传进去一个`ConsumerRebalanceListener`实例\n    - `onPartitionsRevoked`\n        - 在**消费者停止读取消息之后**和**再均衡开始之前**被调用\n        - 如果在这里提交偏移量，下一个接管分区的消费者就知道该从哪里开始读取\n    - `onPartitionsAssigned`\n        - 在**重新分配分区之后**和**消费者开始读取之前**被调用\n\n```java\nMap<TopicPartition, OffsetAndMetadata> currentOffsets = Maps.newHashMap();\n\nclass HandleRebalance implements ConsumerRebalanceListener {\n    @Override\n    public void onPartitionsRevoked(Collection<TopicPartition> partitions) {\n        // 如果发生再均衡，需要提交的是最近处理过的偏移量，而不是批次中还在处理的最后一个偏移量\n        consumer.commitSync(currentOffsets);\n    }\n\n    @Override\n    public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n    }\n}\n\ntry {\n    consumer.subscribe(Collections.singletonList(\"CustomerCountry\"), new HandleRebalance());\n    while (true) {\n        ConsumerRecords<String, String> records = consumer.poll(100);\n        for (ConsumerRecord<String, String> record : records) {\n            log.info(\"topic={}, partition={}, offset={}, key={}, value={}\",\n                    record.topic(), record.partition(), record.offset(),\n                    record.key(), record.value());\n            // 在读取每条记录后，使用期望处理的下一条记录的偏移量更新map里的偏移量\n            // 下一次就从这里开始读取消息\n            currentOffsets.put(new TopicPartition(record.topic(), record.partition()),\n                    new OffsetAndMetadata(record.offset() + 1, \"no metadata\"));\n        }\n        consumer.commitAsync(currentOffsets, null);\n    }\n} catch (WakeupException e) {\n    // 忽略异常，正在关闭消费者\n} catch (Exception e) {\n    log.error(\"Unexpected error\", e);\n} finally {\n    try {\n        consumer.commitSync(currentOffsets);\n    } finally {\n        consumer.close();\n        log.info(\"Close consumer successfully!\");\n    }\n}\n```\n\n## 从特定偏移量开始处理记录\n```java\n// org.apache.kafka.clients.consumer.Consumer\n// 从分区的起始位置开始读取消息\nvoid seekToBeginning(Collection<TopicPartition> partitions);\n// 直接跳到分区的末尾开始读取消息\nvoid seekToEnd(Collection<TopicPartition> partitions);\n// 直接跳到特定偏移量\nvoid seek(TopicPartition partition, long offset);\n```\n\n```java\nprivate void commitDbTransaction() {\n}\nprivate int getOffsetFromDB(TopicPartition partition) {\n    return 0;\n}\nprivate void storeOffsetInDb(String topic, int partition, long offset) {\n}\nprivate void storeRecordInDb(ConsumerRecord<String, String> record) {\n}\nprivate void processRecord(ConsumerRecord<String, String> record) {\n}\n\n@Test\npublic void seekTest() {\n    class SaveOffsetOnRebalance implements ConsumerRebalanceListener {\n        @Override\n        public void onPartitionsRevoked(Collection<TopicPartition> partitions) {\n            commitDbTransaction();\n        }\n\n        @Override\n        public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n            partitions.forEach(partition -> consumer.seek(partition, getOffsetFromDB(partition)));\n        }\n    }\n    consumer.subscribe(Collections.singletonList(TOPIC), new SaveOffsetOnRebalance());\n    consumer.assignment().forEach(partition -> consumer.seek(partition, getOffsetFromDB(partition)));\n    while (true) {\n        ConsumerRecords<String, String> records = consumer.poll(100);\n        records.forEach(record -> {\n            processRecord(record);\n            // 同一个事务\n            storeRecordInDb(record);\n            storeOffsetInDb(record.topic(), record.partition(), record.offset());\n        });\n        commitDbTransaction();\n    }\n}\n```\n\n## 退出\n```java\n// ShutdownHook运行在单独的线程里，所以退出循环最安全的方式是调用wakeup()\nRuntime.getRuntime().addShutdownHook(new Thread() {\n    @Override\n    public void run() {\n        // wakeup()是消费者唯一一个可以从其他线程里安全调用的方法\n        // 调用wakeup()可以退出poll()，并抛出WakeupException\n        //  WakeupException不需要处理，这只是跳出循环的一种方式\n        // 在退出线程之前调用close()是很有必要的\n        //  close()方法会提交任何还没有提交的东西，并向群组协调器发送消息，告知自己要离开群组\n        //  接下来就会触发再均衡，不需要等待会话超时\n        consumer.wakeup();\n        try {\n            // 主线程\n            join();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n});\ntry {\n    // 循环，直到按下CTRL+C，关闭的钩子会在退出时进行清理\n    while (true) {\n        ConsumerRecords<String, String> records = consumer.poll(100);\n        records.forEach(record -> {\n            // process\n        });\n        consumer.assignment().forEach(partition -> {\n        });\n        consumer.commitSync();\n    }\n} catch (WakeupException e) {\n    // ignore\n} finally {\n    // 退出之前，确保彻底关闭了消费者\n    consumer.close();\n}\n```\n\n## 反序列化器\n1. 对于开发者而言\n    - 必须明确写入主题的消息使用的是哪一种序列化器\n    - 并确保每个主题里只包含能够被反序列化器解析的数据\n\n### 自定义序列化器\n1. 不推荐使用**自定义序列化器**和**自定义反序列化器**，它们把生产者和消费者**耦合**在一起，很**脆弱**，容易出错\n2. 推荐使用标准的消息格式，如`JSON`、`Thrift`、`Protobuf`和`Avro`\n\n```java\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"group.id\", GROUP_ID);\nprops.put(\"key.deserializer\", StringDeserializer.class.getName());\n// 自定义的反序列化器\nprops.put(\"value.deserializer\", CustomerDeserializer.class);\nConsumer<Object, Object> consumer = new KafkaConsumer<>(props);\nconsumer.subscribe(Collections.singletonList(TOPIC));\nwhile (true) {\n    ConsumerRecords<Object, Object> records = consumer.poll(100);\n    records.forEach(record -> {\n        // process\n    });\n}\n```\n```java\n@Data\n@AllArgsConstructor\nclass Customer {\n    private int id;\n    private String name;\n}\n\nclass CustomerDeserializer implements Deserializer<Customer> {\n    @Override\n    public void configure(Map<String, ?> configs, boolean isKey) {\n        // 不做任何配置\n    }\n\n    @Override\n    public Customer deserialize(String topic, byte[] data) {\n        try {\n            if (data == null) {\n                return null;\n            }\n            if (data.length < 8) {\n                throw new SerializationException(\"Size of received is shorter than expected\");\n            }\n            ByteBuffer buffer = ByteBuffer.wrap(data);\n            int id = buffer.getInt();\n            int nameSize = buffer.getInt();\n            byte[] nameBytes = new byte[nameSize];\n            buffer.get(nameBytes);\n            String deserializedName = new String(nameBytes, StandardCharsets.UTF_8);\n            return new Customer(id, deserializedName);\n        } catch (Exception e) {\n            // log\n            return null;\n        }\n    }\n\n    @Override\n    public void close() {\n    }\n}\n```\n\n## 独立消费者\n1. 场景\n    - 只需要一个消费者从一个主题的**所有分区**或者某个**特定分区**读取数据\n    - 此时不再需要**消费者群组**和**再均衡**\n    - 只需要把主题或者分区分配给消费者，然后开始读取消息并提交偏移量\n2. 这时不再需要订阅主题，取而代之的是**消费者为自己分配分区**\n3. 一个消费者可以**订阅主题**（并加入消费者群组），或者为自己**分配分区**，但这两个动作是**互斥**的\n\n```java\n// 向集群请求主题可用的分区，如果只读取特定分区，跳过这一步\nList<PartitionInfo> partitionInfoList = consumer.partitionsFor(TOPIC);\nif (partitionInfoList != null) {\n    List<TopicPartition> partitions = Lists.newArrayList();\n    partitionInfoList.forEach(partitionInfo -> {\n        partitions.add(new TopicPartition(partitionInfo.topic(), partitionInfo.partition()));\n    });\n    // 知道哪些分区后，调用assign()方法\n    // 不会发生再均衡，也不需要手动查找分区\n    // 但是如果主题增加了新的分区，消费者并不会收到通知\n    //  因此需要周期性地调用consumer.partitionsFor()来检查是否有新分区加入\n    //  要么在添加新分区后重启应用程序\n    consumer.assign(partitions);\n}\nwhile (true) {\n    ConsumerRecords<String, String> records = consumer.poll(100);\n    records.forEach(record -> {\n        // process\n    });\n    consumer.commitSync();\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["Stream"],"categories":["Kafka"]},{"title":"Kafka -- Avro + Twitter Bijection","url":"%2F2018%2F10%2F16%2Fkafka-avro-bijection%2F","content":"\n## Avro + Kafka Native API\n1. 比较繁琐\n    - 编译`Schema`\n    - 依赖于`Avro`实现**自定义的序列化器和反序列化器**\n\n## 引入依赖\n```xml\n<dependency>\n    <groupId>com.twitter</groupId>\n    <artifactId>bijection-avro_2.12</artifactId>\n    <version>0.9.6</version>\n</dependency>\n```\n\n<!-- more -->\n\n## Schema\n路径：src/main/resources/user.json\n```json\n{\n  \"type\": \"record\",\n  \"name\": \"User\",\n  \"fields\": [\n    {\"name\": \"id\", \"type\": \"int\"},\n    {\"name\": \"name\",  \"type\": \"string\"},\n    {\"name\": \"age\", \"type\": \"int\"}\n  ]\n}\n```\n\n## 发送消息\n```java\nString schemaFilePath = BijectionProducer.class.getClassLoader().getResource(\"user.json\").getPath();\nSchema schema = new Schema.Parser().parse(new File(schemaFilePath));\nInjection<GenericRecord, byte[]> recordInjection = GenericAvroCodecs.toBinary(schema);\n\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"key.serializer\", StringSerializer.class.getName());\nprops.put(\"value.serializer\", ByteArraySerializer.class.getName());\nProducer<String, byte[]> producer = new KafkaProducer<>(props);\n\nfor (int i = 0; i < 10; i++) {\n    GenericData.Record record = new GenericData.Record(schema);\n    record.put(\"id\", i);\n    record.put(\"name\", TOPIC + i);\n    record.put(\"age\", i);\n    byte[] bytes = recordInjection.apply(record);\n    ProducerRecord<String, byte[]> producerRecord = new ProducerRecord<>(TOPIC, bytes);\n    RecordMetadata metadata = producer.send(producerRecord).get();\n    log.info(\"id={}, timestamp={}, partition={}, offset={}\",\n            record.get(\"id\"), metadata.timestamp(), metadata.partition(), metadata.offset());\n}\nproducer.close();\n```\n\n## 消费消息\n```java\nString schemaFilePath = BijectionProducer.class.getClassLoader().getResource(\"user.json\").getPath();\nSchema schema = new Schema.Parser().parse(new File(schemaFilePath));\nInjection<GenericRecord, byte[]> recordInjection = GenericAvroCodecs.toBinary(schema);\n\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"key.serializer\", StringSerializer.class.getName());\nprops.put(\"value.serializer\", ByteArraySerializer.class.getName());\nProducer<String, byte[]> producer = new KafkaProducer<>(props);\n\nfor (int i = 0; i < 10; i++) {\n    GenericData.Record record = new GenericData.Record(schema);\n    record.put(\"id\", i);\n    record.put(\"name\", TOPIC + i);\n    record.put(\"age\", i);\n    byte[] bytes = recordInjection.apply(record);\n    ProducerRecord<String, byte[]> producerRecord = new ProducerRecord<>(TOPIC, bytes);\n    RecordMetadata metadata = producer.send(producerRecord).get();\n    log.info(\"id={}, timestamp={}, partition={}, offset={}\",\n            record.get(\"id\"), metadata.timestamp(), metadata.partition(), metadata.offset());\n}\nproducer.close();\n```\n\n<!-- indicate-the-source -->\n","tags":["Avro"],"categories":["Kafka"]},{"title":"Kafka -- Avro + Kafka Native API","url":"%2F2018%2F10%2F16%2Fkafka-avro-native%2F","content":"\n## Schema\n```json\n{\n    \"namespace\": \"me.zhongmingmao.avro\",\n    \"type\": \"record\",\n    \"name\": \"Stock\",\n    \"fields\": [\n        {\"name\": \"stockCode\", \"type\": \"string\"},\n        {\"name\": \"stockName\",  \"type\": \"string\"},\n        {\"name\": \"tradeTime\", \"type\": \"long\"},\n        {\"name\": \"preClosePrice\", \"type\": \"float\"},\n        {\"name\": \"openPrice\", \"type\": \"float\"},\n        {\"name\": \"currentPrice\", \"type\": \"float\"},\n        {\"name\": \"highPrice\", \"type\": \"float\"},\n        {\"name\": \"lowPrice\", \"type\": \"float\"}\n    ]\n}\n```\n\n<!-- more -->\n\n## 编译Schema\n```\nmvn clean compile\n```\n\n## 自定义序列化器\n```java\npublic class StockSerializer implements Serializer<Stock> {\n    @Override\n    public void configure(Map<String, ?> configs, boolean isKey) {\n    }\n\n    @Override\n    public byte[] serialize(String topic, Stock stock) {\n        if (stock == null) {\n            return null;\n        }\n\n        ByteArrayOutputStream out = new ByteArrayOutputStream();\n        // Avro\n        DatumWriter<Stock> datumWriter = new SpecificDatumWriter<>(stock.getSchema());\n        BinaryEncoder encoder = EncoderFactory.get().directBinaryEncoder(out, null);\n        try {\n            datumWriter.write(stock, encoder);\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n        return out.toByteArray();\n    }\n\n    @Override\n    public void close() {\n    }\n}\n```\n\n## 自定义反序列化器\n```java\npublic class StockDeserializer implements Deserializer<Stock> {\n    @Override\n    public void configure(Map<String, ?> configs, boolean isKey) {\n    }\n\n    @Override\n    public Stock deserialize(String topic, byte[] data) {\n        if (data == null) {\n            return null;\n        }\n\n        Stock stock = new Stock();\n        ByteArrayInputStream in = new ByteArrayInputStream(data);\n        // Avro\n        DatumReader<Stock> datumReader = new SpecificDatumReader<>(stock.getSchema());\n        BinaryDecoder decoder = DecoderFactory.get().directBinaryDecoder(in, null);\n        try {\n            stock = datumReader.read(null, decoder);\n        } catch (IOException e) {\n            throw new SerializationException(e);\n        }\n        return stock;\n    }\n\n    @Override\n    public void close() {\n    }\n}\n```\n\n## 发送消息\n```java\nList<Stock> stocks = Lists.newArrayList();\nfor (int i = 0; i < 10; i++) {\n    Stock stock = Stock.newBuilder()\n            .setStockCode(String.valueOf(i))\n            .setStockName(\"stock\" + i)\n            .setTradeTime(System.currentTimeMillis())\n            .setPreClosePrice(100).setOpenPrice(200)\n            .setCurrentPrice(300).setHighPrice(400).setLowPrice(0).build();\n    stocks.add(stock);\n}\n\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"key.serializer\", StringSerializer.class.getName());\n// 自定义序列化器\nprops.put(\"value.serializer\", StockSerializer.class.getName());\n\nProducer<String, Stock> producer = new KafkaProducer<>(props);\n\nfor (Stock stock : stocks) {\n    ProducerRecord<String, Stock> record = new ProducerRecord<>(TOPIC, stock);\n    RecordMetadata metadata = producer.send(record).get();\n    log.info(\"stock={}, timestamp={}, partition={}, offset={}\",\n            stock.getStockName(), metadata.timestamp(), metadata.partition(), metadata.offset());\n}\n```\n\n## 消费消息\n```java\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"group.id\", GROUP_ID);\nprops.put(\"key.deserializer\", StringDeserializer.class.getName());\n// 自定义反序列化器\nprops.put(\"value.deserializer\", StockDeserializer.class.getName());\n\nConsumer<String, Stock> consumer = new KafkaConsumer<>(props);\nconsumer.subscribe(Collections.singletonList(TOPIC));\n\ntry {\n    while (true) {\n        ConsumerRecords<String, Stock> records = consumer.poll(100);\n        for (ConsumerRecord<String, Stock> record : records) {\n            Stock stock = record.value();\n            log.info(\"stock={}\", stock);\n        }\n    }\n} finally {\n    consumer.close();\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["Avro"],"categories":["Kafka"]},{"title":"Kafka -- Avro入门","url":"%2F2018%2F10%2F15%2Fkafka-avro-introduction%2F","content":"\n## 引入依赖\n```xml\n<dependency>\n    <groupId>org.apache.avro</groupId>\n    <artifactId>avro</artifactId>\n    <version>1.8.2</version>\n</dependency>\n```\n\n<!-- more -->\n```xml\n<plugin>\n    <groupId>org.apache.avro</groupId>\n    <artifactId>avro-maven-plugin</artifactId>\n    <version>1.8.2</version>\n    <executions>\n        <execution>\n            <phase>generate-sources</phase>\n            <goals>\n                <goal>schema</goal>\n            </goals>\n            <configuration>\n                <sourceDirectory>${project.basedir}/src/main/avro/</sourceDirectory>\n                <outputDirectory>${project.basedir}/src/main/java/</outputDirectory>\n            </configuration>\n        </execution>\n    </executions>\n</plugin>\n```\n\n## Schema\n路径：src/main/avro/user.avsc\n```json\n{\n    \"namespace\": \"me.zhongmingmao.avro\",\n    \"type\": \"record\",\n    \"name\": \"User\",\n    \"fields\": [\n        {\"name\": \"name\", \"type\": \"string\"},\n        {\"name\": \"favorite_number\",  \"type\": [\"int\", \"null\"]},\n        {\"name\": \"favorite_color\", \"type\": [\"string\", \"null\"]}\n    ]\n}\n```\n\n## 使用Avro -- 生成代码\n\n### 编译Schema\n```shell\n# 执行avro-maven-plugin:1.8.2:schema\n# 生成类：src/main/java/me/zhongmingmao/avro/User.java\n$ mvn clean compile\n```\n\n### 序列化\n```java\nUser user1 = new User();\nuser1.setName(\"A\");\nuser1.setFavoriteNumber(1);\nUser user2 = new User(\"B\", 2, \"c2\");\nUser user3 = User.newBuilder().setName(\"C\").setFavoriteNumber(3).setFavoriteColor(\"c3\").build();\n\n// org.apache.avro.io.DatumWriter\nDatumWriter<User> userDatumWriter = new SpecificDatumWriter<>(User.class);\nDataFileWriter<User> dataFileWriter = new DataFileWriter<>(userDatumWriter);\ndataFileWriter.create(user1.getSchema(), new File(\"/tmp/users.avro\"));\ndataFileWriter.append(user1);\ndataFileWriter.append(user2);\ndataFileWriter.append(user3);\ndataFileWriter.close();\n```\n\n### 反序列化\n```java\n// org.apache.avro.io.DatumReader\nDatumReader<User> userDatumReader = new SpecificDatumReader<>(User.class);\nDataFileReader<User> dataFileReader = new DataFileReader<>(new File(\"/tmp/users.avro\"), userDatumReader);\nUser user = null;\nwhile (dataFileReader.hasNext()) {\n    user = dataFileReader.next(user);\n    log.info(\"{}\", user);\n}\ndataFileReader.close();\n// {\"name\": \"A\", \"favorite_number\": 1, \"favorite_color\": null}\n// {\"name\": \"B\", \"favorite_number\": 2, \"favorite_color\": \"c2\"}\n// {\"name\": \"C\", \"favorite_number\": 3, \"favorite_color\": \"c3\"}\n```\n\n## 使用Avro -- 不生成代码\n\n### 序列化\n```java\n// src/main/resources/user.avsc\nString avscFilePath = getClass().getClassLoader().getResource(\"user.avsc\").getPath();\nSchema schema = new Schema.Parser().parse(new File(avscFilePath));\n\nGenericData.Record user1 = new GenericData.Record(schema);\nuser1.put(\"name\", \"A\");\nuser1.put(\"favorite_number\", 1);\nGenericData.Record user2 = new GenericData.Record(schema);\nuser2.put(\"name\", \"B\");\nuser2.put(\"favorite_number\", 2);\nuser2.put(\"favorite_color\", \"c2\");\n\n// 序列化\nDatumWriter<GenericRecord> userDatumWriter = new SpecificDatumWriter<>(schema);\nDataFileWriter<GenericRecord> dataFileWriter = new DataFileWriter<>(userDatumWriter);\ndataFileWriter.create(schema, new File(\"/tmp/users.avro\"));\ndataFileWriter.append(user1);\ndataFileWriter.append(user2);\ndataFileWriter.close();\n\n// 反序列化\nDatumReader<GenericRecord> userDatumReader = new SpecificDatumReader<>(schema);\nDataFileReader<GenericRecord> dataFileReader = new DataFileReader<>(new File(\"/tmp/users.avro\"), userDatumReader);\nGenericRecord user = null;\nwhile (dataFileReader.hasNext()) {\n    user = dataFileReader.next(user);\n    log.info(\"{}\", user);\n}\ndataFileReader.close();\n// {\"name\": \"A\", \"favorite_number\": 1, \"favorite_color\": null}\n// {\"name\": \"B\", \"favorite_number\": 2, \"favorite_color\": \"c2\"}\n```\n\n<!-- indicate-the-source -->\n","tags":["Avro"],"categories":["Kafka"]},{"title":"Kafka -- 生产者","url":"%2F2018%2F10%2F11%2Fkafka-produce%2F","content":"\n## 生产者概述\n\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/producer_component.png\" width=\"600\">\n\n1. 创建一个`ProducerRecord`对象，`ProducerRecord`对象包含**Topic**和**Value**，还可以指定**Key**或**Partition**\n2. 在发送`ProducerRecord`对象时，生产者先将**Key**和**Partition**序列化成**字节数组**，以便于在网络上传输\n3. 字节数组被传给**分区器**\n    - 如果在`ProducerRecord`对象里指定了**Partition**\n        - 那么分区器就不会做任何事情，直接返回指定的分区\n    - 如果没有指定分区，那么分区器会根据`ProducerRecord`对象的**Key**来选择一个**Partition**\n    - 选择好分区后，生产者就知道该往哪个主题和分区发送这条记录\n4. 这条记录会被添加到一个**记录批次**里，一个批次内的**所有**消息都会被发送到**相同的Topic和Partition**上\n    - 有一个**单独的线程**负责把这些记录批次发送到相应的Broker\n5. 服务器在收到这些消息时会返回一个响应\n    - 如果消息成功写入Kafka，就会返回一个`RecordMetaData`对象\n        - 包含了**Topic**和**Partition**信息，以及**记录在分区里的偏移量**\n    - 如果写入失败，就会返回一个错误\n    - 生产者在收到错误之后会尝试**重新发送消息**，几次之后如果还是失败，就会返回错误信息\n\n<!-- more -->\n\n## 创建生产者\n\n### 必选属性\n\n#### bootstrap.servers\n1. Broker的地址清单，**host:port**\n2. 清单里不需要包含所有的Broker地址，**生产者会从给定的Broker里找到其它Broker的信息**\n    - 建议**最少两个**，一旦其中一个宕机，生产者仍然能够连接到集群上\n\n#### key.serializer\n1. Broker希望接收到的消息的**Key**和**Value**都是**字节数组**\n2. 生产者接口允许使用**参数化类型**，因此可以把**Java对象**作为**Key**和**Value**发送给Broker\n3. `key.serializer`必须是`org.apache.kafka.common.serialization.Serializer`的实现类\n4. 生产者会通过`key.serializer`把**Key对象**序列化为_**字节数组**_\n5. Kafka默认提供\n    - `ByteArraySerializer`\n    - `StringSerializer`\n    - `IntegerSerializer`\n\n#### value.serializer\n1. 与`key.serializer`类似，`value.serializer`指定的类会把**Value**序列化成**字节数组**\n2. 如果**Key**和**Value**都是**字符串**，可以使用与`key.serializer`一样的序列化器\n3. 如果**Key**是整数类型，而**Value**是字符串，那么需要使用不同的序列化器\n\n#### Java代码\n```java\nProperties properties = new Properties();\nproperties.put(\"bootstrap.servers\", \"localhost:9092\");\nproperties.put(\"key.serializer\", StringSerializer.class.getName());\nproperties.put(\"value.serializer\", StringSerializer.class.getName());\nproducer = new KafkaProducer<>(properties);\n```\n\n## 发送消息\n\n### 发送方式\n\n#### 发送并忘记\n1. 生产者把消息发送给服务器，但**并不关心是否正常到达**\n2. Kafka是**高可用**的，而且生产者会**自动尝试重发**\n3. 但会**丢失**一些消息\n\n#### 同步发送\n```java\n// Key对象和Value对象的类型必须与生产者对象的序列化器相匹配\n// key.serializer -> StringSerializer\n// value.serializer -> StringSerializer\nProducerRecord<String, String> record = new ProducerRecord<>(TOPIC, KEY, VALUE);\n\n// 消息被放入缓冲区，使用单独的线程发送到服务端端\nFuture<RecordMetadata> future = producer.send(record);\n\n// 调用Future对象的get()方法等待Kafka响应，如果服务器返回错误，get()方法会抛出异常\n// 如果没有发生错误，会得到一个RecordMetadata对象，通过RecordMetadata对象可以获取消息的元数据\nRecordMetadata recordMetadata = future.get();\nlog.info(\"timestamp={}\", recordMetadata.timestamp());\nlog.info(\"partition={}\", recordMetadata.partition());\nlog.info(\"offset={}\", recordMetadata.offset());\n```\n\n##### 发送错误\n1. **可重试错误**（可以通过重发消息来解决的错误）\n    - **连接错误**，可以通过再次建立连接来解决\n        - `KafkaProducer`可以被配置成**自动重连**\n        - 如果在多次重试后扔无法解决问题，应用程序会收到一个重试异常\n    - **No Leader 错误**，可以通过重新为分区选举领导来解决\n2. 无法通过重试解决的错误，例如消息太大，`KafkaProducer`不会进行任何重试，直接抛出异常\n\n#### 异步发送\n```java\nProducerRecord<String, String> record = new ProducerRecord<>(TOPIC, KEY, VALUE);\nFuture<RecordMetadata> future = producer.send(record, (metadata, exception) -> {\n    // 如果Kafka返回一个错误，onCompletion方法会抛出一个非空异常\n    log.info(\"timestamp={}\", metadata.timestamp());\n    log.info(\"partition={}\", metadata.partition());\n    log.info(\"offset={}\", metadata.offset());\n});\nRecordMetadata recordMetadata = future.get();\n```\n\n## 生产者配置\n\n### acks\n1. `acks`：必须有多少个**分区副本**收到消息，生产者才会认为**消息写入是成功**的\n2. **ack=0**：生产者**不会等待**任何来自服务器的响应。\n    - 如果当中出现问题，导致服务器没有收到消息，那么生产者无从得知，会造成**消息丢失**\n    - 由于生产者不需要等待服务器的响应\n        - 所以可以以网络能够支持的最大速度发送消息，从而达到**很高的吞吐量**\n3. **acks=1**（默认值）：只要集群的**Leader节点**收到消息，生产者就会收到一个来自服务器的成功响应\n    - 如果消息无法到达**Leader节点**（例如Leader节点崩溃，新的Leader节点还没有被选举出来）\n        - 生产者就会收到一个错误响应，为了避免数据丢失，生产者会**重发消息**\n    - _**如果一个没有收到消息的节点成为新Leader，消息还是会丢失**_\n    - 此时的吞吐量主要取决于使用的是**同步发送**还是**异步发送**\n        - 吞吐量还受到**发送中消息数量的限制**，例如生产者在收到服务器响应之前可以发送多少个消息\n4. **acks=all**：只有当**所有参与复制的节点**全部都收到消息时，生产者才会收到一个来自服务器的成功响应\n    - 这种模式是**最安全**的\n        - 可以保证不止一个服务器收到消息，就算有服务器发生崩溃，整个集群依然可以运行\n    - **延时比acks=1更高**，因为要等待不止一个服务器节点接收消息\n\n### buffer.memory\n1. 该参数用来设置**生产者内缓冲区**的大小，生产者用缓冲区来缓冲要发送到服务器端的消息，默认为`32MB`\n2. 如果应用程序发送消息的速度超过了发送到服务器端速度，会导致生产者空间不足\n3. 这个时候，`send()`方法调用要么被**阻塞**，要么**抛出异常**，取决于`block.on.buffer.full`\n\n### compression.type\n1. 默认情况下为`none`，消息在发送时是**不会被压缩**的\n2. 该参数可以设置为`snappy`、`gzip`或者`lz4`\n    - `snappy`压缩算法由Google发明\n        - 占用**较少的CPU**，却能提供**较好的性能**和相当**可观的压缩比**\n        - 适用于关注**性能**和**网络带宽**的场景\n    - `gzip`压缩算法\n        - 占用**较多的CPU**，但会提供**更高的压缩比**\n        - 适用于**网络带宽比较有限**的场景\n3. 压缩消息可以降低**网络传输开销**和**存储开销**，而这往往是向`Broker`发送消息的瓶颈\n\n### retries\n1. 生产者从服务器收到的错误有可能是**临时性错误**（如分区找不到Leader）\n2. 在这种情况下，`retries`参数决定了生产者可以**重发消息的次数**\n    - 默认情况下，生产者会在每次重试之间等待**100ms**，控制参数为`retry.backoff.ms`\n    - 可以先测试一下恢复一个崩溃节点需要多少时间，假设为`T`\n        - 让生产者**总的重试时间**比`T`长，否着生产者会_**过早地放弃重试**_\n3. 有些错误不是临时性错误，没办法通过重试来解决（例如消息太大）\n4. 一般情况下，因为生产者会**自动**进行重试，所以没必要在代码逻辑处理那些可重试的错误\n    - 只需要处理那些**不可重试的错误**或者**重试次数超过上限**的情况\n\n### batch.size\n1. 当有**多个消息**需要被发送到**同一个分区**时，生产者会把它们放在**同一个批次**里，默认值为`16KB`\n    - 该参数指定了一个批次可以使用多**内存大小**，单位为_**字节**_\n2. 当批次被填满，批次里的所有消息会被发送出去\n    - **生产者不一定会等到批次被填满才发送**，半满设置只有一个消息的批次也有可能被发送\n    - 如果`batch.size`设置**很大**，也**不会造成延迟**，只是会占用**更多的内存**\n    - 如果`batch.size`设置**很小**，生产者需要**频繁地发送消息**，会增加一些**额外的开销**\n\n### linger.ms\n1. 该参数指定了生产者**在发送批次之前等待更多消息加入批次的时间**，默认值为0\n2. `KafkaProducer`会在**批次填满**或者**linger.ms达到上限**时把批次发出去\n3. 默认情况下，只要有可用的线程，生产者就会把消息发出去，就算批次里**只有一个消息**\n4. 设置`linger.ms`，会**增加延迟**，但也会**提高吞吐量**\n    - 一次性发送更多的消息，平摊到单个消息的开销就变小了\n\n### client.id\n任意字符串，服务器会用它来识别**消息的来源**，还可以用在日志和配额指标里\n\n### max.in.flight.requests.per.connection\n1. 该参数指定了生产者**在收到服务器响应之前可以发送多少消息**，默认值为5\n2. 值越高，会占用**越多的内存**，不过也会**提升吞吐量**\n3. 如果设为**1**，可以保证消息是**按照发送的顺序写入服务器**，即使发生重试\n\n### timeout.ms、request.timeout.ms、metadata.fetch.timeout.ms\n1. `timeout.ms`：指定了Broker**等待同步副本返回消息确认**的时间，默认值为30000\n    - 与`acks`的配置相匹配，如果在指定时间内没有收到同步副本的确认，那么Broker就会返回一个错误\n2. `request.timeout.ms`：指定了**生产者**在**发送数据**时**等待服务器返回响应**的时间，默认值为10000\n3. `metadata.fetch.timeout.ms`：指定了**生产者**在**获取元数据**时**等待服务器返回响应**的时间，默认值为60000\n    - 如果等待响应超时，那么生产者要么**重试**发送数据，要么返回一个**错误**（抛出异常或者执行回调）\n\n### max.block.ms\n1. 该参数指定了在调用`send()`方法或使用`partitionsFor()`方法获取元数据时，**生产者阻塞的时间**，默认值为60000\n2. 当生产者的**发送缓冲区已满**，或者**没有可用的元数据**时，上面两个方法会**阻塞**\n3. 在阻塞时间达到`max.block.ms`时，生产者就会抛出超时异常\n\n### max.request.size\n1. 该参数用于控制生产者发送**单个请求的大小**，默认值`1MB`\n    - 可以指**能发送的单个消息的最大值**（因为一个请求最少有一个消息）\n    - 也可以指**单个请求里所有消息（一个批次，多个消息）的总大小**\n3. `Broker`对**单个可接收消息的最大值**也有自己的限制（`message.max.bytes`，默认值为`1000012`）\n    - 所以两边的配置最好可以**匹配**，避免生产者发送的消息被`Broker`拒绝\n\n### receive.buffer.bytes、send.buffer.bytes\n1. 这两个参数分别指定了**TCP Socket**接收和发送数据包的缓冲区大小\n  - 如果都被设为**-1**，就使用**操作系统的默认值**\n  - `receive.buffer.bytes`的默认值为`32KB`\n  - `send.buffer.bytes`的默认值为`128KB`\n2. 如果生产者或消费者与Broker处于不同的数据中心，那么可以适当增大这些值\n\n## 序列化器\n\n### 自定义序列化\n1. 如果发送到Kafka的对象不是简单的**字符串**或**整型**，那么可以使用**序列化框架**来创建消息记录\n    - 例如**通用**的序列化框架（推荐）：`Avro`、`Thrift`、`ProtoBuf`\n    - 也可以使用自定义序列化器，但不推荐\n\n```java\n// 复杂对象\n@Data\n@AllArgsConstructor\nclass Customer {\n    private int id;\n    private String name;\n}\n```\n\n```java\n// 序列化器\nclass CustomerSerializer implements Serializer<Customer> {\n\n    @Override\n    public void configure(Map<String, ?> configs, boolean isKey) {\n        // 不做任何配置\n    }\n\n    @Override\n    public byte[] serialize(String topic, Customer customer) {\n        if (null == customer) {\n            return null;\n        }\n        byte[] serializedName = new byte[0];\n        int strLen = 0;\n        if (customer.getName() != null) {\n            serializedName = customer.getName().getBytes(StandardCharsets.UTF_8);\n            strLen = serializedName.length;\n        }\n\n        // Customer对象被序列化成\n        //  1. id：占用4个字节\n        //  2. name的长度：占用4个字节\n        //  3. name：占用N个字节\n        ByteBuffer buffer = ByteBuffer.allocate(4 + 4 + strLen);\n        buffer.putInt(customer.getId());\n        buffer.putInt(strLen);\n        buffer.put(serializedName);\n\n        return buffer.array();\n    }\n\n    @Override\n    public void close() {\n        // 不需要关闭任何东西\n    }\n}\n```\n\n```java\npublic class CustomSerializerTest {\n    private static final String TOPIC = \"Customer\";\n    private static final String KEY = \"Customer\";\n\n    @Test\n    public void customSerializerTest() {\n        Customer value = new Customer(1, \"zhongmingmao\");\n        ProducerRecord<String, Customer> record = new ProducerRecord<>(TOPIC, KEY, value);\n    }\n}\n```\n\n### Avro\n1. `Apache Avro`是一种**与编程语言无关**的序列化格式\n2. `Avro`数据通过**与语言无关的schema**来定义\n    - `schema`通过**JSON**来**描述**，数据被序列化成**二进制文件**或**JSON文件**，一般会使用二进制文件\n    - `Avro`在**读写文件**时需要用到`schema`，`schema`一般是**内嵌在数据文件**里\n3. 重要特性\n    - _**当负责写消息的应用程序使用新的schema，负责读消息的应用程序可以继续处理消息而无需做任何改动**_\n    - 特别适用于Kafka这样的消息系统\n\n## 分区\n1. Kafka的消息是一个**键值对**，`ProducerRecord`对象可以只包含`Topic`和`Value`，`Key`可以设置为**null**\n2. Key的作用\n    - 作为_**消息的附加信息**_\n    - 用来_**决定消息被写到主题的哪一个分区**_\n3. 拥有**相同Key的消息**会被写入到**同一个分区**\n4. 如果**Key为null**，并且使用了**默认的分区器**，那么记录会被**随机**（**轮询算法**）地发送到主题内的各个**可用分区**上\n5. 如果**Key不为null**，并且使用了**默认的分区器**，那么Kafka会对`Key`进行**散列**，然后根据散列值把消息**映射**到特定的分区上\n    - 使用的是**Kafka内部的散列算法**，即使升级Java版本，散列值也不会发生变化\n    - _**同一个Key总是被映射到同一个分区上**_\n        - 因此在映射时，会使用**主题的所有分区**，如果写入数据的分区是**不可用**的，那么就会**发生错误**\n    - _**只有不改变分区数量的情况下，Key与分区之间的映射才能保持不变**_\n        - 如果使用`Key`来映射分区，最好在创建主题的时候就把分区**规划**好，并且**永远不要增加新分区**\n6. 可以**自定义分区器**\n\n<!-- indicate-the-source -->\n","tags":["Stream"],"categories":["Kafka"]},{"title":"Kafka -- 集群安装与配置（Docker）","url":"%2F2018%2F10%2F08%2Fkafka-install-cluster-docker%2F","content":"\n## 配置文件\n\n### 文件列表\n```\n$ tree\n.\n└── docker-compose.yml\n```\n\n<!-- more -->\n\n### docker-compose.yml\n```\nversion: '2'\nservices:\n  zk1:\n    image: confluentinc/cp-zookeeper:latest\n    hostname: zk1\n    container_name: zk1\n    restart: always\n    ports:\n      - \"12181:2181\"\n    environment:\n      ZOOKEEPER_SERVER_ID: 1\n      ZOOKEEPER_CLIENT_PORT: 2181\n      ZOOKEEPER_TICK_TIME: 2000\n      ZOOKEEPER_INIT_LIMIT: 5\n      ZOOKEEPER_SYNC_LIMIT: 2\n      ZOOKEEPER_SERVERS: zk1:12888:13888;zk2:22888:23888;zk3:32888:33888\n\n  zk2:\n    image: confluentinc/cp-zookeeper:latest\n    hostname: zk2\n    container_name: zk2\n    restart: always\n    ports:\n      - \"22181:2181\"\n    environment:\n      ZOOKEEPER_SERVER_ID: 2\n      ZOOKEEPER_CLIENT_PORT: 2181\n      ZOOKEEPER_TICK_TIME: 2000\n      ZOOKEEPER_INIT_LIMIT: 5\n      ZOOKEEPER_SYNC_LIMIT: 2\n      ZOOKEEPER_SERVERS: zk1:12888:13888;zk2:22888:23888;zk3:32888:33888\n\n  zk3:\n    image: confluentinc/cp-zookeeper:latest\n    hostname: zk3\n    container_name: zk3\n    restart: always\n    ports:\n      - \"32181:2181\"\n    environment:\n      ZOOKEEPER_SERVER_ID: 3\n      ZOOKEEPER_CLIENT_PORT: 2181\n      ZOOKEEPER_TICK_TIME: 2000\n      ZOOKEEPER_INIT_LIMIT: 5\n      ZOOKEEPER_SYNC_LIMIT: 2\n      ZOOKEEPER_SERVERS: zk1:12888:13888;zk2:22888:23888;zk3:32888:33888\n\n  kafka1:\n    image: confluentinc/cp-kafka:latest\n    hostname: kafka1\n    container_name: kafka1\n    restart: always\n    depends_on:\n      - zk1\n      - zk2\n      - zk3\n    environment:\n      KAFKA_BROKER_ID: 1\n      KAFKA_ZOOKEEPER_CONNECT: zk1:2181,zk2:2181,zk3:2181\n      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092\n\n  kafka2:\n    image: confluentinc/cp-kafka:latest\n    hostname: kafka2\n    container_name: kafka2\n    restart: always\n    depends_on:\n      - zk1\n      - zk2\n      - zk3\n    environment:\n      KAFKA_BROKER_ID: 2\n      KAFKA_ZOOKEEPER_CONNECT: zk1:2181,zk2:2181,zk3:2181\n      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9092\n\n  kafka3:\n    image: confluentinc/cp-kafka:latest\n    hostname: kafka3\n    container_name: kafka3\n    restart: always\n    depends_on:\n      - zk1\n      - zk2\n      - zk3\n    environment:\n      KAFKA_BROKER_ID: 3\n      KAFKA_ZOOKEEPER_CONNECT: zk1:2181,zk2:2181,zk3:2181\n      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9092\n\n  kafka_manager:\n    image: hlebalbau/kafka-manager:latest\n    hostname: kafka_manager\n    container_name: kafka_manager\n    restart: always\n    ports:\n      - \"9000:9000\"\n    environment:\n      ZK_HOSTS: \"zk1:2181,zk2:2181,zk3:2181\"\n      APPLICATION_SECRET: \"random-secret\"\n      KAFKA_MANAGER_AUTH_ENABLED: \"true\"\n      KAFKA_MANAGER_USERNAME: zhongmingmao\n      KAFKA_MANAGER_PASSWORD: zhongmingmao\n    command: -Dpidfile.path=/dev/null\n```\n\n## 验证\n\n### 启动\n```\n$ docker-compose up -d\nCreating network \"kafka_default\" with the default driver\nCreating zk2           ... done\nCreating zk3           ... done\nCreating kafka_manager ... done\nCreating zk1           ... done\nCreating kafka1        ... done\nCreating kafka2        ... done\nCreating kafka3        ... done\n\n$ docker-compose ps\n    Name                   Command               State                      Ports\n----------------------------------------------------------------------------------------------------\nkafka1          /etc/confluent/docker/run        Up      9092/tcp\nkafka2          /etc/confluent/docker/run        Up      9092/tcp\nkafka3          /etc/confluent/docker/run        Up      9092/tcp\nkafka_manager   /kafka-manager/bin/kafka-m ...   Up      0.0.0.0:9000->9000/tcp\nzk1             /etc/confluent/docker/run        Up      0.0.0.0:12181->2181/tcp, 2888/tcp, 3888/tcp\nzk2             /etc/confluent/docker/run        Up      0.0.0.0:22181->2181/tcp, 2888/tcp, 3888/tcp\nzk3             /etc/confluent/docker/run        Up      0.0.0.0:32181->2181/tcp, 2888/tcp, 3888/tcp\n```\n\n### 发送消息\n```\n# 进入kafka1\n$ docker exec -it kafka1 bash\n\n# 创建主题\nroot@kafka1:/# kafka-topics --zookeeper zk1:2181,zk2:2181,zk3:2181 --replication-factor 1 --partitions 1 --create --topic zhongmingmao\nCreated topic \"zhongmingmao\".\nroot@kafka1:/# kafka-topics --zookeeper zk1:2181,zk2:2181,zk3:2181 --describe --topic zhongmingmao\nTopic:zhongmingmao\tPartitionCount:1\tReplicationFactor:1\tConfigs:\n\tTopic: zhongmingmao\tPartition: 0\tLeader: 2\tReplicas: 2\tIsr: 2\n\n# 发送消息\nroot@kafka1:/# kafka-console-producer --broker-list kafka1:9092,kafka2:9092,kafka3:9092 --topic=zhongmingmao\n>hello\n>zhongmingmao\n>\n```\n\n### 读取消息\n```\n# 进入kafka2\n$ docker exec -it kafka2 bash\n\n# 读取消息\nroot@kafka2:/# kafka-console-consumer --bootstrap-server kafka1:9092,kafka2:9092,kafka3:9092 --topic zhongmingmao --from-beginning\nhello\nzhongmingmao\n```\n\n### 管理后台\nhttp://localhost:9000/clusters/docker-kafka/topics/zhongmingmao\n\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/kafka-manager.png\" width=800/>\n\n\n### 关闭\n```\n$ docker-compose down\nStopping kafka2        ... done\nStopping kafka1        ... done\nStopping kafka3        ... done\nStopping zk1           ... done\nStopping kafka_manager ... done\nStopping zk3           ... done\nStopping zk2           ... done\nRemoving kafka2        ... done\nRemoving kafka1        ... done\nRemoving kafka3        ... done\nRemoving zk1           ... done\nRemoving kafka_manager ... done\nRemoving zk3           ... done\nRemoving zk2           ... done\nRemoving network kafka_default\n```\n\n<!-- indicate-the-source -->\n","tags":["Docker"],"categories":["Kafka"]},{"title":"Kafka -- 集群安装与配置（Ubuntu）","url":"%2F2018%2F10%2F07%2Fkafka-install-cluster-ubuntu%2F","content":"\n## 单节点\n\n### 安装Java\n\n#### 添加ppa\n```\n$ sudo add-apt-repository ppa:webupd8team/java\n$ sudo apt-get update\n```\n\n#### 安装oracle-java8-installer\n```\n$ sudo apt-get install oracle-java8-installer\n```\n\n<!-- more -->\n\n#### 设置系统默认JDK\n```\n$ sudo update-java-alternatives -s java-8-oracle\n```\n\n### 下载解压Kafka\n```\n$ mkdir ~/Downloads & cd ~/Downloads\n$ wget http://mirrors.hust.edu.cn/apache/kafka/2.0.0/kafka_2.11-2.0.0.tgz\n\n$ mkdir ~/kafka && cd ~/kafka\n$ kafka tar -xvzf ~/Downloads/kafka_2.11-2.0.0.tgz  --strip 1\n```\n\n### 允许Kafka删除主题\n```\n$ vim ~/kafka/config/server.properties\n\n# 添加\ndelete.topic.enable=true\n```\n\n### 定义systemd\n\n#### Zookeeper\n```\n$ sudo vim /etc/systemd/system/zookeeper.service\n```\n\n```\n[Unit]\nRequires=network.target remote-fs.target\nAfter=network.target remote-fs.target\n\n[Service]\nType=simple\nUser=zhongmingmao\nExecStart=/home/zhongmingmao/kafka/bin/zookeeper-server-start.sh /home/zhongmingmao/kafka/config/zookeeper.properties\nExecStop=/home/zhongmingmao/kafka/bin/zookeeper-server-stop.sh\nRestart=on-abnormal\n\n[Install]\nWantedBy=multi-user.target\n```\n\n#### Kafka\n```\n$ sudo vim /etc/systemd/system/kafka.service\n```\n\n```\n[Unit]\nRequires=zookeeper.service\nAfter=zookeeper.service\n\n[Service]\nType=simple\nUser=zhongmingmao\nExecStart=/bin/sh -c '/home/zhongmingmao/kafka/bin/kafka-server-start.sh /home/zhongmingmao/kafka/config/server.properties > /home/zhongmingmao/kafka/kafka.log 2>&1'\nExecStop=/home/zhongmingmao/kafka/bin/kafka-server-stop.sh\nRestart=on-abnormal\n\n[Install]\nWantedBy=multi-user.target\n```\n\n### 启动\n```\n$ sudo systemctl start kafka\n\n$ sudo systemctl status kafka\n● kafka.service\n   Loaded: loaded (/etc/systemd/system/kafka.service; disabled; vendor preset: enabled)\n   Active: active (running) since Mon 2018-10-08 01:52:40 UTC; 6s ago\n\n$ sudo systemctl status zookeeper\n● zookeeper.service\n  Loaded: loaded (/etc/systemd/system/zookeeper.service; disabled; vendor preset: enabled)\n  Active: active (running) since Mon 2018-10-08 01:52:40 UTC; 1min 33s ago\n```\n\n### 查看日志\n```\n$ journalctl -u kafka\n$ journalctl -u zookeeper\n```\n\n### 开机自启动\n```\n$ sudo systemctl enable kafka\nCreated symlink /etc/systemd/system/multi-user.target.wants/kafka.service → /etc/systemd/system/kafka.service.\n```\n\n### 添加环境变量\n```\n$ vim ~/.zshrc\n\n# 添加\nKAFKA_HOME=\"/home/zhongmingmao/kafka/\"\nexport PATH=$KAFKA_HOME/bin:$PATH\n\n$ source ~/.zshrc\n```\n\n### 测试功能\n\n#### 创建主题\n```\n$ kafka-topics.sh --zookeeper localhost:2181 --create --replication-factor 1 --partitions 1 --topic zhongmingmao\nCreated topic \"zhongmingmao\".\n\n$ kafka-topics.sh --zookeeper localhost:2181 --list\nzhongmingmao\n```\n\n#### 发送消息\n```\n$ echo \"hello, zhongmingmao\" | kafka-console-producer.sh --broker-list localhost:9092 --topic zhongmingmao > /dev/null\n```\n\n#### 读取消息\n```\n$ kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic zhongmingmao --from-beginning\nhello, zhongmingmao\n```\n\n### KafkaT\n\n#### 安装\n```\n$ sudo apt install ruby ruby-dev build-essential\n$ sudo gem install kafkat\n```\n\n#### 配置\n```\n$ vim ~/.kafkatcfg\n```\n\n```\n{\n  \"kafka_path\": \"~/kafka\",\n  \"log_path\": \"/tmp/kafka-logs\",\n  \"zk_path\": \"localhost:2181\"\n}\n```\n\n```\n$ kafkat partitions\nTopic\t\tPartition\tLeader\t\tReplicas\t\t\t\t\t\tISRs\nzhongmingmao\t0\t\t0\t\t[0]\t\t\t\t\t\t\t[0]\n__consumer_offsets\t0\t\t0\t\t[0]\t\t\t\t\t\t\t[0]\n```\n\n## 集群\n\n### 机器IP\n- 172.16.143.133\n- 172.16.143.134\n- 172.16.143.135\n\n### 创建数据目录\n```\n$ mkdir -p ~/data/zookeeper && mkdir -p ~/data/kafka\n```\n\n### 配置Zookeeper\n\n#### zookeeper.properties\n```\n$ vim ~/kafka/config/zookeeper.properties\n\n```\n\n```\ndataDir=/home/zhongmingmao/data/zookeeper\nclientPort=2181\n\nmaxClientCnxns=100\ntickTime=2000\ninitLimit=10\nsyncLimit=5\n\nserver.1=172.16.143.133:2888:3888\nserver.2=172.16.143.134:2888:3888\nserver.3=172.16.143.135:2888:3888\n```\n\n#### 新增myid\n```\n$ echo 1 > ~/data/zookeeper/myid # 不同机器，数值为1、2、3\n```\n\n### 配置Kafka\n```\n$ vim ~/kafka/config/server.properties\n\n# 修改下面配置\nbroker.id=0 # 不同机器，数值为0、1、2\nlisteners=PLAINTEXT://172.16.143.133:9092 # 机器IP\nzookeeper.connect=172.16.143.133:2181,172.16.143.134:2181,172.16.143.135:2181 # Zookeeper集群\nlog.dirs=/home/zhongmingmao/data/kafka\n```\n\n### 启动Kafka\n```\n$ sudo systemctl start kafka\n\n$ jps\n4997 Jps\n4331 Kafka\n4317 QuorumPeerMain\n```\n\n### 测试功能\n\n#### 创建主题\n```\n# Mac OS\n$ kafka-topics --zookeeper 172.16.143.133:2181,172.16.143.134:2181,172.16.143.135:2181 --create --replication-factor 1 --partitions 1 --topic zhongmingmao\nCreated topic \"zhongmingmao\".\n\n$ kafka-topics --zookeeper 172.16.143.133:2181,172.16.143.134:2181,172.16.143.135:2181 --list\nzhongmingmao\n\n# --zookeeper 可以只列一个\n```\n\n#### 发送消息\n```\n# Mac OS\n$ echo \"hello, zhongmingmao\" | kafka-console-producer --broker-list 172.16.143.133:9092,172.16.143.134:9092,172.16.143.135:9092, --topic zhongmingmao > /dev/null\n```\n\n#### 读取消息\n```\n# Mac OS\n$ kafka-console-consumer --bootstrap-server 172.16.143.133:9092,172.16.143.134:9092,172.16.143.135:9092 --topic zhongmingmao --from-beginning\nhello, zhongmingmao\n```\n\n#### 修改KafkaT\n```\n$ vim ~/.kafkatcfg\n```\n\n```\n{\n  \"kafka_path\": \"/home/zhongmingmao/kafka\",\n  \"log_path\": \"/home/zhongmingmao/data/kafka\",\n  \"zk_path\": \"172.16.143.133:2181,172.16.143.134:2181,172.16.143.135:2181\"\n}\n```\n\n```\n$ kafkat partitions\nTopic\t\tPartition\tLeader\t\tReplicas\t\t\t\t\t\tISRs\nzhongmingmao\t0\t\t2\t\t[2]\t\t\t\t\t\t\t[2]\n__consumer_offsets\t0\t\t1\t\t[1]\t\t\t\t\t\t\t[1]\n```\n\n<!-- indicate-the-source -->\n","tags":["Stream"],"categories":["Kafka"]},{"title":"Kafka -- 单节点安装与配置（Mac）","url":"%2F2018%2F10%2F06%2Fkafka-install-single-mac%2F","content":"\n## 安装步骤\n\n### Kafka与Zookeeper\nKafka使用`Zookeeper`保存集群的**元数据信息**和**消费者信息**\n\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/kafka_zookeeper.png\" width=\"600\">\n\n<!-- more -->\n\n### 安装Zookeeper和Kafka\n```\n$ brew install kafka\n==> Installing dependencies for kafka: zookeeper\n==> Caveats\n==> zookeeper\nTo have launchd start zookeeper now and restart at login:\n  brew services start zookeeper\nOr, if you don't want/need a background service you can just run:\n  zkServer start\n==> kafka\nTo have launchd start kafka now and restart at login:\n  brew services start kafka\nOr, if you don't want/need a background service you can just run:\n  zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties & kafka-server-start /usr/local/etc/kafka/server.properties\n```\n\n### 启动Zookeeper和Kafka\n\n#### 当前服务列表\n```\n$ brew services list\nName      Status  User         Plist\nkafka     stopped\nmysql     started zhongmingmao /Users/zhongmingmao/Library/LaunchAgents/homebrew.mxcl.mysql.plist\nzookeeper stopped\n```\n\n#### 启动Zookeeper\n```\n$ brew services start zookeeper\n==> Successfully started `zookeeper` (label: homebrew.mxcl.zookeeper)\n```\n#### 启动Kakfa\n```\n$ brew services start kafka\n==> Successfully started `kafka` (label: homebrew.mxcl.kafka)\n```\n\n#### 当前服务列表\n```\n$ brew services list\nName      Status  User         Plist\nkafka     started zhongmingmao /Users/zhongmingmao/Library/LaunchAgents/homebrew.mxcl.kafka.plist\nmysql     started zhongmingmao /Users/zhongmingmao/Library/LaunchAgents/homebrew.mxcl.mysql.plist\nzookeeper started zhongmingmao /Users/zhongmingmao/Library/LaunchAgents/homebrew.mxcl.zookeeper.plist\n```\n\n### 基本测试\n\n#### 创建主题\n```\n$ kafka-topics --zookeeper localhost:2181 --create --replication-factor 1 --partitions 1 --topic zhongmingmao\nCreated topic \"zhongmingmao\".\n\n$ kafka-topics --zookeeper localhost:2181 --list\n__consumer_offsets\nzhongmingmao\n\n$ kafka-topics --zookeeper localhost:2181 --describe --topic zhongmingmao\nTopic:zhongmingmao\tPartitionCount:1\tReplicationFactor:1\tConfigs:\n\tTopic: zhongmingmao\tPartition: 0\tLeader: 0\tReplicas: 0\tIsr: 0\n```\n\n#### 发布消息\n```\n$ kafka-console-producer --broker-list localhost:9092 --topic zhongmingmao\n>zhongmingmao\n>is\n>learning kafka\n>\n```\n\n#### 读取消息\n```\n$ kafka-console-consumer --bootstrap-server localhost:9092 --topic zhongmingmao --from-beginning\nzhongmingmao\nis\nlearning kafka\n```\n\n## Broker配置\n\n### 常规配置\n\n#### broker.id\n1. 每个Broker都需要一个标识符，使用`broker.id`来表示，默认为0，也可以被设置成任意整数\n2. 这个值在**整个Kafka集群**里必须是**唯一**的\n3. 建议把它们设置成**与机器名具有相关性**的整数\n\n#### zookeeper.connect\n1. 指定用来保存**Broker元数据的**Zookeeper地址\n2. 例如 hostname1:port1/path,hostname2:port2/path,hostname3:port3/path\n    - **/path** 是可选的Zookeeper路径，作为Kafka集群的**chroot**环境\n    - 如果不指定，默认使用**根路径**\n    - 如果指定的chroot不存在，Broker会在启动的时候创建它\n    - 在Kafka集群里**使用chroot路径**是一种**最佳实践**\n\n#### log.dirs\n1. Kafka把**所有的消息**都保存在**磁盘**上，存放这些**日志片段**的目录是通过`log.dirs`指定的\n2. 一组**逗号**分隔的**本地文件系统路径**\n3. 如果指定了**多个路径**，那么Broker会依据**最少使用**原则，_**把同一个分区的日志片段保存在同一个路径下**_\n    - Broker会往拥有**最少分区数目**的路径新增分区\n    - 而不是往拥有**最少磁盘空间**的路径新增分区\n\n#### num.recovery.threads.per.data.dir\n> Specify the maximum number of threads that are used for log recovery for each data directory.\n\n##### 处理时机\n1. 服务器**正常启动**，用于打开每个分区的日志片段\n2. 服务器**崩溃后重启**，用于检查和截断每个分区的日志片段\n3. 服务器**正常关闭**，用于关闭日志片段\n\n##### 多线程和单目录\n1. 默认情况下，每个日志目录只使用一个线程\n    - 这些线程只在服务器**启动**或者**关闭**时会用到，所以完全可以设置**大量的线程**来达到**并行操作**的目的\n2. 所配置的数字对应的是`log.dirs`指定的**单个日志目录**\n    - 如果`num.recovery.threads.per.data.dir=8`，`log.dirs=3`，那么总共需要24个线程\n\n#### auto.create.topics.enable\n\n##### 自动创建时机\n1. 当一个**生产者**开始往主题**写入消息**时\n2. 当一个**消费者**开始从主题**读取消息**时\n3. 当任意一个客户端向主题发送**元数据请求**时\n\n### 主题配置\n\n#### num.partitions\n1. 指定新创建的主题包含多少个分区\n2. 如果启用了主题的**自动创建**功能（默认启用）\n    - _**可以增加主题分区的个数，但不能减少分区的个数**_\n    - 如果要让一个主题分区的个数少于`num.partitions`指定的值，需要**手动**创建该主题\n\n##### 选定分区数量\n1. **主题** 需要达到多大的吞吐量？100KB/S还是1GB/S?\n2. 从**单个分区**读取数据的**最大吞吐量**是多少？\n    - **每个分区**一般都会有**一个消费者**\n    - 如果消费者将数据写入数据库的速度不会超过50MB/S\n        - 那么一个分区读取数据的吞吐量不需要超过50MB/S\n3. 通过类似的方法估算生产者向单个分区写入数据的吞吐量\n    - 不过**生产者的速度一般比消费者快得多**，最好为生产者多估算一些吞吐量\n4. 每个Broker包含的**分区个数**、**可用的磁盘空间**和**网络带宽**\n5. 如果消息是按照不同的键写入分区的，那么为已有的主题新增分区就会很困难\n6. _**单个Broker对分区个数是有限制的**_\n    - 因为**分区越多**，**占用的内存越多**，完成**首领选举**需要的时间也越长\n    - 如果已经估算出**主题的吞吐量**和**消费者的吞吐量**，用**主题吞吐量**除以**消费者吞吐量**算出分区的个数\n    - 如果不知道这些信息，把**单个分区的大小**限制在**25GB**以内可以得到比较理想的效果\n\n#### log.retention.{hours,minutes,ms}\n1. 决定消息多久以后会被删除，_**默认一周**_，推荐使用`log.retention.ms`\n2. 如果指定了不止一个参数，会优先使用具有**最小值**的那个参数\n3. 根据时间保留数据是通过检查磁盘上**日志片段文件**的**最后修改时间**来实现的\n    - 一般来说，最后修改时间指的是**日志片段的关闭时间**，也就是_**日志片段文件里最后一个消息的时间戳**_\n\n#### log.retention.bytes\n1. 通过保留的字节数来判断消息是否过期，作用在**每一个分区**上，**默认1GB**\n2. 若同时指定了`log.retention.ms`和`log.retention.bytes`，只要**满足任意一个条件**，消息就会被删除\n\n#### log.segment.bytes\n1. 当消息到达Broker时，它们被追加到**分区的当前日志片段**上\n2. 当**日志片段大小**达到了`log.segment.bytes`指定的上限（**默认1GB**）\n    - _**当前日志片段就会被关闭（记录最后修改时间），一个新的日志片段就会被打开**_\n    - _**如果一个日志片段被关闭，就开始等待过期**_\n    - _**这个参数越小，就会越频繁地关闭和分配新文件，从而降低磁盘写入的整体效率**_\n3. 如果主题的消息量不大，如何调整这个参数的大小变得尤为重要\n    - 如果一个主题每天只接收100MB的消息，而`log.segment.bytes`采用默认值（1GB）\n        - 那么需要10天的时间才能填满一个日志片段\n    - _**日志片段在被关闭之前，消息是不会过期的**_\n    - `log.retention.ms`采用默认值（7天），那么日志片段需要17天才会过期\n        - **需要等到日志片段里的最后一个消息过期才能被删除**\n4. **日志片段的大小** 会影响**使用时间戳获取偏移量**\n    - 在使用**时间戳**获取**日志偏移量**时\n        - Kafka会检查分区里**最后修改时间**大于指定时间戳的日志片段，返回该日志片段**开头**的偏移量\n        - 例如某个分区有3个日志片段：S1:T1，S2:T2，S3:T3，T1.5会返回S2开头的偏移量\n    - 对于使用**时间戳**获取**偏移量**的操作来说，_**日志片段越小，结果越准确**_\n\n#### segment.ms\n1. 指定多长时间之后日志片段会被关闭\n2. `log.segment.bytes`和`segment.ms`不存在互斥关系，看哪个条件先得到满足\n3. 默认情况下，`segment.ms`没有设定值，所以一般依据`log.segment.bytes`来关闭日志片段\n4. 在使用**基于时间的日志片段**时，要着重考虑**并行关闭多个日志片段对磁盘性能的影响**\n\n#### message.max.bytes\n1. 限制**单个消息的大小**，**默认1MB**\n2. 该参数指的是_**压缩后的消息大小**_\n3. 值越大，那么**负责网络连接和请求的线程**就需要花越多的时间来处理这些请求\n    - 而且还会**增加磁盘写入块的大小**，从而**影响IO吞吐量**\n4. 如果**消费者客户端**设置的`fetch.message.max.bytes`比`message.max.bytes`小\n    - 那么**消费者就无法读取比较大的消息**，导致出现**消费者被阻塞**的情况\n\n## 硬件选择\n\n### 磁盘吞吐量\n1. 生产者客户端的性能直接受到**服务器端磁盘吞吐量**的影响\n2. _**生产者生成的消息必须被提交到服务器保存**_\n\n### 磁盘容量\n1. 需要多大的**磁盘容量**取决于**需要保留的消息数量**\n2. 在决定扩展Kafka集群规模时，存储容量是一个需要考虑的因素\n  - 通过让**主题拥有多个分区**，**集群的总流量可以被均衡到整个集群**\n  - 如果**单个Broker无法支持全部容量**，可以让**其它Broker提供可用的容量**\n  - 存储容量的选择同时受到**集群复制策略**的影响\n\n### 内存\n1. _**磁盘性能影响生产者，内存影响消费者**_\n2. 消费者读取的消息会直接存放在**系统的页面缓存**里，这比从磁盘上重新读取要快得多\n3. 运行Kafka的JVM不需要太大的内存\n    - 剩余的系统内存可以用作**页面缓存**，或者用来缓存正在使用中的日志片段\n    - 不建议把Kafka与其它重要的应用程序部署在一起，因为需要**共享页面缓存**\n        - 最终会导致**降低Kafka消费者的性能**\n\n### 网络\n1. **网络吞吐量**决定了Kafka能处理的**最大数据流量**，它和**磁盘存储**是制约Kafka扩展规模的主要因素\n2. Kafka支持**多个消费者**，造成**流入和流出的网络流量不平衡**\n3. **集群复制** 和**镜像**也会占用网络流量\n    - 如果网络接口出现饱和，那么**集群的复制出现延时**就会在所难免，从而让集群不堪一击\n\n### CPU\n1. 与磁盘和内存相比，_**Kafka对计算处理能力的要求相对较低**_\n2. 计算处理\n    - 客户端为了优化**网络**和**磁盘空间**，会对消息进行**压缩**\n    - 服务器需要对消息进行**批量解压**，**设置偏移量**，然后重新进行**批量压缩**，再保存在磁盘上\n\n<!-- indicate-the-source -->\n","tags":["Stream"],"categories":["Kafka"]},{"title":"Kafka -- 简介","url":"%2F2018%2F10%2F05%2Fkafka-introduction%2F","content":"\n## 相关概念\n1. Kafka一般被称为**分布式提交日志**或者**分布式流平台**\n2. 文件系统或数据库提交日志用来提供所有事务的持久记录，通过重放这些日志可以重建系统的状态\n  - Kafka的数据是按照一定顺序持久化保存的，可以**按需读取**\n3. Kafka的数据分布在整个系统里，具备**数据故障保护**和**性能伸缩**的能力\n\n<!-- more -->\n\n### 消息和批次\n1. Kafka的**数据单元**被称为**消息**\n2. 消息由**字节数组**组成，消息里的数据没有特别的格式或者含义\n3. 消息可以有一个可选的**元数据**，就是键，键也是一个**字节数组**，同样没有特殊含义\n  - 消息以**一种可控的方式写入不同的分区**时，会用到键\n  - 例如为键生成一个**一致性散列值**，然后使用散列值对主题分区数进行**取模**\n    - 为消息选取分区，从而保证**具有相同键的消息**总是被写入到**相同的分区**\n4. 为了提高效率，消息被**分批**写入Kafka，**批次就是一组消息**，这些消息**属于同一个主题和分区**\n  - 如果每个消息都单独穿行于网络，会导致大量的网络开销，把消息分成批次传输可以**减少网络开销**\n  - 不过，这需要在**时间延迟**和**吞吐量**之间做出权衡\n    - 批次越大，单位时间内处理的消息就会越多，耽搁消息的传输时间就会越长\n  - 批次数据会被**压缩**，这样可以**提升数据的传输和存储能力**，但要做**更多的计算处理**\n\n### 模式\n1. 对于Kafka来说，消息不过是晦涩难懂的**字节数组**\n2. 依据应用程序的需求，**消息模式** 有许多可用的选项\n3. 像JSON和XML这些简单的系统，不仅易用，而且可读性好\n    - 但是**缺乏强类型的处理能力**，不同版本之间的**兼容性也不好**\n4. Kafka的许多开发者喜欢使用**Apache Avro**，它最初是为了Hadoop开发的一款序列化框架\n  - Avro提供一种**紧凑的序列化格式**，**模式和消息体是分开的，当模式发生变化时，不需要重新生成代码**\n  - Avro还支持**强类型**和**模式进化**，其版本既向前兼容，也向后兼容\n5. **数据格式的一致性**对于Kafka来说很重要，它**消除了消息读写操作之间的耦合性**\n  - 如果读写操作紧密地耦合在一起，消息订阅者需要升级应用程序才能同时处理新旧两种数据格式\n  - 在消息订阅者升级之后，消息发布者才能跟着升级，以便使用新的数据格式\n  - 新的应用程序如果需要使用数据，就要和消息发布者发生耦合，导致开发者需要做很多繁杂的工作\n6. 定义良好的格式，并把它们存放在**公共仓库**，可以方便我们理解**Kafka的消息结构**\n\n### 主题和分区\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/topic.png\" width=\"600\">\n1. Kafka的消息通过**主题**进行分类，主题类似于数据库的表，或者文件系统里的文件夹\n2. **主题可以被分为若干个分区**，_**一个分区就是一个提交日志**_\n3. 消息以**追加**的方式写入分区，然后以**FIFO**的顺序读取\n4. 由于一个主题一般包含几个分区\n    - 因此**无法在整个主题范围内保证消息的顺序**，但_**可以保证消息在单个分区内的顺序**_\n5. Kafka通过分区来实现**数据冗余**和**伸缩性**\n  - _**分区可以分布在不同的服务器上，因此一个主题可以横跨多个服务器**_\n6. 很多时候，会把一个**主题的数据**看成一个**流**，不管它有多少个分区\n  - _**流是一组从生产者移动到消费者的数据**_\n\n### 生产者和消费者\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/consumer.png\" width=\"600\">\n1. 生产者**创建消息**\n  - 一般情况下，一个消息会被发布到特定的主题上\n  - 默认情况下，**生产者把消息均匀地分布到主题的所有分区上**，而并不关心特定消息会被写到哪个分区\n  - 在特定情况下，生产者会把消息直接写到指定的分区，这通常通过**消息键**和**分区器**来实现的\n    - 分区器为键生成一个散列值，并将其映射（例如取模）到指定的分区上\n    - 这样可以保证包含同一个键的消息会被写到同一个分区上\n2. 消费者**读取消息**\n  - 消费者订阅**一个或多个**主题，并按照**消息生成的顺序**读取它们\n  - 消费者通过检查消息的**偏移量**来区分已经读取过的消息\n    - 偏移量是另一种**元数据**，它是一个**不断递增**的整数值\n        - **在创建消息时，Kafka会把偏移量添加到消息里**\n    - _**在给定的分区里，每个消息的偏移量都是唯一的**_\n    - 消费者把**每个分区最后读取的消息偏移量**保存在Zookeeper或Kafka上\n        - 如果消费者关闭或重启，它的读取状态**不会丢失**\n  - 消费者是**消费者群组**的一部分，会有一个或者多个消费者共同读取一个主题\n    - _**群组保证每个分区只能被一个消费者使用**_\n    - 消费者与分区之间的映射通常被称为_**消费者对分区的所有权关系**_\n    - 如果一个消费者失效，群组里的其它消费者可以**接管**失效消费者的工作\n\n### Broker和集群\n1. 一个**独立的Kafka服务器**被称为**Broker**\n2. Broker接收来自生产者的消息，**为消息设置偏移量，并提交消息到磁盘保存**\n3. Broker为消费者提供服务，对**读取分区的请求**作出响应，返回已经提交到磁盘上的消息\n4. Broker是集群的组成部分，每个集群都有一个Broker同时充当**集群控制器**的角色（**自动选举**）\n  - 控制器负责管理工作：**将分区分配给Broker** + **监控Broker**\n5. 在集群中，**一个分区从属于一个Broker**，该Broker被称为_**分区的首领**_\n  - **一个分区可以分配给多个Broker，这个时候就会发生分区复制**\n  - 这种复制机制为分区提供了**消息冗余**\n6. 如果有一个Broker失效，其它Broker可以**接管领导权**，相关的消费者和生产者都需要**重新连接**到新的首领\n\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/partition_replication.png\" width=\"800\">\n\n#### 保留消息\n1. 保留消息是Kafka的一个重要特性\n2. 默认的消息保留策略\n  - 要么保留**一段时间**，要么保留到消息达到**一定大小的字节数**\n  - 当消息数量达到这些上限时，旧消息就会过期并被删除\n3. **主题** 可以配置自己的保留策略，可以将消息保留到不再使用它们为止\n\n### 多集群\n1. 使用多集群的原因\n  - 数据类型分离\n  - 安全需求隔离\n  - 多数据中心（灾难恢复）\n2. _**Kafka的消息复制机制只能在单个集群里进行**_，不能在多个集群之间进行\n  - Kafka提供了一个叫作**MirrorMaker**的工具，可以用它来**实现集群间的消息复制**\n  - MirrorMaker的核心组件包含一个**生产者**和一个**消费者**，两者之间**通过一个队列相连**\n  - **消费者从一个集群读取消息，生产者把消息发送到另一个集群上**\n\n<img src=\"https://kafka-1253868755.cos.ap-guangzhou.myqcloud.com/definitive-guide/multi_data_center.png\" width=\"600\">\n\n## 选择Kafka的原因\n1. **多个生产者**\n  - Kafka可以**无缝**地支持多个生产者，不管客户端在使用单个主题还是多个主题\n  - 非常适合用来从多个前端系统收集数据，并以**统一的格式**对外提供数据\n2. **多个消费者**。\n  - Kafka也支持**多个消费者**从**单独的消息流**上读取数据，而且**消费者之间互不影响**\n  - **其它队列系统的消息一旦被一个客户端读取，其它客户端就无法再读取它**（例如RabbitMQ）\n  - 多个消费者可以组成一个**群组**，它们**共享一个消息流**，并保证_**整个群组对每个给定的消息只处理一次**_\n3. 基于**磁盘**的数据存储\n  - Kafka支持消费者**非实时**地读取消息，这归功于Kafka的数据保留策略\n  - 消息被提交到磁盘，依据设置的保留策略进行保存，每个**主题**可以设置单独的保留策略\n  - 消费者可能会因为处理速度慢或突发的流量高峰导致无法及时读取消息\n    - 而**持久化数据**可以保证**数据不会丢失**\n  - 消费者可以被关闭，但消息会继续保留在Kafka里，消费者可以从上次中断的地方继续处理消息\n4. 伸缩性\n  - 为了能够轻松处理大量数据，Kafka从一开始就被设计成一个具有**灵活伸缩性**的系统\n5. 高性能\n  - 通过**横向扩展**生产者、消费者和Broker，Kafka可以轻松处理巨大的信息流\n  - 在处理大量数据的同时，它还能保证**亚秒级**的消息延迟\n\n<!-- indicate-the-source -->\n","tags":["Stream"],"categories":["Kafka"]},{"title":"Zookeeper -- 分布式锁InterProcessMutex","url":"%2F2017%2F07%2F13%2Fzk-interprocessmutex%2F","content":"\n{% note info %}\n`Curator`是`ZooKeeper`的一个客户端框架，其中封装了`分布式互斥锁`的实现，最为常用的是`InterProcessMutex`，本文将对其进行代码剖析\n{% endnote %}\n\n<!-- more -->\n\n# 简介\n`InterProcessMutex`基于`Zookeeper`实现了_**`分布式的公平可重入互斥锁`**_，类似于单个JVM进程内的`ReentrantLock(fair=true)`\n\n# 构造函数\n```java\n// 最常用\npublic InterProcessMutex(CuratorFramework client, String path){\n    // Zookeeper利用path创建临时顺序节点，实现公平锁的核心\n    this(client, path, new StandardLockInternalsDriver());\n}\n\npublic InterProcessMutex(CuratorFramework client, String path, LockInternalsDriver driver){\n    // maxLeases=1，表示可以获得分布式锁的线程数量（跨JVM）为1，即为互斥锁\n    this(client, path, LOCK_NAME, 1, driver);\n}\n\n// protected构造函数\nInterProcessMutex(CuratorFramework client, String path, String lockName, int maxLeases, LockInternalsDriver driver){\n    basePath = PathUtils.validatePath(path);\n    // internals的类型为LockInternals，InterProcessMutex将分布式锁的申请和释放操作委托给internals执行\n    internals = new LockInternals(client, driver, path, lockName, maxLeases);\n}\n```\n\n# 获取锁\n\n## InterProcessMutex.acquire\n```java\n// 无限等待\npublic void acquire() throws Exception{\n    if ( !internalLock(-1, null) ){\n        throw new IOException(\"Lost connection while trying to acquire lock: \" + basePath);\n    }\n}\n\n// 限时等待\npublic boolean acquire(long time, TimeUnit unit) throws Exception{\n    return internalLock(time, unit);\n}\n```\n\n## InterProcessMutex.internalLock\n```java\nprivate boolean internalLock(long time, TimeUnit unit) throws Exception{\n    Thread currentThread = Thread.currentThread();\n    LockData lockData = threadData.get(currentThread);\n    if ( lockData != null ){\n        // 实现可重入\n        // 同一线程再次acquire，首先判断当前的映射表内（threadData）是否有该线程的锁信息，如果有则原子+1，然后返回\n        lockData.lockCount.incrementAndGet();\n        return true;\n    }\n\n    // 映射表内没有对应的锁信息，尝试通过LockInternals获取锁\n    String lockPath = internals.attemptLock(time, unit, getLockNodeBytes());\n    if ( lockPath != null ){\n        // 成功获取锁，记录信息到映射表\n        LockData newLockData = new LockData(currentThread, lockPath);\n        threadData.put(currentThread, newLockData);\n        return true;\n    }\n    return false;\n}\n```\n```java\n// 映射表\n// 记录线程与锁信息的映射关系\nprivate final ConcurrentMap<Thread, LockData> threadData = Maps.newConcurrentMap();\n```\n```java\n// 锁信息\n// Zookeeper中一个临时顺序节点对应一个“锁”，但让锁生效激活需要排队（公平锁），下面会继续分析\nprivate static class LockData{\n    final Thread owningThread;\n    final String lockPath;\n    final AtomicInteger lockCount = new AtomicInteger(1); // 分布式锁重入次数\n\n    private LockData(Thread owningThread, String lockPath){\n        this.owningThread = owningThread;\n        this.lockPath = lockPath;\n    }\n}\n```\n\n## LockInternals.attemptLock\n```java\n// 尝试获取锁，并返回锁对应的Zookeeper临时顺序节点的路径\nString attemptLock(long time, TimeUnit unit, byte[] lockNodeBytes) throws Exception{\n    final long startMillis = System.currentTimeMillis();\n    // 无限等待时，millisToWait为null\n    final Long millisToWait = (unit != null) ? unit.toMillis(time) : null;\n    // 创建ZNode节点时的数据内容，无关紧要，这里为null，采用默认值（IP地址）\n    final byte[] localLockNodeBytes = (revocable.get() != null) ? new byte[0] : lockNodeBytes;\n    // 当前已经重试次数，与CuratorFramework的重试策略有关\n    int retryCount = 0;\n\n    // 在Zookeeper中创建的临时顺序节点的路径，相当于一把待激活的分布式锁\n    // 激活条件：同级目录子节点，名称排序最小（排队，公平锁），后续继续分析\n    String ourPath = null;\n    // 是否已经持有分布式锁\n    boolean hasTheLock = false;\n    // 是否已经完成尝试获取分布式锁的操作\n    boolean isDone = false;\n\n    while ( !isDone ){\n        isDone = true;\n        try{\n            // 从InterProcessMutex的构造函数可知实际driver为StandardLockInternalsDriver的实例\n            // 在Zookeeper中创建临时顺序节点\n            ourPath = driver.createsTheLock(client, path, localLockNodeBytes);\n            // 循环等待来激活分布式锁，实现锁的公平性，后续继续分析\n            hasTheLock = internalLockLoop(startMillis, millisToWait, ourPath);\n        } catch ( KeeperException.NoNodeException e ) {\n            // 容错处理，不影响主逻辑的理解，可跳过\n            // 因为会话过期等原因，StandardLockInternalsDriver因为无法找到创建的临时顺序节点而抛出NoNodeException异常\n            if ( client.getZookeeperClient().getRetryPolicy().allowRetry(retryCount++,\n                    System.currentTimeMillis() - startMillis, RetryLoop.getDefaultRetrySleeper()) ){\n                // 满足重试策略尝试重新获取锁\n                isDone = false;\n            } else {\n                // 不满足重试策略则继续抛出NoNodeException\n                throw e;\n            }\n        }\n    }\n    if ( hasTheLock ){\n        // 成功获得分布式锁，返回临时顺序节点的路径，上层将其封装成锁信息记录在映射表，方便锁重入\n        return ourPath;\n    }\n    // 获取分布式锁失败，返回null\n    return null;\n}\n```\n```java\n// From StandardLockInternalsDriver\n// 在Zookeeper中创建临时顺序节点\npublic String createsTheLock(CuratorFramework client, String path, byte[] lockNodeBytes) throws Exception{\n    String ourPath;\n    // lockNodeBytes不为null则作为数据节点内容，否则采用默认内容（IP地址）\n    if ( lockNodeBytes != null ){\n        // 下面对CuratorFramework的一些细节做解释，不影响对分布式锁主逻辑的解释，可跳过\n        // creatingParentContainersIfNeeded：用于创建父节点，如果不支持CreateMode.CONTAINER\n        // 那么将采用CreateMode.PERSISTENT\n        // withProtection：临时子节点会添加GUID前缀\n        ourPath = client.create().creatingParentContainersIfNeeded()\n            // CreateMode.EPHEMERAL_SEQUENTIAL：临时顺序节点，Zookeeper能保证在节点产生的顺序性\n            // 依据顺序来激活分布式锁，从而也实现了分布式锁的公平性，后续继续分析\n            .withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).forPath(path, lockNodeBytes);\n    } else {\n        ourPath = client.create().creatingParentContainersIfNeeded()\n            .withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).forPath(path);\n    }\n    return ourPath;\n}\n```\n\n## LockInternals.internalLockLoop\n```java\n// 循环等待来激活分布式锁，实现锁的公平性\nprivate boolean internalLockLoop(long startMillis, Long millisToWait, String ourPath) throws Exception {\n    // 是否已经持有分布式锁\n    boolean haveTheLock = false;\n    // 是否需要删除子节点\n    boolean doDelete = false;\n    try {\n        if (revocable.get() != null) {\n            client.getData().usingWatcher(revocableWatcher).forPath(ourPath);\n        }\n\n        while ((client.getState() == CuratorFrameworkState.STARTED) && !haveTheLock) {\n            // 获取排序后的子节点列表\n            List<String> children = getSortedChildren();\n            // 获取前面自己创建的临时顺序子节点的名称\n            String sequenceNodeName = ourPath.substring(basePath.length() + 1);\n            // 实现锁的公平性的核心逻辑，看下面的分析\n            PredicateResults predicateResults = driver.getsTheLock(client,\n                                                        children , sequenceNodeName , maxLeases);\n            if (predicateResults.getsTheLock()) {\n                // 获得了锁，中断循环，继续返回上层\n                haveTheLock = true;\n            } else {\n                // 没有获得到锁，监听上一临时顺序节点\n                String previousSequencePath = basePath + \"/\" + predicateResults.getPathToWatch();\n                synchronized (this) {\n                    try {\n                        // exists()会导致导致资源泄漏，因此exists()可以监听不存在的ZNode，因此采用getData()\n                        // 上一临时顺序节点如果被删除，会唤醒当前线程继续竞争锁，正常情况下能直接获得锁，因为锁是公平的\n                        client.getData().usingWatcher(watcher).forPath(previousSequencePath);\n                        if (millisToWait != null) {\n                            millisToWait -= (System.currentTimeMillis() - startMillis);\n                            startMillis = System.currentTimeMillis();\n                            if (millisToWait <= 0) {\n                                doDelete = true; // 获取锁超时，标记删除之前创建的临时顺序节点\n                                break;\n                            }\n                            wait(millisToWait); // 等待被唤醒，限时等待\n                        } else {\n                            wait(); // 等待被唤醒，无限等待\n                        }\n                    } catch (KeeperException.NoNodeException e) {\n                    // 容错处理，逻辑稍微有点绕，可跳过，不影响主逻辑的理解\n                    // client.getData()可能调用时抛出NoNodeException，原因可能是锁被释放或会话过期（连接丢失）等\n                    // 这里并没有做任何处理，因为外层是while循环，再次执行driver.getsTheLock时会调用validateOurIndex\n                    // 此时会抛出NoNodeException，从而进入下面的catch和finally逻辑，重新抛出上层尝试重试获取锁并删除临时顺序节点\n                    }\n                }\n            }\n        }\n    } catch (Exception e) {\n        ThreadUtils.checkInterrupted(e);\n        // 标记删除，在finally删除之前创建的临时顺序节点（后台不断尝试）\n        doDelete = true;\n        // 重新抛出，尝试重新获取锁\n        throw e;\n    } finally {\n        if (doDelete) {\n            deleteOurPath(ourPath);\n        }\n    }\n    return haveTheLock;\n}\n```\n```java\n// From StandardLockInternalsDriver\npublic PredicateResults getsTheLock(CuratorFramework client, List<String> children, String sequenceNodeName, int maxLeases) throws Exception{\n    // 之前创建的临时顺序节点在排序后的子节点列表中的索引\n    int ourIndex = children.indexOf(sequenceNodeName);\n    // 校验之前创建的临时顺序节点是否有效\n    validateOurIndex(sequenceNodeName, ourIndex);\n    // 锁公平性的核心逻辑\n    // 由InterProcessMutex的构造函数可知，maxLeases为1，即只有ourIndex为0时，线程才能持有锁，或者说该线程创建的临时顺序节点激活了锁\n    // Zookeeper的临时顺序节点特性能保证跨多个JVM的线程并发创建节点时的顺序性，越早创建临时顺序节点成功的线程会更早地激活锁或获得锁\n    boolean getsTheLock = ourIndex < maxLeases;\n    // 如果已经获得了锁，则无需监听任何节点，否则需要监听上一顺序节点（ourIndex-1）\n    // 因为锁是公平的，因此无需监听除了（ourIndex-1）以外的所有节点，这是为了减少羊群效应，非常巧妙的设计！！\n    String pathToWatch = getsTheLock ? null : children.get(ourIndex - maxLeases);\n    // 返回获取锁的结果，交由上层继续处理（添加监听等操作）\n    return new PredicateResults(pathToWatch, getsTheLock);\n}\n\nstatic void validateOurIndex(String sequenceNodeName, int ourIndex) throws KeeperException{\n    if ( ourIndex < 0 ){\n        // 容错处理，可跳过\n        // 由于会话过期或连接丢失等原因，该线程创建的临时顺序节点被Zookeeper服务端删除，往外抛出NoNodeException\n        // 如果在重试策略允许范围内，则进行重新尝试获取锁，这会重新重新生成临时顺序节点\n        // 佩服Curator的作者将边界条件考虑得如此周到！\n        throw new KeeperException.NoNodeException(\"Sequential path not found: \" + sequenceNodeName);\n    }\n}\n```\n```java\n// From LockInternals\nprivate final Watcher watcher = new Watcher(){\n    @Override\n    public void process(WatchedEvent event){\n        notifyFromWatcher();\n    }\n};\nprivate synchronized void notifyFromWatcher(){\n   notifyAll(); // 唤醒所有等待LockInternals实例的线程\n}\n```\n```java\n// From LockInternals\nprivate void deleteOurPath(String ourPath) throws Exception{\n    try{\n        // 后台不断尝试删除\n        client.delete().guaranteed().forPath(ourPath);\n    } catch ( KeeperException.NoNodeException e ) {\n        // 已经删除(可能会话过期导致)，不做处理\n        // 实际使用Curator-2.12.0时，并不会抛出该异常\n    }\n}\n```\n\n# 释放锁\n弄明白了获取锁的原理，释放锁的逻辑就很清晰了\n\n## InterProcessMutex.release\n```java\npublic void release() throws Exception{\n    Thread currentThread = Thread.currentThread();\n    LockData lockData = threadData.get(currentThread);\n    if ( lockData == null ){\n        // 无法从映射表中获取锁信息，不持有锁\n        throw new IllegalMonitorStateException(\"You do not own the lock: \" + basePath);\n    }\n\n    int newLockCount = lockData.lockCount.decrementAndGet();\n    if ( newLockCount > 0 ){\n        // 锁是可重入的，初始值为1，原子-1到0，锁才释放\n        return;\n    }\n    if ( newLockCount < 0 ){\n        // 理论上无法执行该路径\n        throw new IllegalMonitorStateException(\"Lock count has gone negative for lock: \" + basePath);\n    }\n    try{\n        // lockData != null && newLockCount == 0，释放锁资源\n        internals.releaseLock(lockData.lockPath);\n    } finally {\n        // 最后从映射表中移除当前线程的锁信息\n        threadData.remove(currentThread);\n    }\n}\n```\n\n## LockInternals.releaseLock\n```java\nvoid releaseLock(String lockPath) throws Exception{\n   revocable.set(null);\n   // 删除临时顺序节点，只会触发后一顺序节点去获取锁，理论上不存在竞争，只排队，非抢占，公平锁，先到先得\n   deleteOurPath(lockPath);\n}\n```\n```java\n// Class:LockInternals\nprivate void deleteOurPath(String ourPath) throws Exception{\n    try{\n        // 后台不断尝试删除\n        client.delete().guaranteed().forPath(ourPath);\n    } catch ( KeeperException.NoNodeException e ) {\n        // 已经删除(可能会话过期导致)，不做处理\n        // 实际使用Curator-2.12.0时，并不会抛出该异常\n    }\n}\n```\n\n# 总结\n\n`InterProcessMutex`的特性\n\n1. 分布式锁（基于`Zookeeper`）\n2. 互斥锁\n3. 公平锁（`监听上一临时顺序节点` + `wait() / notifyAll()`）\n4. 可重入\n\n<!-- indicate-the-source -->\n","tags":["Distributed Lock"],"categories":["Zookeeper"]},{"title":"Zookeeper -- ZAB协议","url":"%2F2017%2F07%2F08%2Fzk-zab%2F","content":"\n{% note info %}\n本文将简要介绍`Zookeeper`的`ZAB`协议\n{% endnote %}\n\n<!-- more -->\n\n# 基本概念\n\n## ZAB VS Base-Paxos\n- `Base-Paxos`是**`通用的分布式一致性算法`**\n- `ZAB协议`不是`Base-Paxos`的典型实现，而是特别为`Zookeeper`设计的一种**`支持崩溃恢复的原子广播协议`**\n- 相对于`ZAB协议`，`Base-Paxos`主要存在2个问题：**`活锁问题`**+**`全序问题`**\n    - `活锁问题`是指在`Base-Paxos`算法中，由于并不存在`Leader`角色，**`新轮次可以不断抢占旧轮次`**，如此循环往复，产生`活锁`\n    - `全序问题`是指如果消息a在消息b之前发送，则所有Server应该看到`相同的结果`，但`Base-Paxos`并不保证这一点\n- `ZAB`的解决方案\n    - 为了解决`活锁问题`，`ZAB协议`引入了`Leader`角色，所有的`事务请求`只能由`Leader`处理，但是`单Leader`会存在`单点问题`，`ZAB协议`进而引入`崩溃恢复模式`\n    - 为了解决`全序问题`，`ZAB协议`引入了`ZXID`（全局单调递增的唯一ID）和利用`TCP的FIFO特性`\n\n## 服务器角色\n`Zookeeper`中服务器有三种角色：**`Leader`**、**`Follower`**和**`Observer`**，其中`Observer`与`ZAB`协议本身无关\n- `Leader`的工作职责\n    - **`事务请求`**的唯一调度者和处理者，保证集群事务处理的`顺序性`\n    - 调度集群内部其他服务器（`Follower`和`Observer`）\n- `Follower`的工作职责\n    - 处理**`非事务请求`**\n    - 转发`事务请求`给`Leader`服务器\n    - 参与`事务Proposal的投票`\n    - 参与`Leader选举投票`\n- `Observer`的工作职责\n    - 用于`观察并同步`集群的最新状态变化\n    - `Observer`在工作原理上与`Follower`基本一致，与`Follower`的主要区别\n        - `Observer`只提供非事务服务\n        - `Observer`不参与任何形式的投票\n    - 通常用于在`不影响集群事务处理能力`的前提下`提升集群的非事务处理能力`\n\n## 主备模式架构\nZookeeper实现了一种`主备模式`的系统架构来保持集群中`各副本之间的数据一致性`，Zookeeper使用`单一的主进程`（`Leader`）来接收并处理客户端的所有**`事务请求`**，并采用**`ZAB协议`**，将服务器数据的状态变更以`事务Proposal`的形式**`广播`**到所有副本进程（`Follower`和`Observer`）\n\n### 事务请求\n- 所有事务请求必须由一个`全局唯一`的服务器来协调处理，这样的服务器被称为`Leader`，而其他服务器则被称为`Follower`（`ZAB`协议不考虑`Observer`）\n- `Leader`负责将一个客户端的**`事务请求`**转换成为一个**`事务Proposal`**，并将该`事务Proposal`分发给集群中所有的`Follower`\n- `Leader`等待所有的`Follower`关于`事务Proposal`的反馈，一旦_**`半数或以上`**_的`Follower`进行了正确地反馈，那么`Leader`会再次向所有的`Follower`分发`Commit`消息，要求其将`事务Proposal`进行`Commit`（类似于`2PC`，但移除了`事务回滚`，容易导致数据不一致，需要`崩溃恢复模式`的支持）\n\n#### 半数以上（Follower + Leader）\n_**`半数以上`**_的服务器能够正常相互通信，保证了不会因网络分区等原因而导致同时出现两组集群服务，因为两个 _**`半数以上`**_必然有`交集`！！\n\n#### 半数或以上（Follower）\n`半数或以上（Follower）`是为了保证`半数以上（Follower + Leader）`\n假若有`n-1`个`Follower`，S = sum(`半数或以上的Follower` + `Leader`) >= `ceil[(n-1)/2]+1`\n- 如果n为偶数，即`n=2k`，S >= `ceil[(n-1)/2]+1` = `ceil[(2k-1)/2]+1` = `k+1` ，剩下`k-1 < k+1`\n- 如果n为奇数，即`n=2k+1`，S >= `ceil[(n-1)/2]+1` = `ceil[(2k)/2]+1` = `k+1` ，剩下`k < k+1`\n- 假若有`2个Follower`，`半数或以上的Follower`为`1、2`；假若有`3个Follower`，`半数或以上的Follower`为`2、3`\n\n## 两种模式\nZAB协议运行过程中，存在两种模式：**`崩溃恢复模式`**+**`消息广播模式`**，模式切换图如下\n<img src=\"https://zk-1253868755.cos.ap-guangzhou.myqcloud.com/paxos2zk/zk_zab_mode.png\" width=\"500\">\n\n### 消息广播模式\n\n#### 示意图\n<img src=\"https://zk-1253868755.cos.ap-guangzhou.myqcloud.com/paxos2zk/zk_zab_mode_crash_recovery.png\" width=\"500\">\n\n#### 具体过程（类2PC）\n- 针对客户端的`事务请求`，`Leader`会为其生成对应的`事务Proposal`，`Leader`会为每个`事务Proposal`分配一个`全局单调递增的唯一ID`，即_**`ZXID`**_\n- 消息广播过程中，`Leader`会为每一个`Follower`都各自分配一个**`单独的队列`**，然后将需要广播的`事务Proposal`依次放入到这些队列中去，并根据**`FIFO`**策略进行消息发送\n- 每一个`Follower`在接收到`事务Proposal`之后，都会首先将其以_**`事务日志`**_的形式写入到`本地磁盘`中，并且在成功写入后向`Leader`反馈`ACK`\n- 当`Leader`接收到_**`半数或以上`**_的`Follower`反馈的`ACK`后，就会广播一个`Commit`消息给所有的`Follower`以通知其进行`事务提交`，同时`Leader`自身也会完成`事务提交`\n- 每一个`Follower`接收到`Commit`消息后，也会完成`事务提交`\n\n### 崩溃恢复模式\n- 恢复过程结束后需要`选举新Leader`，`ZAB协议`需要一个高效且可靠的`Leader选举算法`，在选举出`准Leader`后，需要进行`数据同步`，同步完成后，_**`准Leader`**_成为_**`正式Leader`**_\n- 崩溃恢复阶段需要处理2种特殊情况\n    - 提交已被Leader Commit的事务\n    - 丢弃只被Leader Propose的事务\n\n# 进阶理解\n\n## 分布式系统模型\n\n### 进程组 ∏\n分布式系统由一组进程构成：`∏ = {P1,P2,...,Pn}`，各个进程之间通过相互通信来实现消息的传递\n\n### 进程子集 Quorum\n每个进程随时都可能崩溃退出，正常工作的进程处于`UP`状态，否则处于`DOWN`状态，_**`半数以上`**_处于`UP`状态的进程构成`进程子集Q`，`Q`满足两个条件：`∀Q，Q⊆∏`，`∀Q1和Q2，Q1∩Q2≠∅`\n\n### 网络通信 Cij\n`Cij`表示进程`Pi`和`Pj`之间的网络通信，其中`Pi∈∏，Pj∈∏`，`Cij`满足`完整性`和`前置性`\n\n#### 完整性\n如果进程`Pj`收到来自进程`Pi`的`消息m`，那么进程`Pi`一定确实发送了`消息m`\n\n#### 前置性\n如果进程`Pj`收到了`消息m`，那么存在`消息m'`：如果`消息m'`是`消息m`的**`前置消息`**，那么`Pj`务必先接收`消息m'`，然后再接收`消息m`，记为`m≺m'`\n\n## 问题描述\n使用`Zookeeper`的分布式系统，通常存在`大量的客户端进程`，依赖`Zookeeper`来完成类似配置存储等分布式协调工作，因此`Zookeeper`必须具备以下特性\n- `高吞吐`和`低延时`\n- 在`高并发`的情况下完成`分布式数据的一致性处理`\n- 同时能够`优雅地处理运行时故障`，具备快速从故障中恢复的能力\n\n### 主进程周期\n`ZAB`协议是`Zookeeper`框架的核心，任何时候都需要保证只有一个主进程负责消息广播，如果主进程崩溃了，需要选举出新的主进程，随着时间的推移，形成主进程序列：`P1,P2...Pe，∀Pe∈∏`，`e`称为**`主进程周期`**，如果`e`小于`e'`，那么`Pe`是`Pe'`之前的主进程，表示为`Pe≺Pe'`，进程可能会崩溃重启，因此`Pe`和`Pe'`本质上可能是`同一个进程`，只是处于`不同的主进程周期`而已。为了保证主进程每次广播出来的`事务Proposal`都是一致的，只有在 _**`充分完成崩溃恢复阶段`**_之后，新的主进程才可以开始生成`新的事务Proposal`并进行`消息广播`\n\n### 广播事务Proposal\n`transactions(v,z)`：实现事务Proposal的`广播`\n- `v`为事务Proposal的`内容`\n- `z`为事务Proposal的`标识`，`z=<e,c>`\n    - `e`为`主进程周期`，`e=epoch(z)`\n    - `c`为`当前主进程周期内的事务计数`，`c=counter(z)`\n    - 如果`z'`优先于`z`，记为`z≺z'`，有2种情况\n        - `epoch(z)<epoch(z')`：主进程周期不同\n        - `epoch(z)==epoch(z') && counter(z)<counter(z')`：主进程周期相同\n\n## 算法描述\n- 整个ZAB协议主要包括`消息广播`和`崩溃恢复`两个过程，进一步可以细分为**`发现（Discovery）`**、**`同步（Synchronization）`**和**`广播（Broadcast）`**三个阶段，每一个分布式进程会`循环执行`这三个阶段\n- **`崩溃恢复` = `发现`+ `同步` = （`选举准Leader` + `生成新主进程周期`） + `同步`**\n\n### 术语\n\n| 术语   | 说明                                                                     |\n| ------ | ------------------------------------------------------------------------ |\n| F.p    | Follower f处理过的`最后一个`事务Proposal                                 |\n| F.zxid | Follower f处理过的历史事务Proposal中`最后一个`事务Proposal的事务标识ZXID |\n| hf     | Follower f`已经处理过的事务Proposal序列`                                 |\n| Ie     | `准Leader`完成发现阶段后的初始化历史记录                                 |\n\n### 发现：选举准Leader + 生成新主进程周期\n发现过程就是`Leader选举`过程，首先选举`准Leader`，然后完成`epoch`的更新（新的主进程周期）和`Ie`的初始化\n\n#### 选举准Leader\n进入`Leader选举`流程，即机器进入`LOOKING`状态，有3种情况\n- 机器初始化启动，机器进入`LOOKING`状态\n- `Follower`运行期间无法与`Leader`保持连接，`Follower`进入`LOOKING`状态\n- `Leader`无法收到_**`半数或以上`**_ Follower的心跳检测，`Leader`进入`LOOKING`状态\n\n当一个机器进入`Leader选举`流程时，当前集群可能处在两个状态：`存在（准）Leader`+`不存在（准）Leader`\n\n##### 术语\n\n| 术语   | 说明                                                                                       |\n| ------ | ------------------------------------------------------------------------------------------ |\n| SID    | Server ID，用来唯一标识一台Zookeeper集群中的机器，全局唯一，与myid一致                     |\n| ZXID   | 事务ID，用来唯一标识一次服务器状态的变更，在同一时刻，集群中每一台机器的ZXID不一定完全一致 |\n| Vote   | 当集群中的机器发现自己无法检测到Leader机器的时候，就会尝试开始投票                         |\n| Quorum | `半数以上`机器，`quorum >= (n/2+1)`                                                        |\n\n##### 集群存在（准）Leader\n当该机器试图去选举`准Leader`的时候，会被告知当前集群的`（准）Leader`信息，对于该机器来说，仅仅需要与`（准）Leader`机器建立连接，并完成`数据状态同步`既可\n\n##### 集群不存在（准）Leader\n集群中的所有机器都处于一种试图选举出一个`准Leader`的状态，我们把这种状态称为`LOOKING`，处于`LOOKING`状态的机器会向集群中的所有其他机器发送消息，这个消息就是**`投票`**，投票消息组成：所推举的服务器`SID`和`ZXID`，**`(SID，ZXID)`**\n\n###### 第1次投票\n第1次投票，由于无法检测到集群中其他机器的状态信息，因此每台机器都**`将自己作为被推举的对象`**进行投票\n\n###### 变更投票\n集群中的每台机器发出自己的投票后，也会接收到来自集群中其他机器的投票，并依据一定的规则，来处理收到的其他机器的投票，并决定是否需要变更自己的投票\n\n| 术语 | 说明 |\n| --- | --- |\n| vote_sid | 接收到的投票中所推举Leader服务器的SID |\n| vote_zxid | 接收到的投票中所推举Leader服务器的ZXID |\n| self_sid | 当前服务器自己的SID |\n| self_zxid | 当前服务器自己的ZXID |\n\n变更规则：\n- `vote_zxid > self_zxid` ：认可当前收到的选票，并再次将该投票发送出去\n- `vote_zxid < self_zxid` ：坚持自己的投票，不做任何变更\n- `vote_zxid == self_zxid && vote_sid > self_sid` ：认可当前收到的选票，并再次将该投票发送出去\n- `vote_zxid == self_zxid && vote_sid < self_sid` ：坚持自己的投票，不做任何变更\n\n###### 统计投票\n如果一台机器收到_**`半数以上`**_的相同的投票（包括自身投票），那么这个投票对应的`SID`即为**`准Leader`**\n\n###### 示例\n<img src=\"https://zk-1253868755.cos.ap-guangzhou.myqcloud.com/paxos2zk/zk_zab_election.png\" width=\"500\">\n\n#### 生成新主进程周期\n`e'`：表示新的主进程周期，`Ie'`：`e'`对应的初始化历史记录，`准Leader L`与`Follower F`的工作流程\n- `Follower F`将自己最后接受的事务Proposal的epoch值**`CEPOCH(F.p)`**发送给`准Leader L`\n- 当`准Leader L`接收来自_**`半数或以上`**_ Follower的`CEPOCH(F.p)`消息后，从这些`CEPOCH(F.p)`消息中选取出**`最大的epoch`**值，然后`加1`，即为`e'`，最后生成**`NEWEPOCH(e')`**消息并发送给这些_**`半数或以上`**_ Follower\n- 当`Follower`接收到来自`准Leader L`的`NEWEPOCH(e')`消息后，检查当前的`CEPOCH(F.p)是否小于e'`，如果是，则将`CEPOCH(F.p)`更新为`e'`，同时向`准Leader L`发送**`ACK-E`**消息（包含当前`Follower`的epoch值`CEPOCH(F.p)`以及该`Follower`已经处理过的事务Proposal序列 _**`hf`**_）\n- 当`准Leader L`接收到来自_**`半数或以上`**_的`Follower`的`ACK-E`消息后，`准Leader L`会从这_**`半数或以上`**_的`Follower`中选取一个`Follower F`，并将其 _**`hf`**_作为初始化历史记录`Ie'`，假若选取`F`，那么`∀F'∈Q`，满足下面的其中1个条件\n    - `CEPOCH(F'.p)<CEPOCH(F.p)`\n    - `CEPOCH(F'.p)==CEPOCH(F.p) && (F'.zxid≺F.zxid || F'.zxid==F.zxid )`\n\n### 同步：准Leader ➔ 正式Leader\n`准Leader L`与与`Follower F`的工作流程\n- `准Leader L`向`Quorum`中的`Follower`发送**`NEWLEADER(e',Ie')`**消息\n- 当`Follower F`接收到`准Leader L`的`NEWLEADER(e',Ie')`消息后\n    - 如果`Follower F`的`CEPOCH(F.p)≠e'`，不参与本轮的同步，直接进入**`发现阶段`**\n    - 如果`CEPOCH(F.p)=e'`，那么`Follower`会执行`事务应用操作`，即`∀<v,z>∈Ie'`，`Follower`都会接受`<e',<v,z>>`，最后`Followe`会向`准Leader L`发送**`ACK-LD`**消息，表示已经接受并处理`Ie'`中所有的`事务Proposal`\n- 当`准Leader L`接收到_**`半数或以上`**_的`Follower`的`ACK-LD`消息后，向**`所有`**的`Follower`发送**`Commit-LD`**消息，此时`准Leader L`完成`同步`阶段，成为 _**`正式Leader`**_\n- 当`Follower`接收到`Commit-LD`消息后，就会依次提交所有`Ie'`中**`尚未处理`**的`事务Proposal`\n\n### 广播\n广播阶段类似于`2PC`，`ZAB协议`移除了2PC的`事务回滚`，因此`Follower`只能`回复ACK`或者`不回复`，`Leader`主要收到_**`半数或以上`**_的`ACK`，就可以发送`Commit`，这样的设计很容易带来`数据不一致性`，因此才需要`崩溃恢复模式`（Leader选举+数据同步）\n\n#### 工作流程\n- `Leader L`接收到客户端新的`事务请求`后，会生成对应的事务`Proposal<e',<v,z>>`，并根据`ZXID的顺序`向所有`Follower`发送**`Propose<e',<v,z>>`**，其中`epoch(z)=e'`\n- `Follower`根据消息接收的先后顺序来处理这些来自`Leader`的`事务Proposal`，并将它们`追加到hf`，之后给`Leader`反馈**`ACK`**消息\n- 当`Leader`接收到来自_**`半数或以上`**_ Follower针对`Propose<e',<v,z>>`的`ACK`消息后，就会向所有`Follower`发送**`Commit<e',<v,z>>`**消息\n- 当`Follower`接收到来自`Leader`的`Commit<e',<v,z>>`消息后，就会开始提交事务`Proposal<e',<v,z>>`，此时必定已经提交了事务`Proposal<e',<v',z'>>`，其中`<v',z'> ∈ hf，z'≺z`\n\n#### 两种特殊情况\n\n##### 提交已被Leader Commit的事务\n\n###### 发生场景\n`Leader`发送`Propose`请求，`Follower F1`和`Follower F2`都向`Leader`回复了`ACK`，`Leader`向所有的`Follower`发送`Commit`请求并`Commit自身`，此时`Leader`宕机，**`Leader已经Commit`**，但**`Follower尚未Commit`**，数据不一致\n\n###### 处理方式\n选举`F.zxid`最大的`Follower`成为`新的准Leader`，由于`旧Leader`宕机前，_**`半数或以上`**_的Follower曾经发送`ACK`消息，`新的准Leader`必然是这`半数或以上Follower`的一员；`新的准Leader`会发现自身存在**`已经Propose但尚未Commit的事务Proposal`**，`新的准Leader`会向所有的`Follower`先发送`Propose`请求，再发送`Commit`请求\n\n##### 丢弃只被Leader Propose的事务\n\n###### 发生场景\n`Leader`收到了`事务请求`，将其包装成了`事务Proposal`，此时`Leader`宕机，`Follower`并没有收到`Propose`请求，`Follower`进入选举阶段，选举产生`新Leader`，`旧的Leader重启`，以`Follower`的角色加入集群，此时`旧Leader`上有一个`多余的事务Proposal`，数据不一致\n\n###### 处理方式\n`新的准Leader`会根据自己服务器上`最后被提交的事务Proposal`和`Follower的事务Proposal`进行对比，然后`新的准Leader`要求`Follower`执行一个**`回退操作`**，回退到一个`已经被集群半数以上机器提交的最新的事务Proposal`\n\n### 三阶段示意图\n<img src=\"https://zk-1253868755.cos.ap-guangzhou.myqcloud.com/paxos2zk/zk_zab_3_phase_1.png\" width=\"500\">\n在正常运行时，ZAB协议一直运行在**`广播阶段`**，如果出现Leader宕机或其他原因导致的Leader缺失，此时ZAB协议会进入**`发现阶段`**\n\n## 运行分析\n运行状态切换\n<img src=\"https://zk-1253868755.cos.ap-guangzhou.myqcloud.com/paxos2zk/zk_zab_state_switch.png\" width=\"500\">\n- 组成`ZAB协议`的所有进程`启动`的时候，初始状态为`LOOKING`\n- 如果进程发现`已经存在新的（准）Leader`，马上切换到`FOLLOWING`状态，并开始和（准）Leader保持同步\n- 处于`LOOKING`状态的进程称为`Follower`，处于`LEADING`状态的进程称为`Leader`\n- 当检测到`Leader`崩溃或放弃领导地位，其余`Follower`会切换到`LOOKING`状态，并开始新一轮的选举\n- 在`ZAB协议`运行过程中，每个进程的状态都会在`LOOKING`、`FOLLOWING`和`LEADING`之间不断地转换\n- 完成`Leader选举`阶段，进程成为`准Leader`，完成`数据同步`阶段，`准Leader成为正式Leader`\n    - `准Leader`接收来自`半数或以上`的Follower进程针对`Le'`的`NEWLEADER(e',Ie')`的`ACK-LD`消息，那么`Le'`正式成为了周期`e'`的`Leader`\n    - 在`原子广播`阶段，`Leader`会为每一个与自己保持同步的`Follower`创建一个`操作队列`，`Leader`与所有的`Follower`之间需要通过`心跳检测`机制来感知彼此。如果在指定的超时时间内`Leader`无法从`半数或以上`的Follower那里接收到`心跳检测`或者`TCP连接断开`，`Leader`和所有的`Follower`都会切换到`LOOKING`状态\n\n# 参考资料\n[从Paxos到Zookeeper](https://book.douban.com/subject/26292004/)\n\n<!-- indicate-the-source -->\n","tags":["ZAB"],"categories":["Zookeeper"]},{"title":"Zookeeper -- Base-Paxos协议","url":"%2F2017%2F07%2F04%2Fzk-paxos%2F","content":"\n{% note info %}\n本文将简要介绍`Paxos`协议\n{% endnote %}\n\n<!-- more -->\n\n# 基础概念\n\n## Paxos协议\n`Paxos`协议是一种**`通用的分布式一致性协议`**，用于解决**`一致性问题`**\n\n## 一致性问题\n`Paxos`协议用来确定一个**`不可变`**变量的取值，取值具有2个特点：\n- 取值可以为`任意二进制数据`\n- 取值`一旦确定将不可被更改`，并且可以被获取到（`不可变性，可读取性`）\n\n### 系统抽象\n设计一个系统，来存储名称为var的变量，满足以下4个条件：\n- 系统内部由多个`Acceptor`组成，负责存储和管理var变量\n- 系统外部有多个`Proposer`，这些`Proposer`可以`并发`地调用`Acceptor`对外提供的API接口，向系统提交不同的var取值\n- var取值为任意二进制数据\n- `Acceptor`对外提供的API接口：**`propose(var,V) => <ok,f> or <error>`**，f可能是当前`Proposer`提交成功的`V`，也可能是其他`Proposer`提交成功的`V'`\n\n#### var的一致性\n- 如果var取值`没有确定`，则var的取值为`null`\n- 一旦var的取值`被确定`，则**`不可被更改`**，并且可以一直获得这个值\n\n#### 系统的容错特性\n- 可以容忍**`任意数量`**的`Proposer`出现故障\n- 可以容忍**`半数以下`**的`Acceptor`出现故障\n\n# 实现方案\n\n## 互斥访问权\n\n### 适用场景\n系统由`单个Acceptor`组成\n\n### 策略\n- 通过**`互斥锁`**机制，来管理`Proposer`的`并发`执行\n- `Proposer`首先向`Acceptor`申请`互斥锁`，申请成功后才能请求`Acceptor`接受自己的取值\n- `Acceptor`向`Proposer`发放`互斥锁`，`Acceptor`只接收持有互斥锁的`Proposer`提交的取值\n- 让`Proposer`按照获取`Acceptor`互斥锁的顺序来依次访问`Acceptor`\n- 一旦`Acceptor`接收了某个`Proposer`的取值，则认为var的取值被确定，其他`Proposer`无法再更改var的取值\n\n### 实现\n\n#### 基本方法\n- Acceptor保存`变量var`和一个`互斥锁Lock`\n- `Acceptor::prepare()`：`Proposer`向`Acceptor`请求申请互斥锁\n- `Acceptor::release()`：`Proposer`向`Acceptor`请求释放互斥锁\n- `Acceptor::accept(var,V)`：如果`Proposer`已经持有互斥锁，并且var没有取值，则设置var为`V`，然后向`Acceptor`请求释放互斥锁\n\n#### propose(var，V)的两阶段实现\n\n##### 第1阶段\n`Proposer`通过调用`Acceptor::prepare()`向`Acceptor`请求申请互斥锁\n- 申请互斥锁`失败`，返回`<error>`，说明当前互斥锁被其他`Proposer`占用，尚未释放\n- 申请互斥锁`成功`并且返回var变量的`当前值f`，然后进入第2阶段\n\n\n##### 第2阶段\n进入第2阶段，说明当前`Proposer`申请互斥锁`成功`并且返回var变量的`当前值f`\n- 如果当前var的取值`f不为null`，说明var变量已经被其他`Proposer`设置成功，**`形成了确定性取值`**，那么`Proposer`通过`Acceptor::release()`向`Acceptor`请求释放互斥锁，返回`<ok,f>`\n- 如果当前var的取值`f为null`，说明var变量**`尚未形成确定性取值`**，那么`Proposer`通过`Acceptor::accept(var,V)`提交数据V，并且向`Acceptor`请求释放互斥锁，返回`<ok,V>`\n\n### 结论\n- 通过`Acceptor`的互斥锁让**`Proposer串行运行`**，可以简单地实现`var取值的一致性`\n- 如果`Proposer`在`释放互斥锁之前宕机`，将会导致系统陷入**`死锁`** ➔ 不能容忍**`任意数量`**的`Proposer`出现故障！！\n\n## 抢占式访问权 + 后者认同前者\n\n### 适用场景\n系统由`单个Acceptor`组成，引入**`抢占式访问权`**，用于解决互斥访问权的**`死锁`**问题\n\n### 策略\n\n#### 抢占式访问权\n- `Acceptor`可以让某个`Proposer`获取到的访问权失效，不再接受该`Proposer`的访问\n- `Acceptor`可以将访问权发放给其他`Proposer`，让其他`Proposer`访问`Acceptor`\n- `Proposer`向`Acceptor`申请访问权时必须指定编号**`epoch（值越大，代表越新）`**\n- `Proposer`在获取到访问权之后，才能向`Acceptor`提交取值\n- `Acceptor`采用**`喜新厌旧`**的原则\n    - `Acceptor`一旦接收到的`新epoch`（epoch值更大），立马让`旧epoch`的访问权失效，不再接受持有`旧epoch`访问权的`Proposer`提交的取值\n    - `Acceptor`给`新epoch`对应的`Proposer`发放访问权，只接收该`Proposer`提交的取值（同样可以被抢占）\n\n#### 保证一致性\n为了保证**`一致性`**，不同`epoch`对应的`Proposer`之间采用**`后者认同前者`**的原则\n- 在确定**`旧epoch无法形成确定性取值`**时，`新epoch`提交自己的value，不会冲突\n- 一旦**`旧epoch形成了确定性取值`**，新的`epoch`肯定可以获得此值，并且会`认同`此值，不会进行更改\n\n### 实现\n\n#### 基本方法\n\n##### Acceptor保存的状态\n- 当前var的取值：**`<accepted_epoch,accepted_value>`**，表示变量var在`accepted_epoch`形成了_`确定性取值`_`accepted_value`\n- 最新发放访问权的epoch：**`latest_prepared_epoch`**，`Proposer`如果要成功抢占访问权，指定的`新epoch`必须大于`latest_prepared_epoch`\n\n##### Acceptor::prepare(epoch)\n`Proposer`向`Acceptor`请求访问权，具有抢占性质\n- `Proposer`指定`epoch`\n- `Acceptor`只接受`大于latest_prepared_epoch`的`epoch`，并给予`Proposer`关于该`epoch`的访问权\n- 更新`latest_prepared_epoch=epoch`，返回var的当前取值（即`<ok,accepted_epoch,accepted_value>`）\n- 使其他`Proposer`（之前已经获得过访问权）的访问权失效，不再接受它们的访问\n\n##### Acceptor::accept(var,prepared_epoch,V)\n`prepared_epoch`为`Acceptor::prepare(epoch)`指定的`epoch`，验证**`latest_prepared_epoch`**与**`prepared_epoch`**是否相等\n- 相等，说明当前`Proposer`持有的epoch访问权`依然有效`，那么设置var的取值，即**`<accepted_epoch,accepted_value>` ➔ `<prepared_epoch,V>`**\n- 不相等，说明当前`Proposer`持有的epoch访问权`已经被抢占`，无法继续运行\n\n#### propose(var，V)的两阶段实现\n\n##### 第1阶段\n`Proposer`指定`epoch`，并通过调用`Acceptor::prepare(epoch)`向`Acceptor`请求访问权\n- 请求访问权`失败`，返回`<error>`，说明当前`Proposer`指定的`epoch`不比`Acceptor`的`latest_prepared_epoch`大\n- 请求访问权`成功`并且返回var变量的当前值`<accepted_epoch,accepted_value>`，然后进入第2阶段\n\n##### 第2阶段\n采用**`后者认同前者`**的原则执行\n- `var取值为<null,null>`，则`旧epoch肯定尚未形成确定性取值`，`Proposer`通过调用`Acceptor::accept(var,prepared_epoch,V)`向`Acceptor`提交取值\n    - 提交成功，返回**`<ok,prepared_epoch,V>`**\n    - 提交失败，返回`<error>`（`被新epoch抢占`或者`Acceptor发生故障`）\n- `var取值不为<null,null>`，则其他`Proposer`设置成功，变量var`已经形成确定性取值`，认同此值不再更改，直接返回**`<ok,accepted_epoch,accepted_value>`**\n\n### 样例\n<img src=\"https://zk-1253868755.cos.ap-guangzhou.myqcloud.com/paxos2zk/zk_paxos_2.png\" width=\"500\">\n\n### 结论\n- 让`Proposer`按照`epoch递增的顺序`抢占式地依次运行，采用`后者认同前者`的原则\n- 这样可以了`避免Proposer故障带来的死锁问题`，并且仍然`保留var取值的一致性`\n- 但仍然存在_**`单点问题`**_，`Acceptor`故障会导致整个系统宕机\n\n## Paxos\n\n### 适用场景\n系统内部由`多个Acceptor`组成，避免`单点Acceptor故障`\n\n### 策略\n- `Acceptor`的实现与抢占式访问权类似，采用`喜新厌旧`的原则\n- `Paxos`采用_**`少数服从多数`**_的思路：一旦某个epoch的取值f被_**`半数以上`**_的`Acceptor`接受，系统则认为此var了形成`确定性取值`，不再更改\n\n`半数以上`\n- `5`个`Acceptor`，`半数以上`为：`3、4、5`\n- `6`个`Acceptor`，`半数以上`为：`4、5、6`\n\n### 实现\n\n#### propose(var，V)的两阶段实现\n\n##### 第1阶段\n`Proposer`指定`epoch`，向所有的`Acceptor`请求该`epoch`的访问权\n- `Proposer`获取少于`半数以上`的`Acceptor`关于`epoch`的访问权，`Proposer`结束第1阶段的运行，但无法进入第2阶段\n- `Proposer`获取`半数以上`的`Acceptor`关于`epoch`的访问权（并返回var的当前值），进入第2阶段\n\n关键点：_**`半数以上`**_ ➔ 当多个`Proposer`并发地向所有`Acceptor`请求关于`同一个epoch`的访问权，_**`最多只有一个Proposer`**_能获得`半数以上`Acceptor请求关于该`epoch`的访问权并进入到第2阶段！！\n\n##### 第2阶段\n采用`后者认同前者`的原则执行\n- 如果在第1阶段获取到的var的当前值**`都为null`**，说明var**`尚未形成确定性取值`**，此时`Proposer`努力使**`V`**成为`确定性取值`（对应`<epoch,V>`）\n    - `Proposer`向`epoch对应的所有Acceptor`（半数以上的Acceptor，不一定是所有）提交取值`<epoch,V>`\n    - 如果收到`半数以上`提交成功，则已经形成确定性取值，返回`<ok,V>`\n    - 否则，返回`<error>`（`被新epoch抢占`或者`Acceptor发生故障`）\n- 如果第1阶段获取到的var的当前值**`不都为null`**，认同**`最大accepted_epoch对应的取值f`**，努力使得**`f`**成为`确定性取值`（对应`<epoch,f>`）\n    - 如果此时f已经被`半数以上`的`Acceptor`接受，则说明f已经是`确定性取值`，直接返回`<ok,f>`\n    - 否则，向`epoch对应的所有Acceptor`提交取值`<epoch,f>`\n\n### 样例\n<img src=\"https://zk-1253868755.cos.ap-guangzhou.myqcloud.com/paxos2zk/zk_paxos_3_1.png\" width=\"500\">\n\n### 结论\n- 在抢占式访问权的基础上引入`多Acceptor`，避免了`Acceptor`的单点问题\n- 保证`一个epoch的访问权只能被一个Proposer获取`，`Proposer`是按照epoch递增的顺序依次运行的\n- 新的epoch的`Proposer`采用`后者认同前者`的思路运行\n- 可以满足容错性要求\n    - `半数以下Acceptor`出现故障时，存活的`Acceptor`依然可以形成var的确定性取值\n    - 一旦var取值确定，即便出现`半数以下Acceptor`故障，此取值依然可以被获取，并且将不再被更改\n\n# 参考资料\n[paxos和分布式系统](http://video.tudou.com/v/XMTc4NjM4Nzc1Mg==.html)\n\n<!-- indicate-the-source -->\n","tags":["Paxos"],"categories":["Zookeeper"]},{"title":"Java 8 -- Optional","url":"%2F2017%2F06%2F02%2Fjava8-optional%2F","content":"\n{% note info %}\n本文主要介绍`Java 8`的 `Optional` 的简单使用\n{% endnote %}\n\n<!-- more -->\n## Address\n```java\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\npublic class Address {\n    private String province;\n    private String city;\n}\n```\n\n# of + ofNullable\n相关代码托管在[java8_demo](https://github.com/zhongmingmao/java8_demo)\n```java\n@Test(expected = NoSuchElementException.class)\npublic void emptyTest() {\n   // 声明一个空的Optional对象\n   Optional<Address> nameOptional = Optional.empty();\n   // java.util.NoSuchElementException: No value present\n   nameOptional.get();\n}\n\n@Test(expected = NullPointerException.class)\npublic void ofNullTest() {\n   // 依据实例创建Optional对象\n   Optional.of(new Address(\"Guangdong\", \"Zhongshan\"));\n\n   // Optional.ofNullable(null)返回Optional.empty()\n   assertEquals(Optional.empty(), Optional.ofNullable(null));\n   // java.lang.NullPointerException\n   Optional.of(null);\n}\n```\n\n# map\n1. `Stream.map`的定义：`<R> Stream<R> map(Function<? super T, ? extends R> mapper)`\n2. `Optional.map`的定义：`<U> Optional<U> map(Function<? super T, ? extends U> mapper)`\n3. 上面两者定义非常类似，`Optional`可看成`最多包含一个元素`的 `Stream`\n\n<img src=\"https://java8-1253868755.cos.ap-guangzhou.myqcloud.com/java8-optional-map.png\" width=\"500\">\n\n```java\n@Test\npublic void mapTest() {\n   String province = \"Guangdong\";\n   String city = \"Zhongshan\";\n   Optional<Address> addressOptional = Optional.of(new Address(province, city));\n   // mapper : Address -> String\n   // Optional<Address> -> Optional<String>\n   Optional<String> stringOptional = addressOptional.map(Address::getCity);\n   assertTrue(stringOptional.isPresent());\n   assertEquals(city, stringOptional.get());\n}\n```\n\n# flatMap\n1. `Stream.flatMap`的定义：`<R> Stream<R> flatMap(Function<? super T, ? extends Stream<? extends R>> mapper)`\n2. `Optional.flatMap`的定义：`<U> Optional<U> flatMap(Function<? super T, Optional<U>> mapper)`\n\n<img src=\"https://java8-1253868755.cos.ap-guangzhou.myqcloud.com/java8-optional-flatmap.png\" width=\"500\">\n\n```java\n@Test\npublic void flatmapTest() {\n   String province = \"Guangdong\";\n   String city = \"Zhongshan\";\n   Optional<Address> addressOptional = Optional.of(new Address(province, city));\n   // 对于 mapper 为 T -> Optional<U>时，调用Optional.map，生成的是Optional<Optional<U>>\n   Optional<Optional<String>> optionalOptional = addressOptional.map(address -> Optional.ofNullable(address.getCity()));\n   // 对于 mapper 为 T -> Optional<U>时，调用Optional.map，生成的是Optional<U>,被扁平化\n   Optional<String> stringOptional = addressOptional.flatMap(address -> Optional.ofNullable(address.getCity()));\n   assertTrue(stringOptional.isPresent());\n   assertEquals(city, stringOptional.get());\n}\n```\n\n# 解引用\n```java\n@Test(expected = UnsupportedOperationException.class)\npublic void dereferenceTest() {\n   // get：最简单 + 最不安全\n   Address address = addressOptional.get();\n   assertNotNull(address);\n\n   address = null;\n   Optional<Address> emptyAddressOptional = Optional.ofNullable(address);\n\n   String defaultValue = \"Unknown\";\n   // orElse：设置默认值\n   Address elseAddress = emptyAddressOptional.orElse(new Address(defaultValue, defaultValue));\n   assertEquals(defaultValue, elseAddress.getProvince());\n   assertEquals(defaultValue, elseAddress.getCity());\n\n   // orElseGet：orElse的延迟调用版本\n   Address elseGetAddress = emptyAddressOptional.orElseGet(Address::new);\n   assertNull(elseGetAddress.getProvince());\n   assertNull(elseGetAddress.getCity());\n\n   // ifPresent：存在值则运行consumer，否则不进行任何操作\n   emptyAddressOptional.ifPresent(System.out::println);\n\n   // orElseThrow：不存在时，抛出异常\n   emptyAddressOptional.orElseThrow(UnsupportedOperationException::new);\n}\n```\n\n# filter\n```java\n@Test\npublic void filterTest() {\n   assertTrue(addressOptional.filter(address -> address.getCity().contains(\"Z\")).isPresent());\n}\n```\n\n# 基础类型 + Optional\n1. `OptionalInt`、`OptionalLong`、`OptionalDouble`\n2. 最多`只有一个`元素，并没有像`StreamInt`那样相对于 `Stream<Integer>` 有性能优势\n3. 不支持 `map` 、 `flatmap` 、 `filter`\n\n<!-- indicate-the-source -->\n","tags":["Java"],"categories":["SE8"]},{"title":"Java 8 -- Default Method","url":"%2F2017%2F06%2F01%2Fjava8-default%2F","content":"\n{% note info %}\n本文主要介绍`Java 8`的 `default 方法`的简单使用\n{% endnote %}\n\n<!-- more -->\n\n# 简介\n1. `default方法`作为`接口的一部分`由实现类`继承`\n2. `default方法`的目标用户是类库设计者\n    - 以`兼容`的方式解决`类库的演进`问题\n\n<img src=\"https://java8-1253868755.cos.ap-guangzhou.myqcloud.com/java8-default.png\" width=\"500\">\n\n# 冲突解决\n一个类可以实现`多个拥有默认方法的接口`，从而实现行为的`多继承`，按照下列步骤解决冲突\n1. `类或父类`中声明的方法的优先级高于任何声明为默认方法的优先级\n2. `子接口的default方法`优先级高于父接口的default方法\n3. `显式`选择使用哪一个default方法\n\n## 类与接口定义\n相关代码托管在[java8_demo](https://github.com/zhongmingmao/java8_demo)\n```java\ninterface A {\n    default String hello() {\n        return \"Hello From A\";\n    }\n}\n\ninterface B extends A {\n    @Override\n    default String hello() {\n        return \"Hello From B\";\n    }\n}\n\nclass C implements A {\n    @Override\n    public String hello() {\n        return \"Hello From C\";\n    }\n}\n\nclass D extends C implements A, B {\n}\n\n\nclass E extends D implements A, B {\n    @Override\n    public String hello() {\n        return \"Hello From E\";\n    }\n}\n\nclass F implements A, B {\n}\n\ninterface G {\n    default String hello() {\n        return \"Hello From G\";\n    }\n}\n\nclass H implements B, G {\n    @Override\n    public String hello() {\n        // A.super.hello() is not ok\n        return B.super.hello(); // 显示选择 B 的 default 方法实现\n    }\n}\n```\n\n<img src=\"https://java8-1253868755.cos.ap-guangzhou.myqcloud.com/java8-default-classes.png\" width=\"500\">\n\n## 类或父类中的方法\n```java\n @Test\npublic void fatherTest() {\n   Supplier<D> dSupplier = D::new;\n   assertEquals(\"Hello From C\", dSupplier.get().hello());\n}\n\n@Test\npublic void selfTest() {\n   Supplier<E> eSupplier = E::new;\n   assertEquals(\"Hello From E\", eSupplier.get().hello());\n}\n```\n1. 类 `D` 继承类 `C`，类 `C` 有自己的重写版本，优先级高于接口的 `default` 方法，选择父类 `C` 的重写版本\n2. 类 `E` 有自己的重载版本，优先级高于间接父类`C`的重写版本和接口的 `default` 方法，选择自身的重写版本\n\n## 子接口的default方法\n```java\n@Test\npublic void sonInterfaceTest() {\n   Supplier<F> fSupplier = F::new;\n   assertEquals(\"Hello From B\", fSupplier.get().hello());\n}\n```\n类 `F` 实现接口 `B`和`A`，而`B`有继承 `A`，子接口`B`的优先级更高，选择接口 `B`的 `default` 实现\n\n## 显式选择\n```java\n@Test\npublic void explicitTest() {\n   Supplier<H> hSupplier = H::new;\n   assertEquals(\"Hello From B\", hSupplier.get().hello());\n}\n```\n接口 `B` 和 `G` 没有继承关系，对 类 `H` 来说两者属于平等关系 ，必须重写，重写版本中显示选择了 `B` 的`default` 实现\n<!-- indicate-the-source -->\n","tags":["Java"],"categories":["SE8"]},{"title":"Java 8 -- Stream","url":"%2F2017%2F05%2F31%2Fjava8-stream%2F","content":"\n{% note info %}\n本文主要介绍`Java 8`的 `Stream`的简单使用\n{% endnote %}\n\n<!-- more -->\n\n# 简介\n\n## 流与集合的区别\n\n### 计算的时机\n\n|  | 是否全部载入内存 | 能否添加或删除元素 | 类似于 |\n| --- | --- | --- | --- |\n| 集合 | 是 | 能 | DVD |\n| 流 | 否，按需计算 | 不能 | 网络流媒体 |\n\n### 消费一次\n流`只能遍历一次`，遍历后即被消费，类似于`网络流`\n相关代码托管在[java8_demo](https://github.com/zhongmingmao/java8_demo)\n```java\nList<String> strs = Arrays.asList(\"zhong\", \"ming\", \"mao\");\nStream<String> stream = strs.stream();\nstream.forEach(s -> System.out.println(s)); // Lambda\n// throw java.lang.IllegalStateException: stream has already been operated upon or closed\nstream.forEach(System.out::println); // 方法引用，相关内容请参照「Java8回忆录 - Lambda」\n```\n\n### 迭代方式\n\n|  | 迭代方式 | 编程方式 | 并行 | 目的 |\n| --- | --- | --- | --- | --- |\n| 集合 | 外部迭代 | 自行选择数据表示 | 自行实现并行 | 以特定时间/空间复杂度存储和访问元素 |\n| 流 | 内部迭代 | 声明式编程 | 几乎免费的并行 | 计算 |\n\n## 流操作\n流操作类似于`流水线`操作\n<img src=\"https://java8-1253868755.cos.ap-guangzhou.myqcloud.com/java8-stream-pipeline.png\" width=\"500\">\n\n### 中间操作\n1. 返回一个流（`Stream`）的操作\n2. 中间操作`不会执行任何处理`，直到触发了一个`终端操作`\n3. 中间操作一般是可以进行`合并`的，这会在终端操作进行处理\n\n常用中间操作\n\n| 操作 | 出参 | 入参 | 函数描述符（入参） |\n| --- | --- | --- | --- |\n| filter | `Stream<T>` | `Predicate<T>` | T -> boolean |\n| distinct | `Stream<T>` |  |  |\n| skip | `Stream<T>` | long |  |\n| limit | `Stream<T>` | long |  |\n| map | `Stream<R>` | `Function<T,R>` | T -> R |\n| flatMap | `Stream<R>` | `Function<T,Stream<R>>` | `T -> Stream<R>` |\n| sorted | `Stream<T>` | `Comparator<T>` | (T,T) -> int |\n\n### 终端操作\n1. `关闭流`的操作\n2. 从流的流水线`生成结果`（List、Integer、void等）\n\n常用终端操作\n\n| 操作 | 出参 | 入参 | 函数描述符（入参） |\n| --- | --- | --- | --- |\n| anyMatch | boolean | `Predicate<T>` | T -> boolean |\n| noneMatch | boolean | `Predicate<T>` | T -> boolean |\n| allMatch | boolean | `Predicate<T>` | T -> boolean |\n| findAny | `Optional<T>` |  |  |\n| findFirst | `Optional<T>` |  |  |\n| forEach | void | `Consumer<T>` | T -> void |\n| collect | R | `Collector<T,A,R>` |  |\n| count | long |  |  |\n| reduce | `Optional<T>` | `BinaryOperator<T>` | (T,T) -> T |\n\n# 筛选与切片\n## 谓词筛选\n```java\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\npublic class User {\n\n    public enum TYPE {\n        OLD, YOUNG;\n    }\n\n    private String name;\n    private int age;\n    private boolean isStudent;\n\n    public User(int age, boolean isStudent) {\n        this.age = age;\n        this.isStudent = isStudent;\n    }\n}\n```\n```java\n@Test\npublic void filterCountTest() {\n    // 初始化代码实际在@Before中，这里仅为了行文方便\n    List<User> users = Arrays.asList(new User(10, true),\n           new User(20, true), new User(30, false),\n           new User(40, false), new User(50, false),\n           new User(60, false), new User(70, false));\n\n    assertEquals(2, users.stream() // Stream<User>\n                         .filter(User::isStudent) // 谓词筛选，方法引用，Stream<User>\n                         .count()); // 统计，long\n}\n```\n\n## 筛选各异元素\n```java\n@Test\npublic void filterDistinctTest() {\n   List<Integer> numbers = Arrays.asList(1, 2, 3, 4, 3, 2, 1);\n   assertEquals(2, numbers.stream() // Stream<Integer>\n                          .filter(n -> n % 2 == 0) // 谓词过滤，Lambda，Stream<Integer>\n                          .distinct() // 筛选各异的元素，Stream<Integer>\n                          .count()); // 统计，long\n}\n```\n\n## 截断流\n```java\n@Test\npublic void filterLimitTest(){\n   Predicate<User> isStudent = User::isStudent;\n   assertEquals(3, users.stream() // Stream<User>\n                        .filter(isStudent.negate()) // 谓词筛选，Stream<User>\n                        .limit(3) // 截断流，Stream<User>\n                        .count()); // 统计，long\n}\n```\n\n## 跳过N个元素\n```java\n@Test\npublic void filterSkipTest() {\n   Predicate<User> isStudent = User::isStudent;\n   assertEquals(4, users.stream() // Stream<User>\n                        .filter(isStudent.negate()) // 谓词筛选，Stream<User>\n                        .skip(1) // 跳过前N个元素，Stream<User>\n                        .count()); // 统计，long\n}\n```\n\n# 映射\n\n## map\n```java\n@Test\npublic void mapTest() {\n   List<String> words = Arrays.asList(\"zhong\", \"ming\", \"mao\");\n   assertEquals(3, words.stream() // Stream<String>\n                        .map(String::length) // 映射，Stream<Integer>\n                        .distinct() // 筛选各异的元素，Stream<Integer>\n                        .count()); // 统计，long\n}\n```\n## flatMap\n```java\n@Test\npublic void flatMapTest() {\n   List<String> words = Arrays.asList(\"zhong\", \"ming\", \"mao\");\n   Stream<String[]> stream = words.stream() // Stream<String>\n                                  .map(s -> s.split(\"\")); // 映射，Stream<String[]>，此时流中的元素是String[]\n   // <R> Stream<R> flatMap(Function<? super T, ? extends Stream<? extends R>> mapper)\n   // public static <T> Stream<T> stream(T[] array)\n   assertEquals(8, stream.flatMap(Arrays::stream) // 映射，Stream<String>，此时流中的元素恢复为String\n                         .distinct() // 筛选各异的元素，Stream<String>\n                         .collect(toList()) // 收集为List，List<String>\n                         .size());\n}\n```\nflatMap 从定义上理解有点晦涩，做简单解释\n1. `flatMap`方法定义可简单理解为`Stream<R> (Function<T, Stream<R>> mapper)`，`mapper`的函数描述符简单理解为`T -> Stream<R>`\n2. Lambda表达式`Arrays::stream`的签名为`T[] -> Stream<T>`\n3. `stream`为`Stream<String[]>`，元素类型为`String[]`，通过`Arrays::stream`会变成`String[] -> Stream<String>`，依据`flatMap`方法的定义，将返回`Stream<String>`，流`被扁平化`\n\n<img src=\"https://java8-1253868755.cos.ap-guangzhou.myqcloud.com/java8-stream-flatmap.png\" width=\"500\">\n\n下面是 `flatmap` 的 另一个实例\n```java\nList<Integer> numbers1 = Arrays.asList(1, 2, 3);\nList<Integer> numbers2 = Arrays.asList(3, 4);\nStream<Stream<Integer[]>> mapStream = numbers1.stream() // Stream<Integer>\n                                              .map(i ->\n                                                    numbers2.stream() // Stream<Integer>\n                                                    .map(j -> new Integer[]{i, j}) // Stream<Integer[]>\n                                               ); // Stream<Stream<Integer[]>>\n// flatMap 相对于 map，相当于抹去了一层 Stream\nStream<Integer[]> flatMapStream = numbers1.stream() // Stream<Integer>\n                                          .flatMap(i ->\n                                                    numbers2.stream() // Stream<Integer>\n                                                    .map(j -> new Integer[]{i, j}) // Stream<Integer[]>\n                                                ); // Stream<Integer[]>\n\nassertEquals(2, numbers1.stream() // Stream<Integer>\n                        .flatMap(i ->\n                            numbers2.stream() // Stream<Integer>\n                                    .map(j -> new Integer[]{i, j})) // Stream<Integer[]>\n                        .filter(ints -> (ints[0] + ints[1]) % 3 == 0) // Stream<Integer[]> ，只有(2,4)和(3,3)匹配\n                        .count()); // long\n```\n\n\n\n# 查找与匹配\n\n## 查找\n```java\n@Test(expected = IllegalArgumentException.class)\npublic void findTest() {\n   List<Integer> numbers = Arrays.asList(1, 2, 3, 4, 5);\n   Optional<Integer> first = numbers.stream() // Stream<Integer>\n                                    .map(x -> x * x + 2) // Stream<Integer>\n                                    .filter(x -> x % 3 == 0) // Stream<Integer>\n                                    .findFirst(); // Optional<Integer>\n   first.orElseThrow(() -> new RuntimeException(\"error\"));\n\n   Optional<Integer> any = numbers.stream() // Stream<Integer>\n                                    .map(x -> x * x) // Stream<Integer>\n                                    .filter(x -> x % 7 == 0) // Stream<Integer>\n                                    .findAny(); // Optional.EMPTY\n   any.orElseThrow(() -> new IllegalArgumentException(\"error\"));\n}\n```\n\n## 匹配\n```java\n@Test\npublic void matchTest() {\n   List<Integer> numbers = Arrays.asList(1, 2, 3, 4, 5);\n   assertFalse(numbers.stream() // Stream<Integer>\n                      .anyMatch(x -> x > 10)); // boolean\n   assertFalse(numbers.stream() // Stream<Integer>\n                      .noneMatch(x -> x < 10)); // boolean\n   assertTrue(numbers.stream() // Stream<Integer>\n                      .allMatch(x -> x < 10)); // boolean\n}\n```\n\n# 归约\n\n## 求和\n```java\n@Test(expected = RuntimeException.class)\npublic void sumTest() {\n   List<Integer> numbers = Arrays.asList(1, 2, 3, 4, 5);\n   assertEquals(Integer.valueOf(15), numbers.stream() // Stream<Integer>\n                                            .reduce(0, (x, y) -> x + y)); // Integer\n   // 更简洁的写法Integer::sum（方法引用）\n   assertEquals(Integer.valueOf(15), numbers.stream().reduce(0, Integer::sum)); // Integer::sum从 Jdk8 开始引入\n\n   numbers.clear();\n   Optional<Integer> sum = numbers.stream() // Stream<Integer>\n                                  .reduce((x, y) -> x + y); // Optional<Integer>，无初始值，当numbers为空时，返回Optional.EMPTY\n   sum.orElseThrow(() -> new RuntimeException(\"no init value\"));\n}\n```\n\n<img src=\"https://java8-1253868755.cos.ap-guangzhou.myqcloud.com/java8-stream-reduce-sum.png\" width=\"500\">\n\n## 最大值和最小值\n```java\n@Test\npublic void maxMinTest() {\n   List<Integer> numbers = Arrays.asList(1, 2, 3, 4, 5);\n   assertEquals(Integer.valueOf(5), numbers.stream().reduce((x, y) -> Integer.max(x, y)).get());\n   // 方法引用，Lambda语法糖\n   assertEquals(Integer.valueOf(5), numbers.stream() // Stream<Integer>\n                                           .reduce(Integer::max) // Optional<Integer>\n                                           .get());\n   assertEquals(Integer.valueOf(1), numbers.stream().reduce(Integer::min).get());\n\n   assertEquals(Integer.valueOf(5), numbers.stream().max((x, y) -> x.compareTo(y)).get());\n   // 方法引用\n   assertEquals(Integer.valueOf(5), numbers.stream() // Stream<Integer>\n                                           .max(Integer::compareTo) // Optional<Integer>\n                                           .get());\n   assertEquals(Integer.valueOf(1), numbers.stream().min(Integer::compareTo).get());\n}\n```\n\n<img src=\"https://java8-1253868755.cos.ap-guangzhou.myqcloud.com/java8-stream-reduce-maxmin.png\" width=\"500\">\n\n\n## 总数\n```java\n@Test\npublic void countTest() {\n   List<Integer> numbers = Arrays.asList(1, 2, 3, 4, 5);\n   // Map-Reduce\n   assertEquals(Integer.valueOf(5), numbers.stream() // Stream<Integer>\n                                           .map(integer -> 1) // Stream<Integer>，Map\n                                           .reduce(0, Integer::sum)); // Integer，Reduce\n   // 通过reduce 实现与 count 一样的功能\n   assertEquals(5, numbers.stream().count());\n}\n```\n\n# 数值流\n1. 前面涉及到`Stream<String>`、`Stream<Integer>`的都是`对象流`，隐含`装箱`和`拆箱`成本\n2. `数值流`是`对象流的原始类型特化`，如 `IntStream`，没有`装箱`和`拆箱`成本\n\n```java\nList<Integer> numbers = Arrays.asList(1, 2, 3, 4, 5);\nStream<Integer> objStream = numbers.stream(); // 对象流，隐含装箱和拆箱成本\nOptional<Integer> reduce = objStream.reduce(Integer::max); // Optional<Integer>\nassertEquals(Integer.valueOf(5), reduce.get());\n\nIntStream intStream = numbers.stream().mapToInt(Integer::intValue);\nOptionalInt max = intStream.max();\nassertEquals(5, max.getAsInt()); // 数值流，没有装箱和拆箱成本\nStream<Integer> boxed = numbers.stream().mapToInt(Integer::intValue).boxed(); // 对象流\n```\n\n# 构建流\n\n## 有限流\n\n### 值\n```java\n@Test\npublic void buildFromValueTest() {\n   // <T> Stream<T> of(T... values)\n   Stream<String> stringStream = Stream.of(\"zhong\", \"ming\", \"mao\");\n   assertEquals(3, stringStream.count());\n\n   // <T> Stream<T> empty()\n   Stream<Object> objectStream = Stream.empty();\n   assertEquals(0, objectStream.count());\n\n   // IntStream of(int... values) { return Arrays.stream(values); }\n   IntStream intStream = IntStream.of(1, 2, 3);\n   assertEquals(3, intStream.max().getAsInt());\n}\n```\n\n### 数组\n```java\n@Test\npublic void buildFromArrayTest() {\n   int[] intArray = {1, 2, 3, 4, 5, 6, 7};\n   // IntStream stream(int[] array)\n   IntStream intStream = Arrays.stream(intArray);\n   assertEquals(3, intStream.filter(x -> x % 2 == 0).count());\n\n   Integer[] integerArray = {1, 2, 3, 4, 5, 6, 7};\n   // <T> Stream<T> stream(T[] array)\n   Stream<Integer> integerStream = Arrays.stream(integerArray);\n   assertEquals(4, integerStream.filter(x -> x % 2 == 1).count());\n}\n```\n\n### 文件\n```java\n@Test\npublic void buildFromFileTest() throws IOException {\n   String relativePath = \"/tmp.txt\"; // src/test/resources/tmp.txt\n   String absPath = this.getClass().getResource(relativePath).getPath(); // 绝对路径\n   // Stream<String> lines(Path path, Charset cs) throws IOException\n   Stream<String> stringStream = Files.lines(Paths.get(absPath), Charset.defaultCharset()); // Stream<String>，元素为文件中的每一行\n   assertEquals(9, stringStream.flatMap(s -> Arrays.stream(s.split(\"\\\\s+\"))) // 扁平化流，Stream<String>，元素为单词\n                               .distinct() // Stream<String>\n                               .count()); // long\n}\n```\n\n### range + rangeClosed\n```java\n@Test\npublic void buildFromRangeTest() {\n   IntStream intStream = IntStream.range(0, 10);\n   assertEquals(5, intStream.filter(value -> value % 2 == 0).count());\n\n   intStream = IntStream.rangeClosed(0, 10);\n   assertEquals(6, intStream.filter(value -> value % 2 == 0).count());\n}\n```\n## 无限流\n\n### iterate\n```java\n@Test\npublic void buildFromIterateTest() {\n   // 偶数数列\n   // <T> Stream<T> iterate(final T seed, final UnaryOperator<T> f)\n   Stream<Integer> integerStream = Stream.iterate(0, x -> x + 2);\n   assertEquals(20, integerStream.limit(5).mapToInt(Integer::intValue).sum());\n\n   // 偶数数列\n   // IntStream iterate(final int seed, final IntUnaryOperator f)\n   IntStream intStream = IntStream.iterate(0, x -> x + 2);\n   assertEquals(20, intStream.limit(5).sum());\n\n   // 斐波那契数列\n   Stream<int[]> intArrayStream = Stream.iterate(new int[]{0, 1}, // T\n                                                    fibArray -> new int[]{fibArray[1], fibArray[0] + fibArray[1]}); // UnaryOperator<T>\n   assertEquals(5, intArrayStream.mapToInt(fib -> fib[1]).limit(5).max().getAsInt());\n}\n```\n\n### generate\n```java\n@Test\npublic void buildFromGenerateTest() {\n   // <T> Stream<T> generate(Supplier<T> s)\n   Stream<Integer> integerStream = Stream.generate(() -> (int) (Math.random() * 1000));\n   // IntStream generate(IntSupplier s)\n   IntStream intStream = IntStream.generate(() -> (int) (Math.random() * 1000));\n\n   // 斐波那契数列\n   integerStream = Stream.generate(new Supplier<Integer>() {\n\n       private int pre = 0;\n       private int cur = 1;\n\n       @Override\n       public Integer get() {\n           int next = pre + cur;\n           pre = cur;\n           cur = next;\n           return pre;\n       }\n   });\n   assertEquals(5, integerStream.mapToInt(Integer::intValue).limit(5).max().getAsInt());\n\n   intStream = IntStream.generate(new IntSupplier() {\n       private int pre = 0;\n       private int cur = 1;\n\n       @Override\n       public int getAsInt() {\n           int next = pre + cur;\n           pre = cur;\n           cur = next;\n           return pre;\n       }\n   });\n   assertEquals(5, intStream.limit(5).max().getAsInt());\n}\n```\n\n# 收集\n`收集器`（`Collector`）会对`流中的元素`应用一个`转换函数`，并将结果`累积`在一个数据结构中\n\n## 汇总\n\n### 求和\n```java\n @Test\npublic void sumTest() {\n   List<Integer> integerList = Arrays.asList(1, 2, 3, 4, 5);\n   assertEquals(15,\n                  integerList.stream()\n                             .collect(Collectors.summingInt(Integer::intValue))\n                             .intValue());\n}\n```\n`<R, A> R collect(Collector<? super T, A, R> collector)`\n`<T> Collector<T, ?, Integer> summingInt(ToIntFunction<? super T> mapper)`\n\n<img src=\"https://java8-1253868755.cos.ap-guangzhou.myqcloud.com/java8-stream-collect-sum.png\" width=\"500\">\n\n\n### 总数\n```java\n@Test\npublic void countTest() {\n   List<Integer> integerList = Arrays.asList(1, 2, 3, 4, 5);\n   assertEquals(3,\n                integerList.stream().filter(n -> n % 2 == 1)\n                           .collect(Collectors.counting())\n                           .intValue());\n}\n```\n\n\n### 最大值最小值\n```java\n@Test\npublic void maxMinTest() {\n   List<Integer> integerList = Arrays.asList(1, 2, 3, 4, 5);\n   assertEquals(Integer.valueOf(5),\n                                integerList.stream().filter(n -> n % 2 == 1)\n                                           .collect(Collectors.maxBy(Comparator.comparingInt(Integer::intValue)))\n                                           .get());\n   assertEquals(Integer.valueOf(1),\n                                integerList.stream().filter(n -> n % 2 == 1)\n                                           .collect(Collectors.minBy(Comparator.comparing(Integer::intValue)))\n                                           .get());\n}\n```\n\n### 平均数\n```java\n@Test\npublic void avgTest() {\n   List<Integer> integerList = Arrays.asList(1, 2, 3, 4, 5);\n   assertEquals(Double.valueOf(\"3.0\"),\n                                     integerList.stream()\n                                                .collect(Collectors.averagingInt(Integer::intValue)));\n}\n```\n\n### 统计数\n```java\n@Test\npublic void statisticsTest() {\n   List<Integer> integerList = Arrays.asList(1, 2, 3, 4, 5);\n   IntSummaryStatistics statistics = integerList.stream()\n                                                .collect(Collectors.summarizingInt(Integer::intValue));\n   assertEquals(5, statistics.getCount());\n   assertEquals(5, statistics.getMax());\n   assertEquals(1, statistics.getMin());\n   assertEquals(15, statistics.getSum());\n   assertEquals(3, (int) statistics.getAverage());\n}\n```\n\n### 连接字符串\n```java\n@Test\npublic void joinStrTest() {\n\n   List<String> stringList = Arrays.asList(\"zhong\", \"ming\", \"mao\");\n   String delimiter = \",\";\n   String expectedStr = \"\";\n   for (int i = 0, len = stringList.size(); i < len; i++) {\n       expectedStr += stringList.get(i);\n       if (i != len - 1) {\n           expectedStr += delimiter;\n       }\n   }\n   assertEquals(expectedStr,\n                           stringList.stream()\n                                     .collect(Collectors.joining(\",\")));\n}\n```\n\n### 广义归约\n```java\nList<Integer> integerList = Arrays.asList(1, 2, 3, 4, 5);\n\n// <T> Collector<T, ?, Optional<T>> reducing(BinaryOperator<T> op)\nassertEquals(Integer.valueOf(15),\n                                integerList.stream()\n                                           .collect(Collectors.reducing(Integer::sum))\n                                           .get());\n\n// <T> Collector<T, ?, T> reducing(T identity, BinaryOperator<T> op)\nassertEquals(Integer.valueOf(25),\n                                integerList.stream()\n                                           .collect(Collectors.reducing(10, Integer::sum)));\n\n// <T, U> Collector<T, ?, U> reducing(U identity, Function<? super T, ? extends U> mapper, BinaryOperator<U> op)\nassertEquals(Integer.valueOf(50),\n                                integerList.stream()\n                                           .collect(Collectors.reducing(20, // identity\n                                                                        n -> n * 2, // mapper\n                                                                        Integer::sum))); // op\n```\n\n<img src=\"https://java8-1253868755.cos.ap-guangzhou.myqcloud.com/java8-stream-collect-reduce.png\" width=\"500\">\n\n\n## 分组\n\n### 单级分组\n```java\n@Test\npublic void singleGroupTest() {\n   List<User> users = Arrays.asList(new User(\"a\", 10, true),\n                new User(\"b\", 20, true), new User(\"c\", 30, false),\n                new User(\"d\", 40, false), new User(\"e\", 50, false),\n                new User(\"f\", 60, false), new User(\"g\", 70, false));\n   // <T, K> Collector<T, ?,Map<K, List<T>>> groupingBy(Function<? super T, ? extends K> classifier)\n   Map<Boolean, List<User>> listMap = users.stream()\n                                           .collect(Collectors.groupingBy(User::isStudent));\n   assertEquals(2, listMap.size());\n   assertEquals(5, listMap.get(false).size());\n   assertEquals(2, listMap.get(true).size());\n}\n```\n\n### 多级分组\n```java\n@Test\npublic void multiGroupTest() {\n    List<User> users = Arrays.asList(new User(\"a\", 10, true),\n                new User(\"b\", 20, true), new User(\"c\", 30, false),\n                new User(\"d\", 40, false), new User(\"e\", 50, false),\n                new User(\"f\", 60, false), new User(\"g\", 70, false));\n   // <T, K, A, D> Collector<T, ?, Map<K, D>> groupingBy(Function<? super T, ? extends K> classifier, Collector<? super T, A, D> downstream)\n   Map<User.TYPE, Map<Boolean, List<User>>> mapMap =\n   users.stream().collect(\n            Collectors.groupingBy(user -> user.getAge() > 50 ? User.TYPE.OLD : User.TYPE.YOUNG, // 第一层 Key\n            Collectors.groupingBy(User::isStudent))); // 第二层 Key\n\n   assertEquals(2, mapMap.size());\n   assertEquals(1, mapMap.get(User.TYPE.OLD).size());\n   assertEquals(2, mapMap.get(User.TYPE.YOUNG).size());\n   assertFalse(mapMap.get(User.TYPE.OLD).containsKey(Boolean.TRUE));\n   assertEquals(2, mapMap.get(User.TYPE.OLD).get(Boolean.FALSE).size());\n   assertEquals(2, mapMap.get(User.TYPE.YOUNG).get(Boolean.TRUE).size());\n   assertEquals(3, mapMap.get(User.TYPE.YOUNG).get(Boolean.FALSE).size());\n}\n```\n\n### 按子组收集\n```java\n@Test\npublic void groupCollectTest() {\n   Map<User.TYPE, Long> typeLongMap = users.stream().collect(\n                                            Collectors.groupingBy(user -> user.getAge() > 50 ? User.TYPE.OLD : User.TYPE.YOUNG,\n                                            Collectors.counting())); // 子组内总数\n   assertEquals(2, typeLongMap.size());\n   assertEquals(2, typeLongMap.get(User.TYPE.OLD).intValue());\n   assertEquals(5, typeLongMap.get(User.TYPE.YOUNG).intValue());\n\n   Map<User.TYPE, Double> typeDoubleMap = users.stream().collect(\n                                            Collectors.groupingBy(user -> user.getAge() > 50 ? User.TYPE.OLD : User.TYPE.YOUNG,\n                                            Collectors.averagingInt(User::getAge))); // 子组内平均年龄\n   assertEquals(2, typeDoubleMap.size());\n   assertEquals(1, typeDoubleMap.get(User.TYPE.OLD).compareTo(typeDoubleMap.get(User.TYPE.YOUNG)));\n}\n```\n\n## 分区\n```java\n@Test\npublic void partitioningTest() {\n   Map<Boolean, List<User>> listMap = users.stream().collect(\n                                            Collectors.partitioningBy(User::isStudent));\n   assertEquals(2, listMap.size());\n   assertEquals(2, listMap.get(Boolean.TRUE).size());\n   assertEquals(5, listMap.get(Boolean.FALSE).size());\n\n   Map<Boolean, Map<Boolean, List<User>>> map = users.stream().collect(\n                                            Collectors.partitioningBy(user -> user.getAge() > 50 ? true : false,\n                                            Collectors.partitioningBy(User::isStudent)));\n   assertEquals(2, map.size());\n   assertEquals(2, map.get(Boolean.TRUE).size());\n   assertEquals(2, map.get(Boolean.FALSE).size());\n   assertEquals(2, map.get(Boolean.FALSE).get(Boolean.TRUE).size());\n   assertEquals(3, map.get(Boolean.FALSE).get(Boolean.FALSE).size());\n}\n```\n\n## 收集器\n\n### 接口定义\n```java\npublic interface Collector<T, A, R> {\n    // T：流中的元素； A：用于累加器处理对象的类型； R：返回类型\n    Supplier<A> supplier(); // 生成累加器\n    BiConsumer<A, T> accumulator(); // 累加操作\n    BinaryOperator<A> combiner(); // 合并操作，对流的子部分如何进行并行合并\n    Function<A, R> finisher(); // 最终转换\n    Set<Characteristics> characteristics(); // 定义收集器的行为\n\n    enum Characteristics { // 不是很理解，请大神指教\n        CONCURRENT,\n        UNORDERED,\n        IDENTITY_FINISH\n    }\n}\n```\n\n### 自定义收集器\n```java\n// 自定义收集器，最终转换为 Set<T>\npublic class CustomCollector<T> implements Collector<T, List<T>, Set<T>> {\n\n    @Override\n    public Supplier<List<T>> supplier() {\n        // 累加器实例\n        return ArrayList::new;\n    }\n\n    @Override\n    public BiConsumer<List<T>, T> accumulator() {\n        // 将流中的元素添加到容器\n        return List::add;\n    }\n\n    @Override\n    public BinaryOperator<List<T>> combiner() {\n        // 合并两个（部分）结果容器，主要用于并发\n        return (list1, list2) -> {\n            list1.addAll(list2);\n            return list1;\n        };\n    }\n\n    @Override\n    public Function<List<T>, Set<T>> finisher() {\n        // 对结果容器的最终转换\n        return list -> {\n            Set<T> finalSet = new HashSet<>();\n            finalSet.addAll(list);\n            return finalSet;\n        };\n    }\n\n    @Override\n    public Set<Characteristics> characteristics() {\n        return Collections.unmodifiableSet(EnumSet.of(Characteristics.CONCURRENT));\n    }\n}\n```\n```java\n@Test\npublic void customCollectorTest() {\n   List<Integer> integerList = Arrays.asList(1, 2, 3, 4, 3, 2, 1);\n   Set<Integer> set = integerList.stream().collect(new CustomCollector<>());\n   assertEquals(4, set.size());\n}\n```\n\n# 并行流\n这里仅简单介绍`并行流的使用`，平时一般不使用（因为数据量往往不够大，发挥并行优势有比较多的限制条件，`顺序流`基本能应付日常开发的需求）\n\n## 简单使用\n```java\npublic static long sum(int m) {\n   return Stream.iterate(1, n -> n + 1).limit(m)\n           .parallel() // 标记为顺序流，只是设置boolean标志位， 只有最后一个parallel或sequential有意义\n           .filter(n -> n % 2 == 0)\n           .sequential() // 标记为并行流，冗余设置\n           .map(integer -> integer * 3)\n           .parallel() // 最后一个parallel或sequential影响整个流水线\n           .reduce(0, Integer::sum);\n}\n```\n\n## 性能比较\n```java\npublic static int iterativeSum(int n) {\n   // 原始类型，无需拆箱和装箱操作\n   int result = 0;\n   for (int i = 0; i < n; i++) {\n       result += i;\n   }\n   return result;\n}\n\npublic static int sequentialSum(int m) {\n   // 对象顺序流，需要拆箱和装箱操作\n   return Stream.iterate(0, n -> n + 1).limit(m).reduce(0, Integer::sum);\n}\n\npublic static int iterativeParallelSum(int m) {\n   // 对象并行流，需要拆箱和装箱操作\n   // 很难将iterate操作划分成独立块来并行处理，因为每次计算依赖上一次的计算结果\n   // 将流标记为并行，反而增加了开销\n   // 最慢\n   return Stream.iterate(0, n -> n + 1).limit(m).parallel().reduce(0, Integer::sum);\n}\n\npublic static int rangesequentialSum(int m) {\n   // 数值顺序流，无需拆箱和装箱操作\n   // 比iterativeParallelSum快 -> 首先选择合适的数据结构，再考虑是否使用并行流\n   return IntStream.range(0, m).reduce(0, Integer::sum);\n}\n\npublic static int rangeParallelSum(int m) {\n   // 数值并行流，无需拆箱和装箱操作\n   // range操作能够很方便地进行并行处理（RangeIntSpliterator，属于内部原理 Fork/Join的范畴，后续研究）\n   // 最快\n   return IntStream.range(0, m).parallel().reduce(0, Integer::sum);\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["Java"],"categories":["SE8"]},{"title":"Java 8 -- Lambda","url":"%2F2017%2F05%2F29%2Fjava8-lambda%2F","content":"\n{% note info %}\n本文主要介绍`Java 8`的 `Lambda` 表达式的简单使用\n{% endnote %}\n\n<!-- more -->\n\n# 基本语法\n```\n(parameters) -> expression\n(parameters) -> {statements;}\n```\n## Apple\n相关代码托管在[java8_demo](https://github.com/zhongmingmao/java8_demo)\n```java\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\npublic class Apple {\n    public static enum COLOR { GREEN, RED }\n    public static final int HEAVY_WEIGHT = 200;\n    private COLOR color;\n    private Integer weight;\n}\n```\n\n## 实例\n```java\n(String s) -> s.length()\n// 等价于\nint f(String s){ return s.length(); }\n\n(Apple a) -> a.getWeight() > Apple.HEAVY_WEIGHT\n// 等价于\nboolean f(Apple a){ return a.getWeight() > Apple.HEAVY_WEIGHT; }\n\n(int x, int y) -> {\n    System.out.println(\"Result:\");\n    Syetem.out.println(x+y;\n}\n// 等价于\nvoid f(int x, int y){\n    System.out.println(\"Result:\");\n    Syetem.out.println(x+y;\n}\n\n() -> 42\n// 等价于\nint f(){ return 42; }\n\n(Apple a1 , Apple a2) -> a1.getWeight() > a2.getWeight\n// 等价于\nboolean f(Apple a1 , Apple a2){ return a1.getWeight() > a2.getWeight;}\n```\n\n# 函数式接口 + 函数描述符\n\n## 函数式接口\n1. 定义：只定义了`一个抽象方法`（排除 `default` 方法）的接口\n2. 用途：`Lambda` 表达式允许直接以`内联`的形式，`为函数式接口的抽象方法提供实现`，并把整个表达式作为`函数式接口的实例`\n\n## 函数描述符\n1. 定义：`函数式接口的抽象方法的签名`\n2. `函数描述符` = `函数式接口的抽象方法的签名` = `Lambda表达式的签名`\n\n## Lambda 出现的地方\n1. 赋值给一个变量（类型为`函数式接口`）\n2. 传递给一个接受`函数式接口为参数的方法`\n\n# 自定义函数式接口\n\n## 函数式接口\n```java\n@FunctionalInterface\npublic interface Change { // 只有一个抽象方法\n    Integer action(Integer param);\n}\n```\n函数描述符：`Integer -> Integer`\n\n## 单元测试\n```java\nprivate int localChange(int param, Change change) {\n   return change.action(param);\n}\n\n@Test\npublic void multipyTest() {\n   // Lambda 能够赋值给一个函数式接口的变量（前提是函数式接口的抽象方法的签名 = Lambda 表达式的签名）\n   Change multiply = param -> param * 3;\n   assertEquals(15, localChange(5, multiply));\n   // Lambda 能够传递给一个接受函数式接口为参数的方法（前提是函数式接口的抽象方法的签名 = Lambda 表达式的签名）\n   assertEquals(4, localChange(3, param -> param + 1));\n}\n```\n\n\n# 常用内置函数式接口\n\n| 函数式接口 | 函数描述符 |\n| --- | --- |\n| `Predicate<T>` | T -> boolean |\n| `Consumer<T>` | T -> void |\n| `Supplier<T>` | () -> T |\n| `Function<T,R>`  | T -> R  |\n| `BiFunction<T,U,R>` | (T,U) -> R |\n| `BiPredicate<T,U>` | (T,U) -> boolean |\n| `BinaryOperator<T> extends BiFunction<T,T,T>` | (T,T) -> T |\n| `BiConsumer<T,U>` | (T,U) -> void |\n| `UnaryOperator<T> extends Function<T,T>` | T -> T |\n\n## Predicate<T>\n\n### 定义\n```java\n@FunctionalInterface\npublic interface Predicate<T> {\n    boolean test(T t);\n}\n```\n函数描述符：`T -> boolean`\n\n### 实例\n```java\nprivate <T> List<T> predicate(List<T> list, Predicate<T> predicate) {\n   List<T> result = new ArrayList<>();\n   for (T t : list) {\n       if (predicate.test(t)) {\n           result.add(t);\n       }\n   }\n   return result;\n}\n\n@Test\npublic void predicateTest() {\n   assertEquals(2, predicate(Arrays.asList(\"zhongmingmao\", \"\", null),\n           s -> null == s || s.isEmpty()).size());\n}\n```\n\n## Consumer<T>\n\n### 定义\n```java\n@FunctionalInterface\npublic interface Consumer<T> {\n    void accept(T t);\n}\n```\n函数描述符：`T -> void`\n\n### 实例\n```java\nprivate <T> void consume(List<T> list, Consumer<T> consumer) {\n   for (T t : list) {\n       consumer.accept(t);\n   }\n}\n\n@Test\npublic void consumerTest() {\n   consume(Arrays.asList(1, 2, 3), integer -> System.out.println(integer));\n}\n```\n\n## Supplier<T>\n\n### 定义\n```java\n@FunctionalInterface\npublic interface Supplier<T> {\n    T get();\n}\n```\n函数描述符：`() -> T`\n\n### 实例\n```java\nprivate <T> T supply(Supplier<T> supplier) {\n   return supplier.get();\n}\n\n@Test\npublic void supplierTest() {\n   assertEquals(LocalDate.now(), supply(() -> LocalDate.now()));\n}\n```\n\n## Function<T,R>\n### 定义\n```java\n@FunctionalInterface\npublic interface Function<T, R> {\n    R apply(T t);\n}\n```\n函数描述符：`T -> R`\n\n### 实例\n```java\nprivate <T, R> R function(T t, Function<T, R> func) {\n   return func.apply(t);\n}\n\n@Test\npublic void functionTest() {\n   assertEquals(Integer.valueOf(12), function(Integer.valueOf(4), integer -> integer * 3));\n}\n```\n\n## BiFunction<T, U, R>\n\n### 定义\n```java\n@FunctionalInterface\npublic interface BiFunction<T, U, R> {\n    R apply(T t, U u);\n}\n```\n函数描述符：`(T,U) -> R`\n\n### 实例\n```java\nprivate <T, U, R> R biFunction(T t, U u, BiFunction<T, U, R> biFunc) {\n   return biFunc.apply(t, u);\n}\n\n@Test\npublic void biFunctionTest() {\n   assertEquals(\"40\", biFunction(4, \"0\", (integer, s) -> integer + s));\n}\n```\n\n## BiPredicate<T, U>\n\n### 定义\n```java\n@FunctionalInterface\npublic interface BiPredicate<T, U> {\n    boolean test(T t, U u);\n}\n```\n函数描述符：`(T,U) -> boolean`\n\n### 实例\n```java\nprivate <T, U> boolean biPredicate(T t, U u, BiPredicate<T, U> biPred) {\n   return biPred.test(t, u);\n}\n\n@Test\npublic void biPredicateTest() {\n   assertTrue(biPredicate(4, \"zhognmingmao\", (integer, s) -> null != s && s.length() > integer));\n}\n```\n\n## BinaryOperator<T>\n\n### 定义\n```java\n@FunctionalInterface\npublic interface BinaryOperator<T> extends BiFunction<T,T,T> {\n}\n```\n函数描述符：`(T,T) -> T`\n\n### 实例\n```java\nprivate <T> T binaryOperator(T t, BinaryOperator<T> bOp) {\n   return bOp.apply(t, t);\n}\n\n@Test\npublic void binaryOperatorTest() {\n   assertEquals(Integer.valueOf(16), binaryOperator(4, (integer, integer2) -> integer * integer2));\n}\n```\n\n## BiConsumer<T, U>\n\n### 定义\n```java\n@FunctionalInterface\npublic interface BiConsumer<T, U> {\n    void accept(T t, U u);\n}\n```\n函数描述符：`(T,U) -> void`\n\n### 实例\n```java\nprivate <T, U> void biConsumer(T t, U u, BiConsumer<T, U> bCon) {\n   bCon.accept(t, u);\n}\n\n@Test\npublic void biConsumerTest() {\n   biConsumer(4, \"zhongmingmao\", (integer, s) -> System.out.println(integer + s.length()));\n}\n```\n\n## UnaryOperator<T>\n\n### 定义\n```java\n@FunctionalInterface\npublic interface UnaryOperator<T> extends Function<T, T> {\n}\n```\n函数描述符：`T -> T`\n\n### 实例\n```java\nprivate <T> T unaryOperator(T t, UnaryOperator<T> uOp) {\n   return uOp.apply(t);\n}\n\n@Test\npublic void unaryOperatorTest() {\n   assertEquals(\"zhongmingmao\" , unaryOperator(\"zhongming\" , s -> s + \"mao\"));\n}\n```\n\n## IntPredicate\n1. `IntPredicate`是`Predicate<Integer>`的**`原始类型特化`**，节省了`自动装箱`和`自动拆箱`的开销\n2. 类似函数式接口的还有 `LongPredicate`、`IntFunction<R>` 等\n\n### 定义\n```java\n@FunctionalInterface\npublic interface IntPredicate {\n    boolean test(int value);\n}\n```\n\n### 实例\n```java\n@Test\npublic void intPredicateTest() {\n   IntPredicate intPredicate = value -> value % 2 == 0;\n   Predicate<Integer> integerPredicate = integer -> integer % 2 == 0;\n\n   int max = 1 << 30;\n   long p1 = System.currentTimeMillis();\n   for (int i = 0; i < max; i++) {\n       intPredicate.test(i);\n   }\n   long p2 = System.currentTimeMillis();\n   for (int i = 0; i < max; i++) {\n       integerPredicate.test(i);\n   }\n   long p3 = System.currentTimeMillis();\n   System.out.println((p3 - p2) / (p2 - p1 + 0.0)); // 本地结果在100~220之间\n   assertTrue((p3 - p2) > (p2 - p1));\n}\n```\n\n# 类型检查\n\n引用上面的例子进行分析\n```java\n// 函数定义\nprivate <T> List<T> predicate(List<T> list, Predicate<T> predicate) {...}\n// 函数调用\npredicate(Arrays.asList(\"zhongmingmao\", \"\", null), s -> null == s || s.isEmpty()).size());\n```\n1. 函数定义中形参为`Predicate<T> predicate`\n2. `Predicate<T>`中的抽象函数的签名为`boolean test(T t)`，因此`Predicate<T>`的`函数描述符`为`T -> boolean`\n3. 函数调用中 `Lambda` 的`签名`为`String -> boolean`与`Predicate<T>`的`函数描述符`匹配，类型检查通过\n\n# 方法引用\n\n`方法引用`是`Lambda`的一种`快捷写法`（**`语法糖`**）\n\n## 静态方法\n1. Lambda：`(args) -> ClassName.staticMethod(args)`\n2. 方法引用：`ClassName::staticMethod`\n\n```java\nFunction<String, Integer> str2Integer = s -> Integer.parseInt(s);\nstr2Integer = Integer::parseInt;\n```\n\n## 任意类型的实例方法\n1. Lambda：`(arg0,rest) -> arg0.instanceMethod(rest)`（`arg0`是 `ClassName` 类型）\n2. 方法引用：`ClassName::instanceMethod`\n\n```java\nBiPredicate<List<String>, String> contains = (strings, s) -> strings.contains(s);\ncontains = List::contains;\n```\n\n## 现有对象的实例方法\n1. Lambda：`(args) -> expr.instanceMethod(args)`\n2. 方法引用：`expr::instanceMethod`\n\n```java\nList<String> list = Arrays.asList(\"a\", \"b\", \"A\", \"B\");\nPredicate<String> contain = s -> list.contains(s);\ncontain = list::contains;\n```\n\n## 构造函数\n```java\nSupplier<Apple> c1 = () -> new Apple();\nc1 = Apple::new;// 默认构造函数\nApple apple = c1.get();\n\nBiFunction<Apple.COLOR, Integer, Apple> c2 = (color, integer) -> new Apple(color, integer);\nc2 = Apple::new;// 2个参数构造函数\napple = c2.apply(Apple.COLOR.GREEN, Integer.valueOf(200));\n```\n\n# 复合Lambda\n\n## Comparator复合\n```java\n@FunctionalInterface\npublic interface Comparator<T> {\n    int compare(T o1, T o2);\n}\n\n// <T, U extends Comparable<? super U>> Comparator<T> comparing(\n// Function<? super T, ? extends U> keyExtractor)\nComparator<Apple> comparator = Comparator.comparing(Apple::getWeight); // Apple -> Integer\nComparator<Apple> reversedComparetor = comparator.reversed();\nComparator<Apple> linkedComparator = Comparator.comparing(Apple::getWeight).reversed()\n                                              .thenComparing(Apple::getColor).reversed();\n```\n\n## Predicate复合\n```java\nPredicate<Apple> greenApple = apple -> Apple.COLOR.GREEN.equals(apple.getColor());\nPredicate<Apple> notGreenApple = greenApple.negate();\nPredicate<Apple> heavyApple = apple -> apple.getWeight() > Apple.HEAVY_WEIGHT;\nPredicate<Apple> greenAndHeavyApple = greenApple.and(heavyApple);\nPredicate<Apple> redApple = apple -> Apple.COLOR.RED.equals(apple.getColor());\nPredicate<Apple> greenAndHeavyOrRedApple = greenAndHeavyApple.or(redApple);\n// 优先级从左至右，（red or green） and heavy\nPredicate<Apple> redOrGreenAndHeavyApple = redApple.or(greenApple).and(heavyApple);\n```\n\n## Function复合\n```java\nFunction<Integer, Integer> f = integer -> integer + 1;\nFunction<Integer, Integer> g = integer -> integer * 2;\nFunction<Integer, Integer> h = f.andThen(g); // g(f(x)) = (x+1)*2\nFunction<Integer, Integer> i = g.andThen(f); // f(g(x)) = (x*2)+1\n```\n\n\n\n\n\n<!-- indicate-the-source -->\n","tags":["Lambda"],"categories":["SE8"]},{"title":"Java 8 -- 行为参数化","url":"%2F2017%2F05%2F28%2Fjava8-behavioral-parameterization%2F","content":"\n{% note info %}\n本文主要介绍`行为参数化`\n{% endnote %}\n\n<!-- more -->\n\n# 基础概念\n1. 行为参数化：将方法或代码作为`参数或值`进行传递\n2. 谓词：一个返回 `boolean` 值的函数，在 `Java8` 中是一个`函数式接口`（`java.util.function.Predicate`）\n\n# 代码实例\n目录结构如下，相关代码托管在[java8_demo](https://github.com/zhongmingmao/java8_demo)\n\n```\n├── main\n│   └── java\n│       └── me\n│           └── zhongmingmao\n│               ├── domain\n│               │   └── Apple.java\n│               ├── filter\n│               │   ├── FilterJava7.java\n│               │   └── FilterJava8.java\n│               └── predicate\n│                   ├── java7\n│                   │   ├── ColorPredicate.java\n│                   │   ├── PredicateJava7.java\n│                   │   └── WeightPredicate.java\n│                   └── java8\n│                       └── PredicateJava8.java\n└── test\n    └── java\n        └── me\n            └── zhongmingmao\n                └── predicate\n                    └── PredicateJavaTest.java\n```\n\n## Java7 + 策略模式\n\n### Apple\n```java\n@Data\n@AllArgsConstructor\npublic class Apple {\n    public enum COLOR { GREEN, RED }\n    public static final int HEAVY_WEIGHT = 200;\n    private COLOR color;    \n    private int weight;\n}\n```\n\n### PredicateJava7\n```java\npublic interface PredicateJava7 { // 函数式接口\n    boolean test(Apple apple);\n}\n```\n\n### ColorPredicate\n```java\npublic class ColorPredicate implements PredicateJava7 { // 模板代码\n    public boolean test(Apple apple) { // 模板代码\n        // 实际的策略代码\n        return null == apple ? false : Apple.COLOR.GREEN.equals(apple.getColor());\n    }\n}\n```\n\n### WeightPredicate\n```java\npublic class WeightPredicate implements PredicateJava7 { // 模板代码\n    public boolean test(Apple apple) { // 模板代码\n        // 实际的策略代码\n        return null == apple ? false : apple.getWeight() > Apple.HEAVY_WEIGHT;\n    }\n}\n```\n\n### FilterJava7\n```java\npublic class FilterJava7 {\n    public static List<Apple> filterJava7(List<Apple> apples, PredicateJava7 predicateJava7) {\n        List<Apple> result = new ArrayList<Apple>();\n        for (Apple apple : apples) {\n            if (predicateJava7.test(apple)) {\n                result.add(apple);\n            }\n        }\n        return result;\n    }\n}\n```\n\n### PredicateJavaTest\n```java\npublic class PredicateJavaTest {\n\n    private List<Apple> apples = null;\n\n    @Before\n    public void setUp() {\n        apples = Arrays.asList(new Apple(Apple.COLOR.GREEN, 100), new Apple(Apple.COLOR.RED, 300));\n    }\n\n    @Test\n    public void predicateJava7Test() {\n        assertEquals(1, FilterJava7.filterJava7(apples, new ColorPredicate()).size());\n        assertEquals(1, FilterJava7.filterJava7(apples, new WeightPredicate()).size());\n    }\n}\n```\n\n从`ColorPredicate`和`WeightPredicate`可以看出，每实现一个策略都会需要重复相应的`模板代码`\n\n## Java8 + Lambda + 泛型\n\n### PredicateJava8\n```java\npublic interface PredicateJava8<T> { // 函数式接口 + 泛型\n    boolean test(T t);\n}\n```\n\n### FilterJava8\n```java\npublic class FilterJava8 {\n\n    public static <T> List<T> filterJava8(List<T> list, PredicateJava8<T> predicateJava8) {\n        List<T> result = new ArrayList<T>();\n        for (T t : list) {\n            if (predicateJava8.test(t)) {\n                result.add(t);\n            }\n        }\n        return result;\n    }\n}\n```\n与`FilterJava7`，相比仅仅是引入了泛型\n\n### PredicateJavaTest\n增加测试用例`predicateJava8Test`\n```java\n@Test\npublic void predicateJava8Test() {\n    // Lambda 表达式\n    assertEquals(1, FilterJava8.filterJava8(apples, (Apple apple) -> Apple.COLOR.GREEN.equals(apple.getColor())).size());\n    assertEquals(1, FilterJava8.filterJava8(apples, apple -> apple.getWeight() > Apple.HEAVY_WEIGHT).size());\n}\n```\n\n采用 `Lambda` 表达式实现`行为参数化`无需先定义相应的策略，减少`模板代码`的产生\n\n<!-- indicate-the-source -->\n","tags":["Java"],"categories":["SE8"]},{"title":"InnoDB -- 事务隔离级别","url":"%2F2017%2F05%2F21%2Finnodb-isolation-level%2F","content":"\n{% note info %}\n本文主要介绍`InnoDB`的`事务隔离级别`\n关于`Next-Key Lock`的内容，请参照「InnoDB备忘录 - Next-Key Lock」，这里不再赘述\n{% endnote %}\n\n<!-- more -->\n\n# 脏读、不可重复读、幻读\n\n## 脏读\n在不同的事务下，当前事务可以读到其它事务中`尚未提交`的数据，即可以读到`脏数据`\n\n## 不可重复读\n在同一个事务中，同一个查询在T1时间读取某一行，在T2时间重新读取这一行时候，这一行的数据已经发生修改，不可重复读的重点是修改（`Update`）\n\n## 幻读\n在同一事务中，同一查询多次进行，由于包含插入或删除操作的其他事务提交，导致每次返回不同的结果集，幻读的重点在于插入（`Insert`）或者删除(`Delete`)\n\n# 两类读操作\n\n## 一致性非锁定读\n1. `InnoDB`通过行`多版本控制`的方式来读取当前执行时间数据中行的数据，如果读取的行正在执行`DELETE`或`UPDATE`操作，这时读操作`不会等待行上锁的释放`，而是读取行的一个`快照数据`\n2. `非锁定读机`制极大地提高了数据库的`并发性`，这是`InnoDB默认的读取方式`\n3. `READ COMMITED`和`REPEATABLE READ`支持`一致性非锁定读`：在`READ COMMITED`下，总是读取被锁定行的`最新的快照数据`，在`REPEATABLE READ`下，总是读取`事务开始时的快照数据`\n\n## 一致性锁定读\n对数据库读操作进行`显式加锁`以保证数据逻辑的`一致性`，有两种方式：`SELECT…FOR UPDATE`对读取的行记录加一个`X Lock`；`SELECT…LOCK IN SHARE MODE`对读取的行记录加一个`S Lock`\n\n# 隔离级别\n\n## 级别与问题\n`✓`：可能出现   `✗`：不会出现\n\n| 隔离级别         | 脏读 | 不可重复读 | 幻读 |\n| ---------------- | ---- | ---------- | ---- |\n| READ UNCOMMITTED | ✓    | ✓          | ✓    |\n| READ COMMITTED   | ✗    | ✓          | ✓    |\n| REPEATABLE READ  | ✗    | ✗          | ✓    |\n| SERIALIZABLE     | ✗    | ✗          | ✗    |\n\n## 实例\n\n### RUC与脏读\n`READ-UNCOMMITTED`存在`脏读`问题\n\n#### Session A\n```sql\nmysql> CREATE TABLE t (\n    -> a INT NOT NULL PRIMARY KEY,\n    -> b INT NOT NULL\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.05 sec)\n\nmysql> INSERT INTO t SELECT 1,1;\nQuery OK, 1 row affected (0.02 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> SET SESSION TX_ISOLATION='READ-UNCOMMITTED';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql>BEGIN;\nQuery OK, 0 rows affected (0.20 sec)\n\nmysql> SELECT * FROM t;\n+---+---+\n| a | b |\n+---+---+\n| 1 | 1 |\n+---+---+\n1 row in set (0.00 sec)\n```\n\n#### Session B\n```sql\nmysql> SET SESSION TX_ISOLATION='READ-UNCOMMITTED';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> UPDATE t SET b=2 WHERE a=1;\nQuery OK, 1 row affected (0.01 sec)\nRows matched: 1  Changed: 1  Warnings: 0\n```\n`Session B`将记录从`(1,1)`更新为`(1,2)`，因此持有了该记录的`X Lock`\n\n#### Session A\n```sql\nmysql> SELECT * FROM t;\n+---+---+\n| a | b |\n+---+---+\n| 1 | 2 |\n+---+---+\n1 row in set (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a=1 FOR UPDATE; # 一致性锁定，阻塞一段时间后超时\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n```\n`Session A`读到了`Session B`尚未提交的数据，属于`脏读`\n`Session A`尝试持有记录的`X Lock`，此时该`X Lock`的持有者为`Session B`，`Session A`被阻塞\n\n#### Session B\n事务和锁的详细信息如下\n```sql\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1328837 | LOCK WAIT | 1328837:463:3:2       | READ UNCOMMITTED    |\n| 1328836 | RUNNING   | NULL                  | READ UNCOMMITTED    |\n+---------+-----------+-----------------------+---------------------+\n2 rows in set (0.00 sec)\n\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1328837:463:3:2 | 1328837     | X         | RECORD    | `test`.`t` | PRIMARY    |        463 |         3 |        2 | 1         |\n| 1328836:463:3:2 | 1328836     | X         | RECORD    | `test`.`t` | PRIMARY    |        463 |         3 |        2 | 1         |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> SELECT * FROM information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1328837           | 1328837:463:3:2   | 1328836         | 1328836:463:3:2  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n```\n\n### RC与不可重复读\n`READ-COMMITTED`解决了`READ-UNCOMMITTED`存在的`脏读`问题，解决方法是采用`一致性非锁定读`，读取`最新的快照版本`，但仍然存在`不可重复读`问题\n\n#### Session A\n```sql\nmysql> CREATE TABLE t (\n    -> a INT NOT NULL PRIMARY KEY,\n    -> b INT NOT NULL\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.05 sec)\n\nmysql> INSERT INTO t SELECT 1,1;\nQuery OK, 1 row affected (0.02 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> SET SESSION TX_ISOLATION='READ-COMMITTED';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql>BEGIN;\nQuery OK, 0 rows affected (0.20 sec)\n\nmysql> SELECT * FROM t;\n+---+---+\n| a | b |\n+---+---+\n| 1 | 1 |\n+---+---+\n1 row in set (0.00 sec)\n```\n\n#### Session B\n```sql\nmysql> SET SESSION TX_ISOLATION='READ-COMMITTED';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> UPDATE t SET b=2 WHERE a=1;\nQuery OK, 1 row affected (0.01 sec)\nRows matched: 1  Changed: 1  Warnings: 0\n```\n`Session B`将记录从`(1,1)`更新为`(1,2)`，因此持有了该记录的`X Lock`\n\n#### Session A\n```sql\nmysql> SELECT * FROM t; # 一致性非锁定读\n+---+---+\n| a | b |\n+---+---+\n| 1 | 1 |\n+---+---+\n1 row in set (0.00 sec)\n\nmysql> SELECT * FROM t FOR UPDATE; # 一致性锁定，阻塞一段时间后超时\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n```\n`Session A`采用`一致性非锁定读`，而`Session B`尚未提交，因此`Session A`能读取到的`最新快照版本`依然为`(1,1)`，解决了`READ-UNCOMMITTED`的`脏读`问题\n\n#### Session B\n```sql\nmysql> COMMIT; # 提交事务\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n#### Session A\n```sql\nmysql> SELECT * FROM t;\n+---+---+\n| a | b |\n+---+---+\n| 1 | 2 |\n+---+---+\n1 row in set (0.00 sec)\n```\n`Session B`提交事务后，`Session A`能读取到最新的快照版本`(1,2)`，而`Session A`尚未提交事务，初始快照版本为`(1,1)`，属于`不可重复读`\n\n### RR与幻读\n1. `REPEATABLE-READ`解决了`READ-COMMITTED`存在的`不可重复读`问题，解决方法是采用`一致性非锁定读`，读取`事务初始时的快照版本`，但这样仍然存在`幻读`问题\n2. **`REPEATABLE-READ`结合`Next-Key Lock`，可以解决`幻读`问题**。`幻读`问题关注的是`Insert`和`Delete`，而`Next-Key Locking = Record Lock + Gap Lock`，`Gap Lock`可以防止`Insert`，`Record Lock`可以防止`Delete`。（关于`Next-Key Locking`的详细内容，请参照博文「InnoDB备忘录 - Next-Key Lock」）\n3. 在`REPEATABLE-READ`下，`MVCC`可以这样理解：**`MV(Multi Version)`用于解决`脏读`和`不可重复读`**，而**`CC(Concurrency Control)`则是利用`Next-Key Lock`解决`幻读`问题**\n4. `REPEATABLE READ`为`InnoDB`的`默认事务隔离级别`，`REPEATABLE READ`已经完全保证事务的`隔离性`要求，即达到`SERIALIZABLE`隔离级别\n5. 隔离级别越低，`事务请求的锁`越少或`保持锁的时间`就越短，因此大多数数据库系统（`Oracle`、`SQL Server`）的默认事务隔离级别是`READ COMMITTED`\n6. `InnoDB`中选择`REPEATABLE READ`的事务隔离级别`不会有任何性能的损失`，同样地，即使使用`READ COMMITTED`的隔离级别，用户也`不会得到性能上的大幅度提升`\n\n#### Session A\n```sql\nmysql> CREATE TABLE t (\n    -> a INT NOT NULL PRIMARY KEY,\n    -> b INT NOT NULL\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.05 sec)\n\nmysql> INSERT INTO t VALUES (10,10),(20,20),(30,30);\nQuery OK, 3 row affected (0.02 sec)\nRecords: 3  Duplicates: 0  Warnings: 0\n\nmysql> SET SESSION TX_ISOLATION='REPEATABLE-READ';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql>BEGIN;\nQuery OK, 0 rows affected (0.20 sec)\n\nmysql> SELECT * FROM t WHERE a < 25; # 一致性非锁定读\n+----+----+\n| a  | b  |\n+----+----+\n| 10 | 10 |\n| 20 | 20 |\n+----+----+\n2 rows in set (0.00 sec)\n```\n\n#### Session B\n```sql\nmysql> SET SESSION TX_ISOLATION='REPEATABLE-READ';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql>BEGIN;\nQuery OK, 0 rows affected (0.20 sec)\n\nmysql> UPDATE t SET b=200 WHERE a=20;\nQuery OK, 1 row affected (0.01 sec)\nRows matched: 1  Changed: 1  Warnings: 0\n\nmysql> COMMIT;\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n#### Session A\n```sql\nmysql> SELECT * FROM t WHERE a < 25; # 可重复读\n+----+----+\n| a  | b  |\n+----+----+\n| 10 | 10 |\n| 20 | 20 |\n+----+----+\n2 rows in set (0.00 sec)\n```\n`Session A`采用的是`一致性非锁定读`，读取`事务初始时的快照版本`，解决了`READ-COMMITTED`的`不可重复读`问题\n\n#### Session B\n```sql\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> INSERT INTO t SELECT 0,0;\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> COMMIT;\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n#### Session A\n```sql\nmysql> SELECT * FROM t WHERE a < 25; # 可重复读\n+----+----+\n| a  | b  |\n+----+----+\n| 10 | 10 |\n| 20 | 20 |\n+----+----+\n2 rows in set (0.00 sec)\n\nmysql> INSERT INTO t SELECT 0,0;\nERROR 1062 (23000): Duplicate entry '0' for key 'PRIMARY'\n```\n`SELECT`筛选出来并没有`a=0`的记录，但在`DELETE`时却发生主键冲突，属于`幻读`\n\n#### Session A\n```sql\nmysql> SELECT * FROM t WHERE a < 25 FOR UPDATE; # 一致性锁定读，采用Next-Key Locking加锁\n+----+-----+\n| a  | b   |\n+----+-----+\n|  0 |   0 |\n| 10 |  10 |\n| 20 | 200 |\n+----+-----+\n3 rows in set (0.00 sec)\n```\n`SELECT...FOR UPDATE`属于`一致性锁定读`，获取**`最新的快照版本`**，然后利用`Next-Key Locking`进行加锁\n加锁的情况：在`a = 0,10,20,30`上加**`X Lock`**，在`a ∈ (-∞,0)∪(0,10)∪(10,20)∪(20,30)`加**`Gap Lock`**\n（关于`Next-Key Locking`的详细内容，请参照博文「InnoDB备忘录 - Next-Key Lock」）\n\n#### Session B\n```sql\nmysql> SET SESSION innodb_lock_wait_timeout=1; # 默认超时时间为50秒\nQuery OK, 0 rows affected (0.01 sec)\n\n# Session A持有X Lock，Session B无法删除，避免因DELETE而导致的幻读问题\nmysql> DELETE FROM t WHERE a = 0;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\nmysql> DELETE FROM t WHERE a = 10;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\nmysql> DELETE FROM t WHERE a = 20;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\nmysql> DELETE FROM t WHERE a = 30;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\n# Session A持有Gap Lock，Session B无法插入，避免因INSERT而导致的幻读问题\nmysql> INSERT INTO t SELECT -5,-5;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\nmysql> INSERT INTO t SELECT 5,5;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\nmysql> INSERT INTO t SELECT 15,15;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\nmysql> INSERT INTO t SELECT 22,22;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\nmysql> INSERT INTO t SELECT 25,25;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\nmysql> INSERT INTO t SELECT 28,28;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\nmysql> INSERT INTO t SELECT 35,35;\nQuery OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> COMMIT;\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n#### Session A\n```sql\nmysql> SELECT * FROM t WHERE a < 25 FOR UPDATE; # 解决幻读问题\n+----+-----+\n| a  | b   |\n+----+-----+\n|  0 |   0 |\n| 10 |  10 |\n| 20 | 200 |\n+----+-----+\n3 rows in set (0.01 sec)\n```\n\n### SERIALIZABLE\n1. `SERIALIZABLE`不存在`脏读`、`不可重复读`和`幻读`\n2. 在每个`SELECT`后自动加上`LOCK IN SHARE MODE`，即每个`读操作`加上一个`S Lock`，因此不支持`一致性非锁定读`（仅`RC`和`RR`支持）\n3. `本地事务`不使用`SERIALIZABLE`，`SERIALIZABLE`主要用于`InnoDB`的`分布式事务`\n\n#### Session A\n```sql\nmysql> CREATE TABLE t (\n    -> a INT NOT NULL PRIMARY KEY,\n    -> b INT NOT NULL\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.04 sec)\n\nmysql> INSERT INTO t VALUES (10,10),(20,20),(30,30);\nQuery OK, 3 rows affected (0.01 sec)\nRecords: 3  Duplicates: 0  Warnings: 0\n\nmysql> SET SESSION TX_ISOLATION='SERIALIZABLE';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a = 10; # 自动添加LOCK IN SHARE MODE，一致性锁定读\n+----+----+\n| a  | b  |\n+----+----+\n| 10 | 10 |\n+----+----+\n1 row in set (0.00 sec)\n```\n`Session A`持有`S Lock`\n\n#### Session B\n```sql\nmysql> SET SESSION TX_ISOLATION='SERIALIZABLE';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a = 10; # S Lock与S Lock兼容\n+----+----+\n| a  | b  |\n+----+----+\n| 10 | 10 |\n+----+----+\n1 row in set (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a = 10 FOR UPDATE; # S Lock与X Lock兼容，阻塞\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n```\n\n#### Session A\n```sql\nmysql> SELECT * FROM t WHERE a < 25;\n+----+----+\n| a  | b  |\n+----+----+\n| 10 | 10 |\n| 20 | 20 |\n+----+----+\n2 rows in set (0.00 sec)\n```\n\n#### Session B\n```sql\n# 与RR类似，不存在幻读问题\nmysql> DELETE FROM t WHERE a = 10;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\nmysql> DELETE FROM t WHERE a = 20;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\nmysql> DELETE FROM t WHERE a = 30;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\nmysql> INSERT INTO t SELECT 5,5;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\nmysql> INSERT INTO t SELECT 15,15;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\nmysql> INSERT INTO t SELECT 22,22;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\nmysql> INSERT INTO t SELECT 28,28;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\nmysql> INSERT INTO t SELECT 35,35;\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n\n<!-- indicate-the-source -->\n","tags":["InnoDB"],"categories":["InnoDB"]},{"title":"InnoDB -- Next-Key Lock","url":"%2F2017%2F05%2F18%2Finnodb-next-key-lock%2F","content":"\n{% note info %}\n本文主要介绍`InnoDB`存储引擎的`Next-Key Lock`\n{% endnote %}\n\n<!-- more -->\n\n# MVCC\n\n1. InnoDB支持`MVCC`，与之`MVCC`相对的是`LBCC`\n2. MVCC中`读操作`分两类：`Snapshot Read`(`不加锁`)和`Current Read`（`加锁`）\n3. MVCC的好处：**`Snapshot Read不加锁`**，`并发性能好`，适用于常规的`JavaWeb`项目（`OLTP`应用）\n\n# 隔离级别\nInnoDB支持4种事务隔离级别（`Isolation Level`）\n\n| 隔离级别 | 描述 |\n| --- | --- |\n| `READ UNCOMMITTED (RUC)` | 可以读取到其他事务中`尚未提交`的内容，生产环境中不会使用 |\n| `READ COMMITTED (RC)` | 可以读取到其他事务中`已经提交`的内容，`Current Read会加锁`，`存在幻读现象`，`Oracle`和`SQL Server`的默认事务隔离级别为`RC` |\n| `REPEATABLE READ (RR)` | 保证事务的`隔离性`，`Current Read会加锁`，同时会加`Gap Lock`，`不存在幻读现象`，`InnoDB`的默认事务隔离级别为`RR` |\n| `SERIALIZABLE` | MVCC退化为`LBCC`，不区分`Snapshot Read`和`Current Read`，`读`操作加`S Lock`，`写`操作加`X Lock`，读写冲突，并发性能差 |\n\n# 行锁\n1. InnoDB实现了两种标准的`行锁`（`Row-Level Lock`）：共享锁（`Shared(S) Lock`）、排它锁（`Exclusive(X) Lock`）\n2. `S Lock`：允许事务持有该锁去*`读取一行数据`*\n3. `X Lock`：允许事务持有该锁去*`更新或删除一行数据`*\n\n`S Lock`与`X Lock`的兼容性\n\n|  | S | X |\n| --- | --- | --- |\n| S | Y | N |\n| X | N | N |\n\n# 锁的算法\n\n## Record Lock\n1. `Record Lock`即行锁，用于锁住`Index Record`（索引记录），分为`S Lock`和`X Lock`\n2. 如果表中没有`显式定义的主键`或`非NULL唯一的索引`，InnoDB将自动创建`6 Bytes的ROWID`的隐藏主键\n\n## Gap Lock\n1. 用于锁住`Index Record`之间的间隙\n2. 如果是`通过唯一索引来搜索一行记录`的时候，不需要使用`Gap Lock`，此时`Next-Key`降级为`Record Lock`\n3. `Gap S-Lock`与`Gap X-Lock`是兼容的\n4. `Gap Lock`只能_**`阻止其他事务在该Gap中插入记录`**_，但**`无法阻止`**其他事务获取`同一个Gap`上的`Gap Lock`\n5. 禁用`Gap Lock`的两种方式\n    - 将事务隔离级别设置为`READ COMMITTED`\n    - 将变量`innodb_locks_unsafe_for_binlog`（已弃用）设置为`1`\n\n## Next-Key Lock\n1. **`Next-Key Lock` = `Record Lock` + `Gap Lock`**\n2. 若索引a为10、11、13、20，可锁定的区间为`(-∞, 10]`、`(10, 11]`、`(11, 13]`、`(13, 20]`、`(20, +∞)`\n    - 若执行`Select...Where a=13 For Update`，将在`a=13`上有1个`X Lock`和在`(11, 13)`有1个`Gap Lock`\n    - `a=13`的下一个键为`a=20`，将在`a=20`有1个`X Lock`，在`(13, 20)`有1个`Gap Lock`\n    - 因此，在`a=13`上有1个`X Lock`，在`(11, 20]`上的有1个`Gap Lock`\n    - 也可以分解为在`a=13`和`a=20`上有2个`X Lock`，在`(11,13)`和`(13,20)`上有2个`Gap Lock`\n3. 在InnoDB默认事务隔离级别`REPEATABLE READ(RR)`下，支持`Next-Key Lock`\n\n# 11个实例\n1. 下面11个实例仅仅考虑`RC`与`RR`的事务隔离级别\n2. `RR`支持`Next-Key Lock`、`Gap Lock`和`Record Lock`，`RC`仅支持`Record Lock`\n\n## RC/RR+Clustered Index+Equal Match\n\n1. 事务隔离级别`READ COMMITTED(RC)`或`REPEATABLE READ(RR)`\n2. 存在`显式定义`主键\n3. `WHERE`等值匹配成功\n\n注：`RR`支持`Next-Key Lock`，在`通过唯一索引来搜索一行记录`时，`Next-Key Lock`降级为`Record Lock`，此时与`RC`一致，下面实例仅以`RC`进行说明\n\n### 表初始化\n```SQL\nmysql> CREATE TABLE t ( a INT NOT NULL PRIMARY KEY ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.02 sec)\n\nmysql> INSERT INTO t VALUES (10),(20),(30),(40),(50),(60),(70),(80);\nQuery OK, 8 rows affected (0.01 sec)\nRecords: 8  Duplicates: 0  Warnings: 0\n```\n\n### Session A\n```SQL\nmysql> SET SESSION TX_ISOLATION='READ-COMMITTED';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a=30 FOR UPDATE;\n+----+\n| a  |\n+----+\n| 30 |\n+----+\n1 row in set (0.01 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1322763 | RUNNING   | NULL                  | READ COMMITTED      |\n+---------+-----------+-----------------------+---------------------+\n1 row in set (0.00 sec)\n```\n1. 将`Session A`的事务隔离级别设置为`READ COMMITTED`\n2. 事务`1322763`通过`SELECT...FOR UPDATE`操作获得了`聚集索引a`（`Clustered Index`）上`30`的`X Lock`\n\n### Session B\n```SQL\nmysql> SET SESSION TX_ISOLATION='READ-COMMITTED';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> INSERT INTO t SELECT 25;\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 35;\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1322764 | RUNNING   | NULL                  | READ COMMITTED      |\n| 1322763 | RUNNING   | NULL                  | READ COMMITTED      |\n+---------+-----------+-----------------------+---------------------+\n2 rows in set (0.01 sec)\n\nmysql> SELECT * FROM t WHERE a=30 LOCK IN SHARE MODE; # Blocked\n```\n1. 将`Session B`的事务隔离级别设置为`READ COMMITTED`\n2. 成功插入`a=25`和`a=35`，说明在`(20,30)`和`(30,40)`上没有`Gap Lock`\n3. 事务`1322764`尝试通过`SELECT...LOCK IN SHARE MODE`获得`a=30`的`S Lock`，由于`S lock`与`X Lock`不兼容，且此时事务`1322763`持有对应的`X Lock`，所以事务`1322764`被`阻塞`（详细信息见下节）\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1322764:389:3:4 | 1322764     | S         | RECORD    | `test`.`t` | PRIMARY    |        389 |         3 |        4 | 30        |\n| 1322763:389:3:4 | 1322763     | X         | RECORD    | `test`.`t` | PRIMARY    |        389 |         3 |        4 | 30        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.02 sec)\n\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1322764           | 1322764:389:3:4   | 1322763         | 1322763:389:3:4  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (1.18 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1322764 | LOCK WAIT | 1322764:389:3:4       | READ COMMITTED      |\n| 1322763 | RUNNING   | NULL                  | READ COMMITTED      |\n+---------+-----------+-----------------------+---------------------+\n2 rows in set (0.00 sec)\n\nmysql> SHOW ENGINE INNODB STATUS\\G\nLIST OF TRANSACTIONS FOR EACH SESSION:\n---TRANSACTION 1322764, ACTIVE 74 sec starting index read\nmysql tables in use 1, locked 1\nLOCK WAIT 2 lock struct(s), heap size 1136, 1 row lock(s), undo log entries 2\nMySQL thread id 139, OS thread handle 140648641087232, query id 2146 localhost root statistics\nSELECT * FROM t WHERE a=30 LOCK IN SHARE MODE\n------- TRX HAS BEEN WAITING 17 SEC FOR THIS LOCK TO BE GRANTED:\nRECORD LOCKS space id 389 page no 3 n bits 80 index PRIMARY of table `test`.`t` trx id 1322764 lock mode S locks rec but not gap waiting\nRecord lock, heap no 4 PHYSICAL RECORD: n_fields 3; compact format; info bits 0\n 0: len 4; hex 8000001e; asc     ;;\n 1: len 6; hex 000000142f02; asc     / ;;\n 2: len 7; hex dc000001af012a; asc       *;;\n---TRANSACTION 1322763, ACTIVE 153 sec\n2 lock struct(s), heap size 1136, 1 row lock(s)\nMySQL thread id 138, OS thread handle 140648641488640, query id 2150 localhost root starting\n```\n1. `lock_index`为`PRIMARY`，说明锁住的是`聚集索引a`（`Clustered Index`）\n2. `trx id 1322764 lock mode S locks rec but not gap`表示事务`1322764`想要获得`S Lock`，不需要`Gap Lock`\n\n### 示意图\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/lock_rc_primary.png\" width=\"500\">\n\n## RC+Clustered Index+Equal Not Match\n1. 事务隔离级别`READ COMMITTED(RC)`\n2. 存在`显式定义`主键\n3. `WHERE`等值匹配不成功\n\n### 表初始化\n```SQL\nmysql> CREATE TABLE t ( a INT NOT NULL PRIMARY KEY ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.02 sec)\n\nmysql> INSERT INTO t VALUES (10),(20),(30),(40),(50),(60),(70),(80);\nQuery OK, 8 rows affected (0.01 sec)\nRecords: 8  Duplicates: 0  Warnings: 0\n```\n\n### Session A\n```SQL\nmysql> SET SESSION TX_ISOLATION='READ-COMMITTED';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a=35 FOR UPDATE;\nEmpty set (0.00 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1322801 | RUNNING   | NULL                  | READ COMMITTED      |\n+---------+-----------+-----------------------+---------------------+\n1 row in set (0.01 sec)\n```\n1. 将`Session A`的事务隔离级别设置为`READ COMMITTED`\n2. 事务`1322801`尝试通过`SELECT...FOR UPDATE`操作获得了`聚集索引a`（`Clustered Index`）上`35`的`X Lock`，但`a=35`不存在，`并不加任何锁`\n\n### Session B\n```SQL\nmysql> SET SESSION TX_ISOLATION='READ-COMMITTED';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> INSERT INTO t SELECT 34;\nQuery OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 36;\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 35;\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1322802 | RUNNING   | NULL                  | READ COMMITTED      |\n| 1322801 | RUNNING   | NULL                  | READ COMMITTED      |\n+---------+-----------+-----------------------+---------------------+\n2 rows in set (0.00 sec)\n```\n1. 将`Session B`的事务隔离级别设置为`READ COMMITTED`\n2. 成功插入`a=34`和`a=36`，说明在`(30,40)`上没有`Gap Lock`\n3. 成功插入`a=35`，说明在`a=35`上没有`X Lock`\n\n## RR+Clustered Index+Equal Not Match\n1. 事务隔离级别`REPEATABLE READ(RR)`\n2. 存在`显式定义`主键\n3. `WHERE`等值匹配不成功\n\n### 表初始化\n```SQL\nmysql> CREATE TABLE t ( a INT NOT NULL PRIMARY KEY ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.02 sec)\n\nmysql> INSERT INTO t VALUES (10),(20),(30),(40),(50),(60),(70),(80);\nQuery OK, 8 rows affected (0.01 sec)\nRecords: 8  Duplicates: 0  Warnings: 0\n```\n\n### Session A\n```SQL\nmysql> SET SESSION TX_ISOLATION='REPEATABLE-READ';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a=35 FOR UPDATE;\nEmpty set (0.00 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1323280 | RUNNING   | NULL                  | REPEATABLE READ     |\n+---------+-----------+-----------------------+---------------------+\n1 row in set (0.00 sec)\n```\n1. 将`Session A`的事务隔离级别设置为`REPEATABLE-READ`\n2. 事务`1323280`尝试通过`SELECT...FOR UPDATE`操作获得了`聚集索引a`（`Clustered Index`）上`35`的`X Lock`，但`a=35`不存在，在`(30,40)`上加上`Gap Lock`\n\n### Session B\n```SQL\nmysql> SET SESSION TX_ISOLATION='REPEATABLE-READ';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> INSERT INTO t SELECT 35; # Blocked\n```\n1. 将`Session B`的事务隔离级别设置为`REPEATABLE-READ`\n2. `Session B`的事务尝试插入`a=35`，但由于事务`1323280`已经持有了`(30,40)`上的`Gap Lock`，因此被阻塞（详细信息见下节）\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/lock_rr_primary_01.png\" width=\"500\">\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1323281:391:3:5 | 1323281     | X,GAP     | RECORD    | `test`.`t` | PRIMARY    |        391 |         3 |        5 | 40        |\n| 1323280:391:3:5 | 1323280     | X,GAP     | RECORD    | `test`.`t` | PRIMARY    |        391 |         3 |        5 | 40        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1323281           | 1323281:391:3:5   | 1323280         | 1323280:391:3:5  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1323281 | LOCK WAIT | 1323281:391:3:5       | REPEATABLE READ     |\n| 1323280 | RUNNING   | NULL                  | REPEATABLE READ     |\n+---------+-----------+-----------------------+---------------------+\n2 rows in set (0.00 sec)\n\nmysql> SHOW ENGINE INNODB STATUS\\G\nLIST OF TRANSACTIONS FOR EACH SESSION:\n---TRANSACTION 1323281, ACTIVE 16 sec inserting\nmysql tables in use 1, locked 1\nLOCK WAIT 2 lock struct(s), heap size 1136, 1 row lock(s)\nMySQL thread id 5, OS thread handle 140546164094720, query id 119 localhost root executing\nINSERT INTO t SELECT 35\n------- TRX HAS BEEN WAITING 16 SEC FOR THIS LOCK TO BE GRANTED:\nRECORD LOCKS space id 391 page no 3 n bits 80 index PRIMARY of table `test`.`t` trx id 1323281 lock_mode X locks gap before rec insert intention waiting\nRecord lock, heap no 5 PHYSICAL RECORD: n_fields 3; compact format; info bits 0\n 0: len 4; hex 80000028; asc    (;;\n 1: len 6; hex 000000142f41; asc     /A;;\n 2: len 7; hex a7000001fd0137; asc       7;;\n---TRANSACTION 1323280, ACTIVE 99 sec\n2 lock struct(s), heap size 1136, 1 row lock(s)\nMySQL thread id 4, OS thread handle 140546164295424, query id 123 localhost root starting\n\nmysql> INSERT INTO t SELECT 35;\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n1. 在事务隔离级别为`REPEATABLE READ`时，尝试给`不存在`的值上锁，会产生`Gap Lock`\n2. 在事务`1323280`插入`a=35`成功，因为其他事务（`1323281`）暂不持有`包含a=35`的`Gap Lock`，因此无法阻塞事务`1323280`的插入操作\n3. 插入成功后，事务`1323280`持有`a=35`的`X Lock`\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/lock_rr_primary_02.png\" width=\"500\">\n\n### Session B\n```SQL\nmysql> INSERT INTO t SELECT 35; # Timeout\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\nmysql> SELECT * FROM t WHERE a=37 FOR UPDATE;\nEmpty set (0.00 sec)\n```\n事务`1323280`持有`(30,40)`的`Gap Lock`，但无法阻止事务`1323281`获得`(35,40)`上的`Gap Lock`（事务`1323280`已获得`a=35`的`X Lock`）\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/lock_rr_primary_03.png\" width=\"500\">\n\n### Session A\n```SQL\nmysql> INSERT INTO t SELECT 33;\nQuery OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 36; # Blocked\n```\n1. 事务`1323280`持有`(30,40)`上的`Gap Lock`，另一个事务`1323281`持有`(35,40)`上的`Gap Lock`\n2. 插入`a=33`不被阻塞，插入成功后事务`1323280`持有`a=33`的`X Lock`\n3. 插入`a=36`被事务`1323281`持有`(35,40)`上的`Gap Lock`阻塞（详细信息见下节）\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/lock_rr_primary_04.png\" width=\"500\">\n\n### Session B\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1323280:391:3:5 | 1323280     | X,GAP     | RECORD    | `test`.`t` | PRIMARY    |        391 |         3 |        5 | 40        |\n| 1323281:391:3:5 | 1323281     | X,GAP     | RECORD    | `test`.`t` | PRIMARY    |        391 |         3 |        5 | 40        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1323280           | 1323280:391:3:5   | 1323281         | 1323281:391:3:5  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1323281 | RUNNING   | NULL                  | REPEATABLE READ     |\n| 1323280 | LOCK WAIT | 1323280:391:3:5       | REPEATABLE READ     |\n+---------+-----------+-----------------------+---------------------+\n2 rows in set (0.00 sec)\n\nmysql> SHOW ENGINE INNODB STATUS\\G;\nLIST OF TRANSACTIONS FOR EACH SESSION:\n---TRANSACTION 1323281, ACTIVE 305 sec\n2 lock struct(s), heap size 1136, 2 row lock(s)\nMySQL thread id 5, OS thread handle 140546164094720, query id 131 localhost root starting\nSHOW ENGINE INNODB STATUS\n---TRANSACTION 1323280, ACTIVE 388 sec inserting\nmysql tables in use 1, locked 1\nLOCK WAIT 3 lock struct(s), heap size 1136, 4 row lock(s), undo log entries 2\nMySQL thread id 4, OS thread handle 140546164295424, query id 127 localhost root executing\nINSERT INTO t SELECT 36\n------- TRX HAS BEEN WAITING 11 SEC FOR THIS LOCK TO BE GRANTED:\nRECORD LOCKS space id 391 page no 3 n bits 80 index PRIMARY of table `test`.`t` trx id 1323280 lock_mode X locks gap before rec insert intention waiting\nRecord lock, heap no 5 PHYSICAL RECORD: n_fields 3; compact format; info bits 0\n 0: len 4; hex 80000028; asc    (;;\n 1: len 6; hex 000000142f41; asc     /A;;\n 2: len 7; hex a7000001fd0137; asc       7;;\n```\n\n## RC+Clustered Index+Range\n1. 事务隔离级别`READ COMMITTED(RC)`\n2. 存在`显式定义`主键\n3. WHERE采用`RANGE`匹配\n\n###  表初始化\n```SQL\nmysql> CREATE TABLE t ( a INT NOT NULL PRIMARY KEY ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> INSERT INTO t VALUES (10),(20),(30),(40),(50);\nQuery OK, 5 rows affected (0.01 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n```\n\n### Session A\n```SQL\nmysql> SET SESSION TX_ISOLATION='READ-COMMITTED';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a>15 AND a<45 FOR UPDATE;\n+----+\n| a  |\n+----+\n| 20 |\n| 30 |\n| 40 |\n+----+\n3 rows in set (0.00 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1323886 | RUNNING   | NULL                  | READ COMMITTED      |\n+---------+-----------+-----------------------+---------------------+\n1 row in set (0.00 sec)\n```\n1. 将`Session A`的事务隔离级别设置为`READ COMMITTED`\n2. 事务`1323886`将获得`聚集索引a`上`20`、`30`、`40`上的`X Lock`\n\n### Session B\n```SQL\nmysql> SET SESSION TX_ISOLATION='READ-COMMITTED';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> INSERT INTO t SELECT 25;\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 35;\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> SELECT * FROM t WHERE a=30 FOR UPDATE; # Blocked\n```\n1. 将`Session B`的事务隔离级别设置为`READ COMMITTED`\n2. 事务`1323887`成功插入`a=25`和`a=35`，表明`(20,30)`和`(30,40)`上不存在`Gap Lock`\n3. 因为事务`1323886`已经持有`a=30`的`X Lock`，因此事务`1323887`被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1323887:399:3:4 | 1323887     | X         | RECORD    | `test`.`t` | PRIMARY    |        399 |         3 |        4 | 30        |\n| 1323886:399:3:4 | 1323886     | X         | RECORD    | `test`.`t` | PRIMARY    |        399 |         3 |        4 | 30        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1323887           | 1323887:399:3:4   | 1323886         | 1323886:399:3:4  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.01 sec)\n```\n\n### 示意图\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/lock_rc_primary_range.png\" width=\"500\">\n\n## RR+Clustered Index+Range\n1. 事务隔离级别`REPEATABLE READ(RR)`\n2. 存在`显式定义`主键\n3. WHERE采用`RANGE`匹配\n\n### 表初始化\n```SQL\nmysql> CREATE TABLE t ( a INT NOT NULL PRIMARY KEY ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> INSERT INTO t VALUES (10),(20),(30),(40),(50);\nQuery OK, 5 rows affected (0.01 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n```\n\n### Session A\n```SQL\nmysql> SET SESSION TX_ISOLATION='REPEATABLE-READ';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a>15 AND a<25 FOR UPDATE;\n+----+\n| a  |\n+----+\n| 20 |\n+----+\n2 rows in set (0.00 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1332194 | RUNNING   | NULL                  | REPEATABLE READ     |\n+---------+-----------+-----------------------+---------------------+\n1 row in set (0.00 sec)\n```\n1. 将`Session A`的事务隔离级别设置为`REPEATABLE READ`\n2. 事务`1332194`将获得`聚集索引a`上`20`的`X Lock`，并将对应地获得`(10,20)`上的`Gap Lock`\n3. 依据`Next-Key Lock`，事务`1332194`还将获得`聚集索引a`上`30`的`X Lock`以及`(20,30)`上的`Gap Lock`\n\n### Session B\n```SQL\nmysql> SET SESSION TX_ISOLATION='REPEATABLE-READ';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> INSERT INTO t SELECT 5;\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 35;\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 45;\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 55;\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 29; # Blocked\n```\n1. 将`Session B`的事务隔离级别设置为`REPEATABLE READ`\n2. 成功插入`5`、`35`、`45`、`55`，表明事务`1332194`并没有持有`(-∞,10)`、`(30,40)`、`(40,50)`和`(50,+∞)`上的`Gap Lock`\n3. 事务`1332194`已持有`(20,30)`上的`Gap Lock`，因此事务`1332194`插入`29`会被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1332195:486:3:4 | 1332195     | X,GAP     | RECORD    | `test`.`t` | PRIMARY    |        486 |         3 |        4 | 30        |\n| 1332194:486:3:4 | 1332194     | X         | RECORD    | `test`.`t` | PRIMARY    |        486 |         3 |        4 | 30        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1332195           | 1332195:486:3:4   | 1332194         | 1332194:486:3:4  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1332195 | LOCK WAIT | 1332195:486:3:4       | REPEATABLE READ     |\n| 1332194 | RUNNING   | NULL                  | REPEATABLE READ     |\n+---------+-----------+-----------------------+---------------------+\n2 rows in set (0.00 sec)\n```\n\n### Session B\n```SQL\nmysql> INSERT INTO t SELECT 29; # Timeout\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\nmysql> INSERT INTO t SELECT 11; # Blocked\n```\n事务`1332195`插入`11`会被阻塞，原因同插入`29`一致，不再赘述，详细信息见下节\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1332195:486:3:3 | 1332195     | X,GAP     | RECORD    | `test`.`t` | PRIMARY    |        486 |         3 |        3 | 20        |\n| 1332194:486:3:3 | 1332194     | X         | RECORD    | `test`.`t` | PRIMARY    |        486 |         3 |        3 | 20        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1332195           | 1332195:486:3:3   | 1332194         | 1332194:486:3:3  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1332195 | LOCK WAIT | 1332195:486:3:3       | REPEATABLE READ     |\n| 1332194 | RUNNING   | NULL                  | REPEATABLE READ     |\n+---------+-----------+-----------------------+---------------------+\n2 rows in set (0.00 sec)\n```\n\n### Session B\n```SQL\nmysql> INSERT INTO t SELECT 11; # Timeout\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\nmysql> SELECT * FROM t WHERE a=10 FOR UPDATE;\n+----+\n| a  |\n+----+\n| 10 |\n+----+\n1 row in set (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a=30 FOR UPDATE; # Blocked\n```\n1. 事务`1332194`并不持有`聚集索引a`上`10`的`X Lock`，事务`1332195`可以顺利获取`聚集索引a`上`10`的`X Lock`\n2. 事务`1332194`持有`聚集索引a`上`30`的`X Lock`，事务`1332195`被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1332195:486:3:4 | 1332195     | X         | RECORD    | `test`.`t` | PRIMARY    |        486 |         3 |        4 | 30        |\n| 1332194:486:3:4 | 1332194     | X         | RECORD    | `test`.`t` | PRIMARY    |        486 |         3 |        4 | 30        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1332195           | 1332195:486:3:4   | 1332194         | 1332194:486:3:4  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1332195 | LOCK WAIT | 1332195:486:3:4       | REPEATABLE READ     |\n| 1332194 | RUNNING   | NULL                  | REPEATABLE READ     |\n+---------+-----------+-----------------------+---------------------+\n2 rows in set (0.01 sec)\n```\n\n### 示意图\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/lock_rr_primary_range_1.png\" width=\"500\">\n\n## RC+Secondary Unique Index+Range\n1. 事务隔离级别`READ COMMITTED(RC)`\n2. 存在`唯一辅助索引`\n3. `WHERE`通过`RANGE`匹配\n\n### 表初始化\n```SQL\nmysql> CREATE TABLE t (\n    -> a INT NOT NULL,\n    -> b INT NOT NULL,\n    -> PRIMARY KEY (a),\n    -> UNIQUE KEY (b)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.08 sec)\n\nmysql> INSERT INTO t VALUES (10,20),(20,50),(30,10),(40,40),(50,30);\nQuery OK, 5 rows affected (0.05 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n```\n\n### Session A\n```SQL\nmysql> SET SESSION TX_ISOLATION='READ-COMMITTED';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE b>25 AND b<45 FOR UPDATE;\n+----+----+\n| a  | b  |\n+----+----+\n| 50 | 30 |\n| 40 | 40 |\n+----+----+\n2 rows in set (0.00 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1324402 | RUNNING   | NULL                  | READ COMMITTED      |\n+---------+-----------+-----------------------+---------------------+\n1 row in set (0.01 sec)\n```\n1. 将`Session A`的事务隔离级别设置为`READ COMMITTED`\n2. 事务`1324402`将获得`辅助唯一索引b`上`30`、`40`的`X Lock`，并获得对应的`聚集索引a`上`50`、`40`上的`X Lock`\n\n### Session B\n```SQL\nmysql> SET SESSION TX_ISOLATION='READ-COMMITTED';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE b=30 FOR UPDATE; # Blocked\n```\n1. 将`Session B`的事务隔离级别设置为`READ COMMITTED`\n2. 事务`1324402`已经持有`辅助唯一索引b`上`30`的`X Lock`，因此会被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1324403:405:4:6 | 1324403     | X         | RECORD    | `test`.`t` | b          |        405 |         4 |        6 | 30        |\n| 1324402:405:4:6 | 1324402     | X         | RECORD    | `test`.`t` | b          |        405 |         4 |        6 | 30        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.01 sec)\n\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324403           | 1324403:405:4:6   | 1324402         | 1324402:405:4:6  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n```\n\n### Session B\n```SQL\nmysql> SELECT * FROM t WHERE b=30 FOR UPDATE; # Timeout\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\nmysql> SELECT * FROM t WHERE a=50 FOR UPDATE; # Blocked\n```\n 事务`1324402`已经持有`聚集索引b`上`50`的`X Lock`，因此会被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1324403:405:3:6 | 1324403     | X         | RECORD    | `test`.`t` | PRIMARY    |        405 |         3 |        6 | 50        |\n| 1324402:405:3:6 | 1324402     | X         | RECORD    | `test`.`t` | PRIMARY    |        405 |         3 |        6 | 50        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324403           | 1324403:405:3:6   | 1324402         | 1324402:405:3:6  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n```\n\n### 示意图\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/lock_rc_unique_range.png\" width=\"500\">\n\n## RR+Secondary Unique Index+Range\n1. 事务隔离级别`REPEATABLE READ(RR)`\n2. 存在显式定义`唯一辅助索引`\n3. `WHERE`通过`RANGE`匹配\n\n### 表初始化\n```SQL\nmysql> CREATE TABLE t (\n    -> a INT NOT NULL,\n    -> b INT NOT NULL,\n    -> PRIMARY KEY (a),\n    -> UNIQUE KEY (b)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.08 sec)\n\nmysql> INSERT INTO t VALUES (10,90),(20,50),(30,80),(40,60),(50,70);\nQuery OK, 5 rows affected (0.05 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n```\n\n### Session A\n```SQL\nmysql> SET SESSION TX_ISOLATION='REPEATABLE-READ';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE b>55 AND b<85 FOR UPDATE;\n+----+----+\n| a  | b  |\n+----+----+\n| 40 | 60 |\n| 50 | 70 |\n| 30 | 80 |\n+----+----+\n3 rows in set (0.00 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1324512 | RUNNING   | NULL                  | REPEATABLE READ     |\n+---------+-----------+-----------------------+---------------------+\n1 row in set (0.01 sec)\n```\n1. 将`Session A`的事务隔离级别设置为`REPEATABLE READ`\n2. 事务`1324512`将获得`唯一辅助索引b`上`60`、`70`、`80`上的`X Lock`以及`(50,60)`、`(60,70)`、`(70,80)`上的`Gap Lock`，相应地也会获得`聚集索引a`上`40`、`50`、`30`的`X Lock`\n3. 依据`Next-Key Lock`，事务`1324512`将获得`唯一辅助索引b`上`90`上的`X Lock`以及`(80,90)`上的`Gap Lock`，相应地获得`聚集索引a`上`10`的`X Lock`\n4. 事务`1324512`不会在`聚集索引a`上进行`Gap Lock`\n\n### Session B\n```SQL\nmysql> SET SESSION TX_ISOLATION='REPEATABLE-READ';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE b=50 FOR UPDATE;\n+----+----+\n| a  | b  |\n+----+----+\n| 20 | 50 |\n+----+----+\n1 row in set (0.00 sec)\n\nmysql> SELECT * FROM t WHERE b=90 FOR UPDATE; # Blocked(60/70/80 blocked too)\n```\n1. 将`Session B`的事务隔离级别设置为`REPEATABLE READ`\n2. `唯一辅助索引b`上`50`尚未被其他事务锁定，事务`1324513`可以顺利获得`唯一辅助索引b`上`50`的`X Lock`\n3. 事务`1324512`已持有`唯一辅助索引b`上`90`的`X Lock`，事务`1324513`被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1324513:410:4:2 | 1324513     | X         | RECORD    | `test`.`t` | b          |        410 |         4 |        2 | 90        |\n| 1324512:410:4:2 | 1324512     | X         | RECORD    | `test`.`t` | b          |        410 |         4 |        2 | 90        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324513           | 1324513:410:4:2   | 1324512         | 1324512:410:4:2  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n```\n\n### Session B\n```SQL\nmysql> SELECT * FROM t WHERE b=90 FOR UPDATE; # Timeout\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\nmysql> SELECT * FROM t WHERE a=20 FOR UPDATE;\n+----+----+\n| a  | b  |\n+----+----+\n| 20 | 50 |\n+----+----+\n1 row in set (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a=10 FOR UPDATE; # Blocked(40/50/30 blocked too)\n```\n1. `聚集索引a`上`20`尚未被其他事务锁定，事务`1324513`可以顺利获得`聚集索引a`上`20`的`X Lock`\n2. 事务`1324512`已持有`聚集索引a`上`10`的`X Lock`，事务`1324513`被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1324513:410:3:2 | 1324513     | X         | RECORD    | `test`.`t` | PRIMARY    |        410 |         3 |        2 | 10        |\n| 1324512:410:3:2 | 1324512     | X         | RECORD    | `test`.`t` | PRIMARY    |        410 |         3 |        2 | 10        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324513           | 1324513:410:3:2   | 1324512         | 1324512:410:3:2  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n```\n\n### Session B\n```SQL\nmysql> SELECT * FROM t WHERE a=10 FOR UPDATE; # Timeout\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\nmysql> INSERT INTO t VALUES (5,45);\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> INSERT INTO t VALUES (6,55); # Blocked\n```\n1. `唯一聚集索引b`上`(-∞,50)`的尚未被其他事务锁定，因此事务`1324513`成功插入`(5,45)`\n2. 事务`1324512`持有`唯一聚集索引b`上`(50,60)`的`Gap Lock`，因此事务`1324513`插入`(6,55)`时会被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1324513:410:4:5 | 1324513     | X,GAP     | RECORD    | `test`.`t` | b          |        410 |         4 |        5 | 60        |\n| 1324512:410:4:5 | 1324512     | X         | RECORD    | `test`.`t` | b          |        410 |         4 |        5 | 60        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324513           | 1324513:410:4:5   | 1324512         | 1324512:410:4:5  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n```\n\n### 示意图\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/lock_rr_unique_range.png\" width=\"500\">\n\n## RC+Secondary Index+Range\n1. 事务隔离级别`READ COMMITTED(RC)`\n2. 存在显式定义`非唯一辅助索引`\n3. `WHERE`通过`RANGE`匹配\n\n### 表初始化\n```SQL\nmysql> CREATE TABLE t (\n    -> a INT NOT NULL,\n    -> b INT NOT NULL,\n    -> PRIMARY KEY (a),\n    -> KEY (b)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.08 sec)\n\nmysql> INSERT INTO t VALUES (60,50),(70,30),(80,20),(90,40),(100,30),(110,20),(120,10);\nQuery OK, 7 rows affected (0.01 sec)\nRecords: 7  Duplicates: 0  Warnings: 0\n```\n\n### Session A\n```SQL\nmysql> SET SESSION TX_ISOLATION='READ-COMMITTED';\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE b>15 AND b<35 FOR UPDATE;\n+-----+----+\n| a   | b  |\n+-----+----+\n|  80 | 20 |\n| 110 | 20 |\n|  70 | 30 |\n| 100 | 30 |\n+-----+----+\n4 rows in set (1.97 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1324589 | RUNNING   | NULL                  | READ COMMITTED      |\n+---------+-----------+-----------------------+---------------------+\n1 row in set (0.01 sec)\n```\n1. 将`Session A`的事务隔离级别设置为`READ COMMITTED`\n2. 事务`1324589`持有`辅助索引b`上`(b=20,a=80)`、`(b=20,a=110)`、`(b=30,a=70)`、`(b=30,a=100)`的`X Lock`，并相应地持有`聚集索引a`上`(a=80,b=20)`、`(a=110,b=20)`、`(a=70,b=30)`、`(a=100,b=30)`的`X Lock`\n\n### Session B\n```SQL\nmysql> SET SESSION TX_ISOLATION='READ-COMMITTED';\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE b=10 FOR UPDATE;\n+-----+----+\n| a   | b  |\n+-----+----+\n| 120 | 10 |\n+-----+----+\n1 row in set (0.02 sec)\n\nmysql> SELECT * FROM t WHERE b=40 FOR UPDATE;\n+----+----+\n| a  | b  |\n+----+----+\n| 90 | 40 |\n+----+----+\n1 row in set (0.00 sec)\n\nmysql> SELECT * FROM t WHERE b=30 FOR UPDATE; # Blocked\n```\n1. 将`Session B`的事务隔离级别设置为`READ COMMITTED`\n2. `辅助索引b`上`(b=10,a=120)`和`(b=40,a=90)`尚未被其他事务锁定，事务`1324590`能成功获取`辅助索引b`上`(b=10,a=120)`和`(b=40,a=90)`的`X Lock`\n3. 事务`1324589`持有辅助索引b上`(b=30,a=70)`的`X Lock`，因此事务`1324590`被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324590           | 1324590:413:4:3   | 1324589         | 1324589:413:4:3  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.01 sec)\n\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1324590:413:4:3 | 1324590     | X         | RECORD    | `test`.`t` | b          |        413 |         4 |        3 | 30, 70    |\n| 1324589:413:4:3 | 1324589     | X         | RECORD    | `test`.`t` | b          |        413 |         4 |        3 | 30, 70    |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.01 sec)\n```\n\n### Session B\n```SQL\nmysql> SELECT * FROM t WHERE b=30 FOR UPDATE;\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\nmysql> SELECT * FROM t WHERE a=120 FOR UPDATE;\n+-----+----+\n| a   | b  |\n+-----+----+\n| 120 | 10 |\n+-----+----+\n1 row in set (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a=90 FOR UPDATE;\n+----+----+\n| a  | b  |\n+----+----+\n| 90 | 40 |\n+----+----+\n1 row in set (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a=100 FOR UPDATE; # Blocked\n```\n1. `聚集索引a`上`(a=120,b=10)`和`(a=90,b=40)`尚未被其他事务锁定，事务`1324590`能成功获取`聚集索引a`上`(a=120,b=10)`和`(a=90,b=40)`的`X Lock`\n2. 事务`1324589`持有`聚集索引a`上`(a=100,b=30)`的`X Lock`，因此事务`1324590`被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324590           | 1324590:413:3:6   | 1324589         | 1324589:413:3:6  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1324590:413:3:6 | 1324590     | X         | RECORD    | `test`.`t` | PRIMARY    |        413 |         3 |        6 | 100       |\n| 1324589:413:3:6 | 1324589     | X         | RECORD    | `test`.`t` | PRIMARY    |        413 |         3 |        6 | 100       |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n```\n\n### 示意图\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/lock_rc_key_range.png\" width=\"500\">\n\n## RR+Secondary Index+Range\n1. 事务隔离级别`REPEATABLE READ(RR)`\n2. 存在显式定义`非唯一辅助索引`\n3. `WHERE`通过`RANGE`匹配\n\n### 表初始化\n```SQL\nmysql> CREATE TABLE t (\n    -> a INT NOT NULL,\n    -> b INT NOT NULL,\n    -> PRIMARY KEY (a),\n    -> KEY (b)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.08 sec)\n\nmysql> INSERT INTO t VALUES (60,50),(70,30),(80,20),(90,40),(100,30),(110,20),(120,10);\nQuery OK, 7 rows affected (0.01 sec)\nRecords: 7  Duplicates: 0  Warnings: 0\n```\n\n### Session A\n```SQL\nmysql> SET SESSION TX_ISOLATION='REPEATABLE-READ';\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE b>15 AND b<35 FOR UPDATE;\n+-----+----+\n| a   | b  |\n+-----+----+\n|  80 | 20 |\n| 110 | 20 |\n|  70 | 30 |\n| 100 | 30 |\n+-----+----+\n4 rows in set (1.97 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1324567 | RUNNING   | NULL                  | REPEATABLE READ     |\n+---------+-----------+-----------------------+---------------------+\n1 row in set (0.00 sec)\n```\n1. 将`Session A`的事务隔离级别设置为`REPEATABLE READ`\n2. 事务`1324567`持有`辅助索引b`上的`X Lock`：`(b=20,a=80)`、`(b=20,a=110)`、`(b=30,a=70)`、`(b=30,a=100)`\n3. 事务`1324567`持有`辅助索引b`上的`Gap Lock`：`(b=10,a=120)~(b=20,a=80)`、`(b=20,a=80)~(b=20,a=110)`、`(b=20,a=110)~(b=30,a=70)`、`(b=30,a=70)~(b=30,a=100)`\n4. 事务`1324567`持有`聚集索引a`上的`X Lock`：`(a=80,b=20)`、`(a=110,b=20)`、`(a=70,b=30)`、`(a=100,b=30)`\n3. 依据`Next-Key Lock`， 事务`1324567`还持有`辅助索引b`上`(b=40,a=90)`的`X Lock`和`(b=30,a=100)~(b=40,a=90)`上的`Gap Lock`，并相应地持有`聚集索引a`上`(a=90,b=40)`的`X Lock`\n\n### Session B\n```SQL\nmysql> SET SESSION TX_ISOLATION='REPEATABLE-READ';\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE b=10 FOR UPDATE;\n+-----+----+\n| a   | b  |\n+-----+----+\n| 120 | 10 |\n+-----+----+\n1 row in set (0.02 sec)\n\nmysql> SELECT * FROM t WHERE b=40 FOR UPDATE; # Blocked\n```\n1. 将`Session B`的事务隔离级别设置为`REPEATABLE READ`\n2. `辅助索引b`上`(b=10,a=120)`尚未被其他事务锁定，事务`1324568`能成功获取`辅助索引b`上`(b=10,a=120)`的`X Lock`\n3. 事务`1324567`持有`辅助索引b`上`(b=40,a=90)`的`X Lock`，因此事务`1324568`被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1324568:412:4:5 | 1324568     | X         | RECORD    | `test`.`t` | b          |        412 |         4 |        5 | 40, 90    |\n| 1324567:412:4:5 | 1324567     | X         | RECORD    | `test`.`t` | b          |        412 |         4 |        5 | 40, 90    |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.03 sec)\n\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324568           | 1324568:412:4:5   | 1324567         | 1324567:412:4:5  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n```\n\n### Session B\n```SQL\nmysql> SELECT * FROM t WHERE b=40 FOR UPDATE; # Timout\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\nmysql> SELECT * FROM t WHERE a=120 FOR UPDATE;\n+-----+----+\n| a   | b  |\n+-----+----+\n| 120 | 10 |\n+-----+----+\n1 row in set (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a=90 FOR UPDATE; # Blocked\n```\n1. `聚集索引a`上`(a=120,b=10)`尚未被其他事务锁定，事务`1324568`能成功获取`聚集索引a`上`(a=120,b=10)`的`X Lock`\n2. 事务`1324567`持有`聚集索引a`上`(a=90,b=40)`的`X Lock`，因此事务`1324568`被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324568           | 1324568:412:3:5   | 1324567         | 1324567:412:3:5  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.01 sec)\n\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1324568:412:3:5 | 1324568     | X         | RECORD    | `test`.`t` | PRIMARY    |        412 |         3 |        5 | 90        |\n| 1324567:412:3:5 | 1324567     | X         | RECORD    | `test`.`t` | PRIMARY    |        412 |         3 |        5 | 90        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n```\n\n### Session B\n```SQL\nmysql> SELECT * FROM t WHERE a=90 FOR UPDATE; # Timeout\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\nmysql> INSERT INTO t VALUES (95,40);\nQuery OK, 1 row affected (0.01 sec)\n\nmysql> INSERT INTO t VALUES (75,20); # Blocked\n```\n1. `辅助索引b`上`(b=40,a=90)~(b=50,a=60)`不存在`Gap Lock`，事务`1324568`能成功插入`(a=95,b=40)`\n2. 事务`1324567`持有`辅助索引b`上`(b=10,a=120)~(b=20,a=80)`的`Gap Lock`，事务`1324568`插入`(a=75,b=20)`被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1324568:412:4:4 | 1324568     | X,GAP     | RECORD    | `test`.`t` | b          |        412 |         4 |        4 | 20, 80    |\n| 1324567:412:4:4 | 1324567     | X         | RECORD    | `test`.`t` | b          |        412 |         4 |        4 | 20, 80    |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324568           | 1324568:412:4:4   | 1324567         | 1324567:412:4:4  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n```\n\n### Session B\n```SQL\nmysql> INSERT INTO t VALUES (75,20); # Timeout\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\nmysql> INSERT INTO t VALUES (115,20); # Blocked\n```\n事务`1324567`持有`辅助索引b`上`(b=20,a=110)~(b=30,a=70)`的`Gap Lock`，事务`1324568`插入`(a=115,b=20)`被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1324568:412:4:3 | 1324568     | X,GAP     | RECORD    | `test`.`t` | b          |        412 |         4 |        3 | 30, 70    |\n| 1324567:412:4:3 | 1324567     | X         | RECORD    | `test`.`t` | b          |        412 |         4 |        3 | 30, 70    |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324568           | 1324568:412:4:3   | 1324567         | 1324567:412:4:3  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n```\n\n### 示意图\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/lock_rr_key_range_1.png\" width=\"500\">\n\n在`RR`隔离级别下，类似`SELECT ... FOR UPDATE`这种`Current Read`，使用`Gap Lock`能保证过滤出来的范围不被其他事务插入新的记录，防止`幻读`的产生\n\n## RC+No Index\n\n###  表初始化\n```SQL\nmysql> CREATE TABLE t (\n    -> a INT NOT NULL,\n    -> b INT NOT NULL,\n    -> PRIMARY KEY (a)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.08 sec)\n\nmysql> INSERT INTO t VALUES (10,50),(20,60),(30,70),(40,80),(50,90);\nQuery OK, 5 rows affected (0.02 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n```\n\n### Session A\n```SQL\nmysql> SET SESSION TX_ISOLATION='READ-COMMITTED';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE b=70 OR b=90 FOR UPDATE;\n+----+----+\n| a  | b  |\n+----+----+\n| 30 | 70 |\n| 50 | 90 |\n+----+----+\n2 rows in set (0.01 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1324624 | RUNNING   | NULL                  | READ COMMITTED      |\n+---------+-----------+-----------------------+---------------------+\n1 row in set (0.00 sec)\n```\n1. 将`Session A`的事务隔离级别设置为`READ COMMITTED`\n2. 由于`列b上无索引`，只能通过`聚集索引a`进行`全表扫描`，事务`1324624`将持有`聚集索引a`上`30`、`50`的`X Lock`\n\n### Session B\n```SQL\nmysql> SET SESSION TX_ISOLATION='READ-COMMITTED';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a=10 FOR UPDATE;\n+----+----+\n| a  | b  |\n+----+----+\n| 10 | 50 |\n+----+----+\n1 row in set (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a=20 FOR UPDATE;\n+----+----+\n| a  | b  |\n+----+----+\n| 20 | 60 |\n+----+----+\n1 row in set (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a=40 FOR UPDATE;\n+----+----+\n| a  | b  |\n+----+----+\n| 40 | 80 |\n+----+----+\n1 row in set (0.00 sec)\n\nmysql> SELECT * FROM t WHERE a=30 FOR UPDATE; # Blocked\n```\n1. `聚集索引a`上的`10`、`20`、`40`并未被其他事务锁定，事务`1324625`能成功获取它们的`X Lock`\n2. 事务`1324624`持有`聚集索引a`上的`30`的`X lock`，事务`1324625`被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324625           | 1324625:414:3:4   | 1324624         | 1324624:414:3:4  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1324625:414:3:4 | 1324625     | X         | RECORD    | `test`.`t` | PRIMARY    |        414 |         3 |        4 | 30        |\n| 1324624:414:3:4 | 1324624     | X         | RECORD    | `test`.`t` | PRIMARY    |        414 |         3 |        4 | 30        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n```\n\n### Session B\n```SQL\nmysql> SELECT * FROM t WHERE a=30 FOR UPDATE; # Timeout\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\nmysql> SELECT * FROM t WHERE a=50 FOR UPDATE; # Blocked\n```\n事务`1324624`持有`聚集索引a`上的`50`的`X lock`，事务`1324625`被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1324625:414:3:6 | 1324625     | X         | RECORD    | `test`.`t` | PRIMARY    |        414 |         3 |        6 | 50        |\n| 1324624:414:3:6 | 1324624     | X         | RECORD    | `test`.`t` | PRIMARY    |        414 |         3 |        6 | 50        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324625           | 1324625:414:3:6   | 1324624         | 1324624:414:3:6  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n```\n\n### 示意图\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/lock_rc_no_key.png\" width=\"500\">\n\n\n## RR+No Index\n\n### 表初始化\n```SQL\nmysql> CREATE TABLE t (\n    -> a INT NOT NULL,\n    -> b INT NOT NULL,\n    -> PRIMARY KEY (a)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.08 sec)\n\nmysql> INSERT INTO t VALUES (10,50),(20,60),(30,70),(40,80),(50,90);\nQuery OK, 5 rows affected (0.02 sec)\nRecords: 5  Duplicates: 0  Warnings: 0\n```\n\n### Session A\n```SQL\nmysql> SET SESSION TX_ISOLATION='REPEATABLE-READ';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SELECT * FROM t WHERE b=70 FOR UPDATE;\n+----+----+\n| a  | b  |\n+----+----+\n| 30 | 70 |\n+----+----+\n1 row in set (0.01 sec)\n\nmysql> SELECT trx_id,trx_state,trx_requested_lock_id,trx_isolation_level FROM INFORMATION_SCHEMA.INNODB_TRX;\n+---------+-----------+-----------------------+---------------------+\n| trx_id  | trx_state | trx_requested_lock_id | trx_isolation_level |\n+---------+-----------+-----------------------+---------------------+\n| 1324610 | RUNNING   | NULL                  | REPEATABLE READ     |\n+---------+-----------+-----------------------+---------------------+\n1 row in set (0.00 sec)\n```\n1. 将`Session A`的事务隔离级别设置为`REPEATABLE READ`\n2. 由于`列b上无索引`，只能通过`聚集索引a`进行`全表扫描`，事务`1324610`将持有`聚集索引a`上`10`、`20`、`30`、`40`、`50`的`X Lock`，并持有`聚集索引a`上`(-∞,10)`、`(10,20)`、`(20,30)`、`(30,40)`、`(40,50)`、`(50,+∞)`上的`Gap Lock`\n\n### Session B\n```SQL\nmysql> SET SESSION TX_ISOLATION='REPEATABLE-READ';\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> BEGIN;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> INSERT INTO t VALUES (5,100); # Blocked\n```\n事务`1324610`持有`聚集索引a`上`(negative infinity,10)`的`Gap Lock`，事务`1324611`插入`(5,100)`被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1324611:414:3:2 | 1324611     | X,GAP     | RECORD    | `test`.`t` | PRIMARY    |        414 |         3 |        2 | 10        |\n| 1324610:414:3:2 | 1324610     | X         | RECORD    | `test`.`t` | PRIMARY    |        414 |         3 |        2 | 10        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324611           | 1324611:414:3:2   | 1324610         | 1324610:414:3:2  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n```\n\n### Session B\n```SQL\nmysql> INSERT INTO t VALUES (5,100); # Timeout\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\nmysql> INSERT INTO t VALUES (25,100); # Blocked\n```\n事务`1324610`持有`聚集索引a`上`(20,30)`的`Gap Lock`，事务`1324611`插入`(25,100)`被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324611           | 1324611:414:3:4   | 1324610         | 1324610:414:3:4  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1324611:414:3:4 | 1324611     | X,GAP     | RECORD    | `test`.`t` | PRIMARY    |        414 |         3 |        4 | 30        |\n| 1324610:414:3:4 | 1324610     | X         | RECORD    | `test`.`t` | PRIMARY    |        414 |         3 |        4 | 30        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.01 sec)\n```\n\n### Session B\n```SQL\nmysql> INSERT INTO t VALUES (25,100); # Timeout\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\nmysql> INSERT INTO t VALUES (55,100); # Blocked\n```\n1. `+∞`即`supremum pseudo-record`，相关信息请参照「InnoDB备忘录 - 数据页格式」\n2. 事务`1324610`持有`聚集索引a`上`(50,+∞)`的`Gap Lock`，事务`1324611`插入`(55,100)`被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+------------------------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data              |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+------------------------+\n| 1324611:414:3:1 | 1324611     | X         | RECORD    | `test`.`t` | PRIMARY    |        414 |         3 |        1 | supremum pseudo-record |\n| 1324610:414:3:1 | 1324610     | X         | RECORD    | `test`.`t` | PRIMARY    |        414 |         3 |        1 | supremum pseudo-record |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+------------------------+\n2 rows in set, 1 warning (0.00 sec)\n\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324611           | 1324611:414:3:1   | 1324610         | 1324610:414:3:1  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n```\n\n### Session B\n```SQL\nmysql> INSERT INTO t VALUES (55,100); # Timeout\nERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\nmysql> SELECT * FROM t WHERE a=50 FOR UPDATE; # Blocked\n```\n事务`1324610`持有`聚集索引a`上`50`的`X Lock`，事务`1324611`被阻塞（详细信息见下节）\n\n### Session A\n```SQL\nmysql> select * from information_schema.INNODB_LOCK_WAITS;\n+-------------------+-------------------+-----------------+------------------+\n| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |\n+-------------------+-------------------+-----------------+------------------+\n| 1324611           | 1324611:414:3:6   | 1324610         | 1324610:414:3:6  |\n+-------------------+-------------------+-----------------+------------------+\n1 row in set, 1 warning (0.00 sec)\n\nmysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| lock_id         | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n| 1324611:414:3:6 | 1324611     | X         | RECORD    | `test`.`t` | PRIMARY    |        414 |         3 |        6 | 50        |\n| 1324610:414:3:6 | 1324610     | X         | RECORD    | `test`.`t` | PRIMARY    |        414 |         3 |        6 | 50        |\n+-----------------+-------------+-----------+-----------+------------+------------+------------+-----------+----------+-----------+\n2 rows in set, 1 warning (0.00 sec)\n```\n\n### 示意图\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/lock_rr_no_key.png\" width=\"500\">\n\n# 参考资料\n\n1. [MySQL技术内幕 - InnoDB存储引擎 V2](https://book.douban.com/subject/24708143/)\n2. [MySQL 加锁处理分析](http://hedengcheng.com/?p=771)\n3. [InnoDB Locking](https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html)\n4. [The INFORMATION_SCHEMA INNODB_TRX Table](https://dev.mysql.com/doc/refman/5.7/en/innodb-trx-table.html)\n5. [The INFORMATION_SCHEMA INNODB_LOCKS Table](https://dev.mysql.com/doc/refman/5.7/en/innodb-locks-table.html)\n6. [The INFORMATION_SCHEMA INNODB_LOCK_WAITS Tabl](https://dev.mysql.com/doc/refman/5.5/en/innodb-lock-waits-table.html)\n\n<!-- indicate-the-source -->\n","tags":["InnoDB"],"categories":["InnoDB"]},{"title":"InnoDB -- B+Tree索引","url":"%2F2017%2F05%2F12%2Finnodb-btree-index%2F","content":"\n{% note info %}\n本文主要介绍`InnoDB`存储引擎的`B+Tree索引`\n{% endnote %}\n\n<!-- more -->\n\n# B+Tree数据结构\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_btree.png\" width=\"500\">\n\n1. 所有`叶子节点`出现在`同一层`\n2. `叶子节点`包含`关键字信息`\n3. `叶子节点`本身构成`单向有序链表`\n4. `叶子节点`内部的记录也构成`单向有序链表`\n4. `索引节点`不包含`关键字信息`，这样能容纳更多的索引信息，B+Tree的`高度很低`，查找效率很高\n\n关于B+Tree的更多内容请查看[维基百科](https://en.wikipedia.org/wiki/B-tree)\n\n# MyISAM与InnoDB\n\n## MyISAM\n1. `索引文件`与`数据文件`是**`分离`**的\n2. `MyISAM`的索引文件采用`B+Tree`索引\n3. `叶子节点data域`记录的是**`数据存放的地址`**\n4. `主索引（唯一）`与`辅助索引（可重复）`在结构上`没有任何区别`\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_btree_myisam.png\" width=\"500\">\n\n## InnoDB\n1. `数据文件`本身是按照`B+Tree`组织的索引结构（`主索引:Primary Index`或`聚集索引:Clustered Index`），而`叶子节点data域`记录的是**`完整的数据信息`**\n2. InnoDB**`必须有主键`**，如果没有`显式定义主键`或`非NULL的唯一索引`，InnoDB会自动生成`6 Bytes的ROWID`作为主键\n3. `辅助索引`（`Secondary Index`）也是按`B+Tree`组织，`叶子节点data域`记录的是**`主键值`**，因此`主键不宜定义太大`\n3. 搜索`辅助索引`需要`遍历两遍索引`，首先通过`辅助索引`获得主键值，再用主键值在`主索引`中获取实际数据\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_btree_innodb.png\" width=\"500\">\n\n# 单列主键下的DML操作\n本节将通过实例介绍在`单列主键下的DML操作`时，`B+Tree索引`是如何变化的，关于页内查找的实例请参照「InnoDB备忘录 - 数据页结构」\n\n## Insert\n\n### Leaf Page满\n1. 拆分`Leaf Page`，将`中间节点`放入到`Index Page`中\n2. `小于`中间节点的行记录放在`左边Leaf Page`\n3. `大于`中间节点的行记录放`右边Leaf Page`\n\n#### 表初始化\n```SQL\nmysql> CREATE TABLE t (\n    -> a INT NOT NULL PRIMARY KEY,\n    -> b VARCHAR(3500)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.08 sec)\n\nmysql> INSERT INTO t SELECT 10,REPEAT('a',3500);\nQuery OK, 1 row affected (0.02 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 20,REPEAT('a',3500);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 30,REPEAT('a',3500);\nQuery OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 40,REPEAT('a',3500);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 6:\nFreshly Allocated Page: 2\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 1\nFile Segment inode: 1\n```\n\n1. `CHARSET=LATIN1 ROW_FORMAT=COMPACT`下，每个行记录占用`3525 Byte`(相关内容请参照「InnoDB备忘录 - 行记录格式」)\n2. `ROW_FORMAT=COMPACT`下，每个页固定占用（不考虑`User Records`、`Free Space`和`Page Directory`，相关内容请参照「InnoDB备忘录 - 数据页结构」）`128 Bytes`\n3. 默认页大小为`16KB`，因此数据页最多容纳`(16*1024-128)/3525=4`个行记录（这里`Page Directory`可忽略不计）\n4. 插入`4`条记录后，只有一个`Leaf Page`，再插入第`5`条记录时，`B+Tree`索引会`分裂`\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_insert_00.png\" width=\"500\">\n\n#### Insert 50\n```SQL\nmysql> INSERT INTO t SELECT 50,REPEAT('a',3500);\nQuery OK, 1 row affected (0.02 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0001>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\nTotal number of page: 6:\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 3\nFile Segment inode: 1\n```\n```\n# page offset=3\n0000c070: 7375 7072 656d 756d 0010 0011 000e 8000  supremum........\n0000c080: 000a 0000 0004 0000 0019 ffe4 8000 001e  ................\n0000c090: 0000 0005 0000 0000 0000 0000 0000 0000  ................\n```\n\n1. 插入第5条记录`a=50`后，`10 20 30 40 50`无法完全容纳在`page offset=3`的`Leaf Page`，需要进行分裂\n2. 中间节点是`30`，将`30`（包括最小值`10`）提取到`page Offset=3`的`Index Page`（保存的是`主键a与页偏移的映射`）\n3. 将`10 20`提取到`page offset=4`的`Leaf Page`（保存的是`行记录`）\n4. 将`30 40 50`提取到`page offset=5`的`Leaf Page`（保存的是`行记录`）\n    - 如果插入的是`25`，分组为`10 20 25`和`30 40`\n\n\n| 地址 | 值（16进制） | 描述 |\n| --- | --- | --- |\n| 0xc07e~0xc085 | 8000 000a 0000 0004 | 主键`a=10`的行记录在`page offset=4`的`Leaf Page` |\n| 0xc08c~0xc093 | 8000 001e 0000 0005 | 主键`a=30`的行记录在`page offset=5`的`Leaf Page` |\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_insert_01.png\" width=\"500\">\n\n### Leaf Page未满\n\n接着上述步骤继续操作，直接将行记录`a=15`插入到`page offset=4`的`Leaf Page`\n\n#### Insert 15\n```SQL\nmysql> INSERT INTO t SELECT 15,REPEAT('a',3500);\nQuery OK, 1 row affected (0.06 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0001>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\nTotal number of page: 6:\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 3\nFile Segment inode: 1\n```\n```\n# page offset=3\n0000c070: 7375 7072 656d 756d 0010 0011 000e 8000  supremum........\n0000c080: 000a 0000 0004 0000 0019 ffe4 8000 001e  ................\n0000c090: 0000 0005 0000 0000 0000 0000 0000 0000  ................\n......\n# page offset=4\n# a=10\n00010070: 7375 7072 656d 756d ac8d 0000 0010 1b8a  supremum........\n00010080: 8000 000a 0000 0014 0b41 fc00 0001 f201  .........A......\n00010090: 1061 6161 6161 6161 6161 6161 6161 6161  .aaaaaaaaaaaaaaa\n......\n# a=20\n00010e30: 6161 6161 6161 6161 6161 6161 61ac 8d00  aaaaaaaaaaaaa...\n00010e40: 0000 18f2 2b80 0000 1400 0000 140b 42fd  ....+.........B.\n00010e50: 0000 01f3 0110 6161 6161 6161 6161 6161  ......aaaaaaaaaa\n......\n# a=15\n00011c00: 6161 ac8d 0000 0020 f23b 8000 000f 0000  aa..... .;......\n00011c10: 0014 0b4e a500 0001 fb01 1061 6161 6161  ...N.......aaaaa\n```\n\n| 地址 | 值（16进制） | 描述 |\n| --- | --- | --- |\n| 0xc07e~0xc085 | 8000 000a 0000 0004 | 主键`a=10`的行记录在`page offset=4`的`Leaf Page` |\n| 0xc08c~0xc093 | 8000 001e 0000 0005 | 主键`a=30`的行记录在`page offset=5`的`Leaf Page` |\n| 0x10080~0x10083 | 8000 000a | 主键`a=10`的行记录的`ROWID`字段 |\n| 0x10e45~0x10e48 | 8000 0014 | 主键`a=20`的行记录的`ROWID`字段 |\n| 0x11c0a~0x11c0d | 8000 000f | 主键`a=15`的行记录的`ROWID`字段 |\n\n\n1. 在`page offset=4`内可见，物理存储顺序为`10，20，15`，**`非物理有序`**，通过`Page Directory`和`next_record`保持**`逻辑有序`**（`单向有序链表`）\n2. `行记录格式`和`数据页结构`的内容请参照「InnoDB备忘录 - 行记录格式」和「InnoDB备忘录 - 数据页结构」\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_insert_02.png\" width=\"500\">\n\nLeaf Page中显示的是`逻辑顺序`10，15，20\n\n### Index Page满\n1. 拆分`Index Page`，中间节点放入上一次`Index Page`\n2. `小于`中间节点的记录放`左边Index Page`\n3. `大于`中间节点的记录放`右边Index Page`\n\n#### 表初始化\n```SQL\nmysql> CREATE TABLE t (\n    -> a VARCHAR(750) NOT NULL PRIMARY KEY,\n    -> b VARCHAR(6500)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.11 sec)\n\nmysql> DELIMITER //                                                                                                                    mysql> CREATE PROCEDURE load_t (count INT UNSIGNED)\n    -> BEGIN\n    -> SET @c=0;\n    -> WHILE @c < count DO\n    -> SET @x=(@c DIV 10);\n    -> SET @y=(@c MOD 10);\n    -> INSERT INTO t SELECT REPEAT(CONCAT(CHAR(48+@x),CHAR(48+@y)),375) , REPEAT('z',6500);\n    -> SET @c=@c+1;\n    -> END WHILE;\n    -> END;\n    -> //\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> CALL load_t(41);\nQuery OK, 0 rows affected (0.09 sec)\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0001>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\npage offset 00000006, page type <B-tree Node>, page level <0000>\npage offset 00000007, page type <B-tree Node>, page level <0000>\n......\npage offset 00000016, page type <B-tree Node>, page level <0000>\npage offset 00000017, page type <B-tree Node>, page level <0000>\npage offset 00000018, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 26:\nFreshly Allocated Page: 1\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 22\nFile Segment inode: 1\n```\n```\n# page offset=3\n0000c360: 3030 3030 3030 3030 3030 3030 3030 0000  00000000000000..\n0000c370: 0004 ee82 0000 0019 02fa 3031 3031 3031  ..........010101\n......\n0000c660: 3031 3031 3031 3031 0000 0005 ee82 0000  01010101........\n0000c670: 0021 02fa 3033 3033 3033 3033 3033 3033  .!..030303030303\n......\n0000c950: 3033 3033 3033 3033 3033 3033 3033 3033  0303030303030303\n0000c960: 3033 0000 0006 ee82 0004 0029 02fa 3035  03.........)..05\n......\n0000f8f0: 3335 3335 3335 3335 3335 3335 3335 3335  3535353535353535\n0000f900: 3335 0000 0016 ee82 0000 00a9 02fa 3337  35............37\n0000f910: 3337 3337 3337 3337 3337 3337 3337 3337  3737373737373737\n......\n0000fbf0: 3337 3337 3337 3337 3337 3337 0000 0017  373737373737....\n0000fc00: ee82 0000 00b1 c468 3339 3339 3339 3339  .......h39393939\n......\n0000fef0: 3339 3339 3339 0000 0018 0000 0000 0000  393939..........\n```\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_insert_10.png\" width=\"500\">\n\n1. `CHARSET=LATIN1 ROW_FORMAT=COMPACT`下，`Leaf Page`每个行记录占用`7273 Bytes`，页大小为`16KB`时，最多存放`(16384-128)/7273=2`个行记录\n2. `CHARSET=LATIN1 ROW_FORMAT=COMPACT`下，`Index Page`每个行记录（`索引信息`）占用`762 Bytes`，页大小为`16KB`时，最多存放`(16384-128)/762=21`个行记录\n    - `Index Page`中的每一个行记录（`索引信息`）中会指向一个`Leaf Page`，每个`Leaf Page`最多包含`2`条行记录，理论上因此应该`CALL load_t(42)`\n    - 但是在已经插入了`00 01`，准备插入`02`时，此时只有一个`Leaf Page`，没有`Index Page`，这会新建一个`Index Page`，导致`B+Tree增高`，`00`会放入一个`Leaf Page`，`01 02`放入另一个`Leaf Page`，因此只需要`CALL load_t(41)`就可以将`page offset=3`的`Index Page`塞满，再插入记录就需要进行下一步`分裂`（B+Tree继续增高）\n\n注：这里的`00`其实指的是`a=REPEAT('00',375)`的行记录\n\n#### Insert 42th Reocrd\n```SQL\nmysql> INSERT INTO t SELECT REPEAT(CONCAT(CHAR(48+4),CHAR(48+1)),375) , REPEAT('z',6500);\nQuery OK, 1 row affected (0.31 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0002>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\npage offset 00000006, page type <B-tree Node>, page level <0000>\n......\npage offset 00000017, page type <B-tree Node>, page level <0000>\npage offset 00000018, page type <B-tree Node>, page level <0000>\npage offset 00000019, page type <B-tree Node>, page level <0000>\npage offset 0000001a, page type <B-tree Node>, page level <0001>\npage offset 0000001b, page type <B-tree Node>, page level <0001>\nTotal number of page: 28:\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 25\nFile Segment inode: 1\n```\n```\n# page offset=3\n0000c360: 3030 3030 3030 3030 3030 3030 3030 0000  00000000000000..\n0000c370: 001a ee82 0000 0019 fcf6 3139 3139 3139  ..........191919\n......\n0000c660: 3139 3139 3139 3139 0000 001b 0000 0000  19191919........\n\n# page offset=0x1a\n00068030: 0000 0005 0000 000a 0000 0000 0000 0000  ................\n......\n00068360: 3030 3030 3030 3030 3030 3030 3030 0000  00000000000000..\n00068370: 0004 ee82 0000 0019 02fa 3031 3031 3031  ..........010101\n......\n00068660: 3031 3031 3031 3031 0000 0005 ee82 0000  01010101........\n00068670: 0021 02fa 3033 3033 3033 3033 3033 3033  .!..030303030303\n......\n00069b30: 3135 3135 3135 3135 3135 3135 3135 0000  15151515151515..\n00069b40: 000c ee82 0000 0059 e526 3137 3137 3137  .......Y.&171717\n......\n00069e30: 3137 3137 3137 3137 0000 000d ee82 0000  17171717........\n00069e40: 0061 02fa 3139 3139 3139 3139 3139 3139  .a..191919191919\n......\n0006bef0: 3339 3339 3339 0000 0018 0000 0000 0000  393939..........\n\n# page offset=0x1b\n0006c360: 3139 3139 3139 3139 3139 3139 3139 0000  19191919191919..\n0006c370: 000e ee82 0000 0019 02fa 3231 3231 3231  ..........212121\n......\n0006c660: 3231 3231 3231 3231 0000 000f ee82 0000  21212121........\n0006c670: 0021 02fa 3233 3233 3233 3233 3233 3233  .!..232323232323\n......\n0006e130: 3339 0000 0018 ee82 0000 0069 df32 3431  39.........i.241\n......\n0006e420: 3431 3431 3431 3431 3431 3431 0000 0019  414141414141....\n```\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_insert_11.png\" width=\"500\">\n\n1. `CALL load_t(41)`后，`page offset=3`的`Index Page`已经塞满，`page offset=18`的`Leaf Page`也已经塞满，因此在插入第42条行记录是，会新建`Leaf Page`，并且尝试将`索引信息`放入`page offset=3`的`Index Page`中\n2. `page offset=3`的`Index Page`这时需要`分裂`，将其中的中间节点`19`（包括最小节点`00`）提取到上一层的`Index Page`\n    - `00`~`17`的节点放入`page offset=1a`的`Index Page`中（其中包括了冗余节点`19`~`39`，后续再插入数据会被重用这部分空间）\n    - `19`~`39`的节点放入`page offset=1b`的`Index Page`中（新建的索引信息`41`也在这个页中）\n\n## Delete\n\n### 表初始化\n```SQL\nmysql> CREATE TABLE t (\n    -> a INT NOT NULL PRIMARY KEY,\n    -> b VARCHAR(3500)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> INSERT INTO t SELECT 0x10,REPEAT('a',3500);                                                                                     Query OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x20,REPEAT('a',3500);\nQuery OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x30,REPEAT('a',3500);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x40,REPEAT('a',3500);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x50,REPEAT('a',3500);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x60,REPEAT('a',3500);\nQuery OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x70,REPEAT('a',3500);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x80,REPEAT('a',3500);\nQuery OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0001>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\npage offset 00000006, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 8:\nFreshly Allocated Page: 1\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 4\nFile Segment inode: 1\n```\n```\n0000c060: 0200 1b69 6e66 696d 756d 0004 000b 0000  ...infimum......\n0000c070: 7375 7072 656d 756d 0010 0011 000e 8000  supremum........\n0000c080: 0010 0000 0004 0000 0019 000e 8000 0030  ...............0\n0000c090: 0000 0005 0000 0021 ffd6 8000 0070 0000  .......!.....p..\n0000c0a0: 0006 0000 0000 0000 0000 0000 0000 0000  ................\n```\n\n| 主键a | 页偏移 | 说明 |\n| --- | --- | --- |\n| 80 00 00 10 | 00 00 00 04 | 包含行记录：0x10、0x20 |\n| 80 00 00 30 | 00 00 00 05 | 包含行记录：0x30、0x40、0x50、0x60 |\n| 80 00 00 70 | 00 00 00 06 | 包含行记录：0x70、0x80 |\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_delete_00.png\" width=\"500\">\n\n### Delete 0x10\n```SQL\nmysql> DELETE FROM t WHERE a=0x10;\nQuery OK, 1 row affected (0.03 sec)\n```\n```\n# page offset=3\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0001>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\npage offset 00000006, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 8:\nFreshly Allocated Page: 1\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 4\nFile Segment inode: 1\n```\n```\n# page offset=3\n0000c060: 0200 1b69 6e66 696d 756d 0004 000b 0000  ...infimum......\n0000c070: 7375 7072 656d 756d 0010 0011 000e 8000  supremum........\n0000c080: 0010 0000 0004 0000 0019 000e 8000 0030  ...............0\n0000c090: 0000 0005 0000 0021 ffd6 8000 0070 0000  .......!.....p..\n0000c0a0: 0006 0000 0000 0000 0000 0000 0000 0000  ................\n\n# page offset=4\n00010070: 7375 7072 656d 756d ac8d 0020 0010 0dc5  supremum... ....\n00010080: 8000 0010 0000 0014 287c 7700 0001 d919  ........(|w.....\n00010090: 1061 6161 6161 6161 6161 6161 6161 6161  .aaaaaaaaaaaaaaa\n```\n\n| 主键a | 页偏移 | 说明 |\n| --- | --- | --- |\n| `80 00 00 10` | 00 00 00 04 | 包含行记录：0x10(`deleted_flag=1`)、0x20 |\n| 80 00 00 30 | 00 00 00 05 | 包含行记录：0x30、0x40、0x50、0x60 |\n| 80 00 00 70 | 00 00 00 06 | 包含行记录：0x70、0x80 |\n\n1. `DELETE`操作仅仅是将记录**`标记为删除`**（`deleted_flag=1`），实际的删除操作是在`Purge线程`中完成的\n2. `Index Page`最小的行记录依旧是`0x10`（查找所有主键小于`0x30`的行记录都将`page offset=4`的`Leaf Page`载入内存）\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_delete_01.png\" width=\"500\">\n\n### Insert 0x10\n```SQL\nmysql> INSERT INTO t SELECT 0x10,REPEAT('a',3500);\nQuery OK, 1 row affected (0.14 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n```\n# page offset=3\n0000c060: 0200 1b69 6e66 696d 756d 0004 000b 0000  ...infimum......\n0000c070: 7375 7072 656d 756d 0010 0011 000e 8000  supremum........\n0000c080: 0010 0000 0004 0000 0019 000e 8000 0030  ...............0\n0000c090: 0000 0005 0000 0021 ffd6 8000 0070 0000  .......!.....p..\n0000c0a0: 0006 0000 0000 0000 0000 0000 0000 0000  ................\n\n# page offset=4\n00010070: 7375 7072 656d 756d ac8d 0000 0010 0dc5  supremum........\n00010080: 8000 0010 0000 0014 2891 a200 0001 f801  ........(.......\n00010090: 1062 6262 6262 6262 6262 6262 6262 6262  .bbbbbbbbbbbbbbb\n```\n\n| 主键a | 页偏移 | 说明 |\n| --- | --- | --- |\n| `80 00 00 10` | 00 00 00 04 | 包含行记录：0x10、0x20 |\n| 80 00 00 30 | 00 00 00 05 | 包含行记录：0x30、0x40、0x50、0x60 |\n| 80 00 00 70 | 00 00 00 06 | 包含行记录：0x70、0x80 |\n\n1. 在`Purge线程`未回收标记已删除的空间时，再次插入`0x10`，将`重用`该空间\n2. `Index Page`最小的行记录依旧是`0x10`（查找所有主键小于`0x30`的行记录都将`page offset=4`的`Leaf Page`载入内存）\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_delete_00.png\" width=\"500\">\n\n### Delete 0x10 + Insert 0x08\n```SQL\nmysql> DELETE FROM t WHERE a=0x10;\nQuery OK, 1 row affected (0.00 sec)\n\nmysql> INSERT INTO t SELECT 0x08,REPEAT('a',3500);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0001>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\npage offset 00000006, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 9:\nFreshly Allocated Page: 2\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 4\nFile Segment inode: 1\n```\n```\n# page offset=3\n0000c070: 7375 7072 656d 756d 0010 0011 000e 8000  supremum........\n0000c080: 0010 0000 0004 0000 0019 000e 8000 0030  ...............0\n0000c090: 0000 0005 0000 0021 ffd6 8000 0070 0000  .......!.....p..\n0000c0a0: 0006 0000 0000 0000 0000 0000 0000 0000  ................\n\n# page offset=4\n00010070: 7375 7072 656d 756d ac8d 0000 0010 0dc5  supremum........\n00010080: 8000 0008 0000 0014 2898 a600 0001 fc01  ........(.......\n00010090: 1061 6161 6161 6161 6161 6161 6161 6161  .aaaaaaaaaaaaaaa\n```\n\n| 主键a | 页偏移 | 说明 |\n| --- | --- | --- |\n| `80 00 00 10` | 00 00 00 04 | 包含行记录：`0x08`、0x20 |\n| 80 00 00 30 | 00 00 00 05 | 包含行记录：0x30、0x40、0x50、0x60 |\n| 80 00 00 70 | 00 00 00 06 | 包含行记录：0x70、0x80 |\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_delete_02.png\" width=\"500\">\n\n1. `0x08`重用标记为已删除的`0x10`的空间\n2. `Index Page`最小的行记录依旧是`0x10`（查找所有主键小于`0x30`的行记录都将`page offset=4`的`Leaf Page`载入内存）\n\n### Insert 0x68\n```SQL\nmysql> INSERT INTO t SELECT 0x68,REPEAT('a',3500);\nQuery OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0001>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\npage offset 00000006, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 9:\nFreshly Allocated Page: 2\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 4\nFile Segment inode: 1\n```\n```\n# page offset=3\n0000c070: 7375 7072 656d 756d 0010 0011 000e 8000  supremum........\n0000c080: 0010 0000 0004 0000 0019 000e 8000 0030  ...............0\n0000c090: 0000 0005 0000 0021 ffd6 8000 0068 0000  .......!.....h..\n0000c0a0: 0006 0000 0000 0000 0000 0000 0000 0000  ................\n\n# page offset=6\n00018070: 7375 7072 656d 756d ac8d 0000 0010 0dc5  supremum........\n00018080: 8000 0070 0000 0014 289f aa00 0001 9601  ...p....(.......\n00018090: 1061 6161 6161 6161 6161 6161 6161 6161  .aaaaaaaaaaaaaaa\n......\n00018e30: 6161 6161 6161 6161 6161 6161 61ac 8d00  aaaaaaaaaaaaa...\n00018e40: 0000 18f2 2b80 0000 8000 0000 1428 7bf6  ....+........({.\n00018e50: 0000 01ca 0110 6161 6161 6161 6161 6161  ......aaaaaaaaaa\n......\n00019c00: 6161 ac8d 0000 0020 e476 8000 0068 0000  aa..... .v...h..\n00019c10: 0014 28a0 ab00 0001 ff01 1061 6161 6161  ..(........aaaaa\n```\n| 主键a | 页偏移 | 说明 |\n| --- | --- | --- |\n| `80 00 00 10` | 00 00 00 04 | 包含行记录：`0x08`、0x20 |\n| 80 00 00 30 | 00 00 00 05 | 包含行记录：0x30、0x40、0x50、0x60 |\n| `80 00 00 68` | 00 00 00 06 | 包含行记录：`0x68`、0x70、0x80 |\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_delete_03.png\" width=\"500\">\n\n1. `Leaf Page`的行记录是`物理无序`，`逻辑有序`（通过`next_reocord`保证）\n2. `Index Page`最大的行记录从`0x70`修改了`0x68`，因为如果不修改，当查找`0x68`这条行记录时，将`page offset=5`的`Leaf Page`载入内存，而`0x68`实际上是在`page offset=6`的`Leaf Page`中\n\n### Delete 0x30,0x40,0x50,0x60\n```SQL\nmysql> DELETE FROM t WHERE a IN (0x30,0x40,0x50,0x60);\nQuery OK, 4 rows affected (0.03 sec)\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0001>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\npage offset 00000006, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 9:\nFreshly Allocated Page: 2\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 4\nFile Segment inode: 1\n```\n```\n# page offset=3\n0000c070: 7375 7072 656d 756d 0010 0011 001c 8000  supremum........\n0000c080: 0010 0000 0004 0000 0019 0000 8000 0030  ...............0\n0000c090: 0000 0005 0000 0021 ffd6 8000 0068 0000  .......!.....h..\n0000c0a0: 0006 0000 0000 0000 0000 0000 0000 0000  ................\n\n# page offset=4\n00010000: 6e19 4026 0000 0004 ffff ffff 0000 0006  n.@&............\n\n# page offset=5\n00014070: 7375 7072 656d 756d ac8d 0020 0010 294f  supremum... ..)O\n00014080: 8000 0030 0000 0014 28a5 2e00 0002 060a  ...0....(.......\n......\n00014e30: 6161 6161 6161 6161 6161 6161 61ac 8d00  aaaaaaaaaaaaa...\n00014e40: 2000 180d c580 0000 4000 0000 1428 a52e   .......@....(..\n00014e50: 0000 0206 0a8e 6161 6161 6161 6161 6161  ......aaaaaaaaaa\n......\n00015c00: 6161 ac8d 0020 0020 0000 8000 0050 0000  aa... . .....P..\n00015c10: 0014 28a5 2e00 0002 060a b161 6161 6161  ..(........aaaaa\n......\n000169c0: 6161 6161 6161 61ac 8d00 2000 28d6 a180  aaaaaaa... .(...\n000169d0: 0000 6000 0000 1428 a52e 0000 0206 0ad4  ..`....(........\n```\n\n| 主键a | 页偏移 | 说明 |\n| --- | --- | --- |\n| `80 00 00 10` | 00 00 00 04 | 包含行记录：`0x08`、0x20 |\n| `80 00 00 68` | 00 00 00 06 | 包含行记录：`0x68`、0x70、0x80 |\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_delete_04.png\" width=\"500\">\n\n1. `page offset=5`的`Leaf Page`中的行记录0x30、0x40、0x50、0x60`标记为已删除`\n2. `page offset=4`的`Leaf Page`中的`FIL_PAGE_NEXT`从`5`变成了`6`（`0x1000c~1000f`）\n3. `Index Page`中行记录的`单向链表`也由`0x10->0x30->0x68`变成了`0x10->0x68`\n\n### Insert 0x48\n```SQL\nmysql> INSERT INTO t SELECT 0x48,REPEAT('a',3500);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0001>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\npage offset 00000006, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 9:\nFreshly Allocated Page: 2\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 4\nFile Segment inode: 1\n```\n```\n# page offset=3\n0000c070: 7375 7072 656d 756d 0010 0011 001c 8000  supremum........\n0000c080: 0010 0000 0004 0000 0019 0000 8000 0030  ...............0\n0000c090: 0000 0005 0000 0021 ffd6 8000 0068 0000  .......!.....h..\n0000c0a0: 0006 0000 0000 0000 0000 0000 0000 0000  ................\n\n# page offset=4\n00011c00: 6161 ac8d 0000 0020 e466 8000 0048 0000  aa..... .f...H..\n00011c10: 0014 28b6 b700 0001 9401 1061 6161 6161  ..(........aaaaa\n```\n\n| 主键a | 页偏移 | 说明 |\n| --- | --- | --- |\n| `80 00 00 10` | 00 00 00 04 | 包含行记录：`0x08`、0x20、`0x48` |\n| `80 00 00 68` | 00 00 00 06 | 包含行记录：`0x68`、0x70、0x80 |\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_delete_05.png\" width=\"500\">\n\n## Update\n\n### 表初始化\n```SQL\nmysql> CREATE TABLE t (\n    -> a INT NOT NULL PRIMARY KEY,\n    -> b VARCHAR(3500)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> INSERT INTO t SELECT 0x10,REPEAT('a',3500);                                                                                     Query OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x20,REPEAT('a',3500);\nQuery OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x30,REPEAT('a',3500);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x40,REPEAT('a',3500);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x50,REPEAT('a',3500);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x60,REPEAT('a',3500);\nQuery OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x70,REPEAT('a',3500);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x80,REPEAT('a',3500);\nQuery OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_delete_00.png\" width=\"500\">\n\n### 更新主键列\n```SQL\nmysql> UPDATE t SET a=0x68 WHERE a=0x70;\nQuery OK, 1 row affected (0.01 sec)\nRows matched: 1  Changed: 1  Warnings: 0\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0001>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\npage offset 00000006, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 9:\nFreshly Allocated Page: 2\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 4\nFile Segment inode: 1\n```\n```\n# page offset=3\n0000c070: 7375 7072 656d 756d 0010 0011 000e 8000  supremum........\n0000c080: 0010 0000 0004 0000 0019 000e 8000 0030  ...............0\n0000c090: 0000 0005 0000 0021 ffd6 8000 0068 0000  .......!.....h..\n0000c0a0: 0006 0000 0000 0000 0000 0000 0000 0000  ................\n\n# page offset=6\n00018070: 7375 7072 656d 756d ac8d 0020 0010 0dc5  supremum... ....\n00018080: 8000 0070 0000 0014 28e6 3800 0002 3003  ...p....(.8...0.\n00018090: f761 6161 6161 6161 6161 6161 6161 6161  .aaaaaaaaaaaaaaa\n......\n00018e30: 6161 6161 6161 6161 6161 6161 61ac 8d00  aaaaaaaaaaaaa...\n00018e40: 0000 18f2 2b80 0000 8000 0000 1428 e1b5  ....+........(..\n00018e50: 0000 0191 0110 6161 6161 6161 6161 6161  ......aaaaaaaaaa\n......\n00019c00: 6161 ac8d 0000 0020 e476 8000 0068 0000  aa..... .v...h..\n00019c10: 0014 28e6 b800 0001 9701 1061 6161 6161  ..(........aaaaa\n00019c20: 6161 6161 6161 6161 6161 6161 6161 6161  aaaaaaaaaaaaaaaa\n```\n\n| 主键a | 页偏移 | 说明 |\n| --- | --- | --- |\n| 80 00 00 10 | 00 00 00 04 | 包含行记录：0x10，0x20 |\n| 80 00 00 30 | 00 00 00 05 | 包含行记录：0x30、0x40、0x50、0x60 |\n| `80 00 00 68` | 00 00 00 06 | 包含行记录：0x68、0x70(`deleted_flag=1`)、0x80 |\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_update_00.png\" width=\"500\">\n\n1. 更新主键`a:0x70->0x68`，首先是**`逻辑删除`**`0x70`（`MVCC`特性），然后再插入`0x68`\n2. 如果插入的过程中会影响查询过程，会同步更新`Index Page`\n\n### 更新非主键列\n```SQL\nmysql> UPDATE t SET b=REPEAT('b',100) WHERE a=0x68;\nQuery OK, 1 row affected (0.00 sec)\nRows matched: 1  Changed: 1  Warnings: 0\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0001>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\npage offset 00000006, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 9:\nFreshly Allocated Page: 2\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 4\nFile Segment inode: 1\n```\n```\n# page offset=3\n0000c070: 7375 7072 656d 756d 0010 0011 000e 8000  supremum........\n0000c080: 0010 0000 0004 0000 0019 000e 8000 0030  ...............0\n0000c090: 0000 0005 0000 0021 ffd6 8000 0068 0000  .......!.....h..\n0000c0a0: 0006 0000 0000 0000 0000 0000 0000 0000  ................\n\n# page offset=6\n00019c00: 6161 6400 0000 20f2 3c80 0000 6800 0000  aad... .<...h...\n00019c10: 1428 e839 0000 0220 14fe 6262 6262 6262  .(.9... ..bbbbbb\n00019c20: 6262 6262 6262 6262 6262 6262 6262 6262  bbbbbbbbbbbbbbbb\n00019c30: 6262 6262 6262 6262 6262 6262 6262 6262  bbbbbbbbbbbbbbbb\n00019c40: 6262 6262 6262 6262 6262 6262 6262 6262  bbbbbbbbbbbbbbbb\n00019c50: 6262 6262 6262 6262 6262 6262 6262 6262  bbbbbbbbbbbbbbbb\n00019c60: 6262 6262 6262 6262 6262 6262 6262 6262  bbbbbbbbbbbbbbbb\n00019c70: 6262 6262 6262 6262 6262 6262 6262 6161  bbbbbbbbbbbbbbaa\n00019c80: 6161 6161 6161 6161 6161 6161 6161 6161  aaaaaaaaaaaaaaaa\n```\n\n更新非主键列时`无需逻辑删除`，`直接更新`相应行记录\n\n\n# 聚集索引与辅助索引\n\n```SQL\nmysql> CREATE TABLE t (\n    -> a INT NOT NULL,\n    -> b INT NOT NULL,\n    -> c VARCHAR(3500),\n    -> PRIMARY KEY (a),\n    -> KEY (b)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.13 sec)\n\nmysql> SHOW INDEX FROM t;\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+\n| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+\n| t     |          0 | PRIMARY  |            1 | a           | A         |           0 |     NULL | NULL   |      | BTREE      |         |               |\n| t     |          1 | b        |            1 | b           | A         |           0 |     NULL | NULL   |      | BTREE      |         |               |\n+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+\n2 rows in set (0.00 sec)\n\nmysql> INSERT INTO t SELECT 0x10,0x100,REPEAT('a',3500);\nQuery OK, 1 row affected (0.04 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x20,0x200,REPEAT('a',3500);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x30,0x300,REPEAT('a',3500);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x40,0x400,REPEAT('a',3500);\nQuery OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 0x50,0x500,REPEAT('a',3500);\nQuery OK, 1 row affected (0.02 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0001>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\npage offset 00000006, page type <B-tree Node>, page level <0000>\nTotal number of page: 7:\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 4\nFile Segment inode: 1\n```\n```\n# page offset=3\n0000c060: 0200 1b69 6e66 696d 756d 0003 000b 0000  ...infimum......\n0000c070: 7375 7072 656d 756d 0010 0011 000e 8000  supremum........\n0000c080: 0010 0000 0005 0000 0019 ffe4 8000 0030  ...............0\n0000c090: 0000 0006 0000 0000 0000 0000 0000 0000  ................\n\n# page offset=4\n00010070: 7375 7072 656d 756d 0000 1000 0d80 0001  supremum........\n00010080: 0080 0000 1000 0018 000d 8000 0200 8000  ................\n00010090: 0020 0000 2000 0d80 0003 0080 0000 3000  . .. .........0.\n000100a0: 0028 000d 8000 0400 8000 0040 0000 30ff  .(.........@..0.\n000100b0: bf80 0005 0080 0000 5000 0000 0000 0000  ........P.......\n\n# page offset=5\n00014070: 7375 7072 656d 756d ac8d 0000 0010 0dc9  supremum........\n00014080: 8000 0010 0000 0014 2917 da00 0001 ac01  ........).......\n00014090: 1080 0001 0061 6161 6161 6161 6161 6161  .....aaaaaaaaaaa\n......\n00014e40: 61ac 8d00 0000 18f2 2780 0000 2000 0000  a.......'... ...\n00014e50: 1429 18db 0000 01ad 0110 8000 0200 6161  .)............aa\n00014e60: 6161 6161 6161 6161 6161 6161 6161 6161  aaaaaaaaaaaaaaaa\n\n# page offset=6\n00018070: 7375 7072 656d 756d ac8d 0000 0010 0dc9  supremum........\n00018080: 8000 0030 0000 0014 291d de00 0001 b301  ...0....).......\n00018090: 1080 0003 0061 6161 6161 6161 6161 6161  .....aaaaaaaaaaa\n......\n00018e40: 61ac 8d00 0000 180d c980 0000 4000 0000  a...........@...\n00018e50: 1429 1edf 0000 01b7 0110 8000 0400 6161  .)............aa\n......\n00019c00: 6161 6161 6161 6161 6161 ac8d 0000 0020  aaaaaaaaaa.....\n00019c10: e45e 8000 0050 0000 0014 2923 e200 0001  .^...P....)#....\n00019c20: c501 1080 0005 0061 6161 6161 6161 6161  .......aaaaaaaaa\n```\n\n聚集索引的`Index Page`（目前只有一个Page）在`page offset=3`\n\n| 地址 | 16进制 | 描述 |\n| --- | --- | --- |\n| 0xc07e~0xc085 | 8000 0010 0000 0005 | `a=0x10`的行记录在`page offset=5`的`Leaf Page`上 |\n| 0xc08c~0xc093 | 8000 0030 0000 0006 | `a=0x30`的行记录在`page offset=6`的`Leaf Page`上 |\n\n辅助索引的`Index Page`（目前只有一个Page）在`page offset=4`\n\n| 地址 | 16进制 | 描述 |\n| --- | --- | --- |\n| 0x1007d~0x10084 | 8000 0100 8000 0010  | `b=0x100`对应`a=0x10` |\n| 0x1008a~0x10091 | 8000 0100 8000 0010  | `b=0x200`对应`a=0x20` |\n| 0x10097~0x1009e | 8000 0100 8000 0010  | `b=0x300`对应`a=0x30` |\n| 0x100a4~0x100ab | 8000 0100 8000 0010  | `b=0x400`对应`a=0x40` |\n| 0x100b1~0x100b8 | 8000 0100 8000 0010  | `b=0x500`对应`a=0x50` |\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_clustered_secondary.png\" width=\"500\">\n\n# 联合索引\n当表中有`联合索引(a,b)`，能有效利用联合索引的查询（因为索引已经按a，b的顺序进行排序）\n\n1. `WHERE a=xxx AND b=xxx`\n2. `WHERE a=xxx`\n3. `WHERE a=xxx ORDER BY b`\n\n不能有效利用联合索引的查询：`WHERE b=xxx`，因为没有索引`(b)`或索引`(b,a)`\n\n```SQL\nmysql> CREATE TABLE t (\n    -> a INT NOT NULL,\n    -> b INT NOT NULL,\n    -> c VARCHAR(3500),\n    -> PRIMARY KEY (a,b)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.03 sec)\n\nmysql> INSERT INTO t SELECT 1,1,REPEAT('a',3500);\nQuery OK, 1 row affected (0.05 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 2,1,REPEAT('a',3500);\nQuery OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 2,2,REPEAT('a',3500);\nQuery OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 2,3,REPEAT('a',3500);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT 3,1,REPEAT('a',3500);\nQuery OK, 1 row affected (0.01 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0001>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\nTotal number of page: 6:\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 3\nFile Segment inode: 1\n```\n```\n# page offset=3\n0000c070: 7375 7072 656d 756d 0010 0011 0012 8000  supremum........\n0000c080: 0001 8000 0001 0000 0004 0000 0019 ffe0  ................\n0000c090: 8000 0002 8000 0002 0000 0005 0000 0000  ................\n\n```\n\n\n| 地址 | 16进制 | 描述 |\n| --- | --- | --- |\n| 0xc07e~0xc089 | 8000 0001 8000 0001 0000 0004 |  `a=1,b=1`的行记录在`page offset=4`的`Leaf Page`上 |\n| 0xc090~0xc09b | 8000 0002 8000 0002 0000 0005 |  `a=2,b=2`的行记录在`page offset=5`的`Leaf Page`上 |\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/btree_index_multi_clo_index.png\" width=\"500\">\n\n# 参考资料\n\n1. [MySQL技术内幕 - InnoDB存储引擎 V2](https://book.douban.com/subject/24708143/)\n2. [Clustered and Secondary Indexes](https://dev.mysql.com/doc/refman/5.7/en/innodb-index-types.html)\n\n<!-- indicate-the-source -->\n","tags":["InnoDB"],"categories":["InnoDB"]},{"title":"InnoDB -- 数据页结构","url":"%2F2017%2F05%2F08%2Finnodb-table-page-structure%2F","content":"\n{% note info %}\n本文主要介绍`InnoDB`存储引擎的`数据页结构`\n{% endnote %}\n\n<!-- more -->\n\n# 数据页结构\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/page_structure.png\" width=\"500\">\n\n## File Header\n参考链接：[Fil Header](https://dev.mysql.com/doc/internals/en/innodb-fil-header.html)\n\n1. 总共`38 Bytes`，记录页的`头信息`\n\n| 名称 | 大小（Bytes） | 描述 |\n| --- | --- | --- |\n| FIL_PAGE_SPACE | 4 | 该页的`checksum`值 |\n| FIL_PAGE_OFFSET | 4 | 该页在表空间中的`页偏移量` |\n| FIL_PAGE_PREV | 4 | 该页的上一个页 |\n| FIL_PAGE_NEXT | 4 | 该页的下一个页 |\n| FIL_PAGE_LSN | 8 | 该页最后被修改的LSN |\n| FIL_PAGE_TYPE | 2 | 该页的类型，`0x45BF为数据页` |\n| FIL_PAGE_FILE_FLUSH_LSN | 8 | 独立表空间中为`0` |\n| FIL_PAGE_ARCH_LOG_NO | 4 | 该页属于哪一个表空间 |\n\n## Page Header\n参考链接：[Page Header](https://dev.mysql.com/doc/internals/en/innodb-page-header.html)\n\n1. 总共`56 Bytes`，记录页的`状态信息`\n\n| 名称 | 大小（Bytes） | 描述 |\n| --- | --- | --- |\n| PAGE_N_DIR_SLOTS | 2 | 在`Page Directory`中`Slot`的数量，初始值为`2` |\n| PAGE_HEAP_TOP | 2 | 堆中第一个记录的指针 |\n| PAGE_N_HEAP | 2 | 堆中的记录数，初始值为`2` |\n| PAGE_FREE | 2 | 指向`可重用空间`的首指针 |\n| PAGE_GARBAGE | 2 | 已标记为删除（`deleted_flag`）的记录的字节数 |\n| PAGE_LAST_INSERT | 2 | 最后插入记录的位置 |\n| PAGE_DIRECTION | 2 | 最后插入的方向，`PAGE_LEFT(0x01)`，`PAGE_RIGHT(0x02)`，`PAGE_NO_DIRECTION(0x05)` |\n| PAGE_N_DIRECTION | 2 | 一个方向上连续插入记录的数量 |\n| PAGE_N_RECS | 2 | 该页中记录（`User Record`）的数量 |\n| PAGE_MAX_TRX_ID | 8 | 修改该页的最大事务ID（仅在`辅助索引`中定义） |\n| PAGE_LEVEL | 2 | 该页在索引树中位置，`0000代表叶子节点` |\n| PAGE_INDEX_ID | 8 | 索引ID，表示`该页属于哪个索引` |\n| PAGE_BTR_SEG_LEAF | 10 | B+Tree叶子节点所在`Leaf Node Segment`的Segment Header（无关紧要） |\n| PAGE_BTR_SEG_TOP | 10 | B+Tree非叶子节点所在`Non-Leaf Node Segment`的Segment Header（无关紧要） |\n\n## Infimum + Supremum Records\n参考链接：[The Infimum and Supremum Records](https://dev.mysql.com/doc/internals/en/innodb-infimum-and-supremum-records.html)\n\n1. 每个数据页中都有两个`虚拟的行记录`，用来限定记录（`User Record`）的边界（`Infimum为下界`，`Supremum为上界`）\n2. `Infimum`和`Supremum`在`页被创建`是自动创建，`不会被删除`\n3. 在`Compact`和`Redundant`行记录格式下，`Infimum`和`Supremum`占用的`字节数是不一样`的\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/page_structure.png\" width=\"500\">\n\n## User Records\n参考链接：[User Records](https://dev.mysql.com/doc/internals/en/innodb-user-records.html)\n\n1. 存储`实际插入的行记录`\n2. 在`Page Header`中`PAGE_HEAP_TOP`、`PAGE_N_HEAP`的`HEAP`，实际上指的是`Unordered User Record List`\n    - InnoDB不想每次都`依据B+Tree键的顺序`来`插入新行`，因为这可能需要`移动大量的数据`\n    - 因此InnoDB插入新行时，通常是插入到当前行的后面（`Free Space的顶部`）或者是`已删除行留下来的空间`\n3. 为了保证访问B+Tree记录的`顺序性`，在每个记录中都有一个指向`下一条记录的指针`，以此构成了一条**`单向有序链表`**\n\n## Free Space\n1. 空闲空间，数据结构是`链表`，在一个记录`被删除`后，该空间会被加入到空闲链表中\n\n## Page Directory\n参考链接：[Page Directory](https://dev.mysql.com/doc/internals/en/innodb-page-directory.html)\n\n1. 存放着`行记录`（`User Record`）的`相对位置`（不是偏移量）\n2. 这里的`行记录指针称`为`Slot`或`Directory Slot`，每个`Slot`占用`2Byte`\n3. `并不是每一个行记录都有一个Slot`，一个Slot中可能包含多条行记录，通过行记录中`n_owned`字段标识\n4. `Infimum`的n_owned总是`1`，`Supremum`的n_owned为`[1,8]`，`User Record`的n_owned为`[4,8]`\n5. `Slot`是按照`索引键值的顺序`进行`逆序`存放（`Infimum是下界，Supremum是上界`），可以利用`二分查找`快速地定位一个`粗略的结果`，然后再通过`next_record`进行`精确查找`\n7. `B+Tree索引`本身并`不能直接找到具体的一行记录`，只能找到该`行记录所在的页`\n    - 数据库把页载入到`内存`中，然后通过`Page Directory`再进行`二分查找`\n    - 二分查找时间复杂度很低，又在内存中进行查找，这部分的时间基本开销可以忽略\n\n## File Trailer\n参考链接：[Fil Trailer](https://dev.mysql.com/doc/internals/en/innodb-fil-trailer.html)\n\n1. 总共`8 Bytes`，为了`检测页是否已经完整地写入磁盘`\n2. 变量`innodb_checksums`，InnoDB`从磁盘读取一个页`时是否会`检测页的完整性`\n3. 变量`innodb_checksum_algorithm`，`检验和算法`\n\n| 名称 | 大小（Bytes） | 描述 |\n| --- | --- | --- |\n| FIL_PAGE_END_LSN | 8 |  前4Bytes与File Header中的FIL_PAGE_SPACE一致，后4Bytes与File Header中的FIL_PAGE_LSN的后4Bytes一致 |\n\n```SQL\nmysql> SHOW VARIABLES LIKE 'innodb_checksums';\n+------------------+-------+\n| Variable_name    | Value |\n+------------------+-------+\n| innodb_checksums | ON    |\n+------------------+-------+\n1 row in set (0.01 sec)\n\nmysql> SHOW VARIABLES LIKE 'innodb_checksum_algorithm';\n+---------------------------+-------+\n| Variable_name             | Value |\n+---------------------------+-------+\n| innodb_checksum_algorithm | crc32 |\n+---------------------------+-------+\n1 row in set (0.00 sec)\n```\n\n# 实例\n\n## 表初始化\n```SQL\nmysql> CREATE TABLE t (\n    -> a INT UNSIGNED NOT NULL AUTO_INCREMENT,\n    -> b CHAR(10),\n    -> PRIMARY KEY(a)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.89 sec)\n\nmysql> DELIMITER //\nmysql> CREATE PROCEDURE load_t (count INT UNSIGNED)\n    -> BEGIN\n    -> SET @c=0;\n    -> WHILE @c < count DO\n    -> INSERT INTO t SELECT NULL,REPEAT(CHAR(97+RAND()*26),10);\n    -> SET @c=@c+1;\n    -> END WHILE;\n    -> END;\n    -> //\nQuery OK, 0 rows affected (0.06 sec)\n\nmysql> DELIMITER ;\nmysql> CALL load_t(100);\nQuery OK, 0 rows affected (0.22 sec)\n\nmysql> SELECT * FROM t LIMIT 5;\n+---+------------+\n| a | b          |\n+---+------------+\n| 1 | uuuuuuuuuu |\n| 2 | qqqqqqqqqq |\n| 3 | xxxxxxxxxx |\n| 4 | oooooooooo |\n| 5 | cccccccccc |\n+---+------------+\n5 rows in set (0.02 sec)\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 6:\nFreshly Allocated Page: 2\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 1\nFile Segment inode: 1\n```\n\n1. `CHARSET=LATIN1 ROW_FORMAT=COMPACT`下调用存储过程`load_t`，插入的每个行记录大小为`33 Bytes`(行记录格式的相关内容请参「InnoDB备忘录 - 行记录格式」)，因此`CALL load_t(100)`将插入`3300 Bytes`，这`远小于页大小16KB`，一个数据页内完全容纳这些数据，即完全在`page offset=3`的`B+Tree叶子节点`中\n\n## File Header\n```\n# Vim,:%!xxd\n0000c000: d42f 4c48 0000 0003 ffff ffff ffff ffff  ./LH............\n0000c010: 0000 0000 4091 c84f 45bf 0000 0000 0000  ....@..OE.......\n0000c020: 0000 0000 0120 001a 0d5c 8066 0000 0000  ..... ...\\.f....\n```\n| 16进制 | 名称 | 描述 |\n| --- | --- | --- |\n| d4 2f 4c 48 | FIL_PAGE_SPACE | 该页的`checksum`值  |\n| 00 00 00 03 | FIL_PAGE_OFFSET | 该页`page 0ffset=3` |\n| ff ff ff ff | FIL_PAGE_PREV | 目前只有一个数据页，无上一页 |\n| ff ff ff ff | FIL_PAGE_NEXT | 目前只有一个数据页，无下一页 |\n| 00 00 00 00 40 91 c8 4f | FIL_PAGE_LSN | 该页最后被修改的LSN |\n| 45 bf | FIL_PAGE_TYPE | 数据页 |\n| 00 00 00 00 00 00 00 00 | FIL_PAGE_FILE_FLUSH_LSN | 独立表空间中为`0` |\n| 00 00 01 20 | FIL_PAGE_ARCH_LOG_NO | 该页属于哪一个表空间 | |\n\n## File Trailer\n```\n# Vim,:%!xxd\n0000fff0: 01e9 0165 00e1 0063 d42f 4c48 4091 c84f  ...e...c./LH@..O\n```\n| 16进制 | 名称 | 描述 |\n| --- | --- | --- |\n| d4 2f 4c 48 40 91 c8 4f | FIL_PAGE_END_LSN | 前4Bytes与File Header中的FIL_PAGE_SPACE一致，后4Bytes与File Header中的FIL_PAGE_LSN的后4Bytes一致 |\n\n\n\n## Page Header\n```\n# Vim,:%!xxd\n0000c020: 0000 0000 0120 001a 0d5c 8066 0000 0000  ..... ...\\.f....\n0000c030: 0d41 0002 0063 0064 0000 0000 0000 0000  .A...c.d........\n0000c040: 0000 0000 0000 0000 0164 0000 0120 0000  .........d... ..\n0000c050: 0002 00f2 0000 0120 0000 0002 0032 0100  ....... .....2..\n......\n0000cd40: 2f00 0000 6400 0000 1409 e6a3 0000 01f9  /...d...........\n0000cd50: 0110 6d6d 6d6d 6d6d 6d6d 6d6d 0000 0000  ..mmmmmmmmmm....\n```\n| 16进制 | 名称 | 描述 |\n| --- | --- | --- |\n| 00 1a | PAGE_N_DIR_SLOTS | Page Directory有`26个Slot`，每个Slot占用`2Byte`，因此范围为`0xffc4~0xfff7` |\n| 0d 5c | PAGE_HEAP_TOP | `Free Space`开始位置的偏移量，`0xc000+0x0d5c=0xcd5c` |\n| 80 66 | PAGE_N_HEAP | `Compact`时，初始值为`0x8002`（`Redundant`时，初始值为`2`），行记录数为`0x8066-0x8002=0x64=100` |\n| 00 00 | PAGE_FREE | `未执行删除操作`，无可重用空间，该值为`0`|\n| 00 00 | PAGE_GARBAGE | `未执行删除操作`，标记为删除的记录的字节数为`0` |\n| 0d 41 | PAGE_LAST_INSERT | `0xc000+0x0d41=0xcd41`，直接指向`ROWID` |\n| 00 02 | PAGE_DIRECTION | `PAGE_RIGHT`，通过`自增主键`的方式插入行记录 |\n| 00 63 | PAGE_N_DIRECTION | `0x63=99`，通过`自增主键`的方式插入行记录|\n| 00 64 | PAGE_N_RECS | `0x64=100`，与`PAGE_N_HEAP`中计算一致 |\n| 00 00 00 00 00 00 00 00 | PAGE_MAX_TRX_ID | ？？ |\n| 00 00 | PAGE_LEVEL | 叶子节点 |\n| 00 00 00 00 00 00 01 64 | PAGE_INDEX_ID | 索引ID |\n| 00 00 01 20 00 00 00 02 00 f2 | PAGE_BTR_SEG_LEAF | 无关紧要 |\n| 00 00 01 20 00 00 00 02 00 32 | PAGE_BTR_SEG_TOP | 无关紧要 |\n\n1. `PAGE_HEAP_TOP`的计算过程：`38(File Header)+56(Page Header)+13(Infimum)+13(Supremum)+33*100(User Record)=3420=0xd5c`\n2. `User Record`是`向下生长`，`Page Directory`是`向上生长`\n\n## Infimum + Supremum Records\n```\n# Vim,:%!xxd\n0000c050: 0002 00f2 0000 0120 0000 0002 0032 0100  ....... .....2..\n0000c060: 0200 1b69 6e66 696d 756d 0005 000b 0000  ...infimum......\n0000c070: 7375 7072 656d 756d 0000 0010 0021 0000  supremum.....!..\n0000c080: 0001 0000 0014 097f be00 0002 0401 1075  ...............u\n```\n\n### Infimum Records\n| 16进制 | 名称 | 描述 |\n| --- | --- | --- |\n| 01 00 02 00 1b | 记录头信息 | `0xc05e+0x1b=0xc079`，指向`第1个行记录的记录头`；`n_owned=1` |\n| 69 6e 66 69 6d 75 6d 00 | `伪列` | `CHAR(8)，infimum` |\n\n### Supremum Records\n| 16进制 | 名称 | 描述 |\n| --- | --- | --- |\n| 05 00 0b 00 00 | 记录头信息 | `00`，无下一个行记录；`n_owned=5` |\n| 73 75 70 72 65 6d 75 6d | `伪列` | `CHAR(8)，supremum` |\n\n## User Records\n行记录格式的相关内容请参「InnoDB备忘录 - 行记录格式」，这里仅给出第1个行记录的解析\n```\n# Vim,:%!xxd\n0000c070: 7375 7072 656d 756d 0000 0010 0021 0000  supremum.....!..\n0000c080: 0001 0000 0014 097f be00 0002 0401 1075  ...............u\n0000c090: 7575 7575 7575 7575 7500 0000 1800 2100  uuuuuuuuu.....!.\n```\n| 16进制 | 名称 | 描述 |\n| --- | --- | --- |\n|   | 变长字段列表 | 表中没有变长字段 |\n| 00 | NULL标志位 | 该行记录没有列为NULL |\n| 00 00 10 00 21 | 记录头信息 | `0xc078+0x21=0xc099`，指向第`2`个行记录 |\n| 00 00 00 01 | ROWID | 表显式定义主键`a` |\n| 00 00 00 14 09 7f  | Transaction ID | 事务ID |\n| be 00 00 02 04 01 10 | Roll Pointer | 回滚指针 |\n| 75 75 75 75 75 75 75 75 75 75 | 列`b` | 字符串`uuuuuuuuuu` |\n\n## Page Directory\n`Page Header`中的`PAGE_N_DIR_SLOTS`为`26`，能推断出`Page Directory`的范围为`0xffc4~0xfff7`\n```\n# Vim,:%!xxd\n0000ffc0: 0000 0000 0070 0cbd 0c39 0bb5 0b31 0aad  .....p...9...1..\n0000ffd0: 0a29 09a5 0921 089d 0819 0795 0711 068d  .)...!..........\n0000ffe0: 0609 0585 0501 047d 03f9 0375 02f1 026d  .......}...u...m\n0000fff0: 01e9 0165 00e1 0063 d42f 4c48 4091 c84f  ...e...c./LH@..O\n```\n\n### 逆序放置\n1. `0xfff6~0xfff7`为`0x0063`，`0xc000+0x0063=0xc063`，指向的是**`Infimum Record`**（逻辑下界）的`伪列`（CHAR(8),'infimum'）\n\n2. `0xffc4~0xffc5`为`0x0070`，`0xc000+0x0070=0xc070`，指向的是**`Supremum Record`**（逻辑上界）的`伪列`（CHAR(8),'supremum'）\n\n### 二分查找\n下面以查找`主键a=25`为例，展示利用`Page Directory`进行`二分查找`的过程\n\n#### (0xfff7+0xffc4)/2 = 0xffdd\n`0xffdc~0xffdd`为`0x0711`，`0xc000+0x0711=0xc711`\n`0xc711~0xc714`为`0x34`，由于`0x34=52>25`，选择`0xfff7`作为下一轮查找的逻辑下界\n```\n0000c710: 2100 0000 3400 0000 1409 b6d3 0000 0212  !...4...........\n```\n\n#### (0xfff7+0xffdd)/2 = 0xffea\n`0xffea~0xffeb`为`0x0375`，`0xc000+0x0375=0xc375`\n`0xc375~0xc378`为`0x18`，由于`0x18=24<25`，选择`0xffdd`作为下一轮查找的逻辑上界\n```\n0000c370: 0400 c800 2100 0000 1800 0000 1409 9ab7  ....!...........\n```\n\n#### (0xffea+0xffdd)/2 = 0xffe3\n`0xffe2~0xffe3`为`0x0585`，`0xc000+0x0585=0xc585`\n`0xc585~0xc588`为`0x18`，由于`0x28=40>25`，选择`0xffea`作为下一轮查找的逻辑下界\n```\n0000c580: 0401 4800 2100 0000 2800 0000 1409 aac7  ..H.!...(.......\n```\n\n#### (0xffea+0xffe3)/2 = 0xffe6\n`0xffe6~0xffe7`为`0x047d`，`0xc000+0x047d=0xc47d`\n`0xc47d~0xc480`为`0x20`，由于`0x20=32>25`，选择`0xffea`作为下一轮查找的逻辑下界\n```\n0000c470: 7272 7272 7272 7200 0401 0800 2100 0000  rrrrrrr.....!...\n0000c480: 2000 0000 1409 a2bf 0000 019c 0110 6565   .............ee\n```\n\n#### (0xffea+0xffe6)/2 = 0xffe8\n`0xffe8~0xffe9`为`0x03f9`，`0xc000+0x03f9=0xc3f9`\n`0xc3f9~0xc3fc`为`0x1c`，由于`0x1c=28>25`，选择`0xffea`作为下一轮查找的逻辑下界\n```\n0000c3f0: 6666 6600 0400 e800 2100 0000 1c00 0000  fff.....!.......\n```\n\n#### (0xffea+0xffe8)/2 = 0xffe9\n`0xffe8~0xffe9`跟上一步得到的`Slot`一致，目前只得到了`粗略的结果`，下面需要从逻辑上界`0xffea`开始通过`next_record`进行精确查找（`单向链表遍历`）\n\n### next_record\n上面二分查找的结果是`0xffea`，`0xffea~0xffeb`为`0x0375`，`0xc000+0x0375=0xc375`\n`0xc375~0xc378`为`0x18=24`，下一个行记录的偏移为`0x21`(记录头信息)，`0xc375+0x21=0xc396`\n`0xc396~0xc399`为`0x19=25`，终于找到了主键`a=25`的行记录!!\n```\n0000c370: 0400 c800 2100 0000 1800 0000 1409 9ab7  ....!...........\n0000c380: 0000 0194 0110 6666 6666 6666 6666 6666  ......ffffffffff\n0000c390: 0000 00d0 0021 0000 0019 0000 0014 099b  .....!..........\n```\n\n# 参考资料\n\n1. [MySQL技术内幕 - InnoDB存储引擎 V2](https://book.douban.com/subject/24708143/)\n2. [InnoDB Page Structure](https://dev.mysql.com/doc/internals/en/innodb-page-structure.html)\n<!-- indicate-the-source -->\n","tags":["InnoDB"],"categories":["InnoDB"]},{"title":"InnoDB -- 行记录格式","url":"%2F2017%2F05%2F07%2Finnodb-table-row-format%2F","content":"\n{% note info %}\n本文主要介绍`InnoDB`存储引擎的行记录格式`ROW_FORMAT`\n{% endnote %}\n<!-- more -->\n\n# 分类\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/row_format.png\" width=\"500\">\n\n## Named File Format\n1. InnoDB`早期`的文件格式（`页格式`）为`Antelope`，可以定义两种行记录格式，分别是`Compact`和`Redundant`\n2. `Named File Format`为了解决不同版本下`页结构的兼容性`，在`Barracuda`可以定义两种新的行记录格式`Compressed`和`Dynamic`\n3. 变量为`innodb_file_format`和`innodb_default_row_format`\n\n```SQL\nmysql>  SHOW VARIABLES LIKE 'innodb_file_format';\n+--------------------+-----------+\n| Variable_name      | Value     |\n+--------------------+-----------+\n| innodb_file_format | Barracuda |\n+--------------------+-----------+\n1 row in set (0.00 sec)\n\nmysql>  SHOW VARIABLES LIKE '%row%format%';\n+---------------------------+---------+\n| Variable_name             | Value   |\n+---------------------------+---------+\n| innodb_default_row_format | dynamic |\n+---------------------------+---------+\n1 row in set (0.38 sec)\n```\n\n## 行记录最大长度\n1. 页大小（`page size`）为`4KB`、`8KB`、`16KB`和`32KB`时，行记录最大长度（`maximum row length`）应该略小于`页大小的一半`\n    - 默认页大小为`16KB`，因此行记录最大长度应该略小于`8KB` ，因此一个`B+Tree叶子节点最少有2个行记录`\n2. 页大小为`64KB`时，行记录最大长度略小于`16KB`\n\n## CHAR(N)与VARCHAR(N)\n`N`指的是**`字符长度`**，而不是`Byte大小`，在不同的编码下，同样的字符会占用不同的空间，如`LATIN1`（`定长编码`）和`UTF8`(`变长编码`)\n\n## 变长列\n在InnoDB中，变长列（`variable-length column`）可能是以下几种情况\n\n1. `长度不固定`的数据类型，例如`VARCHAR`、`VARBINARY`、`BLOB`、`TEXT`等\n2. 对于`长度固定`的数据类型，如`CHAR`，如果`实际存储`占用的空间`大于768Byte`，InnoDB会将其视为变长列\n3. `变长编码`下的`CHAR`\n\n## 行溢出\n1. 当`行记录的长度`没有超过`行记录最大长度`时，`所有数据`都会存储在`当前页`\n2. 当`行记录的长度`超过`行记录最大长度`时，变长列（`variable-length column`）会选择外部溢出页（`overflow page`，一般是`Uncompressed BLOB Page`）进行存储\n    - `Compact` + `Redundant`：保留前`768Byte`在当前页（`B+Tree叶子节点`），其余数据存放在`溢出页`。`768Byte`后面跟着`20Byte`的数据，用来存储`指向溢出页的指针`\n\n    - `Dynamic` + `Compressed`：仅存储`20Byte`数据，存储`指向溢出页的指针`，这时比`Compact`和`Redundant`更高效，因为一个`B+Tree叶子节点`能`存放更多的行记录`\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/overflow.png\" width=\"500\">\n\n# Redundant\n`MySQL 5.0`之前的ROW_FORMAT\n\n## 格式\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/redundant_format.png\" width=\"500\">\n\n### 字段偏移列表\n1. 按照列的顺序`逆序`放置\n2. 列长度`小于255Byte`，用`1Byte`存储\n3. 列长度`大于255Byte`，用`2Byte`存储\n\n### 记录头信息\n\n| 名称 | 大小（bit） | 描述 |\n| --- | --- | --- |\n| () | 1 | 未知 |\n| () | 1 | 未知 |\n| deleted_flag | 1 | 该行是否已被删除 |\n| min_rec_flag | 1 | 如果该行记录是预定义为最小的记录，为1 |\n| **n_owned** | 4 | 该记录拥有的记录数，用于`Slot`  |\n| heap_no | 13 | 索引堆中该条记录的索引号 |\n| **n_fields** | 10 | 记录中`列的数量`，一行最多支持`1023`列 |\n| **1byte_offs_flag** | 1 | 偏移列表的单位为`1Byte`还是`2Byte` |\n| next_record | 16 | 页中下一条记录的相对位置 |\n| Total | `48(6Byte)` | nothing |\n\n### 隐藏列\n1. ROWID\n    没有`显式定义主键`或`唯一非NULL的索引`时，InnoDB会`自动创建6Byte的ROWID`\n2. Transaction ID\n    事务ID\n3. Roll Pointer\n\n## 非行溢出实例\n\n### 表初始化\n```SQL\nmysql> CREATE TABLE t (\n    -> a VARCHAR(10),\n    -> b VARCHAR(10),\n    -> c CHAR(10),\n    -> d VARCHAR(10)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=REDUNDANT;\nQuery OK, 0 rows affected (0.23 sec)\n\nmysql> INSERT INTO t VALUES ('1','22','22','333'),('4',NULL,NULL,'555');\nQuery OK, 2 rows affected (0.08 sec)\nRecords: 2  Duplicates: 0  Warnings: 0\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 6:\nFreshly Allocated Page: 2\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 1\nFile Segment inode: 1\n```\n行记录在`page offset=3`的页中\n\n### 16进制信息\n```\n# Vim,:%!xxd\n# page offset=3\n0000c000: 32d4 0518 0000 0003 ffff ffff ffff ffff  2...............\n0000c010: 0000 0000 408f 1c1b 45bf 0000 0000 0000  ....@...E.......\n0000c020: 0000 0000 0112 0002 00db 0004 0000 0000  ................\n0000c030: 00ba 0002 0001 0002 0000 0000 0000 0000  ................\n0000c040: 0000 0000 0000 0000 0156 0000 0112 0000  .........V......\n0000c050: 0002 00f2 0000 0112 0000 0002 0032 0801  .............2..\n0000c060: 0000 0300 8a69 6e66 696d 756d 0009 0300  .....infimum....\n0000c070: 0803 0000 7375 7072 656d 756d 0023 2016  ....supremum.# .\n0000c080: 1413 0c06 0000 100f 00ba 0000 0014 b201  ................\n0000c090: 0000 0014 08bf b900 0002 0301 1031 3232  .............122\n0000c0a0: 3232 2020 2020 2020 2020 3333 3321 9e94  22        333!..\n0000c0b0: 1413 0c06 0000 180f 0074 0000 0014 b202  .........t......\n0000c0c0: 0000 0014 08bf b900 0002 0301 1f34 0000  .............4..\n0000c0d0: 0000 0000 0000 0000 3535 3500 0000 0000  ........555.....\n```\n\n#### 第1行记录（`0xc07d`）\n\n- 长度偏移列表（`23 20 16 14 13 0c 06`）\n总共有`7`列，每列的长度都不超过`255Byte`，偏移列表的单位为`1Byte`，所以`0xc07d~0xc083`为长度偏移列表\n\n| 列序号 | 长度 | 描述 |\n| --- | --- | --- |\n| 1 | `6` = 0x06 | ROWID，隐藏列 |\n| 2 | `6` = 0x0c-0x06 | Transaction ID，隐藏列 |\n| 3 | `7` = 0x13-0x0c | Roll Pointer，隐藏列 |\n| 4 | `1` = 0x14-0x13 | a VARCHAR(10)|\n| 5 | `2` = 0x16-0x14 | b VARCHAR(10)|\n| 6 | `10` = 0x20-0x16 | c CHAR(10)|\n| 7 | `3` = 0x23-0x20 | d VARCHAR(10)|\n\n- 记录头信息（`00 00 10 0f 00 ba`）\n\n| 名称 | 值 | 描述 |\n| --- | --- | --- |\n| n_fields | 7 | 记录中列的数量|\n| 1byte_offs_flag | 1 | 偏移列表的单位为`1Byte` |\n\n- ROWID（`00 00 00 14 b2 01`）\n- Transaction ID（`00 00 00 14 08 bf`）\n- Roll Pointer（`b9 00 00 02 03 01 10`）\n- a（`31`）\n    - 字符`1`，VARCHAR(10)，`1个字符`只占用了`1Byte`\n- b（`32 32`）\n    - 字符`22`，VARCHAR(10)，`2个字符`只占用了`2Byte`\n- c（`32 32 20 20 20 20 20 20 20 20`）\n    - 字符`22`，CHAR(10)，`2个字符`依旧占用了`10Byte`\n- d（`33 33 33`）\n    - 字符`333`，VARCHAR(10)，`3个字符`只占用了`3Byte`\n\n#### 第2行记录（`0xc0ad`）\n\n- 长度偏移列表（`21 9e 94 14 13 0c 06`）\n总共有`7`列，每列的长度都不超过`255Byte`，偏移列表的单位为`1Byte`，所以`0xc0ad~0xc0b3`为长度偏移列表\n\n| 列序号 | 长度 | 描述 |\n| --- | --- | --- |\n| 1 | `6` = 0x06 | ROWID，隐藏列 |\n| 2 | `6` = 0x0c-0x06 | Transaction ID，隐藏列 |\n| 3 | `7` = 0x13-0x0c | Roll Pointer，隐藏列 |\n| 4 | `1` = 0x14-0x13 | a VARCHAR(10)|\n| 5 | `0`(0x94-0x14=0x80>10) | b VARCHAR(10)|\n| 6 | `10` = 0x9e-0x94 | c CHAR(10)|\n| 7 | `3` = 0x21-(0x9e-0x94)-0x14 | d VARCHAR(10)|\n\n- 记录头信息（`00 00 18 0f 00 74`）\n\n| 名称 | 值 | 描述 |\n| --- | --- | --- |\n| n_fields | 7 | 记录中列的数量|\n| 1byte_offs_flag | 1 | 偏移列表的单位为`1Byte` |\n\n- ROWID（`00 00 00 14 b2 02`）\n- Transaction ID（`00 00 00 14 08 bf`）\n    - `与第1条记录的事务ID一致`（在InnoDB中会将`INSERT VALUES`视为在`同一事务`内，MyISAM则不会）\n- Roll Pointer（`b9 00 00 02 03 01 1f`）\n- a（`34`）\n    - 字符`4`，VARCHAR(10)，`1个字符`只占用了`1Byte`\n- b\n    - `VARCHAR为NULL`时，**`不占用空间`**\n- c（`00 00 00 00 00 00 00 00 00 00`）\n    - `CHAR(10)为NULL`时，依旧`占用10Byte`\n- d（`35 35 35`）\n    - 字符`555`，VARCHAR(10)，`3个字符`只占用了`3Byte`\n\n## 行溢出实例\n\n### 表初始化\n```SQL\nmysql> CREATE TABLE t (\n    -> a VARCHAR(9000)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=REDUNDANT;\nQuery OK, 0 rows affected (0.08 sec)\n\nmysql> INSERT INTO t SELECT REPEAT('a',9000);\nQuery OK, 1 row affected (0.05 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0000>\npage offset 00000004, page type <Uncompressed BLOB Page>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 6:\nInsert Buffer Bitmap: 1\nFreshly Allocated Page: 1\nFile Segment inode: 1\nB-tree Node: 1\nFile Space Header: 1\nUncompressed BLOB Page: 1\n```\n行记录的前`768Byte`在`page offset=3`的页中，但由于`9000>8192>行记录最大长度`，所以将剩余数据放在了`溢出页`，即`page offset=4`的页中\n\n### 16进制信息\n```\n# Vim,:%!xxd\n# page offset=3\n0000c000: 17e8 3157 0000 0003 ffff ffff ffff ffff  ..1W............\n0000c010: 0000 0000 408f 6113 45bf 0000 0000 0000  ....@.a.E.......\n0000c020: 0000 0000 0113 0002 03b2 0003 0000 0000  ................\n0000c030: 008b 0005 0000 0001 0000 0000 0000 0000  ................\n0000c040: 0000 0000 0000 0000 0157 0000 0113 0000  .........W......\n0000c050: 0002 00f2 0000 0113 0000 0002 0032 0801  .............2..\n0000c060: 0000 0300 8b69 6e66 696d 756d 0009 0200  .....infimum....\n0000c070: 0803 0000 7375 7072 656d 756d 0043 2700  ....supremum.C'.\n0000c080: 1300 0c00 0600 0010 0800 7400 0000 14b2  ..........t.....\n0000c090: 0300 0000 1408 cea3 0000 01f9 0110 6161  ..............aa\n0000c0a0: 6161 6161 6161 6161 6161 6161 6161 6161  aaaaaaaaaaaaaaaa\n......\n0000c390: 6161 6161 6161 6161 6161 6161 6161 0000  aaaaaaaaaaaaaa..\n0000c3a0: 0113 0000 0004 0000 0026 0000 0000 0000  .........&......\n0000c3b0: 2028 0000 0000 0000 0000 0000 0000 0000   (..............\n......\n\n# page offset=4\n00010000: 273a f701 0000 0004 0000 0000 0000 0000  ':..............\n00010010: 0000 0000 408f 6113 000a 0000 0000 0000  ....@.a.........\n00010020: 0000 0000 0113 0000 2028 ffff ffff 6161  ........ (....aa\n00010030: 6161 6161 6161 6161 6161 6161 6161 6161  aaaaaaaaaaaaaaaa\n......\n00012050: 6161 6161 6161 0000 0000 0000 0000 0000  aaaaaa..........\n00012060: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n......\n```\n\n- 长度偏移列表（`4327 0013 000c 0006`）\n总共有`4`列，`a`列的长度超过了`255Byte`，偏移列表的单位为`2Byte`，所以`0xc07d~0xc084`为长度偏移列表\n\n| 列序号 | 长度 | 描述 |\n| --- | --- | --- |\n| 1 | `6` = 0x0006 | ROWID，隐藏列 |\n| 2 | `6` = 0x000c-0x0006 | Transaction ID，隐藏列 |\n| 3 | `7` = 0x0013-0x000c | Roll Pointer，隐藏列 |\n| 4 | `9000`(0x4327暂不理解) | a VARCHAR(9000)|\n\n- 记录头信息（`00 00 10 08 00 74`）\n\n| 名称 | 值 | 描述 |\n| --- | --- | --- |\n| n_fields | 4 | 记录中列的数量|\n| 1byte_offs_flag | 0 | 偏移列表的单位为`2Byte` |\n\n- ROWID（`00 00 00 14 b2 03`）\n- Transaction ID（`00 00 00 14 08 ce`）\n- Roll Pointer（`a3 00 00 01 f9 01 10`）\n- a\n    - `page offset=3`，前768Byte（`0xc09e~0xc39d`），在溢出页的长度为`0x2028`，即`8232`\n    - `page offset=4`为`溢出页`，存放后8232Byte的数据(`0x1002e~0x12055`)\n\n# Compact\n`MySQL 5.0`引入，`MySQL 5.1`默认ROW_FORMAT\n\n## 对比Redundant\n1. 减少了大约`20%`的空间\n2. 在某些操作下会增加`CPU`的占用\n3. 在`典型`的应用场景下，比Redundant快\n\n## 格式\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/compact_format.png\" width=\"500\">\n\n### 变长字段长度列表\n1. 条件\n    - `VARCHAR`、`BLOB`等\n    - `变长编码`（如`UTF8`）下的`CHAR`\n2. 放置排序：`逆序`\n2. 用`2Byte`存储的情况：需要用`溢出页`；`最大长度`超过`255Byte`；`实际长度`超过`127Byte`\n\n### NULL标志位\n1. 行记录中是否有NULL值，是一个位向量（`Bit Vector`）\n2. 可为NULL的列数量为N，则该标志位占用的`CEILING(N/8)Byte`\n3. 列为NULL时`不占用实际空间`\n\n### 记录头信息\n\n| 名称 | 大小（bit） | 描述 |\n| --- | --- | --- |\n| () | 1 | 未知 |\n| () | 1 | 未知 |\n| deleted_flag | 1 | 该行是否已被删除 |\n| min_rec_flag | 1 | 如果该行记录是预定义为最小的记录，为1 |\n| n_owned | 4 | 该记录拥有的记录数，用于`Slot`  |\n| heap_no | 13 | 索引堆中该条记录的索引号 |\n| record_type | 3 | 记录类型，000（普通），001（B+Tree节点指针），010（Infimum），011（Supremum） |\n| next_record | 16 | 页中下一条记录的相对位置 |\n| Total | `40(5Byte)` | nothing |\n\n## 实例\n`行溢出`时的处理方式与`Redundant`类似，这里仅给出`非行溢出`的实例\n\n### 表初始化\n```SQL\nmysql> CREATE TABLE t (\n    -> a VARCHAR(10),\n    -> b VARCHAR(10),\n    -> c CHAR(10),\n    -> d VARCHAR(10)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=COMPACT;\nQuery OK, 0 rows affected (0.03 sec)\n\nmysql> INSERT INTO t VALUES ('1','22','22','333'),('4',NULL,NULL,'555');                                                               Query OK, 2 rows affected (0.02 sec)\nRecords: 2  Duplicates: 0  Warnings: 0\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 6:\nFreshly Allocated Page: 2\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 1\nFile Segment inode: 1\n```\n行记录在`page offset=3`的页中\n\n### 16进制信息\n```\n# Vim,:%!xxd\n# page offset=3\n0000c000: 1f96 f8df 0000 0003 ffff ffff ffff ffff  ................\n0000c010: 0000 0000 408f deaa 45bf 0000 0000 0000  ....@...E.......\n0000c020: 0000 0000 0116 0002 00c3 8004 0000 0000  ................\n0000c030: 00ac 0002 0001 0002 0000 0000 0000 0000  ................\n0000c040: 0000 0000 0000 0000 015a 0000 0116 0000  .........Z......\n0000c050: 0002 00f2 0000 0116 0000 0002 0032 0100  .............2..\n0000c060: 0200 1e69 6e66 696d 756d 0003 000b 0000  ...infimum......\n0000c070: 7375 7072 656d 756d 0302 0100 0000 1000  supremum........\n0000c080: 2b00 0000 14b2 0a00 0000 1409 03c6 0000  +...............\n0000c090: 020a 0110 3132 3232 3220 2020 2020 2020  ....12222\n0000c0a0: 2033 3333 0301 0600 0018 ffc4 0000 0014   333............\n0000c0b0: b20b 0000 0014 0903 c600 0002 0a01 1f34  ...............4\n0000c0c0: 3535 3500 0000 0000 0000 0000 0000 0000  555.............\n```\n\n#### 第1行记录（`0xc078`）\n1. 变长字段长度列表（`03 02 01`）\n    - 列a长度为1\n    - 列b长度为2\n    - 列c在`LATIN1`单字节编码下，长度固定，因此不会出现在该列表中\n    - 列d长度为3\n2. NULL标志位（`00`）\n    - 在表中可以为NULL的可变列为a、b、d，`0< 3/8 < 1`，所以NULL标志位占用`1Byte`\n    - `00`表示没有字段为NULL\n3. 记录头信息（`00 00 10 00 2b`）\n    - 本行记录结束的位置`0xc078+0x2b`=**`c0a3`**\n4. ROWID（`00 00 00 14 b2 0a`）\n5. Transaction ID（`00 00 00 14 09 03`）\n6. Roll Pointer（`c6 00 00 02 0a 01 10`）\n7. a（`31`）\n    - 字符`1`，VARCHAR(10)，`1个字符`只占用了`1Byte`\n8. b（`32 32`）\n    - 字符`22`，VARCHAR(10)，`2个字符`只占用了`2Byte`\n9. c（`32 32 20 20 20 20 20 20 20 20`）\n    - 字符`22`，CHAR(10)，`2个字符`依旧占用了`10Byte`\n10. d（`33 33 33`）\n    - 字符`333`，VARCHAR(10)，`3个字符`只占用了`3Byte`\n\n#### 第2行记录（`0xc0a4`）\n1. 变长字段长度列表（`03 01`）\n    - 列a长度为1\n    - 列b、c为NULL，不占用空间，因此不会出现在该列表中，`NULL标志位`会标识那一列为NULL\n    - 列d长度为3\n2. NULL标志位（`06`）\n    - `0000 0110`，表示列b和列c为NULL\n3. 记录头信息（`00 00 18 ff c4`）\n4. ROWID（`00 00 00 14 b2 0b`）\n5. Transaction ID（`00 00 00 14 09 03`）\n    - 跟第1行记录在`同一个事务内`\n6. Roll Pointer（`c6 00 00 02 0a 01 1f`）\n7. a（`34`）\n    - 字符`1`，VARCHAR(10)，`1个字符`只占用了`1Byte`\n8. b\n    - `VARCHAR(10)`为`NULL`时，`不占用空间`\n9. c\n    - `CHAR(10)`为`NULL`时，`不占用空间`\n10. d（`35 35 35`）\n    - 字符`555`，VARCHAR(10)，`3个字符`只占用了`3Byte`\n\n# Dynamic和Compressed\n1. `Dynamic`和`Compressed`是`Compact`的变种形式\n2. `Compressed`会对存储在其中的行数据会以`zlib`的算法进行压缩，对`BLOB`、`TEXT`、`VARCHAR`这类`大长度类型`的数据能够进行非常有效的存储\n3. `Dynamic`（或`Compressed`）与`Compact`（或`Redundant`）比较大的差异是`行溢出`的处理方式，下面是`Dynamic行溢出实例`\n\n## 表初始化\n```SQL\nmysql> CREATE TABLE t (\n    -> a VARCHAR(9000)\n    -> ) ENGINE=INNODB CHARSET=LATIN1 ROW_FORMAT=DYNAMIC;\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> INSERT INTO t SELECT REPEAT('a',9000);                                                                                          Query OK, 1 row affected (0.02 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n```\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0000>\npage offset 00000004, page type <Uncompressed BLOB Page>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 6:\nInsert Buffer Bitmap: 1\nFreshly Allocated Page: 1\nFile Segment inode: 1\nB-tree Node: 1\nFile Space Header: 1\nUncompressed BLOB Page: 1\n```\n\n## 16进制信息\n```\n# Vim,:%!xxd\n# page offset=3\n0000c000: 0006 f2d2 0000 0003 ffff ffff ffff ffff  ................\n0000c010: 0000 0000 4090 bbcb 45bf 0000 0000 0000  ....@...E.......\n0000c020: 0000 0000 011a 0002 00a7 8003 0000 0000  ................\n0000c030: 0080 0005 0000 0001 0000 0000 0000 0000  ................\n0000c040: 0000 0000 0000 0000 015e 0000 011a 0000  .........^......\n0000c050: 0002 00f2 0000 011a 0000 0002 0032 0100  .............2..\n0000c060: 0200 1d69 6e66 696d 756d 0002 000b 0000  ...infimum......\n0000c070: 7375 7072 656d 756d 14c0 0000 0010 fff0  supremum........\n0000c080: 0000 0014 b211 0000 0014 093d ee00 0001  ...........=....\n0000c090: c201 1000 0001 1a00 0000 0400 0000 2600  ..............&.\n0000c0a0: 0000 0000 0023 2800 0000 0000 0000 0000  .....#(.........\n......\n\n# page offset=4\n00010000: 2371 f7ac 0000 0004 0000 0000 0000 0000  #q..............\n00010010: 0000 0000 4090 bbcb 000a 0000 0000 0000  ....@...........\n00010020: 0000 0000 011a 0000 2328 ffff ffff 6161  ........#(....aa\n00010030: 6161 6161 6161 6161 6161 6161 6161 6161  aaaaaaaaaaaaaaaa\n......\n00012340: 6161 6161 6161 6161 6161 6161 6161 6161  aaaaaaaaaaaaaaaa\n00012350: 6161 6161 6161 0000 0000 0000 0000 0000  aaaaaa..........\n```\n\n1. `page offset=3`中没有前缀的`768Byte`，`Roll Pointer`后直接跟着`20Byte`的指针\n2. `page offset=4`为`溢出页`，存储实际的数据，范围为`0x1002d~0x12355`，总共`9000`，即完全溢出\n\n\n# UTF8与CHAR\n1. `Latin1`与`UTF8`代表了两种编码类型，分别是`定长编码`和`变长编码`\n2. `UTF8`对`CHAR(N)`的的处理方式在`Redundant`和`Compact`（或Dynamic、Compressed）中是不一样的\n    - `Redundant`中占用`N * Maximum_Character_Byte_Length`\n    - `Compact`中`最小化`占用空间\n\n## Redundant实例\n```SQL\nmysql> CREATE TABLE t (\n    -> a CHAR(10)\n    -> ) ENGINE=INNODB CHARSET=UTF8 ROW_FORMAT=REDUNDANT;\nQuery OK, 0 rows affected (0.02 sec)\n\nmysql> INSERT INTO t SELECT 'a';\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n```\n0000c090: 1409 69ae 0000 018d 0110 6120 2020 2020  ..i.......a\n0000c0a0: 2020 2020 2020 2020 2020 2020 2020 2020\n0000c0b0: 2020 2020 2020 2020 0000 0000 0000 0000          ........\n```\n`0xc09a~0xc0b7`总共占用了`30Byte`(=`3`*10)\n\n## Compact实例\n```SQL\nmysql> CREATE TABLE t (\n    -> a CHAR(10)\n    -> ) ENGINE=INNODB CHARSET=UTF8 ROW_FORMAT=REDUNDANT;\nQuery OK, 0 rows affected (0.02 sec)\n\nmysql> INSERT INTO t SELECT 'a';\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n```\n```\n0000c090: 0110 6120 2020 2020 2020 2020 0000 0000  ..a         ....\n```\n`0xc092~0xc09b`总共占用了`10Byte`(=`1`*10)\n\n\n# 参考资料\n\n1. [MySQL技术内幕 - InnoDB存储引擎 V2](https://book.douban.com/subject/24708143/)\n2. [File Space Management](https://dev.mysql.com/doc/refman/5.7/en/innodb-file-space.html)\n4. [COMPACT and REDUNDANT Row Formats](https://dev.mysql.com/doc/refman/5.7/en/innodb-row-format-antelope.html)\n5. [Physical Row Structure of InnoDB Tables](https://dev.mysql.com/doc/refman/5.7/en/innodb-physical-record.html)\n6. [DYNAMIC and COMPRESSED Row Formats](https://dev.mysql.com/doc/refman/5.7/en/innodb-row-format-dynamic.html)\n\n<!-- indicate-the-source -->\n","tags":["InnoDB"],"categories":["InnoDB"]},{"title":"InnoDB -- 逻辑存储","url":"%2F2017%2F05%2F06%2Finnodb-table-logical-structure%2F","content":"\n{% note info %}\n本文主要介绍`InnoDB`存储引擎的`逻辑存储结构`\n{% endnote %}\n\n<!-- more -->\n\n# 逻辑存储结构\n\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/innodb-tablespace.jpg\" width=\"500\">\n\n# Tablespace\n\n1. Tablespace是InnoDB存储引擎逻辑存储结构的`最高层`，`所有数据`都存放在Tablespace中\n2. 分类\n    - `System Tablespace`\n    - `Separate Tablespace`\n    - `General Tablespace`\n\n## System Tablespace\n\n1. `System Tablespace`即我们常见的`共享表空间`，变量为`innodb_data_file_path`，一般为`ibdata1`文件\n2. 里面存放着`undo logs`，`change buffer`，`doublewrite buffer`等信息（后续将详细介绍），在没有开启`file-per-table`的情况下，还会包含`所有表的索引和数据`信息\n3. 没有开启`file-per-table`时存在的问题\n    - 所有的表和索引都会在`System Tablespace`中，`占用空间会越来越大`\n    - `碎片越来越多`（如`truncate table`时，占用的磁盘空间依旧保留在`System Tablespace`）\n\n```SQL\nmysql>  SHOW VARIABLES LIKE 'innodb_data_file_path';\n+-----------------------+------------------------+\n| Variable_name         | Value                  |\n+-----------------------+------------------------+\n| innodb_data_file_path | ibdata1:12M:autoextend |\n+-----------------------+------------------------+\n1 row in set (0.01 sec)\n\nmysql>  SHOW VARIABLES LIKE '%datadir%';\n+---------------+-----------------+\n| Variable_name | Value           |\n+---------------+-----------------+\n| datadir       | /var/lib/mysql/ |\n+---------------+-----------------+\n1 row in set (0.01 sec)\n\nmysql> system sudo ls -lh /var/lib/mysql/ibdata1\n[sudo] password for zhongmingmao:\n-rw-r----- 1 mysql mysql 76M May  6 20:00 /var/lib/mysql/ibdata1\n```\n\n## Separate Tablespace\n\n1. MySQL参考手册中并没有`Separate Tablespace`这个术语，这里只为了行文方便，表示在开启`file-per-table`的情况下，每个表有自己`独立的表空间`，变量为`innodb_file_per_table`\n2. 里面存放在`每个表的索引和数据信息`，后缀一般为`.ibd`\n3. 默认初始大小为`96KB`\n4. 好处\n    - 避免`System Tablespace`越来越大\n    - 减少碎片（`truncate table`，操作系统会`自动回收空间`）\n\n```SQL\nmysql> use test\nReading table information for completion of table and column names\nYou can turn off this feature to get a quicker startup with -A\n\nDatabase changed\nmysql> show tables;\n+----------------+\n| Tables_in_test |\n+----------------+\n| t              |\n+----------------+\n1 row in set (0.00 sec)\n\nmysql>  SHOW VARIABLES LIKE 'innodb_file_per_table';\n+-----------------------+-------+\n| Variable_name         | Value |\n+-----------------------+-------+\n| innodb_file_per_table | ON    |\n+-----------------------+-------+\n1 row in set (0.00 sec)\n\nmysql>  SHOW VARIABLES LIKE '%datadir%';                                                                                               +---------------+-----------------+\n| Variable_name | Value           |\n+---------------+-----------------+\n| datadir       | /var/lib/mysql/ |\n+---------------+-----------------+\n1 row in set (0.01 sec)\n\nmysql> system sudo ls -lh /var/lib/mysql/test\ntotal 112K\n-rw-r----- 1 mysql mysql   61 Apr 28 10:18 db.opt\n-rw-r----- 1 mysql mysql 8.4K May  7 17:03 t.frm\n-rw-r----- 1 mysql mysql  96K May  7 17:03 t.ibd\n```\n\n## General Tablespace\n\n1. `General Tablespace`是`MySQL 5.7.6`引入的新特性，具体内容请参照下面链接\n[15.7.9 InnoDB General Tablespaces](https://dev.mysql.com/doc/refman/5.7/en/general-tablespaces.html)\n\n# Segment\n<img src=\"https://innodb-1253868755.cos.ap-guangzhou.myqcloud.com/segment.png\" width=\"500\">\n\n1. Segment分为三种\n    1. `Leaf node segment`：`数据段`，B+Tree的叶子节点\n    2. `Non-Leaf node segment`：`索引段`，B+Tree的非叶子节点\n    3. `Rollback segment`：回滚段，存放`undo log`，默认是位于`System Tablespace`\n2. InnoDB中的`B+Tree索引`，由`Leaf node segment`和`Non-Leaf node segment`组成\n3. 一个Segment由`多个Extent和Page`组成\n\n# Extent\n\n1. `Extent`是由连续页（默认页大小为`16KB`）组成，在`默认页大小`时，为`64个连续页`，大小为`64*16KB=1MB`\n    - 不同页大小：`4KB*256` or `8KB*128` or `16KB*64` or `32KB*64` or `64KB*64`\n2. 为了保证`页的连续性`，InnoDB可以一次性从磁盘申请`4个Extent`\n3. 为了`节省磁盘空间`，如表的数据量很小（`Leaf node segment`和`Non-Leaf node segment`都很小）或`Rollback segment`，Segment一开始`不会直接申请Extent`，而是先用`32个碎片页`（用于`叶子节点`）来存放数据，用完之后才继续对`Extent(1MB)`的申请（下面实例是`Leaf Node Segment`的对空间的申请过程）\n\n{% note warning %}\n下列操作过程中涉及到了`ROW_FORMAT`的部分内容，本文并没有详细展开，只为佐证结果\n{% endnote %}\n\n## 创建表\n```SQL\n# 创建表\nmysql> CREATE TABLE t (\n    -> a INT NOT NULL AUTO_INCREMENT,\n    -> b VARCHAR(7000),\n    -> PRIMARY KEY (a)\n    -> ) ENGINE=INNODB ROW_FORMAT=COMPACT CHARSET=LATIN1;\nQuery OK, 0 rows affected (0.03 sec)\n\nmysql> system sudo ls -lh /var/lib/mysql/test/t.ibd\n-rw-r----- 1 mysql mysql 96K May  7 17:09 /var/lib/mysql/test/t.ibd\n```\n```\n# 查看表空间信息\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 6:\nFreshly Allocated Page: 2\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 1\nFile Segment inode: 1\n```\n```\n# 查看表空间文件十六进制（Vim,:%!xxd）\n# page offset=3\n0000c000: 18f8 857f 0000 0003 ffff ffff ffff ffff  ................\n0000c010: 0000 0000 4087 2c32 45bf 0000 0000 0000  ....@.,2E.......\n0000c020: 0000 0000 0111 0002 0078 8002 0000 0000  .........x......\n0000c030: 0000 0005 0000 0000 0000 0000 0000 0000  ................\n0000c040: 0000 0000 0000 0000 0155 0000 0111 0000  .........U......\n0000c050: 0002 00f2 0000 0111 0000 0002 0032 0100  .............2..\n0000c060: 0200 0d69 6e66 696d 756d 0001 000b 0000  ...infimum......\n0000c070: 7375 7072 656d 756d 0000 0000 0000 0000  supremum........\n0000c080: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n0000c090: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n......\n0000ffd0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n0000ffe0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n0000fff0: 0000 0000 0070 0063 18f8 857f 4087 2c32  .....p.c....@.,2\n```\n\n1. `py_innodb_page_info.py`是姜承尧大神用Python写的用来分析表空间中的各页类型和信息的工具\n2. `b VARCHAR(7000)`能保证`一个页中最多存放两条记录`，2 < 16KB/7000B < 3\n3. 单独表空间`t.ibd`的默认大小为`96KB`\n4. 单独表空间`t.ibd`目前`只有一个B+Tree叶子节点`（`page level <0000>`），还有`两个可用页`（`Freshly Allocated Page`）\n    - `page offset=3`，`(16K)*3 = 0xc000`，该页范围为`0xc000 ~ 0xffff`\n    - 理论上`0xc078`为`第一个记录的开始`，此时尚未插入任何记录，所以为`0`（行记录格式`ROW_FORMAT`后续将详细介绍）\n\n## 插入2条记录\n```SQL\n# 插入2条记录\nmysql> INSERT INTO t SELECT NULL,REPEAT('a',7000);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> INSERT INTO t SELECT NULL,REPEAT('a',7000);\nQuery OK, 1 row affected (0.00 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> system sudo ls -lh /var/lib/mysql/test/t.ibd\n[sudo] password for zhongmingmao:\n-rw-r----- 1 mysql mysql 96K May  7 17:26 /var/lib/mysql/test/t.ibd\nmysql>\n```\n```\n# 查看表空间信息\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 6:\nFreshly Allocated Page: 2\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 1\nFile Segment inode: 1\n```\n```\n# 查看表空间文件十六进制（Vim,:%!xxd）\n# page offset=3\n0000c000: f185 f4c0 0000 0003 ffff ffff ffff ffff  ................\n0000c010: 0000 0000 4087 697e 45bf 0000 0000 0000  ....@.i~E.......\n0000c020: 0000 0000 0111 0002 375a 8004 0000 0000  ........7Z......\n0000c030: 1bf1 0002 0001 0002 0000 0000 0000 0000  ................\n0000c040: 0000 0000 0000 0000 0155 0000 0111 0000  .........U......\n0000c050: 0002 00f2 0000 0111 0000 0002 0032 0100  .............2..\n0000c060: 0200 1d69 6e66 696d 756d 0003 000b 0000  ...infimum......\n0000c070: 7375 7072 656d 756d 589b 0000 0010 1b71  supremumX......q\n0000c080: 8000 0001 0000 0014 0869 cc00 0002 1001  .........i......\n0000c090: 1061 6161 6161 6161 6161 6161 6161 6161  .aaaaaaaaaaaaaaa\n0000c0a0: 6161 6161 6161 6161 6161 6161 6161 6161  aaaaaaaaaaaaaaaa\n......\n0000dbd0: 6161 6161 6161 6161 6161 6161 6161 6161  aaaaaaaaaaaaaaaa\n0000dbe0: 6161 6161 6161 6161 6158 9b00 0000 18e4  aaaaaaaaaX......\n0000dbf0: 7f80 0000 0200 0000 1408 6acd 0000 01a4  ..........j.....\n0000dc00: 0110 6161 6161 6161 6161 6161 6161 6161  ..aaaaaaaaaaaaaa\n......\n0000f730: 6161 6161 6161 6161 6161 6161 6161 6161  aaaaaaaaaaaaaaaa\n0000f740: 6161 6161 6161 6161 6161 6161 6161 6161  aaaaaaaaaaaaaaaa\n0000f750: 6161 6161 6161 6161 6161 0000 0000 0000  aaaaaaaaaa......\n......\n0000ffd0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n0000ffe0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n0000fff0: 0000 0000 0070 0063 f185 f4c0 4087 697e  .....p.c....@.i~\n......\n```\n\n1. 表空间大小依旧是`96KB`，2条记录可以完全放入`page offset=3`的B+Tree叶子节点中\n2. 第1条记录位于page offset=3的页，地址范围为`0xc078 ~ 0xdbe8`，占用`7025 Byte`\n3. 第2条记录位于page offset=3的页，地址范围为`0xdbe9 ~ 0xf759`，占用`7025 Byte`\n4. 此时，`page offset=3`的页已经无法再容纳下一条同样长度的记录，但此时还有`2个可用页`，可用于`B+Tree的分裂`（此时只有叶子节点）\n\n## 插入第3条记录\n```SQL\n# 插入第3条记录\nmysql> INSERT INTO t SELECT NULL,REPEAT('a',7000);\nQuery OK, 1 row affected (0.03 sec)\nRecords: 1  Duplicates: 0  Warnings: 0\n\nmysql> system sudo ls -lh /var/lib/mysql/test/t.ibd\n-rw-r----- 1 mysql mysql 96K May  7 17:40 /var/lib/mysql/test/t.ibd\n```\n```\n# 查看表空间信息\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0001>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\nTotal number of page: 6:\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 3\nFile Segment inode: 1\n```\n```\n# 查看表空间文件十六进制（Vim,:%!xxd）\n# page offset=4\n00010000: 669d db54 0000 0004 ffff ffff 0000 0005  f..T............\n00010010: 0000 0000 4087 e2e4 45bf 0000 0000 0000  ....@...E.......\n00010020: 0000 0000 0111 0002 375a 8004 1bf1 1b71  ........7Z.....q\n00010030: 0000 0005 0000 0001 0000 0000 0000 0000  ................\n00010040: 0000 0000 0000 0000 0155 0000 0000 0000  .........U......\n00010050: 0000 0000 0000 0000 0000 0000 0000 0100  ................\n00010060: 0200 1d69 6e66 696d 756d 0002 000b 0000  ...infimum......\n00010070: 7375 7072 656d 756d 589b 0000 0010 fff0  supremumX.......\n00010080: 8000 0001 0000 0014 0869 cc00 0002 1001  .........i......\n00010090: 1061 6161 6161 6161 6161 6161 6161 6161  .aaaaaaaaaaaaaaa\n......\n00011bd0: 6161 6161 6161 6161 6161 6161 6161 6161  aaaaaaaaaaaaaaaa\n00011be0: 6161 6161 6161 6161 6158 9b00 0000 1800  aaaaaaaaaX......\n00011bf0: 0080 0000 0200 0000 1408 6acd 0000 01a4  ..........j.....\n00011c00: 0110 6161 6161 6161 6161 6161 6161 6161  ..aaaaaaaaaaaaaa\n......\n00013740: 6161 6161 6161 6161 6161 6161 6161 6161  aaaaaaaaaaaaaaaa\n00013750: 6161 6161 6161 6161 6161 0000 0000 0000  aaaaaaaaaa......\n00013760: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n......\n00013fd0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00013fe0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00013ff0: 0000 0000 0070 0063 669d db54 4087 e2e4  .....p.cf..T@...\n\n# page offset=5\n00014000: 946a 9d01 0000 0005 0000 0004 ffff ffff  .j..............\n00014010: 0000 0000 4087 e2e4 45bf 0000 0000 0000  ....@...E.......\n00014020: 0000 0000 0111 0002 375a 8004 0000 0000  ........7Z......\n00014030: 1bf1 0005 0000 0002 0000 0000 0000 0000  ................\n00014040: 0000 0000 0000 0000 0155 0000 0000 0000  .........U......\n00014050: 0000 0000 0000 0000 0000 0000 0000 0100  ................\n00014060: 0200 1d69 6e66 696d 756d 0003 000b 0000  ...infimum......\n00014070: 7375 7072 656d 756d 589b 0000 0010 1b71  supremumX......q\n00014080: 8000 0002 0000 0014 086a cd00 0001 a401  .........j......\n00014090: 1061 6161 6161 6161 6161 6161 6161 6161  .aaaaaaaaaaaaaaa\n......\n00015bd0: 6161 6161 6161 6161 6161 6161 6161 6161  aaaaaaaaaaaaaaaa\n00015be0: 6161 6161 6161 6161 6158 9b00 0000 18e4  aaaaaaaaaX......\n00015bf0: 7f80 0000 0300 0000 1408 6fd0 0000 0211  ..........o.....\n00015c00: 0110 6161 6161 6161 6161 6161 6161 6161  ..aaaaaaaaaaaaaa\n.......\n00017740: 6161 6161 6161 6161 6161 6161 6161 6161  aaaaaaaaaaaaaaaa\n00017750: 6161 6161 6161 6161 6161 0000 0000 0000  aaaaaaaaaa......\n00017760: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n......\n00017fd0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00017fe0: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00017ff0: 0000 0000 0070 0063 946a 9d01 4087 e2e4  .....p.c.j..@...\n```\n\n1. 插入第3条记录后，表空间大小依旧为`96KB`，因为插入之前还有`两个可用页`，有足够的空间让`B+Tree分裂`\n2. `page offset=3`的`page level`为`<0001>`，表示这是`倒数第一层`的`B+Tree索引节点`\n3. 实际的记录存放在`page offset`为`4`和`5`的`B+Tree叶子节点`，即上一操作后的可用页\n4. 第1条记录位于page offset=4的页，地址范围为`0x10078 ~ 0x11be8`，占用`7025 Byte`\n5. 第2条记录位于page offset=4的页，地址范围为`0x11be9 ~ 0x13759`，占用`7025 Byte`\n    - 第2条记录同时也位于page offset=5的页，地址范围为`0x14078 ~ 0x15be8`，占用`7025 Byte`\n6. 第3条记录位于page offset=5的页，地址范围为`0x15be9 ~ 0x17759`，占用`7025 Byte`\n7. 此时，`page offset=4`和`page offset=5`的页都已经无法再容纳同样长度的记录，而且表空间初始的`96KB`中`已无可用页`\n    - 在插入同样长度的记录，表空间会增大\n\n## 创建存储过程\n```SQL\nmysql> DELIMITER //\nmysql> CREATE PROCEDURE load_t (count INT UNSIGNED)\n    -> BEGIN\n    -> DECLARE s INT UNSIGNED DEFAULT 1;\n    -> DECLARE c VARCHAR(7000) DEFAULT REPEAT('a',7000);\n    -> WHILE s <= count DO\n    -> INSERT INTO t SELECT NULL,c;\n    -> SET s=s+1;\n    -> END WHILE;\n    -> END;\n    -> //\nQuery OK, 0 rows affected (0.09 sec)\n\nmysql> DELIMITER ;\n```\n\n## 插入60条记录\n```SQL\n# 通过调用存储过程，插入60条记录\nmysql> CALL load_t(60);\nQuery OK, 1 row affected (0.67 sec)\n\nmysql>  system sudo ls -lh /var/lib/mysql/test/t.ibd\n-rw-r----- 1 mysql mysql 592K May  8 01:58 /var/lib/mysql/test/t.ibd\n```\n```\n# 查看表空间信息\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0001>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\n......\npage offset 00000022, page type <B-tree Node>, page level <0000>\npage offset 00000023, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 37:\nFreshly Allocated Page: 1\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 33\nFile Segment inode: 1\n```\n\n1. 此时，表空间大小依旧小于`Extent`大小（1MB），目前还是通过`碎片页`来申请数据空间\n2. 上一步操作中，默认的表空间大小已无法再容纳新的同样长度的记录，且已使用了`2个B+Tree叶子节点`，`Leaf Node Segment`在申请`Extent`前可以再使用`30个B+Tree叶子节点`，所以再插入60条记录（每页只能容纳2条记录）\n3. 此时处于`临界状态`，`B+Tree叶子节点为32个`，再插入同样长度的记录时，`Leaf Node Segment`将进行`Extent`的申请\n\n## 插入第64条记录\n```SQL\n# 插入第64条记录\nmysql> CALL load_t(1);\nQuery OK, 1 row affected (0.05 sec)\n\nmysql>  system sudo ls -lh /var/lib/mysql/test/t.ibd\n[sudo] password for zhongmingmao:\n-rw-r----- 1 mysql mysql 2.0M May  8 02:14 /var/lib/mysql/test/t.ibd\n```\n```\n# 查看表空间信息\n$ sudo python py_innodb_page_info.py -v /var/lib/mysql/test/t.ibd\npage offset 00000000, page type <File Space Header>\npage offset 00000001, page type <Insert Buffer Bitmap>\npage offset 00000002, page type <File Segment inode>\npage offset 00000003, page type <B-tree Node>, page level <0001>\npage offset 00000004, page type <B-tree Node>, page level <0000>\npage offset 00000005, page type <B-tree Node>, page level <0000>\n......\npage offset 00000022, page type <B-tree Node>, page level <0000>\npage offset 00000023, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\n......\npage offset 00000000, page type <Freshly Allocated Page>\npage offset 00000040, page type <B-tree Node>, page level <0000>\npage offset 00000000, page type <Freshly Allocated Page>\n......\npage offset 00000000, page type <Freshly Allocated Page>\npage offset 00000000, page type <Freshly Allocated Page>\nTotal number of page: 128:\nFreshly Allocated Page: 91\nInsert Buffer Bitmap: 1\nFile Space Header: 1\nB-tree Node: 34\nFile Segment inode: 1\n```\n\n1. 插入第64条记录时，`Leaf Node Segment`就需要进行`Extent`的申请，从`page offset=0x40`处申请一个`Extent`（`0x40*16KB=1MB`），此时表空间大小为`2MB`\n\n# Page\n\n1. `Page`是InnoDB`磁盘管理的最小单位`，变量为`innodb_page_size`\n\n```SQL\nmysql>  SHOW VARIABLES LIKE 'innodb_page_size';\n+------------------+-------+\n| Variable_name    | Value |\n+------------------+-------+\n| innodb_page_size | 16384 |\n+------------------+-------+\n1 row in set (0.17 sec)\n```\n# Row\n\n1. InnoDB存储引擎的数据是`按行`进行存放的\n2. 行记录格式`Row_FORMAT`将在后续详细介绍\n\n# 参考资料\n\n1. [MySQL技术内幕 - InnoDB存储引擎 V2](https://book.douban.com/subject/24708143/)\n2. [MySQL 5.7 Reference Manual](https://dev.mysql.com/doc/refman/5.7/en)\n<!-- indicate-the-source -->\n","tags":["InnoDB"],"categories":["InnoDB"]},{"title":"Git -- Git Flow","url":"%2F2017%2F04%2F19%2Fgit-flow%2F","content":"\n{% note info %}\n主要介绍`Git Flow`中`Feature`分支、`Release`分支、`Hotfix`分支的流程\n{% endnote %}\n\n<!-- more -->\n\n# Git Flow\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/git-flow.png\" width=\"500\">\n\n# 初始化仓库\n`git flow init`：初始化仓库，支持`GitFlow分支模型`\n```\n$ git clone https://github.com/hzmajia/gitflow-example.git\nCloning into 'gitflow-example'...\nwarning: You appear to have cloned an empty repository.\nChecking connectivity... done.\n\n$ cd gitflow-example && git flow init\nNo branches exist yet. Base branches must be created now.\nBranch name for production releases: [master]\nBranch name for \"next release\" development: [develop]\nHow to name your supporting branch prefixes?\nFeature branches? [feature/]\nBugfix branches? [bugfix/]\nRelease branches? [release/]\nHotfix branches? [hotfix/]\nSupport branches? [support/]\nVersion tag prefix? []\nHooks and filters directory? [/home/zhongmingmao/gitflow-example/.git/hooks]\n\n$ git branch -vv\n* develop 378941f Initial commit\n  master  378941f [origin/master: gone] Initial commit\n\n$ git push origin develop\nCounting objects: 2, done.\nWriting objects: 100% (2/2), 163 bytes | 0 bytes/s, done.\nTotal 2 (delta 0), reused 0 (delta 0)\nTo https://github.com/hzmajia/gitflow-example.git\n * [new branch]      develop -> develop\n\n$ git checkout master\nSwitched to branch 'master'\nYour branch is based on 'origin/master', but the upstream is gone.\n  (use \"git branch --unset-upstream\" to fixup)\n\n$ git push -u origin master\nTotal 0 (delta 0), reused 0 (delta 0)\nTo https://github.com/hzmajia/gitflow-example.git\n * [new branch]      master -> master\nBranch master set up to track remote branch master from origin.\n\n$ git branch -vv\n  develop 378941f Initial commit\n* master  378941f [origin/master] Initial commit\n\n$ git log --oneline --decorate --graph --all\n* 378941f (HEAD -> master, origin/master, origin/develop, develop) Initial commit\n```\n\n# Feature分支\n`git flow feature`：Feature分支列表\n`git flow feature start`：新建一个Feature分支\n`git flow publish`：将Feature分支推送到远程仓库，并设为`上游分支`\n`git flow feature finish`：完成一个Feature分支，一般是`merge request`或`pull request`的接受者执行\n```\n$ git flow feature start featureA\nSwitched to a new branch 'feature/featureA'\nSummary of actions:\n- A new branch 'feature/featureA' was created, based on 'develop'\n- You are now on branch 'feature/featureA'\nNow, start committing on your feature. When done, use:\n     git flow feature finish featureA\n\n$ git branch -vv\n  develop          378941f Initial commit\n* feature/featureA 378941f Initial commit\n  master           378941f [origin/master] Initial commit\n\n$ git flow feature\n* featureA\n\n$ git flow publish featureA\nTotal 0 (delta 0), reused 0 (delta 0)\nTo https://github.com/hzmajia/gitflow-example.git\n * [new branch]      feature/featureA -> feature/featureA\nBranch feature/featureA set up to track remote branch feature/featureA from origin.\nAlready on 'feature/featureA'\nYour branch is up-to-date with 'origin/feature/featureA'.\nSummary of actions:\n- The remote branch 'feature/featureA' was created or updated\n- The local branch 'feature/featureA' was configured to track the remote branch\n- You are now on branch 'feature/featureA'\n\n$ git branch -vv\n  develop          378941f Initial commit\n* feature/featureA 378941f [origin/feature/featureA] Initial commit\n  master           378941f [origin/master] Initial commit\n\n$ touch featureA && git add . && git commit -m 'featureA'\n[feature/featureA 6e6605d] featureA\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 featureA\n\n$ git branch -vv\n  develop          378941f Initial commit\n* feature/featureA 6e6605d [origin/feature/featureA: ahead 1] featureA\n  master           378941f [origin/master] Initial commit\n\n$ git push origin feature/featureA # git flow publish featureA\nCounting objects: 3, done.\nWriting objects: 100% (3/3), 235 bytes | 0 bytes/s, done.\nTotal 3 (delta 0), reused 0 (delta 0)\nTo https://github.com/hzmajia/gitflow-example.git\n   378941f..6e6605d  feature/featureA -> feature/featureA\n\n$ git log --oneline --decorate --graph --all\n* 6e6605d (HEAD -> feature/featureA, origin/feature/featureA) featureA\n* 378941f (origin/master, origin/develop, master, develop) Initial commit\n\n$ git flow feature finish featureA\nSwitched to branch 'develop'\nUpdating 378941f..6e6605d\nFast-forward\n featureA | 0\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 featureA\nTo https://github.com/hzmajia/gitflow-example.git\n - [deleted]         feature/featureA\nDeleted branch feature/featureA (was 6e6605d).\nSummary of actions:\n- The feature branch 'feature/featureA' was merged into 'develop'\n- Feature branch 'feature/featureA' has been locally deleted; it has been remotely deleted from 'origin'\n- You are now on branch 'develop'\n\n$ git fetch origin\n\n$ git branch -vv\n* develop 6e6605d featureA\n  master  378941f [origin/master] Initial commit\n\n$ ls\nfeatureA\n```\n\n# Release分支\n`git flow release`：Release分支列表\n`git flow release start`：新建一个Release分支\n`git flow publish`：将Release分支推送到远程仓库，并设为`上游分支`\n`git flow release finish`：完成一个Release分支，一般是`merge request`或`pull request`的接受者执行\n```\n$ git flow release start releaseA\nBranches 'develop' and 'origin/develop' have diverged.\nAnd local branch 'develop' is ahead of 'origin/develop'.\nSwitched to a new branch 'release/releaseA'\nSummary of actions:\n- A new branch 'release/releaseA' was created, based on 'develop'\n- You are now on branch 'release/releaseA'\nFollow-up actions:\n- Bump the version number now!\n- Start committing last-minute fixes in preparing your release\n- When done, run:\n     git flow release finish 'releaseA'\n\n$ git push -u origin develop\nCounting objects: 3, done.\nWriting objects: 100% (3/3), 235 bytes | 0 bytes/s, done.\nTotal 3 (delta 0), reused 0 (delta 0)\nTo https://github.com/hzmajia/gitflow-example.git\n   378941f..6e6605d  develop -> develop\nBranch develop set up to track remote branch develop from origin.\n\n$ git branch -vv\n  develop          6e6605d [origin/develop] featureA\n  master           378941f [origin/master] Initial commit\n* release/releaseA 6e6605d featureA\n\n$ git flow release\n* releaseA\n\n$ git flow publish releaseA\nTotal 0 (delta 0), reused 0 (delta 0)\nTo https://github.com/hzmajia/gitflow-example.git\n * [new branch]      release/releaseA -> release/releaseA\nBranch release/releaseA set up to track remote branch release/releaseA from origin.\nAlready on 'release/releaseA'\nYour branch is up-to-date with 'origin/release/releaseA'.\nSummary of actions:\n- The remote branch 'release/releaseA' was created or updated\n- The local branch 'release/releaseA' was configured to track the remote branch\n- You are now on branch 'release/releaseA'\n\n$ git branch -vv\n  develop          6e6605d [origin/develop] featureA\n  master           378941f [origin/master] Initial commit\n* release/releaseA 6e6605d [origin/release/releaseA] featureA\n\n$ touch releaseA && git add . && git commit -m 'releaseA'\n[release/releaseA f993ec4] releaseA\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 releaseA\n\n$ git flow publish releaseA # git push origin release/releaseA\nCounting objects: 2, done.\nCompressing objects: 100% (2/2), done.\nWriting objects: 100% (2/2), 237 bytes | 0 bytes/s, done.\nTotal 2 (delta 0), reused 0 (delta 0)\nTo https://github.com/hzmajia/gitflow-example.git\n   6e6605d..f993ec4  release/releaseA -> release/releaseA\nBranch release/releaseA set up to track remote branch release/releaseA from origin.\nAlready on 'release/releaseA'\nYour branch is up-to-date with 'origin/release/releaseA'.\nSummary of actions:\n- The remote branch 'release/releaseA' was created or updated\n- The local branch 'release/releaseA' was configured to track the remote branch\n- You are now on branch 'release/releaseA'\n\n$ git log --oneline --decorate --graph --all\n* f993ec4 (HEAD -> release/releaseA, origin/release/releaseA) releaseA\n* 6e6605d (origin/develop, develop) featureA\n* 378941f (origin/master, master) Initial commit\n\n$ git flow release finish releaseA\nSwitched to branch 'master'\nYour branch is up-to-date with 'origin/master'.\nMerge made by the 'recursive' strategy.\n featureA | 0\n releaseA | 0\n 2 files changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 featureA\n create mode 100644 releaseA\nSwitched to branch 'develop'\nYour branch is up-to-date with 'origin/develop'.\nMerge made by the 'recursive' strategy.\n releaseA | 0\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 releaseA\nTo https://github.com/hzmajia/gitflow-example.git\n - [deleted]         release/releaseA\nDeleted branch release/releaseA (was f993ec4).\nSummary of actions:\n- Release branch 'release/releaseA' has been merged into 'master'\n- The release was tagged 'releaseA'\n- Release tag 'releaseA' has been back-merged into 'develop'\n- Release branch 'release/releaseA' has been locally deleted; it has been remotely deleted from 'origin'\n- You are now on branch 'develop'\n\n$ git branch -vv\n* develop 269c207 [origin/develop: ahead 3] Merge tag 'releaseA' into develop\n  master  4944ec5 [origin/master: ahead 3] Merge branch 'release/releaseA'\n\n$ git push origin master\nCounting objects: 3, done.\nCompressing objects: 100% (3/3), done.\nWriting objects: 100% (3/3), 372 bytes | 0 bytes/s, done.\nTotal 3 (delta 1), reused 0 (delta 0)\nremote: Resolving deltas: 100% (1/1), done.\nTo https://github.com/hzmajia/gitflow-example.git\n   378941f..4944ec5  master -> master\n\n$ git push origin develop\nCounting objects: 1, done.\nWriting objects: 100% (1/1), 238 bytes | 0 bytes/s, done.\nTotal 1 (delta 0), reused 0 (delta 0)\nTo https://github.com/hzmajia/gitflow-example.git\n   6e6605d..269c207  develop -> develop\n\n$ git branch -vv\n* develop 269c207 [origin/develop] Merge tag 'releaseA' into develop\n  master  4944ec5 [origin/master] Merge branch 'release/releaseA'\n\n$ ls\nfeatureA  releaseA\n```\n\n# Hotfix分支\n`git flow hotfix`：Hotfix分支列表\n`git flow hotfix start`：新建一个Hotfix分支\n`git flow publish`：将Hotfix分支推送到远程仓库，并设为`上游分支`\n`git flow hotfix finish`：完成一个Hotfix分支，一般是`merge request`或`pull request`的接受者执行\n```\n$ git flow hotfix start hotfixA\nSwitched to a new branch 'hotfix/hotfixA'\nSummary of actions:\n- A new branch 'hotfix/hotfixA' was created, based on 'master'\n- You are now on branch 'hotfix/hotfixA'\nFollow-up actions:\n- Start committing your hot fixes\n- Bump the version number now!\n- When done, run:\n     git flow hotfix finish 'hotfixA'\n\n$ git branch -vv\n  develop        269c207 [origin/develop] Merge tag 'releaseA' into develop\n* hotfix/hotfixA 4944ec5 Merge branch 'release/releaseA'\n  master         4944ec5 [origin/master] Merge branch 'release/releaseA'\n\n$ git flow hotfix\n* hotfixA\n\n$ git flow publish hotfixA\nTotal 0 (delta 0), reused 0 (delta 0)\nTo https://github.com/hzmajia/gitflow-example.git\n * [new branch]      hotfix/hotfixA -> hotfix/hotfixA\nBranch hotfix/hotfixA set up to track remote branch hotfix/hotfixA from origin.\nAlready on 'hotfix/hotfixA'\nYour branch is up-to-date with 'origin/hotfix/hotfixA'.\nSummary of actions:\n- The remote branch 'hotfix/hotfixA' was created or updated\n- The local branch 'hotfix/hotfixA' was configured to track the remote branch\n- You are now on branch 'hotfix/hotfixA'\n\n$ git branch -vv\n  develop        269c207 [origin/develop] Merge tag 'releaseA' into develop\n* hotfix/hotfixA 4944ec5 [origin/hotfix/hotfixA] Merge branch 'release/releaseA'\n  master         4944ec5 [origin/master] Merge branch 'release/releaseA'\n\n$ touch hotfixA && git add . && git commit -m 'hotfixA'\n[hotfix/hotfixA e17d475] hotfixA\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 hotfixA\n\n$ git flow publish hotfixA\nCounting objects: 2, done.\nCompressing objects: 100% (2/2), done.\nWriting objects: 100% (2/2), 249 bytes | 0 bytes/s, done.\nTotal 2 (delta 0), reused 0 (delta 0)\nTo https://github.com/hzmajia/gitflow-example.git\n   4944ec5..e17d475  hotfix/hotfixA -> hotfix/hotfixA\nBranch hotfix/hotfixA set up to track remote branch hotfix/hotfixA from origin.\nAlready on 'hotfix/hotfixA'\nYour branch is up-to-date with 'origin/hotfix/hotfixA'.\nSummary of actions:\n- The remote branch 'hotfix/hotfixA' was created or updated\n- The local branch 'hotfix/hotfixA' was configured to track the remote branch\n- You are now on branch 'hotfix/hotfixA'\n\n$ git log --oneline --decorate --graph --all\n* e17d475 (HEAD -> hotfix/hotfixA, origin/hotfix/hotfixA) hotfixA\n| *   269c207 (origin/develop, develop) Merge tag 'releaseA' into develop\n| |\\\n| |/\n|/|\n* |   4944ec5 (tag: releaseA, origin/master, master) Merge branch 'release/releaseA'\n|\\ \\\n| * | f993ec4 releaseA\n| |/\n| * 6e6605d featureA\n|/\n* 378941f Initial commit\n\n$ git flow hotfix finish hotfixA\nSwitched to branch 'master'\nYour branch is up-to-date with 'origin/master'.\nMerge made by the 'recursive' strategy.\n hotfixA | 0\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 hotfixA\nSwitched to branch 'develop'\nYour branch is up-to-date with 'origin/develop'.\nMerge made by the 'recursive' strategy.\n hotfixA | 0\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 hotfixA\nTo https://github.com/hzmajia/gitflow-example.git\n - [deleted]         hotfix/hotfixA\nDeleted branch hotfix/hotfixA (was e17d475).\nSummary of actions:\n- Hotfix branch 'hotfix/hotfixA' has been merged into 'master'\n- The hotfix was tagged 'hotfixA'\n- Hotfix tag 'hotfixA' has been back-merged into 'develop'\n- Hotfix branch 'hotfix/hotfixA' has been locally deleted; it has been remotely deleted from 'origin'\n- You are now on branch 'develop'\n\n$ git branch -vv\n* develop c293bc1 [origin/develop: ahead 3] Merge tag 'hotfixA' into develop\n  master  87bca9d [origin/master: ahead 2] Merge branch 'hotfix/hotfixA'\n\n$ git push origin master\nCounting objects: 3, done.\nCompressing objects: 100% (3/3), done.\nWriting objects: 100% (3/3), 338 bytes | 0 bytes/s, done.\nTotal 3 (delta 1), reused 0 (delta 0)\nremote: Resolving deltas: 100% (1/1), done.\nTo https://github.com/hzmajia/gitflow-example.git\n   4944ec5..87bca9d  master -> master\n\n$ git push origin master\nCounting objects: 1, done.\nWriting objects: 100% (1/1), 238 bytes | 0 bytes/s, done.\nTotal 1 (delta 0), reused 0 (delta 0)\nTo https://github.com/hzmajia/gitflow-example.git\n   269c207..c293bc1  develop -> develop\n\n$ git log --oneline --decorate --graph --all\n*   c293bc1 (HEAD -> develop, origin/develop) Merge tag 'hotfixA' into develop\n|\\\n| *   87bca9d (tag: hotfixA, origin/master, master) Merge branch 'hotfix/hotfixA'\n| |\\\n| | * e17d475 hotfixA\n| |/\n* |   269c207 Merge tag 'releaseA' into develop\n|\\ \\\n| |/\n| *   4944ec5 (tag: releaseA) Merge branch 'release/releaseA'\n| |\\\n| | * f993ec4 releaseA\n| |/\n|/|\n* | 6e6605d featureA\n|/\n* 378941f Initial commit\n```\n\n\n\n<!-- indicate-the-source -->\n","tags":["Git"],"categories":["Git"]},{"title":"Git -- 仓库瘦身","url":"%2F2017%2F04%2F19%2Fgit-reduce%2F","content":"\n{% note info %}\n本文主要介绍两种`减少.git仓库磁盘大小`的两种方式：`git gc`和`git prune`\n{% endnote %}\n\n<!-- more -->\n\n# git gc\n{% note info %}\n适用于`存在大文件`，且`多次提交都只是轻微改动该大文件`的场景，因为这些提交都会生成大小相近的大文件`blob对象`，非常占用磁盘空间\n{% endnote %}\n\n1. Git最初向磁盘中存储对象使用`松散`的格式，后续会将多个对象打包为一个二进制的`包文件`（`packfile`），以`节省磁盘空间`\n2. `.pack`文件存储了`对象的内容`\n3. `.idx`文件存储了`包文件`的`偏移信息`，用于`索引具体的对象`\n4. 打包对象时，查找命名和大小相近的文件，保留文件`不同版本之间的差异`（`最新一版保存完整内容`，访问频率最高）\n5. `verify-pack -v *.idx`：查看压缩包内容\n\n添加随机(压缩率低)字符大文件`bigfile`并提交\n```\n$ git init\nInitialized empty Git repository in /home/zhongmingmao/demo/.git/\n\n$ dd if=/dev/urandom of=./bigfile bs=1k count=10240 # use urandom , hard to be compressed\n10240+0 records in\n10240+0 records out\n10485760 bytes (10 MB, 10 MiB) copied, 0.84948 s, 12.3 MB/s\n\n$ du -sh bigfile\n10M bigfile\n\n$ du -sh .git\n96K .git\n\n$ du -sh .git/objects\n12K\t.git/objects\n\n$ git add bigfile\n\n$ du -sh .git\n11M .git\n\n$ du -sh .git/objects\n11M\t.git/objects\n\n$ git commit -m 'add bigfile'\n[master (root-commit) 6091c0e] add bigfile\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 bigfile\n\n$ git cat-file -p master^{tree}\n100644 blob 41b939bb0968e9a0ff69fcc50007107d94d9d3c8 bigfile\n\n$ git cat-file -s 41b939bb0968e9a0ff69fcc50007107d94d9d3c8\n10485760 # 10MBytes\n\n$ du -sh .git/objects/41/b939bb0968e9a0ff69fcc50007107d94d9d3c8\n11M .git/objects/41/b939bb0968e9a0ff69fcc50007107d94d9d3c8\n```\n轻微改动`bigfile`后提交\n```\n$ echo 'zhongmingmao' >> bigfile\n\n$ git commit -am 'echo zhongmingmao >> bigfile'\n[master 5834cad] echo zhongmingmao >> bigfile\n 1 file changed, 0 insertions(+), 0 deletions(-)\n\n$ du -sh .git # double size!!\n21M .git\n\n$ du -sh .git/objects\n21M .git\n\n$ git cat-file -p master^{tree}\n100644 blob ce4134c5eecf2b379d2eac3f812409f1b602cd85 bigfile\n\n$ git cat-file -s ce4134c5eecf2b379d2eac3f812409f1b602cd8\n10485773\n\n$ du -sh .git/objects/ce/4134c5eecf2b379d2eac3f812409f1b602cd85\n11M .git/objects/ce/4134c5eecf2b379d2eac3f812409f1b602cd85\n```\n`git gc`压缩，`41b939`参照`ce4134`（旧版本参照新版本，`最新版本保存完整内容`）\n```\n$ git gc\nCounting objects: 6, done.\nCompressing objects: 100% (4/4), done.\nWriting objects: 100% (6/6), done.\nTotal 6 (delta 1), reused 0 (delta 0)\n\n$ find .git/objects -type f\n.git/objects/info/packs\n.git/objects/pack/pack-73a2d8537fba854db8f9f413799b0d5274a52135.pack\n.git/objects/pack/pack-73a2d8537fba854db8f9f413799b0d5274a52135.idx\n\n$ du -sh .git\n11M .git\n\n$ du -sh .git/objects/*\n8.0K  .git/objects/info\n11M   .git/objects/pack\n\n$ git verify-pack -v .git/objects/pack/pack-73a2d8537fba854db8f9f413799b0d5274a52135.idx\n5834cadac71e81cbcba954f49611feeaaa92cd3a commit 249 153 12\n6091c0e06a518c510e70d09a6892b122672ab837 commit 184 121 165\nce4134c5eecf2b379d2eac3f812409f1b602cd85 blob   10485773 10488983 286\n70f4ea5a7ec96577205e4f8a9e1daba81f4ed6f7 tree   35 46 10489269\n59c311f2a94eb4936ccc39fc1dae89fb3660ffe7 tree   35 46 10489315\n41b939bb0968e9a0ff69fcc50007107d94d9d3c8 blob   327 249 10489361 1 ce4134c5eecf2b379d2eac3f812409f1b602cd85\nnon delta: 5 objects\nchain length = 1: 1 object\n.git/objects/pack/pack-73a2d8537fba854db8f9f413799b0d5274a52135.pack: ok\n\n$ git cat-file -p master^{tree}\n100644 blob ce4134c5eecf2b379d2eac3f812409f1b602cd85 bigfile\n\n$ git cat-file -s ce4134c5eecf2b379d2eac3f812409f1b602cd85\n10485773\n```\n\n# git prune\n{% note warning %}\n`git clone`会下载`整个`项目提交历史，如果`曾经`添加过`大文件`，后续`git rm`了，每次`git clone`依旧会下载那个大文件对应的`blob对象`，将要介绍的方法会`重写提交历史`，请`谨慎使用`\n{% endnote %}\n\n1. `git count-objects -v`：快速查看`object databse`的概要情况\n2. `git rev-list --all --objects`：显示`所有commit及其所关联的所有对象`\n3. `git log --branches -- $filename`：查看哪些对`$filename`做出了修改的`commit`\n4. `git filter-branch --index-filter 'git rm --ignore-unmatch --cached $filename' -- $sha1`\n    - `--index-filter`：不`checkout`到`working directory`，只修改`index`的文件，`速度快很多`\n    - `--ignore-unmatch`：尝试`删除的模式无法匹配`时，`不提示错误`\n    - `--cached`：从`index`删除\n5. `git prune --expire now`：立马删除`object database`中`不可达的对象`\n\n`dd02204`引入了大文件`bigfile`，后续在`f161ef0`删除了`bigfile`，但`object database`大小没有减少，`git gc`也无法减少磁盘占用\n```\n$ git log --oneline --decorate --graph --all\n* cc12440 (HEAD -> master) C4\n* db72b36 C3\n* 5eebbac C2\n* d49df27 C1\n* 19460ce C0\n\n$ dd if=/dev/urandom of=./bigfile bs=1k count=10240\n10240+0 records in\n10240+0 records out\n10485760 bytes (10 MB, 10 MiB) copied, 0.876271 s, 12.0 MB/s\n\n$ git add bigfile && git commit -m 'add bigfile'\n[master dd02204] add bigfile\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 bigfile\n\n$ du -s .git/objects\n10364\t.git/objects\n\n$ git rm bigfile\nrm 'bigfile'\n\n$ git commit -m 'git rm bigfile'\n[master f161ef0] git rm bigfile\n 1 file changed, 0 insertions(+), 0 deletions(-)\n delete mode 100644 bigfile\n\n$ du -s .git/objects\n10372\t.git/objects\n\n$ git gc\nCounting objects: 15, done.\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (15/15), done.\nTotal 15 (delta 5), reused 0 (delta 0)\n\n$ git count-objects -v\ncount: 0\nsize: 0\nin-pack: 15\npacks: 1\nsize-pack: 10245 # 10M\nprune-packable: 0\ngarbage: 0\nsize-garbage: 0\n```\n查找`object database`中的大文件`bigfile`对应的`blob对象`的`ID`\n如果非常清除大文件`bigfile`是从哪一个`commit`引入的，可以直接跳到`filter-branch`\n```\n$ git verify-pack -v .git/objects/pack/pack-695de68a1a8a850a46c18f5619bd51e5efbd8cdc.idx\nf161ef0b13c784cefca1316578e671d4bdc375ec commit 235 152 12\ndd02204bdd017cee28cf1fa156f161cf844951a3 commit 232 150 164\ncc1244046a2534b2097819439ab705c579396937 commit 71 82 314 1 f161ef0b13c784cefca1316578e671d4bdc375ec\ndb72b3604bad5a3f76083f4140517e588e6032cf commit 223 145 396\n5eebbac0f01a8c179f7fd4ca3b800f1cef6d28cd commit 223 145 541\nd49df27f3df12877e347d78b6441254bcc718296 commit 223 144 686\n19460cee4babe9a801cd96148aac236121a3a2cb commit 175 115 830\ne69de29bb2d1d6434b8b29ae775ad8c2e48c5391 blob   0 9 945\n814058ae67e19720f67c9a0cc7ee5550ca1fa4a0 tree   185 85 954\n7b3dc4c67a91b8d838b3ca02421de3a50dcb68d2 tree   6 16 1039 1 814058ae67e19720f67c9a0cc7ee5550ca1fa4a0\n27323e81a35521d9fd8705885b1593cf7f3a953b blob   10485760 10488970 1055\nd8b75f412dd1563d651c6f6e222ddde31b1befda tree   5 18 10490025 1 814058ae67e19720f67c9a0cc7ee5550ca1fa4a0\n8cc551af62c753b24e3f2710b9316b0c02e321ef tree   4 14 10490043 2 d8b75f412dd1563d651c6f6e222ddde31b1befda\nfdfe0e3dc93fa9340d58cd0c0a406e07769c42d9 tree   4 14 10490057 2 d8b75f412dd1563d651c6f6e222ddde31b1befda\necac4a6cf836d86ef14a942fe00287a26534261c tree   30 41 10490071\nnon delta: 10 objects\nchain length = 1: 3 objects\nchain length = 2: 2 objects\n.git/objects/pack/pack-de5573c64f095927d05eaad6c39cd98e53ee4c93.pack: ok\n\n$ git cat-file -s 27323e81a35521d9fd8705885b1593cf7f3a953b\n10485760\n```\n显示`27323e`对应的`文件名`\n```\n$ git rev-list --all --objects | grep 27323e\n27323e81a35521d9fd8705885b1593cf7f3a953b bigfile\n```\n显示对`bigfile`做出过修改的`commit`\n```\n$ git log --oneline --branches -- bigfile\nf161ef0 git rm bigfile\ndd02204 add bigfile\n```\n重建提交历史\n```\n$ git filter-branch --index-filter 'git rm --ignore-unmatch --cached bigfile' -- dd02204^..\nRewrite dd02204bdd017cee28cf1fa156f161cf844951a3 (1/2) (0 seconds passed, remaining 0 predicted)    rm 'bigfile'\nRewrite f161ef0b13c784cefca1316578e671d4bdc375ec (2/2) (0 seconds passed, remaining 0 predicted)\nRef 'refs/heads/master' was rewritten\n\n$ git log --oneline --decorate --graph --all\n* 7c504c6 (HEAD -> master) git rm bigfile\n* 98c862a add bigfile\n| * f161ef0 (refs/original/refs/heads/master) git rm bigfile\n| * dd02204 add bigfile\n|/\n* cc12440 C4\n* db72b36 C3\n* 5eebbac C2\n* d49df27 C1\n* 19460ce C0\n\n$ git count-objects -v\ncount: 2\nsize: 8\nin-pack: 15\npacks: 1\nsize-pack: 10245 # 10M\nprune-packable: 0\ngarbage: 0\nsize-garbage: 0\n\n```\n删除`.git/refs/original`和`.git/logs`（使得`bigfile的blob对象`成为`不可达`）然后再清除`不可达对象`\n```\n$ rm -rf .git/refs/original\n\n$ rm -rf .git/logs\n\n$ git gc\nCounting objects: 13, done.\nCompressing objects: 100% (9/9), done.\nWriting objects: 100% (13/13), done.\nTotal 13 (delta 5), reused 8 (delta 2)\n\n$ git count-objects -v\ncount: 4\nsize: 10256 # 10M\nin-pack: 13\npacks: 1\nsize-pack: 2\nprune-packable: 0\ngarbage: 0\nsize-garbage: 0\n\n$ git prune --expire now\n\n$ git count-objects -v\ncount: 0\nsize: 0\nin-pack: 13\npacks: 1\nsize-pack: 2\nprune-packable: 0\ngarbage: 0\nsize-garbage: 0\n\n$ du -sh .git/objects\n24K\t.git/objects # 10M -> 24K\n\n$ git log --oneline --decorate --graph --all\n* 7c504c6 (HEAD -> master) git rm bigfile\n* 98c862a add bigfile\n* cc12440 C4\n* db72b36 C3\n* 5eebbac C2\n* d49df27 C1\n* 19460ce C0\n```\n\n<!-- indicate-the-source -->\n","tags":["Git"],"categories":["Git"]},{"title":"Git -- 对象","url":"%2F2017%2F04%2F19%2Fgit-object%2F","content":"\n{% note info %}\n本文将主要介绍`blob`对象，`tree`对象，`commit`对象，`tag`对象\n{% endnote %}\n\n<!-- more -->\n\n# .git核心\n\n1. `.git/HEAD`：一般情况下，`指向分支引用`；如果`直接指向提交对象`，将处于`detached HEAD`状态\n2. `.git/index`：`暂存区`信息\n3. `.git/objects`：`Git对象`数据\n4. `.git/refs`：`引用`信息，包括`分支引用`，`标签引用`等\n\n```\n$ git log --oneline --decorate --graph --all\n* ae432e4 (HEAD -> master) echo master > file\n* daa44e8 add file\n\n$ ls .git\nbranches  COMMIT_EDITMSG  config  description  HEAD  hooks  index  info  logs  objects  ORIG_HEAD  refs  rr-cache\n\n$ cat .git/HEAD\nref: refs/heads/master\n\n$ cat .git/refs/heads/master\nae432e46c21f45991f18eeac8586da367134bff7\n\n$ git checkout HEAD~\nNote: checking out 'HEAD~'.\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by performing another checkout.\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -b with the checkout command again. Example:\n  git checkout -b <new-branch-name>\nHEAD is now at daa44e8... add file\n\n$ ➦ daa44e8 cat .git/HEAD # ref a commit object , not a branch ref -> 'detached HEAD' state\ndaa44e833989e82b1f41d12fea5dd391b163bce6\n\n$ ➦ daa44e8 cat .git/refs/heads/master\nae432e46c21f45991f18eeac8586da367134bff7\n\n$ ➦ daa44e8 git checkout master\nPrevious HEAD position was daa44e8... add file\nSwitched to branch 'master'\n\n$ $ cat .git/HEAD\nref: refs/heads/master\n\n$ ls .git/objects\n08  1f  ae  da  df  e6  info  pack\n```\n\n# blob对象\n1. `blob对象`：存储**`实际的文件内容`**\n2. `hash-object -w`：计算`object ID`，并写入`object database`（即`.git/objects`）\n3. `cat-file -p`：显示`Git对象信息`\n4. `cat-file -t`：显示`Git对象类型`\n\n```\n$ git init\nInitialized empty Git repository in /home/zhongmingmao/demo/.git/\n\n$ find .git/objects\n.git/objects\n.git/objects/info\n.git/objects/pack\n\n$ find .git/objects -type f # no objects , stdout printed nothing\n\n$ echo 'zhongmingmao' | git hash-object -w --stdin # write blob object to object database\nb98963d686f67040f88c58be271b1ef7541d5ec0\n\n$ git cat-file -p b98963d686f67040f88c58be271b1ef7541d5ec0\nzhongmingmao\n\n$ git cat-file -t b98963d686f67040f88c58be271b1ef7541d5ec0\nblob\n\n$ echo 'v1' > zhongmingmao.txt\n\n$ git hash-object -w zhongmingmao.txt\n626799f0f85326a8c1fc522db584e86cdfccd51f\n\n$ echo 'v2' > zhongmingmao.txt\n\n$ git hash-object -w zhongmingmao.txt\n8c1384d825dbbe41309b7dc18ee7991a9085c46e\n\n$ find .git/objects -type f\n.git/objects/b9/8963d686f67040f88c58be271b1ef7541d5ec0\n.git/objects/62/6799f0f85326a8c1fc522db584e86cdfccd51f\n.git/objects/8c/1384d825dbbe41309b7dc18ee7991a9085c46e\n\n$ git cat-file -p 626799f0f85326a8c1fc522db584e86cdfccd51\nv1\n\n$ git cat-file -p 8c1384d825dbbe41309b7dc18ee7991a9085c46e\nv2\n\n$ git cat-file -t 8c1384d825dbbe41309b7dc18ee7991a9085c46e\nblob\n```\n\n# tree对象\n1. `tree对象`：主要用于**`组织多个文件`**，类似于`目录的作用`\n2. `$branch^{tree}`：`分支引用的commit对象`所指向的`tree对象`\n3. `update-index`：将文件内容注册到`index`\n    - `--add`：将不存在于`index`的文件添加到`index`\n    - `--cacheinfo`：将`object database`（`.git/objects`）的文件添加到`index`\n4. `write-tree`：将`index`的当前内容创建一个`tree`对象，相当于`保存快照`\n5. `read-tree --prefix`：将一个已存在的`tree`对象写入`index`，指定`子目录前缀`\n\n创建第1个tree对象`904970`\n```\n$ git init\nInitialized empty Git repository in /home/zhongmingmao/demo/.git/\n\n$ echo 'v1' > zhongmingmao.txt\n\n$ git hash-object -w zhongmingmao.txt\n\n$ find .git/objects -type f\n.git/objects/62/6799f0f85326a8c1fc522db584e86cdfccd51f\n\n$ gst -sb\n## Initial commit on master\n?? zhongmingmao.txt\n\n# add zhongmingmao.txt(v1) to index from git object database\n$ git update-index --add --cacheinfo 100644 626799f0f85326a8c1fc522db584e86cdfccd51f zhongmingmao.txt\n\n$ gst -sb\n## Initial commit on master\nA  zhongmingmao.txt\n\n$ find .git/objects -type f\n.git/objects/62/6799f0f85326a8c1fc522db584e86cdfccd51f\n\n$ git write-tree # create tree object from index\n904970fc7917a1f77fff8280298cb54da4bd89c2\n\n$ find .git/objects -type f\n.git/objects/62/6799f0f85326a8c1fc522db584e86cdfccd51f\n.git/objects/90/4970fc7917a1f77fff8280298cb54da4bd89c2\n\n$ git cat-file -p 904970fc7917a1f77fff8280298cb54da4bd89c2\n100644 blob 626799f0f85326a8c1fc522db584e86cdfccd51f zhongmingmao.txt\n\n$ git cat-file -t 904970fc7917a1f77fff8280298cb54da4bd89c2\ntree\n```\n创建第2个tree对象`dec4f9`\n```\n$ echo 'v2' > zhongmingmao.txt\n\n$ gst -sb\n## Initial commit on master\nAM zhongmingmao.txt\n\n# replace zhongmingmao.txt(v2) of zhongmingmao(v1) in index from working directory\n$ git update-index zhongmingmao.txt\n\n$ gst -sb\n## Initial commit on master\nA  zhongmingmao.txt\n\n$ touch README.md\n\n$ git update-index --add README.md # add README.md to index from working diectory\n\n$ gst -sb\n## Initial commit on master\nA  README.md\nA  zhongmingmao.txt\n\n$ git write-tree\ndec4f9365e77576c0a95cd1938a50e71a9f7a6b6\n\n$ git cat-file -p dec4f9365e77576c0a95cd1938a50e71a9f7a6b6\n100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 README.md\n100644 blob 8c1384d825dbbe41309b7dc18ee7991a9085c46e zhongmingmao.txt\n\n$ git cat-file -p 8c1384d825dbbe41309b7dc18ee7991a9085c46e\nv2\n```\n创建第3个tree对象`aff674`\n```\n$ git read-tree --prefix=v1 904970fc7917a1f77fff8280298cb54da4bd89c2 # read tree(904970) to index as subdir 'v1'\n\n$ gst -sb\n## Initial commit on master\nA  README.md\nAD v1/zhongmingmao.txt\nA  zhongmingmao.txt\n\n$ git write-tree\naff6742443246bc0e9df32727ce0e5ee27de3b1c\n\n$ git cat-file -p aff6742443246bc0e9df32727ce0e5ee27de3b1c\n100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 README.md\n040000 tree 904970fc7917a1f77fff8280298cb54da4bd89c2 v1\n100644 blob 8c1384d825dbbe41309b7dc18ee7991a9085c46e zhongmingmao.txt\n\n$ git checkout -- v1\n\n$ gst -sb\n## Initial commit on master\nA  README.md\nA  v1/zhongmingmao.txt\nA  zhongmingmao.txt\n\n$ ls *\nREADME.md  zhongmingmao.txt\nv1:\nzhongmingmao.txt\n\n$ cat zhongmingmao.txt\nv2\n\n$ cat v1/zhongmingmao.txt\nv1\n\n$ git commit -m 'init commit'\n[master (root-commit) bd32670] init commit\n 3 files changed, 2 insertions(+)\n create mode 100644 README.md\n create mode 100644 v1/zhongmingmao.txt\n create mode 100644 zhongmingmao.txt\n\n$ git cat-file -p master^{tree}\n100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 README.md\n040000 tree 904970fc7917a1f77fff8280298cb54da4bd89c2 v1\n100644 blob 8c1384d825dbbe41309b7dc18ee7991a9085c46e zhongmingmao.txt\n\n$ git cat-file -p HEAD^{tree}\n100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 README.md\n040000 tree 904970fc7917a1f77fff8280298cb54da4bd89c2 v1\n100644 blob 8c1384d825dbbe41309b7dc18ee7991a9085c46e zhongmingmao.txt\n\n$ git cat-file -p bd32670^{tree}\n100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 README.md\n040000 tree 904970fc7917a1f77fff8280298cb54da4bd89c2 v1\n100644 blob 8c1384d825dbbe41309b7dc18ee7991a9085c46e zhongmingmao.txt\n```\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/tree_object.png\" width=\"500\">\n\n\n# commit对象\n1. `commit`对象，指向一个`tree`对象，相当于一个`快照`\n2. `commit-tree $tree_object -p $commit_object`：创建提交对象\n\n依次创建3个`tree`对象：`90497`，`dec4f9`，`aff674`\n```\n$ git init\nInitialized empty Git repository in /home/zhongmingmao/demo/.git/\n\n$ echo 'v1' > zhongmingmao.txt\n\n$ git hash-object -w zhongmingmao.txt\n626799f0f85326a8c1fc522db584e86cdfccd51f\n\n$ git update-index --add --cacheinfo 100644 626799f0f85326a8c1fc522db584e86cdfccd51f zhongmingmao.txt\n\n$ git write-tree\n904970fc7917a1f77fff8280298cb54da4bd89c2\n\n$ echo 'v2' > zhongmingmao.txt\n\n$ git update-index zhongmingmao.txt\n\n$ touch README.md\n\n$ git update-index --add README.md\n\n$  git write-tree\ndec4f9365e77576c0a95cd1938a50e71a9f7a6b6\n\n$ git read-tree --prefix=v1 904970fc7917a1f77fff8280298cb54da4bd89c2\n\n$ git checkout -- v1\n\n$ git write-tree\naff6742443246bc0e9df32727ce0e5ee27de3b1c\n\n$ gst -sb\n## Initial commit on master\nA  README.md\nA  v1/zhongmingmao.txt\nA  zhongmingmao.txt\n```\n创建第1个`commit`对象`63dacd`，关于`.git/HEAD`和`.git/refs/heads/master`属于`Git引用`的内容，后续补充\n```\n$ git commit-tree 904970 -m '1st commit'\n63dacdf39138700e82649e7ead745e2a9322d926\n\n$ git cat-file -p 63dacd\ntree 904970fc7917a1f77fff8280298cb54da4bd89c2\nauthor zhongmingmao <zhongmingmao@yeah.net> 1492596559 +0800\ncommitter zhongmingmao <zhongmingmao@yeah.net> 1492596559 +0800\n1st commit\n\n$ gst -sb\n## Initial commit on master\nA  README.md\nA  v1/zhongmingmao.t\n\n$ cat .git/HEAD\nref: refs/heads/master\n\n$ echo '63dacdf39138700e82649e7ead745e2a9322d926' > .git/refs/heads/master\n\n$ gst -sb\n## master\nA  README.md\nA  v1/zhongmingmao.txt\nM  zhongmingmao.txt\n\n$ git diff --cached zhongmingmao.txt\ndiff --git a/zhongmingmao.txt b/zhongmingmao.txt\nindex 626799f..8c1384d 100644\n--- a/zhongmingmao.txt\n+++ b/zhongmingmao.txt\n@@ -1 +1 @@\n-v1\n+v2\n\n$ git log --oneline --decorate --graph --all\n* 63dacdf (HEAD -> master) 1st commit\n```\n创建第2个`commit`对象`1eb9faf`\n```\n$ git commit-tree dec4f9 -p 63dacdf -m '2nd commit'\n1eb9faf3eff1ae9018a223a0a74b9e86ad7f5523\n\n$ echo '1eb9faf3eff1ae9018a223a0a74b9e86ad7f5523' > .git/refs/heads/master\n\n$ gst -sb\n## master\nA  v1/zhongmingmao.txt\n\n$ git log --oneline --decorate --graph --all\n* 1eb9faf (HEAD -> master) 2nd commit\n* 63dacdf 1st commit\n```\n创建第3个`commit`对象`5fbdcc4`\n```\n$ git commit-tree aff674 -p 1eb9faf -m '3rd commit'\n5fbdcc4c76301f9a1c80bdd44ba1c18c1410dc21\n\n$ echo '5fbdcc4c76301f9a1c80bdd44ba1c18c1410dc21' > .git/refs/heads/master\n\n$ gst\nOn branch master\nnothing to commit, working directory clean\n\n$ git log --oneline --decorate --graph --all\n* 5fbdcc4 (HEAD -> master) 3rd commit\n* 1eb9faf 2nd commit\n* 63dacdf 1st commit\n\n$ git cat-file -p 5fbdcc4\ntree aff6742443246bc0e9df32727ce0e5ee27de3b1c\nparent 1eb9faf3eff1ae9018a223a0a74b9e86ad7f5523\nauthor zhongmingmao <zhongmingmao@yeah.net> 1492597186 +0800\ncommitter zhongmingmao <zhongmingmao@yeah.net> 1492597186 +0800\n3rd commit\n```\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/commit_object.png\" width=\"500\">\n\n# tag对象\n{% note info %}\n只有`annotated tag`才会创建`tag`对象，`lightweight tag`直接指向`commit`对象\n{% endnote %}\n\n## lightweight tag\n```\n$ git log --oneline --decorate --graph --all\n* 5fbdcc4 (HEAD -> master) 3rd commit\n* 1eb9faf 2nd commit\n* 63dacdf 1st commit\n\n$ git tag v1.0 1eb9faf # just point to a commit object directly , no tag object\n\n$ git log --oneline --decorate --graph --all\n* 5fbdcc4 (HEAD -> master) 3rd commit\n* 1eb9faf (tag: v1.0) 2nd commit\n* 63dacdf 1st commit\n\n$ git show --oneline -s v1.0\n1eb9faf 2nd commit\n\n$ cat .git/refs/tags/v1.0\n1eb9faf3eff1ae9018a223a0a74b9e86ad7f5523\n\n$ git cat-file -t 1eb9faf3eff1ae9018a223a0a74b9e86ad7f5523\ncommit\n```\n\n## annotated tag\n```\n$ git log --oneline --decorate --graph --all\n* 5fbdcc4 (HEAD -> master) 3rd commit\n* 1eb9faf (tag: v1.0) 2nd commit\n* 63dacdf 1st commit\n\n$ git tag -a v2.0 -m 'tag 2.0' # create a annotated tag object which point to a commit object\n\n$ git log --oneline --decorate --graph --all\n* 5fbdcc4 (HEAD -> master, tag: v2.0) 3rd commit\n* 1eb9faf (tag: v1.0) 2nd commit\n* 63dacdf 1st commit\n\n$ git show --oneline -s v2.0\ntag v2.0\ntag 2.0\n5fbdcc4 3rd commit\n\n$ cat .git/refs/tags/v2.0\n8a4e71ed97d18b9ad3a83850eef09a2c651e0e01\n\n$ git cat-file -p 8a4e71ed97d18b9ad3a83850eef09a2c651e0e01\nobject 5fbdcc4c76301f9a1c80bdd44ba1c18c1410dc21\ntype commit\ntag v2.0\ntagger zhongmingmao <zhongmingmao@yeah.net> 1492599543 +0800\ntag 2.0\n\n$ git cat-file -t 8a4e71ed97d18b9ad3a83850eef09a2c651e0e01\ntag\n\n$ git cat-file -t 5fbdcc4c76301f9a1c80bdd44ba1c18c1410dc21\ncommit\n```\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/tag_object.png\" width=\"500\">\n\n<!-- indicate-the-source -->\n","tags":["Git"],"categories":["Git"]},{"title":"Git -- 合并","url":"%2F2017%2F04%2F17%2Fgit-merge%2F","content":"\n{% note info %}\n本文主要介绍`合并中断`，`查看冲突`，`冲突相关的提交`，`撤销合并`\n{% endnote %}\n\n<!-- more -->\n\n# 中断合并\n`git merge --abort`：当出现冲突时，`放弃当前合并`，尝试恢复到`合并前的状态`\n```\n$ git branch -v\n  dev    43b3f7b echo dev > file\n* master 3f112d7 echo master > file\n\n$ git diff dev # conflict exists\ndiff --git a/file b/file\nindex 38f8e88..1f7391f 100644\n--- a/file\n+++ b/file\n@@ -1 +1 @@\n-dev\n+master\n\n$ git merge dev\nAuto-merging file\nCONFLICT (content): Merge conflict in file\nAutomatic merge failed; fix conflicts and then commit the result.\n\n$ gst\nOn branch master\nYou have unmerged paths.\n  (fix conflicts and run \"git commit\")\nUnmerged paths:\n  (use \"git add <file>...\" to mark resolution)\n\tboth modified:   file\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\n$ git merge --abort\n\n$ gst\nOn branch master\nnothing to commit, working directory clean\n```\n\n# 查看冲突\n1. `git ls-files -u`：显示`unmerged`的文件，有三个版本\n    - `Stage 1`：共同的祖先版本\n    - `Stage 2`：自身版本\n    - `Stage 3`：MERGE_HEAD版本（将要被合并的版本）\n2. `git diff --base`：等效于`git diff`\n3. `git diff --ours`：突出ours，等效于`git diff HEAD`\n4. `git diff --theirs`：突出theirs，等效于`git diff MERGE_HEAD`\n\n```\n$ git branch -v\n  dev    43b3f7b echo dev > file\n* master 3f112d7 echo master > file\n\n$ git merge dev\nAuto-merging file\nCONFLICT (content): Merge conflict in file\nAutomatic merge failed; fix conflicts and then commit the result.\n\n$ gst -sb\n## master\nUU file\n\n$ git ls-files -u\n100644 e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 1 file\n100644 1f7391f92b6a3792204e07e99f71f643cc35e7e1 2 file\n100644 38f8e886e1a6d733aa9bfa7282568f83c133ecd6 3 file\n\n$ git show :1:file\n\n$ git show :2:file\nmaster\n\n$ git show :3:file\ndev\n\n$ git diff --base\n* Unmerged path file\ndiff --git a/file b/file\nindex e69de29..0010ca6 100644\n--- a/file\n+++ b/file\n@@ -0,0 +1,5 @@\n+<<<<<<< HEAD\n+master\n+=======\n+dev\n+>>>>>>> dev\n\n$ git diff --ours\n* Unmerged path file\ndiff --git a/file b/file\nindex 1f7391f..0010ca6 100644\n--- a/file\n+++ b/file\n@@ -1 +1,5 @@\n+<<<<<<< HEAD\n master # highlight\n+=======\n+dev\n+>>>>>>> dev\n\n$ git diff --theirs\n* Unmerged path file\ndiff --git a/file b/file\nindex 38f8e88..0010ca6 100644\n--- a/file\n+++ b/file\n@@ -1 +1,5 @@\n+<<<<<<< HEAD\n+master\n+=======\n dev # highlight\n+>>>>>>> dev\n```\n\n# 冲突来源\n`git log --merge`：显示`与冲突相关的提交`\n```\n$ git log --oneline --decorate --graph --all\n* f14595d (HEAD -> master) add c.txt\n* b69a9be echo master > a.txt\n| * 4ffcc97 (dev) add b.txt\n| * 6f197c8 echo dev > a.txt\n|/\n* 51c144f add a.txt\n\n$ git log --oneline --left-right master...dev # see 「Git++ - 引用和提交区间」\n< f14595d add c.txt\n< b69a9be echo master > a.txt\n> 4ffcc97 add b.txt\n> 6f197c8 echo dev > a.txt\n\n$ git diff master..dev # conflict exists\ndiff --git a/a.txt b/a.txt\nindex 1f7391f..38f8e88 100644\n--- a/a.txt\n+++ b/a.txt\n@@ -1 +1 @@\n-master\n+dev\ndiff --git a/b.txt b/b.txt\nnew file mode 100644\nindex 0000000..e69de29\ndiff --git a/c.txt b/c.txt\ndeleted file mode 100644\nindex e69de29..0000000\n\n$ git merge dev\nAuto-merging a.txt\nCONFLICT (content): Merge conflict in a.txt\nRecorded preimage for 'a.txt'\nAutomatic merge failed; fix conflicts and then commit the result.\n\n$ git log --left-right --oneline --merge -p\n< b69a9be echo master > a.txt\ndiff --git a/a.txt b/a.txt\nindex e69de29..1f7391f 100644\n--- a/a.txt\n+++ b/a.txt\n@@ -0,0 +1 @@\n+master\n> 6f197c8 echo dev > a.txt\ndiff --git a/a.txt b/a.txt\nindex e69de29..38f8e88 100644\n--- a/a.txt\n+++ b/a.txt\n@@ -0,0 +1 @@\n+dev\n```\n\n# 撤销合并\n{% note warning %}\n将要介绍`reset`和`revert`这两种方式来`撤销已提交的合并`，请`谨慎使用`，适用于`尚未共享的提交`\n{% endnote %}\n\n## reset `--hard`\n{% note info %}\n相关内容请参照「Git++ - Reset」\n{% endnote %}\n```\n$ git log --oneline --decorate --graph --all\n*   7a18228 (HEAD -> master) M1\n|\\\n| * c446a31 (dev) C3\n| * 8e12eb6 C2\n* | bc8551b C5\n* | 220958f C4\n|/\n* 4d8ef47 C1\n* 0c1d26b C0\n\n$ git reset --hard HEAD~\nHEAD is now at bc8551b C5\n\n$ git log --oneline --decorate --graph --all\n* bc8551b (HEAD -> master) C5\n* 220958f C4\n| * c446a31 (dev) C3\n| * 8e12eb6 C2\n|/\n* 4d8ef47 C1\n* 0c1d26b C0\n```\n\n## revert\n{% note warning %}\n当提交对象是`普通提交对象`C1时，新建提交对象C2，还原C1的修改\n当提交对象是`合并提交对象`是C1，新建提交对象C2，`保留其中一个父提交对象`P1，还原`其他父提交对象`的修改\n`revert后再次merge`，有可能出现`Already up-to-date`，因为在当前提交对象能回溯到相关的提交。如果想再次合并之前放弃掉的父提交对象的修改，可以再次执行`revert`或直接`reset --hard`\n{% endnote %}\n`revert -m`：保留父提交对象，`1`代表第一父提交对象，`2`代表第二提交对象\n```\n$ git log --oneline --decorate --graph --all\n*   f16d507 (HEAD -> master) M1\n|\\\n| * c446a31 (dev) C3\n| * 8e12eb6 C2\n* | bc8551b C5\n* | 220958f C4\n|/\n* 4d8ef47 C1\n* 0c1d26b C0\n\n$ ls\nC0  C1  C4  C5\n\n$ git revert -m 1 HEAD # keep C5 , give up C3\n[master bc96ef3] Revert \"M1\" -m 1\n 2 files changed, 0 insertions(+), 0 deletions(-)\n delete mode 100644 C2\n delete mode 100644 C3\n\n$ git log --oneline --decorate --graph --all\n* bc96ef3 (HEAD -> master) Revert \"M1\" -m 1\n*   f16d507 M1\n|\\\n| * c446a31 (dev) C3\n| * 8e12eb6 C2\n* | bc8551b C5\n* | 220958f C4\n|/\n* 4d8ef47 C1\n* 0c1d26b C0\n\n$ ls # as same as C5\nC0  C1  C4  C5\n\n$ git merge dev # can track C2 C3\nAlready up-to-date.\n```\n`dev`上新增提交`C6`，`master merge dev`不会出现`C2`和`C3`，因为本质是`bc96ef3 merge 105cf17`\n```\n$ git checkout dev\nSwitched to branch 'dev'\n\n$ cn=C6 && touch $cn && git add . && git commit -m $cn\n[dev 105cf17] C6\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 C6\n\n$ git checkout master\nSwitched to branch 'master'\n\n$ git merge dev -m 'M2'\nMerge made by the 'recursive' strategy.\n C6 | 0\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 C6\n\n$ git log --oneline --decorate --graph --all\n*   f58ffc1 (HEAD -> master) M2\n|\\\n| * 105cf17 (dev) C6\n* | bc96ef3 Revert \"M1\" -m 1\n* |   f16d507 M1\n|\\ \\\n| |/\n| * c446a31 C3\n| * 8e12eb6 C2\n* | bc8551b C5\n* | 220958f C4\n|/\n* 4d8ef47 C1\n* 0c1d26b C0\n\n$ ls # C2 C3 lost!!\nC0  C1  C4  C5  C6\n```\n如果想再次复现`C2`和`C3`的修改，可以`revert bc96ef3`或者`reset --hard f16d507`，注意这些提交对象应该都是`没有被共享`的\n```\n$ git reset --hard HEAD^^\nHEAD is now at f16d507 M1\n\n$ git merge dev -m 'M2'\nMerge made by the 'recursive' strategy.\n C6 | 0\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 C6\n\n$ git log --oneline --decorate --graph --all\n*   ea0507c (HEAD -> master) M2\n|\\\n| * 105cf17 (dev) C6\n* |   f16d507 M1\n|\\ \\\n| |/\n| * c446a31 C3\n| * 8e12eb6 C2\n* | bc8551b C5\n* | 220958f C4\n|/\n* 4d8ef47 C1\n* 0c1d26b C0\n\n$ ls\nC0  C1  C2  C3  C4  C5  C6\n```\n\n\n\n<!-- more -->\n<!-- indicate-the-source -->\n","tags":["Git"],"categories":["Git"]},{"title":"Git -- Reset","url":"%2F2017%2F04%2F17%2Fgit-reset%2F","content":"\n{% note info %}\n本文主要介绍通过`reset`如何将` HEAD重置到特定的状态`\n{% endnote %}\n\n<!-- more -->\n\n# 常见工作流程\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/normal_workflow.png\" width=\"500\">\n\n## 三个区域\n`HEAD`：存储在`.git`目录，`上一次提交对象`，下一次提交对象的`父提交对象`\n`Index`：存储在`.git`目录，`暂存区域`，用于下一次提交\n`Working Directory`：实际的文件\n\n## Working Directory->Index->HEAD\n### v1 : touch file.txt\n`git init`后尚未有commit，此时`master指向不明确`\n```\n$ git init\n\n$ touch file.txt\n\n$ gst -sb\n## Initial commit on master\n?? file.txt\n```\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/touch_file.png\" width=\"500\">\n\n### v1 : git add\n```\n$ git add file.txt\n\n$ gst -sb\n## Initial commit on master\nA  file.txt\n```\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/git_add_v1.png\" width=\"500\">\n\n### v1 : git commit\n```\n$ git commit -m 'file.txt v1'\n[master (root-commit) a5c8857] file.txt v1\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 file.txt\n\n$ gst\nOn branch master\nnothing to commit, working directory clean\n\n$ git branch -vv\n* master a5c8857 file.txt v1\n```\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/git_commit_v1.png\" width=\"500\">\n\n### v2 : edit file.txt\n```\n$ echo 'v2' > file.txt\n\n$ gst -sb\n## master\n M file.txt\n\n$ git diff # changes between Index and working directory\ndiff --git a/file.txt b/file.txt\nIndex e69de29..8c1384d 100644\n--- a/file.txt\n+++ b/file.txt\n@@ -0,0 +1 @@\n+v2\n\n$ git diff --cacheed # changes between the Index and your last commit , same for now\n```\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/edit_file_v2.png\" width=\"500\">\n\n### v2 : git add\n```\n$ git add file.txt\n\n$ gst -sb\n## master\nM  file.txt\n```\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/git_add_v2.png\" width=\"500\">\n\n### v2 : git commit\n```\n$ git commit -m 'file.txt v2'\n[master 7806e5f] file.txt v2\n 1 file changed, 1 insertion(+)\n\n$ gst -sb\nOn branch master\nnothing to commit, working directory clean\n\n$ git branch -vv\n* master 7806e5f file.txt v2\n```\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/git_commit_v2.png\" width=\"500\">\n\n## HEAD->Index->Working Directory\n\n### git checkout\n1. checkout的**`本质是checkout提交对象`**，将`HEAD`指向分支引用，分支引用再指向该提交对象\n2. 将`HEAD`的内容填充`Index`\n3. 将`Index`的内容填充`Working Directory`\n\n### git clone\n1. 从`origin/master`建立分支`master`，将`HEAD`指向master（一般情况下）\n2. 将`HEAD`的内容填充`Index`\n3. 将`Index`的内容填充`Working Directory`\n\n# reset\n{% note info %}\n`reset`可以直接操纵`HEAD`、`Index`、`Working Directory`的状态\n{% endnote %}\n## 提交历史\n```\n$ git log --oneline --decorate --graph --all\n* 5ed53e1 (HEAD -> master) file.txt v3\n* 7806e5f file.txt v2\n* a5c8857 file.txt v1\n```\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/git_commit_v3.png\" width=\"500\">\n\n## git reset `--soft`\n`--soft`：仅移动HEAD的指向，不会改变`Index`和`Working Directory`的内容\n```\n$ git reset --soft HEAD~\n\n$ gst -sb\n## master\nM  file.txt\n\n$ git diff # Index on 5ed53e1 , Working Directory on 5ed53e1 , nothing printed\n\n$ git diff --cached # HEAD on 7806e5f , Index on 5ed53e1\ndiff --git a/file.txt b/file.txt\nindex 8c1384d..29ef827 100644\n--- a/file.txt\n+++ b/file.txt\n@@ -1 +1 @@\n-v2\n+v3\n```\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/git_reset_soft.png\" width=\"500\">\n\n## git reset `--mixed`\n`--mixed`：是reset的`默认行为`，移动HEAD的指向，改变`Index`的内容，但不会改变`Working Directory`的内容\n`reset` == `reset --mixed`\n```\n$ git branch -vv\n* master 7806e5f file.txt v2\n\n$ git reflog\n7806e5f HEAD@{0}: reset: moving to HEAD~\n5ed53e1 HEAD@{1}: commit: file.txt v3\n7806e5f HEAD@{2}: commit: file.txt v2\na5c8857 HEAD@{3}: commit (initial): file.txt v1\n\n$ git reset --hard HEAD@{1}\nHEAD is now at 5ed53e1 file.txt v3\n\n$ git reset HEAD~\nUnstaged changes after reset:\nM\tfile.txt\n\n$ git diff # Index on 7806e5f , Working Directory on 5ed53e1\ndiff --git a/file.txt b/file.txt\nindex 8c1384d..29ef827 100644\n--- a/file.txt\n+++ b/file.txt\n@@ -1 +1 @@\n-v2\n+v3\n\n$ git diff --cached # HEAD on 7806e5f , Index on 7806e5f , nothing printed\n```\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/git_reset_mixed.png\" width=\"500\">\n\n## git reset `--hard`\n{% note danger %}\n`--hard`**直接覆盖**未提交的修改，谨慎使用，可以先`stash`起来（Stash的内容请参照「Git++ - Stash」）\n{% endnote %}\n```\n$ git branch -vv\n* master 7806e5f file.txt v2\n\n$ git reflog\n7806e5f HEAD@{0}: reset: moving to HEAD~\n5ed53e1 HEAD@{1}: reset: moving to HEAD@{1}\n7806e5f HEAD@{2}: reset: moving to HEAD~\n5ed53e1 HEAD@{3}: commit: file.txt v3\n7806e5f HEAD@{4}: commit: file.txt v2\na5c8857 HEAD@{5}: commit (initial): file.txt v1\n\n$ git reset --hard HEAD@{3}\nHEAD is now at 5ed53e1 file.txt v3\n\n# git reset --hard HEAD~\nHEAD is now at 7806e5f file.txt v2\n\n$ gst\nOn branch master\nnothing to commit, working directory clean\n\n$ git diff # Index on 7806e5f , Working Directory on 7806e5f , nothing printed\n\n$ git diff --cached # HEAD on 7806e5f , Index on 7806e5f , nothing printed\n```\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/git_reset_hard.png\" width=\"500\">\n\n## git reset file\n`git reset $ref $file`：不移动HEAD，只更新`Index`\n等效于：`get reset $ref -- $file`\n```\n$ git branch -vv\n* master 7806e5f file.txt v2\n\n$ git reset --hard 5ed53e1\nHEAD is now at 5ed53e1 file.txt v3\n\n$ git reset HEAD~ file.txt # just update Index\nUnstaged changes after reset:\nM\tfile.txt\n\n$ gst -sb\n## master\nMM file.txt\n\n$ git diff # Index on 7806e5f , Working Directory on 5ed53e1\ndiff --git a/file.txt b/file.txt\nindex 8c1384d..29ef827 100644\n--- a/file.txt\n+++ b/file.txt\n@@ -1 +1 @@\n-v2\n+v3\n\n$ git diff --cached # HEAD on 5ed53e1 , Index on 7806e5f\ndiff --git a/file.txt b/file.txt\nindex 29ef827..8c1384d 100644\n--- a/file.txt\n+++ b/file.txt\n@@ -1 +1 @@\n-v3\n+v2\n```\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/git_reset_file.png\" width=\"500\">\n\n## 压缩提交\n`交互式rebase`也能压缩提交，相关内容请参照「Git++ - 重写提交历史」，如果压缩的提交数量较大，选择`reset --soft`更便捷\n```\n$ git reset --hard 5ed53e1\nHEAD is now at 5ed53e1 file.txt v3\n\n$ git reset --soft HEAD~2\n\n$ git branch -v\n* master a5c8857 file.txt v1\n\n$ gst -sb\n## master\nM  file.txt\n\n$ git diff --cached\ndiff --git a/file.txt b/file.txt\nindex e69de29..29ef827 100644\n--- a/file.txt\n+++ b/file.txt\n@@ -0,0 +1 @@\n+v3\n\n$ git commit -m 'file.txt v2+v3'\n[master 0896cad] file.txt v2+v3\n 1 file changed, 1 insertion(+)\n\n$ git log --oneline --decorate --graph --all\n* 0896cad (HEAD -> master) file.txt v2+v3\n* a5c8857 file.txt v1\n```\n<img src=\"https://git-1253868755.cos.ap-guangzhou.myqcloud.com/pro/compress_commit.png\" width=\"500\">\n\n# checkout vs reset\n\n## checkout更安全\n`checkout`会进行`冲突检查`并`尝试简单合并`，`reset --hard`直接`全面替换`\n```\n$ git branch -vv\n* branchA 3c38e92 b.txt\n  branchB 3c38e92 b.txt\n\n$ gst -sb\n## branchA\nA  a1.txt\n?? a2.txt\n\n$ git checkout branchB # a1.txt is staged , auto merge\nA\ta1.txt\nSwitched to branch 'branchB'\n\n$ gst -sb\n## branchB\nA  a1.txt\n?? a2.txt\n\n$ git checkout branchA\nA\ta1.txt\nSwitched to branch 'branchA'\n\n$ git reset --hard branchB # update HEAD , Index , Working Directory\nHEAD is now at 3c38e92 b.txt\n\n$ gst -sb # a1.txt is lost!\n## branchA\n?? a2.txt\n```\n```\n$ git log --oneline --decorate --graph --all\n* a823c74 (dev) dev\n* 50a172e (HEAD -> master) init commit\n\n$ echo 'master' > file\n\n$ git diff dev # conflict!!\ndiff --git a/file b/file\nindex 38f8e88..1f7391f 100644\n--- a/file\n+++ b/file\n@@ -1 +1 @@\n-dev\n+master\n\n$ git checkout dev # check conflict\nerror: Your local changes to the following files would be overwritten by checkout:\n\tfile\nPlease, commit your changes or stash them before you can switch branches.\nAborting\n\n$ git reset --hard dev # no conflict check\nHEAD is now at a823c74 dev\n\n$ cat file\ndev\n```\n\n## checkout不影响原先分支的指向\n`checkout`只是移动`HEAD`，并尝试修改`Index`和`Working Directory`的内容，但不会影响`原先分支的指向`\n**`reset`实际上不会移动`HEAD`的指向（`HEAD`->`分支引用`->`提交对象`，为了行文方便，上文将提`分支指向`的变动简单地归结为`HEAD`的移动），但会使得`分支指向不同的提交对象`**\n```\n$ git log --oneline --decorate --graph --all\n* 7f73c2a (HEAD -> dev) echo dev > file\n* af4c251 (master) init commit\n\n$ cat .git/HEAD\nref: refs/heads/dev\n\n$ git branch -vv\n* dev    7f73c2a echo dev > file\n  master af4c251 init commit\n\n$ git checkout master\nSwitched to branch 'master'\n\n$ cat .git/HEAD\nref: refs/heads/master\n\n$ git branch -vv\n  dev    7f73c2a echo dev > file\n* master af4c251 init commit # nothing changed\n\n-------------------------------\n$ git reset dev\nUnstaged changes after reset:\nM\tfile\n\n$ cat .git/HEAD\nref: refs/heads/master\n\n$ git branch -vv\n  dev    7f73c2a echo dev > file\n* master 7f73c2a echo dev > file # change to 7f73c2a(dev)\n```\n\n## ckeout file会更新Working Directory\n`checkout $ref $file`：不会移动`HEAD`和`分支指向`，会更新`Index`和`Working Directory`\n`reset $ref $file`：不会移动`HEAD`和`分支指向`，也不会更新`Working Directory`，只会会更新`Index`\n```\n$ git branch -vv\n  dev    6bdc578 b.txt\n* master 61779da a.txt\n\n$ git checkout dev b.txt # HEAD not changed , update Index and Working Directory\n\n$ gst -sb\n## master\nA  b.txt\n\n$ git branch -vv\n  dev    6bdc578 b.txt\n* master 61779da a.txt\n\n$ git reset --hard master\nOn branch master\nnothing to commit, working directory clean\n\n$ git reset dev b.txt # HEAD and Working Directory not changed , update Index\n\n$ git branch -vv\n  dev    6bdc578 b.txt\n* master 61779da a.txt\n\n$ gst -sb\n## master\nAD b.txt\n\n$ git diff # Index has b.txt , Working has no b.txt -> delete file\ndiff --git a/b.txt b/b.txt\ndeleted file mode 100644\nindex e69de29..0000000\n\n$ git diff --cached # HEAD has no b.txt , Index has b.txt -> new file\ndiff --git a/b.txt b/b.txt\nnew file mode 100644\nindex 0000000..e69de29\n```\n\n\n\n\n\n<!-- indicate-the-source -->\n","tags":["Git"],"categories":["Git"]},{"title":"Git -- 重写提交历史","url":"%2F2017%2F04%2F17%2Fgit-rewrite-commit%2F","content":"\n{% note danger %}\n本文将通过介绍通过`rebase`和`filter-branch`重写提交历史，但两者都会`新建`提交对象，`谨慎使用`，尤其是提交历史已共享的情况下\n{% endnote %}\n\n<!-- more -->\n\n# 交互式rebase\n`git rebase -i`，基于某个提交对象开始，通过交互的方式，依次进行rebase\nRebase的内容请参照「Git++ - 分支」\n```\n$ git log --oneline --decorate --graph --all\n* 3b1df9b (HEAD -> master) C4\n* bed6252 C3\n* 2b17907 C2\n* 4c02e18 C1\n* b71fde1 C0\n\n$ git rebase -i HEAD~3 # rebase onto (4c02e18 C1)\nreword 2b17907 C2 # edited\nreword bed6252 C3 # edited\npick 3b1df9b C4\n# Rebase 4c02e18..3b1df9b onto 4c02e18 (3 command(s))\n#\n# Commands:\n# p, pick = use commit\n# r, reword = use commit, but edit the commit message\n# e, edit = use commit, but stop for amending\n# s, squash = use commit, but meld into previous commit\n# f, fixup = like \"squash\", but discard this commit's log message\n# x, exec = run command (the rest of the line) using shell\n# d, drop = remove commit\n\n# git log --oneline --decorate --graph --all\n* b9fd388 (HEAD -> master) C4 # pick\n* 85f9b7c C3 Rebase # reword\n* e9c0fc9 C2 Rebase # reword\n* 4c02e18 C1\n* b71fde1 C0\n```\n\n# 重排序提交历史\n```\n$ git log --oneline --decorate --graph --all\n* 3b1df9b (HEAD -> master) C4\n* bed6252 C3\n* 2b17907 C2\n* 4c02e18 C1\n* b71fde1 C0\n\n$ git rebase -i HEAD~3\npick bed6252 C3 # reorder commit\npick 2b17907 C2 # reorder commit\npick 3b1df9b C4\n\n$ git log --oneline --decorate --graph --all\n* 9eaefb4 (HEAD -> master) C4\n* 6619b76 C2\n* 76da537 C3\n* 4c02e18 C1\n* b71fde1 C0\n```\n\n# 压缩提交历史\n```\n$ git log --oneline --decorate --graph --all\n* 3b1df9b (HEAD -> master) C4\n* bed6252 C3\n* 2b17907 C2\n* 4c02e18 C1\n* b71fde1 C0\n\n$ git rebase -i HEAD~3\npick 2b17907 C2\nsquash bed6252 C3 # meld into previous commit\nsquash 3b1df9b C4 # meld into previous commit\n\n$ git log --oneline --decorate --graph --all\n* 59e3d09 (HEAD -> master) C2+C3+C4\n* 4c02e18 C1\n* b71fde1 C0\n```\n\n# 拆分提交\n`git reset HEAD^`：reset `HEAD`和`index`，Reset的内容请参照「Git++ - Reset」\n```\n$ git log --oneline --decorate --graph --all\n* dbd7f9d (HEAD -> master) C4\n* c0264a4 C2+C3\n* 4c02e18 C1\n* b71fde1 C0\n\n$ git rebase -i HEAD~2\nedit c0264a4 C2+C3\npick dbd7f9d C4\n\n$ ➦ c0264a4 >R> gst # oh_my_zsh theme(agnoster) : '>R>' means interactive rebase status\ninteractive rebase in progress; onto 4c02e18\nLast command done (1 command done):\n   edit c0264a4 C2+C3\nNext command to do (1 remaining command):\n   pick dbd7f9d C4\n\n$ ➦ c0264a4 >R> git reset HEAD^ # git reset --mixed HEAD^ , reset HEAD and index\n\n$ ➦ 4c02e18 >R> gst -s\n?? C2\n?? C3\n\n$ ➦ 4c02e18 >R> git add C2 && git commit -m 'C2'\n\n$ ➦ 45fa04d >R> git add C3 && git commit -m 'C3'\n\n$ ➦ a1560a7 >R> git rebase --continue\n\n$ git log --oneline --decorate --graph --all\n* d636f99 (HEAD -> master) C4\n* a1560a7 C3\n* 45fa04d C2\n* 4c02e18 C1\n* b71fde1 C0\n```\n\n# 移除文件\n{% note danger %}\n`filter-branch`会大量`重写提交历史`，`谨慎使用`\n{% endnote %}\n`--tree-filter`：checkout当前分支（所有分支，`--all`）的每一个提交，执行命令后，重新提交，但`原始的提交历史依旧存在`\n```\n$ git log --oneline --decorate --graph --all\n* ed0bdf0 (HEAD -> master) C6\n| * 935d3f9 (dev) C5\n|/\n* 2fd6776 C4\n* 8955126 C3\n* cd003e0 C2\n* 41189ae C1\n* 6cde1e5 passwd.txt\n\n$ ls\nC1  C2  C3  C4  C6  passwd.txt\n\n$ git checkout dev && ls && git checkout master\nC1  C2  C3  C4  C5  passwd.txt\n\n$ git filter-branch --tree-filter 'rm -f passwd.txt' HEAD # --all all branches\nRewrite ed0bdf061439ea1471b3e5f89473dfa2f5b9e252 (3/6) (1 seconds passed, remaining 1 predicted)\nRef 'refs/heads/master' was rewritten\n\n$ git log --oneline --decorate --graph --all\n* 7857432 (HEAD -> master) C6\n* 4b2f01b C4\n* 0ff4616 C3\n* 62f16b3 C2\n* a2d3ffd C1\n* 6cb9305 passwd.txt\n* ed0bdf0 (refs/original/refs/heads/master) C6\n| * 935d3f9 (dev) C5\n|/\n* 2fd6776 C4\n* 8955126 C3\n* cd003e0 C2\n* 41189ae C1\n* 6cde1e5 passwd.txt\n\n$ ls\nC1  C2  C3  C4  C6\n\n$ git checkout dev && ls && git checkout master\nC1  C2  C3  C4  C5  passwd.txt\n\n$ git checkout ed0bdf0 # 'detached HEAD' state\n\n$ ➦ ed0bdf0 ls\nC1  C2  C3  C4  C6  passwd.txt\n```\n\n# 修改邮箱\n公司项目和GitHub使用的邮箱通常是不一样的，提交历史中可能会存在错误的邮箱\n```\n$ git log --pretty=format:'%h %an %ae'\n824f10e zhongmingmao zhongmingmao@yeah.net\n4ce87b1 localuser localuser@gmail.com\nff7fea3 zhongmingmao zhongmingmao@yeah.net\n\n$ git filter-branch --commit-filter '\n        if [ \"$GIT_AUTHOR_NAME\" = \"localuser\" ];\n        then\n                GIT_AUTHOR_NAME=zhongmingmao;\n                GIT_AUTHOR_EMAIL=zhongmingmao@yeah.net;\n                git commit-tree \"$@\";\n        else\n                git commit-tree \"$@\";\n        fi' HEAD\nRewrite 824f10e80dac8f1c4854671de6aba2e703b74d29 (3/3) (0 seconds passed, remaining 0 predicted)\nRef 'refs/heads/master' was rewritten\n\n$ git log --pretty=format:'%h %an %ae'\n314d84f zhongmingmao zhongmingmao@yeah.net\n750e781 zhongmingmao zhongmingmao@yeah.net\nff7fea3 zhongmingmao zhongmingmao@yeah.net\n```\n\n<!-- indicate-the-source -->\n","tags":["Git"],"categories":["Git"]},{"title":"Git -- Stash","url":"%2F2017%2F04%2F16%2Fgit-stash%2F","content":"\n{% note info %}\n本文主要介绍`stash`操作，常用于储藏`未完成的工作`，以免将`脏状态`保存为一个提交\n{% endnote %}\n\n<!-- more -->\n\n# git stash\n`git stash`：储藏`working directory`和`index`的当前状态（不包括`untracked`文件）\n`git stash apply`：仅应用`working directory`的修改，不应用`index`的修改\n`git stash list`：stash列表\n`git stash drop`：删除stash\n```\n$ gst -sb\n## master\nM  a.txt\n M b.txt\n\n$ git stash list # Stdout print nothing\n\n$ git stash # save working directory and index state\nSaved working directory and index state WIP on master: 2e5960b add a.txt b.txt\nHEAD is now at 2e5960b add a.txt b.txt\n\n$ gst\nOn branch master\nnothing to commit, working directory clean\n\n$ git checkout -b dev\n\n$ git stash list\nstash@{0}: WIP on master: 2e5960b add a.txt b.txt\n\n$ git stash apply # default apply stash@{0}\n\n$ gst -sb # only apply working directory\n## dev\n M a.txt\n M b.txt\n\n$ git stash drop stash@{0}\nDropped stash@{0} (8ec72e0160fd187bcc90ddcc7066b9b6c22f350c)\n\n$ git stash list # Stdout print nothing\n\n```\n\n# git stash apply `--index`\n`git stash apply --index`：应用`working directory`和`index`的修改\n```\n$ gst -sb\n## dev\nM  a.txt\n M b.txt\n\n$ git stash\nSaved working directory and index state WIP on dev: 2e5960b add a.txt b.txt\nHEAD is now at 2e5960b add a.txt b.txt\n\n$ gst\nOn branch dev\nnothing to commit, working directory clean\n\n$ git stash apply --index # apply working directory and index\n\n$ gst -sb\n## dev\nM  a.txt\n M b.txt\n```\n\n# git stash `--keep-index`\n`git stash --keep-index`：仅储藏`working directory`的修改，不储藏`index`的修改\n```\n$ gst -sb\n## dev\nM  a.txt\n M b.txt\n\n$ git stash --keep-index\nSaved working directory and index state WIP on dev: 2e5960b add a.txt b.txt\nHEAD is now at 2e5960b add a.txt b.txt\n\n$ gst -sb\n## dev\nM  a.txt\n\n$ git stash apply\n\n$ gst -sb\n## dev\nM  a.txt\n M b.txt\n```\n\n# git stash -u\n`git stash -u`：储藏`untracked`文件\n```\n$ gst -sb\n## dev\nM  a.txt\n M b.txt\n?? c.txt\n\n$ git stash\nSaved working directory and index state WIP on dev: 2e5960b add a.txt b.txt\nHEAD is now at 2e5960b add a.txt b.txt\n\n$ gst -sb\n## dev\n?? c.txt\n\n$ git stash apply\n\n$ gst -sb\n## dev\n M a.txt\n M b.txt\n?? c.txt\n\n$ git stash -u\nSaved working directory and index state WIP on dev: 2e5960b add a.txt b.txt\nHEAD is now at 2e5960b add a.txt b.txt\n\n$ gst\nOn branch dev\nnothing to commit, working directory clean\n```\n<!-- indicate-the-source -->\n","tags":["Git"],"categories":["Git"]},{"title":"Git -- 引用和提交区间","url":"%2F2017%2F04%2F15%2Fgit-ref%2F","content":"\n{% note info %}\n本文主要介绍`常见的引用`（commit对象及其祖先的的引用，branch引用，HEAD引用等）和`提交区间`\n`commit对象`，`tag对象`的内容请参照「Git++ - 对象」\n{% endnote %}\n\n<!-- more -->\n\n# 引用\n\n## commit对象引用\n\n`git show`：显示Git对象信息\n```\n$ git log --oneline --decorate --graph --all\n* 4f6c14f (HEAD -> master) add README.md\n\n$ git show --oneline -s 4f6c14f\n4f6c14f add README.md\n\n$ git show --oneline -s HEAD\n4f6c14f add README.md\n\n$ git show --oneline -s master\n4f6c14f add README.md\n```\n\n## commit对象祖先的引用\n{% note info %}\n在`Fast Forward Merge`中，`只有一个`父提交对象，`第一父提交对象`\n在`Recursive Merge`中，合并操作发生时的当前分支所指向的提交对象是`第一父提交对象`，被合并的分支所指向的提交对象是`第二父提交对象`\n{% endnote %}\n`HEAD^`：HEAD的第一父提交对象\n`HEAD^1`：HEAD的第一父提交对象\n`HEAD^2`：HEAD的第二父提交对象\n`HEAD^^`：HEAD的第一父提交对象的第一父提交对象\n`HEAD~`：HEAD的第一父提交对象\n`HEAD~2`：HEAD的第一父提交对象的第一父提交对象\n`HEAD^2~2`：HEAD的第二父提交对象的第一父提交对象的第一父提交对象（你懂的）\n```\n$ git log --oneline --decorate --graph --all\n*   85a939e (HEAD -> master) M1\n|\\\n| * 187060b (dev) C3\n| * 451ee07 C2\n* | a13db3c C5\n* | ab4285a C4\n|/\n* 4f543bb C1\n* f9d0737 C0\n\n$ git show --oneline -s HEAD^\na13db3c C5\n\n$ git show --oneline -s HEAD^1\na13db3c C5\n\n$ git show --oneline -s HEAD^2\n187060b C3\n\n$ git show --oneline -s HEAD^^\nab4285a C4\n\n$ git show --oneline -s HEAD~\na13db3c C5\n\n$ git show --oneline -s HEAD~2\nab4285a C4\n\n$ git show --oneline -s HEAD^2~2\n4f543bb C1\n```\n\n## branch引用\n`update-ref`：更新`引用`\n```\n$ git log --oneline --decorate --graph --all\n* 5a08236 (HEAD -> master) C5\n* c532bf8 C4\n| * c8910d8 (dev) C3\n| * 0a95c28 C2\n|/\n* 8ce5c36 C1\n* 0b2693b C0\n\n$ git update-ref refs/heads/master HEAD~ # update master(5a08236->c532bf8)\n\n$ git log --oneline --decorate --graph --all\n* c532bf8 (HEAD -> master) C4\n| * c8910d8 (dev) C3\n| * 0a95c28 C2\n|/\n* 8ce5c36 C1\n* 0b2693b C0\n\n$ cat .git/refs/heads/master\nc532bf878fe12373239698279c8ec797d51235ad\n\n$ git update-ref refs/heads/test dev # create a new branch test on dev(c8910d8)\n\n$ git log --oneline --decorate --graph --all\n* c532bf8 (HEAD -> master) C4\n| * c8910d8 (test, dev) C3\n| * 0a95c28 C2\n|/\n* 8ce5c36 C1\n* 0b2693b C0\n\n$ cat .git/refs/heads/dev\nc8910d8b249e4530edfe7c4fc410078da66a187d\n\n$ cat .git/refs/heads/test\nc8910d8b249e4530edfe7c4fc410078da66a187d\n```\n\n## HEAD引用\n`symbolic-ref`：读取、修改或删除`symbolic引用`（`符号引用`）\n```\n$ git log --oneline --decorate --graph --all\n* 5a08236 (HEAD -> master) C5\n* c532bf8 C4\n| * c8910d8 (test, dev) C3\n| * 0a95c28 C2\n|/\n* 8ce5c36 C1\n* 0b2693b C0\n\n$ git symbolic-ref HEA\nrefs/heads/master\n\n$ cat .git/HEAD\nref: refs/heads/master\n\n$ git symbolic-ref HEAD refs/heads/dev # switch to branch dev\n\n$ cat .git/HEAD\nref: refs/heads/dev\n\n$ git log --oneline --decorate --graph --all\n* 5a08236 (master) C5\n* c532bf8 C4\n| * c8910d8 (HEAD -> dev, test) C3\n| * 0a95c28 C2\n|/\n* 8ce5c36 C1\n* 0b2693b C0\n```\n\n## HEAD引用历史\n{% note warning %}\n`git reflog`只存在于本地仓库，记录本地仓库的操作历史\n{% endnote %}\n`reflog`记录`HEAD`的引用历史，常用于本地`reset --hard`（Reset的内容请参照「Git++ - Reset」）后的回滚操作\n```\n$ git log --oneline --graph --decorate --all\n* a13db3c (HEAD -> master) C5\n* ab4285a C4\n| * 187060b (dev) C3\n| * 451ee07 C2\n|/\n* 4f543bb C1\n* f9d0737 C0\n\n$ git reset --hard HEAD^\nHEAD is now at ab4285a C4\n\n$ git log --oneline --graph --decorate --all\n* ab4285a (HEAD -> master) C4 # can not find C5\n| * 187060b (dev) C3\n| * 451ee07 C2\n|/\n* 4f543bb C1\n* f9d0737 C0\n\n$ git reflog # git log -g --oneline\nab4285a HEAD@{0}: reset: moving to HEAD^\na13db3c HEAD@{1}: reset: moving to HEAD^\n85a939e HEAD@{2}: merge dev: Merge made by the 'recursive' strategy.\na13db3c HEAD@{3}: reset: moving to HEAD@{1}\nab4285a HEAD@{4}: reset: moving to HEAD^\na13db3c HEAD@{5}: commit: C5\nab4285a HEAD@{6}: commit: C4\n4f543bb HEAD@{7}: checkout: moving from dev to master\n187060b HEAD@{8}: commit: C3\n451ee07 HEAD@{9}: commit: C2\n4f543bb HEAD@{10}: checkout: moving from master to dev\n4f543bb HEAD@{11}: commit: C1\nf9d0737 HEAD@{12}: commit (initial): C0\n\n$ git show --oneline -s HEAD@{5}\na13db3c C5\n\n$ git reset --hard HEAD@{5}\nHEAD is now at a13db3c C5\n\n$ git log --oneline --graph --decorate --all\n* a13db3c (HEAD -> master) C5\n* ab4285a C4\n| * 187060b (dev) C3\n| * 451ee07 C2\n|/\n* 4f543bb C1\n* f9d0737 C0\n```\n\n## tag引用\n\n### lightweight tag引用\n```\n$ git log --oneline --decorate --graph --all\n* 5a08236 (HEAD -> master) C5\n* c532bf8 C4\n| * c8910d8 (test, dev) C3\n| * 0a95c28 C2\n|/\n* 8ce5c36 C1\n* 0b2693b C0\n\n$ git update-ref refs/tags/v1.0 HEAD~ # create lightweight tag\n\n$ git log --oneline --decorate --graph --all\n* 5a08236 (HEAD -> master) C5\n* c532bf8 (tag: v1.0) C4\n| * c8910d8 (test, dev) C3\n| * 0a95c28 C2\n|/\n* 8ce5c36 C1\n* 0b2693b C0\n\n$ cat .git/refs/tags/v1.0 # point to a commit object directly\nc532bf878fe12373239698279c8ec797d51235ad\n\n$ git cat-file -t c532bf878fe12373239698279c8ec797d51235ad\ncommit\n```\n### annotated tag引用\n```\n$ git log --oneline --decorate --graph --all\n* 5a08236 (HEAD -> master) C5\n* c532bf8 (tag: v1.0) C4\n| * c8910d8 (test, dev) C3\n| * 0a95c28 C2\n|/\n* 8ce5c36 C1\n* 0b2693b C0\n\n$ git tag -a v2.0 -m 'tag v2.0' # ceeate annotated tag\n\n$ git log --oneline --decorate --graph --all\n* 5a08236 (HEAD -> master, tag: v2.0) C5\n* c532bf8 (tag: v1.0) C4\n| * c8910d8 (test, dev) C3\n| * 0a95c28 C2\n|/\n* 8ce5c36 C1\n* 0b2693b C0\n\n$ cat .git/refs/tags/v2.0 # point to a tag object\n9c335494f9fb322d93add8c274f0ef1a632920ea\n\n$ git cat-file -t 9c335494f9fb322d93add8c274f0ef1a632920ea\ntag\n\n$ git cat-file -p 9c335494f9fb322d93add8c274f0ef1a632920ea\nobject 5a0823659a16f3e6aa7caa0a6fc1ee3bebf4112c\ntype commit\ntag v2.0\ntagger zhongmingmao <zhongmingmao@yeah.net> 1492609041 +0800\ntag v2.0\n\n$ git cat-file -t 5a0823659a16f3e6aa7caa0a6fc1ee3bebf4112c # point to a commit object\ncommit\n```\n\n## remote引用\n`remote引用`在本地仓库是只读的，`git commit`不会更新`remote引用`，更新发生在`git fetch`和`git pull`执行时\n```\n$ git remote add hzmajia https://github.com/hzmajia/hzmajia.github.io\n\n$ git remote -v\nhzmajia\thttps://github.com/hzmajia/hzmajia.github.io (fetch)\nhzmajia\thttps://github.com/hzmajia/hzmajia.github.io (push)\n\n$ git fetch hzmajia\nwarning: no common commits\nremote: Counting objects: 145, done.\nremote: Compressing objects: 100% (119/119), done.\nremote: Total 145 (delta 15), reused 140 (delta 10), pack-reused 0\nReceiving objects: 100% (145/145), 531.53 KiB | 496.00 KiB/s, done.\nResolving deltas: 100% (15/15), done.\nFrom https://github.com/hzmajia/hzmajia.github.io\n * [new branch]      blog_source -> hzmajia/blog_source\n * [new branch]      master     -> hzmajia/master\n\n$ git checkout -b hzmajia_master hzmajia/master\nBranch hzmajia_master set up to track remote branch master from hzmajia.\nSwitched to a new branch 'hzmajia_master'\n\n$ cat .git/refs/remotes/hzmajia/master\nbce4632694ed70ae303ea2433930afa910f8e800\n\n$ cat .git/refs/heads/hzmajia_master\nbce4632694ed70ae303ea2433930afa910f8e800\n\n$ git log --oneline --decorate --graph hzmajia_master\n* bce4632 (HEAD -> hzmajia_master, hzmajia/master) Update docs\n\n$ cn=C0 && touch $cn && git add . && git commit -m $cn\n[hzmajia_master b6b0e1e] C0\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 C0\n\n$ cat .git/refs/remotes/hzmajia/master # change nothing\nbce4632694ed70ae303ea2433930afa910f8e800\n\n$ cat .git/refs/heads/hzmajia_master\nb6b0e1e7df4cd830cc399bc201911b632460f7b3\n\n$ git log --oneline --decorate --graph hzmajia_master\n* b6b0e1e (HEAD -> hzmajia_master) C0\n* bce4632 (hzmajia/master) Update docs\n```\n\n### remote引用规格\n1. `fetch = +<src>:<dst>`\n    - `+`在不能`Fast-Forward Merge`的情况下也强制更新引用\n    - `<src>`：`远程版本库中`的引用\n    - `<dst>`：`远程引用在本地所对应的位置`\n2. `push = +<src>:<dst>`\n    - `+`在不能`Fast-Forward Merge`的情况下也强制更新引用\n    - `<src>`：`本地版本库中`的引用\n    - `<dst>`：`远程版本库中`的引用\n\n```\n$ git init\nInitialized empty Git repository in /home/zhongmingmao/demo/.git/\n\n$ git remote add remote_ref https://github.com/hzmajia/remote_ref.git\n\n$ git remote -v\nremote_ref\thttps://github.com/hzmajia/remote_ref.git (fetch)\nremote_ref\thttps://github.com/hzmajia/remote_ref.git (push)\n\n$ cat .git/config\n[core]\n\trepositoryformatversion = 0\n\tfilemode = true\n\tbare = false\n\tlogallrefupdates = true\n[remote \"remote_ref\"]\n\turl = https://github.com/hzmajia/remote_ref.git\n\tfetch = +refs/heads/*:refs/remotes/remote_ref/*\n```\n\n# 提交区间\n\n## 双点..（最常用）\n`branchA..branchB`：在branchB中但不在branchA中提交历史\n等效于：`^branchA branchB`或`branchB --not branchA`\n\n```\n$ git log --oneline --graph --decorate --all\n* a13db3c (HEAD -> master) C5\n* ab4285a C4\n| * 187060b (dev) C3\n| * 451ee07 C2\n|/\n* 4f543bb C1\n* f9d0737 C0\n\n$ git log --oneline --decorate master..dev\n187060b (dev) C3\n451ee07 C2\n\n$ git log --oneline --decorate ^master dev\n187060b (dev) C3\n451ee07 C2\n\n$ git log --oneline --decorate dev --not master\n187060b (dev) C3\n451ee07 C2\n\n$ git log --oneline --decorate dev..master\na13db3c (HEAD -> master) C5\nab4285a C4\n```\n\n## 三点...\n`branchA...branchB`：branchA的branchB提交历史的`差集`\n```\n$ git log --oneline --graph --decorate --all\n* a13db3c (HEAD -> master) C5\n* ab4285a C4\n| * 187060b (dev) C3\n| * 451ee07 C2\n|/\n* 4f543bb C1\n* f9d0737 C0\n\n$ git log --oneline --decorate --left-right master...dev\n> a13db3c (HEAD -> master) C5\n> ab4285a C4\n< 187060b (dev) C3\n< 451ee07 C2\n\n$ git log --oneline --decorate --left-right dev...master\n> a13db3c (HEAD -> master) C5\n> ab4285a C4\n< 187060b (dev) C3\n< 451ee07 C2\n```\n\n<!-- indicate-the-source -->\n","tags":["Git"],"categories":["Git"]},{"title":"Git -- 分支","url":"%2F2017%2F04%2F15%2Fgit-branch%2F","content":"\n{% note info %} 本文主要介绍一些我在日常开发中与`Git分支`相关的一些操作，通过实例阐述一些基本分支概念\n{% endnote %}\n\n<!-- more -->\n# 分支的本质\n\nGit分支的本质仅仅只是指向`Commit对象`的`可变指针`\n\n{% note info %} master分支并非一个特殊分支\n{% endnote %}\n\n# Merge\n\n## Fast-Forward Merge\n当前分支（`HEAD`）指向的`Commit对象`是`待被合并分支`所指向`Commit对象`的**`上游`**，只需要简单地`向前移动HEAD指针`\n```\n$ git log --oneline --decorate --graph --all\n* c4292f7 (hotfix) C4\n| * bebf901 (dev) C3\n|/\n* b17415c (HEAD -> master) C2\n* 425fa18 C1\n* 1f62295 C0\n\n$ git merge hotfix\nUpdating b17415c..c4292f7\nFast-forward\n C4 | 0\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 C4\n\n$ git log --oneline --decorate --graph --all\n* c4292f7 (HEAD -> master, hotfix) C4 # Master just move forward to hotfix\n| * bebf901 (dev) C3\n|/\n* b17415c C2\n* 425fa18 C1\n* 1f62295 C0\n```\n\n## Recursive Merge\n`非上游`时，寻找`最近共同祖先`，做`三方合并`，新建一个`Commit对象`\n```\n$ git log --oneline --decorate --graph --all\n* be69c83 (dev) C5\n* bebf901 C3\n| * c4292f7 (HEAD -> master) C4 # Merge dev , can not be fast forward\n|/\n* b17415c C2\n* 425fa18 C1\n* 1f62295 C0\n\n$ git merge dev  -m 'M1'\nMerge made by the 'recursive' strategy. # Recursive merge , create new commit object M1\n C3 | 0\n C5 | 0\n 2 files changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 C3\n create mode 100644 C5\n\n$ git log --oneline --decorate --graph --all\n*   3226137 (HEAD -> master) M1\n|\\\n| * be69c83 (dev) C5\n| * bebf901 C3\n* | c4292f7 C4\n|/\n* b17415c C2\n* 425fa18 C1\n* 1f62295 C0\n```\n\n# Remote Branch\n{% note info %} `origin`与`master`一样，并`无特殊含义`，仅仅是Git的默认名称\n{% endnote %}\n\n## origin\n`origin`：`Remote Repository`的引用\n`origin/master`：`Remote Branch`的引用\n`master`：`Local Branch`的引用\n```\n$ git clone https://github.com/hzmajia/demo.git\nCloning into 'demo'...\nremote: Counting objects: 3, done.\nremote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0\nUnpacking objects: 100% (3/3), done.\nChecking connectivity... done.\n\n$ gst\nOn branch master\nYour branch is up-to-date with 'origin/master'. # master auto track origin/master\nnothing to commit, working directory clean\n\n$ git log --decorate --graph --oneline\n* 7118626 (HEAD -> master, origin/master, origin/HEAD) Add README.md\n\n$ cn=C1 && touch $cn && git add . && git commit -m $cn # master move forward\n[master 0b2eae6] C1\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 C1\n\n$ gst\nOn branch master\nYour branch is ahead of 'origin/master' by 1 commit. # master track origin/master\n  (use \"git push\" to publish your local commits)\nnothing to commit, working directory clean\n\n$ git log --decorate --graph --oneline\n* 0b2eae6 (HEAD -> master) C1\n* 7118626 (origin/master, origin/HEAD) Add README.md\n```\n\n## git fetch\n{% note info %} git fetch仅仅抓取Remote Repository的数据到本地数据库(包括移动相关指针），但并`不会自动合并`数据\n{% endnote %}\n```\n$ git remote -v # Show remote repository\nrepA\thttps://github.com/hzmajia/repA.git (fetch)\nrepA\thttps://github.com/hzmajia/repA.git (push)\nrepB\thttps://github.com/hzmajia/repB.git (fetch)\nrepB\thttps://github.com/hzmajia/repB.git (push)\n\n$ git log --decorate --graph --oneline\n* 4f8de53 (HEAD -> master, repB/master, repA/master) C1 # All up-to-date By Now\n* 51ce03d C0\n\n$ git fetch repA\nremote: Counting objects: 2, done.\nremote: Compressing objects: 100% (2/2), done.\nremote: Total 2 (delta 0), reused 2 (delta 0), pack-reused 0\nUnpacking objects: 100% (2/2), done.\nFrom https://github.com/hzmajia/repA\n   4f8de53..262e1d5  master     -> repA/master\n\n$ git log --decorate --graph --oneline --all\n* 262e1d5 (repA/master) C3 # Move forward , repA/master , local read only\n* 4f8de53 (HEAD -> master, repB/master) C1\n* 51ce03d C0\n\n$ git fetch repB\nremote: Counting objects: 2, done.\nremote: Compressing objects: 100% (2/2), done.\nremote: Total 2 (delta 0), reused 2 (delta 0), pack-reused 0\nUnpacking objects: 100% (2/2), done.\nFrom https://github.com/hzmajia/repB\n   4f8de53..54824f8  master     -> repB/master\n\n$ git log --decorate --graph --oneline --all\n* 54824f8 (repB/master) C4 # Move forward , repB/master , local read only\n| * 262e1d5 (repA/master) C3\n|/\n* 4f8de53 (HEAD -> master) C1\n* 51ce03d C0\n```\n\n## track remote branch\n{% note info %} 本地分支可以跟踪远程分支，被跟踪的远程分支是本地分支的上游分支（`upstream branch`）\n{% endnote %}\n\n### git clone\nmaster自动跟踪repo_name/master\n```\n$ git clone https://github.com/hzmajia/repA.git\nCloning into 'repA'...\nremote: Counting objects: 7, done.\nremote: Compressing objects: 100% (5/5), done.\nremote: Total 7 (delta 1), reused 6 (delta 0), pack-reused 0\nUnpacking objects: 100% (7/7), done.\nChecking connectivity... done.\n\n$ git branch -vv # Show upstream branch\n* master 262e1d5 [origin/master] C3\n```\n\n### git checkout\n`-b`：从远程分支创建新分支，`分支名自定义`，并跟踪该远程分支\n`--track`：从远程分支创建新分支，`分支名与远程分支一致`，并跟踪该远程分支\n```\n$ git remote -v\norigin\thttps://github.com/hzmajia/repA.git (fetch)\norigin\thttps://github.com/hzmajia/repA.git (push)\n\n$ git checkout -b branchA origin/master # branchA track origin/master\nBranch branchA set up to track remote branch master from origin.\nSwitched to a new branch 'branchA'\n\n$ git branch -vv\n* branchA 262e1d5 [origin/master] C3\n  master  262e1d5 [origin/master] C3\n\n$ git checkout --track origin/dev # dev track origin/dev\nBranch dev set up to track remote branch dev from origin.\nSwitched to a new branch 'dev'\n\n$ git branch -vv\n  branchA 262e1d5 [origin/master] C3\n* dev     262e1d5 [origin/dev] C3\n  master  262e1d5 [origin/master] C3\n```\n\n### git brach -u\n`-u`：修改当前分支的跟踪分支（上游分支）\n```\n$ gst\nOn branch dev\nYour branch is up-to-date with 'origin/dev'.\nnothing to commit, working directory clean\n\n$ git branch -vv\n  branchA 262e1d5 [origin/master] C3\n* dev     262e1d5 [origin/dev] C3\n  master  262e1d5 [origin/master] C3\n\n$ git branch -u origin/master # update upstream branch\nBranch dev set up to track remote branch master from origin.\n\n$ git branch -vv\n  branchA 262e1d5 [origin/master] C3\n* dev     262e1d5 [origin/master] C3\n  master  262e1d5 [origin/master] C3\n```\n\n## git pull\n{% note warning %} 查找当前分支的上游分支，从远程仓库`拉取数据并尝试合并`，推荐使用**`git fetch`+`git merge`**\n{% endnote %}\n```\n$ git branch -vv\n* master 7e00be3 [origin/master] C6\n\n$ git branch test\n\n$ git branch -vv\n* master 7e00be3 [origin/master] C6\n  test   7e00be3 C6\n\n$ git remote -v\norigin\thttps://github.com/hzmajia/repA.git (fetch)\norigin\thttps://github.com/hzmajia/repA.git (push)\n\n$ git log --oneline --graph --decorate --all\n* 7e00be3 (HEAD -> master, origin/master, origin/HEAD, test) C6\n* 8a1ed87 C5\n* 262e1d5 (origin/dev) C3\n* 4f8de53 C1\n* 51ce03d C0\n\n$ git pull\nremote: Counting objects: 2, done. # Fetch data\nremote: Compressing objects: 100% (1/1), done.\nremote: Total 2 (delta 1), reused 2 (delta 1), pack-reused 0\nUnpacking objects: 100% (2/2), done.\nFrom https://github.com/hzmajia/repA\n   7e00be3..ae121e2  master     -> origin/master\nUpdating 7e00be3..ae121e2 # Master auto merge origin/master , test do nothing\nFast-forward\n C7 | 0\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 C7\n\n$ git log --oneline --graph --decorate --all\n* ae121e2 (HEAD -> master, origin/master, origin/HEAD) C7\n* 7e00be3 (test) C6\n* 8a1ed87 C5\n* 262e1d5 (origin/dev) C3\n* 4f8de53 C1\n* 51ce03d C0\n```\n\n# Rebase\n{% note danger %} `谨慎使用`，适用于尚未push的Commit，rebase`会丢弃现有Commit`，新建Commit，从而使得提交历史更加整洁，我在实际开发中比较少使用，真实记录开发中的提交历史\n{% endnote %}\n\n## 原理\n`A rebase B`：寻找两者的`最近共同祖先C`，将C到A的一系列Commit按次序应用到B上，生成一系列新的Commit，`对应的Commit Message不变`\n```\n$ git log --oneline --graph --decorate --all\n* 360950a (HEAD -> master) C6\n* 7567dc8 C5\n| * 7dd1dde (dev) C4\n| * 72fec7e C3\n|/\n* b77035b C2\n* 8e4fa74 C1\n* e43aa3d C0\n\n$ git rebase dev # create new commit objects 8e15506 0ed259f\nFirst, rewinding head to replay your work on top of it...\nApplying: C5\nApplying: C6\n\n$ git log --oneline --graph --decorate --all\n* 0ed259f (HEAD -> master) C6 # 360950a...0ed259f\n* 8e15506 C5 # 7567dc8...8e15506\n* 7dd1dde (dev) C4\n* 72fec7e C3\n* b77035b C2\n* 8e4fa74 C1\n* e43aa3d C0\n```\n\n## 错误样例\n{% note danger %} 下例中因为对`已push的Commit`进行rebase，产生了两个C4，令人很疑惑。这是因为rebase默认生成新的Commit，但Commit Message是一致的\n{% endnote %}\n```\n$ git log --oneline --graph --decorate --all\n*   b91c74e (HEAD -> master) C6\n|\\\n| * 35cc8be (dev) C5\n* | e196df0 C4\n|/\n* 0e127f0 (origin/master) C1\n\n$ git push origin master\nCounting objects: 6, done.\nCompressing objects: 100% (6/6), done.\nWriting objects: 100% (6/6), 545 bytes | 0 bytes/s, done.\nTotal 6 (delta 2), reused 0 (delta 0)\nremote: Resolving deltas: 100% (2/2), done.\nTo https://github.com/hzmajia/demo.git\n   0e127f0..b91c74e  master -> master\n\n$ git log --oneline --graph --decorate --all\n*   b91c74e (HEAD -> master, origin/master) C6\n|\\\n| * 35cc8be (dev) C5\n* | e196df0 C4\n|/\n* 0e127f0 C1\n\n$ git reset --hard HEAD^\nHEAD is now at e196df0 C4\n\n$ git log --oneline --graph --decorate --all\n*   b91c74e (origin/master) C6\n|\\\n| * 35cc8be (dev) C5\n* | e196df0 (HEAD -> master) C4\n|/\n* 0e127f0 C1\n\n$ git rebase dev # rebase pushed commit , generate 2 C4 in log !!!\nFirst, rewinding head to replay your work on top of it...\nApplying: C4\n\n$ git log --oneline --graph --decorate --all\n* 4a785d4 (HEAD -> master) C4\n| *   b91c74e (origin/master) C6\n| |\\\n| |/\n|/|\n* | 35cc8be (dev) C5\n| * e196df0 C4\n|/\n* 0e127f0 C1\n\n\n$ git pull\nMerge made by the 'recursive' strategy.\n\n$ git log --oneline --graph --decorate --all\n*   a6637b9 (HEAD -> master) Merge branch 'master' of https://github.com/hzmajia/demo\n|\\\n| *   b91c74e (origin/master) C6\n| |\\\n| * | e196df0 C4\n* | | 4a785d4 C4\n| |/\n|/|\n* | 35cc8be (dev) C5\n|/\n* 0e127f0 C1\n```\n\n<!-- indicate-the-source -->\n","tags":["Git"],"categories":["Git"]},{"title":"Git -- 有趣的命令","url":"%2F2017%2F04%2F14%2Fgit-basic%2F","content":"\n{% note info %} 本文主要介绍一些我在日常开发中觉得比较有趣的Git`基础命令`\n{% endnote %}\n\n<!-- more -->\n\n# 差异对比\n日常开发中，差异对比是执行比较频繁的命令\n`HEAD`一般指向当前分支的最后一次`Commit`，下面三种是我最常用的差异对比\n\n## git diff\n尚未暂存的`Working Tree`与`HEAD`的差异\n\n## git diff --cached\n`Index`与`HEAD`的差异\n注 ： 别名`git diff --staged`\n\n## git diff HEAD\n尚未暂存的`Working Tree` + `Index`与`HEAD`的差异\n\n## 操作实例\n```\n$ gst -sb\n## master\n\n$ ls\nREADME.md\n\n$ echo 'Hello' >> README.md\n\n$ gst -sb\n## master\n M README.md\n\n$ git diff\ndiff --git a/README.md b/README.md\nindex e69de29..e965047 100644\n--- a/README.md\n+++ b/README.md\n@@ -0,0 +1 @@\n+Hello\n\n$ git diff --cached # Stdout print nothing\n\n$ git diff HEAD\ndiff --git a/README.md b/README.md\nindex e69de29..e965047 100644\n--- a/README.md\n+++ b/README.md\n@@ -0,0 +1 @@\n+Hello\n\n-------------------\n$ git add README.md\n-------------------\n\n$ gst -sb\n## master\nM  README.md\n\n$ git diff # Stdout print nothing\n\n$ git diff --cached\ndiff --git a/README.md b/README.md\nindex e69de29..e965047 100644\n--- a/README.md\n+++ b/README.md\n@@ -0,0 +1 @@\n+Hello\n\n$ git diff HEAD\ndiff --git a/README.md b/README.md\nindex e69de29..e965047 100644\n--- a/README.md\n+++ b/README.md\n@@ -0,0 +1 @@\n+Hello\n```\n\n# 移除版本控制\n{% note warning %} `git rm`只会将文件或目录从版本控制中移除，但并不会从以前的提交记录中移除文件或目录\n{% endnote %}\n\n## git rm\n从`Working Tree`和`Index`中移除\n必须进行`up-to-date`检查，如果文件或目录在`Working Tree`或`Index`中的状态与`HEAD`不一致，则执行失败\n```\n$ gst -sb\n## master\n\n$ ls\nREADME.md\n\n$ git rm README.md\nrm 'README.md'\n\n$ gst -sb\n## master\nD  README.md\n\n$ ls # Stdout print nothing\n\n-------------------------------------------------\n$ git reset --hard HEAD # Reset HEAD , danger ops\nHEAD is now at 03e27f0 init commit\n-------------------------------------------------\n\n$ echo 'Hello' > README.md\n\n$ gst -sb\n## master\n M README.md\n\n$ git rm README.md\nerror: the following file has local modifications:\n    README.md\n(use --cached to keep the file, or -f to force removal)\n\n$ git add README.md\n\n$ gst -sb\n## master\nM  README.md\n\n$ git rm README.md\nerror: the following file has local modifications:\n    README.md\n(use --cached to keep the file, or -f to force removal)\n\n```\n\n\n## git rm -f\n`强制`从`Working Tree`和`Index`中移除，不进行`up-to-date`检查\n```\n$ gst -sb\n## master\n\n$ ls\nREADME.md\n\n$ echo 'Hello' > README.md\n\n$ git add README.md\n\n$ gst -sb\n## master\nM  README.md\n\n$ git rm -f README.md\nrm 'README.md'\n\n$ gst -sb\n## master\nD  README.md\n\n$ ls # Stdout print nothing\n```\n\n## git rm --cached\n只从`Index`中移除，保留`Working Tree`中的文件状态\n```\n$ gst -sb\n## master\n\n$ ls\nREADME.md\n\n$ echo 'Hello' > README.md\n\n$ git add README.md\n\n$ gst -sb\n## master\nM  README.md\n\n$ git rm --cached README.md\nrm 'README.md'\n\n$ gst -sb # README从Index删除，但保留在Working Tree中\n## master\nD  README.md\n?? README.md\n\n$ cat README.md\nHello\n```\n\n# 重命名\n```\n$ gst\nOn branch master\nnothing to commit, working tree clean\n\n$ ls\nREADME.md  src\n\n$ find README.md src\nREADME.md\nsrc\nsrc/Hello.java\nsrc/World.java\n\n$ git mv README.md README.md.bak\n\n$ git mv src src.bak\n\n$ git -sb\n## master\nR  README.md -> README.md.bak\nR  src/Hello.java -> src.bak/Hello.java\nR  src/World.java -> src.bak/World.java\n```\n\n# 查看提交历史\n\n## 常规查看（最常用）\n`--graph`：图形化显示分支提交历史\n`--oneline`：一个提交显示一行\n`--decorate`：显示分支引用\n```\n$ git log --graph --oneline --decorate\n* 807adc2 (HEAD -> master) C8\n* 537a716 C7\n*   a272a81 M1\n|\\\n| * c94d37d (topic) C4\n| * 25737e7 C3\n* | 78dd014 C6\n* | 92ad9ff C5\n|/\n* c110877 C2\n* 3847d71 C1\n```\n\n## 格式化显示\n`%h`：Commit对象的简短哈希串\n`%t`：Tree对象的简短哈希串\n`%p`：父Commit对象的简短哈希串\n`%an`：作者名字\n`%ae`：作者邮件\n`%ad`：修订日期\n`%s`：Commit Message\n```\n$ git log --pretty=format:\"%h %t %p %an %s\" --graph\n* 807adc2 bf5ac3a 537a716 zhongmingmao C8\n* 537a716 f2e0d63 a272a81 zhongmingmao C7\n*   a272a81 525cbc2 78dd014 c94d37d zhongmingmao M1\n|\\\n| * c94d37d 99248a5 25737e7 zhongmingmao C4\n| * 25737e7 cc4ec62 c110877 zhongmingmao C3\n* | 78dd014 a2622d9 92ad9ff zhongmingmao C6\n* | 92ad9ff 771d565 c110877 zhongmingmao C5\n|/\n* c110877 e7b3299 3847d71 zhongmingmao C2\n* 3847d71 fd092f0  zhongmingmao C1\n```\n\n## 提交历史搜索\n`--grep`：搜索提交说明\n`--author`：匹配作者\n`--committer`：匹配提交者\n`--after`：时间起点\n`--before`：时间终点\n`--`：特定路径\n```\n# 查找条件\n$ git log --oneline --decorate --graph --grep=C --author=zhongmingmao  --committer=zhongmingmao \\\n--after=2017-01-01 --before=2018-01-01 -- .\n* 807adc2 (HEAD -> master) C8\n* 537a716 C7\n* c94d37d (topic) C4\n* 25737e7 C3\n| * 78dd014 C6\n| * 92ad9ff C5\n|/\n* c110877 C2\n* 3847d71 C1\n```\n\n# 撤销操作\n\n## 撤销`Commit`\n\n{% note warning %}`git commit --amend `会重新生成新的Commit对象\n{% endnote %}\n\n### 修改提交日志\n```\n$ git log --oneline --decorate --graph\n* d12ae38 (HEAD -> master) add README.md\n\n$ gst\nOn branch master\nnothing to commit, working tree clean\n\n$ git commit --amend -m 'amend commit msg' # Create new commit object\n[master 4e4145a] amend commit msg\n Date: Fri Apr 14 19:39:45 2017 +0800\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 README.md\n\n$ git log --oneline --decorate --graph\n* 4e4145a (HEAD -> master) amend commit msg\n```\n\n### 合并修改+修改提交日志\n```\n$ git log --oneline --decorate --graph\n* 9c9ab11 (HEAD -> master) C2\n* e1fbcea C1\n\n$ gst -sb\n## master\nA  C3\n\n$ git commit --amend -m 'C3' # Create new commit object , merge last commit(C2)\n[master de41093] C3\n Date: Fri Apr 14 19:48:58 2017 +0800\n 2 files changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 C2\n create mode 100644 C3\n\n$ git log --oneline --decorate --graph\n* de41093 (HEAD -> master) C3\n* e1fbcea C1\n```\n\n## 撤销`Index`的修改\n{% note info %}`git reset HEAD` == `git reset --mixed HEAD`，用`HEAD`覆盖`Index`\n{% endnote %}\n```\n$ gst -sb\n## master\nMM C3\n\n$ git diff\ndiff --git a/C3 b/C3\nindex f70f10e..35d242b 100644\n--- a/C3\n+++ b/C3\n@@ -1 +1,2 @@\n A\n+B\n\n$ git diff --cached\ndiff --git a/C3 b/C3\nindex e69de29..f70f10e 100644\n--- a/C3\n+++ b/C3\n@@ -0,0 +1 @@\n+A\n\n$ git diff HEAD\ndiff --git a/C3 b/C3\nindex e69de29..35d242b 100644\n--- a/C3\n+++ b/C3\n@@ -0,0 +1,2 @@\n+A\n+B\n\n$ git reset HEAD C3 # Just reset Index , Not Working Tree\nUnstaged changes after reset:\nM\tC3\n\n$ gst -sb\n## master\n M C3\n\n$ git diff\ndiff --git a/C3 b/C3\nindex e69de29..35d242b 100644\n--- a/C3\n+++ b/C3\n@@ -0,0 +1,2 @@\n+A\n+B\n```\n\n## 撤销`Working Tree`的修改\n{% note info %}`git checkout --`，用`Index`覆盖`Working Tree`\n{% endnote %}\n```\n$ gst -sb\n## master\nMM C3\n\n$ git diff\ndiff --git a/C3 b/C3\nindex f70f10e..35d242b 100644\n--- a/C3\n+++ b/C3\n@@ -1 +1,2 @@\n A\n+B\n\n$ git checkout -- C3\n\n$ gst -sb\n## master\nM  C3\n\n$ git diff # Stdout print nothing\n```\n\n## 撤销`Index`和`Working Tree`的修改\n{% note danger %}`git reset --hard HEAD`，`git checkout HEAD [filename]`是**危险操作**，将会丢失上次Commit后的所有修改，用`HEAD`覆盖`Index`和`Working Tree`\n{% endnote %}\n```\n$ git log --oneline --decorate --graph\nde41093 (HEAD -> master) C3\n* e1fbcea C1\n\n$ gst -sb\n## master\nMM C3\n\n$ git reset --hard HEAD\nHEAD is now at de41093 C3\n\n$ gst\nOn branch master\nnothing to commit, working tree clean\n```\n\n```\n$ gst -sb\n## master\nMM C3\n\n$ git checkout HEAD C3\n\n$ gst\nOn branch master\nnothing to commit, working tree clean\n```\n\n<!-- indicate-the-source -->\n","tags":["Git"],"categories":["Git"]},{"title":"Java并发 -- PriorityBlockingQueue","url":"%2F2016%2F08%2F27%2Fconcurrent-priorityblockingqueue%2F","content":"\n{% note info %}\n本文将通过剖析`PriorityBlockingQueue`的源码来介绍其实现原理\n关于`ReentrantLock`的基本内容请参考「并发 - JUC - ReentrantLock - 源码剖析」，本文不再赘述\n{% endnote %}\n\n<!-- more -->\n\n# 基础\n\n## 概述\n`PriorityBlockingQueue`是`支持优先级`的`无界阻塞队列`\n`PriorityBlockingQueue`默认采用`自然升序`，也可以在`初始化`时通过传入`Comparator`指定排序规则\n`PriorityBlockingQueue`底层通过**`二叉堆`**实现优先级队列\n\n## 二叉堆\n\n### 结构\n结构类似于二叉树，父节点的键值`总是`小于等于（或大于等于）子节点的键值，父节点的`左子树`和`右子树`都是一个`二叉堆`\n最`大`堆：父节点的键值总是`大于等于`子节点的键值\n最`小`堆：父节点的键值总是`小于等于`子节点的键值\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/priorityblockingqueue_min_max_heap_1.png\" width=\"500\">\n\n### 存储\n二叉堆一般采用`数组`存储，`a[n]`的`左子节点`为`a[2*n+1]`，`a[n]`的`右子节点`为`a[2*n+2]`，`a[n]`的`父节点`为`a[(n-1)/2]`\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/priorityblockingqueue_heap_array_1.png\" width=\"500\">\n\n# 源码分析\n\n## 核心结构\n```java\npublic class PriorityBlockingQueue<E> extends AbstractQueue<E>\n                                    implements BlockingQueue<E>, java.io.Serializable {\n    // 数组默认大小\n    private static final int DEFAULT_INITIAL_CAPACITY = 11;\n    // 数组最大大小\n    private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;\n    // 表示堆的数组\n    private transient Object[] queue;\n    // 堆大小\n    private transient int size;\n    // 排序规则\n    private transient Comparator<? super E> comparator;\n    // 用于所有公共操作的锁\n    private final ReentrantLock lock;\n    // 非空等待条件\n    private final Condition notEmpty;\n    // 扩容时采用的自旋锁\n    private transient volatile int allocationSpinLock;\n    // 用于序列化，主要为了兼容之前的版本，本文不关注该特性\n    private PriorityQueue<E> q;\n}\n```\n\n## 构造函数\n```java\npublic PriorityBlockingQueue() {\n    this(DEFAULT_INITIAL_CAPACITY, null);\n}\n\npublic PriorityBlockingQueue(int initialCapacity) {\n   this(initialCapacity, null);\n}\n\npublic PriorityBlockingQueue(int initialCapacity, Comparator<? super E> comparator) {\n    if (initialCapacity < 1)\n        throw new IllegalArgumentException();\n    this.lock = new ReentrantLock();\n    this.notEmpty = lock.newCondition();\n    this.comparator = comparator;\n    this.queue = new Object[initialCapacity];\n}\n\npublic PriorityBlockingQueue(Collection<? extends E> c)\n```\n\n## add\n```java\npublic boolean add(E e) {\n    return offer(e);\n}\n```\n\n### offer\n```java\npublic boolean offer(E e) {\n    if (e == null)\n        // 不接受null元素\n        throw new NullPointerException();\n    final ReentrantLock lock = this.lock;\n    lock.lock(); // 获取独占锁\n    int n, cap;\n    Object[] array;\n    while ((n = size) >= (cap = (array = queue).length))\n        // 扩容\n        tryGrow(array, cap);\n    try {\n        Comparator<? super E> cmp = comparator;\n        if (cmp == null)\n            // 节点上冒，采用自然排序\n            siftUpComparable(n, e, array);\n        else\n            // 节点上冒，采用cmp指定的排序规则\n            siftUpUsingComparator(n, e, array, cmp);\n        size = n + 1;\n        // 唤醒等待非空条件的线程\n        notEmpty.signal();\n    } finally {\n        lock.unlock(); // 释放独占锁\n    }\n    return true;\n}\n```\n\n### tryGrow\n```java\n// 扩容\n// 先释放独占锁，允许多线程以CAS的方式创建新数组，然后重新竞争独占锁，进行数组复制\nprivate void tryGrow(Object[] array, int oldCap) {\n    lock.unlock(); // 先释放独占锁\n\n    // ===== 1. 以自旋锁的方式并发创建新数组\n    Object[] newArray = null;\n    // CAS方式抢占自旋锁\n    if (allocationSpinLock == 0 &&\n            UNSAFE.compareAndSwapInt(this, allocationSpinLockOffset, 0, 1)) {\n        // 当前线程持有自旋锁，并发时只有一个线程能执行到这里\n        try {\n        // 新容量\n        int newCap = oldCap + ((oldCap < 64) ? (oldCap + 2) : (oldCap >> 1));\n        if (newCap - MAX_ARRAY_SIZE > 0) { // 可能溢出\n            int minCap = oldCap + 1;\n            if (minCap < 0 || minCap > MAX_ARRAY_SIZE)\n                // 等价于：Integer.MAX_VALUE - 7 < oldCap <=Integer.MAX_VALUE\n                throw new OutOfMemoryError();\n            newCap = MAX_ARRAY_SIZE; // 采用最大容量\n        }\n\n        if (newCap > oldCap && queue == array)\n            // 1. 既然扩容，必然要求newCap > oldCap\n            // 2. finally会释放自旋锁，其他线程就有可能获得自旋锁，\n            //    queue!=array，说明已经在进行扩容处理，当前线程无需再创建新数组\n            //    queue!=array，也表明当前线程检测到竞争，放弃创建新数组\n            newArray = new Object[newCap];\n        } finally {\n            allocationSpinLock = 0; // 释放自旋锁\n        }\n    }\n\n    if (newArray == null)\n        // newArray==null说明当前线程检测到冲突\n        // 其他线程正在进行扩容处理，已经执行了下面的queue=newArray语句（恰好当前线程读取到了最新的queue）\n        // 当前线程让出CPU资源，让正在进行扩容处理的线程尽快完成扩容\n        Thread.yield();\n\n    // ===== 2. 以独占锁的方式复制数组\n    lock.lock(); // 当前线程再次获取独占锁，获取公共内存中最新的queue\n    if (newArray != null && queue == array) {\n        // newArray!=null：说明新数组内存分配已经完成\n        // queue==array：说明扩容尚未完成，否则扩容已经完成，没必要重复扩容\n        queue = newArray;\n        System.arraycopy(array, 0, newArray, 0, oldCap); // 数组复制\n    }\n}\n```\n\n### siftUpComparable\n```java\n// 节点上冒，采用自然排序\nprivate static <T> void siftUpComparable(int k, T x, Object[] array) {\n    Comparable<? super T> key = (Comparable<? super T>) x;\n    while (k > 0) { // k=0表示array[0]为根节点，无法继续上冒，直接退出\n        int parent = (k - 1) >>> 1; // 父节点：(n-1)/2\n        Object e = array[parent];\n        if (key.compareTo((T) e) >= 0)\n            // 子节点 >= 父节点，退出循环，最小堆\n            break;\n        // 子节点 < 父节点，将原先父节点的值移动到子节点的位置\n        // 这时array[parent]形成可覆盖的空穴，下一次循环时（可能）被覆盖\n        array[k] = e;\n        k = parent; // 准备下一次上冒\n    }\n    array[k] = key;\n}\n```\n\n### siftUpUsingComparator\n```java\n// 节点上冒，采用cmp指定的排序规则\n// 跟siftUpComparable非常类似，不再赘述\nprivate static <T> void siftUpUsingComparator(int k, T x, Object[] array, Comparator<? super T> cmp) {\n    while (k > 0) {\n        int parent = (k - 1) >>> 1;\n        Object e = array[parent];\n        if (cmp.compare(x, (T) e) >= 0)\n            break;\n        array[k] = e;\n        k = parent;\n    }\n    array[k] = x;\n}\n```\n\n### 逻辑示意图\n```java\npublic static void main(String[] args) {\n    int initCap = 15;\n    PriorityBlockingQueue<Integer> queue = new PriorityBlockingQueue(initCap);\n    IntStream.range(0, initCap).forEach(i -> queue.add(2 * i + 1));\n    queue.add(2);\n}\n```\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/priorityblockingqueue_heap_add_1.png\" width=\"500\">\n\n\n## poll\n```java\npublic E poll() {\n    final ReentrantLock lock = this.lock;\n    lock.lock(); // 获取独占锁\n    try {\n        return dequeue();\n    } finally {\n        lock.unlock(); // 释放独占锁\n    }\n}\n```\n\n### dequeue\n```java\nprivate E dequeue() {\n    int n = size - 1;\n    if (n < 0) // 队列为空，返回null\n        return null;\n    else {\n        Object[] array = queue;\n        E result = (E) array[0]; // 暂存第一个节点，用于返回，因为会在下冒过程中被覆盖\n        E x = (E) array[n]; // 暂存最后一个节点\n        array[n] = null; // 置空最后一个节点\n        Comparator<? super E> cmp = comparator;\n        if (cmp == null)\n            // 节点下冒，采用自然排序\n            siftDownComparable(0, x, array, n);\n        else\n            // 节点下冒，采用cmp指定的排序规则\n            siftDownUsingComparator(0, x, array, n, cmp);\n        size = n;\n        return result;\n    }\n}\n```\n\n### siftDownComparable\n```java\n// 节点下冒，采用自然排序\n// k：需要填充的位置，poll操作时，默认为0\n// x：需要插入的元素，poll操作时，为原尾节点\n// array：表示堆的数组\n// n：现在堆大小，为原先堆大小-1，尾节点保存在x\nprivate static <T> void siftDownComparable(int k, T x, Object[] array, int n) {\n    if (n > 0) { // n==0，说明原先堆只有一个节点，无需下冒\n        Comparable<? super T> key = (Comparable<? super T>)x;\n        int half = n >>> 1;\n        // k>=half表示array[k]为叶子节点，无法继续下冒，直接退出，具体解释如下：\n        // 在dequeue中，n=(size-1)，尾节点为a[size-1]=a[n]，dequeue会置空a[n]\n        // 1. 假若尾节点为其父节点的左子节点，即a[n]=a[2*j+1]，父节点为a[j]，half=n>>>1=j，\n        //    置空a[n]后，a[j]失去了唯一的子节点，成为叶子节点，因为a[k<half=j]为非叶子节点\n        // 2. 假若尾节点为其父节点的右子节点，即a[n]=a[2*j+2]，父节点为a[j]，half=n>>>1=j+1，\n        //    置空a[n]后，a[j]仍拥有左子节点，a[j]为非叶子节点，a[j+1]为叶子节点，因此a[k<half=j+1]为非叶子节点\n        while (k < half) {\n            // child表示a[k]左右子节点中较小节点的索引，暂时表示左子节点的索引\n            int child = (k << 1) + 1;\n            // c表示a[k]左右子节点中较小节点的值，暂时表示左子节点的值\n            Object c = array[child];\n            // a[k]右子节点的索引\n            int right = child + 1;\n            if (right < n &&\n                    ((Comparable<? super T>) c).compareTo((T) array[right]) > 0)\n                // a[k]右子节点存在 并且 a[k]左子节点的值大于a[k]右子节点的值，更新child和c\n                c = array[child = right];\n            if (key.compareTo((T) c) <= 0)\n                // 如果key（即原尾节点的值）不大于a[k]左右子节点中较小节点，就没必要继续下冒，退出循环\n                break;\n            array[k] = c;\n            k = child;\n        }\n        array[k] = key; // 将原尾节点重新加入堆\n    }\n}\n```\n\n### siftDownUsingComparator\n```java\n// 节点下冒，采用cmp指定的排序规则\n// 跟siftDownComparable非常类似，不再赘述\nprivate static <T> void siftDownUsingComparator(int k, T x, Object[] array, int n, Comparator<? super T> cmp) {\n    if (n > 0) {\n        int half = n >>> 1;\n        while (k < half) {\n            int child = (k << 1) + 1;\n            Object c = array[child];\n            int right = child + 1;\n            if (right < n && cmp.compare((T) c, (T) array[right]) > 0)\n                c = array[child = right];\n            if (cmp.compare(x, (T) c) <= 0)\n                break;\n            array[k] = c;\n            k = child;\n        }\n        array[k] = x;\n    }\n}\n```\n\n### 逻辑示意图\n```java\npublic static void main(String[] args) {\n    PriorityBlockingQueue<Integer> queue = new PriorityBlockingQueue(15);\n    Arrays.asList(1,             // 第1层\n         2, 3,                   // 第2层\n         7, 8, 4, 5,             // 第3层\n         10, 11, 12, 13, 6, 9)   // 第4层\n         .forEach(i -> queue.add(i));\n    queue.poll();\n}\n```\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/priorityblockingqueue_heap_poll.png\" width=\"500\">\n\n\n## remove\n```java\n// remove操作结合了上冒操作和下冒操作\npublic boolean remove(Object o) {\n    final ReentrantLock lock = this.lock;\n    lock.lock();\n    try {\n        int i = indexOf(o);\n        if (i == -1)\n            // 元素不存在\n            return false;\n        removeAt(i);\n        return true;\n    } finally {\n        lock.unlock();\n    }\n}\n```\n\n### indexOf\n```java\n// 遍历数组，匹配成功，返回索引，否则返回-1\nprivate int indexOf(Object o) {\n    if (o != null) {\n        Object[] array = queue;\n        int n = size;\n        for (int i = 0; i < n; i++)\n            if (o.equals(array[i]))\n                return i;\n    }\n    return -1;\n}\n```\n\n### removeAt\n```java\n// 先下冒，在上冒（不一定存在）\n// 上冒和上冒的过程请参照上面的分析\nprivate void removeAt(int i) {\n    Object[] array = queue;\n    int n = size - 1;\n    if (n == i) // 要移除的元素恰好是堆的最后一个元素\n        array[i] = null;\n    else {\n        E moved = (E) array[n]; // 暂存尾节点\n        array[n] = null; // 置空尾节点\n        Comparator<? super E> cmp = comparator;\n        if (cmp == null)\n            // 原尾节点从索引i开始下冒过程\n            siftDownComparable(i, moved, array, n);\n        else\n            siftDownUsingComparator(i, moved, array, n, cmp);\n\n        // 这个地方很关键！！\n        // array[i]==moved说明在下冒过程中，尾节点直接移动到索引为i的节点\n        // 这仅仅只能保证以array[i]为根节点的子树能满足堆的特性，但无法保证以array[0]根节点的子树也能满足堆的特性\n        // 因为array[i]有可能小于父节点array[(i-1)/2]，因此还需要进行一次上冒过程\n        // 如果array[i]!=moved，说明moved已经下冒到array[i]的子树中去\n        // 而当前的array[i]是以前该子树中的一员，按照堆的特性，必然大于等于父节点array[(i-1)/2]\n        // 因此moved必然大于等于array[(i-1)/2]，以array[0]根节点的子树已经能满足堆的特性\n        if (array[i] == moved) {\n            if (cmp == null)\n                // 原尾节点从索引i开始上冒过程\n                siftUpComparable(i, moved, array);\n            else\n                siftUpUsingComparator(i, moved, array, cmp);\n        }\n    }\n    size = n;\n}\n```\n\n### 逻辑示意图\n```java\npublic static void main(String[] args) {\n    PriorityBlockingQueue<Integer> queue = new PriorityBlockingQueue(15);\n    Arrays.asList(0,                        // 第1层\n          20, 10,                           // 第2层\n          21, 22, 11, 12,                   // 第3层\n          23, 24, 25, 26, 13, 14, 15, 16)   // 第4层\n          .forEach(i -> queue.add(i));\n    queue.remove(22);\n}\n```\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/priorityblockingqueue_heap_remove.png\" width=\"500\">\n<!-- indicate-the-source -->\n","tags":["AQS"],"categories":["Concurrent"]},{"title":"Java并发 -- ArrayBlockingQueue","url":"%2F2016%2F08%2F24%2Fconcurrent-arrayblockingqueue%2F","content":"\n{% note info %}\n本文将通过剖析`ArrayBlockingQueue`的源码来介绍其实现原理\n关于`ReentrantLock`的基本内容请参考「并发 - JUC - ReentrantLock - 源码剖析」，本文不再赘述\n关于`ConditionObject`的基本内容请参考「并发 - JUC - ConditionObject - 源码剖析」，本文不再赘述\n{% endnote %}\n\n<!-- more -->\n\n# 基础\n`ArrayBlockingQueue`是基于`数组`实现的`有界阻塞`队列，`ArrayBlockingQueue`是通过`ReentrantLock`和`ConditionObject`来实现同步的\n\n# 源码分析\n\n## 核心结构\n```java\npublic class ArrayBlockingQueue<E> extends AbstractQueue<E>\n                                implements BlockingQueue<E>, java.io.Serializable {\n    // 定长数组，final修饰，一旦初始化，长度不再变化\n    final Object[] items;\n    // 下一次 take/poll/peek/remove 操作的索引位置\n    int takeIndex;\n    // 下一次 put/offer/add 操作的索引位置\n    int putIndex;\n    // 队列中元素的数量\n    int count;\n\n    // 所有操作共用同一个可重入锁\n    final ReentrantLock lock;\n    // 出队条件\n    private final Condition notEmpty;\n    // 入队条件\n    private final Condition notFull;\n```\n\n## 构造函数\n```java\npublic ArrayBlockingQueue(int capacity) {\n    this(capacity, false); // 默认是非公平锁\n}\n\npublic ArrayBlockingQueue(int capacity, boolean fair) {\n    if (capacity <= 0)\n        throw new IllegalArgumentException();\n    this.items = new Object[capacity];\n    lock = new ReentrantLock(fair);\n    // notEmpty和notFull基于同一把锁lock\n    notEmpty = lock.newCondition();\n    notFull =  lock.newCondition();\n}\n\npublic ArrayBlockingQueue(int capacity, boolean fair, Collection<? extends E> c) {\n    this(capacity, fair);\n    final ReentrantLock lock = this.lock;\n    // 这里加锁是为了保证内存可见性，而不是为了互斥！！\n    // 释放锁的时候会自动写入主内存\n    lock.lock();\n    try {\n        int i = 0;\n        try {\n            for (E e : c) {\n                // e为null则抛出NullPointerException，然后释放锁\n                checkNotNull(e);\n                items[i++] = e;\n            }\n        } catch (ArrayIndexOutOfBoundsException ex) {\n            // 空间不够则抛出IllegalArgumentException，然后释放锁\n            throw new IllegalArgumentException();\n        }\n        count = i;\n        putIndex = (i == capacity) ? 0 : i;\n    } finally {\n        lock.unlock();\n    }\n}\n```\n\n### 逻辑示意图\n```java\npublic static void main(String[] args) {\n    ArrayBlockingQueue queue = new ArrayBlockingQueue(10, false,\n                        Arrays.asList(\"zhong\", \"ming\", \"mao\"));\n}\n```\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/arrayblockingqueue_constructer.png\" width=\"500\">\n\n## add(E e)\n```java\n// 入队操作列表，都比较类似，仅仅分析add(E e)\n// 如果立即可行且不超过队列容量，将指定元素插入到队列尾部，成功时返回true，队列已满时抛出IllegalStateException\npublic boolean add(E e)\n// 如果立即可行且不超过队列容量，将指定元素插入到队列尾部，成功时返回true，队列已满时返回false\npublic boolean offer(E e)\n// 与offer(E e)类似，只是在队列已满时，允许在一段时间内等待可用空间\npublic boolean offer(E e, long timeout, TimeUnit unit)\n// 将指定元素插入到队列尾部，如果队列已满，则不限时等待可用空间，被中断时抛出InterruptedException\npublic void put(E e) throws InterruptedException\n```\n```java\n// From ArrayBlockingQueue\npublic boolean add(E e) {\n    // 调用直接父类AbstractQueue的add(E e)方法\n    return super.add(e);\n}\n```\n\n### AbstractQueue.add\n```java\n// From AbstractQueue\n// 队列未满时，入队成功并返回true\n// 队列已满时，抛出IllegalStateException\npublic boolean add(E e) {\n    if (offer(e))\n        // 队列未满时，入队成功并返回true\n        return true;\n    else\n        // 队列已满时，抛出IllegalStateException\n        throw new IllegalStateException(\"Queue full\");\n}\n```\n\n### offer(E e)\n```java\n// From ArrayBlockingQueue\n// 队列未满时，入队成功并返回true\n// 队列已满时，入队失败并返回false\npublic boolean offer(E e) {\n    checkNotNull(e);\n    final ReentrantLock lock = this.lock;\n    lock.lock();\n    try {\n        if (count == items.length)\n            // 队列已满，返回false\n            return false;\n        else {\n            // 队列未满，入队并唤醒线程，返回true\n            enqueue(e);\n            return true;\n        }\n    } finally {\n        lock.unlock();\n    }\n}\n```\n```java\nprivate static void checkNotNull(Object v) {\n    if (v == null)\n        throw new NullPointerException();\n}\n```\n\n### enqueue\n```java\n// From ArrayBlockingQueue\n// 入队并唤醒线程，需要先持有锁\nprivate void enqueue(E x) {\n    final Object[] items = this.items;\n    items[putIndex] = x; // 入队\n    if (++putIndex == items.length)\n        putIndex = 0; // 重置putIndex\n    count++;\n    // 唤醒等待notEmpty的线程，需要先持有锁\n    notEmpty.signal();\n}\n```\n\n## poll()\n```java\n// 入队操作列表，都比较类似，仅仅分析poll()\n// 获取并移除队列头部，如果队列为空，返回null\npublic E poll()\n// 与poll()类似，只是在队列为空时，允许在一段时间内等待可用元素\npublic E poll(long timeout, TimeUnit unit) throws InterruptedException\n// 从队列中移除指定元素（如果存在）\npublic boolean remove(Object o)\n// 与poll()类似，只是允许在队列为空时，不限时等待可用元素，被中断时抛出InterruptedException\npublic E take() throws InterruptedException\n```\n```java\n// From ArrayBlockingQueue\npublic E poll() {\n    final ReentrantLock lock = this.lock;\n    lock.lock();\n    try {\n        return (count == 0) ?\n                        null : // 队列为空时直接返回null，不等待\n                        dequeue(); // 队列不为空时，获取队列头部，并唤醒线程\n    } finally {\n        lock.unlock();\n    }\n}\n```\n\n### dequeue\n```java\n// From ArrayBlockingQueue\n// 获取队列头部，并唤醒线程\nprivate E dequeue() {\n    final Object[] items = this.items;\n    @SuppressWarnings(\"unchecked\")\n    E x = (E) items[takeIndex]; // 暂存出队元素\n    items[takeIndex] = null; // 置空数组对准备出队元素的引用\n    if (++takeIndex == items.length)\n        takeIndex = 0; // 重置takeIndex\n    count--;\n    if (itrs != null)\n        itrs.elementDequeued();\n    notFull.signal(); // 唤醒等待notFull的线程，需要先持有锁\n    return x; // 返回出队元素\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["AQS"],"categories":["Concurrent"]},{"title":"Java并发 -- FutureTask","url":"%2F2016%2F08%2F23%2Fconcurrent-futuretask%2F","content":"\n{% note info %}\n本文将通过剖析`FutureTask`的源码来介绍其实现原理\n{% endnote %}\n\n<!-- more -->\n\n# 基础\n\n## Runnable + Callable\n```java\n@FunctionalInterface\npublic interface Runnable {\n    public abstract void run();\n}\n```\n```java\n// Callable相对于Runnable，允许返回运行结果和抛出异常\n@FunctionalInterface\npublic interface Callable<V> {\n    V call() throws Exception;\n}\n```\n\n## Future\n```java\n// Future接口代表异步计算的结果\npublic interface Future<V> {\n    // 尝试取消执行任务\n    // 如果任务已经完成、已经被取消或者或者由于某些原因不能被取消，返回false\n    // 如果调用cancel时，任务还没有开始执行，那么任务不会被执行，返回true\n    // 如果调用cancel时，任务已经开始执行但还没有执行完成，\n    //        需要依据参数mayInterruptIfRunning是否中断执行任务的线程，返回true\n    // 如果cancel返回后，后续调用isDone会始终返回true\n    // 如果cancel返回true，后续调用isCancelled会始终返回true\n    boolean cancel(boolean mayInterruptIfRunning)\n\n    // 如果任务正常完成之前被取消，返回true\n    boolean isCancelled();\n\n    // 如果任务完成，返回true；任务完成包括：正常完成、发生异常或被取消\n    boolean isDone();\n\n    // 等待任务执行完成，然后获取执行结果，如果任务还没完成则会阻塞等到任务执行完成\n    // 如果任务被取消，则会抛出CancellationException\n    // 如果任务执行过程中发生异常，则会抛出ExecutionException\n    // 如果任务阻塞等待过程中被中断，则会抛出InterruptedException\n    V get() throws InterruptedException, ExecutionException;\n\n    // get()的超时版本，区别：\n    // 如果阻塞等待过程中超时，则会抛出TimeoutException\n    V get(long timeout, TimeUnit unit)\n        throws InterruptedException, ExecutionException, TimeoutException;\n}\n```\n\n## FutureTask\n```java\n// FutureTask实现RunnableFuture接口\npublic class FutureTask<V> implements RunnableFuture<V>\n```\n```java\n// RunnableFuture接口继承自Runnable接口和Future接口\npublic interface RunnableFuture<V> extends Runnable, Future<V> {\n    void run();\n}\n```\n\n# 源码分析\n\n## 核心结构\n```java\npublic class FutureTask<V> implements RunnableFuture<V> {\n    // 底层实际调用的callable，执行完成后置为null\n    private Callable<V> callable;\n    // get()方法返回的结果或抛出的异常\n    private Object outcome;\n    // 执行callable的线程\n    private volatile Thread runner;\n    // 等待线程链表\n    private volatile WaitNode waiters;\n\n    // 任务的运行状态，初始状态为NEW\n    private volatile int state;\n\n    // 初始状态\n    // 表示任务还未被执行\n    private static final int NEW          = 0;\n\n    // 中间状态\n    // 表示任务已经执行完成或任务执行过程中发生了异常，\n    // 但任务的执行结果或者异常原因还没有保存到outcome\n    // state>COMPLETING表示任务已经执行完成：正常执行完成、发生异常或被取消\n    // NEW -> COMPLETING\n    private static final int COMPLETING   = 1;\n    // 终态\n    // 表示任务已经执行完成并且任务的执行结果已经保存到outcome\n    // NEW -> COMPLETING -> NORMAL\n    private static final int NORMAL       = 2;\n    // 终态\n    // 表示任务执行过程中发生了异常并且异常原因已经保存到outcome\n    // NEW -> COMPLETING -> EXCEPTIONAL\n    private static final int EXCEPTIONAL  = 3;\n\n    // 终态\n    // 表示任务还没开始执行或者任务已经开始执行但还没有执行完成时，用户调用了cancel(false)\n    // NEW -> CANCELLED\n    private static final int CANCELLED    = 4;\n\n    // 中间状态\n    // 表示任务还没开始执行或者任务已经开始执行但还没有执行完成时，用户调用了cancel(true)\n    // 中断执行任务的线程之前\n    // NEW -> INTERRUPTING\n    private static final int INTERRUPTING = 5;\n    // 终态\n    // 表示任务还没开始执行或者任务已经开始执行但还没有执行完成时，用户调用了cancel(true)\n    // 中断执行任务的线程之后\n    // NEW -> INTERRUPTING -> INTERRUPTED\n    private static final int INTERRUPTED  = 6;\n}\n```\n```java\n// 等待线程链表的节点\nstatic final class WaitNode {\n    volatile Thread thread;\n    volatile WaitNode next; // 下一节点\n    WaitNode() {\n        thread = Thread.currentThread();\n    }\n}\n```\n运行状态转换图\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/futuretask_state.png\" width=\"500\">\n\n\n## 构造函数\n```java\npublic FutureTask(Callable<V> callable) {\n    if (callable == null)\n        throw new NullPointerException();\n    this.callable = callable;\n    this.state = NEW; // 初始状态为NEW\n}\n\npublic FutureTask(Runnable runnable, V result) {\n    // 将Runnable适配成Callable\n    this.callable = Executors.callable(runnable, result);\n    this.state = NEW; // 初始状态为NEW\n}\n```\n\n### callable\n```java\n// From Executors\npublic static <T> Callable<T> callable(Runnable task, T result) {\n    if (task == null)\n        throw new NullPointerException();\n    return new RunnableAdapter<T>(task, result); // 适配器模式\n}\n```\n\n### RunnableAdapter\n```java\n// From Executors\nstatic final class RunnableAdapter<T> implements Callable<T> {\n    final Runnable task;\n    final T result;\n    RunnableAdapter(Runnable task, T result) {\n        this.task = task;\n        this.result = result;\n    }\n    public T call() {\n        task.run(); // 只是简单地调用Runnable.run()方法\n        return result;\n    }\n}\n```\n\n## isCancelled\n```java\npublic boolean isCancelled() {\n    // cancel(false) -> CANCELLED\n    // cancel(true) -> INTERRUPTING / INTERRUPTED\n    return state >= CANCELLED;\n}\n```\n\n## isDone\n```java\npublic boolean isDone() {\n    // state >= COMPLETING\n    return state != NEW;\n}\n```\n\n## run\n```java\npublic void run() {\n    // 1. 任务的运行状态不为NEW，说明任务已经开始执行但没有执行完成或者任务已经完成（正常完成、发生异常或者被取消）\n    // 2. 任务的运行状态为NEW，以CAS的方式将runner设置为当前线程，并发时只有一个线程能成功，失败的线程直接返回\n    if (state != NEW ||\n            !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread()))\n        return;\n\n    // 代码执行到这里说明任务的运行状态为NEW，且成功以CAS的方式设置runner为当前线程\n    try {\n        Callable<V> c = callable;\n        if (c != null && state == NEW) {\n            // callable不为null且任务的运行状态为NEW，执行任务\n            V result;\n            boolean ran; // 任务是否正常完成\n            try {\n                result = c.call(); // 执行任务\n                ran = true; // 任务正常完成\n            } catch (Throwable ex) {\n                result = null;\n                ran = false;\n                // 任务执行过程中抛出异常，完成任务运行状态转移，保存异常原因，唤醒等待线程\n                setException(ex);\n            }\n            if (ran)\n                // 任务正常完成，完成任务运行状态转移，保存任务执行结果，唤醒等待线程\n                set(result);\n        }\n    } finally {\n        // runner不为null时，其他线程无法调用run()\n        // 将runner重置为null，允许其他线程调用run()\n        runner = null;\n        int s = state; // 获取最新的任务运行状态\n        if (s >= INTERRUPTING) // INTERRUPTING或者INTERRUPTED\n            // 自旋等待运行状态设置为INTERRUPTED\n            handlePossibleCancellationInterrupt(s);\n    }\n}\n```\n\n### setException\n```java\n// 任务运行状态转移：NEW -> COMPLETING -> EXCEPTIONAL\n// 异常原因保存在outcome\n// 唤醒等待线程链表中节点的对应线程\nprotected void setException(Throwable t) {\n    if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) {\n        // 任务运行状态转移：NEW -> COMPLETING\n        outcome = t; // 异常原因保存在outcome\n        // 任务运行状态转移：COMPLETING -> EXCEPTIONAL\n        UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL);\n        // 唤醒等待线程链表中所有节点的对应线程\n        finishCompletion();\n    }\n}\n```\n\n### set\n```java\n// 任务运行状态转移：NEW -> COMPLETING -> NORMAL\n// 任务的执行结果保存在outcome\n// 唤醒等待线程链表中节点的对应线程\nprotected void set(V v) {\n    if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) {\n        // 任务运行状态转移：NEW -> COMPLETING\n        outcome = v; // 任务的执行结果保存在outcome\n        // 任务运行状态转移：COMPLETING -> NORMAL\n        UNSAFE.putOrderedInt(this, stateOffset, NORMAL);\n        // 唤醒等待线程链表中所有节点的对应线程\n        finishCompletion();\n    }\n}\n```\n\n### finishCompletion\n```java\n// 唤醒等待线程链表中所有节点的对应线程\nprivate void finishCompletion() {\n    for (WaitNode q; (q = waiters) != null;) {\n       if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) {\n            for (;;) {\n                Thread t = q.thread;\n                if (t != null) {\n                    q.thread = null;\n                    LockSupport.unpark(t); // 唤醒线程\n                }\n                WaitNode next = q.next;\n                if (next == null)\n                    break; // 到达尾节点\n                q.next = null; // 断开后继节点连接，加速垃圾回收\n                q = next;\n            }\n            break;\n        }\n    }\n    done(); // 在FutureTask中，done是一个空方法\n    callable = null; // 加快垃圾回收，减少内存占用\n}\n\nprotected void done() { }\n```\n\n### handlePossibleCancellationInterrupt\n```java\n// 自旋等待运行状态设置为INTERRUPTED\nprivate void handlePossibleCancellationInterrupt(int s) {\n    if (s == INTERRUPTING)\n      while (state == INTERRUPTING)\n          Thread.yield();\n\n}\n```\n\n## cancel\n```java\npublic boolean cancel(boolean mayInterruptIfRunning) {\n    // 1. 任务的运行状态不为NEW，说明任务已经开始执行但没有执行完成或者任务已经完成（正常完成、发生异常或者被取消）\n    //    直接返回false，无法取消\n    // 2. 任务的运行状态为NEW，以CAS的方式完成任务的运行状态转移：\n    //    NEW -> (mayInterruptIfRunning ? INTERRUPTING : CANCELLED)\n    //    并发时只有一个线程能成功，失败的线程直接返回false\n    if (!(state == NEW &&\n            UNSAFE.compareAndSwapInt(this, stateOffset, NEW,\n                mayInterruptIfRunning ? INTERRUPTING : CANCELLED)))\n        return false;\n\n    // 代码执行到这里说明任务的运行状态为NEW，且成功以CAS的方式完成任务的运行状态转移\n    try {\n        if (mayInterruptIfRunning) {\n            // 允许中断执行任务的线程\n            try {\n                Thread t = runner;\n                if (t != null)\n                    t.interrupt(); // 中断线程\n            } finally {\n                // 任务运行状态转移：INTERRUPTING -> INTERRUPTED\n                UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED);\n            }\n        }\n    } finally {\n        // 唤醒等待线程链表中所有节点的对应线程\n        finishCompletion();\n    }\n    return true;\n}\n```\n\n## get\n```java\npublic V get() throws InterruptedException, ExecutionException {\n    int s = state;\n    if (s <= COMPLETING) // NEW或者COMPLETING\n        // NEW：表示任务还未被执行\n        // COMPLETING：表示任务已经执行完成或任务执行过程中发生了异常，\n        //             但任务的执行结果或者异常原因还没有保存到outcome\n        // 阻塞等待，超时或运行状态到达终态时，返回对应的运行状态\n        s = awaitDone(false, 0L);\n    // 依据不同的任务运行状态做相应的处理：返回执行结果或抛出异常\n    return report(s);\n}\n```\n\n### awaitDone\n```java\n// 阻塞等待，超时或运行状态到达终态时，返回对应的运行状态\n// 代码逻辑十分巧妙！！\nprivate int awaitDone(boolean timed, long nanos) throws InterruptedException {\n    // 等待截止时间，无限时等待时为0\n    final long deadline = timed ? System.nanoTime() + nanos : 0L;\n    WaitNode q = null; // 等待节点\n    boolean queued = false; // 是否已经排队\n\n    for (;;) { // 自旋\n        if (Thread.interrupted()) {\n            // 线程被中断，此时当前线程有可能已经在链表中等待，移除节点并抛出InterruptedException\n            removeWaiter(q);\n            throw new InterruptedException();\n        }\n\n        int s = state; // 当前运行状态\n\n        if (s > COMPLETING) {\n            // state>COMPLETING表示任务已经执行完成：正常执行完成、发生异常或被取消\n            // 此时依据s能唯一确定终态，归纳为下面2种情况，可以直接返回s\n            //   1. NORMAL(2)、EXCEPTIONAL(3)、CANCELLED(4)和INTERRUPTED(6)为终态\n            //   2. INTERRUPTING(5)的终态为INTERRUPTED(6)\n            // 如果已经创建等待节点，则置空该等待节点的线程信息\n            if (q != null)\n                q.thread = null;\n            return s;\n        }\n\n        else if (s == COMPLETING)\n            // COMPLETING表示任务已经执行完成或任务执行过程中发生了异常\n            // 但任务的执行结果或者异常原因还没有保存到outcome\n            // 由上面的分析可知，从COMPLETING->NORMAL或COMPLETING->EXCEPTIONAL是非常短暂的过程\n            // 另外，report(NORMAL)和report(EXCEPTIONAL)逻辑是不一样的，需要明确知道运行状态会怎样转移\n            // 因此这里也无需进入等待节点链表等待，让出CPU资源，继续自旋，进入下一循环，暂不考虑超时\n            Thread.yield();\n\n        else if (q == null)\n            // 执行到这里说明state为NEW（非终态）且当前线程对应的等待节点尚未创建，创建等待节点\n            q = new WaitNode();\n\n        else if (!queued)\n            // 执行到这里说明tate为NEW（非终态）且当前线程对应的等待节点已经创建，但尚未加入到等待节点链表\n            queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q);\n\n        else if (timed) {\n            // 执行到这里说明tate为NEW（非终态）且当前线程对应的等待节点已经加入到等待节点链表，考虑超时\n            nanos = deadline - System.nanoTime();\n            if (nanos <= 0L) {\n                // 超时，删除对应节点，并返回任务当前的运行状态\n                removeWaiter(q);\n                return state;\n            }\n            // 限时阻塞等待，直到被唤醒或中断\n            // 如果由于中断而退出休眠状态，进入下一循环会抛出InterruptedException\n            LockSupport.parkNanos(this, nanos);\n        }\n\n        else\n            // 执行到这里说明tate为NEW（非终态）且当前线程对应的等待节点已经加入到等待节点链表，不考虑超时\n            // 不限时阻塞等待，与parkNanos非常类似\n            LockSupport.park(this);\n    }\n}\n```\n\n### report\n```java\n// 依据不同的任务运行状态做相应的处理：返回执行结果或抛出异常\nprivate V report(int s) throws ExecutionException {\n    Object x = outcome;\n\n    // NORMAL\n    // 任务正常执行完成，返回任务执行结果\n    if (s == NORMAL)\n        return (V)x;\n\n    // CANCELLED / INTERRUPTING / INTERRUPTED\n    // 任务被取消，抛出CancellationException\n    if (s >= CANCELLED)\n        throw new CancellationException();\n\n    // EXCEPTIONAL\n    // 执行过程中抛出异常，将异常原因封装成ExecutionException后抛出\n    throw new ExecutionException((Throwable)x);\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["JUC"],"categories":["Concurrent"]},{"title":"Java并发 -- ConcurrentHashMap","url":"%2F2016%2F08%2F22%2Fconcurrent-concurrenthashmap-7%2F","content":"\n{% note info %}\n本文将通过剖析`JDK1.7 ConcurrentHashMap`的源码来介绍其实现原理\n{% endnote %}\n\n<!-- more -->\n\n# 基础\n1. `Hashtable`，`Collections.synchronizedMap(map)`是`全局`上锁，在`JDK1.7`中，`ConcurrentHashMap`采用了**`锁分离`**的技术（`分段锁`），允许`多个操作并发`地进行\n2. `ConcurrentHashMap`采用`Segment`将整体切分成不同的部分，每个部分拥有`独立的锁`，如果方法仅`需要单独的部分`，则可以`并发`地执行；如果方法需要跨`Segment`，需要按顺序锁定所有段的锁，然后按`逆序`释放锁\n3. `ConcurrentHashMap`允许多个`读操作并发`进行，`读操作并不需要加锁`\n\n\n# 源码分析\n\n## 核心结构\n\n### ConcurrentHashMap\n```java\n// ConcurrentHashMap类似于一张大的Hash表，将数据切分成一段一段，每段数据由Segment负责管理\npublic class ConcurrentHashMap<K, V> extends AbstractMap<K, V>\n                                implements ConcurrentMap<K, V>, Serializable {\n    static final int DEFAULT_INITIAL_CAPACITY = 16;\n    static final float DEFAULT_LOAD_FACTOR = 0.75f;\n    static final int DEFAULT_CONCURRENCY_LEVEL = 16;\n    static final int MAXIMUM_CAPACITY = 1 << 30;\n    static final int MIN_SEGMENT_TABLE_CAPACITY = 2;\n    static final int MAX_SEGMENTS = 1 << 16;\n    static final int RETRIES_BEFORE_LOCK = 2;\n\n    private transient final int hashSeed = randomHashSeed(this);\n    final int segmentMask;\n    final int segmentShift;\n    final Segment<K,V>[] segments;\n    transient Set<K> keySet;\n    transient Set<Map.Entry<K,V>> entrySet;\n    transient Collection<V> values;\n}\n```\n\n### Segment\n```java\n// Segment继承自ReentrantLock，相当于一把可重入锁，本文中会称之为段\n// Segment与HashMap的结构非常类似，数组+链表结构\n// Segment是实现ConcurrentHashMap锁分离技术的核心\nstatic final class Segment<K,V> extends ReentrantLock implements Serializable {\n    static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() > 1 ? 64 : 1;\n    transient volatile HashEntry<K,V>[] table;\n    transient int count;\n    transient int modCount;\n    transient int threshold;\n    final float loadFactor;\n}\n```\n\n### HashEntry\n```java\n// HashEntry用于存储的实际键值对信息，本文中会称之为节点\nstatic final class HashEntry<K,V> {\n    final int hash;\n    final K key;\n    volatile V value;\n    volatile HashEntry<K,V> next;\n}\n```\n\n## 构造函数\n```java\npublic ConcurrentHashMap() {\n    this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);\n}\npublic ConcurrentHashMap(int initialCapacity) {\n    this(initialCapacity, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);\n}\npublic ConcurrentHashMap(int initialCapacity, float loadFactor) {\n    this(initialCapacity, loadFactor, DEFAULT_CONCURRENCY_LEVEL);\n}\npublic ConcurrentHashMap(Map<? extends K, ? extends V> m) {\n    this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY),\n           DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);\n    putAll(m);\n}\n\npublic ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) {\n    // 默认值：initialCapacity=16, loadFactor=0.75f, concurrencyLevel=16\n    if (!(loadFactor > 0) || initialCapacity < 0 || concurrencyLevel <= 0)\n        throw new IllegalArgumentException();\n\n    if (concurrencyLevel > MAX_SEGMENTS) // 在大多数机器上，MAX_SEGMENTS=64\n        concurrencyLevel = MAX_SEGMENTS;\n\n    int sshift = 0;\n    int ssize = 1;\n    // ssize为segments的长度，为刚好不小于concurrencyLevel的正数，且为2的sshift次幂，即\n    // 2^(sshift-1) < concurrencyLevel <= 2^sshift = ssize\n    // 例如当concurrencyLevel=15时，有2^3 < 15 <= 2^4，因此sshift=4，ssize=16\n    while (ssize < concurrencyLevel) {\n        ++sshift;\n        ssize <<= 1;\n    }\n    this.segmentShift = 32 - sshift;\n    this.segmentMask = ssize - 1;\n\n    if (initialCapacity > MAXIMUM_CAPACITY)\n        initialCapacity = MAXIMUM_CAPACITY;\n    int c = initialCapacity / ssize;\n    if (c * ssize < initialCapacity)\n        ++c;\n    // 默认情况下，c=1\n    int cap = MIN_SEGMENT_TABLE_CAPACITY; // MIN_SEGMENT_TABLE_CAPACITY=2\n    // cap表示每个人Segment的容量(即table[]数组的长度)，Segment的容量必须是2的n次幂，最小值为2，满足2个条件：\n    // 1. (cap * ssize) >= (c * ssize) >= initialCapacity\n    // 2. cap = 2^n , n >= 1\n    // 确定cap，保证ConcurrentHashMap能容纳所有元素\n    while (cap < c)\n        cap <<= 1;\n\n    // 创建第一个Segment\n    // threshold = (int)(cap * loadFactor)\n    // table = (HashEntry<K,V>[])new HashEntry[cap]\n    Segment<K,V> s0 = new Segment<K,V>(loadFactor, (int)(cap * loadFactor),\n                                            (HashEntry<K,V>[])new HashEntry[cap]);\n    // 创建segments\n    Segment<K,V>[] ss = (Segment<K,V>[])new Segment[ssize];\n    UNSAFE.putOrderedObject(ss, SBASE, s0); // segments[0]=s0\n    this.segments = ss;\n}\n```\n\n执行`默认构造器`后，`ConcurrentHashMap的内存布局`如下图所示\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/chm7_constructer.png\" width=\"500\">\n\n## put(K key,V value)\n```java\n// From ConcurrentHashMap\npublic V put(K key, V value) {\n    Segment<K,V> s;\n    if (value == null)\n        throw new NullPointerException();\n    int hash = hash(key); // 计算key的hash值\n    int j = (hash >>> segmentShift) & segmentMask; // 获取段索引j，用于segments[j]\n    // UNSAFE.getObject不具有volatile语义，需要在ensureSegment方法中用volatile语义进行再次检验\n    if ((s = (Segment<K,V>)UNSAFE.getObject(segments, (j << SSHIFT) + SBASE)) == null)\n        // segments[j]尚未初始化，采用自旋+CAS的方式进行初始化，最后返回已经初始化的segments[j]\n        s = ensureSegment(j);\n\n    // 委托给Segment执行实际的put操作\n    return s.put(key, hash, value, false);\n}\n```\n\n### ensureSegment\n```java\n// From ConcurrentHashMap\n// 返回segments[k]，如果segments[k]尚未初始化，采用自旋+CAS的方式进行初始化\nprivate Segment<K,V> ensureSegment(int k) {\n    final Segment<K,V>[] ss = this.segments;\n    long u = (k << SSHIFT) + SBASE; // segments[k]的偏移量\n    Segment<K,V> seg;\n    // segments[k]，volatile读\n    if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) {\n        // segments[k]尚未初始化，采用segments[0]作为原型来初始化segments[k]\n        Segment<K,V> proto = ss[0];\n        int cap = proto.table.length;\n        float lf = proto.loadFactor;\n        int threshold = (int)(cap * lf);\n        HashEntry<K,V>[] tab = (HashEntry<K,V>[])new HashEntry[cap];\n        // segments[k]，volatile读\n        // 如果尚未初始化，才创建Segment，在竞争激烈时能减少开销\n        if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) {\n            Segment<K,V> s = new Segment<K,V>(lf, threshold, tab);\n            // 通过自旋+CAS设置segments[k]，直到segments[k]完成初始化\n            // 每次循环判断用volatile语义读取segments[k]\n            while ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) {\n                if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s))\n                    // 并发时，只有一个线程能竞争成功，直接退出循环，\n                    // 其他竞争失败的线程也会在下一次循环判断时直接退出\n                    // 因此只要segments[k]初始化，并发的线程都能很快退出自旋\n                    // 没有采用锁进行阻塞，而是只采用自旋+CAS，性能要更好\n                    break;\n            }\n        }\n    }\n    return seg;\n}\n```\n\n### put(K key,int hash,V value,boolean onlyIfAbsent)\n```java\n// From Segment\n// put操作的核心代码\nfinal V put(K key, int hash, V value, boolean onlyIfAbsent) {\n    HashEntry<K,V> node = tryLock() ? // 尝试抢占锁，Segment<K,V> extends ReentrantLock\n                      null : // 成功抢占锁\n                      // 抢占锁失败\n                      // scanAndLockForPut首先会定位节点，并尝试多次抢占锁，\n                      // 当抢占锁失败达到一定次数（默认64次）后，进入阻塞lock\n                      scanAndLockForPut(key, hash, value);\n\n    // 执行到这里，当前线程已经持有锁！\n    V oldValue;\n    try {\n        // table是volatile变量，禁止指令重排序，tab为局部变量，允许使用指令重排序来优化\n        HashEntry<K,V>[] tab = table;\n        int index = (tab.length - 1) & hash;\n        HashEntry<K,V> first = entryAt(tab, index); // 链表头结点，tab[index]\n        for (HashEntry<K,V> e = first;;) { // 自旋\n            if (e != null) {\n                K k;\n                if ((k = e.key) == key || (e.hash == hash && key.equals(k))) { // 命中\n                    oldValue = e.value;\n                    if (!onlyIfAbsent) {\n                        // put更新value，putIfAbsent直接返回\n                        e.value = value;\n                        ++modCount;\n                    }\n                    break;\n                }\n                e = e.next;\n            }\n            else { // 链表为空或已经遍历到了链表尾部依然没有命中，则新建节点并成为链表新的头结点\n                if (node != null)\n                    // 更新node的后继节点为链表原头结点\n                    node.setNext(first);\n                else\n                    // 新建节点node，并将node的后继节设置为链表原头结点\n                    node = new HashEntry<K,V>(hash, key, value, first);\n                int c = count + 1;\n                if (c > threshold && tab.length < MAXIMUM_CAPACITY)\n                    // 节点数超过阈值threshold，进行rehash\n                    rehash(node);\n                else\n                    // 节点数未超过阈值，将节点设置为链表头节点\n                    setEntryAt(tab, index, node);\n                ++modCount; // 修改次数\n                count = c; // 节点数量\n                oldValue = null;\n                break;\n            }\n        }\n    } finally {\n        unlock();\n    }\n    return oldValue;\n}\n```\n\n#### scanAndLockForPut\n```java\n// From Segment\n// tryLock失败后会执行scanAndLockForPut\n// 遍历链表，直到查找对应节点，如果没有对应节点就创建一个新节点，然后进入自旋tryLock\n// 自旋tryLock有次数限制，达到次数（默认64次）后进入阻塞lock\n// 在达到次数之前，如果发现链表头结点被修改了，则重新遍历链表并重新自旋tryLock\n// 上述过程中有可能会预先创建节点，这是为了避免在持有锁的期间再创建节点，提高性能，起到预热的作用\n// 如果没有命中，返回一个新节点；如果命中，返回null，返回时当前线程已经持有锁\nprivate HashEntry<K,V> scanAndLockForPut(K key, int hash, V value) {\n    // first为链表头结点：table[(tab.length - 1) & h)]\n    HashEntry<K,V> first = entryForHash(this, hash);\n    HashEntry<K,V> e = first; // e为迭代节点，从链表头结点开始\n    HashEntry<K,V> node = null; // 新节点\n    // 当retries=-1时，遍历链表，查找节点\n    // 当retries>=0时，尝试获取锁\n    int retries = -1;\n    while (!tryLock()) { // 获取锁失败，自旋tryLock，一定次数后阻塞lock\n        HashEntry<K,V> f;\n        if (retries < 0) { // 遍历链表，直到遍历结束或命中\n            if (e == null) {\n                if (node == null)\n                    // 创建一个新的节点\n                    node = new HashEntry<K,V>(hash, key, value, null);\n                retries = 0; // 遍历结束，准备开始有限次tryLock\n            }\n            else if (key.equals(e.key))\n                retries = 0; // 命中，结束遍历，准备开始有限次tryLock\n            else\n                e = e.next; // 尚未命中且遍历尚未结束，继续遍历\n            }\n        else if (++retries > MAX_SCAN_RETRIES) { // 大多数机器上，MAX_SCAN_RETRIES=64\n            // 超过最大重试次数（默认64次），采用lock()，阻塞线程，直到获得锁后退出循环\n            lock();\n            // 当前线程被唤醒后，持有锁，退出循环\n            break;\n        }\n        // 因为新节点会作为链表新的头结点，在并发时链表的头结点可能会发生变化\n        else if ((retries & 1) == 0 && (f = entryForHash(this, hash)) != first) {\n            e = first = f;\n            retries = -1; // 重新遍历链表，查找节点，并重新自旋tryLock\n        }\n    }\n    return node;\n}\n\n// 单核为1，多核为64\nstatic final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() > 1 ? 64 : 1;\n```\n\n##### entryForHash\n```java\n// From ConcurrentHashMap\n// 获取链表头节点：table[(tab.length - 1) & h)]\nstatic final <K,V> HashEntry<K,V> entryForHash(Segment<K,V> seg, int h) {\n    HashEntry<K,V>[] tab;\n    return (seg == null || (tab = seg.table) == null) ? null :\n        // table[(tab.length - 1) & h)]，volatile读\n        (HashEntry<K,V>) UNSAFE.getObjectVolatile(tab, ((long)(((tab.length - 1) & h)) << TSHIFT) + TBASE);\n}\n```\n\n#### entryAt\n```java\n// From ConcurrentHashMap\n// tab[i]，volatile读\nstatic final <K,V> HashEntry<K,V> entryAt(HashEntry<K,V>[] tab, int i) {\n    return (tab == null) ? null :\n        // tab[i]不具有volatile语义，所以这里采用getObjectVolatile\n        (HashEntry<K,V>) UNSAFE.getObjectVolatile(tab, ((long)i << TSHIFT) + TBASE);\n}\n```\n\n#### setNext\n```java\n// From HashEntry\nfinal void setNext(HashEntry<K,V> n) {\n    // 更新后继节点，延时写\n    // 因为在Segment中，执行setNext都必须先持有锁\n    // 当前线程持有锁，持有锁期间的修改无需让其他线程知道\n    // 而在锁释放时，会自动写入主内存，因此采用延时写，这样能提高性能！！\n    // 否则直接更新next，而next是volatile变量，会采用volatile写，反而增加开销\n    UNSAFE.putOrderedObject(this, nextOffset, n);\n}\n```\n\n#### setEntryAt\n```java\n// From Segment\nstatic final <K,V> void setEntryAt(HashEntry<K,V>[] tab, int i, HashEntry<K,V> e) {\n    // 更新链表头结点，延时写\n    // 延时写的原因与setNext类似，不再赘述\n    UNSAFE.putOrderedObject(tab, ((long)i << TSHIFT) + TBASE, e);\n}\n```\n\n#### rehash\n```java\n// From Segment\n// 重建Segment\nprivate void rehash(HashEntry<K,V> node) {\n    HashEntry<K,V>[] oldTable = table;\n    int oldCapacity = oldTable.length;\n    int newCapacity = oldCapacity << 1; // 扩容两倍\n    threshold = (int)(newCapacity * loadFactor);\n    HashEntry<K,V>[] newTable = (HashEntry<K,V>[]) new HashEntry[newCapacity];\n    int sizeMask = newCapacity - 1;\n    for (int i = 0; i < oldCapacity ; i++) { // 遍历旧链表\n        HashEntry<K,V> e = oldTable[i]; // 链表头结点\n        if (e != null) {\n            HashEntry<K,V> next = e.next; // 链表头结点的后继节点\n            int idx = e.hash & sizeMask;\n            if (next == null)\n                // 链表只有一个节点\n                newTable[idx] = e;\n            else {\n                HashEntry<K,V> lastRun = e;\n                int lastIdx = idx;\n                for (HashEntry<K,V> last = next; last != null; last = last.next) {\n                    int k = last.hash & sizeMask;\n                    if (k != lastIdx) {\n                        lastIdx = k;\n                        lastRun = last;\n                    }\n                }\n                // 遍历一遍链表，计算lastIdx和lastRun\n                // lastRun和其之后的所有节点的新索引都是lastIdx\n                // 直接设置newTable[lastIdx]=lastRun，减少重建工作\n                newTable[lastIdx] = lastRun;\n\n                // 重建lastRun之前的节点\n                for (HashEntry<K,V> p = e; p != lastRun; p = p.next) {\n                    V v = p.value;\n                    int h = p.hash;\n                    int k = h & sizeMask;\n                    HashEntry<K,V> n = newTable[k];\n                    // 新建节点，而非修改原先节点的next属性，\n                    // 这就保证了如果有其他线程在遍历原先的链表（如get操作），不会对其造成影响\n                    newTable[k] = new HashEntry<K,V>(h, p.key, v, n);\n                }\n            }\n        }\n    }\n    int nodeIndex = node.hash & sizeMask; // 增加新节点\n    node.setNext(newTable[nodeIndex]);\n    newTable[nodeIndex] = node;\n    table = newTable;\n}\n```\n\n### 逻辑示意图\n```java\npublic static void main(String[] args) {\n    ConcurrentHashMap<String, Integer> map = new ConcurrentHashMap<>();\n    map.put(\"zhongmingmao\", 1);\n}\n```\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/chm7_put.png\" width=\"500\">\n\n## remove(Object key)\n```java\n// From ConcurrentHashMap\npublic V remove(Object key) {\n    int hash = hash(key);\n    Segment<K,V> s = segmentForHash(hash); // segments[((h >>> segmentShift) & segmentMask)]\n    // 委托给Segment执行实际的remove操作\n    return s == null ? null : s.remove(key, hash, null);\n}\n```\n\n### segmentForHash\n```java\n// From ConcurrentHashMap\nprivate Segment<K,V> segmentForHash(int h) {\n    long u = (((h >>> segmentShift) & segmentMask) << SSHIFT) + SBASE;\n    // segments[((h >>> segmentShift) & segmentMask)]，volatile读\n    return (Segment<K,V>) UNSAFE.getObjectVolatile(segments, u);\n}\n```\n\n### remove(Object key, int hash, Object value)\n```java\n// From Segment\n// remove操作的核心操作\nfinal V remove(Object key, int hash, Object value) {\n    if (!tryLock())\n        scanAndLock(key, hash);\n\n    // 执行到这里，当前线程已经持有锁！\n    V oldValue = null;\n    try {\n        HashEntry<K,V>[] tab = table;\n        int index = (tab.length - 1) & hash;\n        HashEntry<K,V> e = entryAt(tab, index); // 迭代节点，从链表头结点开始\n        HashEntry<K,V> pred = null; // e的\"前驱节点\"\n        while (e != null) {\n            K k;\n            HashEntry<K,V> next = e.next;\n            if ((k = e.key) == key || (e.hash == hash && key.equals(k))) {\n                V v = e.value;\n                if (value == null || value == v || value.equals(v)) { // 命中\n                    if (pred == null)\n                        // 待删除的节点是链表头结点，直接设置待删除节点的后继节点为新的头结点\n                        // 即 tab[index] = next\n                        setEntryAt(tab, index, next);\n                    else\n                        // 待删除的节点不是链表头结点，直接更新\"前驱节点\"的后继节点为待删除节点的后继节点\n                        pred.setNext(next);\n                    ++modCount; // 修改次数\n                    --count; // 节点数量\n                    oldValue = v;\n                }\n                break;\n            }\n            pred = e;\n            e = next;\n        }\n    } finally {\n        unlock();\n    }\n    return oldValue;\n}\n```\n\n#### scanAndLock\n```java\n// From Segment\n// 与scanAndLockForPut非常类似，只是少了创建节点而已，不再赘述\nprivate void scanAndLock(Object key, int hash) {\n    HashEntry<K,V> first = entryForHash(this, hash);\n    HashEntry<K,V> e = first;\n    int retries = -1;\n    while (!tryLock()) {\n        HashEntry<K,V> f;\n        if (retries < 0) {\n            if (e == null || key.equals(e.key))\n            retries = 0;\n            else\n            e = e.next;\n        }\n        else if (++retries > MAX_SCAN_RETRIES) {\n            lock();\n            break;\n        }\n        else if ((retries & 1) == 0 && (f = entryForHash(this, hash)) != first) {\n            e = first = f;\n            retries = -1;\n        }\n    }\n}\n```\n\n## get(Object key)\n```java\n// From ConcurrentHashMap\n// 代码非常简单，需要注意的是，get操作不需要先持有锁的！！\n// 在put操作中我们知道，新节点时在链表头，并未修改原节点next属性，不影响get操作中遍历\n// 另外put操作中假如触发rehash，根据上面分析可知，新旧链表是可以同时存在的，也同样不影响get操作中遍历\n// 在remove操作中，最极端的情况是，remove线程要删除的节点的后继节点即为get线程要查询的节点，\n// 哪怕remove线程和get线程同时位于待删除的节点，但由于remove线程仅仅修改\"前驱节点\"的next属性，并不影响get操作中遍历\n// 因此在ConcurrentHashMap中的get操作并不是\"完全实时\"的！！\npublic V get(Object key) {\n    Segment<K,V> s;\n    HashEntry<K,V>[] tab;\n    int h = hash(key);\n    long u = (((h >>> segmentShift) & segmentMask) << SSHIFT) + SBASE;\n    if ((s = (Segment<K,V>)UNSAFE.getObjectVolatile(segments, u)) != null\n                                                        && (tab = s.table) != null) {\n        for (HashEntry<K,V> e = (HashEntry<K,V>) UNSAFE.getObjectVolatile\n                            (tab, ((long)(((tab.length - 1) & h)) << TSHIFT) + TBASE);\n                        e != null;\n                        e = e.next) {\n            K k;\n            if ((k = e.key) == key || (e.hash == h && key.equals(k)))\n                return e.value;\n        }\n    }\n    return null;\n}\n```\n\n## clear()\n```java\n// From ConcurrentHashMap\npublic void clear() {\n    final Segment<K,V>[] segments = this.segments;\n    // 遍历segments，逐个加锁解锁，但不会一次性锁定整个ConcurrentHashMap（所有Segment）\n    for (int j = 0; j < segments.length; ++j) {\n        Segment<K,V> s = segmentAt(segments, j); // segments[j]\n        if (s != null)\n            s.clear();\n    }\n}\n```\n\n### segmentAt\n```java\n// From ConcurrentHashMap\nstatic final <K,V> Segment<K,V> segmentAt(Segment<K,V>[] ss, int j) {\n    long u = (j << SSHIFT) + SBASE;\n    // ss[j]，volatile读\n    return ss == null ? null : (Segment<K,V>) UNSAFE.getObjectVolatile(ss, u);\n}\n```\n\n### clear\n```java\n// From Segment\n// 对整个Segment进行操作，自旋获得锁的可能性不大，放弃自旋tryLock，直接lock\nfinal void clear() {\n    lock();\n    try {\n        HashEntry<K,V>[] tab = table;\n        for (int i = 0; i < tab.length ; i++)\n            setEntryAt(tab, i, null); // tab[i] = null，置空链表\n        ++modCount;\n        count = 0; // 节点数量置为0\n    } finally {\n        unlock();\n    }\n}\n```\n\n## size()\n```java\n// From ConcurrentHashMap\n// 先尝试若干次无锁比较，如果都失败，升级为持有所有Segment的锁，锁定整个ConcurrentHashMap\npublic int size() {\n    final Segment<K,V>[] segments = this.segments;\n    int size;\n    boolean overflow; // 是否溢出\n    long sum;         // 修改次数\n    long last = 0L;   // 上次的修改次数\n    int retries = -1;\n    try {\n        for (;;) {\n            if (retries++ == RETRIES_BEFORE_LOCK) { // 默认RETRIES_BEFORE_LOCK=2\n                // 失败若干次后，升级为持有所有Segment的锁，锁定整个ConcurrentHashMap\n                for (int j = 0; j < segments.length; ++j)\n                    ensureSegment(j).lock();\n            }\n            sum = 0L;\n            size = 0;\n            overflow = false;\n            for (int j = 0; j < segments.length; ++j) {\n                Segment<K,V> seg = segmentAt(segments, j); // segments[j]\n                if (seg != null) {\n                    sum += seg.modCount;\n                    int c = seg.count;\n                    if (c < 0 || (size += c) < 0)\n                        overflow = true;\n                }\n            }\n            if (sum == last)\n                // 只有前后两次的修改次数一致，才退出循环，执行finally\n                break;\n            last = sum;\n        }\n    } finally {\n        if (retries > RETRIES_BEFORE_LOCK) { // 代表曾经上锁，需要释放锁\n            for (int j = 0; j < segments.length; ++j)\n                segmentAt(segments, j).unlock();\n        }\n    }\n\n    // 溢出就返回Integer.MAX_VALUE，感觉有点奇怪\n    return overflow ? Integer.MAX_VALUE : size;\n}\n```\n\n\n<!-- indicate-the-source -->\n","tags":["JUC"],"categories":["Concurrent"]},{"title":"Java并发 -- Semaphore","url":"%2F2016%2F08%2F18%2Fconcurrent-semaphore%2F","content":"\n{% note info %}\n本文将通过剖析`Semaphore`的源码来介绍其实现原理\n关于`CountDownLatch`的基本内容请参考「并发 - JUC - CountDownLatch - 源码剖析」，本文不再赘述\n{% endnote %}\n\n<!-- more -->\n\n# 基础\n1. `Semaphore`与`CountDownLatch`非常类似，都是基于`AQS`的`共享模式`，`CountDownLatch`可以大致理解为`简化版的Semaphore`\n2. `CountDownLatch.await`等待的是`state=0`，`Semaphore.acquire`（如果需要等待）等待的是`Semaphore.release`\n3. `Semaphore`与`CountDownLatch`的源码非常类似，因此有些共通或类似的代码不再重复分析\n\n# 源码分析\n\n## 构造函数\n```java\n// 与ReentrantLock非常类似，默认是非公平策略\n// permits：允许颁发的许可\npublic Semaphore(int permits) {\n    sync = new NonfairSync(permits);\n}\n\npublic Semaphore(int permits, boolean fair) {\n    sync = fair ? new FairSync(permits) : new NonfairSync(permits);\n}\n```\n\n## acquireUninterruptibly\n```java\n// From Semaphore\n// acquire方法列表，实现都非常类似，本文仅分析acquireUninterruptibly\npublic void acquire() throws InterruptedException\npublic void acquire(int permits) throws InterruptedException\npublic void acquireUninterruptibly()\npublic void acquireUninterruptibly(int permits)\n```\n```java\n// From Semaphore\n// 请求一个许可，不响应中断\npublic void acquireUninterruptibly() {\n    sync.acquireShared(1);\n}\n```\n\n### acquireShared\n```java\n// From AQS\npublic final void acquireShared(int arg) {\n    // 自旋获取许可，满足特定条件后退出自旋\n    if (tryAcquireShared(arg) < 0)\n        // 有排队更久的线程或剩余可颁发的许可需要不满足需求，进入同步队列等待\n        doAcquireShared(arg);\n}\n```\n\n#### tryAcquireShared\n```java\n// From FairSync\n// 公平策略\n// 请求共享锁，剩余可颁发的许可满足需求并且并发抢占（CAS）许可成功，才算持有共享锁\n// 自旋获取许可，退出自旋需要满足3个条件之一：\n// 1. 有排队更久的线程（需要进入同步队列进行等待）\n// 2. 剩余可颁发的许可不满足需求（需要进入同步队列进行等待）\n// 3. 剩余可颁发的许可满足需求并且并发抢占（CAS）许可成功\nprotected int tryAcquireShared(int acquires) {\n    for (;;) {\n        // 与非公平策略的唯一区别是：先判断是否有排队时间更久的线程，如果有，退出自旋，进入同步队列\n        if (hasQueuedPredecessors())\n            return -1; // 有排队更久的线程（需要进入同步队列进行等待）\n        int available = getState(); // 剩余可颁发的许可\n        int remaining = available - acquires;\n        if (remaining < 0 || compareAndSetState(available, remaining))\n            // 1. available < acquires ➔ 剩余可颁发的许可不满足需求（需要进入同步队列进行等待）\n            // 2. available >= acquires && compareAndSetState(available, remaining)\n            //                      ➔ 剩余可颁发的许可满足需求并且并发抢占（CAS）许可成功\n            return remaining;\n    }\n}\n// From AQS\npublic final boolean hasQueuedPredecessors() {\n    Node t = tail;\n    Node h = head;\n    Node s;\n    return h != t && ((s = h.next) == null || s.thread != Thread.currentThread());\n}\n```\n```java\n// From NonfairSync\n// 非公平策略\nprotected int tryAcquireShared(int acquires) {\n    return nonfairTryAcquireShared(acquires);\n}\n// From AQS\nfinal int nonfairTryAcquireShared(int acquires) {\n    for (;;) {\n        // 与公平策略比较，仅仅少了hasQueuedPredecessors的判断\n        int available = getState();\n        int remaining = available - acquires;\n        if (remaining < 0 || compareAndSetState(available, remaining))\n            return remaining;\n    }\n}\n```\n\n#### doAcquireShared\n```java\n// From AQS\n// 这段代码与「并发 - JUC - CountDownLatch - 源码剖析」中分析的doAcquireSharedInterruptibly类似，不再赘述\n// 请求共享锁，以广播的方式唤醒线程，被唤醒的线程竞争许可，竞争失败则进行休眠，等待下一轮唤醒\nprivate void doAcquireShared(int arg) {\n    final Node node = addWaiter(Node.SHARED);\n    boolean failed = true;\n    try {\n        boolean interrupted = false;\n        for (;;) {\n            final Node p = node.predecessor();\n            if (p == head) {\n                // 1. CountDownLatch中持有共享锁的条件：state==0。而在CountDownLatch中，state一旦为0，\n                //    则不会再改变，因此，被唤醒的线程必然会持有共享锁\n                // 2. Semaphore中中持有共享锁的条件：剩余可颁发的许可满足需求并且并发抢占（CAS）许可成功。\n                //    而许可是有限的，因此所以被唤醒的线程不一定会持有共享锁，将再次休眠\n                int r = tryAcquireShared(arg);\n                if (r >= 0) { // 持有共享锁\n                    setHeadAndPropagate(node, r);\n                    p.next = null;\n                    if (interrupted)\n                        selfInterrupt();\n                    failed = false;\n                    return;\n                }\n            }\n            if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt())\n                interrupted = true;\n        }\n    } finally {\n        if (failed)\n            cancelAcquire(node);\n    }\n}\n```\n\n## release\n```java\n// From Semaphore\npublic void release() {\n    sync.releaseShared(1);\n}\n```\n\n### releaseShared\n```java\n// From AQS\npublic final boolean releaseShared(int arg) {\n    // 以自旋的方式返回许可\n    if (tryReleaseShared(arg)) {\n        // 以广播的方式唤醒线程\n        doReleaseShared();\n        return true;\n    }\n    return false;\n}\n```\n\n#### tryReleaseShared\n```java\n// From Semaphore\n// 以自旋的方式返回许可\n// 自旋state+releases，直到CAS成功或溢出\nprotected final boolean tryReleaseShared(int releases) {\n    for (;;) {\n        int current = getState();\n        int next = current + releases;\n        if (next < current) // 溢出\n            throw new Error(\"Maximum permit count exceeded\");\n        if (compareAndSetState(current, next))\n            return true;\n    }\n}\n```\n现在回顾下`CountDownLatch`中`tryReleaseShared`的具体实现，没有用到参数`releases`，直接采用\"`-1`\"\n```java\n// From CountDownLatch\n// 自旋state-1，如果刚好是1->0，返回true\nprotected boolean tryReleaseShared(int releases) {\n    for (;;) {\n        int c = getState();\n        if (c == 0)\n            return false;\n        int nextc = c-1;\n        if (compareAndSetState(c, nextc))\n            return nextc == 0;\n    }\n}\n```\n\n#### doReleaseShared\n```java\n// From AQS\n// 这段代码在博文「并发 - JUC - CountDownLatch - 源码剖析」已经分析过了，非常晦涩，不再赘述\n// 以广播的方式唤醒线程\nprivate void doReleaseShared() {\n    for (;;) {\n        Node h = head;\n        if (h != null && h != tail) {\n        int ws = h.waitStatus;\n        if (ws == Node.SIGNAL) {\n            if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))\n                continue;\n            unparkSuccessor(h);\n        }\n        else if (ws == 0 && !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))\n            continue;\n        }\n        if (h == head)\n            break;\n    }\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["AQS"],"categories":["Concurrent"]},{"title":"Java并发 -- CyclicBarrier","url":"%2F2016%2F08%2F17%2Fconcurrent-cyclicbarrier%2F","content":"\n{% note info %}\n本文将通过剖析`CyclicBarrier`的源码来介绍其实现原理\n代码托管在https://github.com/zhongmingmao/concurrent_demo\n关于`ReentrantLock`的基本内容请参考「并发 - JUC - ReentrantLock - 源码剖析」，本文不再赘述\n关于`ConditionObject`的基本内容请参考「并发 - JUC - ConditionObject - 源码剖析」，本文不再赘述\n关于`CountDownLatch`的基本内容请参考「并发 - JUC - CountDownLatch - 源码剖析」，本文不再赘述\n{% endnote %}\n\n<!-- more -->\n\n# 基础\n`CyclicBarrier`可以大致理解为`可重复使用的CountDownLatch`，但`CountDownLatch`是基于`AQS的共享模式`，而`CyclicBarrier`则是基于`AQS的独占模式`（实际为`ReentrantLock`和`ConditionObject`）\n\n# 源码分析\n\n## 核心结构\n```java\npublic class CyclicBarrier {\n    // CyclicBarrier是可重复使用的，Generation标识一代\n    private static class Generation {\n        // CyclicBarrier是否处于broken状态，初始值为false\n        boolean broken = false;\n    }\n    // lock用于控制进入CyclicBarrier\n    private final ReentrantLock lock = new ReentrantLock();\n    // CyclicBarrier基于Condition\n    // 越过CyclicBarrier的条件：一定数量（parties）的线程到达了CyclicBarrier\n    private final Condition trip = lock.newCondition();\n    // 参与的线程数\n    private final int parties;\n    // 在越过CyclicBarrier之前要执行的动作\n    private final Runnable barrierCommand;\n    // 当前代\n    private Generation generation = new Generation();\n    // 还未到达CyclicBarrier的线程数\n    private int count;\n\n    public CyclicBarrier(int parties) {\n        this(parties, null);\n    }\n\n    public CyclicBarrier(int parties, Runnable barrierAction) {\n        if (parties <= 0) throw new IllegalArgumentException();\n        this.parties = parties;\n        this.count = parties; // count初始值为parties\n        this.barrierCommand = barrierAction;\n    }\n```\n\n## nextGeneration\n```java\n// 唤醒当代所有线程，并开启新一代\n// 因为需要调用trip.signalAll()，所以需要先持有lock\n// 触发时机：最后一个线程到达CyclicBarrier或调用reset()\nprivate void nextGeneration() {\n    trip.signalAll();\n    count = parties; // 重置count为parties\n    generation = new Generation();\n}\n```\n\n## breakBarrier\n```java\n// 标记当代已经被打破，并唤醒当代所有线程\n// 因为需要调用trip.signalAll()，所以需要先持有lock\nprivate void breakBarrier() {\n    generation.broken = true;\n    count = parties; // 重置count为parties\n    trip.signalAll();\n}\n```\n\n## reset\n```java\n// 重置CyclicBarrier为初始化状态：标记当代已经被打破 + 唤醒当代所有线程 + 并开启新一代\n// 需要先持有lock\npublic void reset() {\n    final ReentrantLock lock = this.lock;\n    lock.lock();\n    try {\n        breakBarrier();\n        nextGeneration();\n    } finally {\n        lock.unlock();\n    }\n}\n```\n\n## getNumberWaiting\n```java\n// 已经到达CyclicBarrier的线程数 = 参与的线程数 - 还未到达CyclicBarrier的线程数\n// = parties - count\npublic int getNumberWaiting() {\n    final ReentrantLock lock = this.lock;\n    lock.lock();\n    try {\n        return parties - count;\n    } finally {\n        lock.unlock();\n    }\n}\n```\n\n## isBroken\n```java\n// CyclicBarrier是否处于broken状态\npublic boolean isBroken() {\n    final ReentrantLock lock = this.lock;\n    lock.lock();\n    try {\n        return generation.broken;\n    } finally {\n        lock.unlock();\n    }\n}\n```\n\n## await(long timeout,TimeUnit unit)\n```java\npublic int await(long timeout, TimeUnit unit)\n                    throws InterruptedException,\n                           BrokenBarrierException,\n                           TimeoutException {\n    return dowait(true, unit.toNanos(timeout));\n}\n```\n\n### dowait(boolean timed,long nanos)\n**核心代码**\n```java\nprivate int dowait(boolean timed, long nanos)\n                    throws InterruptedException,\n                           BrokenBarrierException,\n                           TimeoutException {\n    final ReentrantLock lock = this.lock;\n    lock.lock(); // 首先持有锁lock\n    try {\n        final Generation g = generation; // 获取当前代\n\n        if (g.broken)\n            // 如果CyclicBarrier处于broken状态，直接抛出BrokenBarrierException\n            // 例如CyclicBarrier(3)，线程A.await()被中断会执行breakBarrier()\n            // 线程B.await()执行到这里，直接抛出BrokenBarrierException\n            throw new BrokenBarrierException();\n\n        if (Thread.interrupted()) {\n            // 如果线程被中断，则标记当代已经被打破，并唤醒当代所有线程，最后抛出InterruptedException\n            breakBarrier();\n            throw new InterruptedException();\n        }\n\n        // 当前线程调用了await()，表示当前线程到达了CyclicBarrier\n        // count：当前线程到达CyclicBarrier之前，还未到达CyclicBarrier的线程数\n        // index：当前线程到达CyclicBarrier之后，还未到达CyclicBarrier的线程数\n        int index = --count;\n\n        // ===== 最后一个线程到达了CyclicBarrier\n        // 如果执行barrierCommand的过程中无异常，执行nextGeneration\n        // 如果执行barrierCommand的过程中抛出异常，执行breakBarrier\n        if (index == 0) {\n            // ranAction：执行barrierCommand是否有抛出异常，初始值为false\n            boolean ranAction = false;\n            try {\n                // barrierCommand：最后一个到达CyclicBarrier后，在越过CyclicBarrier之前要执行的动作\n                final Runnable command = barrierCommand;\n                if (command != null)\n                    command.run();\n                // 执行到这里，说明 无需执行command 或 执行command的过程中没有抛出异常\n                ranAction = true;\n                // 唤醒当代所有线程，并开启新一代\n                nextGeneration();\n                return 0; // 最后一个线程已经到达了CyclicBarrier + 运行Command无异常\n            } finally {\n                if (!ranAction)\n                    // ranAction=false：说明执行barrierCommand的过程中抛出了异常\n                    // 需要标记当代已经被打破，并唤醒当代所有线程，被唤醒的线程将抛出BrokenBarrierException\n                    breakBarrier();\n            }\n        }\n\n        // ===== 最后一个线程尚未到达CyclicBarrier，当前线程进入自旋等待\n        // 执行到这里，说明当前线程不是最后一个到达CyclicBarrier的线程，进入自旋等待，直到下面3种情况发生：\n        // 1. 当前线程被中断\n        // 2. 当前线程被唤醒\n        //    2.1 最后一个线程到达CyclicBarrier后，运行Command无异常，在nextGeneration()中唤醒当代的所有线程\n        //    2.2 最后一个线程到达CyclicBarrier后，运行Command发生异常，在breakBarrier()中唤醒当代的所有线程\n        //    2.3 其他线程执行reset方法\n        // 3. 超时\n        for (;;) { // 自旋等待\n            try {\n                if (!timed)\n                    trip.await();\n                else if (nanos > 0L)\n                    // nanos == deadline - System.nanoTime()\n                    nanos = trip.awaitNanos(nanos);\n            } catch (InterruptedException ie) {\n                // 当前线程由于中断而退出休眠状态\n                if (g == generation && !g.broken) {\n                    // 执行到这里，说明没有开启新一代且当前代没有被标记为已打破\n                    // 而当前线程属于当代，如果当前线程被中断，那当代也就没有意义了\n                    // 所以标记当代已经被打破，并唤醒当代所有线程，其他线程被唤醒后会抛出BrokenBarrierException\n                    // 最后当前线程抛出InterruptedException\n                    breakBarrier();\n                    throw ie;\n                } else {\n                    // 执行到这里有2种情况\n                    // 1. g!=generation，说明已经开启了新的一代，而能对generation赋值的方法只有nextGeneration()，\n                    //    而能调用的nextGeneration()只有dowait(boolean timed,long nanos)和reset()方法\n                    //    1.1 dowait(boolean timed,long nanos)中是由于最后一个线程到达了CyclicBarrier而触发nextGeneration()，\n                    //        就是当前线程被中断的时候，最后一个线程也到达了CyclicBarrier，因此无需再抛出InterruptedException，\n                    //        这里只需要设置中断状态即可\n                    //    1.2 reset()，即当前线程被中断的时候，其他线程触发了reset()，会将CyclicBarrier置为broken状态\n                    //        应该由后续代码抛出BrokenBarrierException，这里只需要设置中断状态即可\n                    // 2. g.broken==true，能对generation.broken赋值的方法只有breakBarrier()，\n                    //    说明CyclicBarrier已经处于broken状态，应该由后续代码抛出BrokenBarrierException，这里只需要设置中断状态即可\n                    //\n                    // 总结：\n                    // 1. g != generation，已经开启新的一代，不能执行breakBarrier，这会让新一代处于Broken状态，当前线程被中断，只需当前线\n                    //    程归属的一代处于Broken状态既可\n                    // 2. g.broken，说明已经有与当前线程同属于同一代的线程触发了breakBarrier，无需再次触发，当前线程应该在后续代码抛出BrokenBarrierException\n                    Thread.currentThread().interrupt();\n                }\n            }\n\n            if (g.broken)\n                // 如果检测到CyclicBarrier是否处于broken状态，那么抛出BrokenBarrierException异常\n                throw new BrokenBarrierException();\n\n            if (g != generation)\n                // 已经开启了新一代，可以退出自旋\n                return index;\n\n            // 执行到这里说明g.broken==false && g==generation，因此考虑超时限制\n            if (timed && nanos <= 0L) {\n                // 如果超时了，标记当代已经被打破，并唤醒当代所有线程，最后抛出TimeoutException\n                breakBarrier();\n                throw new TimeoutException();\n            }\n        }\n\n    } finally {\n        lock.unlock(); // 最终释放锁\n    }\n}\n```\n\n# 常见场景\n\n## 正常流程\n```java\n/**\n * CyclicBarrier正常流程\n */\npublic class CyclicBarrierNormal {\n    private static final int THREAD_COUNT = 3;\n\n    private static CyclicBarrier barrier = new CyclicBarrier(THREAD_COUNT, () -> {\n        log(\"run barrierCommand\");\n    });\n\n    private static Runnable awaitRunnable = () -> {\n        try {\n            log(\"before barrier.await()\");\n            barrier.await();\n            log(\"after barrier.await()\");\n        } catch (InterruptedException | BrokenBarrierException e) {\n            log(e.getClass().getCanonicalName());\n        }\n    };\n\n    public static void main(String[] args) throws InterruptedException {\n        ExecutorService pool = Executors.newFixedThreadPool(THREAD_COUNT);\n        IntStream.range(0, THREAD_COUNT).forEach(value -> {\n            pool.submit(awaitRunnable);\n        });\n        pool.shutdown();\n        /*\n        输出：\n        pool-1-thread-1 before barrier.await()\n        pool-1-thread-3 before barrier.await()\n        pool-1-thread-2 before barrier.await()\n        pool-1-thread-2 run barrierCommand\n        pool-1-thread-1 after barrier.await()\n        pool-1-thread-3 after barrier.await()\n        pool-1-thread-2 after barrier.await()\n         */\n    }\n\n    private static void log(final String msg) {\n        System.out.println(String.format(\"%s %s\", Thread.currentThread().getName(), msg));\n    }\n}\n```\n\n## barrierCommand抛出异常\n```java\n/**\n * 验证barrierCommand抛出异常的场景\n */\npublic class CyclicBarrierCommandException {\n    private static final int THREAD_COUNT = 3;\n\n    private static CyclicBarrier barrier = new CyclicBarrier(THREAD_COUNT, () -> {\n        // 最后一个到达barrier的线程后会先执行barrierCommand\n        // barrierCommand抛出异常，最后一个线程唤醒其他所有线程\n        // 其他线程被唤醒后抛出BrokenBarrierException\n        log(\"run barrierCommand , throw BarrierCommandException\");\n        throw new RuntimeException(\"BarrierCommandException\");\n    });\n\n    private static Runnable awaitRunnable = () -> {\n        try {\n            log(\"before barrier.await()\");\n            barrier.await();\n            log(\"after barrier.await()\");\n        } catch (InterruptedException | BrokenBarrierException e) {\n            log(e.getClass().getCanonicalName());\n        }\n    };\n\n    public static void main(String[] args) throws InterruptedException {\n        ExecutorService pool = Executors.newFixedThreadPool(THREAD_COUNT);\n        IntStream.range(0, THREAD_COUNT).forEach(value -> {\n            pool.submit(awaitRunnable);\n        });\n        pool.shutdown();\n        pool.awaitTermination(10, TimeUnit.SECONDS);\n\n        // 此时barrier处于broken状态，调用await()会直接抛出BrokenBarrierException\n        new Thread(awaitRunnable, \"t1\").start();\n        TimeUnit.MILLISECONDS.sleep(100);\n        // 重置barrier到初始状态\n        // generation = new Generation()，为非Broken状态\n        barrier.reset();\n        new Thread(awaitRunnable, \"t2\").start(); // 不会抛出异常\n        /*\n        输出：\n        pool-1-thread-1 before barrier.await()\n        pool-1-thread-2 before barrier.await()\n        pool-1-thread-3 before barrier.await()\n        pool-1-thread-3 run barrierCommand , throw BarrierCommandException\n        pool-1-thread-1 java.util.concurrent.BrokenBarrierException\n        pool-1-thread-2 java.util.concurrent.BrokenBarrierException\n        t1 before barrier.await()\n        t1 java.util.concurrent.BrokenBarrierException\n        t2 before barrier.await()\n         */\n    }\n\n    private static void log(final String msg) {\n        System.out.println(String.format(\"%s %s\", Thread.currentThread().getName(), msg));\n    }\n}\n```\n\n## await()前被中断\n```java\n/**\n * 验证await()前被中断线程的场景\n */\npublic class CyclicBarrierInterruptBeforeAwait {\n    private static final int THREAD_COUNT = 3;\n    private static final String SELF_INTERRUPT_THREAD_NAME = \"selfInterruptThread\";\n\n    private static CyclicBarrier barrier = new CyclicBarrier(THREAD_COUNT, () -> {\n        log(\"run barrierCommand\");\n    });\n\n    private static Runnable awaitRunnable = () -> {\n        try {\n            if (SELF_INTERRUPT_THREAD_NAME.equals(Thread.currentThread().getName())) {\n                Thread.currentThread().interrupt();\n                log(\"self interrupt\");\n            }\n            // 设置了中断,await()方法会标记当代已经被打破，并唤醒当代所有线程，最后抛出InterruptedException\n            // 被唤醒的线程会抛出BrokenBarrierException\n            log(\"before barrier.await()\");\n            barrier.await();\n            log(\"after barrier.await()\");\n        } catch (InterruptedException | BrokenBarrierException e) {\n            log(e.getClass().getCanonicalName());\n        }\n    };\n\n    public static void main(String[] args) throws InterruptedException {\n        ExecutorService pool = Executors.newFixedThreadPool(THREAD_COUNT);\n        IntStream.range(0, THREAD_COUNT - 1).forEach(value -> {\n            pool.submit(awaitRunnable);\n        });\n        pool.shutdown();\n        pool.awaitTermination(5, TimeUnit.SECONDS);\n\n        new Thread(awaitRunnable, SELF_INTERRUPT_THREAD_NAME).start();\n        /*\n        输出：\n        pool-1-thread-2 before barrier.await()\n        pool-1-thread-1 before barrier.await()\n        selfInterruptThread self interrupt\n        selfInterruptThread before barrier.await()\n        selfInterruptThread java.lang.InterruptedException\n        pool-1-thread-2 java.util.concurrent.BrokenBarrierException\n        pool-1-thread-1 java.util.concurrent.BrokenBarrierException\n         */\n    }\n\n    private static void log(final String msg) {\n        System.out.println(String.format(\"%s %s\", Thread.currentThread().getName(), msg));\n    }\n}\n```\n\n## await()后被中断\n```java\n/**\n * 验证await()后中断线程的场景\n */\npublic class CyclicBarrierInterruptAfterAwait {\n    private static final int THREAD_COUNT = 4;\n\n    private static CyclicBarrier barrier = new CyclicBarrier(THREAD_COUNT, () -> {\n        log(\"run barrierCommand\");\n    });\n\n    private static Runnable awaitRunnable = () -> {\n        try {\n            log(\"before barrier.await()\");\n            barrier.await();\n            log(\"after barrier.await()\");\n        } catch (InterruptedException | BrokenBarrierException e) {\n            log(e.getClass().getCanonicalName());\n        }\n    };\n\n    public static void main(String[] args) throws InterruptedException {\n        Thread t1 = new Thread(awaitRunnable, \"t1\");\n        Thread t2 = new Thread(awaitRunnable, \"t2\");\n        Thread t3 = new Thread(awaitRunnable, \"t3\");\n\n        t1.start();\n        t2.start();\n        t3.start();\n        TimeUnit.MILLISECONDS.sleep(100);\n        // t3被中断，唤醒其他线程，最后抛出InterruptedException\n        // 被唤醒的线程抛出BrokenBarrierException\n        t3.interrupt();\n        /*\n        输出：\n        t1 before barrier.await()\n        t3 before barrier.await()\n        t2 before barrier.await()\n        t2 java.util.concurrent.BrokenBarrierException\n        t1 java.util.concurrent.BrokenBarrierException\n        t3 java.lang.InterruptedException\n         */\n    }\n\n    private static void log(final String msg) {\n        System.out.println(String.format(\"%s %s\", Thread.currentThread().getName(), msg));\n    }\n}\n```\n\n## reset\n```java\n/**\n * 验证还有未到达线程时，触发reset的场景\n */\npublic class CyclicBarrierReset {\n    private static final int THREAD_COUNT = 3;\n\n    private static CyclicBarrier barrier = new CyclicBarrier(THREAD_COUNT, () -> {\n        log(\"run barrierCommand\");\n    });\n\n    private static Runnable awaitRunnable = () -> {\n        try {\n            log(\"before barrier.await()\");\n            barrier.await();\n            log(\"after barrier.await()\");\n        } catch (InterruptedException | BrokenBarrierException e) {\n            log(e.getClass().getCanonicalName());\n        }\n    };\n\n    public static void main(String[] args) throws InterruptedException {\n        ExecutorService pool = Executors.newFixedThreadPool(THREAD_COUNT);\n        IntStream.range(0, THREAD_COUNT - 1).forEach(value -> {\n            pool.submit(awaitRunnable);\n        });\n        pool.shutdown();\n        pool.awaitTermination(5, TimeUnit.SECONDS);\n\n        // reset : 标记当代已经被打破 + 唤醒当代所有线程 + 并开启新一代\n        // 被唤醒的线程将抛出BrokenBarrierException\n        barrier.reset();\n        /*\n        输出：\n        pool-1-thread-2 before barrier.await()\n        pool-1-thread-1 before barrier.await()\n        pool-1-thread-2 java.util.concurrent.BrokenBarrierException\n        pool-1-thread-1 java.util.concurrent.BrokenBarrierException\n         */\n    }\n\n    private static void log(final String msg) {\n        System.out.println(String.format(\"%s %s\", Thread.currentThread().getName(), msg));\n    }\n}\n```\n\n## 超时\n```java\n/**\n * 验证超时的场景\n */\npublic class CyclicBarrierTimeoutException {\n    private static final String TIMED_AWAITED_THREAD = \"timed_awaited_thread\";\n    private static final int THREAD_COUNT = 4;\n\n    private static CyclicBarrier barrier = new CyclicBarrier(THREAD_COUNT);\n\n    private static Runnable awaitRunnable = () -> {\n        try {\n            log(\"before barrier.await()\");\n            if (TIMED_AWAITED_THREAD.equals(Thread.currentThread().getName())) {\n                // 超时会标记当代已经被打破，并唤醒当代所有线程，最终抛出TimeoutException\n                // 被唤醒的线程抛出BrokenBarrierException\n                barrier.await(5, TimeUnit.SECONDS);\n            } else {\n                barrier.await();\n            }\n\n            log(\"after barrier.await()\");\n        } catch (InterruptedException | BrokenBarrierException | TimeoutException e) {\n            log(e.getClass().getCanonicalName());\n        }\n    };\n\n    public static void main(String[] args) throws InterruptedException {\n        ExecutorService pool = Executors.newFixedThreadPool(THREAD_COUNT);\n        IntStream.range(0, THREAD_COUNT - 2).forEach(value -> {\n            pool.submit(awaitRunnable);\n        });\n        pool.shutdown();\n        new Thread(awaitRunnable, TIMED_AWAITED_THREAD).start();\n        /*\n        输出：\n        pool-1-thread-2 before barrier.await()\n        pool-1-thread-1 before barrier.await()\n        timed_awaited_thread before barrier.await()\n        timed_awaited_thread java.util.concurrent.TimeoutException\n        pool-1-thread-2 java.util.concurrent.BrokenBarrierException\n        pool-1-thread-1 java.util.concurrent.BrokenBarrierException\n         */\n    }\n\n    private static void log(final String msg) {\n        System.out.println(String.format(\"%s %s\", Thread.currentThread().getName(), msg));\n    }\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["AQS"],"categories":["Concurrent"]},{"title":"Java并发 -- CountDownLatch","url":"%2F2016%2F08%2F15%2Fconcurrent-countdownlatch%2F","content":"\n{% note info %}\n本文将通过剖析`CountDownLatch`的源码来介绍其实现原理\n代码托管在https://github.com/zhongmingmao/concurrent_demo\n关于`ReentrantLock`的基本内容请参考「并发 - JUC - ReentrantLock - 源码剖析」，本文不再赘述\n{% endnote %}\n\n<!-- more -->\n\n# 使用场景\n常用于：`n`个线程统一`阻塞`在某个`CountDownLatch`上，等待`m`个线程`并发消耗完CountDownLatch`，然后`n`个线程统一通过`CountDownLatch`，继续执行后续代码\n\n## 代码\n```java\npublic class CountDownLatchDemo {\n    private static final int THREAD_COUNT = 4;\n\n    public static void main(String[] args) throws InterruptedException {\n        CountDownLatch countDownLatch = new CountDownLatch(THREAD_COUNT);\n        ExecutorService mPool = Executors.newFixedThreadPool(THREAD_COUNT);\n\n        IntStream.range(0, THREAD_COUNT).forEach(value ->\n                mPool.submit(() -> {\n                    doTask();\n                    log(\"finished!\");\n                    countDownLatch.countDown(); // state-1\n                }));\n\n        ExecutorService nPool = Executors.newFixedThreadPool(THREAD_COUNT);\n        IntStream.range(0, THREAD_COUNT).forEach(value ->\n                nPool.submit(() -> {\n                    try {\n                        countDownLatch.await(); // 等待state减少到0\n                        log(\"started!\");\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                }));\n\n        mPool.shutdown();\n        nPool.shutdown();\n\n        /*\n         输出：\n         pool-1-thread-3 finished!\n         pool-1-thread-1 finished!\n         pool-1-thread-2 finished!\n         pool-1-thread-4 finished!\n         pool-2-thread-2 started!\n         pool-2-thread-3 started!\n         pool-2-thread-4 started!\n         pool-2-thread-1 started!\n         */\n    }\n\n    private static void doTask() {\n        try {\n            TimeUnit.SECONDS.sleep(2);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n\n    private static void log(final String msg) {\n        System.out.println(String.format(\"%s %s\", Thread.currentThread().getName(), msg));\n    }\n}\n```\n\n# 源码分析\n\n## Sync\n```java\n// Sync是在CountDownLatch的静态内部类，继承自AQS\nprivate static final class Sync extends AbstractQueuedSynchronizer {\n    Sync(int count) {\n        // 用AQS中的state属性表示CountDownLatch的count属性\n        setState(count);\n    }\n}\n```\n\n## 核心结构与构造函数\n```java\npublic class CountDownLatch {\n    // 只有一个Sync属性，CountDownLatch的核心方法托管给Sync执行\n    private final Sync sync;\n}\n```\n```java\npublic CountDownLatch(int count) {\n    // count不能为负值\n    if (count < 0) throw new IllegalArgumentException(\"count < 0\");\n    this.sync = new Sync(count);\n}\n```\n\n## await\n```java\n// From CountDownLatch\n// 1. 如果state==0，立即返回，无需等待\n// 2. 如果state>0，线程阻塞，直到发生：\n//    2.1 调用countDown()将state减少到0\n//    2.2 被其他线程中断\npublic void await() throws InterruptedException {\n    // 实际调用AQS.acquireSharedInterruptibly\n    // 请求共享锁，中断时抛出InterruptedException\n    sync.acquireSharedInterruptibly(1);\n}\n```\n\n### acquireSharedInterruptibly\n```java\n// From AQS\n// 请求共享锁，中断时抛出InterruptedException\npublic final void acquireSharedInterruptibly(int arg) throws InterruptedException {\n    if (Thread.interrupted())\n        // 首先判断线程已被中断，如果是则直接抛出InterruptedException\n        throw new InterruptedException();\n    if (tryAcquireShared(arg) < 0) // (getState() == 0) ? 1 : -1\n        // state==0时，直接返回\n        // state!=0时，其实就是state>0，继续执行\n        // 请求共享锁，中断时抛出InterruptedException\n        doAcquireSharedInterruptibly(arg);\n}\n```\n\n#### tryAcquireShared\n```java\n// From AQS\n// 请求共享锁，只要state==0，即持有共享锁\nprotected int tryAcquireShared(int acquires) {\n    return (getState() == 0) ? 1 : -1;\n}\n```\n\n#### doAcquireSharedInterruptibly\n```java\n// From AQS\n// 请求共享锁，中断时抛出InterruptedException\nprivate void doAcquireSharedInterruptibly(int arg) throws InterruptedException {\n    // 以自旋的方式进入同步队列，节点处于共享模式\n    // CountDownLatch采用的是AQS的共享模式，而ReentrantLock采用的是AQS的独占模式\n    // 关于ReentrantLock的更详细分析请参照博文：「并发 - JUC - ReentrantLock - 源码剖析」\n    final Node node = addWaiter(Node.SHARED); // node.isShared()永远为true！！\n    boolean failed = true;\n    try {\n        for (;;) {\n            final Node p = node.predecessor(); // 前驱节点\n            if (p == head) { // 当前节点的前驱节点为同步队列的头结点，即head<->node\n                int r = tryAcquireShared(arg); // (getState() == 0) ? 1 : -1\n                if (r >= 0) { // 持有共享锁\n                    // 执行到这里说明node.prev==head，state==0，r==1\n                    // 即state已经被消耗完了，尝试以广播的方式唤醒同步队列中的线程\n                    setHeadAndPropagate(node, r); // 核心代码，看下面详细分析\n                    p.next = null;\n                    failed = false;\n                    return;\n                }\n            }\n            // 如果当前节点的前驱节点不是头节点，或者state!=0，则尝试挂起线程并等待被唤醒或被中断\n            if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt())\n                // doAcquireSharedInterruptibly是响应中断的，因此如果被中断而退出休眠状态的逻辑比较简单\n                // 直接抛出InterruptedException，执行cancelAcquire取消请求锁\n                throw new InterruptedException();\n        }\n    } finally {\n        if (failed)\n            // 更详细的分析请参照博文：「并发 - JUC - ReentrantLock - 源码剖析」\n            cancelAcquire(node);\n    }\n}\n```\n\n#### addWaiter\n```java\n// From AQS\nprivate Node addWaiter(Node mode) {\n    Node node = new Node(Thread.currentThread(), mode); // 关注这一行\n    Node pred = tail;\n    if (pred != null) {\n        node.prev = pred;\n        if (compareAndSetTail(pred, node)) {\n            pred.next = node;\n            return node;\n        }\n    }\n    enq(node);\n    return node;\n}\n```\n\n#### Node构造函数\n```java\n// From AQS.Node\nNode(Thread thread, Node mode) {\n    // 在CountDownLatch中，this.nextWaiter == mode == Node.SHARED\n    // node.isShared()实际执行的是：nextWaiter == SHARED，必然为true\n    // 因此在setHeadAndPropagate必然会执行doReleaseShared()\n    this.nextWaiter = mode;\n    this.thread = thread;\n}\n```\n\n##### setHeadAndPropagate\n```java\n// From AQS\n// 在AQS中，执行setHeadAndPropagate必然满足2个条件\n// 1. node.prev==head\n// 2. propagate==1\n// 更新同步队列头结点为当前节点，并以自旋的方式唤醒头结点的后继节点的关联线程\nprivate void setHeadAndPropagate(Node node, int propagate) {\n    Node h = head;\n    setHead(node);\n    // propagate==1，必然满足propagate>0，因此暂不关心后续条件判断\n    if (propagate > 0 || h == null || h.waitStatus < 0 || (h = head) == null || h.waitStatus < 0) {\n        Node s = node.next;\n        if (s == null || s.isShared()) // s == null || nextWaiter == SHARED\n            // s.isShared()必然为true，因此只需考虑s==null\n            // setHead(node)已经将head设置为node，因此s=head.next!=null表示同步队列有可供唤醒的线程，以广播的方式唤醒线程\n            // doReleaseShared的代码将在分析countDown()时进行详细分析，这里暂时跳过\n            doReleaseShared(); // 核心代码，很晦涩！！\n    }\n}\n```\n```java\n// From AQS\nprivate void setHead(Node node) {\n    head = node;\n    node.thread = null;\n    node.prev = null;\n}\n```\n\n## countDown\n```java\npublic void countDown() {\n    sync.releaseShared(1);\n}\n```\n\n### releaseShared\n```java\n// From AQS\npublic final boolean releaseShared(int arg) {\n    if (tryReleaseShared(arg)) {\n        // // 自旋state-1，如果刚好是1->0，以广播的方式唤醒线程\n        doReleaseShared();\n        return true;\n    }\n    return false;\n}\n```\n\n#### tryReleaseShared\n```java\n// 自旋state-1，如果刚好是1->0，返回true，以广播的方式唤醒线程\nprotected boolean tryReleaseShared(int releases) {\n  for (;;) {\n      int c = getState();\n      // 如果当前state已经为0，直接返回false，\n      // 表示state早已消耗完毕，无需再次唤醒同步队列节点的关联线程（唤醒进行中或已经完全唤醒所有线程）\n      if (c == 0)\n          return false;\n      // 自旋state-1，直到成功\n      int nextc = c-1;\n      if (compareAndSetState(c, nextc))\n            // 刚好1->0，返回true，表示state恰好消耗完毕，需要唤醒同步队列节点的关联线程\n            // 否则返回false，表示state尚未消耗完，无需唤醒同步队列节点的关联线程\n            return nextc == 0;\n  }\n}\n```\n\n#### doReleaseShared\n`doReleaseShared`是本文分析中**`最晦涩`**的代码\n在开始分析`doReleaseShared`之前，先分析概况一下`AQS`的`独占模式`与`共享模式`的区别（个人理解，如有错误，还望指正）\n\n场景：\n假若当前`同步队列`的排队情况为`[head:null] <-> [node1:t1] <-> [node2:t2] <-> [node3:t3] <-> [node4:t4]`，且没有新的线程排队\n\n区别1：\n1. `独占模式`：`AQS`的`state`是`线程独占`的，例如`ReentrantLock.lock()`、`ReentrantLock.unLock()`\n2. `共享模式`：`AQS`的`state`是`线程共享`的，例如`Countdownlatch.countDown()`\n\n区别2：\n1. `独占模式`：`线程自身任务优先`。线程c唤醒线程t1，线程t1必须先执行完本身任务以后在唤醒线程t2，以此类推\n2. `共享模式`：`唤醒其他线程优先`（唤醒其他线程的前提：当前线程已经获得`共享锁`，`CountDownLatch`的共享锁和`Semaphore`的共享锁含义是不一样的）。线程c唤醒线程t1，线程c和线程t1首先竞争着唤醒t2（c也有可能直接退出，不参与竞争），再去执行本身任务，以此类推\n\n\n```java\n// From AQS\n// 以广播的方式唤醒线程，核心代码\nprivate void doReleaseShared() {\n    for (;;) {\n        Node h = head;\n        // 1. h==null，说明此时同步队列为空，没有后继节点，也就没有线程可供唤醒\n        // 2. h!=null && h==tail，有2种情况，但都没有可供唤醒的节点\n        //      2.1. head==tail==new Node()，同步队列的tail为null时入队，初始化的空节点new Node()，具体代码请看AQS.enq()\n        //      2.2 同步队列尾节点被唤醒，此时head==tail，具体代码请看AQS.doAcquireSharedInterruptibly\n        if (h != null && h != tail) { // 同步队列非空 + head!=tail ➔ 有可供唤醒的线程\n            int ws = h.waitStatus;\n            if (ws == Node.SIGNAL) {\n                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))\n                    // 由下面 if(h==head) 的分析，可能存在多个线程并发地执行doReleaseShared\n                    // 因此这里的CAS操作就有可能会失败，进入下一轮唤醒竞争\n                    continue;\n                // 并发时只有一个线程能CAS操作成功，head.waitStatus:Node.SIGNAL->0，则唤醒头结点的后继节点\n                unparkSuccessor(h);\n            } else if (ws == 0 && !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))\n                // 由下面 if(h==head) 的分析，可能存在多个线程并发地执行doReleaseShared\n                // 因此这里的CAS操作就有可能会失败，进入下一轮唤醒竞争\n\n                // 当参与唤醒竞争的线程很多时，很有可能会导致ws=PROPAGATE\n                // 而ws=PROPAGATE又会导致线程会参与判断是否继续参与唤醒竞争\n                // 大多数参与唤醒竞争线程会发现h==head，退出唤醒竞争\n                continue;\n        }\n\n        // 执行到这里，说明必然已经有线程已经执行了unparkSuccessor(h)！！\n        // 即下一轮唤醒竞争必然开始\n        // 下一步就是要判断当前线程是否要参与下一轮的唤醒竞争\n\n        // h==head则结束自旋：\n        //\n        // ===== 理解1：\n        // 为了解释清楚，假设目前同步队列的排队情况为：\n        // [head:null] <-> [node1:t1] <-> [node2:t2] <-> [node3:t3] <-> [node4:t4]\n        //\n        // 当前线程c触发了unparkSuccessor，即唤醒了t1，\n        // t1会触发setHead来更新head，开启新一轮的唤醒竞争\n        // 1. 假若 t1的setHead 发生在 当前线程c的if(h==head) 之后，则当前线程c退出下一轮的唤醒竞争，由t1去尝试唤醒t2\n        // 2. 假若 t1的setHead 发生在 当前线程c的if(h==head) 之前，则当前线程c继续参与下一轮的唤醒竞争，这会导致当前线程c与t1竞争去唤醒t2\n        // 两种情况总结：\n        // 1. 当前线程c发现其他线程修改了head，那么我们通过\"竞争\"（CAS）来加速唤醒；\n        // 2. 当前线程c没有发现其他线程修改了head，当前线程c认为反正已经唤醒了一个线程（可能是其他线程唤醒的），\n        //    那么让这个被唤醒线程继续去唤醒其他线程，当前线程c可以\"安心地退出\"\n        //\n        // 以此类推，当前的线程c最多苟且到最后一轮竞争，即当前线程、t1、t2和t3竞争去唤醒t4\n        // 在t4唤醒后，因为t4没有后继节点了，因此当前线程t1、t2、t3和t4在下一轮唤醒竞争中都会结束自旋\n        //\n        // ===== 理解2：\n        // 这段代码非常晦涩，尝试换另外一个角度来理解，如有错误，还望指正\n        // head的值其实就是标识一轮并发唤醒竞争！！\n        // 1. head.waitStatus的初始值必然为SIGNAL，因此在并发时，必然只有一个线程A能将等待状态由 SIGNAL CAS更新为 0，\n        //    该线程A会唤醒其他线程B\n        // 2. 被唤醒的线程B会首先执行setHead\n        //    2.1 因此如果最后h!=head，说明新一轮的唤醒竞争已经开始，当前线程c已经觉察到，因此继续参与竞争，加快唤醒\n        //    2.2 因此如果最后h==head，说明新一轮的唤醒竞争尚未开始，而被唤醒的线程B必然会开启新一轮的唤醒竞争，而当前线程c可以安心退出唤醒竞选\n        //\n        // JUC代码的套路很深，上面说法纯属个人理解，如有错误，还望指正\n        if (h == head)\n            break;\n    }\n}\n```\n\n# 逻辑示意图\n经过了上面的源码分析，下面将通过一段代码，简单回顾上面的过程\n\n## 代码\n```java\n/**\n * 简述CountDownLatch的工作过程\n */\npublic class CountDownLatchProcedure {\n\n    private static final int THREAD_COUNT = 4;\n\n    private static CountDownLatch countDownLatch = new CountDownLatch(THREAD_COUNT);\n\n    private static Runnable awaitRunnable = () -> {\n        try {\n            log(\"start!\");\n            countDownLatch.await();\n            log(\"continue!\");\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    };\n\n    public static void main(String[] args) {\n        IntStream.range(0, THREAD_COUNT).forEach(i -> {\n            new Thread(awaitRunnable, String.format(\"t%s\", i + 1)).start();\n            try {\n                TimeUnit.SECONDS.sleep(1);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n\n        IntStream.range(0, THREAD_COUNT).forEach(i -> countDownLatch.countDown());\n\n        /*\n         输出：\n        t1 start!\n        t2 start!\n        t3 start!\n        t4 start!\n        t1 continue!\n        t2 continue!\n        t4 continue!\n        t3 continue!\n         */\n    }\n\n    private static void log(final String msg) {\n        System.out.println(String.format(\"%s %s\", Thread.currentThread().getName(), msg));\n    }\n}\n```\n\n## 逻辑示意图\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/count_down_latch_procedure.png\" width=\"500\">\n\n<!-- indicate-the-source -->\n","tags":["AQS"],"categories":["Concurrent"]},{"title":"Java并发 -- ConditionObject","url":"%2F2016%2F08%2F11%2Fconcurrent-conditionobject%2F","content":"\n{% note info %}\n本文将剖析与`ReentrantLock`密切相关的`ConditionObject`的相关源码，并简要介绍`ConditionObject`的实现原理\n代码托管在https://github.com/zhongmingmao/concurrent_demo\n关于`ReentrantLock`的基本内容请参考「并发 - JUC - ReentrantLock - 源码剖析」，本文不再赘述\n{% endnote %}\n\n<!-- more -->\n\n# 基础\n\n## 使用场景\n`Condition`常用于**`生产者-消费者`**的场景，例如`ArrayBlockingQueue`，`JUC`框架也有很多地方使用了`Condition`，如下图所示\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/condition_usages.png\" width=\"500\">\n\n## 生产者-消费者\n```java\n/**\n * 利用Condition实现生产者-消费者\n * @author zhongmingmao zhongmingmao0625@gmail.com\n */\npublic class ProducerAndConsumer {\n\n    static class Buffer {\n        // 缓冲区大小\n        private static final int BUFFER_LENGTH = 5;\n        // 缓冲区\n        private final Object[] buffer = new Object[BUFFER_LENGTH];\n\n        // 非公平锁\n        private final Lock lock = new ReentrantLock();\n        // ConditionObject\n        private final Condition notEmpty = lock.newCondition();\n        private final Condition notFull = lock.newCondition();\n\n        int produceIndex;\n        int consumeIndex;\n        int count;\n\n        /**\n         * 生产者方法\n         */\n        public void produce() throws InterruptedException {\n            while (true) {\n                lock.lock(); // 先持有notEmpty和notFull相关联的锁\n                try {\n                    while (count == BUFFER_LENGTH) {\n                        System.out.println(\"buffer is full , need to consume\");\n                        // 缓存区已满，需要等待消费者消费后，唤醒生产者才能继续生产\n                        notFull.await();\n                    }\n                    buffer[produceIndex++] = new Object();\n                    produceIndex %= BUFFER_LENGTH;\n                    ++count;\n                    System.out.println(String.format(\"produce buffer[%s] , buffer size : %s\",\n                            (BUFFER_LENGTH + produceIndex - 1) % BUFFER_LENGTH, count));\n                    // 已经生产，唤醒消费者去消费\n                    notEmpty.signal();\n                } finally {\n                    lock.unlock();\n                    // 模拟生产耗时，并让消费者能获得锁\n                    TimeUnit.MILLISECONDS.sleep(new Random().nextInt(1000));\n                }\n            }\n        }\n\n        /**\n         * 消费者方法\n         */\n        public void consume() throws InterruptedException {\n            while (true) {\n                lock.lock(); // 先持有notEmpty和notFull相关联的锁\n                try {\n                    while (count == 0) {\n                        System.out.println(\"buffer is full , need to produce\");\n                        // 缓存区为空，需要等待生产者生产完成后，唤醒消费者\n                        notEmpty.await();\n                    }\n                    Object x = buffer[consumeIndex++];\n                    consumeIndex %= BUFFER_LENGTH;\n                    --count;\n                    System.out.println(String.format(\"consume buffer[%s] , buffer size : %s\",\n                            (BUFFER_LENGTH + consumeIndex - 1) % BUFFER_LENGTH, count));\n                    // 已经消费，唤醒生产者去生产\n                    notFull.signal();\n                } finally {\n                    lock.unlock();\n                    // 模拟消费耗时，并让生产者能获得锁\n                    TimeUnit.MILLISECONDS.sleep(new Random().nextInt(1000));\n                }\n            }\n        }\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        Buffer buffer = new Buffer();\n\n        ExecutorService pool = Executors.newFixedThreadPool(2);\n        pool.submit(() -> { // 生产者线程\n            try {\n                buffer.produce();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n\n        pool.submit(() -> { // 消费者线程\n            try {\n                buffer.consume();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n\n        pool.shutdown();\n        pool.awaitTermination(5, TimeUnit.SECONDS);\n    }\n}\n```\n\n## Condition接口\n```java\npublic interface Condition {\n\n    // ===== await方法列表\n    // 使当前线程进入等待状态直到被signal或中断，相当于synchronized等待唤醒机制中的wait()方法\n    void await() throws InterruptedException;\n    // 使当前线程进入等待状态直到被signal，不响应中断\n    void awaitUninterruptibly();\n    // 使当前线程进入等待状态直到被signal、或被中断、或超时（相对时间）\n    long awaitNanos(long nanosTimeout) throws InterruptedException;\n    // 与awaitNanos类似，可以指明时间单位\n    boolean await(long time, TimeUnit unit) throws InterruptedException;\n    // 与awaitNanos类似，只是采用的是绝对时间\n    boolean awaitUntil(Date deadline) throws InterruptedException;\n\n    // ===== signal方法列表\n    // 唤醒一个等待在某个Condition实例上的线程，必须首先持有与Condition相关联的锁，相当于notify()\n    void signal();\n    // 与signal类似，相当于notifyAll()\n    void signalAll();\n}\n```\n一个很关键的地方：`Condition`的实现类在重写`Condition`的`所有方法`都建议`先持有与Condition关联的锁`，`AQS`中的`ConditionObject`就满足这一点，因此调用`ConditionObject`的方法是`线程安全`的，这里说的线程安全有一个前提，就是线程必须先`持有独占锁`，下面的分析说线程安全的时候，不再重复说明这一前提\n\n## ConditionObject\n\n### 实例化\n在`生产者-消费者`的代码里面，`newCondition()`实际创建的是`ConditionObject`对象\n```java\n// From ReentrantLock\npublic Condition newCondition() {\n    return sync.newCondition();\n}\n```\n```java\n// From Sync\nfinal ConditionObject newCondition() {\n    return new ConditionObject();\n}\n```\n\n### 核心结构\n```java\npublic class ConditionObject implements Condition, java.io.Serializable {\n    // 条件队列（condition queue）的头结点\n    private transient Node firstWaiter;\n    // 条件队列（condition queue）的尾节点\n    private transient Node lastWaiter;\n\n    // 中断模式是为了对不同的中断情况做不同的处理，进而告诉上层调用者中断情况，有2种模式\n    // 中断模式：需要重新设置线程的中断状态\n    private static final int REINTERRUPT =  1;\n    // 中断模式：需要抛出InterruptedException异常\n    private static final int THROW_IE    = -1;\n}\n```\n在进一步分析之前，先行回顾一下`AQS`中`Node`的定义\n```java\nstatic final class Node {\n  // 本文不关注该模式\n  static final Node SHARED = new Node();\n  // 节点处于独占模式\n  static final Node EXCLUSIVE = null;\n\n  // 由于超时或中断而导致当前线程（对应同步队列或条件队列中的一个节点）被取消\n  // CANCELLED是终态\n  // 被取消了的节点对应的线程永远不会阻塞，放弃竞争锁\n  static final int CANCELLED =  1;\n  // 当前节点的后继节点通过park操作被阻塞（或将要被阻塞）\n  // 因此当前节点在它们释放锁或被取消的时候，需要通过unpark操作唤醒它的后继节点\n  // 为了避免竞争（依据等待状态进行筛选，无需全部唤醒），\n  // 执行竞争锁的方法（acquire methods）的线程首先需要表明它们需要被唤醒，\n  // 如果竞争锁失败，它们就会被阻塞，等待被唤醒\n  // 是否需要被唤醒，其实是记录在当前节点的前驱节点的等待状态中\n  // 因此SIGNAL表示后继节点需要被唤醒，这一点非常重要！！\n  static final int SIGNAL    = -1;\n  /**\n  * This node is currently on a condition queue.\n  * It will not be used as a sync queue node\n  * until transferred, at which time the status\n  * will be set to 0. (Use of this value here has\n  * nothing to do with the other uses of the\n  * field, but simplifies mechanics.\n  */\n  // 当前线程对应的节点处于条件队列中\n  // 在当前线程对应的节点转移到同步队列之前，同步队列不会使用当前线程对应的节点\n  // 在当前线程对应的节点转移到同步队列的时候，等待状态会首先被设置为0\n  static final int CONDITION = -2;\n  // 本文不关注该状态\n  static final int PROPAGATE = -3;\n\n  // 等待状态，只能为CANCELLED、SIGNAL、CONDITION、PROPAGATE或0\n  volatile int waitStatus;\n\n  // 同步队列中的前驱节点\n  volatile Node prev;\n  // 同步队列中的后继节点\n  volatile Node next;\n  // 请求锁或等待Condition的线程\n  volatile Thread thread;\n  // 条件队列的后继节点\n  Node nextWaiter;\n}\n```\n由此可见：\n1. `条件队列`仅有`nextWaiter`，因此**`条件队列是单向非循环队列`**，而**`同步队列是双向非循环队列`**\n2. `条件队列`中节点只有3种`等待状态`：\n  - **`CANCELLED`**：需要从条件队列中移除\n  - **`CONDITION`**：等待被转移到同步队列\n  - **`0`**：转移过程中或已经转移完成，在_`transferAfterCancelledWait`_或_`transferForSignal`_中设置，后面会详细分析\n3. `AQS`只能拥有_**`1个同步队列`**_，但可以拥有_**`多个条件队列`**_\n\n### 同步队列与条件队列\n`条件队列`与`同步队列`的关系大致如下：\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/aqs_condition_queue.png\" width=\"500\">\n简单说明（后面源码分析将详细介绍）：\n1. `ReentrantLock.newCondition()`：创建一个新的`ConditionObject`实例，每个`ConditionObject`拥有`firstWaiter`属性和`lastWaiter`属性，对应一个`条件队列`\n2. `ConditionObject.await()`：将`当前线程`包装成`节点`后加入到`对应的条件队列`并进行`阻塞`，然后`等待被转移`到`同步队列`中\n3. `ConditionObject.signal()`：将`ConditionObject实例对应的条件队列中的节点`（从头结点开始往后遍历筛选）转移到`AQS同步队列的队尾`，`等待获得独占锁`，获得独占锁后，上面的`ConditionObject.await()`方法返回，继续执行\n\n# 源码分析\n\n## await\n`await()`方法的分析在本文中是**`最复杂的`**！！\n```java\n// From ConditionObject\n// 需要先持有独占锁，线程安全\npublic final void await() throws InterruptedException {\n    if (Thread.interrupted())\n        // 线程被中断则直接抛出InterruptedException，可响应中断\n        throw new InterruptedException();\n\n    // ===== 1. 创建新节点并加入条件队列的队尾\n    Node node = addConditionWaiter();\n\n    // ===== 2. 释放锁\n    // 完全释放独占锁（锁是可重入的）并尝试唤醒同步队列头结点的后继节点，并返回释放锁之前的同步状态\n    int savedState = fullyRelease(node);\n\n    int interruptMode = 0;\n\n    // ===== 3. 自旋转移节点（条件队列 -> 同步队列），并记录中断模式\n    while (!isOnSyncQueue(node)) { // isOnSyncQueue：判断节点是否已经由条件队列转移到同步队列\n        // 节点还在条件队列中，挂起当前线程，等待被唤醒或被中断\n        LockSupport.park(this);\n        // 执行到这里，说明当前线程退出休眠状态，有3种情况：\n        // 1. ConditionObject.signal -> 节点从条件队列转移到同步队列（前驱节点等待状态为SIGNAL） -> 等待被前驱节点唤醒（unpark）\n        // 2. ConditionObject.signal -> 节点从条件队列转移到同步队列（前驱节点等待状态为CANCELLED） -> 直接唤醒（unpark）\n        // 3. 当前线程被中断（interrupt）\n\n        // 节点转移过程中当前线程的中断情况，有3种情况：\n        // 1. 当前线程没有被中断，返回0\n        // 2. 当前线程被中断 + 中断发生在ConditionObject.signal()调用之前，执行自旋入队操作，记录中断模式：THROW_IE(-1)\n        //    转移到同步队列后，再次抛出InterruptedException异常，然后执行cancelAcquire，将节点的等待状态置为CANCELLED\n        // 3. 当前线程被中断 + 中断发生在ConditionObject.signal()调用之后，自旋等待入队操作完成，记录中断模式：REINTERRUPT(1)\n        //    转移到同步队列后，仅仅设置对应线程的中断状态\n        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)\n            // 由于中断而导致退出休眠状态，则退出循环\n            // interruptMode = THROW_IE(-1) OR REINTERRUPT(1)\n            break;\n    }\n\n    // ===== 4. 自旋请求独占锁，并维护中断模式\n    // 执行到这里，说明线程被中断（被中断也会完成节点转移，下面会详细分析）或者节点转移成功，所以此时节点已经转移到了同步队列\n    // fullyRelease已经释放了独占锁，下面会等待独占锁（acquireQueued方法），与包裹await()方法的unlock()方法配对\n    if (acquireQueued(node, savedState) // acquireQueued是通过自旋来等待锁，并且返回退出休眠状态去竞争锁的原因是否是被中断\n            && interruptMode != THROW_IE) // 执行第二个条件判断，说明已经获得锁并且当前线程被中断了，但中断标志被重置了\n        // 执行到这里，说明interruptMode为0或REINTERRUPT(1)\n        // 1. 对于REINTERRUPT(1)，下面的语句interruptMode=REINTERRUPT，显然是没有意义的\n        // 2. 对于interruptMode=0，说明上面的while(!isOnSyncQueue(node))循环没有被中断，但在acquireQueued被中断了，\n        //    且中断标志被重置了，因此需要将interruptMode设置为REINTERRUPT\n        // 3. 对于THROW_IE(-1)，说明判断节点是否已经由条件队列转移到同步队列时发生中断，且中断发生在ConditionObject.signal()调用之前，\n        //    直接抛出异常即可\n        // 总结：acquireQueued被中断，但while(!isOnSyncQueue(node))没有被中断，需要记录中断模式为REINTERRUPT\n        interruptMode = REINTERRUPT;\n\n    // ===== 5. 清理条件队列\n    // 执行到这里说明节点已经转移到同步队列中，且已经获得独占锁（或在acquireQueued的过程中被中断）\n    // 此时节点不应该跟条件队列有关联了，而且此时节点的状态肯定不为CONDITION\n    // 因此执行unlinkCancelledWaiters，从条件队列移除该节点\n    if (node.nextWaiter != null)\n        unlinkCancelledWaiters();\n\n    // ===== 6. 已经中断模式，向上层反馈中断情况\n    if (interruptMode != 0) // interruptMode = THROW_IE(-1) OR REINTERRUPT(1)\n        // 依据不同的中断模式，向调用方报告当前线程的中断情况\n        // 1. ConditionObject.signal方法调用之前中断了当前线程，往外抛出InterruptedException异常，中断线程的后续操作\n        // 2. ConditionObject.signal方法调用之后中断了当前线程，重置当前线程的中断状态，对线程不会有实际性的影响\n        reportInterruptAfterWait(interruptMode);\n}\n```\n\n### addConditionWaiter\n```java\n// From ConditionObject\n// 需要先持有独占锁，线程安全\nprivate Node addConditionWaiter() {\n    Node t = lastWaiter;\n\n    if (t != null && t.waitStatus != Node.CONDITION) {\n        // 如果条件队列尾节点是非CONDITION节点，从头结点开始遍历条件队列，并移除非CONDITION节点\n        unlinkCancelledWaiters();\n        // 获取条件队列最新的尾节点\n        t = lastWaiter;\n    }\n\n    // 创建新节点，初始等待状态为CONDITION\n    Node node = new Node(Thread.currentThread(), Node.CONDITION);\n    if (t == null)\n        // 条件队列为空，将firstWaiter指向刚创建的节点node\n        firstWaiter = node;\n    else\n        // 条件队列不为空，原条件队列队尾的后继节点设置为刚创建的节点node\n        t.nextWaiter = node;\n\n    // 更新条件队列的队尾为刚创建的节点\n    lastWaiter = node;\n    return node;\n}\n```\n#### unlinkCancelledWaiters\n```java\n// From ConditionObject\n// 需要先持有独占锁，线程安全\n// 从头结点开始遍历条件队列，并移除非CONDITION节点\n// 很巧妙的代码！！\nprivate void unlinkCancelledWaiters() {\n    Node t = firstWaiter; // 从头结点开始遍历条件队列，t用于迭代\n    Node trail = null; // 遍历过程中，用于记录最近的已遍历的CONDITION节点，初始值为null，这点非常重要！！\n    while (t != null) {\n        Node next = t.nextWaiter; // next为t在条件队列中的后继节点\n        if (t.waitStatus != Node.CONDITION) {\n            // t为非CONDITION节点，首先需要断开t与next的单线链接nextWaiter\n            t.nextWaiter = null;\n            if (trail == null)\n                // trail等于null，说明从头结点到当前遍历节点t都是非CONDITION节点，\n                // 直接将头结点设置为当前遍历节点的后继节点next\n                firstWaiter = next;\n            else\n                // trail不为null，即已经找到CONDITION节点，\n                // 将trail的后继节点设置为当前遍历节点的后继节点next，\n                // 这将跳过trail（不包括）到当前遍历节点（包括），因为这些节点都明确是非CONDITION节点\n                // 但在当前循环没必要判断next是不是CONDITION节点，那是下个循环的任务\n                trail.nextWaiter = next;\n\n            if (next == null)\n                // next=null，说明t是原尾节点，\n                // 直接将尾节点更新为trail（最近的已遍历的CONDITION节点）\n                lastWaiter = trail;\n        }\n        else\n            // trail用于记录最近的已遍历的CONDITION节点\n            trail = t;\n        // t是迭代节点，往后迭代\n        t = next;\n    }\n}\n```\n逻辑示意图如下：\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/aqs_condition_queue_unlink_cancelled_waiters.png\" width=\"500\">\n\n### fullyRelease\n```java\n// From AQS\n// 需要先持有独占锁，线程安全\n// 完全释放独占锁（锁是可重入的）并尝试唤醒同步队列头结点的后继节点，并返回释放锁之前的同步状态\nfinal int fullyRelease(Node node) {\n    boolean failed = true;\n    try {\n        // 释放锁之前的同步状态\n        int savedState = getState();\n        // 尝试释放独占锁并唤醒同步队列中头结点的后继节点\n        // 释放锁调用的tryRelease方法必须首先要持有锁\n        // 说明了ConditionObject.await()方法必须要先持有ConditionObject对应的锁\n        if (release(savedState)) {\n            failed = false;\n            // 成功释放独占锁\n            return savedState;\n        } else {\n            throw new IllegalMonitorStateException();\n        }\n    } finally {\n        if (failed)\n            // fullyRelease在addConditionWaiter之后，节点已经进入了条件队列，\n            // 因此在释放独占锁失败，需要将节点的等待状态置为CANCELLED，等待被移除\n            // 释放独占锁失败的场景：调用await方法时没有先持有独占锁\n            node.waitStatus = Node.CANCELLED;\n    }\n}\n```\n```java\n// From AQS\n// 尝试释放独占锁并唤醒同步队列中头结点的后继节点\n// 更详细的分析请参照博文：「并发 - JUC - ReentrantLock - 源码剖析」\npublic final boolean release(int arg) {\n    if (tryRelease(arg)) { // 尝试释放独占锁\n        Node h = head;\n        if (h != null && h.waitStatus != 0)\n            unparkSuccessor(h); // 唤醒同步队列中头结点的后继节点\n        return true;\n    }\n    return false;\n}\n```\n```java\n// From Sync\nprotected final boolean tryRelease(int releases) {\n    int c = getState() - releases;\n    if (Thread.currentThread() != getExclusiveOwnerThread())\n        // 只有持有独占锁的线程才能释放独占锁\n        // 在博文「并发 - JUC - ReentrantLock - 源码剖析」的分析中，我们易知：\n        // lock操作会在同步队列中等待独占锁，一旦获得独占锁，就会记录在exclusiveOwnerThread变量中，并从同步队列移除\n        // 而后才加入到条件队列中，最后又被转移回同步队列等待独占锁\n        // 这也从一方面说明了await()为什么要先获得独占锁\n        throw new IllegalMonitorStateException();\n    boolean free = false;\n    if (c == 0) {\n        free = true;\n        setExclusiveOwnerThread(null);\n    }\n    setState(c);\n    return free; // fullyRelease实际执行到这里的时候，独占锁已经完全释放了\n}\n```\n\n### isOnSyncQueue\n```java\n// From AQS\n// 判断节点是否已经由条件队列转移到同步队列\n// ConditionObject.signal()会将节点从条件队列转移到同步队列\nfinal boolean isOnSyncQueue(Node node) {\n    if (node.waitStatus == Node.CONDITION || node.prev == null)\n        // 1. 节点加入条件队列时，等待状态为CONDITION，在节点转移过程中，会将等待状态设置为0，\n        //    所以如果节点的等待状态为CONDITION，说明节点一定还在条件队列中；\n        // 2. 转移过程中会首先设置节点的同步队列前驱节点属性prev，\n        //    如果节点的同步队列前驱节点属性为null，说明节点一定还在条件队列中，\n        //    另外需要注意的是，即使节点拥有了同步队列的前驱节点属性prev也不能说明节点已经转移到了同步队列中，\n        //    因为有可能compareAndSetTail失败，那么同步队列的原尾节点的后继节点依旧为null，而不是node\n        //    此时node还只是单方面的连接到同步队列，同步队列中没有任何节点将其作为前驱节点或后继节点\n        //    更详细的分析请参照博文：「并发 - JUC - ReentrantLock - 源码剖析」\n        return false;\n    if (node.next != null)\n        // 如果节点拥有了同步队列的后继节点next，那么节点一定已经转移到了同步队列中\n        // 更详细的分析请参照博文：「并发 - JUC - ReentrantLock - 源码剖析」\n        return true;\n\n    // 从同步队列的尾节点向前遍历，看能否找到节点node\n    // 由于入队操作是在队尾，因此大部分情况下，当前节点不会离同步队列队尾太远，效率比较高\n    return findNodeFromTail(node);\n}\n```\n\n#### findNodeFromTail\n```java\n// From AQS\n// 从同步队列的尾节点向前遍历（依据节点的prev属性，而prev属性用于连接同步队列的），看能否找到节点node\nprivate boolean findNodeFromTail(Node node) {\n    Node t = tail; // 从同步队列尾节点开始遍历\n    for (;;) {\n        if (t == node)\n            return true;\n        if (t == null)\n            // t.next为head，即同步队列头结点\n            return false;\n        t = t.prev;\n    }\n}\n```\n\n### checkInterruptWhileWaiting\n```java\n// From ConditionObject\n// 判断节点转移过程中当前线程的中断情况\n// 1. 当前线程没有被中断，返回0\n// 2. 当前线程被中断 + 中断发生在ConditionObject.signal()调用之前，执行自旋入队操作，返回THROW_IE(-1)\n//    时序：中断（直接中断await线程，继续执行） -> signal，\n//    这种情况下，中断先发生，按照正常语义，对应线程已经没有继续执行的必要，因此转移到同步队列后，需要再次抛出异常，取消排队\n// 3. 当前线程被中断 + 中断发生在ConditionObject.signal()调用之后，自旋等待入队操作的完成，返回REINTERRUPT(1)\n//    时序：signal（完成节点转移才会唤醒await线程，继续执行） -> 中断，\n//    这种情况下，signal先发生，按照正常语义，对应的线程应该继续执行\n// 代码的套路好深啊！！\nprivate int checkInterruptWhileWaiting(Node node) {\n    return Thread.interrupted() ? // 返回线程是否被中断，并重置中断状态\n                    (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) :\n                    0; // 没有被线程没有被中断，返回0\n}\n```\n\n#### transferAfterCancelledWait\n```java\n// From AQS\n// 如果线程中断发生在ConditionObject.signal()调用之前，执行入队操作，返回true，对应THROW_IE\n// 如果线程中断发生在ConditionObject.signal()调用之后，自旋等待入队操作完成，返回false，对应REINTERRUPT\n// 即便发生中断，也会自旋完成节点的转移，这一点很重要！！\nfinal boolean transferAfterCancelledWait(Node node) {\n    if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) { // 很巧妙的设计！！\n        // CAS成功地将节点的等待状态从CONDITION置为0，则进入同步队列\n        // 执行到这里，说明是ConditionObject.signal（实际上是transferForSignal）尚未被调用\n        // 因为ConditionObject.signal在将节点转移到同步节点时也会执行同样的CAS操作（将节点的等待状态从CONDITION置为0）\n        // 如果ConditionObject.signal的CAS操作成功了，上面的CAS操作就会失败\n        // 因此返回true，表明中断发生在ConditionObject.signal()之前\n\n        // 这会导致transferForSignal不会继续执行转移操作，因此这里要完成transferForSignal本该完成的工作（节点转移）\n        // 自旋进入同步队列！！\n        enq(node);\n        return true;\n    }\n\n    // 执行到这里是因为ConditionObject.signal已经将节点的等待状态置为0，导致上面的CAS操作失败\n    // 因此返回false，表明中断发生在ConditionObject.signal()调用之后，这时节点转移可能还没有完成（这个概率很低）\n    // 出现这种情况，就通过自旋来等待转移操作完成（即便发生中断，依旧会转移节点）！！\n    while (!isOnSyncQueue(node))\n        Thread.yield(); // 尝试让出CPU资源，但不会让出锁资源\n    return false;\n}\n```\n\n### reportInterruptAfterWait\n```java\n// From ConditionObject\n// 依据不同的中断模式，向调用方报告当前线程的中断情况\n// 1. 如果中断模式是THROW_IE时，则抛出InterruptedException异常\n// 3. 如果中断模式是REINTERRUPT时，则执行线程自我中断，重置当前线程中断状态\nprivate void reportInterruptAfterWait(int interruptMode) throws InterruptedException {\n    if (interruptMode == THROW_IE)\n        throw new InterruptedException();\n    else if (interruptMode == REINTERRUPT)\n        selfInterrupt();\n}\n```\n\n## signal\n有一点需要说明，ConditionObject.signal**`并不总是直接唤醒线程`**，而是首先将节点从`条件队列`转移到`同步队列`，再依据在`同步队列中前驱节点的等待状态`做不同的处理\n1. 如果`被转移的节点`在同步队列中的**`前驱节点没有被取消`**，那么`被转移的节点`在`同步队列`中`等待锁`\n2. 如果`被转移的节点`在同步队列中的**`前驱节点被取消`**了，才会`直接唤醒被转移节点`的关联线程，这点比较重要，不要认为signal就是直接唤醒\n\n```java\n// From ConditionObject\n// 从条件队列头节点开始遍历，找出第一个需要转移的节点，并转移到同步队列\npublic final void signal() {\n    if (!isHeldExclusively()) // 当前线程是否持有独占锁\n        // 说明调用ConditionObject.signal()方法之前必须先持有与ConditionObject关联的独占锁\n        throw new IllegalMonitorStateException();\n    Node first = firstWaiter;\n    if (first != null)\n        // 条件队列不为空时，从条件队列头节点开始遍历，找出第一个需要转移的节点，并转移到同步队列\n        doSignal(first);\n}\n```\n\n### isHeldExclusively\n```java\n// From Sync\nprotected final boolean isHeldExclusively() {\n    return getExclusiveOwnerThread() == Thread.currentThread();\n}\n```\n\n### doSignal\n```java\n// From ConditionObject\n// 从条件队列头节点开始遍历，找出第一个需要转移的节点，并转移到同步队列\nprivate void doSignal(Node first) {\n    do {\n        if ( (firstWaiter = first.nextWaiter) == null)\n            // 如果条件队列的头结点为null，条件队列的尾节点必为null\n            lastWaiter = null;\n        // first将要被转移到同步队列，需要从条件队列中断开\n        first.nextWaiter = null;\n    } while (\n        // 没有成功转移有效节点并且未达到条件队列尾节点，继续循环\n        !transferForSignal(first) && (first = firstWaiter) != null);\n}\n```\n\n#### transferForSignal\n```java\n// From AQS\n// 将节点从条件队列转移到同步队列，转移成功且没有被中断则返回true，因中断而取消则返回false\n// 即成功转移有效节点返回true，否则返回false\nfinal boolean transferForSignal(Node node) {\n    // 转移节点之前首先将其等待状态设置为0\n    // 这与ReentrantLock.lock()竞争锁失败时，封装成节点并准备进入同步队列的场景保持一致\n    // 那时节点的等待状态也是0，因此当前节点准备进入同步队列前，等待状态也设置为0\n    if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))\n        // 节点的等待状态为0：在transferForSignal被调用前，线程因中断而退出休眠状态，继续执行await()后半段代码\n        // 这会通过transferAfterCancelledWait来校验中断发生在transferForSignal之前还是transferForSignal之后\n        // 如果是之前，那么此时的预期值为0，CAS会失败，直接返回false，\n        // transferAfterCancelledWait()方法会在中断产生时完成节点转移工作，进入下一循环\n        return false;\n\n    // 节点自旋进入同步队列，并返回前驱节点\n    // 更详细的分析请参照博文：「并发 - JUC - ReentrantLock - 源码剖析」\n    Node p = enq(node);\n    int ws = p.waitStatus; // 前驱节点的等待状态\n\n    // 1. ws>0，说明前驱节点的等待状态为CANCELLED，放弃竞争锁，直接唤醒当前节点\n    // 2. 如果ws<=0，则统一将前驱节点跟新为SIGNAL，表示当前驱节点取消时，能够唤醒当前节点，当前节点可以被安全地挂起\n    //    如果CAS更新失败，则直接唤醒当前节点\n    // 简单概括起来就是如果前驱节点取消了，就直接唤醒当前节点\n    if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))\n        LockSupport.unpark(node.thread); // 线程被唤醒后会继续执行await()的后半段代码\n    return true;\n}\n```\n\n## awaitUninterruptibly\n前面分析的`await()`方法是`响应中断`的，本节介绍的`waitUninterruptibly()`是`不响应中断`的\n```java\n// From ConditionObject\n// 与await()方法类似，仅标注不一样的地方\npublic final void awaitUninterruptibly() {\n    Node node = addConditionWaiter();\n    int savedState = fullyRelease(node);\n    boolean interrupted = false;\n    while (!isOnSyncQueue(node)) {\n        LockSupport.park(this);\n        if (Thread.interrupted())\n            // 如果曾经由于中断而退出休眠状态，而标记被中断\n            interrupted = true;\n    }\n    if (acquireQueued(node, savedState) || interrupted)\n        selfInterrupt(); // 在节点转移过程中，如果曾经被中断，则重新设置中断标志\n}\n```\n\n## await(long time,TimeUnit unit)\n前面分析的`await()`方法是`不限时等待`的，本节介绍的`await(long time,TimeUnit unit)`是`限时等待`的\n```java\n// From ConditionObject\n// 与await()方法类似，仅标注不一样的地方\npublic final boolean await(long time, TimeUnit unit) throws InterruptedException {\n    // 剩余的等待时长（纳秒）\n    long nanosTimeout = unit.toNanos(time);\n    if (Thread.interrupted())\n        throw new InterruptedException();\n    Node node = addConditionWaiter();\n    int savedState = fullyRelease(node);\n    // 超时的绝对时间\n    final long deadline = System.nanoTime() + nanosTimeout;\n    // 标注是否超时\n    boolean timedout = false;\n    int interruptMode = 0;\n    while (!isOnSyncQueue(node)) {\n        if (nanosTimeout <= 0L) {\n            // 剩余的等待时长为非正值，说明超时了，则执行transferAfterCancelledWait并取消等待\n            // transferAfterCancelledWait如果返回true，说明节点转移成功\n            // transferAfterCancelledWait如果返回false，说明在超时发生前，ConditionObject.signal已经触发，可以归纳为没有超时\n            timedout = transferAfterCancelledWait(node);\n            break;\n        }\n        // 当剩余的等待时长不小于1000纳秒时，这选择限时挂起线程，线程在nanosTimeout会自动唤醒（假如期间没有被中断）\n        // 当剩余的等待时长小于1000纳秒时，选择自旋，不挂起线程\n        if (nanosTimeout >= spinForTimeoutThreshold)\n            LockSupport.parkNanos(this, nanosTimeout);\n        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)\n            break;\n        // 更新剩余的等待时长\n        nanosTimeout = deadline - System.nanoTime();\n    }\n    if (acquireQueued(node, savedState) && interruptMode != THROW_IE)\n        interruptMode = REINTERRUPT;\n    if (node.nextWaiter != null)\n        unlinkCancelledWaiters();\n    if (interruptMode != 0)\n        reportInterruptAfterWait(interruptMode);\n    return !timedout; // 返回是否await等待超时\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["AQS"],"categories":["Concurrent"]},{"title":"Java并发 -- ReentrantLock","url":"%2F2016%2F08%2F08%2Fconcurrent-reentrantlock%2F","content":"\n{% note info %}\n本文将通过剖析`ReentrantLock`的源码来介绍其实现原理（关于`Condition`的内容，后面会单独成文）\n代码托管在https://github.com/zhongmingmao/concurrent_demo\n关于`CAS`的内容请参考「并发 - Unsafe类的简单使用」，本文不再赘述\n关于`LockSupport`的内容请参考「并发 - JUC - LockSupport - 源码剖析」，本文不再赘述\n原创不易，转载请注明出处：http://zhongmingmao.me/2016/08/09/concurrent-reentrantlock/\n{% endnote %}\n\n<!-- more -->\n\n# 基础\n\n## Lock接口\n`ReentrantLock`实现了`java.util.concurrent.locks.Lock`，其中定义了`lock()`、`tryLock()`、`unlock()`等核心方法\n```java\npublic interface Lock {\n    // 加锁\n    void lock();\n    // 可中断获取锁（synchronized获取锁进入阻塞时是无法响应中断）\n    void lockInterruptibly() throws InterruptedException;\n    // 尝试获取锁，非阻塞\n    boolean tryLock();\n    // 尝试获取锁，等待若干时间\n    boolean tryLock(long time, TimeUnit unit) throws InterruptedException;\n    // 解锁\n    void unlock();\n    // 与该Lock绑定的Condition实例\n    // 当前线程获取锁后，才能调用Condition.await()，调用后，当前线程将自动释放锁\n    // 本文不关注Condition的内容\n    Condition newCondition();\n}\n```\n\n## AbstractQueuedSynchronizer\n\n### 概述\n\n`AbstractQueuedSynchronizer`简称`AQS`，是`JUC`中一个`基础组件`，用来构建`同步工具`，例如本文的主题`ReentrantLock`，下图是一些使用了`AQS`的`同步工具`\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/reentrantlock_aqs.png\" width=\"500\">\n\n### 核心结构\n```java\n// AQS中存在两种队列：同步队列（sync queue）和条件队列（condition queue）\n// 本文仅关注同步队列，不关注条件队列\n// 同步队列实际上由Node构成的的双向非循环链表\npublic abstract class AbstractQueuedLongSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable {\n    // 同步队列的\"头节点\"，如果不为null，其等待状态（waitStatus）不为CANCELLED\n    private transient volatile Node head;\n    // 同步队列的尾节点\n    private transient volatile Node tail;\n    // 同步状态（synchronization state），代表锁的状态，\n    // 0表示锁没有线程被持有，大于0（AQS支持可重入锁）表示被线程持有\n    private volatile long state;\n}\n\npublic abstract class AbstractOwnableSynchronizer implements java.io.Serializable {\n    // 采用独占模式进行同步时，持有独占锁的线程\n    private transient Thread exclusiveOwnerThread;\n}\n```\n\n## Node\n`Node`用于`包装线程`，是`同步队列`中的节点\n```java\nstatic final class Node {\n    // 本文不关注该模式\n    static final Node SHARED = new Node();\n    // 节点处于独占模式\n    static final Node EXCLUSIVE = null;\n\n    // 理解节点的等待状态（waitStatus）非常重要，附带源码注释帮助理解\n    /**\n     * This node is cancelled due to timeout or interrupt.\n     * Nodes never leave this state. In particular,\n     * a thread with cancelled node never again blocks.\n     */\n    // 由于超时或中断而导致当前线程（对应同步队列中的一个节点）被取消\n    // CANCELLED是终态\n    // 被取消了的节点对应的线程永远不会阻塞，放弃竞争锁\n    static final int CANCELLED =  1;\n    /**\n     * The successor of this node is (or will soon be) blocked (via park),\n     * so the current node must unpark its successor when it releases or cancels.\n     * To avoid races, acquire methods must first indicate they need a signal,\n     * then retry the atomic acquire, and then, on failure, block.\n     */\n    // 当前节点的后继节点通过park操作被阻塞（或将要被阻塞）\n    // 因此当前节点在它们释放锁或被取消的时候，需要通过unpark操作唤醒它的后继节点\n    // 为了避免竞争（依据等待状态进行筛选，无需全部唤醒），\n    // 执行竞争锁的方法（acquire methods）的线程首先需要表明它们需要被唤醒，\n    // 如果竞争锁失败，它们就会被阻塞，等待被唤醒\n    // 是否需要被唤醒，其实是记录在当前节点的前驱节点的等待状态中\n    // 因此SIGNAL表示后继节点需要被唤醒，这一点非常重要！！\n    static final int SIGNAL    = -1;\n    // 本文不关注该状态\n    static final int CONDITION = -2;\n    // 本文不关注该状态\n    static final int PROPAGATE = -3;\n\n    /**\n     * Status field, taking on only the values:\n     *      CANCELLED / SIGNAL / CONDITION / PROPAGATE / 0\n     * Non-negative values mean that a node doesn't need to signal\n     * So, most code doesn't need to check for particular values, just for sign.\n     * The field is initialized to 0 for normal sync nodes, and CONDITION for condition nodes.\n     */\n    // 等待状态，只能为CANCELLED、SIGNAL、CONDITION、PROPAGATE或0\n    // 非负值（CANCELLED和0）表示节点关联的线程不需要被唤醒\n    // 同步队列中节点的等待状态初始化为0，条件队列中节点的等待状态初始化为CONDITION（本文不关心条件队列）\n    volatile int waitStatus;\n\n    // 同步队列中的前驱节点\n    volatile Node prev;\n    // 同步队列中的后继节点\n    volatile Node next;\n    // 请求锁的线程\n    volatile Thread thread;\n    // 条件队列的后继节点，本文不关注\n    Node nextWaiter;\n}\n```\n\n## 同步队列\n在介绍了`AQS的核心结构`和节点`Node`以后，可以很容易得出`同步队列的结构图`如下\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/reentrantlock_aqs_sync_queue_1.png\" width=\"500\">\n\n## 公平锁与非公平锁\n`ReentrantLock`支持`公平锁`和`非公平锁`，锁的管理分别由`FairSync`和`NonfairSync`来具体控制，\n\n### ReentrantLock构造函数\n```java\n// Sync为抽象类，进行锁的管理，两个实现类为FairSync（公平锁）和NonfairSync（非公平锁）\nprivate final Sync sync;\n\n// 默认构造函数，创建非公平锁NonfairSync\npublic ReentrantLock() {\n    sync = new NonfairSync();\n}\n// 构造函数，依据参数，选择公平锁FairSync还是非公平锁NonfairSync\npublic ReentrantLock(boolean fair) {\n   sync = fair ? new FairSync() : new NonfairSync();\n}\n```\n\n### UML\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/reentrantlock_fair_nonfair_uml.png\" width=\"500\">\n`FairSync`和`NonfairSync`是`AQS`的实现类，`ReentrantLock`通过`FairSync`实现公平策略和通过`NonfairSync`实现非公平策略\n\n# 源码分析 - 非公平锁\n\n## ReentrantLock.lock\n```java\n// From ReentrantLock\npublic void lock() {\n    // 采用非公平锁时，实际调用的是NonfairSync.lock()\n    sync.lock();\n}\n```\n\n### NonfairSync.lock\n```java\n// From NonfairSync\n// 首先尝试快速抢占独占锁，如果失败，则回退到正常的独占锁请求流程\nfinal void lock() {\n    // 一开始就立马尝试通过CAS操作获取独占锁，具有抢占性质，\n    // 非公平，不考虑是否已经有其他线程在排队等待独占锁\n    // 这是与公平锁的区别1\n    if (compareAndSetState(0, 1))\n        // 并发情况下，最多只有一个线程能CAS更新成功，即持有独占锁，记录持有独占锁的线程（即当前线程）\n        // 如果线程能CAS更新失败，说明同步状态的预期值不是0，独占锁已经被其他线程持有\n        // compareAndSetState(0,n)其实就是尝试抢占锁，下面分析不再重复说明这一点\n        setExclusiveOwnerThread(Thread.currentThread());\n    else\n        // 快速抢占独占锁失败，则回退到正常的独占锁请求流程，有可能会挂起当前线程\n        // 请求独占锁，不响应中断\n        acquire(1);\n}\n```\n```java\n// From AbstractOwnableSynchronizer\n// 记录持有独占锁的线程\nprotected final void setExclusiveOwnerThread(Thread thread) {\n    exclusiveOwnerThread = thread;\n}\n```\n\n### AQS.acquire\n`AQS`即`AbstractQueuedSynchronizer`的简称，下面分析不再重复说明这一点\n`acquire(int arg)`是正常的独占锁请求流程\n```java\n// From AQS\n// 请求独占锁，不响应中断\n// 至少调用一次tryAcquire来尝试获得独占锁，tryAcquire有公平和非公平的两种策略，这里先关注非公平策略\n// tryAcquire成功则直接返回，否则进入同步队列进行排队\npublic final void acquire(int arg) {\n    if (!tryAcquire(arg) && // 实际调用Sync.nonfairTryAcquire，非公平策略\n            // addWaiter：进入同步队列并返回节点（包装了当前线程）\n            // acquireQueued：节点就会进入一个\"自旋\"过程，待条件满足时尝试获取锁，如果成功则从同步队列退出，并结束自旋\n            //     如果退出休眠状态是由于中断导致的，返回true，正常情况下应该返回false\n            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n      // 由于中断而退出休眠状态，则自我中断，设置中断标志\n      selfInterrupt();\n}\n```\n```java\n// From AQS\n// 当前线程自我中断，设置中断标志\nstatic void selfInterrupt() {\n    Thread.currentThread().interrupt();\n}\n```\n\n#### Sync.nonfairTryAcquire\n```java\n// From Sync\n// 非公平策略tryAcquire\n// 如果当前线程能成功获得独占锁，返回true，否则返回false，具体逻辑如下：\n// 1. 直接尝试通过CAS操作获取独占锁（非公平），如果获取成功，直接返回true\n// 2. 直接获取独占锁失败，判断是否是锁重入，如果是返回true\n// 3. 上述两种情况都不是，返回false\nfinal boolean nonfairTryAcquire(int acquires) {\n    final Thread current = Thread.currentThread();\n    int c = getState();\n    // 同步状态为0，说明当前没有线程持有独占锁\n    if (c == 0) {\n        // 不考虑是否有线程在排队等待独占锁，直接尝试通过CAS操作抢占锁，不公平\n        // 这是与公平锁的区别2\n        if (compareAndSetState(0, acquires)) {\n            // 仅有一个线程能CAS更新成功，获得独占锁\n            setExclusiveOwnerThread(current);\n            return true;\n        }\n    }\n    // 如果同步状态不为0，说明独占锁已被占用，判断当前线程是否是独占锁的持有者\n    else if (current == getExclusiveOwnerThread()) {\n        // 如果当前线程是独占锁的持有者，采取可重入逻辑\n        // 因为是独占锁，只有一个线程能进入到该代码块\n        int nextc = c + acquires;\n        if (nextc < 0)\n            throw new Error(\"Maximum lock count exceeded\");\n        setState(nextc);\n        return true;\n    }\n    // 独占锁被其他线程占用\n    // 执行后续逻辑acquireQueued(addWaiter(Node.EXCLUSIVE), arg))，入队+自旋\n    return false;\n}\n```\n\n#### AQS.addWaiter\n`tryAcquire`失败后（**`即独占锁被其他线程持有`**），首先调用`addWaiter`，进行入队\n```java\n// From AQS\n// 尝试获取锁失败后，封装当前线程成一个节点，并进行入队（同步队列）操作，并返回刚刚创建的节点\n// 首先尝试快速版本的入队操作，失败后再进行完整版本的入队操作\n// 快速版本：CAS竞争入队\n// 完整版本：head与tail的懒初始化 + 自旋CAS竞争入队\nprivate Node addWaiter(Node mode) {\n    // 将当前线程封装成节点，节点处于独占模式\n    Node node = new Node(Thread.currentThread(), mode);\n\n    // ========== 快速版本的入队操作，假设当前队列不为空，直接CAS竞争入队\n    Node pred = tail; // 暂存同步队列的尾节点\n    if (pred != null) { // 队列不为空\n        // 首先将刚刚获取的尾节点设置为当前节点的前驱节点\n        // 在并发时，此时尾节点有可能已经不是pred，下面的CAS操作就会失败\n        node.prev = pred;\n        if (compareAndSetTail(pred, node)) {\n            // 在并发时，只有一个线程能入队成功，将尾节点的后继节点设置为当前节点，形成双向链表\n            pred.next = node;\n            return node;\n        }\n        // 并发更新CAS失败的节点，将执行完整版的入队操作enq(node)\n    }\n\n    // ========== 完整版本的入队操作，进行head与tail的懒初始化 + 通过自旋进行CAS竞争入队操作\n    // 完整版本 = 自旋的快速版本 + head与tail的懒初始化\n    enq(node);\n    return node;\n}\n```\n```java\n// From AQS\n// 当 队列为空时 或 CAS入队失败 采用完整版的入队操作\n// 进行head与tail的懒初始化 + 通过自旋进行CAS竞争入队操作\nprivate Node enq(final Node node) {\n    for (;;) { // 自旋，不响应中断\n        Node t = tail; // 获取最新的尾节点，在并发情况下，有可能需要进行多次循环\n        if (t == null) { // 第1次入队，tail和head均为null，队列为空\n            if (compareAndSetHead(new Node()))\n                // 在并发时，最多只有一个线程能成功设置head，\n                // 其他线程失败后直接接着下一个循环，进入else分支，不会直接return，这点很重要！！\n                // head与tail是懒初始化\n                // 同步队列的\"头节点\"的等待状态此时为0，thread为null\n                tail = head;\n        } else {  // 队列不为空，往队列尾部添加当前节点node\n            node.prev = t; // 将本次循环获取的尾节点设置为当前节点的前驱节点\n            if (compareAndSetTail(t, node)) {\n                // 在并发时，只有一个线程能入队成功，将尾节点的后继节点指向当前节点，形成双向链表\n                t.next = node;\n                // enq方法返回的是t，而非node，这是与快速版本的另一个区别，主要用于条件队列，本文不关注\n                return t;\n            }\n            // 并发更新CAS失败的节点，将进入下一循环，参与下一轮的CAS竞争\n        }\n    }\n}\n```\n`addWaiter`逻辑示意图：\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/reentrantlock_aqs_addWaiter.png\" width=\"500\">\n\n#### AQS.acquireQueued\n`acquireQueued(final Node node, int arg)`是非公平锁的`lock`执行路径上**`最为重要的的方法`**！！\n`addWaiter`之后，当前线程对相应的节点已经成功地添加到`同步队列`的`\"队尾\"`\n```java\n// From AQS\n// 当前线程进入一个自旋过程，待条件满足时会尝试获取独占锁，如果成功获取独占锁则从同步队列退出，并结束自旋\nfinal boolean acquireQueued(final Node node, int arg) {\n    boolean failed = true;\n    try {\n        boolean interrupted = false;\n        for (;;) { // 自旋，不响应中断\n            final Node p = node.predecessor(); // 当前节点的前驱节点\n            // 当前驱节点为head时，而head中不包含线程信息，\n            // head的后继节点才是同步队列中是第1个拥有线程信息的节点\n            // 尝试获得独占锁，符合同步队列\"FIFO\"的特性\n            if (p == head && tryAcquire(arg)) {\n                // 当前线程对应的节点为head的后继节点并且当前线程成功持有独占锁\n                // 将head更新为当前线程对应的节点，并且去除无用的线程信息和前驱节点信息，但仍然需要保留等待状态信息\n                setHead(node);\n                // head已经被更新，p作为旧head，无需保持后继节点属性，加快旧head的垃圾回收\n                p.next = null;\n                failed = false;\n                // 唯一的return语句，表明当前线程会一直自旋（可能会被挂起）\n                // 直到当前节点成为head的后继节点并成功持有独占锁\n                return interrupted;\n            }\n            // 如果不满足条件：当前线程对应的节点是head的后继节点，并且当前线程成功持有独占锁，那么就要考虑挂起当前线程\n            // shouldParkAfterFailedAcquire是判断能否安全地挂起当前线程\n            // 安全的意思是指前驱节点（包括head节点）的等待状态为SIGNAL\n            // 如果能够安全地挂起当前线程，就挂起线程并等待唤醒或中断（退出休眠状态）\n            // 被唤醒或中断后，进入下一轮循环，有可能再次挂起线程\n            if (shouldParkAfterFailedAcquire(p, node) &&\n                // 挂起当前线程，进入休眠状态，并判断退出休眠状态的原因是不是由于中断导致的\n                parkAndCheckInterrupt())\n                interrupted = true; // 由于中断导致退出休眠状态\n        }\n    } finally {\n        if (failed)\n            // 代码实际上不会执行到这里\n            // 个人理解：只是为了与doAcquireInterruptibly和doAcquireNanos等方法的代码风格保持一致\n            cancelAcquire(node);\n    }\n}\n```\n```java\n// From AQS\n// 将head更新为当前线程对应的节点，并且去除无用的线程信息和前驱节点信息，但仍然需要保留等待状态信息\nprivate void setHead(Node node) {\n    head = node;\n    node.thread = null; // 线程信息已经保存在exclusiveOwnerThread中，无需在节点中保留\n    node.prev = null; // 同步队列是双向非循环链表，head节点无需前驱节点信息，加快旧head的回收\n}\n```\n\n##### AQS.shouldParkAfterFailedAcquire\n```java\n// From AQS\n// 当前线程不持有独占锁，判断能否安全地挂起线程\n// 在本文仅需关注等待状态的3个可能值：CANCELLED(1)、SIGNAL(-1)、0\nprivate static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {\n    // pred记为前驱节点，node记为当前节点\n    int ws = pred.waitStatus; // 前驱节点的等待状态\n    if (ws == Node.SIGNAL) // SIGNAL(-1)\n        // 前驱节点的等待状态为SIGNAL\n        // 表明前驱节点对应的线程在释放锁或被中断的时候会唤醒当前节点对应的线程，可以安全挂起当前线程\n        return true;\n    if (ws > 0) { // CANCELLED(1)\n        // 唤醒的操作是由前驱节点完成的，而前驱节点的状态为CANCELLED时，是不会唤醒当前线程的\n        // 因此直接挂起当前线程是不安全的，需要将当前节点的前驱节点设置非CANCELLED的节点\n        // 从前驱节点往前遍历，直到找到等待状态不是CANCELLED的节点为止，并将当前节点的前驱节点属性指向\"新的前驱节点\"\n        do {\n            node.prev = pred = pred.prev;\n        } while (pred.waitStatus > 0);\n        // 找到\"新的前驱节点\"后，将\"新的前驱节点\"的后继节点设置为当前节点，为了保证双向链表，这会导致跳过一堆CANCELLED节点\n        pred.next = node;\n    } else { // 0\n        // 个人理解，前驱节点的等待状态为0，有两种情况\n        // 情况1：\n        //   第1次进入时，前驱节点（包括head）的等待状态为0\n        //   参照上面的addWaiter方法可知，节点入队时的等待状态为0\n        //   CAS设置前驱节点的等待状态为SIGNAL，下个循环即可直接离开，进入线程挂起操作\n        // 情况2：下面这段注释比较难理解，需要结合unlock的代码来理解\n        //   unlock操作会唤醒head的后继节点对应的线程，而被唤醒的线程会参与竞争独占锁（tryAcquire）\n        //   另外非公平锁的lock操作具有抢占性质，一开始就会通过compareAndSetState(0,acquires)来竞争独占锁\n        //   从而在unlock与lock存在并发时，有可能导致被unlock操作唤醒的线程T竞争独占锁失败，那么就要考虑是否能够安全地再次挂起线程T\n        //   而在unlock的执行路径上会将head的waitstatus在unlock时会被CAS设置成0，显然是不能安全地挂起线程T\n        //   因此需要重新将head的waitstatus重新设置为SIGNAL，从而保证等待状态的语义一致性\n        // Doug Lea大神的代码套路太深，后面还需多次阅读\n        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);\n    }\n    // 前驱节点的等待状态不为SIGNAL时，直接挂起当前线程是不安全的，因为当前线程需要前驱节点对应的线程唤醒，因此直接返回false，等待下一循环\n    // 下一循环有可能成为head的后继节点并持有独占锁成功，省去了挂起/唤醒操作，这是自旋可能带来的好处，但实际上发生概率不高\n    return false;\n}\n```\n\n##### AQS.parkAndCheckInterrupt\n```java\n// From AQS\n// 挂起当前线程，进入休眠状态，在退出休眠状态后，返回当前线程是否由于中断而退出休眠状态\nprivate final boolean parkAndCheckInterrupt() {\n    // 将当前线程挂起，进入休眠状态，等待被唤醒或中断\n    LockSupport.park(this);\n    // 退出休眠状态的3种情况，其中两种为：其他线程unpark当前线程；其他线程中断当前线程\n    // 通过获取当前线程的中断标志来判断当前线程是否由于中断而导致退出休眠状态的\n    // Thread.interrupted()：判断当前线程是否被中断并重置当前线程的中断状态\n    // 重置当前线程的中断状态是因为在acquireQueued方法中是一个\"自旋过程\"，需要在每次循环中获取准确的值\n    return Thread.interrupted();\n}\n```\n\n\n## ReentrantLock.unlock\n```java\n// From ReentrantLock\npublic void unlock() {\n    // lock实际是acquire(1)，unlock实际是relase(1)\n    // 因此lock与unlock应该配对出现\n    sync.release(1);\n}\n```\n```java\n// From AQS\n// 释放独占锁\npublic final boolean release(int arg) {\n    if (tryRelease(arg)) { // 实际调用的Sync.tryRelease\n        Node h = head;\n        if (h != null && h.waitStatus != 0)\n            // 如果head的等待状态不为0，正常情况下为SIGNAL，唤醒head的后继节点\n            unparkSuccessor(h);\n        return true;\n    }\n    return false;\n}\n```\n\n### Sync.tryRelease\n```java\n// From Sync\n// 尝试释放锁\nprotected final boolean tryRelease(int releases) {\n    int c = getState() - releases;\n    if (Thread.currentThread() != getExclusiveOwnerThread())\n        // 仅允许持有独占锁的线程释放锁\n        throw new IllegalMonitorStateException();\n    boolean free = false;\n    if (c == 0) {\n        // 锁是可重入的，当同步状态为0，表示可以释放锁\n        free = true;\n        // 重置独占锁的持有者为null，表示当前没有线程持有独占锁\n        setExclusiveOwnerThread(null);\n    }\n    setState(c);\n    return free;\n}\n```\n\n### AQS.unparkSuccessor\n```java\n// From AQS\n// 唤醒后继节点\nprivate void unparkSuccessor(Node node) {\n    int ws = node.waitStatus;\n    if (ws < 0)\n        // 如果当前节点的等待状态为SIGNAL（本文仅关注CANCELLED、SIGNAL和0），CAS更新为0\n        // 表示当前节点不再有唤醒后继节点对应线程的义务，因为现在已经在执行唤醒操作\n        // 如果被唤醒的后继节点对应的线程参与竞争锁失败，shouldParkAfterFailedAcquire会将前驱节点的waitStatus重置为SIGNAL\n        // 从而可以再次安全地挂起线程\n        compareAndSetWaitStatus(node, ws, 0);\n\n    // s为待唤醒的节点，表示离当前节点最近且等待状态不为CANCELLED的\"后继节点\"\n    // 在正常情况下，s为当前节点的后继节点\n    Node s = node.next;\n    // 如果s为null或者s的等待状态为CANCELLED，需要跳过，往后遍历\n    if (s == null || s.waitStatus > 0) {\n        s = null;\n        // 从尾节点开始向当前节点遍历，获取离当前节点最近且等待状态不为CANCELLED的节点\n        for (Node t = tail; t != null && t != node; t = t.prev)\n            if (t.waitStatus <= 0)\n                s = t;\n    }\n    if (s != null)\n        // 唤醒线程\n        LockSupport.unpark(s.thread);\n}\n```\n到这里并没有会产生`取消`节点（等待状态为`CANCELLED`）的代码，暂时不考虑`CANCELLED`的节点状态，结合前面的`lock`代码，`unlock`的逻辑示意图如下\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/reentrantlock_aqs_unlock.png\" width=\"500\">\n\n\n# 源码分析 - 公平锁\n分析了`非公平锁`的`lock`和`unlock`源码后，再分析`公平锁`就比较简单了\n`unlock`的实现在`AQS.release(int arg)`中，没有公平与否的差异，主要差异在`lock`操作，下面关注`lock`操作的差异\n\n## ReentrantLock.lock\n```java\n// From FairSync\nfinal void lock() {\n    // 非公平锁会首先执行compareAndSetState(0,1)来尝试抢占锁，失败后才会执行acquire(1)\n    // 公平锁直接执行acquire(1)，即正常的独占锁请求流程\n    acquire(1);\n}\n```\n```java\n// From AQS\npublic final void acquire(int arg) {\n    // tryAcquire有公平策略和非公平策略，上面已经分析过了非公平策略，这里关注公平策略\n    if (!tryAcquire(arg) &&\n        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n        selfInterrupt();\n}\n```\n```java\n// From FairSync\n// 公平策略的tryAcquire\nprotected final boolean tryAcquire(int acquires) {\n    final Thread current = Thread.currentThread();\n    int c = getState();\n    if (c == 0) {\n        // 非公平锁没有hasQueuedPredecessors判断\n        // 公平锁首先会进行hasQueuedPredecessors判断，查询是否有线程比当前线程等待了更长时间\n        if (!hasQueuedPredecessors() &&\n            compareAndSetState(0, acquires)) {\n            setExclusiveOwnerThread(current);\n            return true;\n        }\n    } else if (current == getExclusiveOwnerThread()) {\n        int nextc = c + acquires;\n        if (nextc < 0)\n            throw new Error(\"Maximum lock count exceeded\");\n        setState(nextc);\n        return true;\n    }\n    return false;\n}\n```\n```java\n// From AQS\n// 查询是否有线程比当前线程等待了更长时间\n// 如果当前线程对应的节点之前是否存在有效节点（即非head），返回true\n// 如果当前线程是head的后继节点或队列为空，返回false\npublic final boolean hasQueuedPredecessors() {\n   Node t = tail;\n   Node h = head;\n   Node s;\n   return h != t && // 队列不为空\n        // head的后继节点的关联线程不是当前线程\n        ((s = h.next) == null || s.thread != Thread.currentThread());\n}\n```\n\n# 源码分析 - CANCELLED\n上面的逻辑示意图中，选择性地忽略节点等待状态为`CANCELLED`的情况，\n下面将关注产生等待状态为`CANCELLED`的代码及其运行过程，\n由上面的源码分析可知，产生`CANCELLED`的原因有两个：**`中断`**或**`超时`**，\n因此下面关注两个代表性的方法：\n`lockInterruptibly`（中断） + `tryLock(long timeout,TimeUnit unit)`（超时），\n下面分析均以`非公平锁`为例\n\n## ReentrantLock.lockInterruptibly\n`lock`是不响应中断的，`lockInterruptibly`是可以**`响应中断`**的\n```java\n// From ReentrantLock\npublic void lockInterruptibly() throws InterruptedException {\n    // 实际调用的是AQS.acquireInterruptibly\n    sync.acquireInterruptibly(1);\n}\n```\n\n### AQS.acquireInterruptibly\n```java\n// From AQS\npublic final void acquireInterruptibly(int arg) throws InterruptedException {\n    if (Thread.interrupted())\n        // 在尝试获取锁之前，当前线程被中断，直接抛出InterruptedException\n        // 此时尚未入队，因此除了抛出异常，无需其他操作\n        throw new InterruptedException();\n    if (!tryAcquire(arg))\n        // 获取锁失败后，当前线程并未持有锁\n        doAcquireInterruptibly(arg);\n}\n```\n```java\n// From AQS\n// 代码结构acquireQueued非常类似，仅标注差异的地方\nprivate void doAcquireInterruptibly(int arg) throws InterruptedException {\n    // 首先进行入队操作\n    final Node node = addWaiter(Node.EXCLUSIVE);\n    boolean failed = true;\n    try {\n        for (;;) { // 自旋，可响应中断，抛出InterruptedException异常\n            final Node p = node.predecessor();\n            if (p == head && tryAcquire(arg)) {\n                setHead(node);\n                p.next = null;\n                failed = false;\n                return;\n            }\n            if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt())\n                // 如果是由于中断而退出休眠状态，直接抛出异常\n                // failed为true，会执行cancelAcquire，取消请求锁\n                throw new InterruptedException();\n        }\n    } finally {\n        if (failed)\n            // 当前线程取消请求锁，此时当前线程对应的节点已经入队\n            cancelAcquire(node);\n    }\n}\n```\n\n### AQS.cancelAcquire\n这是`lockInterruptibly`执行路径上**`最为重要的方法`**！！\n```java\n// From AQS\n// 取消请求锁\nprivate void cancelAcquire(Node node) {\n    if (node == null)\n        return; // 防御性编程\n    node.thread = null; // 清除当前线程对应节点的线程信息\n\n    // 跳过同步队列中等待状态为CANCELLED的前驱节点\n    // pred是从当前线程对应节点往前搜索第一个等待状态不是CANCELLED的节点N，节点N具有唤醒后继节点的能力\n    Node pred = node.prev;\n    while (pred.waitStatus > 0)\n        node.prev = pred = pred.prev;\n\n    // 用于后面代码CAS更新pread的next属性时的期望值\n    Node predNext = pred.next;\n\n    // 将当前线程对应节点的等待状态置为CANCELLED\n    node.waitStatus = Node.CANCELLED;\n\n    if (node == tail && compareAndSetTail(node, pred)) {\n        // 当前线程对应节点为尾节点，且将尾节点成功地CAS设置为原尾节点的前驱节点，这时需要清空新尾节点的后继节点属性（置为null）\n        compareAndSetNext(pred, predNext, null);\n    } else {\n        // 如果当前节点不是尾节点或者CAS更新队尾为pred失败（有可能addWaiter新增节点到队尾，当前节点不再是尾节点）\n        // 执行到这里表明当前节点必然有后继节点，需要结合等待状态串联当前节点的\"前驱节点\"和\"后继节点\"\n        int ws;\n\n        if (pred != head &&\n            ((ws = pred.waitStatus) == Node.SIGNAL || (ws <= 0 && compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &&\n            pred.thread != null) {\n            // 三个逻辑条件比较难理解，具体分析请参照else分支，概括起来就是：\n            // pred不是head + pred具有唤醒后继节点的能力 + pred此刻尚未在执行ancelAcquire或尚未成为新的head\n            // 如果此时后继节点的同步状态不为CANCELLED，尝试串联有意义的\"前驱节点\"和\"后继节点\"\n            // 如果此时后继节点的同步状态为CANCELLED，当前节点对应的线程无需任何操作，因为后继节点对应线程会做同样的尝试\n            Node next = node.next;\n            if (next != null && next.waitStatus <= 0)\n                // 后继节点的同步状态不为CANCELLED，说明等待被唤醒\n                // 将pred的后继节点设置为当前节点的后继节点，即pred->next\n                compareAndSetNext(pred, predNext, next);\n        } else {\n            // 1. 如果pred是head，可以直接唤醒node的后继节点\n            // 2. 如果pred不是head + pred已经不具有唤醒后继节点的能力，直接唤醒node的后继节点（可以跳过CANCELLED节点）\n            //    2.1 pred.waitStatus == Node.SIGNAL && !compareAndSetWaitStatus(pred, ws, Node.SIGNAL)\n            //    2.2 pred.waitStatus == 0 or Node.CANCELLED\n            // 3. 如果pred不是head + pred具有唤醒后继节点的能力 + pred此刻已经在执行ancelAcquire或已经成为新的head，直接唤醒node的后继节点\n            //    3.1 pred.waitStatus == Node.SIGNAL\n            //    3.2 pred.waitStatus == 0 && compareAndSetWaitStatus(pred, ws, Node.SIGNAL)\n            unparkSuccessor(node);\n        }\n\n        node.next = node; // 加快垃圾回收\n    }\n}\n```\n\n## ReentrantLock.tryLock(long timeout,TimeUnit unit)\n```java\n// From AQS\n// 实际调用的是sync.tryAcquireNanos(1, unit.toNanos(timeout))\npublic boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {\n   return sync.tryAcquireNanos(1, unit.toNanos(timeout));\n}\n```\n\n### AQS.tryAcquireNanos\n```java\n// From AQS\npublic final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException {\n    if (Thread.interrupted())\n        throw new InterruptedException();\n    return tryAcquire(arg)\n                || doAcquireNanos(arg, nanosTimeout); // 获取锁失败后，当前线程并未持有锁\n}\n```\n```java\n// From AQS\n// 代码结构doAcquireInterruptibly非常类似，仅标注差异的地方\nprivate boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException {\n    if (nanosTimeout <= 0L)\n        // nanosTimeout为非正值，不合法\n        // 此时尚未入队，无需其他操作，直接返回false\n        return false;\n    // 绝对时间\n    final long deadline = System.nanoTime() + nanosTimeout;\n    // 进入同步队列进行排队等待锁\n    final Node node = addWaiter(Node.EXCLUSIVE);\n    boolean failed = true;\n    try {\n        for (;;) { // 自旋，可响应中断，抛出InterruptedException；超时会取消请求并返回false\n            final Node p = node.predecessor();\n            if (p == head && tryAcquire(arg)) {\n                setHead(node);\n                p.next = null;\n                failed = false;\n                return true;\n            }\n            nanosTimeout = deadline - System.nanoTime();\n            if (nanosTimeout <= 0L)\n                // 超时会执行cancelAcquire来取消请求锁，然后返回false\n                return false;\n            if (shouldParkAfterFailedAcquire(p, node) &&\n                // 距离超时的时间大于spinForTimeoutThreshold时，挂起线程一段时间后自动退出休眠状态\n                // 前面lock执行路径上的acquireQueued方法和lockInterruptibly执行路径上的doAcquireInterruptibly方法都是调用parkAndCheckInterrupt，休眠直到被唤醒或被中断\n                // tryLock(long timeout,TimeUnit unit)的执行路径上是依据距离超时时间的多少进行限时休眠，自动唤醒\n                // 离超时时间仅剩1000纳秒时，采用自旋，不再挂起线程\n                nanosTimeout > spinForTimeoutThreshold)\n                LockSupport.parkNanos(this, nanosTimeout);\n            if (Thread.interrupted())\n                // 线程如果被中断，执行cancelAcquire来取消请求锁，然后抛出InterruptedException\n                throw new InterruptedException();\n        }\n    } finally {\n        if (failed)\n            cancelAcquire(node);\n    }\n}\n```\n\n## 逻辑示意图\n已经分析了产生`CANCELLED`节点的代码，以`中断`产生`CANCELLED`节点为例，下面是有`CANCELLED`节点参与的逻辑示意图\n\n### 代码\n```java\n/**\n * Debug查看lockInterruptibly的时同步队列的变化过程\n */\npublic class LockInterruptiblyDemo {\n    static ReentrantLock lock = new ReentrantLock();\n    static Runnable task = () -> {\n        try {\n            System.out.println(String.format(\"%s acquire lock...\", Thread.currentThread().getName()));\n            lock.lockInterruptibly();\n            System.out.println(String.format(\"%s hold lock\", Thread.currentThread().getName()));\n        } catch (InterruptedException e) {\n            System.out.println(String.format(\"%s interrupted\", Thread.currentThread().getName()));\n        } finally {\n            // never unlock\n        }\n    };\n\n    public static void main(String[] args) throws InterruptedException {\n        Thread t0 = new Thread(task, \"t0\");\n        Thread t1 = new Thread(task, \"t1\");\n        Thread t2 = new Thread(task, \"t2\");\n        Thread t3 = new Thread(task, \"t3\");\n        Thread t4 = new Thread(task, \"t4\");\n\n        // 确保t0持有锁，排队顺序为t1->t2->t3\n        t0.start();\n        sleepForAwhile();\n        t1.start();\n        sleepForAwhile();\n        t2.start();\n        sleepForAwhile();\n        t3.start();\n        sleepForAwhile();\n\n        // 中断尾节点\n        t3.interrupt();\n        sleepForAwhile();\n\n        // t4加入排队\n        t4.start();\n        sleepForAwhile();\n\n        // 中断非尾节点、非head的后继节点\n        t2.interrupt();\n        sleepForAwhile();\n\n        // 中断head的后继节点\n        t1.interrupt();\n    }\n\n    private static void sleepForAwhile() throws InterruptedException {\n        TimeUnit.SECONDS.sleep(1);\n    }\n}\n```\n\n### 逻辑示意图\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/reentrantlock_aqs_lockInterruptibly.png\" width=\"500\">\n\n<!-- indicate-the-source -->\n","tags":["AQS"],"categories":["Concurrent"]},{"title":"Java并发 -- LockSupport","url":"%2F2016%2F08%2F06%2Fconcurrent-locksupport%2F","content":"\n{% note info %}\n本文将剖析`LockSupport`的源码及其实现原理，在博文末尾再补充`线程中断`的内容\n代码托管在https://github.com/zhongmingmao/concurrent_demo\n关于`Unsafe`类的内容请参考「并发 - Unsafe类的简单使用」，本文不再赘述\n{% endnote %}\n\n<!-- more -->\n\n# 源码分析\n\n## UML\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/locksupport_uml.png\" width=\"500\">\n\n## 实例域\n```java\npublic class LockSupport {\n    private static final sun.misc.Unsafe UNSAFE;\n    private static final long parkBlockerOffset;\n    static {\n        try {\n            // 获取Unsafe实例\n            UNSAFE = sun.misc.Unsafe.getUnsafe();\n            Class<?> tk = Thread.class;\n            // 获取java.lang.Thread中parkBlocker实例域在Thread对象内存布局中的偏移量\n            // 详细请参考博文「并发 - Unsafe类的简单使用」，不再赘述\n            parkBlockerOffset = UNSAFE.objectFieldOffset(tk.getDeclaredField(\"parkBlocker\"));\n        } catch (Exception ex) { throw new Error(ex); }\n    }\n}\n```\n```java\npublic class Thread implements Runnable {\n    // 提供给java.util.concurrent.locks.LockSupport调用\n    volatile Object parkBlocker;\n}\n```\n## 构造函数\n```java\n// 私有构造函数，无法实例化\nprivate LockSupport() {}\n```\n\n## park函数\n\n### park()\n```java\npublic static void park() {\n    // 当前线程进入无限期的等待状态（WAITING状态），除非许可证可用（最近调用过unpark）\n    // 如果许可证可用，那么立即返回，比wait()/notify()/notifyAll()灵活！！\n    // 退出WAITING状态的3种情况\n    //   1. 其他线程unpark当前线程\n    //   2. 其他线程中断当前线程\n    //   3. 该调用毫无理由地返回（这个不是很理解）\n    UNSAFE.park(false, 0L);\n}\n```\n\n### park(Object blocker)\n```java\npublic static void park(Object blocker) {\n    // 获取当前线程\n    Thread t = Thread.currentThread();\n    // 设置当前线程的实例域parkBlocker\n    setBlocker(t, blocker);\n    // 当前线程进入无限期的等待状态（WAITING状态），与park()函数一致\n    UNSAFE.park(false, 0L);\n    // 执行到这里线程已经退出WAITING状态，需要重置当前线程的实例域parkBlocker\n    // 如果不重置，同一线程下次调用getBlocker时，会返回上一次park(Object blocker)设置的blocker，不符合逻辑\n    setBlocker(t, null);\n}\n```\n```java\nprivate static void setBlocker(Thread t, Object arg) {\n    UNSAFE.putObject(t, parkBlockerOffset, arg);\n}\n```\n```java\npublic static Object getBlocker(Thread t) {\n    if (t == null)\n        throw new NullPointerException();\n    return UNSAFE.getObjectVolatile(t, parkBlockerOffset);\n}\n```\n\n### parkNanos(Object blocker,long nanos)\n```java\n// 与上面parkpark(Object blocker)类似，只是最多等待nanos纳秒(相对时间)\n// 当前线程进入限时等待状态（TIMED_WAITING状态）\npublic static void parkNanos(Object blocker, long nanos) {\n    if (nanos > 0) {\n        Thread t = Thread.currentThread();\n        setBlocker(t, blocker);\n        // 退出TIMED_WAITING状态的4种情况\n        //    1. 其他线程unpark当前线程\n        //    2. 其他线程中断当前线程\n        //    3. 等待超时（相对时间）\n        //    4. 该调用毫无理由地返回（这个不是很理解）\n        UNSAFE.park(false, nanos);\n        setBlocker(t, null);\n    }\n}\n```\n\n### parkUntil(Object blocker,long deadline)\n```java\n// 与上面parkpark(Object blocker)类似，只是最多等待到deadline（Uninx时间戳，单位毫秒，绝对时间）\n// 当前线程进入限时等待状态（TIMED_WAITING状态）\npublic static void parkUntil(Object blocker, long deadline) {\n    Thread t = Thread.currentThread();\n    setBlocker(t, blocker);\n    // 退出TIMED_WAITING状态的4种情况\n    //    1. 其他线程unpark当前线程\n    //    2. 其他线程中断当前线程\n    //    3. 等待超时（相对时间）\n    //    4. 该调用毫无理由地返回（这个不是很理解）\n    UNSAFE.park(true, deadline);\n    setBlocker(t, null);\n}\n```\n\n## unpark函数\n\n### unpark(Thread thread)\n```java\n// 如果给定线程的许可尚不可用，则使其可用：\n//  1. 如果线程等待在park/parkNanos/parkUntil上，则解除其等待状态；\n//  2. 否则保证下一次调用park/parkNanos/parkUntil的线程不会进入等待状态\n//        比wait()/notify()/notifyAll()灵活，wait()必须在notify()/notifyAll()之前触发\n//\n// 如果给定的线程尚未启动，无法保证unpark操作有效果\npublic static void unpark(Thread thread) {\n    if (thread != null)\n        UNSAFE.unpark(thread);\n}\n```\n\n# 使用样例\n\n## wait/notify + park/unpark\n`park/unpark`相对于`wait/notify`更灵活\n\n### wait/notify\n```java\n/**\n * 验证notify()/notifyAll()必须在wait()之后\n */\npublic class WaitAndNotify {\n    private static Object LOCK = new Object();\n\n    private static Thread waitThread = new Thread(() -> {\n        try {\n            synchronized (LOCK) {\n                log(\"before LOCK.wait()\");\n                LOCK.wait();\n                log(\"after LOCK.wait()\");\n            }\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }, \"waitThread\");\n\n    private static Thread notifyThread = new Thread(() -> {\n        synchronized (LOCK) {\n            log(\"before LOCK.notifyAll()\");\n            LOCK.notifyAll();\n            log(\"after LOCK.notifyAll()\");\n        }\n    }, \"notifyThread\");\n\n    private static void log(String message) {\n        System.out.println(String.format(\"%s : %s\",\n                Thread.currentThread().getName(),\n                message));\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        notifyThread.start();\n        TimeUnit.MILLISECONDS.sleep(100);\n        // notifyAll发生在wait之前，waitThread一直等待被唤醒\n        waitThread.start();\n        /*\n        输出：\n        notifyThread : before LOCK.notifyAll()\n        notifyThread : after LOCK.notifyAll()\n        waitThread : before LOCK.wait()\n         */\n    }\n}\n```\n\n### park/unpark\n```java\n/**\n * 验证unpark(Thread thread)可以在park(Object blocker)前面（前提：被park的线程需要在执行unpark操作之前启动）\n */\npublic class ParkAndUnpark {\n    private static Object BLOCKER = new Object();\n\n    private static Thread parkThread = new Thread(() -> {\n        try {\n            TimeUnit.SECONDS.sleep(1); // 休眠1秒，确保unparkThread执行完\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        log(\"before LockSupport.park(BLOCKER)\");\n        LockSupport.park(BLOCKER);\n        log(\"after LockSupport.park(BLOCKER)\");\n    }, \"parkThread\");\n\n    private static Thread unparkThread = new Thread(() -> {\n        log(\"before LockSupport.unpark(parkThread)\");\n        LockSupport.unpark(parkThread);\n        log(\"after LockSupport.unpark(parkThread)\");\n    }, \"unparkThread\");\n\n    private static void log(String message) {\n        System.out.println(String.format(\"%s : %s\",\n                Thread.currentThread().getName(),\n                message));\n    }\n\n    public static void main(String[] args) {\n        parkThread.start();// parkThread必须要先启动，否则无法确保LockSupport.unpark(parkThread)能让许可证有效\n        unparkThread.start();\n        /*\n        输出：\n        unparkThread : before LockSupport.unpark(parkThread)\n        unparkThread : after LockSupport.unpark(parkThread)\n        parkThread : before LockSupport.park(BLOCKER)\n        parkThread : after LockSupport.park(BLOCKER)\n         */\n    }\n}\n```\n\n## 中断响应\n```java\n/**\n * 验证park能响应中断\n */\npublic class InterruptPark {\n    private static Object BLOCKER = new Object();\n\n    private static Thread parkThread = new Thread(() -> {\n        log(\"before LockSupport.park(BLOCKER)\");\n        LockSupport.park(BLOCKER);\n        log(\"after LockSupport.park(BLOCKER)\");\n    }, \"parkThread\");\n\n    private static Thread interruptThread = new Thread(() -> {\n        log(\"before parkThread.interrupt()\");\n        parkThread.interrupt();\n        log(\"after parkThread.interrupt()\");\n    }, \"interruptThread\");\n\n    private static void log(String message) {\n        System.out.println(String.format(\"%s : %s\",\n                Thread.currentThread().getName(),\n                message));\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        parkThread.start();\n        TimeUnit.SECONDS.sleep(1);\n        interruptThread.start();\n        /*\n        输出：\n        parkThread : before LockSupport.park(BLOCKER)\n        interruptThread : before parkThread.interrupt()\n        interruptThread : after parkThread.interrupt()\n        parkThread : after LockSupport.park(BLOCKER)\n         */\n    }\n}\n```\n\n# 再谈中断\n之前的博文没有详细地讨论过`中断`，这里补充一下\n\n## Thread中断\nThread提供了5个关于中断的方法\npublic方法\n```java\nprivate volatile Interruptible blocker;\nprivate final Object blockerLock = new Object();\n// 实例方法\n// 中断线程，仅仅设置中断状态\n//\n// 1. 对于存活线程\n//    1.1. 如果线程因为调用Object.wait、Thread.sleep和Thread.join而进入\n//         WAITING或TIMED_WAITING状态，重置中断状态并抛出InterruptedException\n//    1.2. 否则只会设置中断状态\n// 2. 对于非存活线程\n//    2.1 中断一个非存活的线程，不会有任何影响\npublic void interrupt() {\n    if (this != Thread.currentThread())\n        // 除了线程自中断，都需要检查访问权限\n        checkAccess();\n\n    synchronized (blockerLock) {\n        Interruptible b = blocker;\n        if (b != null) {\n            interrupt0(); // 仅仅设置中断状态\n            b.interrupt(this);\n            return;\n        }\n    }\n    interrupt0(); // 仅仅设置中断状态\n}\n// 实例方法，判断某个线程是否被中断，不重置中断状态\npublic boolean isInterrupted() {\n    return isInterrupted(false);\n}\n// 类方法，判断当前线程是否被中断，重置中断状态\npublic static boolean interrupted() {\n   return currentThread().isInterrupted(true);\n}\n```\nprivate方法\n```java\n// 仅仅设置中断状态\nprivate native void interrupt0();\n// 线程是否被中断，依据ClearInterrupted是否重置中断状态\nprivate native boolean isInterrupted(boolean ClearInterrupted);\n```\n\n## interrupt sleep\n```java\n/**\n * 验证因sleep而进入TIMED_WAITING状态的线程被中断时，会抛出InterruptedException并重置中断状态\n */\npublic class InterruptSleep {\n    private static Thread sleepThread = new Thread(() -> {\n        try {\n            log(\"before TimeUnit.SECONDS.sleep(10)\");\n            TimeUnit.SECONDS.sleep(10);\n            log(\"after TimeUnit.SECONDS.sleep(10)\");\n        } catch (InterruptedException e) {\n            log(\"interrupted when sleeping!!\");\n            // 抛出InterruptedException异常并重置中断状态\n            log(String.format(\"interrupt status [%s]\", Thread.currentThread().isInterrupted()));\n        }\n\n    }, \"sleepThread\");\n\n    private static Thread interruptThread = new Thread(() -> {\n        log(\"before sleepThread.interrupt()\");\n        sleepThread.interrupt();\n        log(\"after sleepThread.interrupt()\");\n    }, \"interruptThread\");\n\n    private static void log(String message) {\n        System.out.println(String.format(\"%s : %s\",\n                Thread.currentThread().getName(),\n                message));\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        sleepThread.start();\n        TimeUnit.MILLISECONDS.sleep(100);\n        interruptThread.start();\n        /*\n        输出：\n        sleepThread : before TimeUnit.SECONDS.sleep(10)\n        interruptThread : before sleepThread.interrupt()\n        interruptThread : after sleepThread.interrupt()\n        sleepThread : interrupted when sleeping!!\n        sleepThread : interrupt status [false]\n         */\n    }\n}\n```\n\n## interrupt running\n```java\n/**\n * 验证中断一个处于RUNNABLE状态的线程，只会设置中断状态，而不会抛出InterruptedException\n */\npublic class InterruptRunning {\n    private static Thread runningThread = new Thread(() -> {\n        boolean hasPrintInterruptStatus = false;\n        while (true) {\n            if (!hasPrintInterruptStatus && Thread.currentThread().isInterrupted()) {\n                log(\"interrupted when running!!\");\n                // 设置中断状态，但不会抛出InterruptedException\n                log(String.format(\"interrupt status [%s]\", Thread.currentThread().isInterrupted()));\n                hasPrintInterruptStatus = true;\n            }\n        }\n    }, \"runningThread\");\n\n    private static Thread interruptThread = new Thread(() -> {\n        log(\"before runningThread.interrupt()\");\n        runningThread.interrupt();\n        log(\"after runningThread.interrupt()\");\n    }, \"interruptThread\");\n\n    private static void log(String message) {\n        System.out.println(String.format(\"%s : %s\",\n                Thread.currentThread().getName(),\n                message));\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        runningThread.start();\n        TimeUnit.MILLISECONDS.sleep(100);\n        interruptThread.start();\n        /*\n        输出：\n        interruptThread : before runningThread.interrupt()\n        interruptThread : after runningThread.interrupt()\n        runningThread : interrupted when running!!\n        runningThread : interrupt status [true]\n         */\n    }\n}\n```\n\n## interrupt synchronized\n`synchronized`关键字**`无法响应中断`**，要么获得锁，要么一直等待\n后续博文介绍的`ReentrantLock比synchronized灵活`，能够响应中断\n```java\n/**\n * 验证因synchronized而进入阻塞状态的线程是无法响应中断的，线程要么获得锁，要么一直等待\n */\npublic class InterruptSynchronized {\n    private static Object LOCK = new Object();\n\n    private static Thread holdLockThread = new Thread(() -> {\n        log(\"hold LOCK forever!!\");\n        synchronized (LOCK) {\n            while (true) {\n                Thread.yield(); // 只会尝试让出CPU资源，但不会释放锁资源\n            }\n        }\n    }, \"holdLockThread\");\n\n    private static Thread acquireLockThread = new Thread(() -> {\n        log(\"try to acquire LOCK\");\n        synchronized (LOCK) {\n            log(\"hold LOCK successfully!!\");\n        }\n    }, \"acquireLockThread\");\n\n    private static Thread interruptThread = new Thread(() -> {\n        log(\" interrupt acquireLockThread!!\");\n        acquireLockThread.interrupt();\n    }, \"interruptThread\");\n\n    private static void log(String message) {\n        System.out.println(String.format(\"%s : %s\",\n                Thread.currentThread().getName(),\n                message));\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        holdLockThread.start();\n        TimeUnit.SECONDS.sleep(1); // 确保holdLockThread持有锁\n        acquireLockThread.start(); // 尝试获得锁，进入阻塞状态\n        TimeUnit.MILLISECONDS.sleep(100); // 确保acquireLockThread进入阻塞状态\n        interruptThread.start(); // 尝试中断在处于阻塞状态的acquireLockThread，acquireLockThread并不会响应中断\n        /*\n        输出：\n        holdLockThread : hold LOCK forever!!\n        acquireLockThread : try to acquire LOCK\n        interruptThread :  interrupt acquireLockThread!!\n         */\n    }\n}\n```\n<!-- indicate-the-source -->\n","tags":["JUC"],"categories":["Concurrent"]},{"title":"Java并发 -- Atomic","url":"%2F2016%2F08%2F05%2Fconcurrent-atomic%2F","content":"\n{% note info %}\n本文主要介绍`java.util.concurrent.atomic`包下的`AtomicInteger`、`AtomicReference`、`AtomicIntegerArray`、`AtomicIntegerFieldUpdater`和`AtomicStampedReference`\n代码托管在https://github.com/zhongmingmao/concurrent_demo\n关于`Unsafe`类的内容请参考「并发 - Unsafe类的简单使用」，本文不再赘述\n{% endnote %}\n\n<!-- more -->\n\n\n\n# AtomicInteger\n`AtomicBoolean`、`AtomicInteger`和`AtomicLong`都是通过`原子方式`更新`基本类型`，实现原理类似，下面以**`AtomicInteger`**为例进行分析\n\n## 源码概要\n```java\npublic class AtomicInteger extends Number implements java.io.Serializable {\n    // 获取Unsafe实例\n    private static final Unsafe unsafe = Unsafe.getUnsafe();\n    // value在AtomicInteger中的偏移量，通过unsafe实现，具体见下面static{}块中的实现\n    private static final long valueOffset;\n    static {\n        try {\n            valueOffset = unsafe.objectFieldOffset(AtomicInteger.class.getDeclaredField(\"value\"));\n        } catch (Exception ex) { throw new Error(ex); }\n    }\n    // AtomicInteger封装int变量value，volatile变量\n    private volatile int value;\n    // 获取当前最新值value\n    public final int get() {\n        return value;\n    }\n    // 设置value为newValue\n    public final void set(int newValue) {\n        value = newValue;\n    }\n    // 最终设置value为newValue，其他线程在之后的一小段时间内有可能仍然获取得到的是旧值value\n    public final void lazySet(int newValue) {\n        unsafe.putOrderedInt(this, valueOffset, newValue);\n    }\n    // 设置新值newValue并返回旧值，底层CAS操作\n    public final int getAndSet(int newValue) {\n        return unsafe.getAndSetInt(this, valueOffset, newValue);\n    }\n    // 如果当前值value为expect，则value设置为update，底层CAS操作\n    public final boolean compareAndSet(int expect, int update) {\n        return unsafe.compareAndSwapInt(this, valueOffset, expect, update);\n    }\n    // 当前值value加1，返回旧值，底层CAS操作\n    public final int getAndIncrement() {\n        return unsafe.getAndAddInt(this, valueOffset, 1);\n    }\n    // 当前值value减1，返回旧值，底层CAS操作\n    public final int getAndDecrement() {\n        return unsafe.getAndAddInt(this, valueOffset, -1);\n    }\n    // 当前值value加delta，返回旧值，底层CAS操作\n    public final int getAndAdd(int delta) {\n        return unsafe.getAndAddInt(this, valueOffset, delta);\n    }\n    // 当前值value加1，返回新值，底层CAS操作\n    public final int incrementAndGet() {\n        return unsafe.getAndAddInt(this, valueOffset, 1) + 1;\n    }\n    // 当前值value减1，返回新值，底层CAS操作\n    public final int decrementAndGet() {\n        return unsafe.getAndAddInt(this, valueOffset, -1) - 1;\n    }\n    // 当前值value加delta，返回新值，底层CAS操作\n    public final int addAndGet(int delta) {\n        return unsafe.getAndAddInt(this, valueOffset, delta) + delta;\n    }\n    // 当前值value应用函数式接口IntUnaryOperator进行更新，返回旧值，底层CAS操作\n    public final int getAndUpdate(IntUnaryOperator updateFunction) {\n        int prev, next;\n        do {\n            prev = get();\n            next = updateFunction.applyAsInt(prev);\n        } while (!compareAndSet(prev, next));\n        return prev;\n    }\n    // 当前值value应用函数式接口IntUnaryOperator进行更新，返回新值，底层CAS操作\n    public final int updateAndGet(IntUnaryOperator updateFunction) {\n        int prev, next;\n        do {\n            prev = get();\n            next = updateFunction.applyAsInt(prev);\n        } while (!compareAndSet(prev, next));\n        return next;\n    }\n    // 当前值value应用函数式接口IntBinaryOperator进行运算，返回旧值，底层CAS操作\n    public final int getAndAccumulate(int x,\n                                      IntBinaryOperator accumulatorFunction) {\n        int prev, next;\n        do {\n            prev = get();\n            next = accumulatorFunction.applyAsInt(prev, x);\n        } while (!compareAndSet(prev, next));\n        return prev;\n    }\n    // 当前值value应用函数式接口IntBinaryOperator进行运算，返回新值，底层CAS操作\n    public final int accumulateAndGet(int x,\n                                      IntBinaryOperator accumulatorFunction) {\n        int prev, next;\n        do {\n            prev = get();\n            next = accumulatorFunction.applyAsInt(prev, x);\n        } while (!compareAndSet(prev, next));\n        return next;\n    }\n}\n```\n有源码概要可知，`AtomicInteger`内部基于`Unsafe的CAS方法`实现（**`无锁`**），下面分析有代表性的`incrementAndGet()`方法\n\n## incrementAndGet()\nAtomicInteger\n```java\n// 当前值value加1，返回新值，底层CAS操作\npublic final int incrementAndGet() {\n   return unsafe.getAndAddInt(this, valueOffset, 1) + 1;\n}\n```\nUnsafe\n```java\n// 1.8新增，给定对象o，根据获取内存偏移量指向的字段，将其增加delta，\n// 这是一个CAS操作过程，直到设置成功方能退出循环，返回旧值\npublic final int getAndAddInt(Object o, long offset, int delta) {\n   int v;\n   do {\n       v = getIntVolatile(o, offset);\n   } while (!compareAndSwapInt(o, offset, v, v + delta));\n   return v;\n}\n```\n\n## 简单使用\n\n### 并发安全\n```java\n/**\n * 验证基于CAS实现的AtomicInteger是否并发安全\n */\npublic class AtomicIntegerCAS {\n    private static final int THREAD_COUNT = 4;\n    private static final long TASK_COUNT = 500 * 1000 * 1000;\n\n    public static void main(String[] args) throws NoSuchFieldException, InterruptedException {\n        AtomicInteger counter = new AtomicInteger();\n\n        ExecutorService pool = Executors.newFixedThreadPool(THREAD_COUNT);\n        IntStream.range(0, THREAD_COUNT).forEach(i ->\n                pool.submit(() -> LongStream.range(0, TASK_COUNT)\n                        .forEach(j -> counter.incrementAndGet())));\n        pool.shutdown();\n        pool.awaitTermination(10, TimeUnit.MINUTES);\n\n        // 基于CAS实现的AtomicInteger能保证并发安全\n        System.out.println(counter.get()); // 2,000,000,000 = THREAD_COUNT * TASK_COUNT\n    }\n}\n```\n\n### CAS与synchronized\n```java\n/**\n * 比对CAS(无锁)和synchronize(锁)速度\n */\npublic class CasAndsynchronizedTest {\n    private static final int THREAD_COUNT = 4;\n    private static final long TASK_COUNT = 100 * 1000 * 1000;\n\n    @Data\n    static class Counter {\n        private long count;\n\n        public synchronized long incrementAndGet() {\n            return ++count;\n        }\n    }\n\n    private static void runWithCas() throws InterruptedException {\n        LocalDateTime start = LocalDateTime.now();\n        AtomicInteger counter = new AtomicInteger();\n\n        ExecutorService pool = Executors.newFixedThreadPool(THREAD_COUNT);\n        IntStream.range(0, THREAD_COUNT).forEach(i ->\n                pool.submit(() -> LongStream.range(0, TASK_COUNT)\n                        .forEach(j -> counter.incrementAndGet())));\n        pool.shutdown();\n        pool.awaitTermination(10, TimeUnit.MINUTES);\n        System.out.println(String.format(\"cas takes %sms\",\n                Duration.between(start, LocalDateTime.now()).toMillis())); // cas takes 6552ms\n    }\n\n    private static void runWithSynchronized() throws InterruptedException {\n        LocalDateTime start = LocalDateTime.now();\n        Counter counter = new Counter();\n\n        ExecutorService pool = Executors.newFixedThreadPool(THREAD_COUNT);\n        IntStream.range(0, THREAD_COUNT).forEach(i ->\n                pool.submit(() -> LongStream.range(0, TASK_COUNT)\n                        .forEach(j -> counter.incrementAndGet())));\n        pool.shutdown();\n        pool.awaitTermination(10, TimeUnit.MINUTES);\n        System.out.println(String.format(\"synchronized takes %sms\",\n                Duration.between(start, LocalDateTime.now()).toMillis())); // synchronized takes 17974ms\n    }\n\n    public static void main(String[] args) throws NoSuchFieldException, InterruptedException {\n        runWithCas();\n        runWithSynchronized();\n    }\n}\n```\n基于`CAS（无锁）`和基于`synchronized（有锁）`两个一样的计数程序，性能差异大致是`2.74`，测试不够全面，这里只为说明两者的性能差异\n\n# AtomicReference\n\n## 源码概要\n跟`AtomicInteger`类似的内容不再标注\n```java\n// AtomicReference是一个泛型类（虽然Java是伪泛型）\npublic class AtomicReference<V> implements java.io.Serializable {\n    private static final Unsafe unsafe = Unsafe.getUnsafe();\n    private static final long valueOffset;\n    static {\n        try {\n            valueOffset = unsafe.objectFieldOffset\n                (AtomicReference.class.getDeclaredField(\"value\"));\n        } catch (Exception ex) { throw new Error(ex); }\n    }\n    // volatile变量\n    private volatile V value;\n    public final V get() {\n        return value;\n    }\n    public final void set(V newValue) {\n        value = newValue;\n    }\n    public final void lazySet(V newValue) {\n        unsafe.putOrderedObject(this, valueOffset, newValue);\n    }\n    // 底层CAS操作\n    public final boolean compareAndSet(V expect, V update) {\n        return unsafe.compareAndSwapObject(this, valueOffset, expect, update);\n    }\n    // 底层CAS操作\n    @SuppressWarnings(\"unchecked\")\n    public final V getAndSet(V newValue) {\n        return (V)unsafe.getAndSetObject(this, valueOffset, newValue);\n    }\n    // 底层CAS操作\n    public final V getAndUpdate(UnaryOperator<V> updateFunction) {\n        V prev, next;\n        do {\n            prev = get();\n            next = updateFunction.apply(prev);\n        } while (!compareAndSet(prev, next));\n        return prev;\n    }\n    // 底层CAS操作\n    public final V updateAndGet(UnaryOperator<V> updateFunction) {\n        V prev, next;\n        do {\n            prev = get();\n            next = updateFunction.apply(prev);\n        } while (!compareAndSet(prev, next));\n        return next;\n    }\n    // 底层CAS操作\n    public final V getAndAccumulate(V x,\n                                    BinaryOperator<V> accumulatorFunction) {\n        V prev, next;\n        do {\n            prev = get();\n            next = accumulatorFunction.apply(prev, x);\n        } while (!compareAndSet(prev, next));\n        return prev;\n    }\n    // 底层CAS操作\n    public final V accumulateAndGet(V x,\n                                    BinaryOperator<V> accumulatorFunction) {\n        V prev, next;\n        do {\n            prev = get();\n            next = accumulatorFunction.apply(prev, x);\n        } while (!compareAndSet(prev, next));\n        return next;\n    }\n}\n```\n`AtomicReference`与`AtomicInteger`类似，都是基于`CAS`的`无锁`实现\n\n## 简单使用\n```java\npublic class AtomicReferenceDemo {\n    @Data\n    @AllArgsConstructor\n    static class User {\n        private String name;\n        private String location;\n    }\n\n    public static void main(String[] args) {\n        AtomicReference<User> atomicReference = new AtomicReference<>();\n        User expectUser = new User(\"zhongmingmao\", \"ZhongShan\");\n        atomicReference.set(expectUser);\n        User updateUser = new User(\"zhongmingwu\", \"GuangZhou\");\n\n        expectUser.setLocation(\"HangZhou\"); // 修改实例域不影响结果\n        boolean casOK = atomicReference.compareAndSet(expectUser, updateUser);\n        System.out.println(casOK); // true\n        System.out.println(atomicReference.get()); // AtomicReferenceDemo.User(name=zhongmingwu, location=GuangZhou)\n    }\n}\n```\n\n# AtomicIntegerArray\n`AtomicIntegerArray`、`AtomicLongArray`和`AtomicReferenceArray`都是通过`原子方式`更新`数组里的某个元素`，实现原理类似，下面以**`AtomicIntegerArray`**为例进行分析\n\n## 源码概要\n跟`AtomicInteger`类似的内容不再标注\n```java\npublic class AtomicIntegerArray implements java.io.Serializable {\n    private static final Unsafe unsafe = Unsafe.getUnsafe();\n    // array[0]的偏移量\n    private static final int base = unsafe.arrayBaseOffset(int[].class);\n    // 数组元素占用空间大小，用2取对数\n    private static final int shift;\n    // final修饰符保证内存可见性（对象被正确构造且this没有逃逸，其他线程能看到final域在构造函数中被初始化之后的值）\n    // See http://ifeve.com/java-memory-model/\n    private final int[] array;\n    static {\n        // int类型占用空间大小，4 Bytes\n        int scale = unsafe.arrayIndexScale(int[].class);\n        if ((scale & (scale - 1)) != 0)\n            throw new Error(\"data type scale not a power of two\");\n        // shift = 2\n        shift = 31 - Integer.numberOfLeadingZeros(scale);\n    }\n    // array[i]的偏移量\n    private long checkedByteOffset(int i) {\n        if (i < 0 || i >= array.length)\n            throw new IndexOutOfBoundsException(\"index \" + i);\n\n        return byteOffset(i);\n    }\n    // array[i]的偏移量\n    private static long byteOffset(int i) {\n        return ((long) i << shift) + base;\n    }\n    public AtomicIntegerArray(int length) {\n        array = new int[length];\n    }\n    public AtomicIntegerArray(int[] array) {\n\n        this.array = array.clone();\n    }\n    // 获取数组长度\n    public final int length() {\n        return array.length;\n    }\n    // 以volatile语义获取array[i]\n    public final int get(int i) {\n        return getRaw(checkedByteOffset(i));\n    }\n    // 以volatile语义获取数组array中偏移为offset的int值\n    private int getRaw(long offset) {\n        return unsafe.getIntVolatile(array, offset);\n    }\n    // 以volatile语义设置array[i]=newValue\n    public final void set(int i, int newValue) {\n        unsafe.putIntVolatile(array, checkedByteOffset(i), newValue);\n    }\n    public final void lazySet(int i, int newValue) {\n        unsafe.putOrderedInt(array, checkedByteOffset(i), newValue);\n    }\n    // 设置array[i]=newValue，底层CAS操作\n    public final int getAndSet(int i, int newValue) {\n        return unsafe.getAndSetInt(array, checkedByteOffset(i), newValue);\n    }\n    // 设置array[i]=update，底层CAS操作\n    public final boolean compareAndSet(int i, int expect, int update) {\n        return compareAndSetRaw(checkedByteOffset(i), expect, update);\n    }\n    // 设置array中偏移为offset的int值为update，底层CAS操作\n    private boolean compareAndSetRaw(long offset, int expect, int update) {\n        return unsafe.compareAndSwapInt(array, offset, expect, update);\n    }\n    // array[i]加1，返回旧值，底层CAS操作\n    public final int getAndIncrement(int i) {\n        return getAndAdd(i, 1);\n    }\n    // array[i]减1，返回旧值，底层CAS操作\n    public final int getAndDecrement(int i) {\n        return getAndAdd(i, -1);\n    }\n    // array[i]加delta，返回旧值，底层CAS操作\n    public final int getAndAdd(int i, int delta) {\n        return unsafe.getAndAddInt(array, checkedByteOffset(i), delta);\n    }\n    // array[i]加1，返回新值，底层CAS操作\n    public final int incrementAndGet(int i) {\n        return getAndAdd(i, 1) + 1;\n    }\n    // array[i]减1，返回新值，底层CAS操作\n    public final int decrementAndGet(int i) {\n        return getAndAdd(i, -1) - 1;\n    }\n    // array[i]加delta，返回新值，底层CAS操作\n    public final int addAndGet(int i, int delta) {\n        return getAndAdd(i, delta) + delta;\n    }\n    // array[i]应用函数式接口IntUnaryOperator进行更新，返回旧值，底层CAS操作\n    public final int getAndUpdate(int i, IntUnaryOperator updateFunction) {\n        long offset = checkedByteOffset(i);\n        int prev, next;\n        do {\n            prev = getRaw(offset);\n            next = updateFunction.applyAsInt(prev);\n        } while (!compareAndSetRaw(offset, prev, next));\n        return prev;\n    }\n    // array[i]应用函数式接口IntUnaryOperator进行更新，返回新值，底层CAS操作\n    public final int updateAndGet(int i, IntUnaryOperator updateFunction) {\n        long offset = checkedByteOffset(i);\n        int prev, next;\n        do {\n            prev = getRaw(offset);\n            next = updateFunction.applyAsInt(prev);\n        } while (!compareAndSetRaw(offset, prev, next));\n        return next;\n    }\n    // array[i]应用函数式接口IntBinaryOperator进行计算，返回旧值，底层CAS操作\n    public final int getAndAccumulate(int i, int x,\n                                      IntBinaryOperator accumulatorFunction) {\n        long offset = checkedByteOffset(i);\n        int prev, next;\n        do {\n            prev = getRaw(offset);\n            next = accumulatorFunction.applyAsInt(prev, x);\n        } while (!compareAndSetRaw(offset, prev, next));\n        return prev;\n    }\n    // array[i]应用函数式接口IntBinaryOperator进行计算，返回新值，底层CAS操作\n    public final int accumulateAndGet(int i, int x,\n                                      IntBinaryOperator accumulatorFunction) {\n        long offset = checkedByteOffset(i);\n        int prev, next;\n        do {\n            prev = getRaw(offset);\n            next = accumulatorFunction.applyAsInt(prev, x);\n        } while (!compareAndSetRaw(offset, prev, next));\n        return next;\n    }\n}\n```\n`AtomicIntegerArray`跟`AtomicInteger`实现原理类似，无非是由`value`变成了`array`，对数组中的`单个元素`进行`CAS`操作\n\n## 简单使用\n```java\npublic class AtomicIntegerArrayDemo {\n    private static final int THREAD_COUNT = 4;\n    private static final int TASK_COUNT = 1000 * 1000;\n\n    public static void main(String[] args) throws InterruptedException {\n        AtomicIntegerArray array = new AtomicIntegerArray(THREAD_COUNT);\n\n        ExecutorService pool = Executors.newFixedThreadPool(THREAD_COUNT);\n        IntStream.range(0, THREAD_COUNT).forEach(i ->\n                pool.submit(() -> IntStream.range(0, TASK_COUNT)\n                        .forEach(j -> array.getAndIncrement(j % THREAD_COUNT))));\n        pool.shutdown();\n        pool.awaitTermination(10, TimeUnit.MINUTES);\n        // CAS保证并发安全\n        System.out.println(array); // [1000000, 1000000, 1000000, 1000000]\n    }\n}\n```\n\n# AtomicIntegerFieldUpdater\n`AtomicIntegerFieldUpdater`、`AtomicLongFieldUpdater`和`AtomicReferenceFieldUpdater`都是通过`原子方式`更新`类里的字段`（让普通的变量采用原子操作），实现原理类似，下面以**`AtomicIntegerFieldUpdater`**为例进行分析，采用原子更新器的其中几个条件（详细限制条件请参考代码`AtomicIntegerFieldUpdaterImpl`）\n1. 操作的字段`不能`是`static`修饰\n2. 操作的字段`不能`是`final`修饰\n3. 操作的字段`必须`是`volatile`修饰（`final`和`volatile`本身就无法组合在一起）\n4. 操作的字段`对Updater必须可见`\n\n## 源码概要\n\n### AtomicIntegerFieldUpdater\n```java\npublic abstract class AtomicIntegerFieldUpdater<T> {\n    @CallerSensitive\n    public static <U> AtomicIntegerFieldUpdater<U> newUpdater(Class<U> tclass, String fieldName) {\n        // 实际的实现类是AtomicIntegerFieldUpdaterImpl\n        return new AtomicIntegerFieldUpdaterImpl<U>(tclass, fieldName, Reflection.getCallerClass());\n    }\n\n    protected AtomicIntegerFieldUpdater() {\n    }\n    public abstract boolean compareAndSet(T obj, int expect, int update);\n    public abstract void set(T obj, int newValue);\n    public abstract void lazySet(T obj, int newValue);\n    public abstract int get(T obj);\n    // 更新obj.field=newValue，返回旧值，底层CAS操作\n    public int getAndSet(T obj, int newValue) {\n        int prev;\n        do {\n            prev = get(obj);\n        } while (!compareAndSet(obj, prev, newValue));\n        return prev;\n    }\n    // obj.field加1，返回旧值，底层CAS操作\n    public int getAndIncrement(T obj) {\n        int prev, next;\n        do {\n            prev = get(obj);\n            next = prev + 1;\n        } while (!compareAndSet(obj, prev, next));\n        return prev;\n    }\n    // obj.field减1，返回旧值，底层CAS操作\n    public int getAndDecrement(T obj) {\n        int prev, next;\n        do {\n            prev = get(obj);\n            next = prev - 1;\n        } while (!compareAndSet(obj, prev, next));\n        return prev;\n    }\n    // obj.field加delta，返回旧值，底层CAS操作\n    public int getAndAdd(T obj, int delta) {\n        int prev, next;\n        do {\n            prev = get(obj);\n            next = prev + delta;\n        } while (!compareAndSet(obj, prev, next));\n        return prev;\n    }\n    // obj.field加1，返回新值，底层CAS操作\n    public int incrementAndGet(T obj) {\n        int prev, next;\n        do {\n            prev = get(obj);\n            next = prev + 1;\n        } while (!compareAndSet(obj, prev, next));\n        return next;\n    }\n    // obj.field减1，返回新值，底层CAS操作\n    public int decrementAndGet(T obj) {\n        int prev, next;\n        do {\n            prev = get(obj);\n            next = prev - 1;\n        } while (!compareAndSet(obj, prev, next));\n        return next;\n    }\n    // obj.field加delta，返回新值，底层CAS操作\n    public int addAndGet(T obj, int delta) {\n        int prev, next;\n        do {\n            prev = get(obj);\n            next = prev + delta;\n        } while (!compareAndSet(obj, prev, next));\n        return next;\n    }\n    // obj.field应用函数式接口IntUnaryOperator进行更新，并返回旧值，底层CAS操作\n    public final int getAndUpdate(T obj, IntUnaryOperator updateFunction) {\n        int prev, next;\n        do {\n            prev = get(obj);\n            next = updateFunction.applyAsInt(prev);\n        } while (!compareAndSet(obj, prev, next));\n        return prev;\n    }\n    // obj.field应用函数式接口IntUnaryOperator进行更新，并返回新值，底层CAS操作\n    public final int updateAndGet(T obj, IntUnaryOperator updateFunction) {\n        int prev, next;\n        do {\n            prev = get(obj);\n            next = updateFunction.applyAsInt(prev);\n        } while (!compareAndSet(obj, prev, next));\n        return next;\n    }\n    // obj.field应用函数式接口IntBinaryOperator进行计算，并返回旧值，底层CAS操作\n    public final int getAndAccumulate(T obj, int x,\n                                      IntBinaryOperator accumulatorFunction) {\n        int prev, next;\n        do {\n            prev = get(obj);\n            next = accumulatorFunction.applyAsInt(prev, x);\n        } while (!compareAndSet(obj, prev, next));\n        return prev;\n    }\n    // obj.field应用函数式接口IntBinaryOperator进行计算，并返回新值，底层CAS操作\n    public final int accumulateAndGet(T obj, int x,\n                                      IntBinaryOperator accumulatorFunction) {\n        int prev, next;\n        do {\n            prev = get(obj);\n            next = accumulatorFunction.applyAsInt(prev, x);\n        } while (!compareAndSet(obj, prev, next));\n        return next;\n    }\n}\n```\n### AtomicIntegerFieldUpdaterImpl\n```java\nprivate static final class AtomicIntegerFieldUpdaterImpl<T> extends AtomicIntegerFieldUpdater<T> {\n   private static final sun.misc.Unsafe U = sun.misc.Unsafe.getUnsafe();\n   private final long offset;\n   private final Class<?> cclass;\n   private final Class<T> tclass;\n\n   AtomicIntegerFieldUpdaterImpl(final Class<T> tclass, final String fieldName, final Class<?> caller) {\n       final Field field; // 要原子更新的字段\n       final int modifiers; // 字段修饰符\n       try {\n           field = AccessController.doPrivileged(\n               new PrivilegedExceptionAction<Field>() {\n                   public Field run() throws NoSuchFieldException {\n                       return tclass.getDeclaredField(fieldName);\n                   }\n               });\n           // 获取字段修饰符\n           modifiers = field.getModifiers();\n           // 对字段的访问权限进行检查，不在访问范围内抛异常\n           sun.reflect.misc.ReflectUtil.ensureMemberAccess(\n               caller, tclass, null, modifiers);\n           ClassLoader cl = tclass.getClassLoader();\n           ClassLoader ccl = caller.getClassLoader();\n           if ((ccl != null) && (ccl != cl) &&\n               ((cl == null) || !isAncestor(cl, ccl))) {\n               sun.reflect.misc.ReflectUtil.checkPackageAccess(tclass);\n           }\n       } catch (PrivilegedActionException pae) {\n           throw new RuntimeException(pae.getException());\n       } catch (Exception ex) {\n           throw new RuntimeException(ex);\n       }\n\n       // 判断是否为原生int类型\n       if (field.getType() != int.class)\n           throw new IllegalArgumentException(\"Must be integer type\");\n       // 判断是否被volatile修饰\n       if (!Modifier.isVolatile(modifiers))\n           throw new IllegalArgumentException(\"Must be volatile type\");\n       this.cclass = (Modifier.isProtected(modifiers) &&\n                      tclass.isAssignableFrom(caller) &&\n                      !isSamePackage(tclass, caller))\n                     ? caller : tclass;\n       this.tclass = tclass;\n       // 获取该字段在对象内存布局中的偏移量\n       this.offset = U.objectFieldOffset(field);\n   }\n   // second是否在first的类加载器委托链上（双亲委派模型）\n   private static boolean isAncestor(ClassLoader first, ClassLoader second) {\n       ClassLoader acl = first;\n       do {\n           acl = acl.getParent();\n           if (second == acl) {\n               return true;\n           }\n       } while (acl != null);\n       return false;\n   }\n   // 是否具有相同的ClassLoader和包名称\n   private static boolean isSamePackage(Class<?> class1, Class<?> class2) {\n       return class1.getClassLoader() == class2.getClassLoader()\n              && Objects.equals(getPackageName(class1), getPackageName(class2));\n   }\n   // 获取包名称\n   private static String getPackageName(Class<?> cls) {\n       String cn = cls.getName();\n       int dot = cn.lastIndexOf('.');\n       return (dot != -1) ? cn.substring(0, dot) : \"\";\n   }\n   // obj是否是cclass的实例\n   private final void accessCheck(T obj) {\n       if (!cclass.isInstance(obj))\n           throwAccessCheckException(obj);\n   }\n   // 构建异常\n   private final void throwAccessCheckException(T obj) {\n       if (cclass == tclass)\n           throw new ClassCastException();\n       else\n           throw new RuntimeException(\n               new IllegalAccessException(\n                   \"Class \" +\n                   cclass.getName() +\n                   \" can not access a protected member of class \" +\n                   tclass.getName() +\n                   \" using an instance of \" +\n                   obj.getClass().getName()));\n   }\n   public final boolean compareAndSet(T obj, int expect, int update) {\n       accessCheck(obj);\n       return U.compareAndSwapInt(obj, offset, expect, update);\n   }\n   public final boolean weakCompareAndSet(T obj, int expect, int update) {\n       accessCheck(obj);\n       return U.compareAndSwapInt(obj, offset, expect, update);\n   }\n   public final void set(T obj, int newValue) {\n       accessCheck(obj);\n       U.putIntVolatile(obj, offset, newValue);\n   }\n   public final void lazySet(T obj, int newValue) {\n       accessCheck(obj);\n       U.putOrderedInt(obj, offset, newValue);\n   }\n   public final int get(T obj) {\n       accessCheck(obj);\n       return U.getIntVolatile(obj, offset);\n   }\n   public final int getAndSet(T obj, int newValue) {\n       accessCheck(obj);\n       return U.getAndSetInt(obj, offset, newValue);\n   }\n   public final int getAndAdd(T obj, int delta) {\n       accessCheck(obj);\n       return U.getAndAddInt(obj, offset, delta);\n   }\n   public final int getAndIncrement(T obj) {\n       return getAndAdd(obj, 1);\n   }\n   public final int getAndDecrement(T obj) {\n       return getAndAdd(obj, -1);\n   }\n   public final int incrementAndGet(T obj) {\n       return getAndAdd(obj, 1) + 1;\n   }\n   public final int decrementAndGet(T obj) {\n       return getAndAdd(obj, -1) - 1;\n   }\n   public final int addAndGet(T obj, int delta) {\n       return getAndAdd(obj, delta) + delta;\n   }\n}\n```\n`AtomicIntegerFieldUpdaterImpl`依旧是基于`CAS`实现\n\n\n## 简单使用\n```java\npublic class AtomicIntegerFieldUpdaterDemo {\n    private static final int THREAD_COUNT = 4;\n    private static final int TASK_COUNT = 1000 * 1000;\n\n    @Data\n    static class Counter {\n        volatile int count; // 让原本没有原子更新能力的count具有原子更新能力\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        AtomicIntegerFieldUpdater<Counter> fieldUpdater = AtomicIntegerFieldUpdater.newUpdater(Counter.class, \"count\");\n        Counter counter = new Counter();\n        ExecutorService pool = Executors.newFixedThreadPool(THREAD_COUNT);\n        IntStream.range(0, THREAD_COUNT).forEach(i ->\n                pool.submit(() -> IntStream.range(0, TASK_COUNT)\n                        .forEach(j -> fieldUpdater.incrementAndGet(counter))));\n        pool.shutdown();\n        pool.awaitTermination(10, TimeUnit.MINUTES);\n        System.out.println(counter.getCount()); // 4000000 = THREAD_COUNT * TASK_COUNT\n    }\n}\n```\n\n# AtomicStampedReference\n`AtomicStampedReference`是为了解决`CAS中的ABA问题`\n\n## 源码概要\n```java\npublic class AtomicStampedReference<V> {\n    // 存储数据和时间戳\n    private static class Pair<T> {\n        final T reference;\n        final int stamp;\n        private Pair(T reference, int stamp) {\n            this.reference = reference;\n            this.stamp = stamp;\n        }\n        static <T> Pair<T> of(T reference, int stamp) {\n            return new Pair<T>(reference, stamp);\n        }\n    }\n    // Pair实例，volatile变量\n    private volatile Pair<V> pair;\n    // 构建Pair实例\n    public AtomicStampedReference(V initialRef, int initialStamp) {\n        pair = Pair.of(initialRef, initialStamp);\n    }\n    public V getReference() {\n        return pair.reference;\n    }\n    public int getStamp() {\n        return pair.stamp;\n    }\n    // 返回当前的reference和stamp\n    public V get(int[] stampHolder) {\n        Pair<V> pair = this.pair;\n        stampHolder[0] = pair.stamp;\n        return pair.reference;\n    }\n    // 只有旧的reference和stamp相等，才会执行casPair，底层CAS操作，是解决ABA问题的核心\n    // AtomicReference<V>.compareAndSet(V expect, V update)只会比较reference\n    public boolean compareAndSet(V   expectedReference, V   newReference,\n                                 int expectedStamp, int newStamp) {\n        Pair<V> current = pair;\n        return\n            expectedReference == current.reference && expectedStamp == current.stamp &&\n            ((newReference == current.reference && newStamp == current.stamp)\n                || casPair(current, Pair.of(newReference, newStamp)));\n    }\n    private boolean casPair(Pair<V> cmp, Pair<V> val) {\n        return UNSAFE.compareAndSwapObject(this, pairOffset, cmp, val);\n    }\n    // 无条件直接更新reference和stamp\n    public void set(V newReference, int newStamp) {\n        Pair<V> current = pair;\n        if (newReference != current.reference || newStamp != current.stamp)\n            this.pair = Pair.of(newReference, newStamp);\n    }\n    public boolean attemptStamp(V expectedReference, int newStamp) {\n        Pair<V> current = pair;\n        return\n            expectedReference == current.reference &&\n            (newStamp == current.stamp ||\n             casPair(current, Pair.of(expectedReference, newStamp)));\n    }\n    private static final sun.misc.Unsafe UNSAFE = sun.misc.Unsafe.getUnsafe();\n    // 获取pair的偏移量\n    private static final long pairOffset = objectFieldOffset(UNSAFE, \"pair\", AtomicStampedReference.class);\n    static long objectFieldOffset(sun.misc.Unsafe UNSAFE,\n                                  String field, Class<?> klazz) {\n        try {\n            return UNSAFE.objectFieldOffset(klazz.getDeclaredField(field));\n        } catch (NoSuchFieldException e) {\n            NoSuchFieldError error = new NoSuchFieldError(field);\n            error.initCause(e);\n            throw error;\n        }\n    }\n}\n```\n\n## 简单使用\n```java\n/**\n * 通过AtomicStampedReference解决ABA问题\n */\npublic class AtomicStampedReferenceDemo {\n    public static void main(String[] args) throws InterruptedException {\n        AtomicStampedReference<Integer> stampedReference = new AtomicStampedReference<>(10, 0);\n\n        Thread t1 = new Thread(() -> { // 构造ABA问题\n            int stamp = stampedReference.getStamp();\n            // 要注意autoboxing\n            boolean success = stampedReference.compareAndSet(10, 20, stamp, stamp + 1);\n            System.out.println(String.format(\"thread: %s , compareAndSet success : %s , current value : %s\",\n                    Thread.currentThread().getName(), success, stampedReference.getReference()));\n\n            stamp = stampedReference.getStamp();\n            success = stampedReference.compareAndSet(20, 10, stamp, stamp + 1);\n            System.out.println(String.format(\"thread: %s , compareAndSet success : %s , current value : %s\",\n                    Thread.currentThread().getName(), success, stampedReference.getReference()));\n        });\n\n        Thread t2 = new Thread(() -> { // 遇到ABA问题，无法更新\n            int stamp = stampedReference.getStamp();\n            try {\n                TimeUnit.SECONDS.sleep(1);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            boolean success = stampedReference.compareAndSet(10, 30, stamp, stamp + 1);\n            System.out.println(String.format(\"thread: %s , compareAndSet success : %s , current value : %s\",\n                    Thread.currentThread().getName(), success, stampedReference.getReference()));\n        });\n\n        t2.start();\n        TimeUnit.MILLISECONDS.sleep(200);\n        t1.start();\n    }\n}\n```\n\n### 运行结果\n```\nthread: Thread-0 , compareAndSet success : true , current value : 20\nthread: Thread-0 , compareAndSet success : true , current value : 10\nthread: Thread-1 , compareAndSet success : false , current value : 10\n```\n\n<!-- indicate-the-source -->\n","tags":["JUC"],"categories":["Concurrent"]},{"title":"Java并发 -- Unsafe","url":"%2F2016%2F08%2F04%2Fconcurrent-unsafe%2F","content":"\n{% note info %}\n本文主要介绍`sun.misc.Unsafe`类的简单使用\n代码托管在https://github.com/zhongmingmao/concurrent_demo\n关于`JOL`的内容请参考「对象内存布局 - JOL使用教程 1」,本文不再赘述\n{% endnote %}\n\n<!-- more -->\n\n# 概述\n1. `sun.misc.Unsafe`类提供底层（`low-level`）的，不安全（`unsafe`）的方法\n2. 提供与`并发`相关的**`CAS`**、**`park/unpark`**等操作\n\n\n# 获取源码\n`Oracle JDK 8`仅有`Unsafe.class`文件，`反编译的代码`是没法看到`JavaDoc`、`代码注释`和`实际方法参数名`等信息的，可以借助[OpenJDK 8](http://download.java.net/openjdk/jdk8)来解决这个问题\n\n## 下载并打包\n```\n$ wget http://www.java.net/download/openjdk/jdk8/promoted/b132/openjdk-8-src-b132-03_mar_2014.zip\n\n$ unzip openjdk-8-src-b132-03_mar_2014.zip\n\n$ find . -name \"Unsafe.java\"\n./openjdk/jdk/src/share/classes/sun/misc/Unsafe.java\n\n$ cd ./openjdk/jdk/src/share/classes/\n\n# 将sun下面的源码打包\n$ zip -r sun.zip sun\n\n# 放置在Java_HOME或任意目录\n$ sudo cp sun.zip /Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/sun.zip\n```\n## IDEA配置\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/unsafe_idea.png\" width=\"500\">\n\n# 获取Unsafe实例\n\n## Unsafe.getUnsafe()\n```java\n@CallerSensitive\npublic static Unsafe getUnsafe() {\n   Class<?> caller = Reflection.getCallerClass();\n   if (!VM.isSystemDomainLoader(caller.getClassLoader()))\n       throw new SecurityException(\"Unsafe\");\n   return theUnsafe;\n}\n```\n1. `Unsafe.getUnsafe()`方法仅提供给`Bootstrap类`加载器使用，直接调用会抛出`SecurityException`异常\n2. [Stack Overflow](https://stackoverflow.com/questions/10829281/is-it-possible-to-use-java-unsafe-in-user-code)提供了两种解决方法，下面将采用`反射`的方式来实例化`sun.misc.Unsafe`类\n\n## 反射\n```java\n/**\n * Unsafe工具类\n */\npublic class UnsafeUtil {\n    /**\n     * 通过反射获得sun.misc.Unsafe实例<br/>\n     * see https://stackoverflow.com/questions/10829281/is-it-possible-to-use-java-unsafe-in-user-code\n     */\n    public static Unsafe getUnsafe() {\n        try {\n            // 通过反射得到theUnsafe对应的Field对象\n            Field f = Unsafe.class.getDeclaredField(\"theUnsafe\");\n            f.setAccessible(true);\n            // theUnsafe是static，因此传入null即可\n            return (Unsafe) f.get(null);\n        } catch (Exception e) {\n            throw new SecurityException(\"Unsafe\");\n        }\n    }\n\n    public static void main(String[] args) {\n        System.out.println(getUnsafe()); // sun.misc.Unsafe@2626b418\n    }\n}\n```\n\n# 内存管理\n\n## Unsafe方法\n```java\n// 操作系统的内存页大小\npublic native int pageSize();\n\n// 分配内存指定大小的内存\npublic native long allocateMemory(long bytes);\n// 根据给定的内存地址address设置重新分配指定大小的内存\npublic native long reallocateMemory(long address, long bytes);\n// 用于释放allocateMemory和reallocateMemory申请的内存\npublic native void freeMemory(long address);\n// 将指定对象的给定offset偏移量内存块中的所有字节设置为固定值\npublic native void setMemory(Object o, long offset, long bytes, byte value);\n\n// 设置给定内存地址的long值\npublic native void putLong(long address, long x);\n// 获取指定内存地址的long值\npublic native long getLong(long address);\n```\n\n## 测试代码\n```java\npublic class UnsafeMemory {\n    public static void main(String[] args) {\n        Unsafe unsafe = UnsafeUtil.getUnsafe();\n        System.out.println(unsafe.pageSize()); // 4096\n\n        long address = unsafe.allocateMemory(1024);\n        System.out.println(address);\n        unsafe.putLong(address, 1024);\n        System.out.println(unsafe.getLong(address)); // 1024\n        unsafe.freeMemory(address);\n    }\n}\n```\n\n# 对象管理\n\n## Unsafe方法\n```java\n// 传入一个Class对象并创建该实例对象，但不会调用构造方法\npublic native Object allocateInstance(Class<?> cls) throws InstantiationException;\n\n// 获取字段f在实例对象中的偏移量\npublic native long objectFieldOffset(Field f);\n\n// 返回值就是f.getDeclaringClass()\npublic native Object staticFieldBase(Field f);\n// 静态属性的偏移量，用于在对应的Class对象中读写静态属性\npublic native long staticFieldOffset(Field f);\n\n// 获得给定对象偏移量上的int值，所谓的偏移量可以简单理解为指针指向该变量；的内存地址，\n// 通过偏移量便可得到该对象的变量，进行各种操作\npublic native int getInt(Object o, long offset);\n// 设置给定对象上偏移量的int值\npublic native void putInt(Object o, long offset, int x);\n\n// 获得给定对象偏移量上的引用类型的值\npublic native Object getObject(Object o, long offset);\n// 设置给定对象偏移量上的引用类型的值\npublic native void putObject(Object o, long offset, Object x););\n\n// 设置给定对象的int值，使用volatile语义，即设置后立马更新到内存对其他线程可见\npublic native void putIntVolatile(Object o, long offset, int x);\n// 获得给定对象的指定偏移量offset的int值，使用volatile语义，总能获取到最新的int值。\npublic native int getIntVolatile(Object o, long offset);\n\n// 与putIntVolatile一样，但要求被操作字段必须有volatile修饰\npublic native void putOrderedInt(Object o, long offset, int x);\n```\n\n## 测试代码\n```java\n// JVM Args : -Djol.tryWithSudo=true\npublic class UnsafeObject {\n    @AllArgsConstructor\n    @ToString(of = {\"name\", \"age\", \"location\"})\n    static class User {\n        private String name;\n        private int age;\n        private static String location = \"ZhongShan\";\n    }\n\n    public static void main(String[] args) throws InstantiationException, NoSuchFieldException {\n        Unsafe unsafe = UnsafeUtil.getUnsafe();\n\n        //通过allocateInstance直接创建对象，但未运行任何构造函数\n        User user = (User) unsafe.allocateInstance(User.class);\n        System.out.println(user); // UnsafeObject.User(name=null, age=0, location=ZhongShan)\n\n        // 通过JOL打印对象内存布局\n        /*\n        me.zhongmingmao.unsafe.UnsafeObject$User object internals:\n         OFFSET  SIZE               TYPE DESCRIPTION                               VALUE\n              0     4                    (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)\n              4     4                    (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)\n              8     4                    (object header)                           81 c1 00 f8 (10000001 11000001 00000000 11111000) (-134168191)\n             12     4                int User.age                                  0\n             16     4   java.lang.String User.name                                 null\n             20     4                    (loss due to the next object alignment)\n        Instance size: 24 bytes\n        Space losses: 0 bytes internal + 4 bytes external = 4 bytes total\n         */\n        System.out.println(ClassLayout.parseInstance(user).toPrintable());\n\n        // Class && Field\n        Class<? extends User> userClass = user.getClass();\n        Field name = userClass.getDeclaredField(\"name\");\n        Field age = userClass.getDeclaredField(\"age\");\n        Field location = userClass.getDeclaredField(\"location\");\n\n        // 获取实例域name和age在对象内存中的偏移量并设置值\n        System.out.println(unsafe.objectFieldOffset(name)); // 16\n        unsafe.putObject(user, unsafe.objectFieldOffset(name), \"zhongmingmao\");\n        System.out.println(unsafe.objectFieldOffset(age)); // 12\n        unsafe.putInt(user, unsafe.objectFieldOffset(age), 99);\n        System.out.println(user); // UnsafeObject.User(name=zhongmingmao, age=99, location=ZhongShan)\n\n        // 获取定义location字段的类\n        Object staticFieldBase = unsafe.staticFieldBase(location);\n        System.out.println(staticFieldBase); // class me.zhongmingmao.unsafe.UnsafeObject$User\n\n        // 获取static变量location的偏移量\n        long staticFieldOffset = unsafe.staticFieldOffset(location);\n        // 获取static变量location的值\n        System.out.println(unsafe.getObject(staticFieldBase, staticFieldOffset)); // ZhongShan\n        // 设置static变量location的值\n        unsafe.putObject(staticFieldBase, staticFieldOffset, \"GuangZhou\");\n        System.out.println(user); // UnsafeObject.User(name=zhongmingmao, age=99, location=GuangZhou)\n    }\n}\n```\n\n# 数组\n\n## Unsafe方法\n```java\n// 获取数组第一个元素的偏移地址\npublic native int arrayBaseOffset(Class<?> arrayClass);\n// 数组中一个元素占据的内存空间,arrayBaseOffset与arrayIndexScale配合使用，可定位数组中每个元素在内存中的位置\npublic native int arrayIndexScale(Class<?> arrayClass);\n```\n\n## 测试代码\n```java\n// JVM Args : -Djol.tryWithSudo=true\npublic class UnsafeArray {\n    @Data\n    @AllArgsConstructor\n    static class User {\n        private String name;\n        private int age;\n    }\n\n    public static void main(String[] args) {\n        Unsafe unsafe = UnsafeUtil.getUnsafe();\n\n        // 通过JOL打印虚拟机信息\n        /*\n        # Running 64-bit HotSpot VM.\n        # Using compressed oop with 3-bit shift.\n        # Using compressed klass with 3-bit shift.\n        # Objects are 8 bytes aligned.\n        # Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n        # Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n         */\n        System.out.println(VM.current().details());\n\n        // 实例化User[]\n        User[] users = new User[3];\n        IntStream.range(0, users.length).forEach(i ->\n                users[i] = new User(String.format(\"zhongmingmao_%s\", i), i));\n\n        // 通过JOL打印users的内存布局\n        /*\n        [Lme.zhongmingmao.unsafe.UnsafeArray$User; object internals:\n         OFFSET  SIZE                                      TYPE DESCRIPTION                               VALUE\n              0     4                                           (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)\n              4     4                                           (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)\n              8     4                                           (object header)                           24 f1 00 f8 (00100100 11110001 00000000 11111000) (-134155996)\n             12     4                                           (object header)                           03 00 00 00 (00000011 00000000 00000000 00000000) (3)\n             16    12   me.zhongmingmao.unsafe.UnsafeArray$User UnsafeArray$User;.<elements>              N/A\n             28     4                                           (loss due to the next object alignment)\n        Instance size: 32 bytes\n        Space losses: 0 bytes internal + 4 bytes external = 4 bytes total\n         */\n        System.out.println(ClassLayout.parseInstance(users).toPrintable());\n\n        // users[0]的偏移\n        int baseOffset = unsafe.arrayBaseOffset(User[].class);\n        System.out.println(baseOffset); // 16\n        int indexScale = unsafe.arrayIndexScale(User[].class);\n        System.out.println(indexScale); // 4\n\n        // users[1]\n        Object object = unsafe.getObject(users, baseOffset + indexScale + 0L);\n        System.out.println(object); // UnsafeArray.User(name=zhongmingmao_1, age=1)\n    }\n}\n```\n\n# CAS\n\n## Unsafe方法\n```java\n// 第一个参数o为给定对象，offset为对象内存的偏移量，通过这个偏移量迅速定位字段并设置或获取该字段的值，\n// expected表示期望值，x表示要设置的值，下面3个方法都通过CAS原子指令执行操作。\npublic final native boolean compareAndSwapObject(Object o, long offset, Object expected, Object x);\npublic final native boolean compareAndSwapInt(Object o, long offset, int expected,int x);\npublic final native boolean compareAndSwapLong(Object o, long offset, long expected,long x);\n```\n```java\n// 1.8新增，给定对象o，根据获取内存偏移量指向的字段，将其增加delta，\n// 这是一个CAS操作过程，直到设置成功方能退出循环，返回旧值\npublic final int getAndAddInt(Object o, long offset, int delta) {\n   int v;\n   do {\n       v = getIntVolatile(o, offset);\n   } while (!compareAndSwapInt(o, offset, v, v + delta));\n   return v;\n}\n\n// 1.8新增，方法作用同上，只不过这里操作的long类型数据\npublic final long getAndAddLong(Object o, long offset, long delta) {\n   long v;\n   do {\n       v = getLongVolatile(o, offset);\n   } while (!compareAndSwapLong(o, offset, v, v + delta));\n   return v;\n}\n\n// 1.8新增，给定对象o，根据获取内存偏移量对于字段，将其 设置为新值newValue，\n// 这是一个CAS操作过程，直到设置成功方能退出循环，返回旧值\npublic final int getAndSetInt(Object o, long offset, int newValue) {\n   int v;\n   do {\n       v = getIntVolatile(o, offset);\n   } while (!compareAndSwapInt(o, offset, v, newValue));\n   return v;\n}\n\n// 1.8新增，同上，操作的是long类型\npublic final long getAndSetLong(Object o, long offset, long newValue) {\n   long v;\n   do {\n       v = getLongVolatile(o, offset);\n   } while (!compareAndSwapLong(o, offset, v, newValue));\n   return v;\n}\n\n// 1.8新增，同上，操作的是引用类型数据\npublic final Object getAndSetObject(Object o, long offset, Object newValue) {\n   Object v;\n   do {\n       v = getObjectVolatile(o, offset);\n   } while (!compareAndSwapObject(o, offset, v, newValue));\n   return v;\n}\n```\n\n## 测试代码\n```java\npublic class UnsafeCAS {\n\n    private static final int THREAD_COUNT = 4;\n    private static final long TASK_COUNT = 500 * 1000 * 1000;\n\n    @Data\n    @AllArgsConstructor\n    static class Counter {\n        private long count;\n    }\n\n    public static void main(String[] args) throws NoSuchFieldException, InterruptedException {\n        Unsafe unsafe = UnsafeUtil.getUnsafe();\n        Field count = Counter.class.getDeclaredField(\"count\");\n        long offset = unsafe.objectFieldOffset(count);\n        Counter counter = new Counter(0);\n        ExecutorService pool = Executors.newFixedThreadPool(THREAD_COUNT);\n\n        IntStream.range(0, THREAD_COUNT).forEach(i ->\n                pool.submit(() -> LongStream.range(0, TASK_COUNT)\n                        .forEach(j -> unsafe.getAndAddInt(counter, offset, 1))));\n        pool.shutdown();\n        pool.awaitTermination(10, TimeUnit.MINUTES);\n\n        // CAS实现并发安全\n        System.out.println(counter.getCount()); // 2,000,000,000 = THREAD_COUNT * TASK_COUNT\n    }\n}\n```\n\n# park/unpark\n\n## Unsafe方法\n```java\n// 线程调用该方法，线程将一直阻塞直到超时，或者是中断条件出现。\npublic native void park(boolean isAbsolute, long time);\n// 终止挂起的线程，恢复正常.java.util.concurrent包中挂起操作都是在LockSupport类实现的，其底层正是使用这两个方法，\npublic native void unpark(Object thread);\n```\n\n## 测试代码\n```java\npublic class UnsafePark {\n    private static Thread mainThread;\n\n    public static void main(String[] args) {\n        Unsafe unsafe = UnsafeUtil.getUnsafe();\n        mainThread = Thread.currentThread();\n\n        System.out.println(String.format(\"park %s\", mainThread.getName())); // park main\n        unsafe.park(false, TimeUnit.SECONDS.toNanos(1));\n\n        new Thread(() -> {\n            System.out.println(String.format(\"%s unpark %s\",\n                    Thread.currentThread().getName(),\n                    mainThread.getName())); // Thread-0 unpark main\n            unsafe.unpark(mainThread);\n        }).start();\n    }\n}\n```\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- volatile","url":"%2F2016%2F08%2F03%2Fconcurrent-volatile%2F","content":"\n{% note info %}\n本文主要介绍关键字`volatile`在实际开发中最为重要的特性：**`可见性`**\n代码托管在https://github.com/zhongmingmao/concurrent_demo\n{% endnote %}\n\n<!-- more -->\n\n# JMM 基础\n`JMM`即`Java Memory Model`，`Java内存模型`\n\n## 主内存 + 工作内存\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/jmm.png\" width=\"500\">\n1. `JMM`定义程序中`可被共享变量`的访问规则，即在虚拟机中将变量存储在内存和从内存中取出变量这样的底层细节\n2. 共享变量包括：`实例字段`、`静态字段`和`构成数组对象的元素`\n3. 线程私有数据包括：`局部变量`、`方法参数`等\n4. `所有变量`存储在`主内存`中，线程拥有自己的`工作内存`，工作内存保存了`该线程使用的变量的主内存副本拷贝`\n5. **`线程对变量的所有操作都必须在工作内存中进行`**，不能直接读取`主内存`中的变量，不同的线程之间也无法直接访问对方`工作内存`中的变量\n\n## 交互协议（原子操作）\n1. `lock`：作用于`主内存`的变量，把一个变量标识为一条`线程独占`的状态\n2. `unlock`：作用于`主内存`的变量，把一个处于`锁定状态`的变量释放出来，释放后的变量才可以被其他线程锁定\n3. `read`：作用于`主内存`的变量，把一个变量的值从主内存`传输`到线程的工作内存中，以便随后的load动作使用\n4. `load`：作用于`工作内存`的变量，把`read`操作从主内存得到的变量放入工作内存的`变量副本`中\n5. `use`：作用于`工作内存`的变量，把工作内存中一个`变量的值传递给执行引擎`；每当虚拟机遇到一个需要使用到变量的值的字节码指令时会执行这个操作\n6. `assign`：作用于`工作内存`的变量，把一个`从执行引擎接收到的值赋给工作内存的变量`；每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作\n7. `store`：作用于`工作内存`的变量，把工作内存中一个变量的值`传送`到主内存中，以便随后的write动作使用\n8. `write`：作用于`主内存`的变量，把`store`操作从工作内存中得到的变量值放入`主内存的变量`中\n\n### 规则\n阅读时可跳过，不影响全文理解\n1. read和load、store和write必须成对、按顺序（不要求连续）出现\n2. 不允许一个线程丢弃它最近的assign操作，变量在工作内存中改变之后必须把该变化同步回主内存\n3. 不允许一个没发生过assign操作的线程把数据从工作内存同步回主内存中\n4. 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量\n5. 一个变量可以被同一线程lock多次，但必须执行一样次数的unlock，变量才会被解锁\n6. 对一个变量来说，lock和unlock只能由同一个线程执行\n7. 如果对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用该变量前，需要重新执行load或assign操作初始化变量的值\n8. 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中\n\n## 原子性、可见性、有序性\n1. `原子性`：一个操作是`不可中断`的；能够实现原子性的关键词：`synchronized`\n2. `可见性`：当一个线程修改了某一个共享变量的值，其他线程是否能够**`立即知道`**这个修改；能够实现可见性的关键词：`synchronized`、`volatile`、`final`\n3. `有序性`（理解有待加深）：如果在`本线程内观察`，所有操作都是`有序`的；如果`在一个线程中观察另一个线程`，所有操作都是`无序`的。前半句是指`线程内表现为串行语义`，后半句是指`指令重排序`现象和`工作内存中主内存同步延迟`现象；能实现有序性的关键字：`synchronized`、`volatile`\n\n| 特性 | 关键字 |\n| --- | --- |\n| 原子性 | `synchronized` |\n| 可见性 | `synchronized`、`volatile`、`final` |\n| 有序性 | `synchronized`、`volatile` |\n\n## 先行发生原则（happen-before）\n\n### 先行发生\n操作A`先行发生`于操作B：**`发生操作B之前，操作A产生的影响能被操作B观察到`**\n\n### 作用\n判断数据是`否存在竞争`、`线程是否安全`的主要依据\n`先行发生`主要用于阐述**`操作之间的内存可见性`**\n\n### 规则\n1. **`程序次序规则`**：在一个线程内，按照控制流顺序执行\n2. **`管程锁定规则 — synchronized`**：一个unlock操作先行发生于后面（时间先后顺序）对同一个锁的lock操作\n3. **`volatile变量规则 — volatile`**：对一个volatile变量的写操作先行发生于后面（时间先后顺序）对这个变量的读操作\n4. `线程启动规则`：Thread对象的start()方法先行发生于此线程的每一个动作\n5. `线程终止规则`：线程的所有操作都先行发生于对此线程的终止检测（Thread.join()方法结束、Thread.isAlive()的返回值）\n6. `线程中断规则`：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生（Thread.interrupted()）\n7. `对象终结规则`：一个对象的初始化（构造函数执行结束）完成先行发生于它的finalize()方法的开始\n8. **`传递性`**：如果操作A先行发生于操作B，操作B先行发生于操作C ➜ 操作A先行发生于操作C\n\n\n# volatile的特性\n\n## 开销\n1. `volatile`是**`最轻量级的同步机制`**\n2. volatile变量`读操作的性能消耗与普通变量没什么差别，写操作可能会慢一些`\n3. 大多数场景下，`volatile的总开销仍然比锁低`\n4. 如果`volatile的语义能满足使用的场景，尽量使用volatile`\n\n\n\n## 可见性\n\n### 交互动作\n\n1. 线程T对`volatile变量V的use动作`，必须与`read`、`load`动作相关联，必须连续一起出现；**`在工作内存中，每次使用V之前都必须从主内存刷新最新的值`**，用于保证能看见其他线程对变量V所做的修改后的值\n2. 线程T对`volatile变量V的assign动作`，必须与`store`、`write`动作相关联，必须连续一起出现；**`在工作内存中，每次修改V后都必须立刻同步回到主内存中`**，用于保证其他线程可以看到自己对变量V所做的修改\n\n### 代码\n```java\n/**\n * 结合happens-before说明volatile的可见性\n * @author zhongmingmao zhongmingmao0625@gmail.com\n */\npublic class VolatileVisibility {\n    static class A {\n        private int x = 0;\n        private volatile int y = 0; // 如果y不声明为volatile，程序将无法结束\n\n        private void write() {\n            x = 5;\n            y = 1;\n            System.out.println(\"update x = 5\");\n        }\n\n        private void read() {\n            while (y < Integer.MAX_VALUE && x != 5) {\n            }\n            System.out.println(\"read x = 5\");\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        A a = new A();\n        Thread writeThread = new Thread(() -> a.write());\n        Thread readThread = new Thread(() -> a.read());\n\n        readThread.start();\n        Thread.sleep(100); // 休眠一段时间，确保readThread已经在运行，验证volatile的可见性\n        writeThread.start();\n    }\n}\n```\n\n### 分析\n依据`先行发生原则`分析\n1. `程序次序规则`：`x = 5`happen-before`y = 1`，`y < Integer.MAX_VALUE`happen-before`x != 5`\n2. `volatile变量规则`：`y = 1`happen-before`y < Integer.MAX_VALUE`\n3. `传递性`：依据1、2 ➜ **`x = 5`happen-before`x != 5`** ➜ `可见性`\n`volatile变量y`能让线程`readThread`看到线程`writeThread`对`普通变量x`的修改\n\n## 不保证并发安全\n\n### 代码\n```java\n/**\n * volatile能保证可见性，但不保证并发安全\n */\npublic class ConcurrentNotSafe {\n    private static final int POOL_SIZE = 4;\n\n    private static volatile int i = 0;\n    private static CountDownLatch countDownLatch = new CountDownLatch(1000 * 1000);\n\n    private static void increase() {\n        while (countDownLatch.getCount() > 0) {\n            ++i;\n            countDownLatch.countDown();\n        }\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        ExecutorService pool = Executors.newFixedThreadPool(POOL_SIZE);\n        IntStream.range(0, POOL_SIZE).forEach(value -> pool.submit(ConcurrentNotSafe::increase));\n        pool.shutdown();\n        countDownLatch.await();\n        System.out.println(i); // 890672 < 1000 * 1000\n    }\n}\n```\n\n### 运行结果\n```\n890672\n```\n`volatile`能`保证可见性`，但`不保证并发安全`，并非`预期结果`1000 * 1000\n\n### 字节码\n```\n# javap -v -p\nprivate static void increase();\n    descriptor: ()V\n    flags: ACC_PRIVATE, ACC_STATIC\n    Code:\n        stack=4, locals=0, args_size=0\n            0: getstatic        #2 // Field countDownLatch:Ljava/util/concurrent/CountDownLatch;\n            3: invokevirtual    #3 // Method java/util/concurrent/CountDownLatch.getCount:()J\n            6: lconst_0\n            7: lcmp\n            8: ifle          28\n            11: getstatic       #4  // Field i:I\n            14: iconst_1\n            15: iadd\n            16: putstatic       #4  // Field i:I\n            19: getstatic       #2  // Field countDownLatch:Ljava/util/concurrent/CountDownLatch;\n            22: invokevirtual   #5  // Method java/util/concurrent/CountDownLatch.countDown:()V\n            25: goto          0\n            28: return\n```\n`++i`对应的`4个字节码`：`11:getstatic`、`14:iconst_1`、`15:iadd`和`16:putstatic`，因此`算术符++不具有原子性`，从而`不能保证并发安全`\n\n{% note info %}\nvolatile内存语义的实现主要依赖于`内存屏障（Memory Barrier）`来禁用`特定的的指令重排序`，相关内容请参考[深入理解Java内存模型（四）- volatile](http://ifeve.com/java-memory-model-4/)，不在赘述\n{% endnote %}\n\n# 参考资料\n[深入理解Java虚拟机（第2版）](https://book.douban.com/subject/24722612/)\n\n\n\n\n<!-- indicate-the-source -->\n","tags":["Java Concurrent"],"categories":["Concurrent"]},{"title":"Java并发 -- synchronized","url":"%2F2016%2F07%2F31%2Fconcurrent-synchronized%2F","content":"\n{% note info %}\n本文主要介绍`synchronized 概述`以及`synchronized 锁优化`\n代码托管在https://github.com/zhongmingmao/concurrent_demo\n{% endnote %}\n\n<!-- more -->\n\n# synchronized 概述\n\n## Mark Word\n关于`对象的内存布局`，请参考「对象内存布局 - Instrumentation + sa-jdi 实例分析」，这里不再赘述\n`Mark Word`是`synchronized`锁机制的`核心数据结构`，[markOop.hpp](http://hg.openjdk.java.net/jdk8/jdk8/hotspot/file/87ee5ee27509/src/share/vm/oops/markOop.hpp)的代码注释如下（仅仅列出`32-bit`）：\n```java\n//  32 bits:\n//  --------\n//             hash:25 ------------>| age:4    biased_lock:1 lock:2 (normal object)\n//             JavaThread*:23 epoch:2 age:4    biased_lock:1 lock:2 (biased object)\n//             size:32 ------------------------------------------>| (CMS free block)\n//             PromotedObject*:29 ---------->| promo_bits:3 ----->| (CMS promoted object)\n\n//    [JavaThread* | epoch | age | 1 | 01]       lock is biased toward given thread\n//    [0           | epoch | age | 1 | 01]       lock is anonymously biased\n\n//    [ptr             | 00]  locked             ptr points to real header on stack\n//    [header      | 0 | 01]  unlocked           regular object header\n//    [ptr             | 10]  monitor            inflated lock (header is wapped out)\n//    [ptr             | 11]  marked             used by markSweep to mark an object\n//                                               not valid at any other time\n```\n在`32-bit JVM`的`Mark Word`与`锁状态`对应如下\n<img src=\"https://concurrent-1253868755.cos.ap-guangzhou.myqcloud.com/mark_word.png\" width=\"500\">\n\n## monitor\n`重量级锁`也就是我们常说的`对象锁`，锁标志位为`10`，`Mark Word`的指针字段指向`monitor对象`（也称为`管程`或`对象监视器`）的起始地址，每个`Java对象`都存在一个与之关联的`monitor对象`\n在`Hotspot JVM`中，`monitor`由`ObjectMonitor`实现，主要数据结构如下（代码：[objectMonitor.hpp](http://hg.openjdk.java.net/jdk8/jdk8/hotspot/file/87ee5ee27509/src/share/vm/runtime/objectMonitor.hpp)）\n```CPP\nObjectMonitor() {\n    _header       = NULL;\n    _count        = 0; // 重入次数\n    _waiters      = 0,\n    _recursions   = 0;\n    _object       = NULL;\n    _owner        = NULL; // 获得锁的线程\n    _WaitSet      = NULL; // 调用wait()/wait(long timeout)方法的线程\n    _WaitSetLock  = 0 ;\n    _Responsible  = NULL ;\n    _succ         = NULL ;\n    _cxq          = NULL ;\n    FreeNext      = NULL ;\n    _EntryList    = NULL ; // Contention List中那些有资格成为候选人的线程被移到Entry List\n    _SpinFreq     = 0 ;\n    _SpinClock    = 0 ;\n    OwnerIsThread = 0 ;\n    _previous_owner_tid = 0;\n}\n```\n简要分析：\n1. 每一`等待锁的线程`都会被封装成`ObjectWaiter`对象，`_WaitSet`和`_EntryList`保存`ObjectWaiter`对象\n2. `_owner`指向持有`ObjectMonitor`对象的线程\n3. 当`多个线程`同时访问一段`同步代码`时，首先会进入`_EntryList`\n4. 当线程A`竞争ObjectMonitor成功`后，把`ObjectMonitor`的`_owner`设置为线程A，`_count加1`\n5. 如果线程A（已经获得对象锁）调用`wait()`（等待被唤醒，然后重新进入`_EntryList`），那么线程A将释放当前持有的`ObjectMonitor`（相对地，`sleep()不会释放锁`），把`ObjectMonitor`的`_owner`设置为`null`，`_count减1`\n\n扩展阅读：\n1. 详细的`线程状态转换过程`，请参考[深入JVM锁机制1-synchronized](http://blog.csdn.net/chen77716/article/details/6618779)\n2. Hotspot JVM`源码`解读，请参考[OpenJDK9 Hotspot : synchronized 浅析](https://segmentfault.com/a/1190000008532548)\n\n## JVM字节码\n\n### 同步块\n\n#### 代码\n```java\npublic class SyncBlock {\n    private int i;\n\n    public void increase() {\n        synchronized (this) {\n            i++;\n        }\n    }\n}\n```\n\n#### 字节码\n```\npublic void increase();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n        stack=3, locals=3, args_size=1\n            0: aload_0\n            1: dup\n            2: astore_1\n            3: monitorenter // 进入同步方法\n            4: aload_0\n            5: dup\n            6: getfield #2  // Field i:I // i++ start\n            9: iconst_1\n            10: iadd\n            11: putfield #2 // Field i:I // i++ end 总共有4个指令，说明++操作不具有原子性\n            14: aload_1\n            15: monitorexit // 正常退出同步方法\n            16: goto 24\n            19: astore_2\n            20: aload_1\n            21: monitorexit // 异常退出同步方法\n            22: aload_2\n            23: athrow\n            24: return\n        Exception table:\n            from    to  target type\n               4    16    19   any # 进入异常处理流程，第2个monitorexit保证在出现异常时，monitorenter与monitorexit成对出现\n              19    22    19   any\n        LocalVariableTable:\n            Start  Length  Slot  Name   Signature\n                0      25     0  this   Lme/zhongmingmao/_synchronized/SyncBlock;\n```\n1. 在JVM字节码可知，同步块的实现是使用了`monitorenter`和`monitorexit`\n2. 当执行`monitorenter`时，当前线程尝试获取`monitor的持有权`，当`monitor`的`_count`为`0`时，可以成功取得monitor的持有权，并将`_count置为1`（`重入时加1`），若其他线程已经持有`monitor`的持有权，那么当前线程将进入`WAITING`或`TIMED_WAITING`状态（线程状态请参照代码`java.lang.Thread$State`）\n3. 当执行`monitorexit`时，当前线程释放`monitor的持有权`，将当`monitor`的`_count`减`1`\n4. 为保证`异常情况`下，`monitorenter`与`monitorexit`成对执行，采用`2个monitorexit`指令\n\n### 同步方法\n\n#### 代码\n```java\npublic class SyncMethod {\n    private int i;\n\n    public synchronized void increase() {\n        i++;\n    }\n}\n```\n\n#### 字节码\n```\npublic synchronized void increase();\n    descriptor: ()V\n    flags: ACC_PUBLIC, ACC_SYNCHRONIZED // ACC_SYNCHRONIZED指明为同步方法\n    Code:\n        stack=3, locals=1, args_size=1\n            0: aload_0\n            1: dup\n            2: getfield #2  // Field i:I\n            5: iconst_1\n            6: iadd\n            7: putfield #2  // Field i:I\n            10: return\n        LocalVariableTable:\n            Start  Length  Slot  Name   Signature\n                0      11     0  this   Lme/zhongmingmao/_synchronized/SyncMethod;\n```\n1. 当方法调用时，首先会检查方法是否有`ACC_SYNCHRONIZED`标志，如果设置了，则尝试“竞争”`monitor`的持有权，然后再执行方法\n2. 如果同步方法在执行期间抛出了异常，且方法内部无法处理，当前线程所持有的`monitor`将在异常抛到同步方法之外时`自动释放`\n\n# synchronized 锁优化\n早期Java版本，`synchronized`属于`重量级锁`，因为`monitor`依赖`操作系统的互斥操作`，操作系统实现`线程切换`需要从`用户态切换到核心态`，成本比较高\n\n## 乐观 - 偏向锁\n在**`无竞争`**的场合，之前获得锁的线程再次获得锁时，会判断是否偏向锁指向当前线程，如果是，该线程`不用做任何同步`操作，省去大量有关锁申请的操作，进而提升性能\n\n### Mark Word\n\n#### 代码\n```java\n// JVM Args : -XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0 -Djol.tryWithSudo=true\npublic class BiasedLockingMarkWorld {\n    static class A {\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        Layouter layouter = new HotSpotLayouter(new X86_32_DataModel());\n\n        final A a = new A();\n\n        ClassLayout layout = ClassLayout.parseInstance(a, layouter);\n        out.println(\"**** Fresh object\");\n        out.println(layout.toPrintable());\n\n        synchronized (a) {\n            out.println(\"**** With the lock\");\n            out.println(layout.toPrintable());\n        }\n\n        out.println(\"**** After the lock\");\n        out.println(layout.toPrintable());\n    }\n}\n```\n\n#### 运行结果\n```\n**** Fresh object\nme.zhongmingmao._synchronized.BiasedLockingMarkWorld$A object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           05 00 00 00 (00000101 00000000 00000000 00000000) (5)\n      4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)\n      8     8        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 8 bytes external = 8 bytes total\n\n**** With the lock\nme.zhongmingmao._synchronized.BiasedLockingMarkWorld$A object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           05 38 00 09 (00000101 00111000 00000000 00001001) (151009285)\n      4     4        (object header)                           d6 7f 00 00 (11010110 01111111 00000000 00000000) (32726)\n      8     8        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 8 bytes external = 8 bytes total\n\n**** After the lock\nme.zhongmingmao._synchronized.BiasedLockingMarkWorld$A object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           05 38 00 09 (00000101 00111000 00000000 00001001) (151009285)\n      4     4        (object header)                           d6 7f 00 00 (11010110 01111111 00000000 00000000) (32726)\n      8     8        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 8 bytes external = 8 bytes total\n```\n1. `Intel`是`小端模式`，因此`Fresh object`时的`低8bit`为`00000101`，处于`偏向锁`模式，但此时没有线程持有对象a的`monitor`，因此没有数据\n2. `With the lock`阶段和`After the lock`阶段的`Mark Word`一致，均处于`偏向锁`模式，且有`指向栈中锁记录的指针`，没有竞争的情况下，说明退出同步块后，依然保留偏向锁的的信息\n\n### 性能对比\n\n#### 代码\n```java\n// JVM Args : -XX:BiasedLockingStartupDelay=10000\n// JVM Args : -XX:BiasedLockingStartupDelay=0\npublic class BiasedLockingSpeedTest {\n    static Number number = new Number();\n\n    public static void main(String[] args) {\n        long start = System.currentTimeMillis();\n        long i = 0;\n        while (i++ < 1000000000L) {\n            number.increase();\n        }\n        System.out.println(String.format(\"%sms\", System.currentTimeMillis() - start));\n    }\n\n    static class Number {\n        int i;\n\n        public synchronized void increase() {\n            i++;\n        }\n    }\n}\n```\n\n#### 运行结果\n```\n# JVM Args : -XX:BiasedLockingStartupDelay=10000\n29274ms\n\n# JVM Args : -XX:BiasedLockingStartupDelay=0\n3048ms\n```\n\n| 偏向锁 | 轻量级锁 |\n| --- | --- |\n| 3048ms | 29274ms |\n\n1. `BiasedLockingStartupDelay`：系统刚启动时，一般数据竞争比较激烈，启用偏向锁反而会`降低性能`，因此一般是系统启动一段时间后才启用偏向锁，默认`4秒`\n2. 由运行结果可见，在`无竞争`的情况下，`偏向锁的性能提升`还是很明显的（实际是`偏向锁`与`轻量级锁`的对比）\n\n## 乐观 - 轻量级锁\n1. 如果`偏向锁失败`，那么就会升级为`轻量级锁`\n2. `轻量级锁`尝试`在应用层面解决线程同步问题`，而不触发操作系统的互斥操作（`重量级锁`）\n3. `轻量级锁`是为了**`减少多线程进入互斥的几率`**，并非要替代互斥\n4. `轻量级锁`利用了CPU原语`Compare-And-Swap`（`CAS`），具体过程请参考[深入理解Java虚拟机（第2版）](https://book.douban.com/subject/24722612/)\n\n### Mark Word\n\n#### 代码\n```java\n// JVM Args : -Djol.tryWithSudo=true\npublic class ThinLockingMarkWord {\n    static class A {\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        Layouter layouter = new HotSpotLayouter(new X86_32_DataModel());\n\n        final A a = new A();\n\n        ClassLayout layout = ClassLayout.parseInstance(a, layouter);\n        out.println(\"**** Fresh object\");\n        out.println(layout.toPrintable());\n\n        synchronized (a) {\n            out.println(\"**** With the lock\");\n            out.println(layout.toPrintable());\n        }\n\n        out.println(\"**** After the lock\");\n        out.println(layout.toPrintable());\n    }\n}\n```\n\n#### 运行结果\n```\n**** Fresh object\nme.zhongmingmao._synchronized.ThinLockingMarkWord$A object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)\n      4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)\n      8     8        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 8 bytes external = 8 bytes total\n\n**** With the lock\nme.zhongmingmao._synchronized.ThinLockingMarkWord$A object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           c0 18 5a 00 (11000000 00011000 01011010 00000000) (5904576)\n      4     4        (object header)                           00 70 00 00 (00000000 01110000 00000000 00000000) (28672)\n      8     8        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 8 bytes external = 8 bytes total\n\n**** After the lock\nme.zhongmingmao._synchronized.ThinLockingMarkWord$A object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)\n      4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)\n      8     8        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 8 bytes external = 8 bytes total\n```\n1. `Fresh objectd`阶段的`锁标志位`为`01`，`是否偏向锁`标志位为`0`，表示处于`无锁状态`\n2. `With the lock`阶段的`锁标志位`为`00`，表示处于`轻量级锁`（因为系统刚启动时`还不支持偏向锁`，因此直接进入`轻量级锁`）\n3. `After the lock`阶段的`锁标志位`恢复`01`，`是否偏向锁`标志位为`0`，表示恢复`无锁状态`，没有偏向锁信息\n\n### 性能对比\n\n#### 代码\n```java\n/**\n * 重量级锁的性能测试\n */\npublic class FatLockingSpeedTest {\n    static Number number = new Number();\n    static final int THREAD_COUNT = 2;\n    static CountDownLatch countDownLatch = new CountDownLatch(1000000000);\n\n\n    public static void main(String[] args) throws InterruptedException {\n        long start = System.currentTimeMillis();\n        for (int i = 0; i < THREAD_COUNT; i++) {\n            new Thread(new Task()).start();\n        }\n        countDownLatch.await();\n        System.out.println(String.format(\"%sms\", System.currentTimeMillis() - start));\n    }\n\n    static class Number {\n        int i;\n\n        public synchronized void increase() {\n            i++;\n            countDownLatch.countDown();\n        }\n    }\n\n    static class Task implements Runnable {\n\n        @Override\n        public void run() {\n            while (countDownLatch.getCount() > 0) {\n                number.increase();\n            }\n        }\n    }\n}\n```\n\n#### 运行结果\n```\n57383ms\n```\n结合上面的测试，性能对比如下\n\n| 偏向锁 | 轻量级锁 | 重量级锁 |\n| --- | --- | --- |\n| 3048ms | 29274ms | 57383ms |\n\n测试对比可能不是很严谨，只为了**大致**说明`偏向锁`、`轻量级锁`和`重量级锁`之间的性能差异\n\n\n\n## 乐观 - 自旋锁\n1. 如果`轻量级锁`失败，可能直接升级为`重量级锁`，也可能尝试尝试`自旋锁`\n2. `自旋锁`乐观地认为线程线程可以`很快获得锁`，可以让线程自旋（`空循环`），并不直接采用操作系统的互斥操作\n3. `自旋锁`如果`自旋成功`，可以`避免操作系统的互斥操作`\n4. `自旋锁`如果`自旋失败`，依然会升级为`重量级锁`\n\n## 悲观 - 重量级锁\n\n### Mark Word\n\n#### 代码\n```java\n// JVM Args : -Djol.tryWithSudo=true\npublic class FatLockingMarkWord {\n    static class A {\n    }\n\n    public static void main(String[] args) throws Exception {\n        Layouter layouter = new HotSpotLayouter(new X86_32_DataModel());\n\n        final A a = new A();\n\n        ClassLayout layout = ClassLayout.parseInstance(a, layouter);\n\n        out.println(\"**** Fresh object\");\n        out.println(layout.toPrintable());\n\n        Thread t = new Thread(() -> {\n            synchronized (a) {\n                try {\n                    TimeUnit.SECONDS.sleep(10);\n                } catch (InterruptedException e) {\n                    return;\n                }\n            }\n        });\n\n        t.start();\n\n        TimeUnit.SECONDS.sleep(1);\n\n        out.println(\"**** Before the lock\");\n        out.println(layout.toPrintable());\n\n        synchronized (a) {\n            out.println(\"**** With the lock\");\n            out.println(layout.toPrintable());\n        }\n\n        out.println(\"**** After the lock\");\n        out.println(layout.toPrintable());\n\n        System.gc();\n\n        out.println(\"**** After System.gc()\");\n        out.println(layout.toPrintable());\n    }\n}\n```\n\n#### 运行结果\n```\n**** Fresh object\nme.zhongmingmao._synchronized.FatLockingMarkWord$A object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)\n      4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)\n      8     8        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 8 bytes external = 8 bytes total\n\n**** Before the lock\nme.zhongmingmao._synchronized.FatLockingMarkWord$A object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           40 b8 c2 03 (01000000 10111000 11000010 00000011) (63092800)\n      4     4        (object header)                           00 70 00 00 (00000000 01110000 00000000 00000000) (28672)\n      8     8        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 8 bytes external = 8 bytes total\n\n**** With the lock\nme.zhongmingmao._synchronized.FatLockingMarkWord$A object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           2a a9 82 45 (00101010 10101001 10000010 01000101) (1166190890)\n      4     4        (object header)                           a6 7f 00 00 (10100110 01111111 00000000 00000000) (32678)\n      8     8        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 8 bytes external = 8 bytes total\n\n**** After the lock\nme.zhongmingmao._synchronized.FatLockingMarkWord$A object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           2a a9 82 45 (00101010 10101001 10000010 01000101) (1166190890)\n      4     4        (object header)                           a6 7f 00 00 (10100110 01111111 00000000 00000000) (32678)\n      8     8        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 8 bytes external = 8 bytes total\n\n**** After System.gc()\nme.zhongmingmao._synchronized.FatLockingMarkWord$A object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           09 00 00 00 (00001001 00000000 00000000 00000000) (9)\n      4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)\n      8     8        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 8 bytes external = 8 bytes total\n```\n对Mark Word的分析与上述类似，不过多赘述\n1. `Fresh object`阶段，`锁标志位`为`01`，`是否偏向锁标志位`为`0`，处于`无锁状态`\n2. `Before the lock`阶段，`锁标志位`为`00`，处于`轻量级锁`，此时`t线程`已经持有锁且`main线程`尚未请求锁，即此时`无竞争`\n3. `With the lock`阶段，`锁标志位`为`10`，膨胀为`重量级锁`，此时`t线程`已经释放锁且`main线程`等待锁成功，即此时存在`竞争`\n4. `After the lock`阶段，依旧为`重量级锁`，不会自动降级\n5. `After System.gc()`阶段，恢复为`无锁状态`，GC年龄变为`1`\n\n### Object.wait()\n调用`Object.wait()`方法会让`轻量级锁`升级为`重量级锁`\n\n#### 代码\n```java\n// JVM Args : -Djol.tryWithSudo=true\npublic class FatLockingWaitMarkWord {\n    static Object object = new Object();\n\n    public static void main(String[] args) throws InterruptedException {\n        Layouter layouter = new HotSpotLayouter(new X86_32_DataModel());\n        ClassLayout layout = ClassLayout.parseInstance(object, layouter);\n        new Thread(() -> {\n            try {\n                synchronized (object) {\n                    System.out.println(\"**** Before wait\");\n                    System.out.println(layout.toPrintable());\n                    object.wait();\n                    System.out.println(\"**** After wait\");\n                    System.out.println(layout.toPrintable());\n                }\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }).start();\n        TimeUnit.SECONDS.sleep(10);\n        synchronized (object) {\n            object.notifyAll();\n        }\n    }\n}\n```\n\n#### 运行结果\n```\n**** Before wait\njava.lang.Object object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           48 98 c9 05 (01001000 10011000 11001001 00000101) (97097800)\n      4     4        (object header)                           00 70 00 00 (00000000 01110000 00000000 00000000) (28672)\n      8     8        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 8 bytes external = 8 bytes total\n\n**** After wait\njava.lang.Object object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           0a b0 81 55 (00001010 10110000 10000001 01010101) (1434562570)\n      4     4        (object header)                           c0 7f 00 00 (11000000 01111111 00000000 00000000) (32704)\n      8     8        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 8 bytes external = 8 bytes total\n```\n1. `Before wait`阶段，`锁标志位`为`00`，处于`轻量级锁`\n2. `After wait`阶段，`锁标志位`为`10`，处于`重量级锁`\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Concurrent"]},{"title":"JVM基础 -- 类初始化","url":"%2F2016%2F07%2F14%2Fjvm-class-initialization%2F","content":"\n{% note info %}\n本文主要关注`类加载`过程中的`类初始化`阶段，介绍`clinit`方法、`主动引用`和`被动引用`\n{% endnote %}\n\n<!-- more -->\n\n# clinit\n`类（接口）初始化`阶段是执行**`clinit`**方法的过程\n\n## 接口 clinit\n1. 接口的`clinit`方法主要用于在`接口初始化`时，**`初始化接口的域`**（默认是`public static final`）\n2. `编译`后，接口中的`域`，有些会在`Class文件常量池`中，有些在`clinit`方法中进行`初始化`\n\n\n### 代码\n```java\npublic interface InterfaceClinit {\n    class InnerClass {\n    }\n\n    InnerClass INNER_CLASS = new InnerClass();\n    String NAME = \"zhongmingmao\";\n}\n```\n\n### 字节码\n```\npublic static final me.zhongmingmao.class_initialization.InterfaceClinit$InnerClass INNER_CLASS;\n    descriptor: Lme/zhongmingmao/class_initialization/InterfaceClinit$InnerClass;\n    flags: ACC_PUBLIC, ACC_STATIC, ACC_FINAL\n\npublic static final java.lang.String NAME;\n    descriptor: Ljava/lang/String;\n    flags: ACC_PUBLIC, ACC_STATIC, ACC_FINAL\n    ConstantValue: String zhongmingmao\n\n# <clinit>() 方法\nstatic {};\n    descriptor: ()V\n    flags: ACC_STATIC\n    Code:\n        stack=2, locals=0, args_size=0\n            0: new           #1 // class me/zhongmingmao/class_initialization/InterfaceClinit$InnerClass\n            3: dup\n            4: invokespecial #2 // Method me/zhongmingmao/class_initialization/InterfaceClinit$InnerClass.\"<init>\":()V\n            7: putstatic     #3 // Field INNER_CLASS:Lme/zhongmingmao/class_initialization/InterfaceClinit$InnerClass;\n            10: return\n```\n\n### 分析\n1. `NAME`拥有**`ConstantValue`**属性，存储在**`Class文件常量池`**中（`Constant pool`），不需要在`clinit`方法中进行初始化\n2. `INNER_CLASS`需要在`clinit`方法中进行初始化，对应的字节码是实现了`INNER_CLASS = new InnerClass()`，关于那`new`、`dup`、`invokespecial`等指令的具体含义，可参照博文「字节码 - 方法重载 + 方法重写」，这里不再赘述\n\n## 类 clinit\n1. `类clinit`与`接口clinit`最大的区别是允许**`static{}`**块\n2. `类clinit`由类中的所有**`static变量的赋值动作`**和**`static{}块中的语句`**`合并产生`的\n4. `static{}块`只能读取定义在`static{}块`之前的`static变量`，但能为定义在`static{}块`之后的`static变量`赋值\n\n### 代码\n```java\npublic class ClassClinit {\n    static class InnerClass {\n    }\n\n    static {\n        j = 2;\n        // System.out.println(i); // 非法前向引用\n    }\n\n    static int i = 1;\n    static int j;\n    static InnerClass INNER_CLASS = new InnerClass();\n}\n```\n\n### 字节码\n```\nstatic int i;\n    descriptor: I\n    flags: ACC_STATIC\n\nstatic int j;\n    descriptor: I\n    flags: ACC_STATIC\n\nstatic me.zhongmingmao.class_initialization.ClassClinit$InnerClass INNER_CLASS;\n    descriptor: Lme/zhongmingmao/class_initialization/ClassClinit$InnerClass;\n    flags: ACC_STATIC\n\n# <clinit>() 方法\nstatic {};\n    descriptor: ()V\n    flags: ACC_STATIC\n    Code:\n        stack=2, locals=0, args_size=0\n        0: iconst_2\n        1: putstatic     #2     // Field j:I\n        4: iconst_1\n        5: putstatic     #3     // Field i:I\n        8: new           #4     // class me/zhongmingmao/class_initialization/ClassClinit$InnerClass\n        11: dup\n        12: invokespecial #5    // Method me/zhongmingmao/class_initialization/ClassClinit$InnerClass.\"<init>\":()V\n        15: putstatic     #6    // Field INNER_CLASS:Lme/zhongmingmao/class_initialization/ClassClinit$InnerClass;\n        18: return\n```\n\n## 空 clinit\n`clinit`方法对于`类或接口`来说**`并不是必需`**的，如果一个类中没有`static{}块`，也没有对`static变量的赋值操作`，那么编译器可以不为这个类生成`clinit`方法\n\n### 代码\n```java\npublic class EmptyClassClinit {\n    // 字节码中不会有<clinit>()方法\n}\n\ninterface EmptyInterfaceClinit {\n    // 字节码中不会有<clinit>()方法\n}\n```\n\n## 隐含地并发\n1. `JVM`会保证一个`clinit`方法在`多线程`环境中被**`正确地加锁、同步`** ➜ `隐蔽地阻塞`\n2. 其他线程被阻塞，但如果执行clinit方法的线程退出clinit方法后，其他线程唤醒之后**`不会再次进入`**clinit方法\n\n### 代码\n```java\npublic class ClinitConcurrencyTest {\n    static class A {\n        static {\n            System.out.println(\"Class A Initialization\");\n            BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\n            try {\n                reader.readLine();\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n\n        Runnable initClassTask = () -> {\n            System.out.println(String.format(\"%s start\", Thread.currentThread().getName()));\n            new A(); // 隐蔽地同步，不会重复进入\n            System.out.println(String.format(\"%s run over\", Thread.currentThread().getName()));\n        };\n\n        new Thread(initClassTask, \"t1\").start();\n        new Thread(initClassTask, \"t2\").start();\n    }\n}\n```\n\n### 运行结果\n```\nt2 start\nt1 start\nClass A Initialization\nxxxxx # 控制台输入随意字符\nt2 run over\nt1 run over\n```\n\n## 类初始化 vs 接口初始化\n1. 当`类初始化`时，要求其`父类`全部都已经`类初始化`过了\n2. 当`接口初始化`时，并不要求其父接口全部都完成初始化，只有在`真正使用父接口`的时候（如`引用接口中定义的常量`）才会进行`父接口初始化`\n3. `接口的实现类`在进行`类初始化`时，也一样不会进行`父接口初始化`\n\n# 主动引用 - 触发类初始化\n\n## new指令\n\n### 代码\n```java\npublic class NewTest {\n    static class A {\n        static {\n            System.out.println(\"Class A Initialization\");\n        }\n    }\n\n    public static void main(String[] args) {\n        new A(); // 触发类A的初始化\n    }\n}\n```\n\n### 运行结果\n```\nClass A Initialization\n```\n\n### 字节码\n```\npublic static void main(java.lang.String[]);\n    descriptor: ([Ljava/lang/String;)V\n    flags: ACC_PUBLIC, ACC_STATIC\n    Code:\n        stack=2, locals=1, args_size=1\n            # new指令会触发类A的初始化\n            0: new           #2 // class me/zhongmingmao/class_initialization/NewTest$A\n            3: dup\n            4: invokespecial #3 // Method me/zhongmingmao/class_initialization/NewTest$A.\"<init>\":()V\n            7: pop\n            8: return\n        LocalVariableTable:\n            Start  Length  Slot  Name   Signature\n                0       9     0  args   [Ljava/lang/String;\n```\n\n## putstatic/getstatic指令\n\n### 代码\n```java\npublic class StaticTest {\n    static class A {\n        static String name;\n\n        static {\n            System.out.println(\"Class A Initialization\");\n        }\n    }\n\n    static class B {\n        static String name;\n\n        static {\n            System.out.println(\"Class B Initialization\");\n        }\n    }\n\n    public static void main(String[] args) {\n        A.name = \"zhongmingmao\"; // 触发类A的初始化\n        String name = B.name; // 触发类B的初始化\n    }\n}\n```\n\n### 运行结果\n```\nClass A Initialization\nClass B Initialization\n```\n\n### 字节码\n```\npublic static void main(java.lang.String[]);\n    descriptor: ([Ljava/lang/String;)V\n    flags: ACC_PUBLIC, ACC_STATIC\n    Code:\n        stack=1, locals=2, args_size=1\n            0: ldc           #2 // String zhongmingmao\n            # putstatic指令会触发类A的初始化\n            2: putstatic     #3 // Field me/zhongmingmao/class_initialization/StaticTest$A.name:Ljava/lang/String;\n            # getstatic指令会触发类B的初始化\n            5: getstatic     #4 // Field me/zhongmingmao/class_initialization/StaticTest$B.name:Ljava/lang/String;\n            8: astore_1\n            9: return\n            LocalVariableTable:\n                Start  Length  Slot  Name   Signature\n                    0      10     0  args   [Ljava/lang/String;\n                    9       1     1  name   Ljava/lang/String;\n```\n`putstatic`/`getstatic`指令会触发`类的初始化`\n\n## invokestatic指令\n\n### 代码\n```java\npublic class InvokestaticTest {\n    static class A {\n        static {\n            System.out.println(\"Class A Initialization\");\n        }\n\n        static void staticMethod() {\n        }\n    }\n\n    public static void main(String[] args) {\n        A.staticMethod(); // 触发类A的初始化\n    }\n}\n```\n\n### 运行结果\n```\nClass A Initialization\n```\n\n### 字节码\n```\npublic static void main(java.lang.String[]);\n    descriptor: ([Ljava/lang/String;)V\n    flags: ACC_PUBLIC, ACC_STATIC\n    Code:\n        stack=0, locals=1, args_size=1\n            # invokestatic指令会触发类A的初始化\n            0: invokestatic  #2 // Method me/zhongmingmao/class_initialization/InvokestaticTest$A.staticMethod:()V\n            3: return\n        LocalVariableTable:\n            Start  Length  Slot  Name   Signature\n                0       4     0  args   [Ljava/lang/String;\n```\n\n## 反射\n\n### Class.forName\n`Class.forName`方法可以通过`参数initialize`来确定是否触发类的初始化\n\n#### 代码\n```java\npublic class ClassForNameTest {\n    static class A {\n\n        static {\n            System.out.println(\"Class A Initialization\");\n        }\n    }\n\n    static class B {\n\n        static {\n            System.out.println(\"Class B Initialization\");\n        }\n    }\n\n    public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException,\n            InstantiationException {\n        ClassLoader classLoader = ClassForNameTest.class.getClassLoader();\n        Class.forName(A.class.getName()); // 触发类A的初始化\n\n        Class<?> clazz = Class.forName(B.class.getName(), false, classLoader); // 不会触发类B的初始化\n        System.out.println(\"Load Class B\");\n        clazz.newInstance(); // 触发类B的初始化\n    }\n}\n```\n\n#### 运行结果\n```\nClass A Initialization\nLoad Class B # 说明此时类B尚未初始化\nClass B Initialization\n```\n\n#### 分析\n`Class.forName`实际调用的是`native`方法（对应的CPP代码暂未研究）`forName0`，有一个标志位`initialize`，是否进行`类的初始化`\n```java\nprivate static native Class<?> forName0(String name, boolean initialize,\n                                       ClassLoader loader,\n                                       Class<?> caller) throws ClassNotFoundException;\n```\n\n### Class.newInstance\n1. `ClassLoader.loadClass`不会触发类的初始化\n2. `Class.newInstance`会触发类的初始化\n\n#### 代码\n```java\npublic class LoadClassTest {\n    static class A {\n\n        static {\n            System.out.println(\"Class A Initialization\");\n        }\n    }\n\n    public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException,\n            InstantiationException {\n        ClassLoader classLoader = LoadClassTest.class.getClassLoader();\n        Class<?> clazz = classLoader.loadClass(A.class.getName()); // 被动加载类A，不会触发类A的初始化\n        System.out.println(\"Load Class A\");\n        clazz.newInstance(); // 触发类A的初始化\n    }\n}\n```\n\n#### 运行结果\n```\nLoad Class A\nClass A Initialization\n```\n\n## 继承\n当初始化一个类的时候，如果发现其`父类`还没有进行过初始化，则`首先触发其父类的初始化`\n\n### 代码\n```java\npublic class InheritTest {\n    static class Father {\n\n        static {\n            System.out.println(\"Class Father Initialization\");\n        }\n    }\n\n    static class Son extends Father {\n\n        static {\n            System.out.println(\"Class Son Initialization\");\n        }\n    }\n\n    public static void main(String[] args) {\n        new Son(); // 首先触发类Father的初始化，再触发类Son的初始化\n    }\n}\n```\n\n### 运行结果\n```\nClass Father Initialization\nClass Son Initialization\n```\n\n### 字节码\n```\npublic static void main(java.lang.String[]);\n    descriptor: ([Ljava/lang/String;)V\n    flags: ACC_PUBLIC, ACC_STATIC\n    Code:\n        stack=2, locals=1, args_size=1\n            # new指令会触发类Son的初始化，由于其直接父类Father尚未初始化，会首先触发直接父类Father的初始化\n            0: new           #2 // class me/zhongmingmao/class_initialization/InheritTest$Son\n            3: dup\n            4: invokespecial #3 // Method me/zhongmingmao/class_initialization/InheritTest$Son.\"<init>\":()V\n            7: pop\n            8: return\n        LocalVariableTable:\n            Start  Length  Slot  Name   Signature\n                0       9     0  args   [Ljava/lang/String;\n```\n\n## 执行主类\n当JVM启动时，用户需要指定一个要执行的主类，JVM会先初始化这个主类\n\n### 代码\n```java\npublic class MainClassTest {\n    static {\n        System.out.println(\"Class MainClassTest Initialization\");\n    }\n\n    public static void main(String[] args) {\n    }\n}\n```\n\n### 运行结果\n```\nClass MainClassTest Initialization\n```\n\n# 被动引用 - 不触发类初始化\n\n## static 字段\n1. 对于`static字段`，只有**`直接定义这个字段的类才会被初始化`**\n2. 通过子类来引用父类中定义的static字段，只会触发父类的初始化而不会触发子类的初始化\n\n### 代码\n```java\npublic class StaticFieldTest {\n    static class Father {\n        static String FATHER_CLASS_NAME = Father.class.getName();\n\n        static {\n            System.out.println(\"Class Father Initialization\");\n        }\n    }\n\n    static class Son extends Father {\n        static String SON_CLASS_NAME = Son.class.getName();\n\n        static {\n            System.out.println(\"Class Son Initialization\");\n        }\n    }\n\n    public static void main(String[] args) {\n        String className = Son.FATHER_CLASS_NAME; // 只会触发类Father的初始化，不会触发类Son的初始化\n    }\n}\n```\n\n### 运行结果\n```\nClass Father Initialization\n```\n\n### 字节码\n```\npublic static void main(java.lang.String[]);\n    descriptor: ([Ljava/lang/String;)V\n    flags: ACC_PUBLIC, ACC_STATIC\n    Code:\n        stack=1, locals=2, args_size=1\n            # getstatic指令会触发类的初始化，FATHER_CLASS_NAME在类Father中定义，因此只会触发类Father（及其父类）的初始化\n            0: getstatic     #2 // Field me/zhongmingmao/class_initialization/StaticFieldTest$Son.FATHER_CLASS_NAME:Ljava/lang/String;\n            3: astore_1\n            4: return\n        LocalVariableTable:\n            Start  Length  Slot  Name   Signature\n                0       5     0  args   [Ljava/lang/String;\n                4       1     1 className   Ljava/lang/String;\n}\n```\n\n## 引用数组\n通过`数组`定义来引用类，不会触发类的初始化\n\n### 代码\n```java\npublic class ArrayRefTest {\n    static class A {\n        static {\n            System.out.println(\"Class A Initialization\");\n        }\n    }\n\n    public static void main(String[] args) {\n        A[] as = new A[10]; // 不会触发类A的初始化\n    }\n}\n```\n\n### 字节码\n```\npublic static void main(java.lang.String[]);\n    descriptor: ([Ljava/lang/String;)V\n    flags: ACC_PUBLIC, ACC_STATIC\n    Code:\n        stack=1, locals=2, args_size=1\n            0: bipush        10\n            # anewarray指令并不会触发类A的初始化\n            2: anewarray     #2 // class me/zhongmingmao/class_initialization/ArrayRefTest$A\n            5: astore_1\n            6: return\n        LocalVariableTable:\n            Start  Length  Slot  Name   Signature\n                0       7     0  args   [Ljava/lang/String;\n                6       1     1    as   [Lme/zhongmingmao/class_initialization/ArrayRefTest$A;\n}\n```\n\n## 编译时常量\n`常量`在`编译阶段`会存入`Class文件常量池`（`Constant pool`）中，编译时便会**`直接替换`**，本质上并没有直接引用绑定到定义常量的类，不会触发定义常量的类的初始化\n\n### 代码\n```java\npublic class ConstantValueTest {\n    static class A {\n        static final String NAME = \"zhongmingmao\";\n\n        static {\n            System.out.println(\"Class A Initialization\");\n        }\n    }\n\n    public static void main(String[] args) {\n        String className = A.NAME;// 不会触发类A的初始化\n    }\n}\n```\n\n### 字节码\nConstantValueTest\\$A\n```\nstatic final java.lang.String NAME;\n    descriptor: Ljava/lang/String;\n    flags: ACC_STATIC, ACC_FINAL\n    ConstantValue: String zhongmingmao # 存储在Class文件常量池，运行时会存放到运行时常量池\n\n# clinit 方法\nstatic {};\n    descriptor: ()V\n    flags: ACC_STATIC\n    Code:\n        stack=2, locals=0, args_size=0\n            0: getstatic     #2 // Field java/lang/System.out:Ljava/io/PrintStream;\n            3: ldc           #3 // String Class A Initialization\n            5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n            8: return\n```\nConstantValueTest\n```\npublic static void main(java.lang.String[]);\n    descriptor: ([Ljava/lang/String;)V\n    flags: ACC_PUBLIC, ACC_STATIC\n    Code:\n        stack=1, locals=2, args_size=1\n            # ldc指令直接将常量直接压入操作数栈，这在编译时已经可以确定了，因此直接替换，因此在运行时也不会触发类A的初始化\n            0: ldc       #3 // String zhongmingmao\n            2: astore_1\n            3: return\n        LocalVariableTable:\n            Start  Length  Slot  Name   Signature\n                0       4     0  args   [Ljava/lang/String;\n                3       1     1 className   Ljava/lang/String;\n```\n\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- 晋升规则","url":"%2F2016%2F07%2F09%2Fjvm-gc-promotion%2F","content":"\n{% note info %}\n本文将通过最`基本`的垃圾收集器（`Serial` + `Serial Old`），简单地讲述JVM`内存分配和回收过程`中的`3`个基本的晋升规则：`大对象直接晋升`、`对象年龄晋升`、`动态晋升`\n代码托管在：[https://github.com/zhongmingmao/jvm_demo](https://github.com/zhongmingmao/jvm_demo)\n{% endnote %}\n\n<!-- more -->\n\n# -XX:+UseSerialGC\n1. `新生代`采用`Serial`垃圾收集器（`Copying`算法，`单线程`，`Stop The World`）\n2. `老年代`采用`Serial Old`垃圾收集器（`Mark-Compact`算法，`单线程`，`Stop The World`）\n\n# Minor GC / Major GC / Full GC\n\n## 常规理解\n1. `Eden`空间不够 ➔ `Minor GC` ➔ 回收`Young Generation`\n2. `Old Generation`空间不够 ➔ `Major GC` ➔ 回收`Old Generation`\n3. `Method Area`（`Java 8`开始由`MetaSpace`实现，之前由`Permanent Generation`实现）空间不够 ➔ `Full GC` ➔ 回收`Young Generation`+`Old Generation`+`Method Area`\n\n最难区分的是`Major GC`和`Full GC`，其实并没有明确规定两者的区别，因此不要以`Minor GC`、`Major GC`、`Full GC`的方式来思考问题，而应该关注\n1. `GC`是否需要`Stop-The-World`\n2. `GC`能否`并发`（不是并行，是并发！）\n3. 应用的`延迟`和`吞吐量`\n\n本文认为`Major GC` ≈ `Full GC`，不作区分\n\n## Minor GC\n1. 发生在`新生代`，当`Eden`区域没有足够空间进行分配\n2. Java对象大多具有`短命`的特性\n3. `Minor GC`非常`频繁`，速度也比较`快`\n4. `Minor GC`会造成`Stop-The-World`，但由于`新生代`的对象为大多为`短命`对象，因此由`Stop-The-World`而造成的延迟可以忽略\n\n## Major GC / Full GC\n1. 发生在`老年代`\n2. 出现`Major GC`，经常伴随`至少一次Minor GC`\n3. 速度比较`慢`，`SpeedOf(Minor GC) ≈ 10 * SpeedOf(Major GC)`\n4. `Major GC`也会造成`Stop-The-World`，但由于`老年代`的对象为大多为`长命`对象，因此由`Stop-The-World`而造成的延迟可能会比较大，因此才会出现`并发收集器`：`CMS`和`G1`（Java 9默认）\n\n# 大对象直接晋升\n\n## 代码\n```java\n// JVM Args : -Xms20m -Xmx20m -Xmn10m -XX:SurvivorRatio=8 -XX:+UseSerialGC -XX:+PrintGCDetails\n// 堆大小：20M\n// 新生代大小：10M\n// Eden区大小：8M\n// Survivor区大小：1M\n// 老年代大小：10M\npublic class MinorGCAndFullGC {\n    private static final int _1MB = 1024 * 1024;\n\n    public static void main(String[] args) {\n        System.gc();\n        byte[] b1 = new byte[5 * _1MB];\n        byte[] b2 = new byte[5 * _1MB];// 1次Minor GC\n        byte[] b3 = new byte[5 * _1MB];// 1次Minor GC + 1次Full GC ⇒ OOM\n    }\n}\n```\n\n## 运行结果\n```\n[Full GC (System.gc()) [Tenured: 0K->467K(10240K), 0.0037172 secs] 2217K->467K(19456K), [Metaspace: 3177K->3177K(1056768K)], 0.0037645 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]\n[GC (Allocation Failure) [DefNew: 5447K->4K(9216K), 0.0036997 secs] 5915K->5592K(19456K), 0.0037186 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]\n[GC (Allocation Failure) [DefNew: 5209K->5209K(9216K), 0.0000165 secs][Tenured: 5587K->5587K(10240K), 0.0029173 secs] 10796K->10713K(19456K), [Metaspace: 3270K->3270K(1056768K)], 0.0029714 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]\n[Full GC (Allocation Failure) [Tenured: 5587K->5527K(10240K), 0.0036178 secs] 10713K->10653K(19456K), [Metaspace: 3270K->3270K(1056768K)], 0.0036448 secs] [Times: user=0.01 sys=0.00, real=0.01 secs]\nHeap\n def new generation   total 9216K, used 5508K [0x00000007bec00000, 0x00000007bf600000, 0x00000007bf600000)\n  eden space 8192K,  67% used [0x00000007bec00000, 0x00000007bf161370, 0x00000007bf400000)\n  from space 1024K,   0% used [0x00000007bf500000, 0x00000007bf500000, 0x00000007bf600000)\n  to   space 1024K,   0% used [0x00000007bf400000, 0x00000007bf400000, 0x00000007bf500000)\n tenured generation   total 10240K, used 5527K [0x00000007bf600000, 0x00000007c0000000, 0x00000007c0000000)\n   the space 10240K,  53% used [0x00000007bf600000, 0x00000007bfb65f68, 0x00000007bfb66000, 0x00000007c0000000)\n Metaspace       used 3330K, capacity 4496K, committed 4864K, reserved 1056768K\n  class space    used 370K, capacity 388K, committed 512K, reserved 1048576K\nException in thread \"main\" java.lang.OutOfMemoryError: Java heap space\n```\n\n## 运行过程\n\n### System.gc()\n对应的GC日志\n```\n[Full GC (System.gc()) [Tenured: 0K->467K(10240K), 0.0037172 secs] 2217K->467K(19456K), [Metaspace: 3177K->3177K(1056768K)], 0.0037645 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]\n```\n1. 进行`Full GC`的原因是代码调用`System.gc()`\n2. `堆`总大小为`19456K` ≈ `20M`\n3. `老年代`（`Tenured Generation`）总大小为`10240K` = `10M`，目前占用`467K`，可忽略\n4. `新生代`（`Def New Generation`）目前占用`467K-467K=0K`，总大小 = 堆大小 - 老年代大小 ≈ `10M`，`SurvivorRatio=8`，因此`Eden`区大小为`8M`，`Survivor`区大小为`1M`\n\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/gc_1_system_gc.png\" width=\"500\">\n\n### byte[] b1 = new byte[5 * _1MB]\n`Eden区`有`8M`空闲空间，能完全容纳`b1`，不会进行`GC`\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/gc_1_b1.png\" width=\"500\">\n\n### byte[] b2 = new byte[5 * _1MB]\n对应的GC日志\n```\n[GC (Allocation Failure) [DefNew: 5447K->4K(9216K), 0.0036997 secs] 5915K->5592K(19456K), 0.0037186 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]\n```\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/gc_1_b2.png\" width=\"500\">\n1. `Eden`区只有`8M`，此时已经分配了`b1`，最多只剩下`3M`的可用空间，`Serial`采集器采用`Copying`算法，不足以容纳`b2`，触发`Minor GC`\n2. 进行`Minor GC`的原因是`Allocation Failure`，即内存分配失败，与上面分析一致\n3. 进行`Minor GC`，首先尝试将`Eden`区和`Survivor 0`区中的`存活对象`一起移到`Survivor 1`区，`b1`是强引用，依旧存活，但由于`Survivor 1`区只有`1M`，无法容纳`b1`，尝试将`b1`直接晋升到`Tenured`区\n4. 此时`Tenured`有`10M`的可用空间，能容纳`b1`，可以将`b1`晋升到`Tenured`区，并释放`b1`原本在`Eden`区占用的内存空间\n5. `Minor GC`结束后，`b2`便能顺利地在`Eden`区进行分配\n\n### byte[] b3 = new byte[5 * _1MB]\n对应的GC日志\n```\n[GC (Allocation Failure) [DefNew: 5209K->5209K(9216K), 0.0000165 secs][Tenured: 5587K->5587K(10240K), 0.0029173 secs] 10796K->10713K(19456K), [Metaspace: 3270K->3270K(1056768K)], 0.0029714 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]\n[Full GC (Allocation Failure) [Tenured: 5587K->5527K(10240K), 0.0036178 secs] 10713K->10653K(19456K), [Metaspace: 3270K->3270K(1056768K)], 0.0036448 secs] [Times: user=0.01 sys=0.00, real=0.01 secs]\n```\n1. 由于`Eden`区此时最多有`3M`的可用空间，要分配`b3`，首先触发一次`Minor GC`\n2. 由于内存空间（`Eden`、`Survivor 0`、`Tenured`）不足，`Minor GC`也会失败，进而触发`Full GC`\n3. `Tenured`区采用`Serial Old`收集器，`Full GC`时会尝试采用`Mark-Compact`算法进行GC，但依旧会失败，进而导致抛出`OutOfMemoryError`\n\n## 小结\n尽量避免使用**`需要连续内存空间的短命大对象`**，例如`长字符串`和`基本类型的大数组`，因为这会导致`Minor GC`的时候，这些短命大对象有可能会`直接晋升`到老年代，进而`加大Full GC的频率`\n\n# 对象年龄晋升\n对象每经历一次`Minor GC`，年龄就会增加`1`，到了一定的阈值(`-XX:MaxTenuringThreshold`，默认是`15`)，就会`晋升`到老年代\n\n## 代码\n```java\n/**\n * 校验JVM参数 -XX:MaxTenuringThreshold\n *\n * @author zhongmingmao zhongmingmao0625@gmail.com\n */\npublic class TenuringThreshold {\n\n    private static final int _10MB = 10 * 1024 * 1024;\n    private static Pattern BIN_PATTERN = Pattern.compile(\"\\\\(((\\\\d{8}\\\\s?){4})\\\\)\");\n\n    // JVM Args : -Xms200m -Xmx200m -Xmn100m -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=3\n    // -XX:+UseSerialGC -XX:+PrintGCDetails  -Djol.tryWithSudo=true\n    public static void main(String[] args) {\n\n        System.gc();\n        byte[] b = new byte[_10MB / 4];\n        System.out.println(String.format(\"Init Address : %s\\n\", VM.current().addressOf(b)));\n\n        for (int i = 0; i < 6; ++i) {\n            // 从i=1开始，每分配一次bytes，就会触发一次Minor GC\n            // 当对象b的GCAge < MaxTenuringThreshold -> 在两个Survivor区之间来回移动\n            // 当对象b的GCAge >= MaxTenuringThreshold -> 晋升到Tenured区\n            byte[] bytes = new byte[5 * _10MB];\n            System.out.println(String.format(\"Address[%s] : %s , GC Age : %s\", i,\n                    VM.current().addressOf(b),\n                    getObjectGCAge(b)));\n            System.out.println();\n        }\n    }\n\n    /**\n     * 获取对象的GC年龄<br/>\n     * Java对象头结构 See http://hg.openjdk.java.net/jdk8/jdk8/hotspot/file/87ee5ee27509/src/share/vm/oops/markOop.hpp\n     */\n    private static int getObjectGCAge(Object object) {\n        /*\n        ClassLayout.parseInstance(object).toPrintable()的完整格式\n        [B object internals:\n         OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n              0     4        (object header)                           19 00 00 00 (00011001 00000000 00000000\n              00000000) (25)\n              4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000\n              00000000) (0)\n              8     4        (object header)                           f5 00 00 f8 (11110101 00000000 00000000\n              11111000) (-134217483)\n             12     4        (object header)                           00 00 28 00 (00000000 00000000 00101000\n             00000000) (2621440)\n             16 2621440   byte [B.<elements>                             N/A\n        Instance size: 2621456 bytes\n        Space losses: 0 bytes internal + 0 bytes external = 0 bytes total\n        * */\n        String line = ClassLayout.parseInstance(object).toPrintable().split(\"\\n\")[2];\n        Matcher matcher = BIN_PATTERN.matcher(line);\n        if (matcher.find()) {\n            return Integer.parseInt(matcher.group(1).split(\"\\\\s\")[0].substring(1, 5), 2);\n        }\n        return -1;\n    }\n}\n```\n\n## 运行结果\n```\n[Full GC (System.gc()) [Tenured: 0K->452K(102400K), 0.0032760 secs] 6555K->452K(194560K), [Metaspace: 3198K->3198K(1056768K)], 0.0033038 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]\nInit Address : 33076281344\n\nAddress[0] : 33076281344 , GC Age : 0\n\n[GC (Allocation Failure) [DefNew: 70169K->3565K(92160K), 0.0051274 secs] 70622K->4017K(194560K), 0.0051485 secs] [Times: user=0.01 sys=0.00, real=0.00 secs]\nAddress[1] : 33170780832 , GC Age : 1\n\n[GC (Allocation Failure) [DefNew: 57128K->3417K(92160K), 0.0075981 secs] 57580K->3869K(194560K), 0.0076253 secs] [Times: user=0.01 sys=0.01, real=0.00 secs]\nAddress[2] : 33160295048 , GC Age : 2\n\n[GC (Allocation Failure) [DefNew: 56715K->3417K(92160K), 0.0020149 secs] 57168K->3869K(194560K), 0.0020339 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]\nAddress[3] : 33170780808 , GC Age : 3\n\n[GC (Allocation Failure) [DefNew: 56533K->0K(92160K), 0.0052362 secs] 56985K->3870K(194560K), 0.0052590 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]\nAddress[4] : 33181729784 , GC Age : 3\n\n[GC (Allocation Failure) [DefNew: 52773K->0K(92160K), 0.0004461 secs] 56643K->3870K(194560K), 0.0004610 secs] [Times: user=0.01 sys=0.00, real=0.00 secs]\nAddress[5] : 33181729784 , GC Age : 3\n\nHeap\n def new generation   total 92160K, used 53599K [0x00000007b3800000, 0x00000007b9c00000, 0x00000007b9c00000)\n  eden space 81920K,  65% used [0x00000007b3800000, 0x00000007b6c57cd8, 0x00000007b8800000)\n  from space 10240K,   0% used [0x00000007b9200000, 0x00000007b92000f0, 0x00000007b9c00000)\n  to   space 10240K,   0% used [0x00000007b8800000, 0x00000007b8800000, 0x00000007b9200000)\n tenured generation   total 102400K, used 3869K [0x00000007b9c00000, 0x00000007c0000000, 0x00000007c0000000)\n   the space 102400K,   3% used [0x00000007b9c00000, 0x00000007b9fc7710, 0x00000007b9fc7800, 0x00000007c0000000)\n Metaspace       used 6569K, capacity 6832K, committed 7040K, reserved 1056768K\n  class space    used 765K, capacity 843K, committed 896K, reserved 1048576K\n```\n\n### byte[] b = new byte[_10MB / 4]\n```\nInit Address : 33076281344\n```\n尝试分配`对象b`到**`Eden`**区，内存空间充足，初始内存地址为`33076281344`，`GC年龄`为`0`\n\n### 循环`i=0`\n```\nAddress[0] : 33076281344 , GC Age : 0\n```\n尝试在`Eden`区分配`5*_10MB`的内存空间，内存空间充足，不需要触发`Minor GC`，`对象b`的内存地址`不变`，依旧是`33076281344`，在**`Eden`**区，`GC年龄`为`0`\n\n### 循环`i=1`\n```\n[GC (Allocation Failure) [DefNew: 70169K->3565K(92160K), 0.0051274 secs] 70622K->4017K(194560K), 0.0051485 secs] [Times: user=0.01 sys=0.00, real=0.00 secs]\nAddress[1] : 33170780832 , GC Age : 1\n```\n尝试在`Eden`区再分配`5*_10MB`的内存空间，内存空间不足，触发`Minor GC`，循环`i=0`分配的`5*_10MB`的内存空间被回收，`对象b`被移动到了**`Survivor 0`**区，内存地址变成了`33170780832`，`GC年龄`为`1`\n\n### 循环`i=2`\n```\n[GC (Allocation Failure) [DefNew: 57128K->3417K(92160K), 0.0075981 secs] 57580K->3869K(194560K), 0.0076253 secs] [Times: user=0.01 sys=0.01, real=0.00 secs]\nAddress[2] : 33160295048 , GC Age : 2\n```\n尝试在`Eden`区再分配`5*_10MB`的内存空间，内存空间不足，触发`Minor GC`，循环`i=1`分配的`5*_10MB`的内存空间被回收，`对象b`被移动到了**`Survivor 1`**区，内存地址变成了`33160295048`，`GC年龄`为`2`\n\n### 循环`i=3`\n```\n[GC (Allocation Failure) [DefNew: 56715K->3417K(92160K), 0.0020149 secs] 57168K->3869K(194560K), 0.0020339 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]\nAddress[3] : 33170780808 , GC Age : 3\n```\n尝试在`Eden`区再分配`5*_10MB`的内存空间，内存空间不足，触发`Minor GC`，循环`i=2`分配的`5*_10MB`的内存空间被回收，`对象b`**`再次`**被移动到了**`Survivor 0`**区，内存地址变成了`33170780808`，`GC年龄`为`3`\n\n### 循环`i=4`\n```\n[GC (Allocation Failure) [DefNew: 56533K->0K(92160K), 0.0052362 secs] 56985K->3870K(194560K), 0.0052590 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]\nAddress[4] : 33181729784 , GC Age : 3\n```\n尝试在`Eden`区再分配`5*_10MB`的内存空间，内存空间不足，触发`Minor GC`，循环`i=3`分配的`5*_10MB`的内存空间被回收，`对象b`的`GC年龄`已经达到了`MaxTenuringThreshold`，可以直接晋升到`Tenured`区，内存地址变成了`33181729784`，`GC年龄`依旧为`3`,不会再增加\n\n### 循环`i=5`\n```\n[GC (Allocation Failure) [DefNew: 52773K->0K(92160K), 0.0004461 secs] 56643K->3870K(194560K), 0.0004610 secs] [Times: user=0.01 sys=0.00, real=0.00 secs]\nAddress[5] : 33181729784 , GC Age : 3\n```\n尝试在`Eden`区再分配`5*_10MB`的内存空间，内存空间不足，触发`Minor GC`，循环`i=4`分配的`5*_10MB`的内存空间被回收，`对象b`已经在`Tenured`区，此时并不是`Full GC`，内存地址不会改变，依旧是`33181729784`，`GC年龄`也依旧是`3`\n\n\n# 动态晋升\n在`Minor GC`时，如果在`Survivor`中**`相同年龄的所有对象大小之和`** ≧ `0.5 * sizeof(Survivor)` ⇒ **`大于或等于`**该年龄的对象**`直接晋升`**到老年代，无须考虑`MaxTenuringThreshold`\n\n## 代码\n```java\n/**\n * 验证动态晋升<br/>\n *\n * @author zhongmingmao zhongmingmao@0625@gmail.com\n */\npublic class DynamicGCAge {\n\n    private static final int _10MB = 10 * 1024 * 1024;\n    private static Pattern BIN_PATTERN = Pattern.compile(\"\\\\(((\\\\d{8}\\\\s?){4})\\\\)\");\n\n    // JVM Args : -Xms200m -Xmx200m -Xmn100m -XX:SurvivorRatio=8 -XX:+UseSerialGC\n    // -XX:+PrintGCDetails -Djol.tryWithSudo=true\n    public static void main(String[] args) {\n        System.gc();\n        byte[] b0 = new byte[_10MB / 8];\n        byte[] b1 = null;\n        byte[] b2 = null;\n        byte[] b3 = null;\n        byte[] b4 = null;\n        System.out.println(getObjectInfo(\"b0\", b0));\n        System.out.println();\n        for (int i = 0; i < 5; ++i) {\n            // i=2才实例化b1~b4,b1的GC年龄比b1~b4大，且b1~b4的总大小等于Survivor区的一半，下次Minor GC，能直接晋升\n            if (i == 2) {\n                b1 = new byte[_10MB / 8];\n                b2 = new byte[_10MB / 8];\n                b3 = new byte[_10MB / 8];\n                b4 = new byte[_10MB / 8];\n            }\n            byte[] bytes = new byte[5 * _10MB];\n\n            System.out.println(getObjectInfo(\"b0\", b0));\n            System.out.println(getObjectInfo(\"b1\", b1));\n            System.out.println(getObjectInfo(\"b2\", b2));\n            System.out.println(getObjectInfo(\"b3\", b3));\n            System.out.println(getObjectInfo(\"b4\", b4));\n            System.out.println();\n        }\n    }\n\n    private static int getObjectGCAge(Object object) {\n        if (null == object) {\n            return -1;\n        }\n        String line = ClassLayout.parseInstance(object).toPrintable().split(\"\\n\")[2];\n        Matcher matcher = BIN_PATTERN.matcher(line);\n        if (matcher.find()) {\n            return Integer.parseInt(matcher.group(1).split(\"\\\\s\")[0].substring(1, 5), 2);\n        }\n        return 0;\n    }\n\n    private static long getObjectAddress(Object object) {\n        return null == object ? -1 : VM.current().addressOf(object);\n    }\n\n    private static String getObjectInfo(String name, Object object) {\n        return String.format(\"Obj[%s] , Address:[%s] , GCAge:[%s]\",\n                name,\n                getObjectAddress(object),\n                getObjectGCAge(object));\n    }\n}\n```\n\n## 运行结果\n```\n[Full GC (System.gc()) [Tenured: 0K->484K(102400K), 0.0046554 secs] 6555K->484K(194560K), [Metaspace: 3346K->3346K(1056768K)], 0.0047017 secs] [Times: user=0.01 sys=0.00, real=0.00 secs]\nObj[b0] , Address:[33076281344] , GCAge:[0]\n\nObj[b0] , Address:[33076281344] , GCAge:[0]\nObj[b1] , Address:[-1] , GCAge:[-1]\nObj[b2] , Address:[-1] , GCAge:[-1]\nObj[b3] , Address:[-1] , GCAge:[-1]\nObj[b4] , Address:[-1] , GCAge:[-1]\n\n[GC (Allocation Failure) [DefNew: 67248K->2254K(92160K), 0.0069139 secs] 67732K->2738K(194560K), 0.0069444 secs] [Times: user=0.00 sys=0.01, real=0.01 secs]\nObj[b0] , Address:[33170752344] , GCAge:[1]\nObj[b1] , Address:[-1] , GCAge:[-1]\nObj[b2] , Address:[-1] , GCAge:[-1]\nObj[b3] , Address:[-1] , GCAge:[-1]\nObj[b4] , Address:[-1] , GCAge:[-1]\n\n[GC (Allocation Failure) [DefNew: 59673K->7226K(92160K), 0.0059408 secs] 60157K->7710K(194560K), 0.0059641 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]\nObj[b0] , Address:[33160266584] , GCAge:[2]\nObj[b1] , Address:[33161577320] , GCAge:[1]\nObj[b2] , Address:[33162888056] , GCAge:[1]\nObj[b3] , Address:[33164198792] , GCAge:[1]\nObj[b4] , Address:[33165509528] , GCAge:[1]\n\n[GC (Allocation Failure) [DefNew: 60004K->0K(92160K), 0.0086877 secs] 60488K->7710K(194560K), 0.0087102 secs] [Times: user=0.00 sys=0.01, real=0.00 secs]\nObj[b0] , Address:[33181733760] , GCAge:[2]\nObj[b1] , Address:[33183044496] , GCAge:[1]\nObj[b2] , Address:[33184355232] , GCAge:[1]\nObj[b3] , Address:[33185665968] , GCAge:[1]\nObj[b4] , Address:[33186976704] , GCAge:[1]\n\n[GC (Allocation Failure) [DefNew: 53328K->0K(92160K), 0.0009302 secs] 61039K->7710K(194560K), 0.0009761 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]\nObj[b0] , Address:[33181733760] , GCAge:[2]\nObj[b1] , Address:[33183044496] , GCAge:[1]\nObj[b2] , Address:[33184355232] , GCAge:[1]\nObj[b3] , Address:[33185665968] , GCAge:[1]\nObj[b4] , Address:[33186976704] , GCAge:[1]\n\nHeap\n def new generation   total 92160K, used 53610K [0x00000007b3800000, 0x00000007b9c00000, 0x00000007b9c00000)\n  eden space 81920K,  65% used [0x00000007b3800000, 0x00000007b6c5aa18, 0x00000007b8800000)\n  from space 10240K,   0% used [0x00000007b8800000, 0x00000007b8800050, 0x00000007b9200000)\n  to   space 10240K,   0% used [0x00000007b9200000, 0x00000007b9200000, 0x00000007b9c00000)\n tenured generation   total 102400K, used 7710K [0x00000007b9c00000, 0x00000007c0000000, 0x00000007c0000000)\n   the space 102400K,   7% used [0x00000007b9c00000, 0x00000007ba387ae8, 0x00000007ba387c00, 0x00000007c0000000)\n Metaspace       used 6608K, capacity 6832K, committed 7040K, reserved 1056768K\n  class space    used 765K, capacity 843K, committed 896K, reserved 1048576K\n```\n\n### byte[] b0 = new byte[_10MB / 8]\n```\nObj[b0] , Address:[33076281344] , GCAge:[0]\n```\n尝试分配`对象b0`到**`Eden`**区，内存空间充足，初始内存地址为`33076281344`，`GC年龄`为`0`\n\n### 循环`i=0`\n```\nObj[b0] , Address:[33076281344] , GCAge:[0]\nObj[b1] , Address:[-1] , GCAge:[-1]\nObj[b2] , Address:[-1] , GCAge:[-1]\nObj[b3] , Address:[-1] , GCAge:[-1]\nObj[b4] , Address:[-1] , GCAge:[-1]\n```\n1. 尝试在`Eden`区分配`5*_10MB`的内存空间，内存空间充足，不需要触发`Minor GC`，`对象b0`的内存地址`不变`，依旧是`33076281344`，在**`Eden`**区，`GC年龄`为`0`\n2. `b1~b4`尚未实例化\n\n### 循环`i=1`\n```\n[GC (Allocation Failure) [DefNew: 67248K->2254K(92160K), 0.0069139 secs] 67732K->2738K(194560K), 0.0069444 secs] [Times: user=0.00 sys=0.01, real=0.01 secs]\nObj[b0] , Address:[33170752344] , GCAge:[1]\nObj[b1] , Address:[-1] , GCAge:[-1]\nObj[b2] , Address:[-1] , GCAge:[-1]\nObj[b3] , Address:[-1] , GCAge:[-1]\nObj[b4] , Address:[-1] , GCAge:[-1]\n```\n1. 尝试在`Eden`区再分配`5*_10MB`的内存空间，内存空间不足，触发`Minor GC`，循环`i=0`分配的`5*_10MB`的内存空间被回收，`对象b0`被移动到了**`Survivor 0`**区，内存地址变成了`33170752344`，`GC年龄`为`1`\n2. `b1~b4`尚未实例化\n\n### 循环`i=2`\n```\n[GC (Allocation Failure) [DefNew: 59673K->7226K(92160K), 0.0059408 secs] 60157K->7710K(194560K), 0.0059641 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]\nObj[b0] , Address:[33160266584] , GCAge:[2]\nObj[b1] , Address:[33161577320] , GCAge:[1]\nObj[b2] , Address:[33162888056] , GCAge:[1]\nObj[b3] , Address:[33164198792] , GCAge:[1]\nObj[b4] , Address:[33165509528] , GCAge:[1]\n```\n1. 尝试在`Eden`区再分配`b1~b4`的内存空间，内存空间充足，不会触发`Minor GC`\n2. 尝试在`Eden`区再分配`5*_10MB`的内存空间，内存空间不足，触发`Minor GC`，循环`i=1`分配的`5*_10MB`的内存空间被回收，`对象b0`被移动到了**`Survivor 1`**区，内存地址变成了`33160266584`，`GC年龄`为`2`\n3. 另外这次`Minor GC`也把`b1~b4`移动到了**`Survivor 1`**区，具体信息GC日志所示\n\n### 循环`i=3`\n```\n[GC (Allocation Failure) [DefNew: 60004K->0K(92160K), 0.0086877 secs] 60488K->7710K(194560K), 0.0087102 secs] [Times: user=0.00 sys=0.01, real=0.00 secs]\nObj[b0] , Address:[33181733760] , GCAge:[2]\nObj[b1] , Address:[33183044496] , GCAge:[1]\nObj[b2] , Address:[33184355232] , GCAge:[1]\nObj[b3] , Address:[33185665968] , GCAge:[1]\nObj[b4] , Address:[33186976704] , GCAge:[1]\n```\n尝试在`Eden`区再分配`5*_10MB`的内存空间，内存空间不足，触发`Minor GC`，循环`i=2`分配的`5*_10MB`的内存空间被回收，此时**`Survivor 1`**区中`b1~b4`具有`相同的GC年龄`，`总大小 = 5M = 0.5 * sizeof(Survivor)`，可以进行**`动态晋升`**，所有GC年龄大于等于1的对象都可以直接晋升到老年代，因此`b0~b4`直接晋升，具体信息GC日志所示\n\n### 循环`i=4`\n```\n[GC (Allocation Failure) [DefNew: 53328K->0K(92160K), 0.0009302 secs] 61039K->7710K(194560K), 0.0009761 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]\nObj[b0] , Address:[33181733760] , GCAge:[2]\nObj[b1] , Address:[33183044496] , GCAge:[1]\nObj[b2] , Address:[33184355232] , GCAge:[1]\nObj[b3] , Address:[33185665968] , GCAge:[1]\nObj[b4] , Address:[33186976704] , GCAge:[1]\n```\n尝试在`Eden`区再分配`5*_10MB`的内存空间，内存空间不足，触发`Minor GC`，循环`i=3`分配的`5*_10MB`的内存空间被回收，此时`b0~b4`都已经在老年代中了，此时只是`Minor GC`，内存地址和GC年龄都不会改变\n\n<!-- indicate-the-source -->\n","tags":["GC"],"categories":["Baisc"]},{"title":"JVM基础 -- 伪泛型","url":"%2F2016%2F07%2F07%2Fjvm-fake-generic%2F","content":"\n{% note info %}\n本文将从`JVM字节码`的角度解释一下Java为什么是`伪泛型`\n{% endnote %}\n\n<!-- more -->\n\n# 伪泛型\n1. Java是`伪泛型`的，泛型在Java中只是`语法糖`，是通过`类型擦除`和`强制转换`来实现的\n2. 在`运行期`，`ArrayList<Integer>`与`ArrayList<String>`就是`同一个类`，在Java中并不存在类似与`ArrayList<Integer>`这种`泛型类型`\n\n# 代码\n```java\npublic class FakeGeneric {\n\n    static class Father {\n    }\n\n    static class Son extends Father {\n    }\n\n    private static void checkFather(Father father) {\n    }\n\n    public static void main(String[] args) {\n        Map<Father, Father> map = new HashMap<>(); // Map<K,V> , HashMap<K,V>\n        Father father = new Father();\n        Father son = new Son();\n\n        map.put(father, son); // V put(K key, V value);\n        checkFather(map.get(father)); // V get(Object key);\n    }\n}\n```\n\n# 字节码\n```\npublic static void main(java.lang.String[]);\n    descriptor: ([Ljava/lang/String;)V\n    flags: ACC_PUBLIC, ACC_STATIC\n    Code:\n        stack=3, locals=4, args_size=1\n            0: new           #2         // class java/util/HashMap\n            3: dup\n            4: invokespecial #3         // Method java/util/HashMap.\"<init>\":()V\n            7: astore_1\n            8: new           #4         // class me/zhongmingmao/test/FakeGeneric$Father\n            11: dup\n            12: invokespecial #5        // Method me/zhongmingmao/test/FakeGeneric$Father.\"<init>\":()V\n            15: astore_2\n            16: new           #6        // class me/zhongmingmao/test/FakeGeneric$Son\n            19: dup\n            20: invokespecial #7        // Method me/zhongmingmao/test/FakeGeneric$Son.\"<init>\":()V\n            23: astore_3\n            24: aload_1\n            25: aload_2\n            26: aload_3\n            27: invokeinterface #8,3    // InterfaceMethod java/util/Map.put:(Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;\n            32: pop\n            33: aload_1\n            34: aload_2\n            35: invokeinterface #9,2    // InterfaceMethod java/util/Map.get:(Ljava/lang/Object;)Ljava/lang/Object;\n            40: checkcast     #4        // class me/zhongmingmao/test/FakeGeneric$Father\n            43: invokestatic  #10       // Method checkFather:(Lme/zhongmingmao/test/FakeGeneric$Father;)V\n            46: return\n        LocalVariableTable:\n            Start  Length  Slot  Name   Signature\n                0      47     0  args   [Ljava/lang/String;\n                8      39     1   map   Ljava/util/Map;\n               16      31     2 father   Lme/zhongmingmao/test/FakeGeneric$Father;\n               24      23     3   son   Lme/zhongmingmao/test/FakeGeneric$Father;\n        LocalVariableTypeTable:\n            Start  Length  Slot  Name   Signature\n                8      39     1   map   Ljava/util/Map<Lme/zhongmingmao/test/FakeGeneric$Father;Lme/zhongmingmao/test/FakeGeneric$Father;>;\n}\n```\n\n## new HashMap<>()\n在Java代码中，创建map时是带有泛型信息的\n```java\nMap<Father, Father> map = new HashMap<>();\n```\n对应的JVM字节码\n```\n0: new           #2 // class java/util/HashMap\n3: dup\n4: invokespecial #3 // Method java/util/HashMap.\"<init>\":()V\n7: astore_1\n```\n在map的创建过程中并`没有任何泛型信息`，已经可以初步判断，Java并不存在`HashMap<Father,Father>`这样的`泛型类型`，是**`伪泛型`**\n关于那4个指令的具体含义，可参照博文「字节码 - 方法重载 + 方法重写」，这里不再赘述\n\n## map.put(father, son)\n在Java代码中，Map接口的`put`方法签名也是带有泛型信息的\n```java\nV put(K key, V value);\n```\n对应的JVM字节码\n```\n27: invokeinterface #8,3    // InterfaceMethod java/util/Map.put:(Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;\n```\n在`put`操作中也是`没有任何泛型信息`，只是简单地处理为`java.lang.Object`，这也是我们常说的**`类型擦除`**\n\n## map.get(father)\n在Java代码中，Map接口的`get`方法签名也是带有泛型信息的\n```\nV get(Object key);\n```\n对应的JVM字节码\n```\n35: invokeinterface #9,2    // InterfaceMethod java/util/Map.get:(Ljava/lang/Object;)Ljava/lang/Object;\n```\n在`get`操作中也是`没有任何泛型信息`，只是简单地处理为`java.lang.Object`，与`put`操作类似\n\n## checkFather(Father father)\nJava代码\n```\ncheckFather(map.get(father));\n```\n对应的字节码（排除`get`操作的字节码，前面已经提及过）\n```\n40: checkcast     #4        // class me/zhongmingmao/test/FakeGeneric$Father\n43: invokestatic  #10       // Method checkFather:(Lme/zhongmingmao/test/FakeGeneric$Father;)V\n```\n1. 非常值得注意的是在调用`checkFather`方法之前有一个**`checkcast`**指令，这就是将之前的`get`操作得到的对象进行**`强制转换`**，由`Object`转换成`Father`\n2. 那么JVM在执行`checkcast`的时候`怎么知道要转换成什么类型`呢？前面分析字节码操作都是没有附带任何泛型信息的\n3. 答案就是在字节码文件中的**`LocalVariableTypeTable`**属性，因为Java是`伪泛型`的，因此需要这么一个属性详细记录的泛型信息，才能进行强制转换\n\n\n# 伴随的问题\nJava的伪泛型会带来一些语法上的`尴尬`，例如重载\n```java\npublic static void method(List<String> list){\n}\n\npublic static void method(List<Integer> list){\n}\n```\n1. `List<String> list`与`List<Integer> list`在`Java语法层面`是`不同的参数类型`，应该`属于重载`\n2. `List<String> list`与`List<Integer> list`在`JVM层面`，会进行所谓的`类型擦除`（其实只是伪泛型的一层`伪装`），是`同一参数类型`，方法具有`相同的特征签名`（`signature`）\n\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- 方法重载 + 方法重写","url":"%2F2016%2F07%2F06%2Fjvm-overload-override%2F","content":"\n{% note info %}\n本文将从`JVM字节码`的角度解释`方法重载`与`方法重写`\n{% endnote %}\n\n<!-- more -->\n\n# 方法重载\n\n## 代码\n```java\npackage me.zhongmingmao.test;\n\npublic class StaticDispatch {\n    interface Human {\n    }\n\n    static class Man implements Human {\n    }\n\n    static class Woman implements Human {\n    }\n\n    public static void sayHello(Human human) {\n        System.out.println(\"Hello , I'm a human\");\n    }\n\n    public static void sayHello(Man man) {\n        System.out.println(\"Hello , I'm a man\");\n    }\n\n    public static void sayHello(Woman woman) {\n        System.out.println(\"Hello , I'm a woman\");\n    }\n\n    public static void main(String[] args) {\n        Human man = new Man();          // 静态类型是Human，实际类型是Man\n        Human woman = new Woman();      // 静态类型是Human，实际类型是Woman\n\n        sayHello(man);                  // 静态类型是Human，实际类型是Man\n        sayHello(woman);                // 静态类型是Human，实际类型是Woman\n        sayHello((Man) man);            // 静态类型是Man，实际类型是Man\n        sayHello((Woman) woman);        // 静态类型是Woman，实际类型是Woman\n    }\n}\n```\n\n## 运行结果\n```\nHello , I'm a human\nHello , I'm a human\nHello , I'm a man\nHello , I'm a woman\n```\n\n## 分析\n\n### 静态类型 VS 实际类型\n1. `静态类型`在`编译期`可知，`实际类型`需要到`运行期`才可确定\n2. 例如sayHello(Human human)，编译期只知道传进来的参数是Human类型的实例，但只有到了运行期才知道实际传进来的是Man类型实例还是Woman类型实例（或者其他Human实现类的实例）\n\n### 重载判定\n1. `编译期`在`重载`时是通过`参数的静态类型`而不是实际类型作为`判断依据`\n2. 因此在`编译期`会依据`参数的静态类型`来决定使用哪一个重载版本\n\n### 字节码\n```\n# javap -v\npublic static void main(java.lang.String[]);\n    descriptor: ([Ljava/lang/String;)V\n    flags: ACC_PUBLIC, ACC_STATIC\n    Code:\n        stack=2, locals=3, args_size=1\n            0: new           #7     // class me/zhongmingmao/test/StaticDispatch$Man\n            3: dup\n            4: invokespecial #8     // Method me/zhongmingmao/test/StaticDispatch$Man.\"<init>\":()V\n            7: astore_1\n            8: new           #9     // class me/zhongmingmao/test/StaticDispatch$Woman\n            11: dup\n            12: invokespecial #10   // Method me/zhongmingmao/test/StaticDispatch$Woman.\"<init>\":()V\n            15: astore_2\n            16: aload_1\n            17: invokestatic  #11   // Method sayHello:(Lme/zhongmingmao/test/StaticDispatch$Human;)V\n            20: aload_2\n            21: invokestatic  #11   // Method sayHello:(Lme/zhongmingmao/test/StaticDispatch$Human;)V\n            24: aload_1\n            25: checkcast     #7    // class me/zhongmingmao/test/StaticDispatch$Man\n            28: invokestatic  #12   // Method sayHello:(Lme/zhongmingmao/test/StaticDispatch$Man;)V\n            31: aload_2\n            32: checkcast     #9    // class me/zhongmingmao/test/StaticDispatch$Woman\n            35: invokestatic  #13   // Method sayHello:(Lme/zhongmingmao/test/StaticDispatch$Woman;)V\n            38: return\n        LocalVariableTable:\n            Start  Length  Slot  Name   Signature\n                0      39     0  args   [Ljava/lang/String;\n                8      31     1   man   Lme/zhongmingmao/test/StaticDispatch$Human;\n               16      23     2 woman   Lme/zhongmingmao/test/StaticDispatch$Human;\n```\n其中`4`个调用`sayHello方法`的`JVM字节码指令`\n```\n17: invokestatic  #11   // Method sayHello:(Lme/zhongmingmao/test/StaticDispatch$Human;)V\n21: invokestatic  #11   // Method sayHello:(Lme/zhongmingmao/test/StaticDispatch$Human;)V\n28: invokestatic  #12   // Method sayHello:(Lme/zhongmingmao/test/StaticDispatch$Man;)V\n35: invokestatic  #13   // Method sayHello:(Lme/zhongmingmao/test/StaticDispatch$Woman;)V\n```\n从字节码可以看出，在`编译期`，依据按照参数的静态类型已经`明确选择`了调用哪一个重载版本\n\n# 方法重写\n\n## 代码\n```java\npackage me.zhongmingmao.test;\n\npublic class DynamicDispatch {\n\n    interface Human {\n        default void sayHello() {\n            System.out.println(\"Hello , I'm a human\");\n        }\n    }\n\n    static class Man implements Human {\n        @Override\n        public void sayHello() {\n            System.out.println(\"Hello , I'm a man\");\n        }\n    }\n\n    static class Woman implements Human {\n        @Override\n        public void sayHello() {\n            System.out.println(\"Hello , I'm a woman\");\n        }\n    }\n\n    public static void main(String[] args) {\n        Human man = new Man();\n        Human woman = new Woman();\n\n        man.sayHello();\n        woman.sayHello();\n\n        man = new Woman();\n        man.sayHello();\n    }\n}\n```\n\n## 运行结果\n```\nHello , I'm a man\nHello , I'm a woman\nHello , I'm a woman\n```\n\n## 分析\n\n### 字节码\n```\npublic static void main(java.lang.String[]);\n    descriptor: ([Ljava/lang/String;)V\n    flags: ACC_PUBLIC, ACC_STATIC\n    Code:\n        stack=2, locals=3, args_size=1\n            0: new           #2         // class me/zhongmingmao/test/DynamicDispatch$Man\n            3: dup\n            4: invokespecial #3         // Method me/zhongmingmao/test/DynamicDispatch$Man.\"<init>\":()V\n            7: astore_1\n            8: new           #4         // class me/zhongmingmao/test/DynamicDispatch$Woman\n            11: dup\n            12: invokespecial #5        // Method me/zhongmingmao/test/DynamicDispatch$Woman.\"<init>\":()V\n            15: astore_2\n            16: aload_1\n            17: invokeinterface #6,  1  // InterfaceMethod me/zhongmingmao/test/DynamicDispatch$Human.sayHello:()V\n            22: aload_2\n            23: invokeinterface #6,  1  // InterfaceMethod me/zhongmingmao/test/DynamicDispatch$Human.sayHello:()V\n            28: new           #4        // class me/zhongmingmao/test/DynamicDispatch$Woman\n            31: dup\n            32: invokespecial #5        // Method me/zhongmingmao/test/DynamicDispatch$Woman.\"<init>\":()V\n            35: astore_1\n            36: aload_1\n            37: invokeinterface #6,  1  // InterfaceMethod me/zhongmingmao/test/DynamicDispatch$Human.sayHello:()V\n            42: return\n        LocalVariableTable:\n            Start  Length  Slot  Name   Signature\n                0      43     0  args   [Ljava/lang/String;\n                8      35     1   man   Lme/zhongmingmao/test/DynamicDispatch$Human;\n               16      27     2 woman   Lme/zhongmingmao/test/DynamicDispatch$Human;\n```\n关于字节码的执行过程请参考博文「字节码 - JVM字节码执行过程」，下面仅做简略说明\n\n#### 创建对象\n\n指令`0`、`3`、`4`、`7`的主要作用是`创建并初始化`一个Man实例，并存入`局部变量表中偏移为1的slot`中（指令`8`、`11`、`12`、`15`作用类似）\n\n1. `0: new` ：为Man类型`分配内存`，并将引入`压入操作数栈`\n2. `3: dup` ：`复制栈顶元素`（即刚刚创建的Man引用），**`再次入栈`**，此时栈有`2个一样的Man引用`，主要是为了后面有`2个出栈操作`\n3. `4: invokespecial` ：`弹出栈顶元素`，即Man引用，调用`<init>`方法（即JVM为我们生成的**`合成构造器`**方法）\n4. `7: astore_1` ：`弹出栈顶元素`，同样也是Man引用，并将其存入`局部变量表中偏移为1的slot`中\n5. `15: astore_2` ：这条指令执行完以后，局部变量表中`偏移为1的slot`中存储的是`man实例的引用`，`偏移为2的slot`中存储的是`woman实例的引用`\n\n#### 多态查找\n这里仅分析第一个`man.sayHello();`，其他的都是类似的原理\n1. `16: aload_1` ： 将局部变量表中`偏移为1的slot`中的值`压入到操作数栈`中，此时`栈顶元素`为`man实例的引用`\n2. `17: invokeinterface` ：弹出栈顶元素，并调用接口方法（中间还有校验等步骤，这里忽略），即调用`Man类型的实现`\n\n`JVM字节码指令的执行`伴随着`操作数栈的出栈和入栈操作`，`多态调用`也是在`运行期`才能确定调用的是哪一个重写版本\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- JVM字节码执行过程","url":"%2F2016%2F07%2F05%2Fjvm-bytecode-execution%2F","content":"\n{% note info %}\n本文将通过是实例简单介绍`JVM字节码`基于`栈`的执行过程\n{% endnote %}\n\n<!-- more -->\n# Stack Frame\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/stack_frame.png\" width=\"500\">\n\n1. 一个方法`从调用到执行完成`，对应着一个栈帧（`Stack Frame`）在虚拟机栈（`VM Stack`）里面`从入栈到出栈`的过程\n2. 在`编译`成`字节码`期间，栈帧需要多大的局部变量表（`Local Variable Table`），多深的操作数栈（`Operand Stack`）都已经完全确定，并且写入到`方法表的Code`属性中\n3. 在`活动线程`中，只有位于`栈顶的栈帧`才是有效的，称为`当前栈帧`，与这个栈帧关联的方法称为`当前方法`\n4. 局部变量表\n    - 用于存放`方法参数`和`方法内部定义的局部变量`\n    - 方法表中的`locals`属性记录了`局部变量表的最大容量`\n    - 局部变量表的存储单元为`32-bit的slot`，`boolean`、`byte`、`char`、`short`、`int`、`float`等会占用一个`slot`，`long`和`double`会占用两个`slot`\n    - 如果执行的是`实例方法`，那么`第0个slot`默认存储`this`\n    - 为了`节省栈帧空间`，`slot是可重用`的\n5. 操作数栈\n    - 方法表中的`stack`属性记录了`操作数栈的最大深度`\n    - 操作数栈可以容纳任意的`Java`数据类型，`32-bit`数据类型所占用的栈容量为`1`，`64-bit`数据类型所以占用的栈容量为`2`\n\n# 代码\n```java\npackage me.zhongmingmao.test;\npublic class BytecodeExecution {\n    public int calc() {\n        int a = 100;\n        int b = 200;\n        int c = 300;\n        return (a + b) * c;\n    }\n}\n```\n\n# 字节码\n```\n# javap -v\npublic int calc();\n    descriptor: ()I\n    flags: ACC_PUBLIC\n    Code:\n        stack=2, locals=4, args_size=1\n            0: bipush        100\n            2: istore_1\n            3: sipush        200\n            6: istore_2\n            7: sipush        300\n            10: istore_3\n            11: iload_1\n            12: iload_2\n            13: iadd\n            14: iload_3\n            15: imul\n            16: ireturn\n        LocalVariableTable:\n            Start  Length  Slot  Name   Signature\n                0      17     0  this   Lme/zhongmingmao/test/BytecodeExecution;\n                3      14     1     a   I\n                7      10     2     b   I\n               11       6     3     c   I\n```\n\n1. `stack=2`，这个在分析下面`16个JVM字节码指令`的运行过程后就能验证这是正确的，从`Java源代码`是无法直观的得出这个值\n2. `locals=4`，从`Java源代码`可以看出，`calc()`只定义了`a`、`b`、`c`三个局部变量，而`calc()`又是`实例方法`，局部变量表`第1个slot`默认会有记录`this`，因此能得出`locals=4`（在这里slot没有进行复用）\n3. 在`JVM字节码`中的`LocalVariableTable`属性，很清晰表述了`局部变量表`的布局，其中需要注意的是`Start`指的是局部变量`生命周期开始的字节码偏移量`，`Length`指的是`作用范围覆盖的长度`，而并非变量本身的长度\n4. `args_size=1`，`实例方法`默认会传入`this`，因此`args_size=1`\n\n# 执行过程\n\n## bipush 100\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/bytecode_execution_1.png\" width=\"500\">\n\n## istore_1\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/bytecode_execution_2.png\" width=\"500\">\n\n## iload_1\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/bytecode_execution_3_1.png\" width=\"500\">\n\n## iload_2\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/bytecode_execution_4.png\" width=\"500\">\n\n## iadd\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/bytecode_execution_5.png\" width=\"500\">\n\n## iload_3\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/bytecode_execution_6.png\" width=\"500\">\n\n## imul\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/bytecode_execution_7.png\" width=\"500\">\n\n## ireturn\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/bytecode_execution_8.png\" width=\"500\">\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- JOL使用教程 3","url":"%2F2016%2F07%2F03%2Fjvm-jol-tutorial-3%2F","content":"\n{% note info %}\n本文将通过`JOL`分析`Java对象的内存布局`，包括`伪共享`、`DataModel`、`Externals`、`数组对齐`等内容\n代码托管在[https://github.com/zhongmingmao/java_object_layout](https://github.com/zhongmingmao/java_object_layout)\n{% endnote %}\n\n<!-- more -->\n\n# 伪共享\n`Java8`引入`@sun.misc.Contended`注解，自动进行`缓存行填充`，`原始支持`解决`伪共享问题`，实现高效并发，关于`伪共享`，网上已经很多资料，请参考下列连接：\n1. https://yq.aliyun.com/articles/62865\n2. http://www.cnblogs.com/Binhua-Liu/p/5620339.html\n3. http://blog.csdn.net/zero__007/article/details/54951584\n4. http://blog.csdn.net/aigoogle/article/details/41517213\n5. http://hg.openjdk.java.net/jdk8u/jdk8u/jdk/file/tip/src/share/classes/sun/misc/Contended.java\n\n## 代码\n```java\n// JVM Args : -Djol.tryWithSudo=true  -XX:-RestrictContended\npublic class JOLSample_09_Contended {\n\n    public static void main(String[] args) throws Exception {\n        out.println(VM.current().details());\n        out.println(ClassLayout.parseClass(A.class).toPrintable());\n    }\n\n    @sun.misc.Contended\n    public static class A {\n        int a;\n    }\n}\n```\n\n## 运行结果\n```\n# Running 64-bit HotSpot VM.\n# Using compressed oop with 3-bit shift.\n# Using compressed klass with 3-bit shift.\n# Objects are 8 bytes aligned.\n# Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n# Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n\nme.zhongmingmao.jol.JOLSample_09_Contended$A object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0    12        (object header)                           N/A\n     12   128        (alignment/padding gap)\n    140     4    int A.a                                       N/A\nInstance size: 144 bytes\nSpace losses: 128 bytes internal + 0 bytes external = 128 bytes total\n```\n\n## 分析\n1. 本机CPU采用的`Intel I5 Broadwell`，`Cache Line Size`为`64 Bytes`，相关链接[Broadwell](https://en.wikichip.org/wiki/intel/microarchitectures/broadwell#Memory_Hierarchy)\n2. 在对象头部后插入了`128 Bytes`的`Padding`，这样保证了`同一缓存行`中，不可能同时容纳`2`个`JOLSample_09_Contended$A`实例，避免了`伪共享`的问题\n3. `@Contended`注解的相关概念请查看代码[Contended.java](http://hg.openjdk.java.net/jdk8u/jdk8u/jdk/file/tip/src/share/classes/sun/misc/Contended.java)\n\n## 性能对比代码\n```java\n// JVM Args : -Djol.tryWithSudo=true  -XX:-RestrictContended\npublic class FalseSharingTest {\n\n    public final static int THREAD_COUNT = 4;\n\n    @Ignore(\"take too long\")\n    @Test\n    public void falseSharingTest() throws InterruptedException {\n        long commonDuration = duration(CommonLong.class); // 29.189s\n        long contendedDuration = duration(ContendedLong.class); // 11.047s\n        assertTrue(commonDuration / (contendedDuration + 0.0) > 1); // 29.189/11.047 ≈ 2.64，性能提升很明显\n    }\n\n    private long duration(Class<? extends VolatileLong> clazz) throws InterruptedException {\n        out.println(ClassLayout.parseClass(clazz).toPrintable());\n        VolatileLong[] longs = new VolatileLong[THREAD_COUNT];\n        IntStream.range(0, longs.length).forEach(value -> {\n            try {\n                longs[value] = clazz.newInstance();\n            } catch (InstantiationException | IllegalAccessException e) {\n                e.printStackTrace();\n            }\n        });\n\n        ExecutorService pool = Executors.newFixedThreadPool(THREAD_COUNT);\n        IntStream.range(0, THREAD_COUNT).forEach(value -> pool.submit(new Task(value, longs)));\n        pool.shutdown();\n        LocalDateTime start = LocalDateTime.now();\n        while (!pool.awaitTermination(100, TimeUnit.MILLISECONDS)) {\n        }\n        Duration duration = Duration.between(start, LocalDateTime.now());\n        out.println(String.format(\"%s , duration : %s\\n\", clazz.getSimpleName(), duration));\n        return duration.toNanos();\n    }\n\n\n    @AllArgsConstructor\n    private class Task implements Runnable {\n        public static final long ITERATIONS = 500L * 1000L * 1000L;\n        private final int index;\n        private final VolatileLong[] longs;\n\n        @Override\n        public void run() {\n            LongStream.range(0, ITERATIONS).forEach(longs[index]::setValue);\n        }\n    }\n\n    private interface VolatileLong {\n        void setValue(long value);\n    }\n\n    @Data\n    private static class CommonLong implements VolatileLong {\n        public volatile long value = 0L; // 暴露因缓存行而导致的伪共享问题\n    }\n\n    @Data\n    @sun.misc.Contended\n    private static class ContendedLong implements VolatileLong {\n        public volatile long value = 0L;\n    }\n}\n```\n## 性能对比结果\n```\nme.zhongmingmao.jol.FalseSharingTest$CommonLong object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0    12        (object header)                           N/A\n     12     4        (alignment/padding gap)\n     16     8   long CommonLong.value                          N/A\nInstance size: 24 bytes\nSpace losses: 4 bytes internal + 0 bytes external = 4 bytes total\n\nCommonLong , duration : PT29.189S\n\nme.zhongmingmao.jol.FalseSharingTest$ContendedLong object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0    12        (object header)                           N/A\n     12   132        (alignment/padding gap)\n    144     8   long ContendedLong.value                       N/A\nInstance size: 152 bytes\nSpace losses: 132 bytes internal + 0 bytes external = 132 bytes total\n\nContendedLong , duration : PT11.047S\n```\n\n# DataModel\n\n## 代码\n```java\n// JVM Args : -Djol.tryWithSudo=true\npublic class JOLSample_10_DataModels {\n\n    public static void main(String[] args) throws Exception {\n        Layouter layouter;\n\n        layouter = new CurrentLayouter();\n        System.out.println(\"***** \" + layouter);\n        System.out.println(ClassLayout.parseClass(A.class, layouter).toPrintable());\n\n        layouter = new HotSpotLayouter(new X86_32_DataModel());\n        System.out.println(\"***** \" + layouter);\n        System.out.println(ClassLayout.parseClass(A.class, layouter).toPrintable());\n\n        layouter = new HotSpotLayouter(new X86_64_DataModel());\n        System.out.println(\"***** \" + layouter);\n        System.out.println(ClassLayout.parseClass(A.class, layouter).toPrintable());\n\n        layouter = new HotSpotLayouter(new X86_64_COOPS_DataModel());\n        System.out.println(\"***** \" + layouter);\n        System.out.println(ClassLayout.parseClass(A.class, layouter).toPrintable());\n    }\n\n    public static class A {\n        Object a;\n        Object b;\n    }\n}\n```\n\n## 运行结果\n```\n***** Current VM Layout\nme.zhongmingmao.jol.JOLSample_10_DataModels$A object internals:\n OFFSET  SIZE               TYPE DESCRIPTION                               VALUE\n      0    12                    (object header)                           N/A\n     12     4   java.lang.Object A.a                                       N/A\n     16     4   java.lang.Object A.b                                       N/A\n     20     4                    (loss due to the next object alignment)\nInstance size: 24 bytes\nSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total\n\n***** VM Layout Simulation (X32 model, 8-byte aligned, compact fields, field allocation style: 1)\nme.zhongmingmao.jol.JOLSample_10_DataModels$A object internals:\n OFFSET  SIZE               TYPE DESCRIPTION                               VALUE\n      0     8                    (object header)                           N/A\n      8     4   java.lang.Object A.a                                       N/A\n     12     4   java.lang.Object A.b                                       N/A\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 0 bytes external = 0 bytes total\n\n***** VM Layout Simulation (X64 model, 8-byte aligned, compact fields, field allocation style: 1)\nme.zhongmingmao.jol.JOLSample_10_DataModels$A object internals:\n OFFSET  SIZE               TYPE DESCRIPTION                               VALUE\n      0    16                    (object header)                           N/A\n     16     8   java.lang.Object A.a                                       N/A\n     24     8   java.lang.Object A.b                                       N/A\nInstance size: 32 bytes\nSpace losses: 0 bytes internal + 0 bytes external = 0 bytes total\n\n***** VM Layout Simulation (X64 model (compressed oops), 8-byte aligned, compact fields, field allocation style: 1)\nme.zhongmingmao.jol.JOLSample_10_DataModels$A object internals:\n OFFSET  SIZE               TYPE DESCRIPTION                               VALUE\n      0    12                    (object header)                           N/A\n     12     4   java.lang.Object A.a                                       N/A\n     16     4   java.lang.Object A.b                                       N/A\n     20     4                    (loss due to the next object alignment)\nInstance size: 24 bytes\nSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total\n```\n\n## 分析\n1. `CurrentLayouter`是`真实`的内存布局，`HotSpotLayouter`是`模拟`的内存布局\n2. 通过`parseInstance(Object instance, Layouter layouter)`能够观察在不同`DataModel`下`synchronized锁升级`的过程\n\n# Externals\n之前显示的都是`internals size`（即`shallow size`），这里展示`externals size`（`retained size`=`internals size`+`externals size`）\n\n## 代码\n```java\n// JVM Args : -Djol.tryWithSudo=true\npublic class JOLSample_16_AL_LL {\n\n    public static void main(String[] args) throws Exception {\n        out.println(VM.current().details());\n        PrintWriter pw = new PrintWriter(out);\n\n        int objectCount = 4;\n        Object[] objects = new Object[objectCount];\n        for (int i = 0; i < objectCount; i++) {\n            if (new Random().nextInt() % 2 == 0) {\n                objects[i] = new A(i);\n            } else {\n                objects[i] = new B(i);\n            }\n        }\n\n        pw.println(GraphLayout.parseInstance(objects).toFootprint());\n        pw.close();\n    }\n\n    @AllArgsConstructor\n    public static class A {\n        int a;\n    }\n\n    @AllArgsConstructor\n    public static class B {\n        long b;\n    }\n}\n```\n\n## 运行结果\n```\nme.zhongmingmao.jol.JOLSample_16_AL_LL$A@7de26db8d, me.zhongmingmao.jol.JOLSample_16_AL_LL$B@1175e2dbd, me.zhongmingmao.jol.JOLSample_16_AL_LL$B@36aa7bc2d, me.zhongmingmao.jol.JOLSample_16_AL_LL$B@76ccd017d footprint:\n     COUNT       AVG       SUM   DESCRIPTION\n         1        16        16   me.zhongmingmao.jol.JOLSample_16_AL_LL$A\n         3        24        72   me.zhongmingmao.jol.JOLSample_16_AL_LL$B\n         4                  88   (total)\n```\n\n## 分析\n遍历数组`objects`相连的外部对象，并做了统计\n\n# 数组对齐\n\n## 代码\n```java\n// JVM Args : -Djol.tryWithSudo=true\npublic class JOLSample_26_ArrayAlignment {\n\n    public static void main(String[] args) throws Exception {\n        out.println(VM.current().details());\n        out.println(ClassLayout.parseInstance(new short[0]).toPrintable());\n        for (int size = 1; size <= 5; size += 2) {\n            out.println(ClassLayout.parseInstance(new short[size]).toPrintable());\n        }\n    }\n}\n```\n\n## 运行结果\n```\n# Running 64-bit HotSpot VM.\n# Using compressed oop with 3-bit shift.\n# Using compressed klass with 3-bit shift.\n# Objects are 8 bytes aligned.\n# Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n# Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n\n[S object internals:\n OFFSET  SIZE    TYPE DESCRIPTION                               VALUE\n      0     4         (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)\n      4     4         (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)\n      8     4         (object header)                           31 01 00 f8 (00110001 00000001 00000000 11111000) (-134217423)\n     12     4         (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)\n     16     0   short [S.<elements>                             N/A\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 0 bytes external = 0 bytes total\n\n[S object internals:\n OFFSET  SIZE    TYPE DESCRIPTION                               VALUE\n      0     4         (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)\n      4     4         (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)\n      8     4         (object header)                           31 01 00 f8 (00110001 00000001 00000000 11111000) (-134217423)\n     12     4         (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)\n     16     2   short [S.<elements>                             N/A\n     18     6         (loss due to the next object alignment)\nInstance size: 24 bytes\nSpace losses: 0 bytes internal + 6 bytes external = 6 bytes total\n\n[S object internals:\n OFFSET  SIZE    TYPE DESCRIPTION                               VALUE\n      0     4         (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)\n      4     4         (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)\n      8     4         (object header)                           31 01 00 f8 (00110001 00000001 00000000 11111000) (-134217423)\n     12     4         (object header)                           03 00 00 00 (00000011 00000000 00000000 00000000) (3)\n     16     6   short [S.<elements>                             N/A\n     22     2         (loss due to the next object alignment)\nInstance size: 24 bytes\nSpace losses: 0 bytes internal + 2 bytes external = 2 bytes total\n\n[S object internals:\n OFFSET  SIZE    TYPE DESCRIPTION                               VALUE\n      0     4         (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)\n      4     4         (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)\n      8     4         (object header)                           31 01 00 f8 (00110001 00000001 00000000 11111000) (-134217423)\n     12     4         (object header)                           05 00 00 00 (00000101 00000000 00000000 00000000) (5)\n     16    10   short [S.<elements>                             N/A\n     26     6         (loss due to the next object alignment)\nInstance size: 32 bytes\nSpace losses: 0 bytes internal + 6 bytes external = 6 bytes total\n```\n\n## 对象布局\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/jol_arrayAlignment.png\" width=\"500\">\n\n## 分析\n`数组对齐`与前面`字节对齐`的例子类似，在`64-bit Hotspot JVM`按`8 Bytes`对齐\n\n\n<!-- indicate-the-source -->\n","tags":["JOL"],"categories":["Baisc"]},{"title":"JVM基础 -- JOL使用教程 2","url":"%2F2016%2F07%2F02%2Fjvm-jol-tutorial-2%2F","content":"\n{% note info %}\n本文将通过`JOL`分析`Java对象的内存布局`，包括`Throwable`、`Class`、`Object Header`、`HashCode`等内容\n代码托管在[https://github.com/zhongmingmao/java_object_layout](https://github.com/zhongmingmao/java_object_layout)\n{% endnote %}\n\n<!-- more -->\n\n# Throwable\n\n## 代码\n```java\n// JVM Args : -Djol.tryWithSudo=true\npublic class JOLSample_07_Exceptions {\n\n    public static void main(String[] args) throws Exception {\n        out.println(VM.current().details());\n        out.println(ClassLayout.parseClass(Throwable.class).toPrintable());\n    }\n}\n```\n\n## 运行结果\n```\n# Running 64-bit HotSpot VM.\n# Using compressed oop with 3-bit shift.\n# Using compressed klass with 3-bit shift.\n# Objects are 8 bytes aligned.\n# Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n# Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n\njava.lang.Throwable object internals:\n OFFSET  SIZE                            TYPE DESCRIPTION                               VALUE\n      0    12                                 (object header)                           N/A\n     12     4                                 (alignment/padding gap)\n     16     4                java.lang.String Throwable.detailMessage                   N/A\n     20     4             java.lang.Throwable Throwable.cause                           N/A\n     24     4   java.lang.StackTraceElement[] Throwable.stackTrace                      N/A\n     28     4                  java.util.List Throwable.suppressedExceptions            N/A\nInstance size: 32 bytes\nSpace losses: 4 bytes internal + 0 bytes external = 4 bytes total\n```\n\n## 分析\n1. 在内存中并没有为`Throwable.backtrace`分配空间，这是因为这个实例域用于处理`虚拟机的内部信息`（`VM internal info`），因此**`在任何条件下都不允许用户访问`**\n2. 下面尝试用`反射`的机制访问`Throwable.backtrace`\n\n## 反射测试代码\n```java\n@Test(expected = NoSuchFieldException.class)\npublic void backtraceTest() throws NoSuchFieldException {\n   try {\n       new Throwable().getClass().getDeclaredField(\"backtrace\");\n   } catch (NoSuchFieldException e) {\n       System.err.println(String.format(\"无法通过反射获得Throwable的backtrace实例域 ，%s\", e));\n       throw e;\n   }\n}\n```\n在尝试通过`反射`获取`Throwable的backtrace实例域`时，会抛出`NoSuchFieldException`\n\n# Class\n\n## 代码\n```java\n// JVM Args : -Djol.tryWithSudo=true\npublic class JOLSample_08_Class {\n\n    public static void main(String[] args) throws Exception {\n        out.println(VM.current().details());\n        out.println(ClassLayout.parseClass(Class.class).toPrintable());\n    }\n}\n```\n\n## 运行结果\n```\n# Running 64-bit HotSpot VM.\n# Using compressed oop with 3-bit shift.\n# Using compressed klass with 3-bit shift.\n# Objects are 8 bytes aligned.\n# Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n# Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n\njava.lang.Class object internals:\n OFFSET  SIZE                                              TYPE DESCRIPTION                               VALUE\n      0    12                                                   (object header)                           N/A\n     12     4                     java.lang.reflect.Constructor Class.cachedConstructor                   N/A\n     16     4                                   java.lang.Class Class.newInstanceCallerCache              N/A\n     20     4                                  java.lang.String Class.name                                N/A\n     24     4                                                   (alignment/padding gap)\n     28     4                       java.lang.ref.SoftReference Class.reflectionData                      N/A\n     32     4   sun.reflect.generics.repository.ClassRepository Class.genericInfo                         N/A\n     36     4                                java.lang.Object[] Class.enumConstants                       N/A\n     40     4                                     java.util.Map Class.enumConstantDirectory               N/A\n     44     4                    java.lang.Class.AnnotationData Class.annotationData                      N/A\n     48     4             sun.reflect.annotation.AnnotationType Class.annotationType                      N/A\n     52     4                java.lang.ClassValue.ClassValueMap Class.classValueMap                       N/A\n     56    32                                                   (alignment/padding gap)\n     88     4                                               int Class.classRedefinedCount                 N/A\n     92     4                                                   (loss due to the next object alignment)\nInstance size: 96 bytes\nSpace losses: 36 bytes internal + 4 bytes external = 40 bytes total\n```\n\n## 分析\n1. 在`56`的位置开始有`32 Bytes`的的内存空间，`JVM`会向该内存区域注入`元数据`（`meta-information`），相关内容请看下来`CPP`代码，暂未弄懂其中原理\n2. http://hg.openjdk.java.net/jdk8/jdk8/hotspot/file/tip/src/share/vm/classfile/javaClasses.hpp\n3. http://hg.openjdk.java.net/jdk8/jdk8/hotspot/file/tip/src/share/vm/classfile/javaClasses.cpp\n\n# Object Header\n\n## 代码\n```java\n// JVM Args : -Djol.tryWithSudo=true\npublic class JOLSample_11_ClassWord {\n\n    public static void main(String[] args) throws Exception {\n        out.println(VM.current().details());\n        out.println(ClassLayout.parseInstance(new A()).toPrintable());\n        out.println(ClassLayout.parseInstance(new B()).toPrintable());\n    }\n\n    public static class A {\n        // no fields\n    }\n\n    public static class B {\n        // no fields\n    }\n}\n```\n\n## 运行结果\n```\n# Running 64-bit HotSpot VM.\n# Using compressed oop with 3-bit shift.\n# Using compressed klass with 3-bit shift.\n# Objects are 8 bytes aligned.\n# Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n# Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n\nme.zhongmingmao.jol.JOLSample_11_ClassWord$A object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)\n      4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)\n      8     4        (object header)                           a2 f0 00 f8 (10100010 11110000 00000000 11111000) (-134156126)\n     12     4        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total\n\nme.zhongmingmao.jol.JOLSample_11_ClassWord$B object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)\n      4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)\n      8     4        (object header)                           32 f2 00 f8 (00110010 11110010 00000000 11111000) (-134155726)\n     12     4        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total\n```\n\n## 分析\n1. 在`Hotspot JVM`中，对象头（Object Header）由两部分组成`Mark Word`和`Class Word`（即「对象内存布局 - Instrumentation + sa-jdi 实例分析」中的`Klass Ref`）\n2. 上述运行结果将对象头的值都打印出来了，方便进行更详细地分析，因为`hashCode`和`锁信息`都存储在`Mark Word`中\n\n# HashCode\n\n## 代码\n```java\n// JVM Args : -Djol.tryWithSudo=true\npublic class JOLSample_15_IdentityHashCode {\n\n    public static void main(String[] args) throws Exception {\n        out.println(VM.current().details());\n\n        final A a = new A();\n\n        ClassLayout layout = ClassLayout.parseInstance(a);\n\n        out.println(\"**** Fresh object\");\n        out.println(layout.toPrintable());\n\n        out.println(\"hashCode: \" + Integer.toHexString(a.hashCode()));\n        out.println();\n\n        out.println(\"**** After identityHashCode()\");\n        out.println(layout.toPrintable());\n    }\n\n    public static class A {\n        // no fields\n    }\n}\n```\n\n## 运行结果\n```\n# Running 64-bit HotSpot VM.\n# Using compressed oop with 3-bit shift.\n# Using compressed klass with 3-bit shift.\n# Objects are 8 bytes aligned.\n# Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n# Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n\n**** Fresh object\nme.zhongmingmao.jol.JOLSample_15_IdentityHashCode$A object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)\n      4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)\n      8     4        (object header)                           a2 f0 00 f8 (10100010 11110000 00000000 11111000) (-134156126)\n     12     4        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total\n\nhashCode: 36aa7bc2\n\n**** After identityHashCode()\nme.zhongmingmao.jol.JOLSample_15_IdentityHashCode$A object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0     4        (object header)                           01 c2 7b aa (00000001 11000010 01111011 10101010) (-1434729983)\n      4     4        (object header)                           36 00 00 00 (00110110 00000000 00000000 00000000) (54)\n      8     4        (object header)                           a2 f0 00 f8 (10100010 11110000 00000000 11111000) (-134156126)\n     12     4        (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total\n```\n\n## 分析\n1. 对象尚未调用`hashCode()`之前，`Mark Word`对应的`hash`全为为`0`\n2. 对象尚调用`hashCode()`之后，计算得到的`hash`记录在`Mark Word`中（`08~39`），（Intel是`小端序`，低字节存储在低地址）\n3. `Mark Word`的格式请参考[markOop.hpp](http://hg.openjdk.java.net/jdk8/jdk8/hotspot/file/87ee5ee27509/src/share/vm/oops/markOop.hpp)\n\n## 手动计算HashCode\n```java\n@Test\npublic void haseCodeTest() throws NoSuchFieldException, IllegalAccessException {\n   ClassLayout layout = ClassLayout.parseClass(Object.class);\n   Object object = new Object();\n   // 未调用hashCode()，Mark Word没有相应的值\n   System.out.println(layout.toPrintable(object));\n\n   String realHashCode = Integer.toHexString(object.hashCode());\n   System.out.println(String.format(\"realHashCode : 0x%s\\n\", realHashCode));\n   // 确认HashCode已经添加到Mark Word中\n   System.out.println(layout.toPrintable(object));\n\n   // 手动计算HashCode\n   Field field = Unsafe.class.getDeclaredField(\"theUnsafe\");\n   field.setAccessible(true);\n   Unsafe unsafe = (Unsafe) field.get(null);\n   long hashCode = 0;\n   for (long index = 7; index > 0; index--) {\n       // 取Mark Word中的每一个Byte进行计算\n       hashCode |= (unsafe.getByte(object, index) & 0xFF) << ((index - 1) * 8);\n   }\n   String manualHashCode = Long.toHexString(hashCode);\n   System.out.println(String.format(\"manualHashCode : 0x%s\", manualHashCode));\n   assertEquals(realHashCode, manualHashCode);\n}\n```\n在`Hotspot JVM`计算对象的`HashCode`后，通过`Mark Word`可以手动计算`HashCode`，如果哪位大神知道个中原理，麻烦不吝赐教\n\n<!-- indicate-the-source -->\n","tags":["JOL"],"categories":["Baisc"]},{"title":"JVM基础 -- JOL使用教程 1","url":"%2F2016%2F07%2F01%2Fjvm-jol-tutorial-1%2F","content":"\n{% note info %}\n本文将通过`JOL`分析`Java对象的内存布局`，包括`基本使用`、`字节对齐`、`实例域重排序`、`继承`、`继承栅栏`、`继承对齐`等内容\n代码托管在[https://github.com/zhongmingmao/java_object_layout](https://github.com/zhongmingmao/java_object_layout)\n{% endnote %}\n\n<!-- more -->\n\n# Maven依赖\n```xml\n<dependency>\n  <groupId>org.openjdk.jol</groupId>\n  <artifactId>jol-core</artifactId>\n  <version>0.8</version>\n</dependency>\n```\n\n# 基本使用\n\n## 代码\n```java\n// JVM Args : -Djol.tryWithSudo=true\npublic class JOLSample_01_Basic {\n\n    public static void main(String[] args) throws Exception {\n        out.println(VM.current().details());\n        out.println(ClassLayout.parseClass(A.class).toPrintable());\n    }\n\n    public static class A {\n        boolean f;\n    }\n}\n```\n\n## 运行结果\n```\n# Running 64-bit HotSpot VM.\n# Using compressed oop with 3-bit shift.\n# Using compressed klass with 3-bit shift.\n# Objects are 8 bytes aligned.\n# Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n# Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n\nme.zhongmingmao.jol.JOLSample_01_Basic$A object internals:\n OFFSET  SIZE      TYPE DESCRIPTION                               VALUE\n      0    12           (object header)                           N/A\n     12     1   boolean A.f                                       N/A\n     13     3           (loss due to the next object alignment)\nInstance size: 16 bytes\nSpace losses: 0 bytes internal + 3 bytes external = 3 bytes total\n```\n\n## 对象布局\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/jol_basic_1.png\" width=\"500\">\n\n## 分析\n1. `64-bit HotSpot JVM`默认开启`指针压缩`，`Mark Word`占用`8 Bytes`，`Klass Ref`占用`4 Bytes`，`对象头`总共占据了`12 Bytes`（如果是`数组对象`，对象头还会包括`4 Bytes`的`Array Length`，总共占据`16 Bytes`）\n2. `64-bit HotSpot JVM`是`8 Bytes对齐`，因此有`3 Byte`的字节填充（`Padding`）\n\n# 字节对齐\n\n## 代码\n```java\n// JVM Args : -Djol.tryWithSudo=true\npublic class JOLSample_02_Alignment {\n\n    public static void main(String[] args) throws Exception {\n        out.println(VM.current().details());\n        out.println(ClassLayout.parseClass(A.class).toPrintable());\n    }\n\n    public static class A {\n        long f;\n    }\n}\n```\n\n## 运行结果\n```\n# Running 64-bit HotSpot VM.\n# Using compressed oop with 3-bit shift.\n# Using compressed klass with 3-bit shift.\n# Objects are 8 bytes aligned.\n# Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n# Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n\nme.zhongmingmao.jol.JOLSample_02_Alignment$A object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0    12        (object header)                           N/A\n     12     4        (alignment/padding gap)\n     16     8   long A.f                                       N/A\nInstance size: 24 bytes\nSpace losses: 4 bytes internal + 0 bytes external = 4 bytes total\n```\n\n## 对象布局\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/jol_alignment.png\" width=\"500\">\n\n## 分析\n1. `a.f`是`long类型`，占用`8 Bytes`，由于`8 Bytes字节对齐`的限制，无法放入`12~15`的位置，因此`12~15`只能是`Padding`\n2. `a.f`顺延到`16~23`的位置\n\n# 实例域重排序\n\n## 代码\n```java\n// JVM Args : -Djol.tryWithSudo=true\npublic class JOLSample_03_Packing {\n\n    public static void main(String[] args) throws Exception {\n        out.println(VM.current().details());\n        out.println(ClassLayout.parseClass(A.class).toPrintable());\n    }\n\n    public static class A {\n        boolean bo1, bo2;\n        byte b1, b2;\n        char c1, c2;\n        double d1, d2;\n        float f1, f2;\n        int i1, i2;\n        long l1, l2;\n        short s1, s2;\n    }\n}\n```\n\n## 运行结果\n```\n# Running 64-bit HotSpot VM.\n# Using compressed oop with 3-bit shift.\n# Using compressed klass with 3-bit shift.\n# Objects are 8 bytes aligned.\n# Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n# Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n\nme.zhongmingmao.jol.JOLSample_03_Packing$A object internals:\n OFFSET  SIZE      TYPE DESCRIPTION                               VALUE\n      0    12           (object header)                           N/A\n     12     4     float A.f1                                      N/A\n     16     8    double A.d1                                      N/A\n     24     8    double A.d2                                      N/A\n     32     8      long A.l1                                      N/A\n     40     8      long A.l2                                      N/A\n     48     4     float A.f2                                      N/A\n     52     4       int A.i1                                      N/A\n     56     4       int A.i2                                      N/A\n     60     2      char A.c1                                      N/A\n     62     2      char A.c2                                      N/A\n     64     2     short A.s1                                      N/A\n     66     2     short A.s2                                      N/A\n     68     1   boolean A.bo1                                     N/A\n     69     1   boolean A.bo2                                     N/A\n     70     1      byte A.b1                                      N/A\n     71     1      byte A.b2                                      N/A\nInstance size: 72 bytes\nSpace losses: 0 bytes internal + 0 bytes external = 0 bytes total\n```\n\n## 对象布局\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/jol_packing.png\" width=\"500\">\n\n## 分析\n1. 「对象内存布局 - Instrumentation + sa-jdi 实例分析」也存在类似的实例\n2. `实例域重排序`是为了让`内存更紧凑`\n3. 重排序规则：按照`域占用空间大小来倒排`，`8->4->2->1`，即`double/long`->`int/float`->`short/char`->`boolean/byte`->`reference`\n4. 如果间隙能容纳`占用空间更小的实例域`，则将该间隙分配给该实例域，因此`A.f1`会排在了`A.d1`前面\n5. 由上面左右图对比可知，进行了实例域重排序后，节省了`8 Bytes`的内存空间\n6. 由于实例域重排序，也导致了实例域在`内存中的顺序`和`声明的顺序`往往是`不一致`的\n\n# 继承\n\n## 代码\n```java\n// JVM Args : -Djol.tryWithSudo=true\npublic class JOLSample_04_Inheritance {\n\n    public static void main(String[] args) throws Exception {\n        out.println(VM.current().details());\n        out.println(ClassLayout.parseClass(C.class).toPrintable());\n    }\n\n    public static class A {\n        int a;\n    }\n\n    public static class B extends A {\n        int b;\n    }\n\n    public static class C extends B {\n        int c;\n    }\n}\n```\n\n## 运行结果\n```\n# Running 64-bit HotSpot VM.\n# Using compressed oop with 3-bit shift.\n# Using compressed klass with 3-bit shift.\n# Objects are 8 bytes aligned.\n# Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n# Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n\nme.zhongmingmao.jol.JOLSample_04_Inheritance$C object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0    12        (object header)                           N/A\n     12     4    int A.a                                       N/A\n     16     4    int B.b                                       N/A\n     20     4    int C.c                                       N/A\nInstance size: 24 bytes\nSpace losses: 0 bytes internal + 0 bytes external = 0 bytes total\n```\n\n## 对象布局\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/jol_inheritance.png\" width=\"500\">\n\n## 分析\n1. 在继承关系`C->B->A`中，`父类的实例域`必然排在`子类的实例域`之前\n\n# 继承栅栏\n\n## 代码\n```java\n// -Djol.tryWithSudo=true\npublic class JOLSample_05_InheritanceBarrier {\n\n    public static void main(String[] args) throws Exception {\n        out.println(VM.current().details());\n        out.println(ClassLayout.parseClass(C.class).toPrintable());\n    }\n\n    public static class A {\n        long a;\n    }\n\n    public static class B extends A {\n        long b;\n    }\n\n    public static class C extends B {\n        long c;\n        int d;\n    }\n\n}\n```\n\n## 运行结果\n```\n# Running 64-bit HotSpot VM.\n# Using compressed oop with 3-bit shift.\n# Using compressed klass with 3-bit shift.\n# Objects are 8 bytes aligned.\n# Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n# Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n\nme.zhongmingmao.jol.JOLSample_05_InheritanceBarrier$C object internals:\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      0    12        (object header)                           N/A\n     12     4        (alignment/padding gap)\n     16     8   long A.a                                       N/A\n     24     8   long B.b                                       N/A\n     32     8   long C.c                                       N/A\n     40     4    int C.d                                       N/A\n     44     4        (loss due to the next object alignment)\nInstance size: 48 bytes\nSpace losses: 4 bytes internal + 4 bytes external = 8 bytes total\n```\n\n## 对象布局\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/jol_inheritance_barrier.png\" width=\"500\">\n\n## 分析\n1. 继承栅栏（`inheritance barrier`）通俗点就是在继承关系中，分配当前类的实例域时，`Hotspot JVM`不会考虑在之前可能存在的`内存间隙`，`实例域的重排序仅限于当前类`，因此`父类的实例域`必然排在`子类的实例域`之前\n2. 因此`C.d`不会被提升到`12`的位置\n\n# 继承对齐\n继承对齐只是我个人的表述，指的是在继承关系中，`Hotspot JVM`会通过`Padding`的的方式将`每个类自身定义的实例域总空间`填充为`引用大小(4 Bytes/8 Bytes)的整数倍`\n\n## 代码\n```java\n// -Djol.tryWithSudo=true\npublic class JOLSample_06_Gaps {\n\n    public static void main(String[] args) throws Exception {\n        out.println(VM.current().details());\n        out.println(ClassLayout.parseClass(C.class).toPrintable());\n    }\n\n    public static class A {\n        boolean a;\n    }\n\n    public static class B extends A {\n        boolean b;\n    }\n\n    public static class C extends B {\n        boolean c;\n    }\n}\n```\n\n## 运行结果\n```\n# Running 64-bit HotSpot VM.\n# Using compressed oop with 3-bit shift.\n# Using compressed klass with 3-bit shift.\n# Objects are 8 bytes aligned.\n# Field sizes by type: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n# Array element sizes: 4, 1, 1, 2, 2, 4, 4, 8, 8 [bytes]\n\nme.zhongmingmao.jol.JOLSample_06_Gaps$C object internals:\n OFFSET  SIZE      TYPE DESCRIPTION                               VALUE\n      0    12           (object header)                           N/A\n     12     1   boolean A.a                                       N/A\n     13     3           (alignment/padding gap)\n     16     1   boolean B.b                                       N/A\n     17     3           (alignment/padding gap)\n     20     1   boolean C.c                                       N/A\n     21     3           (loss due to the next object alignment)\nInstance size: 24 bytes\nSpace losses: 6 bytes internal + 3 bytes external = 9 bytes total\n```\n\n## 对象布局\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/jol_inheritance_gap.png\" width=\"500\">\n\n## 分析\n1. `64-bit Hotspot JVM`默认是开启`指针压缩`，因为引用大小为`4 Bytes`\n2. 由于`继承补全`的限制，因此在`B.b`没有存放在`13`的位置，而是等A继承对齐后，存放在`16`的位置\n\n<!-- indicate-the-source -->\n","tags":["JOL"],"categories":["Baisc"]},{"title":"JVM基础 -- Instrumentation + sa-jdi 实例分析","url":"%2F2016%2F06%2F28%2Fjvm-object-layout-2%2F","content":"\n{% note info %}\n本文将通过`Instrumentation` + `sa-jdi`来分析几个实例的内存对象布局\n{% endnote %}\n\n<!-- more -->\n\n# 关键概念\n\n1. Java对象的内存布局：对象头(`Header`) + 实例数据（`Instance Data`） + 对其填充（`Padding`）\n2. `Header`具体内容\n    - `Mark Word`：存储对象hashCode、锁信息等\n    - `Class MetaData Address`：存储对象类型数据的指针\n    - `Array Length`：数组的长度（如果当前对象是数组，否则没有这一内容）\n3. HotSpot JVM中对象的对齐方式：`8字节对齐`\n4. `实例域重排序`：为了`节省内存空间`，实例域将按（`double/long`，`int/float`，`short/char`，`boolean/byte`，`reference`）进行重排序\n5. `非静态内部类`：有一个`隐藏的对外部类的引用`\n6. `指针压缩`：影响对象的内存布局，JVM参数：`-XX:+UseCompressedOops`\n\n指针压缩的影响\n\n| 是否开启压缩 | Mark Word | Class MetaData Address | Reference |\n| --- | --- | --- | --- |\n| 否 | 8 | 8 | 8 |\n| 是 | 8 | 4 | 4 |\n\n# 指针压缩\n\n## 代码\n```java\npublic class CompressedOopsTestClass {\n\n    int intValue;\n    Integer integerRef;\n    Integer[] integerArrayRef = new Integer[3];\n}\n```\n\n## 开启压缩\n\n### 运行结果\n```\nme.zhongmingmao.create.classes.CompressedOopsTestClass : shallow size = 24 Bytes , retained size= 56 Bytes\n```\n\n### 内存映像\n```\nOop for me/zhongmingmao/create/classes/CompressedOopsTestClass @ 0x00000007bffe4e78 (object size = 24)\n - _mark:    {0} :392050833673\n - _metadata._compressed_klass:  {8} :InstanceKlass for me/zhongmingmao/create/classes/CompressedOopsTestClass\n - intValue:     {12} :0\n - integerRef:   {16} :null\n - integerArrayRef:  {20} :ObjArray @ 0x00000007bffe4e90\n\nObjArray @ 0x00000007bffe4e90 (object size = 32)\n - _mark:    {0} :490473115401\n - _metadata._compressed_klass:  {8} :ObjArrayKlass for InstanceKlass for java/lang/Integer\n - 0:    {16} :null\n - 1:    {20} :null\n - 2:    {24} :null\n```\n\n### 对象布局\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/compressed.png\" width=\"500\">\n\n## 关闭压缩\n\n### 运行结果\n```\nme.zhongmingmao.create.classes.CompressedOopsTestClass : shallow size = 40 Bytes , retained size= 88 Bytes\n```\n\n### 内存映像\n```\nOop for me/zhongmingmao/create/classes/CompressedOopsTestClass @ 0x000000011602d7f8 (object size = 40)\n - _mark:    {0} :392050833665\n - _metadata._klass:     {8} :InstanceKlass for me/zhongmingmao/create/classes/CompressedOopsTestClass\n - intValue:     {16} :0\n - integerRef:   {24} :null\n - integerArrayRef:  {32} :ObjArray @ 0x000000011602da20\n\nObjArray @ 0x000000011602da20 (object size = 48)\n - _mark:    {0} :490473115393\n - _metadata._klass:     {8} :ObjArrayKlass for InstanceKlass for java/lang/Integer\n - 0:    {24} :null\n - 1:    {32} :null\n - 2:    {40} :null\n```\n\n### 对象布局\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/uncompressed.png\" width=\"500\">\n\n# 实例域重排序\n\n## 代码\n```java\npublic class ReorderingTestClass {\n    Object   objectRef;\n    Integer integerRef;\n    int intValue_1;\n    int intValue_2;\n    byte byteValue_1;\n    byte byteValue_2;\n    byte byteValue_3;\n    short shortValue_1;\n    long longValue_1;\n    Long[] longArrayRef;\n}\n```\n\n## 运行结果\n```\n# 默认进行指针压缩\nme.zhongmingmao.create.classes.ReorderingTestClass : shallow size = 48 Bytes , retained size= 48 Bytes\n```\n\n## 内存映像\n```\nOop for me/zhongmingmao/create/classes/ReorderingTestClass @ 0x00000007bfe2c750 (object size = 48)\n - _mark:    {0} :40809812993\n - _metadata._compressed_klass:  {8} :InstanceKlass for me/zhongmingmao/create/classes/ReorderingTestClass\n - objectRef:    {36} :null\n - integerRef:   {40} :null\n - intValue_1:   {12} :0\n - intValue_2:   {24} :0\n - byteValue_1:  {30} :0\n - byteValue_2:  {31} :0\n - byteValue_3:  {32} :0\n - shortValue_1:     {28} :0\n - longValue_1:  {16} :0\n - longArrayRef:     {44} :null\n```\n\n## 对象布局\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/reordering_1.png\" width=\"500\">\n1. 实例域重排序的主要目的是为了`让内存更为紧凑`，因为`Hotspot JVM`在内存中是`8Byte对齐`，必然会出现上面左图那样的内存浪费\n2. 大致原则上是按照`double/long`，`int/float`，`short/char`，`boolean/byte`，`reference`的优先级进行重排序，但还有进一步优化，如果有比自身优先级低的但能填充自己无法填充的区域，则让优先级低的进行填充（表述有点拗口）\n    - 如右图中，`12`的位置原本尝试填充`longValue_1`，但由于`long需要8 Bytes`和`字节对齐`，无法填充，而`intValue_1`恰好能填充这原本会被浪费的空间，让内存更为紧凑\n3. 从上图可知，进行实例域重排序能更有效的利用内存\n\n# 内部类\n\n## 代码\n```java\npublic class OuterClass {\n    InnerClass innerClassRef;\n\n    public OuterClass() {\n        this.innerClassRef = new InnerClass();\n    }\n\n    class InnerClass {\n        Integer integerRef;\n    }\n}\n```\n\n## 运行结果\n```\nme.zhongmingmao.create.classes.OuterClass : shallow size = 16 Bytes , retained size= 40 Bytes\n```\n\n## 内存映像\n```\nOop for me/zhongmingmao/create/classes/OuterClass @ 0x00000007bfe30b40 (object size = 16)\n - _mark:    {0} :128250200577\n - _metadata._compressed_klass:  {8} :InstanceKlass for me/zhongmingmao/create/classes/OuterClass\n - innerClassRef:    {12} :Oop for me/zhongmingmao/create/classes/OuterClass$InnerClass @ 0x00000007bfe30b50\n\nOop for me/zhongmingmao/create/classes/OuterClass$InnerClass @ 0x00000007bfe30b50 (object size = 24)\n - _mark:    {0} :47710727425\n - _metadata._compressed_klass:  {8} :InstanceKlass for me/zhongmingmao/create/classes/OuterClass$InnerClass\n - integerRef:   {12} :null\n - this$0:   {16} :Oop for me/zhongmingmao/create/classes/OuterClass @ 0x00000007bfe30b40\n```\n\n## 对象布局\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/innerclass.png\" width=\"500\">\n`非静态内部类`隐藏有一个的对`外部类的引用`（`this$0`）\n\n# 继承\n\n## 代码\n```java\npublic class Father {\n\n    int intValue;\n    Integer integerRef;\n\n    public Father() {\n        integerRef = new Integer(1 << 10);\n    }\n\n}\n```\n```java\npublic class Son extends Father {\n\n    byte byteValue;\n    short shortValue;\n    Integer[] integerArrayRef = new Integer[3];\n}\n```\n```java\npublic class GranSon extends Son {\n\n    boolean booleanValue;\n    Father[] fatherArrayRef = new Father[3];\n\n    public GranSon() {\n        for (int i = 0; i < fatherArrayRef.length; ++i) {\n            fatherArrayRef[i] = new Father();\n        }\n    }\n\n}\n```\n\n## 运行结果\n```\nme.zhongmingmao.create.classes.Father : shallow size = 24 Bytes , retained size= 40 Bytes\nme.zhongmingmao.create.classes.Son : shallow size = 32 Bytes , retained size= 80 Bytes\nme.zhongmingmao.create.classes.GranSon : shallow size = 40 Bytes , retained size= 240 Bytes\n```\n\n## 内存映像\n```\n# 只摘录了GranSon对象的完整记录，对于Son和Father的分析也是类似的\nOop for me/zhongmingmao/create/classes/GranSon @ 0x00000007bfe364e8 (object size = 40)\n - _mark:    {0} :116709573121\n - _metadata._compressed_klass:  {8} :InstanceKlass for me/zhongmingmao/create/classes/GranSon\n - intValue:     {12} :0\n - integerRef:   {16} :Oop for java/lang/Integer @ 0x00000007bfe36510\n - byteValue:    {22} :0\n - shortValue:   {20} :0\n - integerArrayRef:  {24} :ObjArray @ 0x00000007bfe36520\n - booleanValue:     {28} :false\n - fatherArrayRef:   {32} :ObjArray @ 0x00000007bfe365a8\n\n# integerRef\nOop for java/lang/Integer @ 0x00000007bfe36510 (object size = 16)\n - _mark:    {0} :1\n - _metadata._compressed_klass:  {8} :InstanceKlass for java/lang/Integer\n - value:    {12} :1024\n\n# integerArrayRef\nObjArray @ 0x00000007bfe36520 (object size = 32)\n - _mark:    {0} :440814568449\n - _metadata._compressed_klass:  {8} :ObjArrayKlass for InstanceKlass for java/lang/Integer\n - 0:    {16} :null\n - 1:    {20} :null\n - 2:    {24} :null\n\n# fatherArrayRef\nObjArray @ 0x00000007bfe365a8 (object size = 32)\n - _mark:    {0} :131009079297\n - _metadata._compressed_klass:  {8} :ObjArrayKlass for InstanceKlass for me/zhongmingmao/create/classes/Father\n - 0:    {16} :Oop for me/zhongmingmao/create/classes/Father @ 0x00000007bfe365c8\n - 1:    {20} :Oop for me/zhongmingmao/create/classes/Father @ 0x00000007bfe365f0\n - 2:    {24} :Oop for me/zhongmingmao/create/classes/Father @ 0x00000007bfe36618\n\n# fatherArrayRef[0]\nOop for me/zhongmingmao/create/classes/Father @ 0x00000007bfe365c8 (object size = 24)\n - _mark:    {0} :306715851521\n - _metadata._compressed_klass:  {8} :InstanceKlass for me/zhongmingmao/create/classes/Father\n - intValue:     {12} :0\n - integerRef:   {16} :Oop for java/lang/Integer @ 0x00000007bfe365e0\n\nOop for java/lang/Integer @ 0x00000007bfe365e0 (object size = 16)\n - _mark:    {0} :1\n - _metadata._compressed_klass:  {8} :InstanceKlass for java/lang/Integer\n - value:    {12} :1024\n\n# fatherArrayRef[1]\nOop for me/zhongmingmao/create/classes/Father @ 0x00000007bfe365f0 (object size = 24)\n - _mark:    {0} :54816361729\n - _metadata._compressed_klass:  {8} :InstanceKlass for me/zhongmingmao/create/classes/Father\n - intValue:     {12} :0\n - integerRef:   {16} :Oop for java/lang/Integer @ 0x00000007bfe36608\n\nOop for java/lang/Integer @ 0x00000007bfe36608 (object size = 16)\n - _mark:    {0} :1\n - _metadata._compressed_klass:  {8} :InstanceKlass for java/lang/Integer\n - value:    {12} :1024\n\n# fatherArrayRef[2]\nOop for me/zhongmingmao/create/classes/Father @ 0x00000007bfe36618 (object size = 24)\n - _mark:    {0} :101599592961\n - _metadata._compressed_klass:  {8} :InstanceKlass for me/zhongmingmao/create/classes/Father\n - intValue:     {12} :0\n - integerRef:   {16} :Oop for java/lang/Integer @ 0x00000007bfe36630\n\nOop for java/lang/Integer @ 0x00000007bfe36630 (object size = 16)\n - _mark:    {0} :1\n - _metadata._compressed_klass:  {8} :InstanceKlass for java/lang/Integer\n - value:    {12} :1024\n```\n\n## 对象布局\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/inherit_1.png\" width=\"500\">\n1. `父类实例字段在子类实例字段前面`，只有`类自身定义的实例域`才会进行`重排序`，不会跨域到父类或子类\n    - 例如在GranSon的`23`的位置其实可以存放`booleanValue`，但由于来自Son的实例域还有`integerArrayRef`没有填充完，因此只能是`padding`\n    - 因此，`子类实例域不会插入到父类实例域的空隙中`\n2. retained size= 240 Bytes\n    - 240 = (24 + 16) * 3 + 32 + 32 +16 + 40\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- Instrumentation + sa-jdi 工具构建","url":"%2F2016%2F06%2F26%2Fjvm-object-layout-1%2F","content":"\n{% note info %}\n本文首先介绍测量对象内存布局的其中一种方法，`Instrumentation` + `sa-jdi`\n{% endnote %}\n\n<!-- more -->\n\n# 核心代码\n\n1. 代码托管在：[https://github.com/zhongmingmao/java_object_layout](https://github.com/zhongmingmao/java_object_layout)\n2. 采用`Instrumentation` + `sa-jdi`的方式需要自己编写代码，比较繁琐，`OpenJDK`提供的`JOL` (Java Object Layout) 工具则是`开箱即用`，非常方便，后续博文会进一步介绍JOL的使用\n\n## 测量对象大小\n通过`Instrumentation`测量`对象占用的空间大小`\n```java\n/**\n * 对象占用字节大小工具类<br/>\n * see http://yueyemaitian.iteye.com/blog/2033046\n */\npublic class SizeOfObjectUtil {\n\n    static Instrumentation inst;\n\n    public static void premain(String args, Instrumentation instP) {\n        inst = instP;\n    }\n\n    /**\n     * 直接计算当前对象占用空间大小<br/>\n     * 包括\n     * <ol>\n     * <li>当前类及超类的基本类型实例字段大小</li>\n     * <li>引用类型实例字段引用大小</li>\n     * <li>实例基本类型数组总占用空间</li>\n     * <li>实例引用类型数组引用本身占用空间大小</li>\n     * </ol>\n     * <br/>\n     * 但是不包括\n     * <ol>\n     * <li>超类继承下来的和当前类声明的实例引用字段的对象本身的大小</li>\n     * <li>实例引用数组引用的对象本身的大小</li>\n     * </ol>\n     *\n     * @param obj 待计算空间占用的对象\n     * @return 对象占用的空间大小\n     */\n    public static long sizeOf(Object obj) {\n        return inst.getObjectSize(obj);\n    }\n\n    /**\n     * 递归计算当前对象占用空间总大小，包括当前类和超类的实例字段大小以及实例字段引用对象大小\n     */\n    public static long fullSizeOf(Object objP) throws IllegalAccessException {\n        Set<Object> visited = new HashSet<>();\n        Deque<Object> toBeQueue = new ArrayDeque<>();\n        toBeQueue.add(objP);\n        long size = 0L;\n        while (toBeQueue.size() > 0) {\n            Object obj = toBeQueue.poll();\n            // sizeOf的时候已经计基本类型和引用的长度，包括数组\n            size += skipObject(visited, obj) ? 0L : sizeOf(obj);\n            Class<?> tmpObjClass = obj.getClass();\n            if (tmpObjClass.isArray()) {\n                // [I , [F 基本类型名字长度是2\n                if (tmpObjClass.getName().length() > 2) {\n                    for (int i = 0, len = Array.getLength(obj); i < len; i++) {\n                        Object tmp = Array.get(obj, i);\n                        if (tmp != null) {\n                            // 非基本类型需要深度遍历其对象\n                            toBeQueue.add(Array.get(obj, i));\n                        }\n                    }\n                }\n            } else {\n                while (tmpObjClass != null) {\n                    Field[] fields = tmpObjClass.getDeclaredFields();\n                    for (Field field : fields) {\n                        if (Modifier.isStatic(field.getModifiers()) // 静态不计\n                                || field.getType().isPrimitive() // 基本类型不重复计\n                                || field.getName().contains(\"this\")) {  // 内部类实例对外部类实例的引用不再重复计算\n                            continue;\n                        }\n\n                        field.setAccessible(true);\n                        Object fieldValue = field.get(obj);\n                        if (fieldValue == null) {\n                            continue;\n                        }\n                        toBeQueue.add(fieldValue);\n                    }\n                    tmpObjClass = tmpObjClass.getSuperclass();\n                }\n            }\n        }\n        return size;\n    }\n\n    /**\n     * String.intern的对象不计；计算过的不计，也避免死循环\n     */\n    static boolean skipObject(Set<Object> visited, Object obj) {\n        if (obj instanceof String && obj == ((String) obj).intern()) {\n            return true;\n        }\n        return visited.contains(obj);\n    }\n}\n```\n\n## 创建对象\n通过`反射`创建对象，这些对象都是具有代表性的实例，下一博文继续分析\n```java\n/**\n * 通过反射实例化类<br/>\n * java -cp create-object-1.0-SNAPSHOT.jar -javaagent:./size-of-object-1.0-SNAPSHOT.jar\n * me.zhongmingmao.create.CreateObjectUtil\n *\n * @author zhongmingmao zhongmingmao0625@gmail.com\n */\npublic class CreateObjectUtil {\n\n    /**\n     * 实例化对象的列表\n     */\n    static List<Object> objects = new ArrayList<>();\n\n    /**\n     * 通过反射实例化类，考虑jar包和非jar包的情况\n     */\n    static void createObject(Class<?> clazz) throws Exception {\n        String packageName = clazz.getName().substring(0, clazz.getName().lastIndexOf(\".\"));\n        String resourcePath = clazz.getResource(\"\").getPath();\n        Set<String> outClassSet = new HashSet<>();\n\n        if (resourcePath.contains(\"!\")) {\n            // 打包成jar包后路径会含有!字符\n            String jarFilePath = resourcePath.substring(resourcePath.indexOf(\":\") + 1, resourcePath.lastIndexOf(\"!\"));\n            new JarFile(jarFilePath).stream().forEach(jarEntry -> {\n                if (jarEntry.getName().endsWith(\".class\")) {\n                    String className = jarEntry.getName()\n                            .substring(0, jarEntry.getName().length() - 6).replace(\"/\", \".\");\n                    if (className.contains(packageName)) {// 只实例化packageName下的类\n                        instance(className, outClassSet);\n                    }\n                }\n            });\n        } else {\n            // 在IDE或终端直接采用运行class文件\n            for (File subFile : new File(resourcePath).listFiles()) {\n                String className = String.format(\"%s.%s\", packageName,\n                        subFile.getName().substring(0, subFile.getName().lastIndexOf(\".\")));\n                if (className.contains(packageName)) {\n                    instance(className, outClassSet);\n                }\n            }\n        }\n    }\n\n    /**\n     * 实例化\n     */\n    private static void instance(String className, Set<String> outClassSet) {\n        try {\n            Class<?> klass = Class.forName(className);\n            if (className.contains(\"$\")) {\n                // 不能单独实例化内部类\n                outClassSet.add(className.substring(0, className.lastIndexOf(\"$\")));\n                return;\n            }\n            Object object = klass.newInstance();\n            objects.add(object);\n            System.out.println(String.format(\"%20s : shallow size = %d Bytes , retained size= %s Bytes\",\n                    klass.getCanonicalName(),\n                    sizeOf(object),\n                    fullSizeOf(object)));\n\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        createObject(CompressedOopsTestClass.class);\n        BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\n        reader.readLine();\n    }\n}\n```\n\n## 打印内存布局\n通过`Hotspot JVM`提供的工具，打印`JVM进程的内存映像`到磁盘文件，便于后续继续分析\n```java\npackage me.zhongmingmao.layout;\n\nimport sun.jvm.hotspot.oops.HeapPrinter;\nimport sun.jvm.hotspot.oops.HeapVisitor;\nimport sun.jvm.hotspot.oops.ObjectHeap;\nimport sun.jvm.hotspot.runtime.VM;\nimport sun.jvm.hotspot.tools.Tool;\n\n/**\n * 打印JVM进程中的对象内存布局\n */\npublic class PrintObjectMemLayout extends Tool {\n\n    @Override\n    public void run() {\n        VM vm = VM.getVM();\n        ObjectHeap objHeap = vm.getObjectHeap();\n        HeapVisitor heapVisitor = new HeapPrinter(System.out);\n        objHeap.iterate(heapVisitor);\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        PrintObjectMemLayout layout = new PrintObjectMemLayout();\n        layout.execute(args);\n        layout.stop();\n    }\n}\n```\n\n# 使用\n\n## git clone\n```\n$ git clone https://github.com/zhongmingmao/java_object_layout\n```\n\n## mvn clean install\n```\n$ cd java_object_layout && mvn clean install\n```\n\n## 创建对象\n```\n$ cd create-object/target\n\n# -Xms5m -Xmx5m ➔ 限制Heap大小是为了加快JVM内存映像的导出时间和减小文件大小，可以依据实际情况进行调整\n# -XX:+UseCompressedOops ➔ 开启指针压缩，可以关闭观察差异，默认打开\n$ java -cp create-object-1.0-SNAPSHOT.jar -javaagent:./size-of-object-1.0-SNAPSHOT.jar -Xms5m -Xmx5m -XX:+UseCompressedOops me.zhongmingmao.create.CreateObjectUtil\nme.zhongmingmao.create.classes.CompressedOopsTestClass : shallow size = 24 Bytes , retained size= 56 Bytes\n```\n\n## 导出JVM内存布局\n```\n# 另起一个会话\n$ cd print-object-mem-layout/src/main/java\n\n$ javac -cp $JAVA_HOME/lib/sa-jdi.jar me/zhongmingmao/layout/PrintObjectMemLayout.java\n\n# 需要sudo权限\n$ sudo java -cp $JAVA_HOME/lib/sa-jdi.jar:.  me.zhongmingmao.layout.PrintObjectMemLayout $(jps | grep CreateObjectUtil | awk  '{print $1}') > heap_oops_compress.txt\n\n$ du -sh heap_oops_compress.txt\n9.7M\theap_oops_compress.txt # 上面限制Heap大小，导出的文件也很小，便于分析\n\n# 通过导出的JVM内存映像就能对对象的内存布局进行分析\n$ cat heap_oops_compress.txt | grep CompressedOopsTestClass | head -n 1\n\"me/zhongmingmao/create/classes/CompressedOopsTestClass.class\" @ 0x00000007bfa31ea0 (object size = 24)\n```\n\n# 待续\n下一博文将通过`Instrumentation` + `sa-jdi`来分析对象的内存布局\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"JVM基础 -- VirtualMachineError实例","url":"%2F2016%2F06%2F24%2Fjvm-virtualmachineerror%2F","content":"\n{% note info %}\n`VirtualMachineError`有两个常见的实现类：`StackOverflowError`、`OutOfMemoryError`，本文将用代码分析几种情况的`VirtualMachineError`\n{% endnote %}\n\n<!-- more -->\n\n# JVM参数\n\n| 内存区域 | 虚拟机栈<br/>VM Stack | 堆<br/>Heap | 方法区<br/>Method Area |\n| --- | --- | --- | --- |\n| 共享/隔离 | 线程隔离 | 线程共享 | 线程共享 |\n| 存放的数据 | 栈帧 Stack Frame | 对象实例/数组 | 类信息、常量、静态变量等数据 |\n| 异常情况 | StackOverflowError<br/>OutOfMemoryError | OutOfMemoryError | OutOfMemoryError |\n| JVM参数 | -Xss | -Xms<br/>-Xmx | -XX:PermSize<br/>-XX:MaxPermSize<br/>-XX:MetaspaceSize<br/>-XX:MaxMetaspaceSize |\n\n{% note warning %}\n注：在JDK8之前，`Hotspot JVM`采用永生代（`Permanent Generation`）来实现方法区（`Method Area`），从`JDK8`开始，已经移除了永生代，使用`Metaspace`进行替代，相关连接请参考：\n1. http://blog.csdn.net/zhushuai1221/article/details/52122880\n2. http://openjdk.java.net/jeps/122\n3. https://stackoverflow.com/questions/18339707/permgen-elimination-in-jdk-8\n{% endnote %}\n\n\n# 实例\n\n\n## VM Stack - StackOverflowError\n\n### 代码\n```java\npublic class VMStackSOF {\n    private int stackDepth = 0;\n\n    public void stackLeak() {\n        ++stackDepth;\n        stackLeak();\n    }\n\n    @Override\n    public String toString() {\n        return String.format(\"stackDepth:%s\", stackDepth);\n    }\n\n    // JDK ➔ 7\n    // JVM Args ➔ -Xss256k\n    // -Xss ➔ VM Stack大小\n    public static void main(String[] args) {\n        VMStackSOF sof = new VMStackSOF();\n        try {\n            sof.stackLeak();\n        } catch (Throwable e) {\n            System.out.println(e.getClass().getCanonicalName());\n            System.out.println(sof);\n        }\n    }\n}\n```\n\n### 运行结果\n```\njava.lang.StackOverflowError\nstackDepth:1890\n```\n\n### 分析\n1. `VM Stack`是`线程私有`，当线程执行一个方法时，会在`VM Stack`上创建一个`Stack Frame`，`VM Stack`类似于`Stack`（FILO）的数据结构，`最上层的Stack Frame`即`当前线程执行的方法`\n2. 方法`从调用到执行完成`，对应着`Stack Frame`在`VM Stack`中`从入栈到出栈`的过程\n3. 由于`VM Stack`的空间有限，当递归调用的深度过大，有可能会抛出`StackOverflowError`\n\n## Heap - OutOfMemoryError\n\n### 代码\n```java\npublic class HeapOOM {\n    static class OOMObject {\n        private static final int _1_MB = 1 * 1024 * 1024;\n        private final byte[] body = new byte[_1_MB];\n    }\n\n    // JDK ➔ 7\n    // JVM Args ➔ -Xms10M -Xmx10M -XX:+HeapDumpOnOutOfMemoryError -verbose:gc -XX:+PrintGCDetails -XX:+UseSerialGC\n    // -Xms ➔ 初始堆内存大小\n    // -Xmx ➔ 最大堆内存大小\n    // -XX:+HeapDumpOnOutOfMemoryError ➔ 当发生OutOfMemoryError，生成Heap Dump文件，便于MAT等工具进分析\n    // -XX:+PrintGCDetails ➔ 打印GC日志\n    // -XX:+UseSerialGC ➔ 新生代采用Serial收集器，老年代采用Serial Old收集器\n    public static void main(String[] args) {\n        List<OOMObject> list = new ArrayList<>();\n        while (true) {\n            list.add(new OOMObject());\n        }\n    }\n}\n```\n\n### 运行结果\n```\n[GC[DefNew: 2542K->320K(3072K), 0.0030860 secs] 2542K->1392K(9920K), 0.0031220 secs] [Times: user=0.00 sys=0.01, real=0.01 secs]\n[GC[DefNew: 2520K->0K(3072K), 0.0036840 secs] 3593K->3440K(9920K), 0.0037070 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]\n[GC[DefNew: 2094K->0K(3072K), 0.0024930 secs] 5534K->5489K(9920K), 0.0025120 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]\n[GC[DefNew: 2078K->2078K(3072K), 0.0000150 secs][Tenured: 5488K->6512K(6848K), 0.0062400 secs] 7567K->7537K(9920K), [Perm : 2973K->2973K(21248K)], 0.0062960 secs] [Times: user=0.01 sys=0.00, real=0.00 secs]\n[Full GC[Tenured: 6512K->6512K(6848K), 0.0043250 secs] 8569K->8562K(9920K), [Perm : 2982K->2982K(21248K)], 0.0043490 secs] [Times: user=0.01 sys=0.00, real=0.01 secs]\n[Full GC[Tenured: 6512K->6475K(6848K), 0.0054820 secs] 8562K->8525K(9920K), [Perm : 2982K->2981K(21248K)], 0.0055010 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]\njava.lang.OutOfMemoryError: Java heap space\nDumping heap to java_pid96337.hprof ...\nHeap dump file created [9431959 bytes in 0.064 secs]\nException in thread \"main\" java.lang.OutOfMemoryError: Java heap space\n\nHeap\n def new generation   total 3072K, used 2214K [0x00000007fa400000, 0x00000007fa750000, 0x00000007fa750000)\n  eden space 2752K,  80% used [0x00000007fa400000, 0x00000007fa629bc8, 0x00000007fa6b0000)\n  from space 320K,   0% used [0x00000007fa700000, 0x00000007fa700000, 0x00000007fa750000)\n  to   space 320K,   0% used [0x00000007fa6b0000, 0x00000007fa6b0000, 0x00000007fa700000)\n tenured generation   total 6848K, used 6475K [0x00000007fa750000, 0x00000007fae00000, 0x00000007fae00000)\n   the space 6848K,  94% used [0x00000007fa750000, 0x00000007fada2da0, 0x00000007fada2e00, 0x00000007fae00000)\n compacting perm gen  total 21248K, used 3124K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)\n   the space 21248K,  14% used [0x00000007fae00000, 0x00000007fb10d130, 0x00000007fb10d200, 0x00000007fc2c0000)\nNo shared spaces configured.\n```\n\n### MAT分析\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/mat_oom_serialgc.png\" width=\"500\">\n1. 当线程运行main方法时，list是在的`VM Stack`的`Current Stack Frame`定义的`强引用(Strong Reference)`，且为`GC ROOT`，哪怕JVM堆内存不足的时候，触发`Full GC`，也不会将其回收，最后导致`OutOfMemoryError`\n2. 由GC日志可以看出，`新生代的Eden区`存有`2`个OOMObject对象，`老年代`存有`6`个OOMObject对象，已经无法再容纳新的OOMObject对象，抛出`OutOfMemoryError`\n\n## Interned Strings\n`Interned Strings`（字面量）在`JDK6`会存储在`PermGen`，从`JDK7`开始存储在`Java Heap`，减少`OOM`和`性能问题`\n\n### JDK6 - PermGen\n\n#### 代码\n```java\n// JDK ➔ 6\n// JVM Args ➔ -Xms60m -Xmx60m -XX:PermSize=50m -XX:MaxPermSize=50m -verbose:gc -XX:+PrintGCDetails -XX:+UseSerialGC\n// -XX:PermSize ➔ PermGen的初始大小\n// -XX:MaxPermSize ➔ PermGen的最大值\npublic static void main(String[] args) throws Throwable {\n\n   BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\n   System.out.println(\"waiting for input...\");\n   reader.readLine();\n   int i = 0;\n   List<String> strings = new ArrayList<String>();\n   while (true) {\n       // 当前线程保持强引用，阻止被GC回收\n       strings.add(String.valueOf(i++).intern());\n   }\n}\n```\n\n#### 运行结果\n```\n[GC [DefNew: 17587K->784K(18432K), 0.0078576 secs] 17587K->1928K(59392K), 0.0078864 secs] [Times: user=0.01 sys=0.00, real=0.01 secs]\n[GC [DefNew: 17168K->1764K(18432K), 0.0065362 secs] 18312K->2909K(59392K), 0.0065645 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]\n[GC [DefNew: 18148K->12K(18432K), 0.0087651 secs] 19293K->3794K(59392K), 0.0087963 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]\n[Full GC [Tenured: 3781K->3783K(40960K), 0.1019995 secs] 7657K->3783K(59392K), [Perm : 51199K->51199K(51200K)], 0.1033236 secs] [Times: user=0.10 sys=0.00, real=0.10 secs]\n[Full GC [Tenured: 3783K->3783K(40960K), 0.1647300 secs] 3783K->3783K(59392K), [Perm : 51199K->51199K(51200K)], 0.1659092 secs] [Times: user=0.16 sys=0.00, real=0.17 secs]\n[Full GC [Tenured: 3783K->1152K(40960K), 0.0483188 secs] 4020K->1152K(59392K), [Perm : 51199K->13270K(51200K)], 0.0497827 secs] [Times: user=0.05 sys=0.00, real=0.05 secs]\nException in thread \"main\" java.lang.OutOfMemoryError: PermGen space\n```\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/StringInternJDK6.png\" width=\"500\">\n\n#### 分析\n1. `String.valueOf(i++).intern()`会在`Heap`（`valueOf`）和`PermGen`（`intern`）中分配存储空间，并返回引用到`strings`进行保存（强引用，不会被GC回收）\n2. 从GC日志可以看出，`Full GC`时，`PermGen`接近填满（`[Perm : 51199K->51199K(51200K)]`）\n\n### JDK8 - Heap\n\n#### 代码\n```java\n// JDK ➔ 8\n// JVM Args ➔ -Xms600m -Xmx600m -XX:MetaspaceSize=50m -XX:MaxMetaspaceSize=50m -verbose:gc -XX:+PrintGCDetails -XX:+UseSerialGC\n// -XX:MetaspaceSize ➔ Metaspace的初始大小，在JDK8开始，PermGen已经被移除，采用Metaspace来替代\n// -XX:MaxMetaspaceSize ➔ Metaspace的最大值\npublic static void main(String[] args) throws Throwable {\n\n   BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\n   System.out.println(\"waiting for input...\");\n   reader.readLine();\n   int i = 0;\n   List<String> strings = new ArrayList<String>();\n   while (true) {\n       // 当前线程保持强引用，阻止被GC回收\n       strings.add(String.valueOf(i++).intern());\n   }\n}\n```\n\n#### 运行结果\n```\n[GC (Allocation Failure) [DefNew: 161762K->20480K(184320K), 0.4081917 secs] 161762K->108735K(593920K), 0.4082377 secs] [Times: user=0.31 sys=0.06, real=0.41 secs]\n[GC (Allocation Failure) [DefNew: 180388K->20480K(184320K), 0.5512956 secs] 268644K->242289K(593920K), 0.5513318 secs] [Times: user=0.44 sys=0.08, real=0.55 secs]\n[GC (Allocation Failure) [DefNew: 163946K->20480K(184320K), 0.5983332 secs] 385755K->362517K(593920K), 0.5983566 secs] [Times: user=0.46 sys=0.07, real=0.60 secs]\n[GC (Allocation Failure) [DefNew: 184320K->184320K(184320K), 0.0000114 secs][Tenured: 342037K->409599K(409600K), 2.0193780 secs] 526357K->497464K(593920K), [Metaspace: 9048K->9048K(1058816K)], 2.0194333 secs] [Times: user=1.89 sys=0.08, real=2.02 secs]\n[Full GC (Allocation Failure) [Tenured: 409599K->409599K(409600K), 2.0671005 secs] 546537K->542781K(593920K), [Metaspace: 9065K->9065K(1058816K)], 2.0671389 secs] [Times: user=1.95 sys=0.03, real=2.07 secs]\n[Full GC (Allocation Failure) [Tenured: 409599K->409599K(409600K), 2.1368935 secs] 542781K->542354K(593920K), [Metaspace: 9065K->9065K(1058816K)], 2.1370422 secs] [Times: user=2.08 sys=0.02, real=2.14 secs]\nException in thread \"main\" java.lang.OutOfMemoryError: Java heap space\n```\n<img src=\"https://jvm-1253868755.cos.ap-guangzhou.myqcloud.com/StringInternJDK8.png\" width=\"500\">\n\n#### 分析\n1. `String.valueOf(i++).intern()`会在`Heap`（`valueOf`）中分配存储空间，并返回引用到`strings`进行保存（强引用，不会被GC回收）\n2. 从GC日志可以看出，`Full GC`时，`Old Gen`接近填满（`Tenured: 409599K->409599K(409600K)`）\n\n\n<!-- indicate-the-source -->\n","tags":["JVM"],"categories":["Baisc"]},{"title":"Vim -- 文件","url":"%2F2015%2F11%2F11%2Fvim-file%2F","content":"\n{% note info %}\n本文将介绍`Vim`中的`文件`\n{% endnote %}\n\n<!-- more -->\n\n# 基础\n\n## 文件、缓冲区和编辑会话\n文件：存储在磁盘上\n缓冲区：存在于内存中\n编辑会话：执行一次vim命令，默认显示第一个文件的缓冲区，其他文件的缓冲区为后台缓冲区\n\n## 缓冲区列表\n一次编辑会话可以在多个缓冲区上工作，这多个缓冲区就是缓冲区列表\n```\n# 展示缓冲区列表\n:ls：列出所有被载入到内存中的缓冲区列表\n    -：非活动的缓冲区\n    a：激活的缓冲区\n    h：隐藏的缓冲区\n    =：只读的缓冲区\n    +：已经修改但尚未写入磁盘的缓冲区\n    #：轮换缓冲区，通过<C-^>切换成当前缓冲区\n    %：当前缓冲区，通过<C-^>把当前缓冲区切换成轮换缓冲区\n    <C-^>：#与%切换\n\n# 遍历缓冲区列表\nbp[rev]：上一个缓冲区\nbn[ext]：下一个缓冲区\nbf[irst]：第一个缓冲区\nbl[ast]：最后一个缓冲区\nb[uffer] {N}：直接跳转到第{N}个缓冲区，例如:b 3\nb[uffer] {bufferName}：{bufferName}是足以唯一标识某一缓冲区的字符序列，可以结合<Tab>自动补全，例如:b c，:b c.txt\n\n# 删除缓冲区（缓冲区编号自动分配，删除缓冲区操作用得很少）\n# 删除特定缓冲区\nbd[elete] {N1} {N2} {N3}：删除第{N1}，{N2}，{N3}个缓冲区\nbd[elete] {bufferName1} {bufferName2} {bufferName3}，删除标识符为{bufferName1}，{bufferName2}，{bufferName3}的缓冲区\n# 删除连续缓冲区\nN1,N2 bd[elete]：删除第{N1}到{N2}个缓冲区\n\n# 内置的缓冲区列表缺乏灵活性\n```\n\n## 参数列表\nvi：记录在启动时作为参数传递给vim的文件列表，例如vi *，参数列表就是当前目录的所有文件\n```\n:args\n[a.txt] b.txt c.txt d.txt e.txt // a.txt为活动文件（即当前可见的缓冲区）\n\nvim：可以在任意时刻改变参数列表的内容，即按你的需求把一组匹配的文件加入到缓冲区列表，相当于一个workspace\n\n:args {fileName1} {fileName2}\n    {fileName1}和{fileName2}是具体的文件名\n:args {glob1} {glob2}\n    {glob1}和{glob2}是Glob模式\n    *：匹配0个或多个字符，不递归子目录\n    **：匹配0个或多个字符，递归子目录\n:args {shellCmd1} {shellCmd2}\n    {shellCmd1} 和 {shellCmd2} 是Shell命令的标准输出\n    例如:args cat fileName\n```\n\n## 窗口\n缓冲区的显示区域，与缓冲区是多对多的关系\n**创建分割窗口**\n\n| 命令 | 用途 |\n| --- | --- |\n| `<C-w>s` or sp[lit]   | 水平切分当前窗口，新窗口仍显示当前缓冲区 |\n| `<C-w>v` or vs[plit]  | 垂直切分当前窗口，新窗口仍显示当前缓冲区 |\n| sp[lit] {fileName}  | 水平切分当前窗口，并在新窗口中载入{fileName} |\n| vs[plit] {fileName} | 垂直切分当前窗口，并在新窗口中载入{fileName} |\n\n**在窗口间切换**\n\n| 命令 | 用途 |\n| --- | --- |\n| `<C-w>w`              | 在窗口间循环切换 |\n| `<C-w>h`              | 切换到左边的窗口 |\n| `<C-w>j`              | 切换到下边的窗口 |\n| `<C-w>k`              | 切换到右边的窗口 |\n| `<C-w>l`              | 切换到右边的窗口 |\n\n**关闭窗口**\n\n| 命令 | 用途 |\n| --- | --- |\n| `<C-w>c` or `clo[se]`   | 关闭活动窗口 |\n| `<C-w>o` or `on[ly]`    | 只保留活动窗口，关闭其他所有窗口 |\n\n**改变窗口大小**\n\n`<C-w>=`：使所有窗口等宽、等高\n`<C-w>_`：最大化活动窗口的高度\n`<C-w>|`：最大化活动窗口的宽度\n`[N]<C-w>_`：把活动窗口的高度设为[N]行\n`[N]<C-w>|`：把活动窗口的宽设为[N]行\n\n## 标签页\n可以容纳一系列窗口的容器，类似于Linux的虚拟桌面\n**新建标签页**\n\n| 命令 | 用途 |\n| --- | --- |\n| :tabe[dit] {fileName}       | 在新标签页中打开{fileName}，{fileName}为空，则打开一个空缓冲区 |\n| `<C-w>T`                      | 把当前窗口移动到一个新标签页 |\n\n**关闭标签页**\n\n| 命令 | 用途 |\n| --- | --- |\n| :tabc[lose]                 | 关闭当前标签页及其中的所有窗口 |\n| :tabo[nly]                  | 只保留活动标签页，关闭所有其他标签页 |\n\n**切换标签页**\n\n| 命令 | 用途 |\n| --- | --- |\n| :tabnext {N} or {N}gt       | 切换到编号为{N}的标签页，{N}为空，则切换到下一标签页|\n| :tabp[revious] {N} or {N}gT | 切换到上{N}个标签页，{N}为空，则切换到上一标签页 |\n\n**移动标签页**\n\n| 命令 | 用途 |\n| --- | --- |\n| :tabm[ove] [N]              | [N]为0，当前标签页会被移到开头，[N]为空，当前标签页被移到结尾 |\n\n`argsdo {ExCmd}`和`bufdo {ExCmd}`：在当前编辑会话中的所有缓冲区上执行`Ex`命令\n使用`argsdo`或`bufdo`，请设置`set hidden`\n默认情况下，vim不会允许我们从一个改动过但未保存（即缓冲区状态为`+`）的缓冲区切换到其他缓冲区，设置set hidden，相当于：\n`:first :{ExCmd} :bnext! :{ExCmd}`\n\n\n# 使用样例\n\n## 文件路径\n```Zsh\napp.js\nindex.html\napp/\n    controllers/\n\t\tMailer.js\n\t\tMain.js\n\t\tNavigation.js\n\tmodels/\n\t\tUser.js\n\tviews/\n\t\tHome.js\n\t\tMain.js\n\t\tSettings.js\nlib/\n\tframework.js\n\ttheme.css\n```\n\n\n## 使用参数列表筛选所有的js文件\n```\nargs **/**js\nargs find . -name '*js'\n```\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/file_args.gif\" width=\"500\">\n\n## 窗口的使用\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/file_win.gif\" width=\"500\">\n\n## 标签的使用\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/file_tag.gif\" width=\"500\">\n\n## :edit命令打开文件\nvim的工作目录：执行vim命令的当前目录\n相对路径：接受相对工作目录的文件路径\n`:edit %<Tab>`：`%`代表活动缓冲区的完整文件路径\n`:edit %h<Tab>`：与`:edit %<Tab>`类似，但去除文件名，保留路径中的其他部分\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/file_edit.gif\" width=\"500\">\n\n## :find命令查找并打开文件\npath变量值是:find命令查找的范围，默认值为`.,/usr/include`,\n`set path+=./**`：可以将工作目录的所有递归子目录加入到查找的范围\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/file_find.gif\" width=\"500\">\n\n## 保存在不存在的目录\n`:!mkdir -p %:h`：创建活动缓冲区的完整路径对应的目录（去除文件名）\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/file_mkdir.gif\" width=\"500\">\n\n## 使用超级管理员权限保存只读权限的文件\n`:w !sudo tee % > /dev/null`:使用超级管理员权限保存只读文件\n`w !{cmd}`：把当前活动缓冲区的内容作为命令{cmd}的标准输入\n`sudo tee % > /dev/null`：使用超级管理员的权限，执行`tee`命令，`%`代表当前活动缓冲区的完整路径，即将`tee`的标准输入（缓冲区内容）覆盖缓存区对应的文件,并且`tee`命令的标准输出不显示（`/dev/null`）\n因为要输入密码，所以该例子不显示按键\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/file_tee.gif\" width=\"500\">\n\n<!-- indicate-the-source -->\n","tags":["Vim"],"categories":["Vim"]},{"title":"Vim -- 命令行模式","url":"%2F2015%2F11%2F09%2Fvim-commandlinemode%2F","content":"\n{% note info %}\n本文将介绍`Vim`中的`命令行模式`\n{% endnote %}\n\n<!-- more -->\n\n# 基础\n\n## 8种模式\n1. 普通模式：Vim的自然放松状态，也是Vim的默认模式；操作符和动作命令结合在一起；操作 = 操作符 + 动作命令\n2. 插入模式：与Sublime Text默认模式类似\n3. 插入-普通模式：这是普通模式的一个特例，让我们从插入模式执行一次普通模式命令，然后回归插入模式，按键为`<C-o>`\n4. 替换模式：与插入模式的区别：在替换模式中输入会替换文档中的已有文本\n5. 虚拟替换模式（推荐）：制表符当成一组空格进行处理，假设制表符列宽为8，输入的前7个字符时，每个字符会被插入到制表符之前，当输入第8个字符时，该字符会替换制表符\n6. 可视模式：允许我们选中一块文本区域并在其上进行操作；面向字符（v）、面向行（`SHIFT+v`）、面向列（`<C-v>`）\n7. 选择模式：与Word和Sublime Text的操作模式类似，当选中一段文本后，再输入任何可见字符，选择的文本会被删除\n8. 命令行模式：行编辑器ex是vi的先祖，vim支持Ex命令\n\n## 模式切换\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/vim_mode_switch.png\" width=\"500\">\n\n## 常用Ex命令\n操作缓冲区文本的常用Ex命令（完整列表:h ex-cmd-index）\n[range]：连续的行\n```\n# 行号：{start},{end}{command}\n:1p ➔ 打印第一行\n:2,5p ➔ 打印第2-5行\n:$p ➔ 打印最后一行\n:1,$p ➔ 打印全部\n:.,$p ➔ 打印当前行到最后一行\n:%p ➔ 打印全部\n\n# 位置标记\n'm ➔ 包含位置标记m的行\n'< ➔ 高亮选区首行\n'> ➔ 高亮选区最后一行\n:'<,'> ➔ 高亮选区的范围\n\n# 查找模式\n:/<html>/,/<\\/html>/p ➔ 打印第一个<html>标签和第一个</html>标签之间的内容\n\n# 位置偏移\n{address}+n ➔ {address}可以为行号，位置标记，查找模式\n```\nglobal：可以是[range]范围内非连续的行\n\n| Ex命令 | 用途 |\n| --- | --- |\n| :[range]delete [x] | 删除指定范围内的行[到寄存器 x 中] |\n| :[range]yank [x] | 复制指定范围的行[到寄存器 x 中] |\n| :[line]put [x] | 在指定行后粘贴寄存器 x 中的内容 |\n| :[range]copy {address} | 把指定范围内的行拷贝到 {address} 所指定的行之下 |\n| :[range]move {address} | 把指定范围内的行移动到 {address} 所指定的行之下 |\n| :[range]join | 连接指定范围内的行 |\n| :[range]normal {commands} | 对指定范围内的每一行执行普通模式命令 {commands} |\n| :[range]substitute/{pattern}/ {string}/[flags] | 把指定范围内出现{pattern}的地方替换为{string} |\n| :[range]global/{pattern}/[cmd] | 对指定范围内匹配{pattern}的所有行,在其上执行 Ex 命令{cmd}  |\n\n## Ex命令 vs 普通模式\n普通模式一般操作当前字符或当前行，适合\"本地\"操作\nEX命令，可以在任意位置执行，拥有在多行上同时执行的能力，可以远距离操作\n\n# 使用样例\n\n##  复制（:co[py]==:t）和移动(:m[ove])行\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_mode_copy&move.gif\" width=\"500\">\n\n## :normal - 代码行尾添加分号 和 注释代码\n在普通模式时介绍过，可以使用`命令.`重复修改，但不适用于有很多行的代码\n`:nomal`：将`强大表现力的Vim普通模式命令`和`具有大范围影响力的Ex命令`结合在一起\n`Ex命令`结合`命令.`能节省很多按键操作\n注释代码（`:%normal i//`）：在执行指定的普通模式命令之前，Vim 会先把光标移动到该行的行首\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_mode_;comment.gif\" width=\"500\">\n\n## 遍历缓冲区列表\n同时打开多个文件，会形成缓冲区列表，`bn[ext]`打开下一个缓冲文件，`bp[revious]`打开上一个缓冲文件。\n`@:`：重复执行上次Ex命令；\n`@@`：重复执行`@:`\n`<C-o>`：回退到上一个缓冲文件\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_mode_@@_bn_bp.gif\" width=\"500\">\n\n## Ex命令自动补全\n针对zsh的vim配置：`set wildmenu` `set wildmode=full`\n正向查找：`<Tab>`，`<Right>`，`<C-n>`\n反向查找：`<S-Tab>`，`<Left>`，`<C-p>`\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_mode_auto_complete.gif\" width=\"500\">\n\n## 替换单词\n`<C-r><C-w>`：复制光标下的单词并把它插入到命令行中\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_mode_CrCw.gif\" width=\"500\">\n\n## 命令行窗口\n\n命令行模式适用于从头开始构建命令，但在命令行模式中编辑命令的能力有限，而且不能利用历史命令（Ex命令或查找命令），命令行窗口能弥补这两个短处\n命令行窗口就像一个常规的Vim缓冲区，只不过内容是命令历史，允许我们使用Vim完整的区分模式的编辑能力来修改历史命令，并可以在活动窗口的上下文中执行命令\n```\nq: ➔ 打开Ex命令历史的命令行窗口\nq/ ➔ 打开查找命令历史的命令行窗口\n<C-f> ➔ 从命令行模式切换到命令行窗口，保存原先输入\n:q ➔ 退出命令行窗口\n<CR> ➔ 在活动窗口上下文执行命令并退出命令行窗口\n```\n\n演示例子中，将:w，:%p，:!python3 %在命令行窗口中合成一个命令并执行\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_mode_cmdwin.gif\" width=\"500\">\n\n## 运行Shell命令\n\n`%`：代表当前文件\n调用外部命令\n```\n:shell ➔ 启动一个shell（输入exit返回Vim）\n!{cmd} ➔ 在shell中执行{cmd}\n:read !{cmd} ➔ 在shell中执行{cmd}，并把其标准输出插入到光标下方\n:[range]write !{cmd} ➔ 在shell中执行{cmd}，以[range]作为其标准输入\n:[range]!{filter} ➔ 使用外部程序{filter}过滤执行的[range]\n    [range]所指定的内容会传递给{cmd}作为标准输入，然后又会用{cmd}的输出覆盖[range]内原本的内容\n```\n\n把缓冲区内容作为标准输入和标准输出\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_mode_shell_in_out.gif\" width=\"500\">\n\n过滤缓冲区内容（依据第`2`个字段进行排序）\n`:2,$!sort -t ',' -k2`\n`!{motion}` ➔ 切换到`命令行`模式，命令行上预设为`.,{motion}!`，即当前行移动`{motion}`的区域\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_mode_shell_filter.gif\" width=\"500\">\n\n<!-- indicate-the-source -->\n","tags":["Vim"],"categories":["Vim"]},{"title":"Vim -- 可视模式","url":"%2F2015%2F11%2F06%2Fvim-visualmode%2F","content":"\n{% note info %}\n本文将介绍`Vim`中的`可视模式`\n{% endnote %}\n\n<!-- more -->\n\n# 基础\n\n## 可视模式\nVim的可视模式允许我们选中一块文本区域并在其上进行操作\n\n## 语法规则\n与普通模式的语法规则次序颠倒\n普通模式的语法规则：`{operator}{motion}`\n可视模式的语法规则：先选中选区，再触发可视命令；类似于典型文本编辑器的操作模式\n\n## 选择模式\n典型文本编辑器的操作模式：当选中一段文本后，再输入任何可见字符，选择的文本会被删除\n可视模式和选择模式相互切换：`<C-g>`\n```\n:help Select-mode\n\n8. Select mode                                          *Select* *Select-mode*\nSelect mode looks like Visual mode, but the commands accepted are quite different.  \nThis resembles the selection mode in Microsoft Windows.\nWhen the 'showmode' option is set, \"-- SELECT --\" is shown in the last line.\n```\n\n## 可视模式的子模式\n面向`字符`：任意字符范围，适用于操作单词或短语；触发命令：`v`\n面向`行`：触发命令：`V = SHIFT + v`\n操作`列块`：触发命令：`<C-v>`\n`gv`：重选上次的高亮选区；前提是上次的高亮选区没有被删除\n\n子模式间的切换图\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/visual_mode_switch.png\" width=\"500\">\n\n# 使用样例\n\n## 切换选区活动端 o\n高亮选区的范围由其两个对角的端点界定\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/visual_mode-select_area.gif\" width=\"500\">\n\n## 重复执行面向行的可视命令\n使用`命令.`重复低高亮选区所做的修改，此修改会重复作用于相同范围的文本\n下列例子采用Vim配置：`set shiftwidth=4 softtabstop=4 expandtab`\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/visual_mode-line_point.gif\" width=\"500\">\n\n## 操作符命令 vs 可视命令\n1. 尽量使用操作符命令\n\t- 我们需要重复修改的时候，最好是使用`命令.`，而`命令.`与`操作符命令`（普通模式）结合得很好\n\t- `命令.`与可视命令（可视模式）有一些异常情况,具体参照下面的manual（:h visual-repeat）\n2. 可视命令的应用场景\n\t- 一次性的修改任务\n\t- 需要修改的文本范围的结构很难用普通模式的动作命令表达\n3. `vitU` vs `gUit`\n\t- `it`：表示`标签里面的内容`，文本对象，一种特殊的动作命令；`iw`也是一个文本对象，表示`一个单词`\n\t- vitU：两条命令，vit + U\n\t- gUit：单独的命令\n\n```\n:h visual-repeat\n\n6. Repeating                                            *visual-repeat*\nWhen repeating a Visual mode operator, the operator will be applied to the same amount\nof text as the last time:\n- Linewise Visual mode: The same number of lines.\n- Blockwise Visual mode: The same number of lines and columns.\n- Normal Visual mode within one line: The same number of characters.\n- Normal Visual mode with several lines: The same number of lines, in the last line the\n  same number of characters as in the last line the last time.\n```\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/visual_mode-commonORvisual.gif\" width=\"500\">\n\n## 使用面向块的可视模式处理表格（列）\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/visual_mode-create_table.gif\" width=\"500\">\n\n## 修改列文本\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/visual_mode-batch_modify_col.gif\" width=\"500\">\n\n## 在长短不一的高亮块后添加文本\n`a`，`i`：在普通模式：切换至插入模式；在可视模式和操作符待决模式：当做一个文本对象的组成部分，如`viw`，`vit`，`daw`\n`A`，`I`：在普通模式、可视模式和操作符待决模式：切换至插入模式\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/visual_mode-uneq_len.gif\" width=\"500\">\n\n<!-- indicate-the-source -->\n","tags":["Vim"],"categories":["Vim"]},{"title":"Vim -- 插入模式","url":"%2F2015%2F11%2F04%2Fvim-insertmode%2F","content":"\n{% note info %}\n本文将介绍`Vim`中的`插入模式`\n{% endnote %}\n\n<!-- more -->\n\n# 基础\n\n## 插入模式\n`i`：在当前字符的左边插入\n`I`：在当前行首插入\n`a`：在当前字符的右边插入\n`A`：在当前行尾插入\n`o`：在当前行下面插入一个新行\n`O`：在当前行上面插入一个新行\n`c{motion}`：删除 motion 命令跨过的字符，并且进入插入模式\n    `c$`：删除从光标位置到行尾的字符并且进入插入模式\n    `ct!`：删除从光标位置到下一个叹号（但不包括）\n`cc`：剪切当前行并且进入插入模式\n`C`：等同于`c$`\n`s`：删除光标处字符，并进入插入模式\n`S`：删除当前行并进入插入模式，等同于`cc`\n\n## 插入-普通模式\n这是普通模式的一个特例，让我们从插入模式执行一次普通模式命令，然后回归插入模式，按键为`<C-o>`\n\n## 替换模式\n与插入模式的区别：在替换模式中输入会替换文档中的已有文本\n触发命令：`r`，`R`\n\n## 虚拟替换模式（推荐）\n把制表符当成一组空格进行处理\n假设制表符列宽为8，输入的前7个字符时，每个字符会被插入到制表符之前，当输入第8个字符时，该字符会替换制表符\n触发命令：`gr`，`gR`\n\n# 使用样例\n\n## 插入模式中撤销修改\n`<C-h>`：删除前一个字符\n`<C-w>`：删除前一个单词\n`<C-u>`：删除至行首\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/insert_mode-ChCwCu.gif\" width=\"500\">\n\n## 返回普通模式\n切换到普通模式：`<Esc>`：不推荐，按键距离比较长；`<C-[>`：推荐，双手协作\n切换到插入-普通模式：`<C-o>`\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/insert_mode-EscC.gif\" width=\"500\">\n\n## 粘贴寄存器中的文本\n`<C-r>{register}`：将寄存器的内容插入到光标所在的位置，适合粘贴少量的几个单词\n`<C-r><C-p>{register}`：按原义插入寄存器内的文本，减少因textwidth或者autoindent选项触发的不必要的换行或缩进，适合大量文本，但不推荐使用，推荐直接使用普通模式的粘贴命令\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/insert_mode-Cr0.gif\" width=\"500\">\n\n## 表达式寄存器\n大部分Vim寄存器保存的都是文本：删除及复制命令允许我们把文本保存到寄存器；粘贴命令允许我们把寄存器中的内容插入到文档里\n表达式寄存器`<C-r>=`：执行一段Vim脚本，并返回结果\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/insert_mode-Cr=.gif\" width=\"500\">\n\n\n## 插入特殊字符\n`ga`：当前光标字符编码（十进制、十六进制、八进制）\n`<C-v>{xxx}`：以十进制字符编码插入字符（最多三位）\n`<C-v>u{xxxx}`：以十六进制字符编码插入字符（最多四位）\n`<C-v>{nondigit}`：按原义插入非数字字符\n`<C-k>{char}{char}`：插入以二合字母`{char1}{char2}`表示的字符，例如`<C-k>!=`表示为`≠`\n\n`:h digraph-table`：查看具体的二合字母\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/digraph-table.png\" width=\"500\">\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/insert_mode-CvCk.gif\" width=\"500\">\n\n## 替换模式\n`r`，`R`：替换模式\n`gr`，`gR`虚拟替换模式\n为了显示`Tab键`，增加Vim配置:`set list`，`set listchars=tab:>-,trail:-`\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/insert_mode-replace_mode.gif\" width=\"500\">\n\n<!-- indicate-the-source -->\n","tags":["Vim"],"categories":["Vim"]},{"title":"Vim -- 普通模式","url":"%2F2015%2F11%2F03%2Fvim-commonmode%2F","content":"\n{% note info %}\n本文将介绍`Vim`中的`普通模式`\n{% endnote %}\n\n<!-- more -->\n\n# 基础\n\n## 概念\n`普通模式（normal mode）`是Vim的`自然放松`状态，也是Vim的`默认模式`\n`其他文本编辑器`大部分时间都处于类似Vim`插入模式`的状态中\n普通模式之所以强大，主要由于它可以把`操作符`和`动作命令`结合在一起：**`操作 = 操作符 + 动作命令`**\n\n```\n:h operator\nThe motion commands can be used after an operator command,\nto have the command operate on the text that was moved over.\nThat is the text between the cursor position before and after the motion.\nOperators are generally used to delete or change text.\n```\n\n## 语法规则\n`{operator}{motion}`\n`{operator}{operator}`（`motion`默认为`当前行`）\n\n## 操作符待决模式\n该模式在`调用操作符时被激活`，`只接受动作命令`的状态\n```\ngg=G\n\ngg：命名空间命令（普通模式的一个扩充），表示移动到首行\n=：操作符，表示缩进，激活操作符待决模式\nG：动作命令，表示到尾行\n```\n\n# 使用样例\n\n## 撤销命令 u\n该命令会`撤销最新的修改`\n在插入模式中使用光标键（`<Up>`，`<Down>`，`<Left>`，`<Right>`），会产生新的`撤销块`\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/common_mode_u.gif\" width=\"500\">\n\n## 删除一个单词（包括空格） daw\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/common_mode_daw.gif\" width=\"500\">\n\n## 数字加减 <C-a> <C-x>\n`{number}<C-a>`：正向查找第一个数字，并`加`number\n`{number}<C-x>`：正向查找第一个数字，并`减`number\n`0`开头的数字为`8`进制；`0x`开头的数字为`16`进制\n\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/common_mode_CaCx.gif\" width=\"500\">\n\n## 作用于当前行{operator}{operator} ： >>，gUU(gUgU)，dd\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/common_mode_opertor_opertor.gif\" width=\"500\">\n\n<!-- indicate-the-source -->\n","tags":["Vim"],"categories":["Vim"]},{"title":"Vim -- 命令.","url":"%2F2015%2F11%2F01%2Fvim-commandpoint%2F","content":"\n{% note info %}\n本文将介绍`Vim`中的`命令.`\n{% endnote %}\n\n<!-- more -->\n\n# 基础\n\n## Vim启动命令\n```Zsh\n# 不加载配置文件，且不启用vi兼容模式\n$ vim -u NONE -N\n```\n\n## Vim手册\n```Zsh\n$ man vim\n-u {vimrc}      Use the commands in the file {vimrc} for initializations.  \n                All the other initializations are skipped.  Use this to edit a special  kind  of  files.\n                It can also be used to skip all initializations by giving the name \"NONE\".\n                See \":help initialization\" within vim for more details.\n-N              No-compatible mode.  Reset the 'compatible' option.  This will make Vim behave a bit better,\n                but less Vi compatible, even though a .vimrc file does not exist.\n```\n\n## 命令.作用\n`命令.`会**`重复最近的一次修改`**\n\n# 使用样例\n\n## 普通模式\n\n### 删除一个字符 x\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_point_x.gif\" width=\"500\">\n\n### 删除一行 dd\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_point_dd.gif\" width=\"500\">\n\n### 缩进当前行到文档末尾 SHIFT + > + G\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_point_>G.gif\" width=\"500\">\n\n## 插入模式\n\n### 添加分号 A + ';'\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_point_A;.gif\" width=\"500\">\n\n### 行首添加字符串 I + 'start : ''\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_point_Istart.gif\" width=\"500\">\n\n### 增加一行 o + 'add line'\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_point_add_line.gif\" width=\"500\">\n\n### 截断到行尾 C\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_point_trunc_line.gif\" width=\"500\">\n\n### 代码添加空格 f+s空格+空格;\n`f{char}`：查找字符\n重复查找（推荐使用`n`和`N`，我们经常将`SHIFT`当成`取反`的意思，`N = SHIFT + n`）\n`;`或者`n`：`前向`重复上次查找\n`,`或者`N`：`反向`向重复上次查找\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_point_add_codespace.gif\" width=\"500\">\n\n### 选择性替换 *\n<img src=\"https://vim-1253868755.cos.ap-guangzhou.myqcloud.com/practical/command_point_selectivity_replace.gif\" width=\"500\">\n\n<!-- indicate-the-source -->\n","tags":["Vim"],"categories":["Vim"]}]